{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06c7c2c6",
   "metadata": {
    "papermill": {
     "duration": 0.011363,
     "end_time": "2025-03-14T13:08:40.556698",
     "exception": false,
     "start_time": "2025-03-14T13:08:40.545335",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c33e3b49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T13:08:40.578824Z",
     "iopub.status.busy": "2025-03-14T13:08:40.578588Z",
     "iopub.status.idle": "2025-03-14T13:09:06.922432Z",
     "shell.execute_reply": "2025-03-14T13:09:06.921718Z"
    },
    "papermill": {
     "duration": 26.356463,
     "end_time": "2025-03-14T13:09:06.924018",
     "exception": false,
     "start_time": "2025-03-14T13:08:40.567555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from collections import defaultdict\n",
    "from scipy.stats import beta\n",
    "from scipy.special import betaln\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068f1570",
   "metadata": {
    "papermill": {
     "duration": 0.010101,
     "end_time": "2025-03-14T13:09:06.945160",
     "exception": false,
     "start_time": "2025-03-14T13:09:06.935059",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cc3d3e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T13:09:06.966709Z",
     "iopub.status.busy": "2025-03-14T13:09:06.966223Z",
     "iopub.status.idle": "2025-03-14T13:09:06.969782Z",
     "shell.execute_reply": "2025-03-14T13:09:06.968986Z"
    },
    "papermill": {
     "duration": 0.01572,
     "end_time": "2025-03-14T13:09:06.971029",
     "exception": false,
     "start_time": "2025-03-14T13:09:06.955309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9160a511",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T13:09:06.992369Z",
     "iopub.status.busy": "2025-03-14T13:09:06.992109Z",
     "iopub.status.idle": "2025-03-14T13:09:06.995917Z",
     "shell.execute_reply": "2025-03-14T13:09:06.995179Z"
    },
    "papermill": {
     "duration": 0.015763,
     "end_time": "2025-03-14T13:09:06.997049",
     "exception": false,
     "start_time": "2025-03-14T13:09:06.981286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/working/results') == False:\n",
    "    os.mkdir('/kaggle/working/results')\n",
    "\n",
    "if os.path.exists('/kaggle/working/acquired_data') == False:\n",
    "    os.mkdir('/kaggle/working/acquired_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6eb002b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T13:09:07.018364Z",
     "iopub.status.busy": "2025-03-14T13:09:07.018134Z",
     "iopub.status.idle": "2025-03-14T13:09:07.027230Z",
     "shell.execute_reply": "2025-03-14T13:09:07.026642Z"
    },
    "papermill": {
     "duration": 0.020963,
     "end_time": "2025-03-14T13:09:07.028459",
     "exception": false,
     "start_time": "2025-03-14T13:09:07.007496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0ca413",
   "metadata": {
    "papermill": {
     "duration": 0.009874,
     "end_time": "2025-03-14T13:09:07.048598",
     "exception": false,
     "start_time": "2025-03-14T13:09:07.038724",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72d11e35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T13:09:07.069678Z",
     "iopub.status.busy": "2025-03-14T13:09:07.069478Z",
     "iopub.status.idle": "2025-03-14T13:09:07.121033Z",
     "shell.execute_reply": "2025-03-14T13:09:07.119641Z"
    },
    "papermill": {
     "duration": 0.063748,
     "end_time": "2025-03-14T13:09:07.122442",
     "exception": false,
     "start_time": "2025-03-14T13:09:07.058694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Shared resources\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "data_used = manager.list()\n",
    "sampling_dur = manager.list()\n",
    "new_samples = manager.list()\n",
    "\n",
    "# Non shared resources\n",
    "filename = 'dat-besra'\n",
    "epochs = 10\n",
    "batch_size = 4\n",
    "sequence_length = 192"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ff00e8",
   "metadata": {
    "papermill": {
     "duration": 0.011166,
     "end_time": "2025-03-14T13:09:07.143904",
     "exception": false,
     "start_time": "2025-03-14T13:09:07.132738",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e91b635c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T13:09:07.165453Z",
     "iopub.status.busy": "2025-03-14T13:09:07.165189Z",
     "iopub.status.idle": "2025-03-14T13:09:07.313516Z",
     "shell.execute_reply": "2025-03-14T13:09:07.312679Z"
    },
    "papermill": {
     "duration": 0.160599,
     "end_time": "2025-03-14T13:09:07.314828",
     "exception": false,
     "start_time": "2025-03-14T13:09:07.154229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>answer</th>\n",
       "      <th>1-FR</th>\n",
       "      <th>2-GI</th>\n",
       "      <th>3-PI</th>\n",
       "      <th>4-DM</th>\n",
       "      <th>5-EDTRB</th>\n",
       "      <th>6-RE</th>\n",
       "      <th>Text_Clean</th>\n",
       "      <th>filtered_text</th>\n",
       "      <th>token</th>\n",
       "      <th>tokens_stemmed</th>\n",
       "      <th>Process_Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Halo Rizal,Radang tenggorokan umunya disebabka...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo rizal radang tenggorokan umunya disebabka...</td>\n",
       "      <td>halo rizal radang tenggorokan umunya disebabka...</td>\n",
       "      <td>['halo', 'rizal', 'radang', 'tenggorokan', 'um...</td>\n",
       "      <td>['halo', 'rizal', 'radang', 'tenggorok', 'umu'...</td>\n",
       "      <td>halo rizal radang tenggorok umu sebab infeksi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Halo Hellas,Cacar air merupakan suatu penyakit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo hellas cacar air merupakan suatu penyakit...</td>\n",
       "      <td>halo hellas cacar air penyakit disebabkan viru...</td>\n",
       "      <td>['halo', 'hellas', 'cacar', 'air', 'penyakit',...</td>\n",
       "      <td>['halo', 'hellas', 'cacar', 'air', 'sakit', 's...</td>\n",
       "      <td>halo hellas cacar air sakit sebab virus varise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Halo Rory.......Terimakasih atas pertanyaan An...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo rory terimakasih atas pertanyaan anda per...</td>\n",
       "      <td>halo rory terimakasih ketahui gangguan kulit s...</td>\n",
       "      <td>['halo', 'rory', 'terimakasih', 'ketahui', 'ga...</td>\n",
       "      <td>['halo', 'rory', 'terimakasih', 'tahu', 'gangg...</td>\n",
       "      <td>halo rory terimakasih tahu ganggu kulit rangka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Alo AfriYani, Terimakasih atas pertanyaannya. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>alo afriyani terimakasih atas pertanyaannya ku...</td>\n",
       "      <td>alo afriyani terimakasih pertanyaannya kuku ja...</td>\n",
       "      <td>['alo', 'afriyani', 'terimakasih', 'pertanyaan...</td>\n",
       "      <td>['alo', 'afriyani', 'terimakasih', 'tanya', 'k...</td>\n",
       "      <td>alo afriyani terimakasih tanya kuku jari kaki ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Halo,Telinga berdenging atau  tinitus  merupak...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo telinga berdenging atau tinitus merupakan...</td>\n",
       "      <td>halo telinga berdenging tinitus sensasi penden...</td>\n",
       "      <td>['halo', 'telinga', 'berdenging', 'tinitus', '...</td>\n",
       "      <td>['halo', 'telinga', 'denging', 'tinitus', 'sen...</td>\n",
       "      <td>halo telinga denging tinitus sensasi dengar de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No                                             answer  1-FR  2-GI  3-PI  \\\n",
       "0   1  Halo Rizal,Radang tenggorokan umunya disebabka...     1     0     1   \n",
       "1   2  Halo Hellas,Cacar air merupakan suatu penyakit...     1     0     1   \n",
       "2   3  Halo Rory.......Terimakasih atas pertanyaan An...     1     0     1   \n",
       "3   4  Alo AfriYani, Terimakasih atas pertanyaannya. ...     1     0     1   \n",
       "4   5  Halo,Telinga berdenging atau  tinitus  merupak...     1     0     1   \n",
       "\n",
       "   4-DM  5-EDTRB  6-RE                                         Text_Clean  \\\n",
       "0     1        1     0  halo rizal radang tenggorokan umunya disebabka...   \n",
       "1     1        1     0  halo hellas cacar air merupakan suatu penyakit...   \n",
       "2     1        1     0  halo rory terimakasih atas pertanyaan anda per...   \n",
       "3     1        1     0  alo afriyani terimakasih atas pertanyaannya ku...   \n",
       "4     1        1     0  halo telinga berdenging atau tinitus merupakan...   \n",
       "\n",
       "                                       filtered_text  \\\n",
       "0  halo rizal radang tenggorokan umunya disebabka...   \n",
       "1  halo hellas cacar air penyakit disebabkan viru...   \n",
       "2  halo rory terimakasih ketahui gangguan kulit s...   \n",
       "3  alo afriyani terimakasih pertanyaannya kuku ja...   \n",
       "4  halo telinga berdenging tinitus sensasi penden...   \n",
       "\n",
       "                                               token  \\\n",
       "0  ['halo', 'rizal', 'radang', 'tenggorokan', 'um...   \n",
       "1  ['halo', 'hellas', 'cacar', 'air', 'penyakit',...   \n",
       "2  ['halo', 'rory', 'terimakasih', 'ketahui', 'ga...   \n",
       "3  ['alo', 'afriyani', 'terimakasih', 'pertanyaan...   \n",
       "4  ['halo', 'telinga', 'berdenging', 'tinitus', '...   \n",
       "\n",
       "                                      tokens_stemmed  \\\n",
       "0  ['halo', 'rizal', 'radang', 'tenggorok', 'umu'...   \n",
       "1  ['halo', 'hellas', 'cacar', 'air', 'sakit', 's...   \n",
       "2  ['halo', 'rory', 'terimakasih', 'tahu', 'gangg...   \n",
       "3  ['alo', 'afriyani', 'terimakasih', 'tanya', 'k...   \n",
       "4  ['halo', 'telinga', 'denging', 'tinitus', 'sen...   \n",
       "\n",
       "                                        Process_Data  \n",
       "0  halo rizal radang tenggorok umu sebab infeksi ...  \n",
       "1  halo hellas cacar air sakit sebab virus varise...  \n",
       "2  halo rory terimakasih tahu ganggu kulit rangka...  \n",
       "3  alo afriyani terimakasih tanya kuku jari kaki ...  \n",
       "4  halo telinga denging tinitus sensasi dengar de...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/kaggle/input/doctors-answer-text-dataset/Indo-Online Health Consultation-Medical Interview-Clean.csv', encoding='latin-1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b97d6f0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T13:09:07.337679Z",
     "iopub.status.busy": "2025-03-14T13:09:07.337443Z",
     "iopub.status.idle": "2025-03-14T13:09:07.354838Z",
     "shell.execute_reply": "2025-03-14T13:09:07.353896Z"
    },
    "papermill": {
     "duration": 0.030195,
     "end_time": "2025-03-14T13:09:07.356036",
     "exception": false,
     "start_time": "2025-03-14T13:09:07.325841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,) (400, 6)\n",
      "(100,) (100, 6)\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "train_labels = train_data.columns[2:8]\n",
    "val_labels = val_data.columns[2:8]\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['Text_Clean'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['Text_Clean'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ec7a1d",
   "metadata": {
    "papermill": {
     "duration": 0.010198,
     "end_time": "2025-03-14T13:09:07.376781",
     "exception": false,
     "start_time": "2025-03-14T13:09:07.366583",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BUILD DATASET & DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a763df8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T13:09:07.398682Z",
     "iopub.status.busy": "2025-03-14T13:09:07.398449Z",
     "iopub.status.idle": "2025-03-14T13:09:08.818287Z",
     "shell.execute_reply": "2025-03-14T13:09:08.817629Z"
    },
    "papermill": {
     "duration": 1.432275,
     "end_time": "2025-03-14T13:09:08.819626",
     "exception": false,
     "start_time": "2025-03-14T13:09:07.387351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5829f9545f8747e7aafbfdb30191327d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1ad97c8a3a4c5f8c5960a29a84e066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4508888d1b44bd9a8bfe0996fb0bb9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ad7542c5e041ff97a53b70e9c84dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class DoctorAnswerDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=256, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        labels = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(labels, dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "    def get_per_class_probs(self):\n",
    "        \"\"\"\n",
    "        Calculate the spread of labels (0 and 1) for each class in the dataset.\n",
    "        Returns:\n",
    "            dict: A dictionary where keys are class indices and values are [count_0, count_1].\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize a dictionary to store counts for each class\n",
    "        label_counts = defaultdict(lambda: [0, 0])  # [count_0, count_1] for each class\n",
    "\n",
    "        for i in range(len(self)):\n",
    "            # Get the labels for the i-th sample\n",
    "            labels = self[i]['labels']\n",
    "\n",
    "            # Update counts for each class\n",
    "            for class_idx, label in enumerate(labels):\n",
    "                label_counts[class_idx][int(label)] += 1\n",
    "\n",
    "        for key in label_counts.keys():\n",
    "            total = sum(label_counts[key])\n",
    "            label_counts[key] = [x / total for x in label_counts[key]]\n",
    "\n",
    "        return label_counts\n",
    "\n",
    "    def get_global_probs(self):\n",
    "        \"\"\"\n",
    "        Calculate the global count of 0s and 1s across all classes in the dataset.\n",
    "        Returns:\n",
    "            dict: A dictionary with keys '0' and '1' representing their global counts.\n",
    "        \"\"\"\n",
    "        global_counts = {'0': 0, '1': 0}\n",
    "\n",
    "        for i in range(len(self)):\n",
    "            # Get the labels for the i-th sample\n",
    "            labels = self[i]['labels']\n",
    "\n",
    "            # Update global counts\n",
    "            for label in labels:\n",
    "                global_counts[str(int(label))] += 1\n",
    "\n",
    "        total = global_counts['0'] + global_counts['1']\n",
    "        for key in global_counts.keys():\n",
    "            global_counts[key] /= total\n",
    "\n",
    "        return global_counts\n",
    "\n",
    "\n",
    "# Initialize BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3561aca2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T13:09:08.843609Z",
     "iopub.status.busy": "2025-03-14T13:09:08.843366Z",
     "iopub.status.idle": "2025-03-14T13:09:08.847647Z",
     "shell.execute_reply": "2025-03-14T13:09:08.846877Z"
    },
    "papermill": {
     "duration": 0.017557,
     "end_time": "2025-03-14T13:09:08.848897",
     "exception": false,
     "start_time": "2025-03-14T13:09:08.831340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataloaders(X_train, y_train, X_val, y_val, sequence_length=256, num_workers=4):\n",
    "    train_dataset = DoctorAnswerDataset(X_train, y_train, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = DoctorAnswerDataset(X_val, y_val, tokenizer, max_length=sequence_length)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b83d544a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T13:09:08.871793Z",
     "iopub.status.busy": "2025-03-14T13:09:08.871568Z",
     "iopub.status.idle": "2025-03-14T13:09:08.877086Z",
     "shell.execute_reply": "2025-03-14T13:09:08.876489Z"
    },
    "papermill": {
     "duration": 0.018314,
     "end_time": "2025-03-14T13:09:08.878294",
     "exception": false,
     "start_time": "2025-03-14T13:09:08.859980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7d8cd9fb0c70>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7d8cd9fb1810>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dataloaders(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84625169",
   "metadata": {
    "papermill": {
     "duration": 0.010694,
     "end_time": "2025-03-14T13:09:08.899831",
     "exception": false,
     "start_time": "2025-03-14T13:09:08.889137",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5953b6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T13:09:08.922379Z",
     "iopub.status.busy": "2025-03-14T13:09:08.922168Z",
     "iopub.status.idle": "2025-03-14T13:09:08.925564Z",
     "shell.execute_reply": "2025-03-14T13:09:08.924968Z"
    },
    "papermill": {
     "duration": 0.015931,
     "end_time": "2025-03-14T13:09:08.926705",
     "exception": false,
     "start_time": "2025-03-14T13:09:08.910774",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5564f9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T13:09:08.949338Z",
     "iopub.status.busy": "2025-03-14T13:09:08.949088Z",
     "iopub.status.idle": "2025-03-14T13:09:08.953603Z",
     "shell.execute_reply": "2025-03-14T13:09:08.952954Z"
    },
    "papermill": {
     "duration": 0.017138,
     "end_time": "2025-03-14T13:09:08.954775",
     "exception": false,
     "start_time": "2025-03-14T13:09:08.937637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        target_names=['1-FR', '2-GI', '3-PI', '4-DM', '5-EDTRB', '6-RE'],\n",
    "        zero_division=0\n",
    "    )  \n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23a33ff5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T13:09:08.977286Z",
     "iopub.status.busy": "2025-03-14T13:09:08.977021Z",
     "iopub.status.idle": "2025-03-14T13:09:08.988401Z",
     "shell.execute_reply": "2025-03-14T13:09:08.987828Z"
    },
    "papermill": {
     "duration": 0.023924,
     "end_time": "2025-03-14T13:09:08.989628",
     "exception": false,
     "start_time": "2025-03-14T13:09:08.965704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, metrics, trials, i):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "\n",
    "    # Define DataLoaders\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    train_loader, val_loader = get_dataloaders(current_X_train, current_y_train, X_val, y_val)\n",
    "\n",
    "    with accelerator.main_process_first():\n",
    "        model = BertForSequenceClassification.from_pretrained(\n",
    "            'indobenchmark/indobert-base-p2',\n",
    "            num_labels=len(train_labels),\n",
    "            problem_type=\"multi_label_classification\"\n",
    "        )\n",
    "        \n",
    "    # Define optimizer and loss function\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Prepare everything with Accelerator\n",
    "    model, optimizer, train_loader, val_loader = accelerator.prepare(\n",
    "        model, optimizer, train_loader, val_loader\n",
    "    )\n",
    "\n",
    "    best_result = None\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key != 'labels'}\n",
    "            labels = batch['labels']\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key != 'labels'}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "        result = compute_metrics(type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}))\n",
    "\n",
    "        if best_result is None or result['f1_micro'] >= best_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'{filename}-{trials+1}-model-{i+1}',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "            best_result = result\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    accelerator.print(f\"Model {i+1} - Iteration {current_train_size}: Accuracy: {round(best_result['accuracy'], 4)}, F1 Micro: {round(best_result['f1_micro'], 4)}, F1 Macro: {round(best_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(best_result['report'])\n",
    "        \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    accelerator.print(f\"Training completed in {duration} s\")\n",
    "    \n",
    "    # Update the shared lists\n",
    "    if accelerator.is_local_main_process:\n",
    "        metrics[0].append(best_result['accuracy'])\n",
    "        metrics[1].append(best_result['f1_micro'])\n",
    "        metrics[2].append(best_result['f1_macro'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a08ca5",
   "metadata": {
    "papermill": {
     "duration": 0.010643,
     "end_time": "2025-03-14T13:09:09.011076",
     "exception": false,
     "start_time": "2025-03-14T13:09:09.000433",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PLOT RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b808e6ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T13:09:09.033428Z",
     "iopub.status.busy": "2025-03-14T13:09:09.033198Z",
     "iopub.status.idle": "2025-03-14T13:09:09.038482Z",
     "shell.execute_reply": "2025-03-14T13:09:09.037623Z"
    },
    "papermill": {
     "duration": 0.017946,
     "end_time": "2025-03-14T13:09:09.039822",
     "exception": false,
     "start_time": "2025-03-14T13:09:09.021876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60df6a7",
   "metadata": {
    "papermill": {
     "duration": 0.010894,
     "end_time": "2025-03-14T13:09:09.061628",
     "exception": false,
     "start_time": "2025-03-14T13:09:09.050734",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QUERY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c0c8059",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T13:09:09.084463Z",
     "iopub.status.busy": "2025-03-14T13:09:09.084210Z",
     "iopub.status.idle": "2025-03-14T13:09:09.104757Z",
     "shell.execute_reply": "2025-03-14T13:09:09.103927Z"
    },
    "papermill": {
     "duration": 0.033492,
     "end_time": "2025-03-14T13:09:09.105956",
     "exception": false,
     "start_time": "2025-03-14T13:09:09.072464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def beta_score(p, y, alpha=0.1, beta=3):\n",
    "    \"\"\"Calculates Beta score for a given probability p and label y.\"\"\"\n",
    "    \n",
    "    if y == 1:\n",
    "        return -betaln(alpha, beta + 1) + betaln(alpha + p, beta + 1 - p)\n",
    "    elif y == 0:\n",
    "        return -betaln(alpha + 1, beta) + betaln(alpha + 1 - p, beta + p)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid label: y must be 0 or 1.\")\n",
    "\n",
    "def bayesian_update(prior, likelihood, evidence, alpha=0.1, beta_param=3):\n",
    "    \"\"\" \n",
    "    Bayes' Theorem: P(y'|x') = P(x'|y') * P(y') / P(x')\n",
    "    P(y'|x') or likelihood = model probs\n",
    "    p(y') or prior = class probabilities\n",
    "    p(x') or evidence = 1 / number of data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Using the Beta score to simulate the posterior\n",
    "    posterior = (likelihood * prior) / evidence\n",
    "    \n",
    "    # We calculate the posterior using the Beta distribution\n",
    "    return posterior\n",
    "\n",
    "def compute_expected_score_change(predicted_prob, class_probs, label_probs, class_idx):\n",
    "    scores_before = []\n",
    "    scores_after = []\n",
    "\n",
    "    # Before data addition: calculate Beta score for predicted prob\n",
    "    scores_before.append(beta_score(predicted_prob, int(1 if predicted_prob >= 0.5 else 0)))\n",
    "    scores_before.append(beta_score(1-predicted_prob, int(1 if predicted_prob >= 0.5 else 0)))\n",
    "    \n",
    "    # After data addition: use Bayesian update (posterior probability)\n",
    "    for k in range(2):\n",
    "        prior = predicted_prob\n",
    "        likelihood = class_probs[class_idx][k]  # Likelihood is the true label (0 or 1)\n",
    "        posterior = bayesian_update(prior, likelihood, 1)\n",
    "        scores_after.append(beta_score(posterior, int(1 if posterior >= 0.5 else 0)))\n",
    "\n",
    "    score_diff_0 = scores_after[0] - scores_before[0]\n",
    "    score_diff_1 = scores_after[1] - scores_before[1]\n",
    "    return label_probs['0'] * score_diff_0 + label_probs['1'] * score_diff_1\n",
    "\n",
    "# Function to compute Expected Score Change (âˆ†Q)\n",
    "def besra_sampling(models, X_pool, train_indices, remaining_indices, tokenizer, sampling_dur, new_samples, trials, n_clusters=min_increment):\n",
    "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "    device = accelerator.device\n",
    "    \n",
    "    dataset = DoctorAnswerDataset(X_pool, np.zeros((len(X_pool), 6)), tokenizer, max_length=sequence_length)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    current_train_size = len(train_indices)\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    labeled_dataset = DoctorAnswerDataset(current_X_train, current_y_train, tokenizer, max_length=sequence_length)\n",
    "    label_probs = labeled_dataset.get_global_probs()\n",
    "    class_probs = labeled_dataset.get_per_class_probs()\n",
    "\n",
    "    for model in models:\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "    start_time = time.time()\n",
    "    score_changes = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids'].to(model.device)\n",
    "        attention_mask = batch['attention_mask'].to(model.device)\n",
    "        labels = batch['labels'].to(model.device)\n",
    "\n",
    "        model_probs = []\n",
    "\n",
    "        for model in models:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "                probs = torch.sigmoid(logits)  # Multi-label classification uses sigmoid\n",
    "                model_probs.append(probs.unsqueeze(0))  # Add batch dimension for averaging\n",
    "        \n",
    "        # Stack all model predictions and compute the mean across models\n",
    "        model_probs = torch.cat(model_probs, dim=0)  # Concatenate predictions across models\n",
    "        probs = model_probs.mean(dim=0)  # Take the mean along the model axis\n",
    "\n",
    "        # Calculate Beta scores before and after data addition\n",
    "        for i in range(len(probs)):\n",
    "            score_diff = []\n",
    "            for class_idx in range(probs.shape[1]):\n",
    "                predicted_prob = probs[i, class_idx].item()\n",
    "                score_diff.append(compute_expected_score_change(predicted_prob, class_probs, label_probs, class_idx))\n",
    "            \n",
    "            score_changes.append(np.mean(score_diff))\n",
    "    \n",
    "    accelerator.wait_for_everyone()    \n",
    "    if accelerator.is_local_main_process:\n",
    "        score_changes = np.array(score_changes)\n",
    "        score_changes = score_changes.reshape(-1, 1)\n",
    "\n",
    "        target_samples = math.ceil(0.1 * len(X_pool))\n",
    "        collected_indices = set()\n",
    "        thresholds = []\n",
    "    \n",
    "        # Check nearest checkpoint\n",
    "        nearest_cp = 0\n",
    "        arrived_at_cp = False\n",
    "        for cp in checkpoints:\n",
    "            if cp > current_train_size:\n",
    "                nearest_cp = cp\n",
    "                break\n",
    "\n",
    "        # Determine number of maximum samples to be acquired\n",
    "        if target_samples <= n_clusters and n_clusters < nearest_cp - current_train_size:\n",
    "            target_samples = n_clusters\n",
    "        elif target_samples > n_clusters and target_samples < nearest_cp - current_train_size:\n",
    "            target_samples = target_samples\n",
    "        else:\n",
    "            arrived_at_cp = True\n",
    "            target_samples = nearest_cp - current_train_size\n",
    "\n",
    "        # No clustering needed when there's little data left\n",
    "        if current_train_size >= checkpoints[len(checkpoints)-1] - min_increment:\n",
    "            end_time = time.time()\n",
    "            duration = end_time - start_time\n",
    "            \n",
    "            temp = train_indices.copy()\n",
    "            temp.extend(remaining_indices)\n",
    "            \n",
    "            # Save acquired data up to checkpoint\n",
    "            acquired_data = pd.DataFrame({\n",
    "                'processed_text': [X_train[i] for i in temp],\n",
    "                '1-FR': [y_train[i][0] for i in temp],\n",
    "                '2-GI': [y_train[i][1] for i in temp],\n",
    "                '3-PI': [y_train[i][2] for i in temp],\n",
    "                '4-DM': [y_train[i][3] for i in temp],\n",
    "                '5-EDTRB': [y_train[i][4] for i in temp],\n",
    "                '6-RE': [y_train[i][5] for i in temp],\n",
    "            })\n",
    "            acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "\n",
    "            print(\"Nearest checkpoint:\", nearest_cp)\n",
    "            print(\"Acquired samples:\", len(remaining_indices))\n",
    "            print(f\"Sampling duration: {duration} seconds\")\n",
    "            \n",
    "            sampling_dur.append(duration)\n",
    "            for i in remaining_indices:\n",
    "                new_samples.append(i)\n",
    "\n",
    "        else:\n",
    "            # Cluster the data based on its embeddings\n",
    "            kmeans=KMeans(n_clusters=n_clusters, n_init=1)\n",
    "            kmeans.fit(score_changes)\n",
    "            \n",
    "            for cluster_id in range(n_clusters):\n",
    "                # Cluster center and indices of samples in the current cluster\n",
    "                cluster_center = kmeans.cluster_centers_[cluster_id]\n",
    "                cluster_indices = np.where(kmeans.labels_ == cluster_id)[0]\n",
    "            \n",
    "                if cluster_indices.size == 0:\n",
    "                    # Skip clusters with no members\n",
    "                    print(f\"Cluster {cluster_id} has no members, skipping.\")\n",
    "                    continue\n",
    "            \n",
    "                # Calculate distances of each point in the cluster from the cluster center\n",
    "                cluster_distances = np.linalg.norm(score_changes[cluster_indices] - cluster_center, axis=1)\n",
    "            \n",
    "                # Determine the local threshold (10th percentile of closest distances to cluster center)\n",
    "                local_threshold = np.percentile(cluster_distances, 90)\n",
    "                thresholds.append(local_threshold)\n",
    "            \n",
    "                below_threshold_indices = cluster_indices[cluster_distances >= local_threshold]\n",
    "                collected_indices.update(below_threshold_indices)\n",
    "\n",
    "            # To handle multiple points with same distance\n",
    "            if len(collected_indices) > target_samples:\n",
    "                collected_indices = np.array(list(collected_indices))\n",
    "                np.random.shuffle(collected_indices)\n",
    "                collected_indices = collected_indices[:target_samples]\n",
    "                \n",
    "            end_time = time.time() \n",
    "            duration = end_time - start_time \n",
    "    \n",
    "            if arrived_at_cp:\n",
    "                temp = train_indices.copy()\n",
    "                temp.extend(collected_indices)\n",
    "                \n",
    "                # Save acquired data up to checkpoint\n",
    "                acquired_data = pd.DataFrame({\n",
    "                    'processed_text': [X_train[i] for i in temp],\n",
    "                    '1-FR': [y_train[i][0] for i in temp],\n",
    "                    '2-GI': [y_train[i][1] for i in temp],\n",
    "                    '3-PI': [y_train[i][2] for i in temp],\n",
    "                    '4-DM': [y_train[i][3] for i in temp],\n",
    "                    '5-EDTRB': [y_train[i][4] for i in temp],\n",
    "                    '6-RE': [y_train[i][5] for i in temp],\n",
    "                })\n",
    "        \n",
    "                acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "            \n",
    "            print(\"Nearest checkpoint:\", nearest_cp)\n",
    "            print(\"Acquired samples:\", len(collected_indices))\n",
    "            print(f\"Sampling duration: {duration} seconds\")\n",
    "        \n",
    "            sampling_dur.append(duration)\n",
    "            for i in collected_indices:\n",
    "                new_samples.append(remaining_indices[i])\n",
    "\n",
    "        threshold_data = pd.DataFrame({\n",
    "            'Threshold': thresholds\n",
    "        })\n",
    "        threshold_data.to_csv(f\"results/{filename}-thresholds-{trials+1}-{current_train_size}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0792d643",
   "metadata": {
    "papermill": {
     "duration": 0.010795,
     "end_time": "2025-03-14T13:09:09.127834",
     "exception": false,
     "start_time": "2025-03-14T13:09:09.117039",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4dc9df8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T13:09:09.152101Z",
     "iopub.status.busy": "2025-03-14T13:09:09.151875Z",
     "iopub.status.idle": "2025-03-14T13:09:09.161932Z",
     "shell.execute_reply": "2025-03-14T13:09:09.161170Z"
    },
    "papermill": {
     "duration": 0.024379,
     "end_time": "2025-03-14T13:09:09.163206",
     "exception": false,
     "start_time": "2025-03-14T13:09:09.138827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i):\n",
    "    accuracies = manager.list()\n",
    "    f1_micros = manager.list()\n",
    "    f1_macros = manager.list()\n",
    "    data_used = manager.list()\n",
    "    sampling_dur = manager.list()\n",
    "    new_samples = manager.list()\n",
    "    \n",
    "    print(\"TRIAL {}\".format(i+1))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "\n",
    "    \n",
    "    \n",
    "    start_time = time.time()\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        model_accuracies = manager.list()\n",
    "        model_f1_micros = manager.list()\n",
    "        model_f1_macros = manager.list()\n",
    "        \n",
    "        # Train the model\n",
    "        for j in range(3):\n",
    "            set_seed(seed[j])\n",
    "            args = (current_train_size, train_indices, (model_accuracies, model_f1_micros, model_f1_macros), i, j)\n",
    "            notebook_launcher(train_model, args, num_processes=2)\n",
    "\n",
    "        data_used.append(current_train_size)\n",
    "        accuracies.append(np.mean(model_accuracies))\n",
    "        f1_micros.append(np.mean(model_f1_micros))\n",
    "        f1_macros.append(np.mean(model_f1_macros))\n",
    "        print(f\"Averaged - Iteration {current_train_size}: Accuracy: {round(np.mean(accuracies), 4)}, F1 Micro: {round(np.mean(f1_micros), 4)}, F1 Macro: {round(np.mean(f1_macros), 4)}\")\n",
    "\n",
    "        models = []\n",
    "        for j in range(3):\n",
    "            model = BertForSequenceClassification.from_pretrained(f'{filename}-{i+1}-model-{j+1}')\n",
    "            models.append(model)\n",
    "        \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples = manager.list()\n",
    "        sampling_args = (models, [X_train[i] for i in remaining_indices], train_indices, remaining_indices, tokenizer, sampling_dur, new_samples, i)\n",
    "        notebook_launcher(besra_sampling, sampling_args, num_processes=2)\n",
    "        new_samples = list(new_samples)\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    model_accuracies = manager.list()\n",
    "    model_f1_micros = manager.list()\n",
    "    model_f1_macros = manager.list()\n",
    "    \n",
    "    for j in range(3):\n",
    "        set_seed(seed[j])\n",
    "        args = (current_train_size, train_indices, (model_accuracies, model_f1_micros, model_f1_macros), i, j)\n",
    "        notebook_launcher(train_model, args, num_processes=2)\n",
    "        \n",
    "    data_used.append(current_train_size)\n",
    "    accuracies.append(np.mean(model_accuracies))\n",
    "    f1_micros.append(np.mean(model_f1_micros))\n",
    "    f1_macros.append(np.mean(model_f1_macros))\n",
    "    print(f\"Averaged - Iteration {current_train_size}: Accuracy: {round(np.mean(accuracies), 4)}, F1 Micro: {round(np.mean(f1_micros), 4)}, F1 Macro: {round(np.mean(f1_macros), 4)}\")\n",
    "        \n",
    "    data_used, accuracies, f1_micros, f1_macros, sampling_dur = list(data_used), list(accuracies), list(f1_micros), list(f1_macros), list(sampling_dur)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    \n",
    "    sampling_dur.insert(0, 0)\n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    results.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a317cbba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T13:09:09.185920Z",
     "iopub.status.busy": "2025-03-14T13:09:09.185698Z",
     "iopub.status.idle": "2025-03-14T13:09:09.189013Z",
     "shell.execute_reply": "2025-03-14T13:09:09.188280Z"
    },
    "papermill": {
     "duration": 0.015695,
     "end_time": "2025-03-14T13:09:09.190172",
     "exception": false,
     "start_time": "2025-03-14T13:09:09.174477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [[50, 67, 42], [81, 90, 11], [14, 7, 33], [3, 44, 85], [94, 21, 5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c072acbf",
   "metadata": {
    "papermill": {
     "duration": 0.010723,
     "end_time": "2025-03-14T13:09:09.211809",
     "exception": false,
     "start_time": "2025-03-14T13:09:09.201086",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3eeacc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-14T13:09:09.235083Z",
     "iopub.status.busy": "2025-03-14T13:09:09.234859Z",
     "iopub.status.idle": "2025-03-14T14:46:08.392272Z",
     "shell.execute_reply": "2025-03-14T14:46:08.391310Z"
    },
    "papermill": {
     "duration": 5819.171159,
     "end_time": "2025-03-14T14:46:08.393893",
     "exception": false,
     "start_time": "2025-03-14T13:09:09.222734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 1\n",
      "Random seed: [50, 67, 42]\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5938, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3975, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2793, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2126, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2185, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1651, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2095, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1328, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1332, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1526, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 1 - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 40.92873167991638 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.638, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4006, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.296, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2339, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2347, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1755, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2175, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1383, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1454, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1626, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 2 - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 38.34223961830139 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5657, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3775, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2687, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2018, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2273, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.156, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2098, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1346, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1357, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1585, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 3 - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 38.27757287025452 s\n",
      "Averaged - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 38\n",
      "Sampling duration: 12.580198287963867 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4884, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.232, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1879, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1546, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1461, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1418, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1161, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0974, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1166, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.087, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 1 - Iteration 63: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 44.58583950996399 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5064, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2491, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1913, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1625, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1524, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1454, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1278, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0997, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1254, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0992, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 2 - Iteration 63: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 43.307775020599365 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4589, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2181, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1785, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1519, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1482, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1414, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1217, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0971, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.12, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0954, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 3 - Iteration 63: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 42.69642996788025 s\n",
      "Averaged - Iteration 63: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 34\n",
      "Sampling duration: 13.091331958770752 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3826, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1972, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1823, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1361, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.136, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1057, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1103, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "Epoch 8/10, Train Loss: 0.1167, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.6528\n",
      "Epoch 9/10, Train Loss: 0.084, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0879, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "Model 1 - Iteration 97: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.64      0.66      0.65       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 51.01919984817505 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4229, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2101, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1872, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1429, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1382, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1081, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1222, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1192, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 9/10, Train Loss: 0.0862, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.652\n",
      "Epoch 10/10, Train Loss: 0.0857, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6526\n",
      "Model 2 - Iteration 97: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 46.20804023742676 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3655, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1934, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1839, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1353, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1323, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1055, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1155, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 8/10, Train Loss: 0.106, Accuracy: 0.9583, F1 Micro: 0.9681, F1 Macro: 0.6497\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.074, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Epoch 10/10, Train Loss: 0.0749, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6526\n",
      "Model 3 - Iteration 97: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 46.48961329460144 s\n",
      "Averaged - Iteration 97: Accuracy: 0.9635, F1 Micro: 0.9723, F1 Macro: 0.6531\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 31\n",
      "Sampling duration: 12.025523662567139 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3777, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1937, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1388, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.166, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1309, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1135, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.11, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Epoch 8/10, Train Loss: 0.1037, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6526\n",
      "Epoch 9/10, Train Loss: 0.0899, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6526\n",
      "Epoch 10/10, Train Loss: 0.081, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.6528\n",
      "Model 1 - Iteration 128: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 49.96286344528198 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3934, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2002, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1435, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1684, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1329, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1218, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1148, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1119, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "Epoch 9/10, Train Loss: 0.1108, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.084, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "Model 2 - Iteration 128: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.64      0.66      0.65       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 52.361305236816406 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3502, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1894, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1389, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1651, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1309, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1188, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 7/10, Train Loss: 0.1096, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1039, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0891, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Epoch 10/10, Train Loss: 0.0679, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6523\n",
      "Model 3 - Iteration 128: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 50.761250734329224 s\n",
      "Averaged - Iteration 128: Accuracy: 0.9638, F1 Micro: 0.9725, F1 Macro: 0.6532\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 28\n",
      "Sampling duration: 10.89576506614685 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3318, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1944, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1585, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1454, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1531, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Epoch 6/10, Train Loss: 0.097, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6526\n",
      "Epoch 7/10, Train Loss: 0.1085, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6517\n",
      "Epoch 8/10, Train Loss: 0.0817, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6517\n",
      "Epoch 9/10, Train Loss: 0.0616, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6517\n",
      "Epoch 10/10, Train Loss: 0.0566, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6517\n",
      "Model 1 - Iteration 156: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 52.590503454208374 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3539, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1995, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1651, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1497, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1654, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 6/10, Train Loss: 0.1129, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1311, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 8/10, Train Loss: 0.1036, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Epoch 9/10, Train Loss: 0.0688, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0608, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7217\n",
      "Model 2 - Iteration 156: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7217\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.70      0.72       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 55.65592050552368 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3179, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1965, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1622, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1498, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1651, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 6/10, Train Loss: 0.1123, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.6528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1199, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7091\n",
      "Epoch 8/10, Train Loss: 0.0853, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.7162\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0576, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7202\n",
      "Epoch 10/10, Train Loss: 0.0542, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7201\n",
      "Model 3 - Iteration 156: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7202\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.81      0.71      0.72       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 56.30544567108154 s\n",
      "Averaged - Iteration 156: Accuracy: 0.9644, F1 Micro: 0.973, F1 Macro: 0.6623\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 25\n",
      "Sampling duration: 10.094423770904541 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3331, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1505, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.154, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1398, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1389, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1253, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1099, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "Epoch 8/10, Train Loss: 0.075, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.6522\n",
      "Epoch 9/10, Train Loss: 0.0694, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0602, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7227\n",
      "Model 1 - Iteration 181: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7227\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.71      0.72       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 62.040186405181885 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3476, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1565, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1543, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1506, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1531, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 6/10, Train Loss: 0.1373, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6526\n",
      "Epoch 7/10, Train Loss: 0.1206, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.6528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0786, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7214\n",
      "Epoch 9/10, Train Loss: 0.0687, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7206\n",
      "Epoch 10/10, Train Loss: 0.0504, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7384\n",
      "Model 2 - Iteration 181: Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7214\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.92      0.94      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.97      0.98       407\n",
      "   macro avg       0.82      0.70      0.72       407\n",
      "weighted avg       0.97      0.97      0.97       407\n",
      " samples avg       0.98      0.97      0.98       407\n",
      "\n",
      "Training completed in 58.73750352859497 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3195, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1514, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1532, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1464, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1436, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1312, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "Epoch 7/10, Train Loss: 0.1064, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.653\n",
      "Epoch 8/10, Train Loss: 0.0678, Accuracy: 0.9599, F1 Micro: 0.969, F1 Macro: 0.6499\n",
      "Epoch 9/10, Train Loss: 0.0605, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7182\n",
      "Epoch 10/10, Train Loss: 0.0477, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.736\n",
      "Model 3 - Iteration 181: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.64      0.66      0.65       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 58.16309595108032 s\n",
      "Averaged - Iteration 181: Accuracy: 0.9651, F1 Micro: 0.9735, F1 Macro: 0.6684\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 22\n",
      "Sampling duration: 8.753212213516235 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3075, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1661, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1353, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1377, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1409, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1187, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.114, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Epoch 8/10, Train Loss: 0.0775, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0609, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0474, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Model 1 - Iteration 203: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.65      0.66      0.65       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 67.78618574142456 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3206, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1684, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1417, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1412, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.15, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1195, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1149, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Epoch 8/10, Train Loss: 0.0737, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Epoch 9/10, Train Loss: 0.054, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7193\n",
      "Epoch 10/10, Train Loss: 0.0425, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7193\n",
      "Model 2 - Iteration 203: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.65      0.66      0.65       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 64.93962574005127 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2876, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.165, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1371, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1383, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1339, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Epoch 6/10, Train Loss: 0.1083, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.652\n",
      "Epoch 7/10, Train Loss: 0.1003, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6526\n",
      "Epoch 8/10, Train Loss: 0.0602, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.6528\n",
      "Epoch 9/10, Train Loss: 0.0453, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7186\n",
      "Epoch 10/10, Train Loss: 0.0389, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6526\n",
      "Model 3 - Iteration 203: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 61.44979000091553 s\n",
      "Averaged - Iteration 203: Accuracy: 0.9652, F1 Micro: 0.9735, F1 Macro: 0.6664\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 20\n",
      "Sampling duration: 7.964461326599121 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3041, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1663, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1369, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.188, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1284, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Epoch 6/10, Train Loss: 0.1179, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Epoch 7/10, Train Loss: 0.1081, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0772, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Epoch 9/10, Train Loss: 0.0609, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.058, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7219\n",
      "Model 1 - Iteration 223: Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7219\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.71      0.72       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 67.30682516098022 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.315, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1688, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.14, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.192, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1351, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1243, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1108, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7211\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0766, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7228\n",
      "Epoch 9/10, Train Loss: 0.0565, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7219\n",
      "Epoch 10/10, Train Loss: 0.051, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.654\n",
      "Model 2 - Iteration 223: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7228\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.71      0.72       407\n",
      "weighted avg       0.97      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 68.96372652053833 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2843, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1642, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1399, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1908, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1297, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 6/10, Train Loss: 0.1166, Accuracy: 0.9535, F1 Micro: 0.9639, F1 Macro: 0.6456\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1038, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Epoch 8/10, Train Loss: 0.0679, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Epoch 9/10, Train Loss: 0.0499, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7201\n",
      "Epoch 10/10, Train Loss: 0.0483, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7201\n",
      "Model 3 - Iteration 223: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.67      0.66       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.97      0.99      0.97       407\n",
      "\n",
      "Training completed in 66.30921673774719 s\n",
      "Averaged - Iteration 223: Accuracy: 0.9657, F1 Micro: 0.9739, F1 Macro: 0.6706\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 18\n",
      "Sampling duration: 7.134152889251709 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2936, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1701, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1564, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1438, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Epoch 5/10, Train Loss: 0.106, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.6512\n",
      "Epoch 6/10, Train Loss: 0.0986, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.6515\n",
      "Epoch 7/10, Train Loss: 0.0771, Accuracy: 0.9535, F1 Micro: 0.9642, F1 Macro: 0.6463\n",
      "Epoch 8/10, Train Loss: 0.0763, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7192\n",
      "Epoch 9/10, Train Loss: 0.0521, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7182\n",
      "Epoch 10/10, Train Loss: 0.0441, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7089\n",
      "Model 1 - Iteration 241: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.66      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 66.78343510627747 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3025, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1719, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1604, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1507, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1122, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.653\n",
      "Epoch 6/10, Train Loss: 0.1012, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6528\n",
      "Epoch 7/10, Train Loss: 0.0665, Accuracy: 0.9567, F1 Micro: 0.9664, F1 Macro: 0.6476\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0676, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0498, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.6539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0307, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.654\n",
      "Model 2 - Iteration 241: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.96      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.97      0.97       407\n",
      "   macro avg       0.65      0.66      0.65       407\n",
      "weighted avg       0.96      0.97      0.97       407\n",
      " samples avg       0.98      0.98      0.97       407\n",
      "\n",
      "Training completed in 73.77902483940125 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2769, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1709, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.157, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1477, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Epoch 5/10, Train Loss: 0.1085, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6533\n",
      "Epoch 6/10, Train Loss: 0.0881, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0609, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0548, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7636\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0409, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0296, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7671\n",
      "Model 3 - Iteration 241: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 74.4795491695404 s\n",
      "Averaged - Iteration 241: Accuracy: 0.9661, F1 Micro: 0.9742, F1 Macro: 0.673\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 9\n",
      "Sampling duration: 6.538536787033081 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2932, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1884, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1373, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1635, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Epoch 5/10, Train Loss: 0.1386, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0842, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7219\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0646, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7962\n",
      "Epoch 8/10, Train Loss: 0.0594, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7773\n",
      "Epoch 9/10, Train Loss: 0.0499, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7783\n",
      "Epoch 10/10, Train Loss: 0.0453, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7942\n",
      "Model 1 - Iteration 250: Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7962\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 71.65613031387329 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3091, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1908, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1399, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1688, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.147, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0869, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7664\n",
      "Epoch 7/10, Train Loss: 0.0676, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7653\n",
      "Epoch 8/10, Train Loss: 0.0609, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Epoch 9/10, Train Loss: 0.0501, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7953\n",
      "Epoch 10/10, Train Loss: 0.0423, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7963\n",
      "Model 2 - Iteration 250: Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7664\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.75      0.77       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 71.96833872795105 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2804, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1905, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1386, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1678, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.14, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0795, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7395\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0632, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7664\n",
      "Epoch 8/10, Train Loss: 0.0517, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7783\n",
      "Epoch 9/10, Train Loss: 0.0425, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7963\n",
      "Epoch 10/10, Train Loss: 0.0363, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7785\n",
      "Model 3 - Iteration 250: Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7664\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.96      0.99      0.98       407\n",
      "\n",
      "Training completed in 73.10578799247742 s\n",
      "Averaged - Iteration 250: Accuracy: 0.9665, F1 Micro: 0.9745, F1 Macro: 0.6833\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 15\n",
      "Sampling duration: 6.6750569343566895 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2754, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1645, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1521, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1446, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Epoch 5/10, Train Loss: 0.1144, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0956, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7663\n",
      "Epoch 7/10, Train Loss: 0.0682, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0544, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 9/10, Train Loss: 0.0472, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7802\n",
      "Epoch 10/10, Train Loss: 0.0366, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.7637\n",
      "Model 1 - Iteration 265: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 74.5071485042572 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2925, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1688, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1582, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1466, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1223, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0959, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7494\n",
      "Epoch 7/10, Train Loss: 0.0688, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7207\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0512, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7494\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0407, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7662\n",
      "Epoch 10/10, Train Loss: 0.0377, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7486\n",
      "Model 2 - Iteration 265: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7662\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.75      0.77       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 77.00564932823181 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2639, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1638, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1553, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1423, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1096, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0797, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7802\n",
      "Epoch 7/10, Train Loss: 0.0579, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.044, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0397, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7802\n",
      "Epoch 10/10, Train Loss: 0.035, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7794\n",
      "Model 3 - Iteration 265: Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7802\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 77.23911190032959 s\n",
      "Averaged - Iteration 265: Accuracy: 0.967, F1 Micro: 0.9749, F1 Macro: 0.6923\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 14\n",
      "Sampling duration: 5.572272539138794 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2776, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1871, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.17, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1548, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1186, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.087, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7672\n",
      "Epoch 7/10, Train Loss: 0.0675, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7663\n",
      "Epoch 8/10, Train Loss: 0.058, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0425, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7802\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0333, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "Model 1 - Iteration 279: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 79.21519875526428 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2931, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1882, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.173, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1589, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1206, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0819, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0636, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.8208\n",
      "Epoch 8/10, Train Loss: 0.0519, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.796\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0401, Accuracy: 0.9728, F1 Micro: 0.9794, F1 Macro: 0.7895\n",
      "Epoch 10/10, Train Loss: 0.0283, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7967\n",
      "Model 2 - Iteration 279: Accuracy: 0.9728, F1 Micro: 0.9794, F1 Macro: 0.7895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 79.12970733642578 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2637, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1878, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1725, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1588, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 5/10, Train Loss: 0.1285, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0868, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7494\n",
      "Epoch 7/10, Train Loss: 0.0655, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0539, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Epoch 9/10, Train Loss: 0.0414, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7495\n",
      "Epoch 10/10, Train Loss: 0.0319, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7505\n",
      "Model 3 - Iteration 279: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 75.88865494728088 s\n",
      "Averaged - Iteration 279: Accuracy: 0.9675, F1 Micro: 0.9752, F1 Macro: 0.7004\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 13\n",
      "Sampling duration: 5.557002067565918 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.28, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1679, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1669, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Epoch 4/10, Train Loss: 0.1437, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.6512\n",
      "Epoch 5/10, Train Loss: 0.0914, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.7345\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0865, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0533, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7505\n",
      "Epoch 8/10, Train Loss: 0.0457, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.037, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0318, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7886\n",
      "Model 1 - Iteration 292: Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 81.38166356086731 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2925, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1721, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1708, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1549, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.6522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0967, Accuracy: 0.9663, F1 Micro: 0.974, F1 Macro: 0.7936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0922, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 7/10, Train Loss: 0.0537, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7801\n",
      "Epoch 8/10, Train Loss: 0.0452, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.8186\n",
      "Epoch 9/10, Train Loss: 0.04, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7374\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0341, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7894\n",
      "Model 2 - Iteration 292: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 79.88158249855042 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2715, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1685, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1691, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1478, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.6512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0931, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7471\n",
      "Epoch 6/10, Train Loss: 0.0844, Accuracy: 0.9583, F1 Micro: 0.9678, F1 Macro: 0.7044\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0499, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.779\n",
      "Epoch 8/10, Train Loss: 0.0492, Accuracy: 0.9583, F1 Micro: 0.9678, F1 Macro: 0.7155\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.035, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.78\n",
      "Epoch 10/10, Train Loss: 0.0305, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7662\n",
      "Model 3 - Iteration 292: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 79.73174285888672 s\n",
      "Averaged - Iteration 292: Accuracy: 0.9677, F1 Micro: 0.9755, F1 Macro: 0.707\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 8\n",
      "Sampling duration: 4.719808101654053 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2935, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1754, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1592, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1528, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1208, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0826, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7653\n",
      "Epoch 7/10, Train Loss: 0.0665, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7871\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0472, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.78\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0382, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7894\n",
      "Epoch 10/10, Train Loss: 0.0285, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7493\n",
      "Model 1 - Iteration 300: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 83.74665689468384 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3025, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1766, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1609, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1546, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7494\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1177, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7966\n",
      "Epoch 6/10, Train Loss: 0.0807, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7208\n",
      "Epoch 7/10, Train Loss: 0.0669, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7651\n",
      "Epoch 8/10, Train Loss: 0.0416, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0351, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.798\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0248, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8208\n",
      "Model 2 - Iteration 300: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8208\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      1.00      1.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.83      0.82       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 82.0036473274231 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2804, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1765, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1606, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1502, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1136, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7553\n",
      "Epoch 6/10, Train Loss: 0.0747, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7622\n",
      "Epoch 7/10, Train Loss: 0.0593, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0436, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0346, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7671\n",
      "Epoch 10/10, Train Loss: 0.0248, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7661\n",
      "Model 3 - Iteration 300: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.82      0.75      0.77       407\n",
      "weighted avg       0.97      0.98      0.98       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 81.92229628562927 s\n",
      "Averaged - Iteration 300: Accuracy: 0.968, F1 Micro: 0.9757, F1 Macro: 0.7131\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.768085956573486 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2561, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1674, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1481, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1348, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1038, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7973\n",
      "Epoch 6/10, Train Loss: 0.0888, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.8012\n",
      "Epoch 7/10, Train Loss: 0.0605, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7875\n",
      "Epoch 8/10, Train Loss: 0.0418, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7642\n",
      "Epoch 9/10, Train Loss: 0.0397, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7448\n",
      "Epoch 10/10, Train Loss: 0.0289, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7663\n",
      "Model 1 - Iteration 310: Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7973\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 80.11471486091614 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2776, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1707, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1512, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1421, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1148, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0878, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0606, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Epoch 8/10, Train Loss: 0.0422, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 9/10, Train Loss: 0.0422, Accuracy: 0.9583, F1 Micro: 0.9687, F1 Macro: 0.7292\n",
      "Epoch 10/10, Train Loss: 0.0303, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.798\n",
      "Model 2 - Iteration 310: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 83.68433403968811 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2512, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1668, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1482, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1385, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1086, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7498\n",
      "Epoch 6/10, Train Loss: 0.0852, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0599, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7794\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0405, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0398, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7671\n",
      "Epoch 10/10, Train Loss: 0.0272, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7503\n",
      "Model 3 - Iteration 310: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 86.5429995059967 s\n",
      "Averaged - Iteration 310: Accuracy: 0.9683, F1 Micro: 0.9759, F1 Macro: 0.7176\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.420601844787598 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2661, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1641, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1488, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1302, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7384\n",
      "Epoch 5/10, Train Loss: 0.1153, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0711, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7789\n",
      "Epoch 7/10, Train Loss: 0.0584, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7859\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0409, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7671\n",
      "Epoch 9/10, Train Loss: 0.0354, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.768\n",
      "Epoch 10/10, Train Loss: 0.028, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.78\n",
      "Model 1 - Iteration 320: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.75      0.77       407\n",
      "weighted avg       0.97      0.98      0.98       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 83.46401476860046 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2789, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1669, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1556, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.137, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7208\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1208, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7219\n",
      "Epoch 6/10, Train Loss: 0.0793, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.766\n",
      "Epoch 7/10, Train Loss: 0.0577, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7573\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0432, Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7998\n",
      "Epoch 9/10, Train Loss: 0.0338, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 10/10, Train Loss: 0.0289, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7781\n",
      "Model 2 - Iteration 320: Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 82.8786690235138 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2569, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1652, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1512, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1352, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1226, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0809, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "Epoch 7/10, Train Loss: 0.0553, Accuracy: 0.9712, F1 Micro: 0.9778, F1 Macro: 0.7966\n",
      "Epoch 8/10, Train Loss: 0.0424, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0325, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7902\n",
      "Epoch 10/10, Train Loss: 0.0255, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7672\n",
      "Model 3 - Iteration 320: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7902\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 84.70196342468262 s\n",
      "Averaged - Iteration 320: Accuracy: 0.9686, F1 Micro: 0.9762, F1 Macro: 0.7219\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.5898220539093018 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2778, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1806, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1489, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1284, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Epoch 5/10, Train Loss: 0.1083, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0725, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 7/10, Train Loss: 0.0599, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.8013\n",
      "Epoch 8/10, Train Loss: 0.0485, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7884\n",
      "Epoch 9/10, Train Loss: 0.0335, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7949\n",
      "Epoch 10/10, Train Loss: 0.0298, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7876\n",
      "Model 1 - Iteration 330: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 85.81297540664673 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2835, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1838, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1539, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1391, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.6539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1213, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "Epoch 6/10, Train Loss: 0.0781, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0621, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "Epoch 8/10, Train Loss: 0.0454, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.781\n",
      "Epoch 9/10, Train Loss: 0.0292, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8022\n",
      "Epoch 10/10, Train Loss: 0.0267, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7969\n",
      "Model 2 - Iteration 330: Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 86.36293768882751 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.266, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.184, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.149, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Epoch 4/10, Train Loss: 0.1326, Accuracy: 0.9615, F1 Micro: 0.9702, F1 Macro: 0.6507\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1068, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Epoch 6/10, Train Loss: 0.0712, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7787\n",
      "Epoch 7/10, Train Loss: 0.0536, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7762\n",
      "Epoch 8/10, Train Loss: 0.0444, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0298, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8041\n",
      "Epoch 10/10, Train Loss: 0.0264, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7671\n",
      "Model 3 - Iteration 330: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8041\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 84.5897319316864 s\n",
      "Averaged - Iteration 330: Accuracy: 0.969, F1 Micro: 0.9764, F1 Macro: 0.7265\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.312075138092041 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2631, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1831, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1692, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 4/10, Train Loss: 0.145, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1252, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Epoch 6/10, Train Loss: 0.0877, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7561\n",
      "Epoch 7/10, Train Loss: 0.0638, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.7618\n",
      "Epoch 8/10, Train Loss: 0.0479, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7883\n",
      "Epoch 9/10, Train Loss: 0.0399, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7764\n",
      "Epoch 10/10, Train Loss: 0.0239, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.781\n",
      "Model 1 - Iteration 340: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 84.40565633773804 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2795, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1829, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1693, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.149, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1289, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7662\n",
      "Epoch 6/10, Train Loss: 0.0995, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.796\n",
      "Epoch 7/10, Train Loss: 0.068, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0499, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.781\n",
      "Epoch 9/10, Train Loss: 0.0416, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7672\n",
      "Epoch 10/10, Train Loss: 0.0222, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7959\n",
      "Model 2 - Iteration 340: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 87.35239148139954 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2571, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1821, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.167, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1408, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1171, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7226\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0844, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7819\n",
      "Epoch 7/10, Train Loss: 0.0592, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7505\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0479, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7902\n",
      "Epoch 9/10, Train Loss: 0.0387, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7764\n",
      "Epoch 10/10, Train Loss: 0.0234, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7779\n",
      "Model 3 - Iteration 340: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7902\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 88.73847842216492 s\n",
      "Averaged - Iteration 340: Accuracy: 0.9692, F1 Micro: 0.9766, F1 Macro: 0.7297\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.06388258934021 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2717, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.169, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.149, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1291, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1071, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Epoch 6/10, Train Loss: 0.0778, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.768\n",
      "Epoch 7/10, Train Loss: 0.0536, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0423, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7902\n",
      "Epoch 9/10, Train Loss: 0.0379, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.768\n",
      "Epoch 10/10, Train Loss: 0.0236, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7894\n",
      "Model 1 - Iteration 350: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7902\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 89.45808959007263 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2793, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1702, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1521, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1328, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7513\n",
      "Epoch 5/10, Train Loss: 0.1058, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7782\n",
      "Epoch 6/10, Train Loss: 0.0746, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7449\n",
      "Epoch 7/10, Train Loss: 0.0514, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0408, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 9/10, Train Loss: 0.0402, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7651\n",
      "Epoch 10/10, Train Loss: 0.0262, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7393\n",
      "Model 2 - Iteration 350: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 88.93628263473511 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2634, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1698, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1502, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1233, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7387\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1027, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Epoch 6/10, Train Loss: 0.0741, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7585\n",
      "Epoch 7/10, Train Loss: 0.0503, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0403, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7819\n",
      "Epoch 9/10, Train Loss: 0.0369, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.779\n",
      "Epoch 10/10, Train Loss: 0.023, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.8394\n",
      "Model 3 - Iteration 350: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7819\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 89.0240707397461 s\n",
      "Averaged - Iteration 350: Accuracy: 0.9695, F1 Micro: 0.9768, F1 Macro: 0.7329\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.064525604248047 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2604, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1734, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1617, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1496, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7218\n",
      "Epoch 5/10, Train Loss: 0.0962, Accuracy: 0.9647, F1 Micro: 0.9735, F1 Macro: 0.7741\n",
      "Epoch 6/10, Train Loss: 0.0811, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.778\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0569, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Epoch 8/10, Train Loss: 0.0507, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7772\n",
      "Epoch 9/10, Train Loss: 0.0352, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0274, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Model 1 - Iteration 360: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 90.4373996257782 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2609, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.173, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1602, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1498, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7672\n",
      "Epoch 5/10, Train Loss: 0.0983, Accuracy: 0.9663, F1 Micro: 0.9747, F1 Macro: 0.7656\n",
      "Epoch 6/10, Train Loss: 0.0766, Accuracy: 0.9679, F1 Micro: 0.9753, F1 Macro: 0.7946\n",
      "Epoch 7/10, Train Loss: 0.0554, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.767\n",
      "Epoch 8/10, Train Loss: 0.051, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7762\n",
      "Epoch 9/10, Train Loss: 0.0307, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0249, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.805\n",
      "Model 2 - Iteration 360: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.81       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 88.61724758148193 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2498, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1709, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1609, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Epoch 4/10, Train Loss: 0.1346, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7493\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0897, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7757\n",
      "Epoch 6/10, Train Loss: 0.0703, Accuracy: 0.9599, F1 Micro: 0.9694, F1 Macro: 0.742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0517, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7819\n",
      "Epoch 8/10, Train Loss: 0.0485, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7769\n",
      "Epoch 9/10, Train Loss: 0.0298, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.8379\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0232, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7902\n",
      "Model 3 - Iteration 360: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7902\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 90.62896180152893 s\n",
      "Averaged - Iteration 360: Accuracy: 0.9697, F1 Micro: 0.977, F1 Macro: 0.7359\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.419964551925659 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2588, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1719, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 3/10, Train Loss: 0.1439, Accuracy: 0.9631, F1 Micro: 0.9715, F1 Macro: 0.6517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1336, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7587\n",
      "Epoch 5/10, Train Loss: 0.087, Accuracy: 0.9663, F1 Micro: 0.974, F1 Macro: 0.7934\n",
      "Epoch 6/10, Train Loss: 0.0694, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0542, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.776\n",
      "Epoch 8/10, Train Loss: 0.0439, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7662\n",
      "Epoch 9/10, Train Loss: 0.0339, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7439\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0249, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7772\n",
      "Model 1 - Iteration 370: Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.74      0.83      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 92.10500860214233 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2646, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1749, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1479, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1431, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7887\n",
      "Epoch 5/10, Train Loss: 0.0911, Accuracy: 0.9631, F1 Micro: 0.9715, F1 Macro: 0.7915\n",
      "Epoch 6/10, Train Loss: 0.0738, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.753\n",
      "Epoch 7/10, Train Loss: 0.0547, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7969\n",
      "Epoch 8/10, Train Loss: 0.0408, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.755\n",
      "Epoch 9/10, Train Loss: 0.0323, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7959\n",
      "Epoch 10/10, Train Loss: 0.0236, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.781\n",
      "Model 2 - Iteration 370: Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7887\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.96      0.99      0.98       407\n",
      "\n",
      "Training completed in 90.0480751991272 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2486, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1718, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1482, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1321, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7656\n",
      "Epoch 5/10, Train Loss: 0.0898, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.7601\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.067, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7883\n",
      "Epoch 7/10, Train Loss: 0.0498, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7672\n",
      "Epoch 8/10, Train Loss: 0.0421, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7782\n",
      "Epoch 9/10, Train Loss: 0.0327, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7779\n",
      "Epoch 10/10, Train Loss: 0.0258, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.8329\n",
      "Model 3 - Iteration 370: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7883\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 91.72922348976135 s\n",
      "Averaged - Iteration 370: Accuracy: 0.9698, F1 Micro: 0.977, F1 Macro: 0.7382\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.9694838523864746 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2524, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1751, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1609, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1195, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1024, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "Epoch 6/10, Train Loss: 0.0745, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7654\n",
      "Epoch 7/10, Train Loss: 0.0567, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7383\n",
      "Epoch 8/10, Train Loss: 0.0386, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.743\n",
      "Epoch 9/10, Train Loss: 0.0275, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7491\n",
      "Epoch 10/10, Train Loss: 0.0245, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "Model 1 - Iteration 380: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 93.4322497844696 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.268, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1754, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1685, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1312, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 5/10, Train Loss: 0.1129, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0771, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "Epoch 7/10, Train Loss: 0.0535, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7751\n",
      "Epoch 8/10, Train Loss: 0.034, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.8227\n",
      "Epoch 9/10, Train Loss: 0.0242, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7959\n",
      "Epoch 10/10, Train Loss: 0.029, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.762\n",
      "Model 2 - Iteration 380: Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 93.2333083152771 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2497, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1762, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1662, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1238, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7754\n",
      "Epoch 5/10, Train Loss: 0.1024, Accuracy: 0.9631, F1 Micro: 0.9723, F1 Macro: 0.7446\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0759, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7764\n",
      "Epoch 7/10, Train Loss: 0.0524, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7754\n",
      "Epoch 8/10, Train Loss: 0.0366, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.797\n",
      "Epoch 9/10, Train Loss: 0.0274, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7762\n",
      "Epoch 10/10, Train Loss: 0.024, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.797\n",
      "Model 3 - Iteration 380: Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       407\n",
      "   macro avg       0.74      0.83      0.78       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 93.12038969993591 s\n",
      "Averaged - Iteration 380: Accuracy: 0.9699, F1 Micro: 0.9771, F1 Macro: 0.7406\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.8917014598846436 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2322, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1728, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1482, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.137, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.799\n",
      "Epoch 5/10, Train Loss: 0.0884, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7672\n",
      "Epoch 6/10, Train Loss: 0.0676, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.743\n",
      "Epoch 7/10, Train Loss: 0.045, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7642\n",
      "Epoch 8/10, Train Loss: 0.05, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7449\n",
      "Epoch 9/10, Train Loss: 0.0297, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7819\n",
      "Epoch 10/10, Train Loss: 0.0225, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7577\n",
      "Model 1 - Iteration 390: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 93.1842942237854 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2409, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1745, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.149, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1408, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7774\n",
      "Epoch 5/10, Train Loss: 0.0918, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7569\n",
      "Epoch 6/10, Train Loss: 0.0696, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7429\n",
      "Epoch 7/10, Train Loss: 0.0513, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.7536\n",
      "Epoch 8/10, Train Loss: 0.0491, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7458\n",
      "Epoch 9/10, Train Loss: 0.03, Accuracy: 0.9679, F1 Micro: 0.9759, F1 Macro: 0.8086\n",
      "Epoch 10/10, Train Loss: 0.0224, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.8067\n",
      "Model 2 - Iteration 390: Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       407\n",
      "   macro avg       0.74      0.83      0.78       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 94.49150848388672 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2219, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.174, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1489, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1423, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7037\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0918, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7819\n",
      "Epoch 6/10, Train Loss: 0.0631, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7402\n",
      "Epoch 7/10, Train Loss: 0.0439, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.8\n",
      "Epoch 8/10, Train Loss: 0.0494, Accuracy: 0.9631, F1 Micro: 0.9723, F1 Macro: 0.7394\n",
      "Epoch 9/10, Train Loss: 0.0282, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7771\n",
      "Epoch 10/10, Train Loss: 0.022, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.8505\n",
      "Model 3 - Iteration 390: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7819\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 94.66002702713013 s\n",
      "Averaged - Iteration 390: Accuracy: 0.97, F1 Micro: 0.9772, F1 Macro: 0.7426\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.1983304023742676 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2437, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1574, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1386, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1244, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7662\n",
      "Epoch 5/10, Train Loss: 0.0887, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.764\n",
      "Epoch 6/10, Train Loss: 0.0734, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7513\n",
      "Epoch 7/10, Train Loss: 0.0566, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.777\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0432, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7586\n",
      "Epoch 9/10, Train Loss: 0.033, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7394\n",
      "Epoch 10/10, Train Loss: 0.0237, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7512\n",
      "Model 1 - Iteration 400: Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7586\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.44      1.00      0.62         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       407\n",
      "   macro avg       0.72      0.83      0.76       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 96.38146209716797 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2545, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1587, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1392, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1192, Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.8226\n",
      "Epoch 5/10, Train Loss: 0.0898, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7958\n",
      "Epoch 6/10, Train Loss: 0.0691, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7671\n",
      "Epoch 7/10, Train Loss: 0.0504, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7883\n",
      "Epoch 8/10, Train Loss: 0.037, Accuracy: 0.9631, F1 Micro: 0.9723, F1 Macro: 0.7774\n",
      "Epoch 9/10, Train Loss: 0.0299, Accuracy: 0.9744, F1 Micro: 0.9806, F1 Macro: 0.8467\n",
      "Epoch 10/10, Train Loss: 0.0206, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7882\n",
      "Model 2 - Iteration 400: Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.8226\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      1.00      1.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.83      0.82       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 94.5913577079773 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2351, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1571, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1382, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Epoch 4/10, Train Loss: 0.1142, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7992\n",
      "Epoch 5/10, Train Loss: 0.0847, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.7611\n",
      "Epoch 6/10, Train Loss: 0.0646, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.753\n",
      "Epoch 7/10, Train Loss: 0.0508, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0387, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.031, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0229, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Model 3 - Iteration 400: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 98.06788444519043 s\n",
      "Averaged - Iteration 400: Accuracy: 0.9701, F1 Micro: 0.9773, F1 Macro: 0.7444\n",
      "Total sampling time: 142.3 seconds\n",
      "Total runtime: 5818.269457578659 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebfc66c",
   "metadata": {
    "papermill": {
     "duration": 0.149981,
     "end_time": "2025-03-14T14:46:08.701643",
     "exception": false,
     "start_time": "2025-03-14T14:46:08.551662",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1c19dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 2\n",
      "Random seed: [81, 90, 11]\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6098, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3918, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.28, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2134, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2275, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1581, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2152, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1361, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1355, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1654, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 1 - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 39.22024321556091 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5672, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.359, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2512, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1913, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2132, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1532, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2049, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1264, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1302, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1522, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 2 - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 39.21651649475098 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5373, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3816, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2713, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2123, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2312, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.154, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2138, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1374, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1382, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1649, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 3 - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 41.186362504959106 s\n",
      "Averaged - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 38\n",
      "Sampling duration: 15.946570873260498 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5159, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2902, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2467, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1846, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1727, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1704, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1639, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1602, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1383, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7212\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1123, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.722\n",
      "Model 1 - Iteration 63: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.722\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.71      0.72       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 44.032747745513916 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4549, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2606, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2369, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1808, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1676, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1675, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1545, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1523, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1335, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Epoch 10/10, Train Loss: 0.1072, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Model 2 - Iteration 63: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.65      0.66      0.65       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 43.863285541534424 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4555, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2761, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2395, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1856, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1736, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.173, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1658, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1702, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1412, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7204\n",
      "Epoch 10/10, Train Loss: 0.1155, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Model 3 - Iteration 63: Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7204\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       407\n",
      "   macro avg       0.81      0.71      0.72       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 42.662978172302246 s\n",
      "Averaged - Iteration 63: Accuracy: 0.9653, F1 Micro: 0.9736, F1 Macro: 0.6759\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 34\n",
      "Sampling duration: 15.239473819732666 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4202, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2235, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1912, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1913, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1414, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1699, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 7/10, Train Loss: 0.1552, Accuracy: 0.9599, F1 Micro: 0.969, F1 Macro: 0.6499\n",
      "Epoch 8/10, Train Loss: 0.1005, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.6502\n",
      "Epoch 9/10, Train Loss: 0.104, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.6522\n",
      "Epoch 10/10, Train Loss: 0.0745, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.7068\n",
      "Model 1 - Iteration 97: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 45.674352169036865 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3785, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2106, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1866, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1873, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1379, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1653, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1477, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.656\n",
      "Epoch 8/10, Train Loss: 0.1064, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Epoch 9/10, Train Loss: 0.113, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0693, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.722\n",
      "Model 2 - Iteration 97: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.722\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.71      0.72       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 49.085432291030884 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3871, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2177, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1949, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1874, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.142, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1677, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.159, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.656\n",
      "Epoch 8/10, Train Loss: 0.1071, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 9/10, Train Loss: 0.1214, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0779, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7219\n",
      "Model 3 - Iteration 97: Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7219\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.71      0.72       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 48.15412878990173 s\n",
      "Averaged - Iteration 97: Accuracy: 0.966, F1 Micro: 0.9742, F1 Macro: 0.6836\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 31\n",
      "Sampling duration: 13.780829429626465 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3867, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2271, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1689, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1647, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1829, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1598, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Epoch 7/10, Train Loss: 0.1496, Accuracy: 0.9599, F1 Micro: 0.9691, F1 Macro: 0.65\n",
      "Epoch 8/10, Train Loss: 0.133, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.6512\n",
      "Epoch 9/10, Train Loss: 0.0981, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.7172\n",
      "Epoch 10/10, Train Loss: 0.0727, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.7169\n",
      "Model 1 - Iteration 128: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.65      0.66      0.65       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 48.897459268569946 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3569, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2232, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1686, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1633, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.177, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Epoch 6/10, Train Loss: 0.1578, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Epoch 7/10, Train Loss: 0.1531, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.655\n",
      "Epoch 8/10, Train Loss: 0.1364, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.655\n",
      "Epoch 9/10, Train Loss: 0.0994, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Epoch 10/10, Train Loss: 0.0751, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Model 2 - Iteration 128: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.67      0.66       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.97      0.99      0.97       407\n",
      "\n",
      "Training completed in 47.08303236961365 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3624, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.226, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1715, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1613, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.178, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1637, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1522, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1354, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Epoch 9/10, Train Loss: 0.0963, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6523\n",
      "Epoch 10/10, Train Loss: 0.0705, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.6512\n",
      "Model 3 - Iteration 128: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.66      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 51.17352247238159 s\n",
      "Averaged - Iteration 128: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6764\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 28\n",
      "Sampling duration: 12.585692882537842 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3607, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2074, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.159, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1852, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1725, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1405, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1339, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Epoch 8/10, Train Loss: 0.0811, Accuracy: 0.9599, F1 Micro: 0.9691, F1 Macro: 0.65\n",
      "Epoch 9/10, Train Loss: 0.0766, Accuracy: 0.9567, F1 Micro: 0.9666, F1 Macro: 0.649\n",
      "Epoch 10/10, Train Loss: 0.0615, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.7056\n",
      "Model 1 - Iteration 156: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.65      0.66      0.65       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 57.19843792915344 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3253, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1978, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1561, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1759, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Epoch 5/10, Train Loss: 0.1628, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Epoch 6/10, Train Loss: 0.1262, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.6522\n",
      "Epoch 7/10, Train Loss: 0.1228, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Epoch 8/10, Train Loss: 0.0753, Accuracy: 0.9535, F1 Micro: 0.9641, F1 Macro: 0.6461\n",
      "Epoch 9/10, Train Loss: 0.0728, Accuracy: 0.9567, F1 Micro: 0.9665, F1 Macro: 0.648\n",
      "Epoch 10/10, Train Loss: 0.0584, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Model 2 - Iteration 156: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.67      0.66       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.97      0.99      0.97       407\n",
      "\n",
      "Training completed in 51.08997964859009 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3434, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2092, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1594, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1872, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1778, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1465, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Epoch 7/10, Train Loss: 0.1455, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 8/10, Train Loss: 0.092, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.6502\n",
      "Epoch 9/10, Train Loss: 0.0847, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6523\n",
      "Epoch 10/10, Train Loss: 0.0699, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6523\n",
      "Model 3 - Iteration 156: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.67      0.66       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.97      0.99      0.97       407\n",
      "\n",
      "Training completed in 55.13121581077576 s\n",
      "Averaged - Iteration 156: Accuracy: 0.9666, F1 Micro: 0.9746, F1 Macro: 0.6721\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 25\n",
      "Sampling duration: 11.360219717025757 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3343, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2171, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.202, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2086, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1544, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1247, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1067, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7653\n",
      "Epoch 8/10, Train Loss: 0.0805, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.777\n",
      "Epoch 9/10, Train Loss: 0.0602, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.778\n",
      "Epoch 10/10, Train Loss: 0.047, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7543\n",
      "Model 1 - Iteration 181: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7653\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.74      0.77       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 59.98069739341736 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3152, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2158, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.198, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2069, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1505, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 6/10, Train Loss: 0.1202, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Epoch 7/10, Train Loss: 0.1022, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7375\n",
      "Epoch 8/10, Train Loss: 0.0807, Accuracy: 0.9583, F1 Micro: 0.9678, F1 Macro: 0.743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0598, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7037\n",
      "Epoch 10/10, Train Loss: 0.0504, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7158\n",
      "Model 2 - Iteration 181: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7037\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.33      0.25      0.29         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.70      0.71      0.70       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 59.21626830101013 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3087, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2177, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2004, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2149, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1613, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1321, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1233, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.655\n",
      "Epoch 8/10, Train Loss: 0.0883, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0694, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7495\n",
      "Epoch 10/10, Train Loss: 0.0513, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Model 3 - Iteration 181: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7495\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.76      0.75      0.75       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 63.10444188117981 s\n",
      "Averaged - Iteration 181: Accuracy: 0.9669, F1 Micro: 0.9748, F1 Macro: 0.6834\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 22\n",
      "Sampling duration: 10.208772897720337 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3159, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1828, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1687, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1557, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Epoch 5/10, Train Loss: 0.1407, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1229, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Epoch 7/10, Train Loss: 0.0924, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.7757\n",
      "Epoch 8/10, Train Loss: 0.0635, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.753\n",
      "Epoch 9/10, Train Loss: 0.0583, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7772\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0454, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7653\n",
      "Model 1 - Iteration 203: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7653\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 63.48937439918518 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2986, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.181, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.17, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1492, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1446, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1306, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Epoch 7/10, Train Loss: 0.0971, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.652\n",
      "Epoch 8/10, Train Loss: 0.0684, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7449\n",
      "Epoch 9/10, Train Loss: 0.0574, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7386\n",
      "Epoch 10/10, Train Loss: 0.0418, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.729\n",
      "Model 2 - Iteration 203: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.66      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 63.19134998321533 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.31, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1877, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1731, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.159, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1527, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1398, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Epoch 7/10, Train Loss: 0.1013, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.7167\n",
      "Epoch 8/10, Train Loss: 0.0714, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0651, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7209\n",
      "Epoch 10/10, Train Loss: 0.0489, Accuracy: 0.9535, F1 Micro: 0.9649, F1 Macro: 0.7148\n",
      "Model 3 - Iteration 203: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7209\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.70      0.72       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 65.50794553756714 s\n",
      "Averaged - Iteration 203: Accuracy: 0.967, F1 Micro: 0.9749, F1 Macro: 0.6877\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 20\n",
      "Sampling duration: 9.212269306182861 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3149, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1939, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1807, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1507, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.655\n",
      "Epoch 5/10, Train Loss: 0.1265, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.652\n",
      "Epoch 6/10, Train Loss: 0.1063, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.652\n",
      "Epoch 7/10, Train Loss: 0.0838, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0605, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.778\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0452, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0418, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.779\n",
      "Model 1 - Iteration 223: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.96      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.77      0.78      0.78       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 67.63407349586487 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2927, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1922, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1791, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1493, Accuracy: 0.9615, F1 Micro: 0.9703, F1 Macro: 0.6509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1285, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Epoch 6/10, Train Loss: 0.1082, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6541\n",
      "Epoch 7/10, Train Loss: 0.0874, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7333\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0587, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7493\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0446, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0404, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.781\n",
      "Model 2 - Iteration 223: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 68.27780508995056 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.294, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1939, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1824, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1549, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1345, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Epoch 6/10, Train Loss: 0.1213, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Epoch 7/10, Train Loss: 0.1028, Accuracy: 0.9583, F1 Micro: 0.9683, F1 Macro: 0.7128\n",
      "Epoch 8/10, Train Loss: 0.07, Accuracy: 0.9567, F1 Micro: 0.9672, F1 Macro: 0.6836\n",
      "Epoch 9/10, Train Loss: 0.0481, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6552\n",
      "Epoch 10/10, Train Loss: 0.0485, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.7058\n",
      "Model 3 - Iteration 223: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.66      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 64.87470364570618 s\n",
      "Averaged - Iteration 223: Accuracy: 0.9673, F1 Micro: 0.9751, F1 Macro: 0.694\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 18\n",
      "Sampling duration: 8.334405183792114 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3069, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1831, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1706, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1459, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1292, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7672\n",
      "Epoch 6/10, Train Loss: 0.0912, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7874\n",
      "Epoch 7/10, Train Loss: 0.0666, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.746\n",
      "Epoch 8/10, Train Loss: 0.0512, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.778\n",
      "Epoch 9/10, Train Loss: 0.0383, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7881\n",
      "Epoch 10/10, Train Loss: 0.0307, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7884\n",
      "Model 1 - Iteration 241: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.75      0.77       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 68.36035108566284 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2863, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1818, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1657, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1423, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1255, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Epoch 6/10, Train Loss: 0.0906, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.747\n",
      "Epoch 7/10, Train Loss: 0.0678, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0545, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7394\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0364, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7394\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0326, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7513\n",
      "Model 2 - Iteration 241: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7513\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.75      0.75       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 73.22231888771057 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2906, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1831, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1708, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1511, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1521, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1134, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Epoch 7/10, Train Loss: 0.0825, Accuracy: 0.9631, F1 Micro: 0.9723, F1 Macro: 0.7441\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0585, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0396, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0332, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7793\n",
      "Model 3 - Iteration 241: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 75.04606294631958 s\n",
      "Averaged - Iteration 241: Accuracy: 0.9678, F1 Micro: 0.9755, F1 Macro: 0.702\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 9\n",
      "Sampling duration: 7.602128267288208 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.309, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1703, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1672, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1438, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1397, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.081, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.069, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7802\n",
      "Epoch 8/10, Train Loss: 0.0552, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7566\n",
      "Epoch 9/10, Train Loss: 0.0473, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.767\n",
      "Epoch 10/10, Train Loss: 0.0377, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7661\n",
      "Model 1 - Iteration 250: Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7802\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 73.40321016311646 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2901, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1679, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1604, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 4/10, Train Loss: 0.1376, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1353, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.656\n",
      "Epoch 6/10, Train Loss: 0.0832, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7386\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0719, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7663\n",
      "Epoch 8/10, Train Loss: 0.0528, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7362\n",
      "Epoch 9/10, Train Loss: 0.0467, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7206\n",
      "Epoch 10/10, Train Loss: 0.0333, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7653\n",
      "Model 2 - Iteration 250: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.75      0.77       407\n",
      "weighted avg       0.97      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 71.17345142364502 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.29, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1705, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.164, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1474, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.149, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0991, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0805, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Epoch 8/10, Train Loss: 0.0559, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7644\n",
      "Epoch 9/10, Train Loss: 0.0477, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7632\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0364, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7108\n",
      "Model 3 - Iteration 250: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7108\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.25      0.33         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.73      0.71      0.71       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 75.52414035797119 s\n",
      "Averaged - Iteration 250: Accuracy: 0.968, F1 Micro: 0.9756, F1 Macro: 0.7071\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 15\n",
      "Sampling duration: 7.14765191078186 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3049, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1809, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1674, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1592, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1086, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0817, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0666, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 8/10, Train Loss: 0.0628, Accuracy: 0.9583, F1 Micro: 0.9678, F1 Macro: 0.7587\n",
      "Epoch 9/10, Train Loss: 0.0403, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7971\n",
      "Epoch 10/10, Train Loss: 0.0328, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.7755\n",
      "Model 1 - Iteration 265: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 75.75814032554626 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2876, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1787, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1617, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 4/10, Train Loss: 0.1521, Accuracy: 0.9599, F1 Micro: 0.969, F1 Macro: 0.6499\n",
      "Epoch 5/10, Train Loss: 0.1099, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.7196\n",
      "Epoch 6/10, Train Loss: 0.0756, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.7186\n",
      "Epoch 7/10, Train Loss: 0.0645, Accuracy: 0.9631, F1 Micro: 0.9722, F1 Macro: 0.7275\n",
      "Epoch 8/10, Train Loss: 0.0659, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.7196\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0359, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8656\n",
      "Epoch 10/10, Train Loss: 0.0286, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7097\n",
      "Model 2 - Iteration 265: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.50      0.33      0.40         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.90      0.85      0.87       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 72.38624143600464 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2915, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1798, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1686, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.17, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6533\n",
      "Epoch 5/10, Train Loss: 0.1302, Accuracy: 0.9631, F1 Micro: 0.9715, F1 Macro: 0.6517\n",
      "Epoch 6/10, Train Loss: 0.1066, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.7342\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0795, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.072, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.778\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0365, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.8219\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0287, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7791\n",
      "Model 3 - Iteration 265: Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 78.80785799026489 s\n",
      "Averaged - Iteration 265: Accuracy: 0.9684, F1 Micro: 0.9759, F1 Macro: 0.7168\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 14\n",
      "Sampling duration: 6.4799113273620605 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2753, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1784, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1562, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Epoch 4/10, Train Loss: 0.1427, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1064, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Epoch 6/10, Train Loss: 0.0871, Accuracy: 0.9615, F1 Micro: 0.9702, F1 Macro: 0.7597\n",
      "Epoch 7/10, Train Loss: 0.064, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7754\n",
      "Epoch 8/10, Train Loss: 0.0391, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7791\n",
      "Epoch 9/10, Train Loss: 0.0391, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7791\n",
      "Epoch 10/10, Train Loss: 0.0285, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7875\n",
      "Model 1 - Iteration 279: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 74.39370560646057 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2586, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1773, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1518, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1437, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Epoch 5/10, Train Loss: 0.1027, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0801, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7671\n",
      "Epoch 7/10, Train Loss: 0.0631, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0394, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 9/10, Train Loss: 0.0432, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7662\n",
      "Epoch 10/10, Train Loss: 0.0304, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7642\n",
      "Model 2 - Iteration 279: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 76.22123193740845 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2575, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1777, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.158, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1495, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Epoch 5/10, Train Loss: 0.1165, Accuracy: 0.9599, F1 Micro: 0.9691, F1 Macro: 0.65\n",
      "Epoch 6/10, Train Loss: 0.089, Accuracy: 0.9599, F1 Micro: 0.9689, F1 Macro: 0.7585\n",
      "Epoch 7/10, Train Loss: 0.0659, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Epoch 8/10, Train Loss: 0.0455, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7567\n",
      "Epoch 9/10, Train Loss: 0.0399, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0266, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7793\n",
      "Model 3 - Iteration 279: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7793\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 74.99421691894531 s\n",
      "Averaged - Iteration 279: Accuracy: 0.9686, F1 Micro: 0.9761, F1 Macro: 0.723\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 13\n",
      "Sampling duration: 5.970175743103027 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2926, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1793, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1761, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1446, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Epoch 5/10, Train Loss: 0.1131, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.7177\n",
      "Epoch 6/10, Train Loss: 0.0869, Accuracy: 0.9679, F1 Micro: 0.9753, F1 Macro: 0.7946\n",
      "Epoch 7/10, Train Loss: 0.0624, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7651\n",
      "Epoch 8/10, Train Loss: 0.0465, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7852\n",
      "Epoch 9/10, Train Loss: 0.0302, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0328, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7791\n",
      "Model 1 - Iteration 292: Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 78.8476300239563 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2793, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1785, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1709, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 4/10, Train Loss: 0.1387, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Epoch 5/10, Train Loss: 0.1132, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.744\n",
      "Epoch 6/10, Train Loss: 0.0875, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.743\n",
      "Epoch 7/10, Train Loss: 0.0638, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.763\n",
      "Epoch 8/10, Train Loss: 0.0492, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0311, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0329, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7672\n",
      "Model 2 - Iteration 292: Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 79.92156219482422 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.278, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1807, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1785, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.147, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Epoch 5/10, Train Loss: 0.1254, Accuracy: 0.9615, F1 Micro: 0.9703, F1 Macro: 0.6509\n",
      "Epoch 6/10, Train Loss: 0.0986, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.7196\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0693, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7789\n",
      "Epoch 8/10, Train Loss: 0.0548, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0322, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0331, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "Model 3 - Iteration 292: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 82.74828791618347 s\n",
      "Averaged - Iteration 292: Accuracy: 0.9688, F1 Micro: 0.9763, F1 Macro: 0.7275\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 8\n",
      "Sampling duration: 5.334896802902222 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2845, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1838, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1766, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1473, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Epoch 5/10, Train Loss: 0.1036, Accuracy: 0.9615, F1 Micro: 0.9702, F1 Macro: 0.7163\n",
      "Epoch 6/10, Train Loss: 0.0852, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0604, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7793\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0382, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "Epoch 9/10, Train Loss: 0.0305, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7966\n",
      "Epoch 10/10, Train Loss: 0.028, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7362\n",
      "Model 1 - Iteration 300: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 84.03026223182678 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.266, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1817, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1735, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1435, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Epoch 5/10, Train Loss: 0.0987, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0843, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.781\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0602, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8042\n",
      "Epoch 8/10, Train Loss: 0.0393, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7773\n",
      "Epoch 9/10, Train Loss: 0.0293, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.778\n",
      "Epoch 10/10, Train Loss: 0.0315, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7819\n",
      "Model 2 - Iteration 300: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8042\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 85.04954624176025 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2687, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.181, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1762, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1536, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Epoch 5/10, Train Loss: 0.1125, Accuracy: 0.9615, F1 Micro: 0.9702, F1 Macro: 0.7597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0884, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0627, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.041, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7654\n",
      "Epoch 9/10, Train Loss: 0.029, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0295, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7654\n",
      "Model 3 - Iteration 300: Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.97       407\n",
      "\n",
      "Training completed in 88.29888033866882 s\n",
      "Averaged - Iteration 300: Accuracy: 0.969, F1 Micro: 0.9764, F1 Macro: 0.7319\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 5.121000051498413 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2788, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1832, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.165, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1403, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.6522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1146, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.7937\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0724, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 7/10, Train Loss: 0.0532, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7662\n",
      "Epoch 8/10, Train Loss: 0.0384, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7949\n",
      "Epoch 9/10, Train Loss: 0.039, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7893\n",
      "Epoch 10/10, Train Loss: 0.0238, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.8031\n",
      "Model 1 - Iteration 310: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 84.85753393173218 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2626, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.183, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1629, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 4/10, Train Loss: 0.1342, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7197\n",
      "Epoch 5/10, Train Loss: 0.1116, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.777\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0671, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7681\n",
      "Epoch 7/10, Train Loss: 0.0561, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7483\n",
      "Epoch 8/10, Train Loss: 0.0369, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7781\n",
      "Epoch 9/10, Train Loss: 0.0341, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7743\n",
      "Epoch 10/10, Train Loss: 0.0231, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7651\n",
      "Model 2 - Iteration 310: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7681\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      1.00      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.75      0.77       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 82.72734594345093 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2655, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1834, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1678, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1504, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Epoch 5/10, Train Loss: 0.1327, Accuracy: 0.9615, F1 Micro: 0.9703, F1 Macro: 0.7165\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.08, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "Epoch 7/10, Train Loss: 0.0589, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7672\n",
      "Epoch 8/10, Train Loss: 0.0406, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7788\n",
      "Epoch 9/10, Train Loss: 0.0351, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.8033\n",
      "Epoch 10/10, Train Loss: 0.0245, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7663\n",
      "Model 3 - Iteration 310: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 84.90947365760803 s\n",
      "Averaged - Iteration 310: Accuracy: 0.9693, F1 Micro: 0.9767, F1 Macro: 0.7357\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.724935531616211 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2892, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1946, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.172, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1324, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Epoch 5/10, Train Loss: 0.0941, Accuracy: 0.9663, F1 Micro: 0.974, F1 Macro: 0.7936\n",
      "Epoch 6/10, Train Loss: 0.0863, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Epoch 7/10, Train Loss: 0.0563, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7586\n",
      "Epoch 8/10, Train Loss: 0.0506, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.796\n",
      "Epoch 9/10, Train Loss: 0.0289, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7752\n",
      "Epoch 10/10, Train Loss: 0.0254, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7662\n",
      "Model 1 - Iteration 320: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 84.92664003372192 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2732, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1918, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1687, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1255, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7107\n",
      "Epoch 5/10, Train Loss: 0.0961, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.763\n",
      "Epoch 6/10, Train Loss: 0.0818, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7566\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0556, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7586\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0499, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0293, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0261, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Model 2 - Iteration 320: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 90.50521421432495 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.279, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1915, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1743, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1383, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Epoch 5/10, Train Loss: 0.1252, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.6539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1029, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7884\n",
      "Epoch 7/10, Train Loss: 0.0652, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0528, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 9/10, Train Loss: 0.0302, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Epoch 10/10, Train Loss: 0.0273, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7552\n",
      "Model 3 - Iteration 320: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 87.68231296539307 s\n",
      "Averaged - Iteration 320: Accuracy: 0.9695, F1 Micro: 0.9768, F1 Macro: 0.7389\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.406352996826172 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.27, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.183, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1737, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1358, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7587\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1123, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7959\n",
      "Epoch 6/10, Train Loss: 0.0685, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.7925\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.052, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0389, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8197\n",
      "Epoch 9/10, Train Loss: 0.0338, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.797\n",
      "Epoch 10/10, Train Loss: 0.026, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7864\n",
      "Model 1 - Iteration 330: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8197\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      1.00      1.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.94      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.82      0.82       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 93.08710241317749 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2546, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1805, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1641, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1286, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7561\n",
      "Epoch 5/10, Train Loss: 0.1048, Accuracy: 0.9599, F1 Micro: 0.9691, F1 Macro: 0.7898\n",
      "Epoch 6/10, Train Loss: 0.0641, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0502, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "Epoch 8/10, Train Loss: 0.0412, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7949\n",
      "Epoch 9/10, Train Loss: 0.0353, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7978\n",
      "Epoch 10/10, Train Loss: 0.0282, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7576\n",
      "Model 2 - Iteration 330: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.98      0.98       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 88.94823956489563 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2581, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1823, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1767, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1394, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7505\n",
      "Epoch 5/10, Train Loss: 0.1181, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.7908\n",
      "Epoch 6/10, Train Loss: 0.0729, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.7919\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0549, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0407, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7989\n",
      "Epoch 9/10, Train Loss: 0.035, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.746\n",
      "Epoch 10/10, Train Loss: 0.024, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.776\n",
      "Model 3 - Iteration 330: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 90.94299745559692 s\n",
      "Averaged - Iteration 330: Accuracy: 0.9697, F1 Micro: 0.9769, F1 Macro: 0.7428\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.978435754776001 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2669, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1767, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1635, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1429, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0924, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7982\n",
      "Epoch 6/10, Train Loss: 0.068, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 7/10, Train Loss: 0.0521, Accuracy: 0.9712, F1 Micro: 0.9778, F1 Macro: 0.7966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0448, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7987\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0291, Accuracy: 0.976, F1 Micro: 0.9816, F1 Macro: 0.7997\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0216, Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.805\n",
      "Model 1 - Iteration 340: Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.81       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 96.00619769096375 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2518, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1746, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 3/10, Train Loss: 0.1552, Accuracy: 0.9599, F1 Micro: 0.9689, F1 Macro: 0.6497\n",
      "Epoch 4/10, Train Loss: 0.1503, Accuracy: 0.9599, F1 Micro: 0.9689, F1 Macro: 0.6497\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0943, Accuracy: 0.9728, F1 Micro: 0.9794, F1 Macro: 0.7895\n",
      "Epoch 6/10, Train Loss: 0.0703, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7672\n",
      "Epoch 7/10, Train Loss: 0.0511, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7633\n",
      "Epoch 8/10, Train Loss: 0.0446, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7653\n",
      "Epoch 9/10, Train Loss: 0.0289, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.743\n",
      "Epoch 10/10, Train Loss: 0.0226, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7551\n",
      "Model 2 - Iteration 340: Accuracy: 0.9728, F1 Micro: 0.9794, F1 Macro: 0.7895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 85.7345621585846 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2564, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1765, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1643, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Epoch 4/10, Train Loss: 0.1537, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7189\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1022, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0693, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7989\n",
      "Epoch 7/10, Train Loss: 0.0504, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7789\n",
      "Epoch 8/10, Train Loss: 0.0437, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.796\n",
      "Epoch 9/10, Train Loss: 0.0279, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7793\n",
      "Epoch 10/10, Train Loss: 0.0202, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7802\n",
      "Model 3 - Iteration 340: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 87.9928572177887 s\n",
      "Averaged - Iteration 340: Accuracy: 0.9699, F1 Micro: 0.9771, F1 Macro: 0.7458\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.490718126296997 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2539, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1829, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.182, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1171, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1029, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "Epoch 6/10, Train Loss: 0.0656, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7662\n",
      "Epoch 7/10, Train Loss: 0.0409, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.78\n",
      "Epoch 8/10, Train Loss: 0.0353, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7672\n",
      "Epoch 9/10, Train Loss: 0.0254, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7671\n",
      "Epoch 10/10, Train Loss: 0.0221, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7772\n",
      "Model 1 - Iteration 350: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.98      0.98       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 88.98302984237671 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2398, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1821, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1764, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1176, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7471\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0945, Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7998\n",
      "Epoch 6/10, Train Loss: 0.0639, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 7/10, Train Loss: 0.0486, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7449\n",
      "Epoch 8/10, Train Loss: 0.0384, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7595\n",
      "Epoch 9/10, Train Loss: 0.0238, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7781\n",
      "Epoch 10/10, Train Loss: 0.023, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7781\n",
      "Model 2 - Iteration 350: Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 88.78376746177673 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2408, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1838, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1856, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1309, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Epoch 5/10, Train Loss: 0.108, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.7179\n",
      "Epoch 6/10, Train Loss: 0.0833, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.051, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7989\n",
      "Epoch 8/10, Train Loss: 0.0415, Accuracy: 0.9631, F1 Micro: 0.9723, F1 Macro: 0.7505\n",
      "Epoch 9/10, Train Loss: 0.0262, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.778\n",
      "Epoch 10/10, Train Loss: 0.0245, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7971\n",
      "Model 3 - Iteration 350: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 89.62919569015503 s\n",
      "Averaged - Iteration 350: Accuracy: 0.9701, F1 Micro: 0.9773, F1 Macro: 0.7486\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.056684970855713 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.256, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1832, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1622, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1208, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "Epoch 5/10, Train Loss: 0.0964, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Epoch 6/10, Train Loss: 0.0595, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7948\n",
      "Epoch 7/10, Train Loss: 0.054, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.799\n",
      "Epoch 8/10, Train Loss: 0.0422, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0284, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7997\n",
      "Epoch 10/10, Train Loss: 0.0218, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7671\n",
      "Model 1 - Iteration 360: Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.92      0.98      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 89.65560030937195 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2432, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1808, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1605, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Epoch 4/10, Train Loss: 0.1249, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7187\n",
      "Epoch 5/10, Train Loss: 0.0959, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.7533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0588, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7959\n",
      "Epoch 7/10, Train Loss: 0.0526, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7585\n",
      "Epoch 8/10, Train Loss: 0.0437, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7578\n",
      "Epoch 9/10, Train Loss: 0.0292, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7751\n",
      "Epoch 10/10, Train Loss: 0.0225, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7577\n",
      "Model 2 - Iteration 360: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7959\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.94      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.78      0.80       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.98      0.98      0.97       407\n",
      "\n",
      "Training completed in 87.82855319976807 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2425, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1831, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.166, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1378, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.11, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7949\n",
      "Epoch 6/10, Train Loss: 0.0659, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7952\n",
      "Epoch 7/10, Train Loss: 0.0559, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7632\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0439, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7799\n",
      "Epoch 9/10, Train Loss: 0.0298, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.761\n",
      "Epoch 10/10, Train Loss: 0.0218, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7451\n",
      "Model 3 - Iteration 360: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.96      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.78      0.78      0.78       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 89.90102314949036 s\n",
      "Averaged - Iteration 360: Accuracy: 0.9702, F1 Micro: 0.9773, F1 Macro: 0.7508\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.683129072189331 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2558, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1689, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1638, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1103, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0795, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7812\n",
      "Epoch 6/10, Train Loss: 0.0635, Accuracy: 0.9679, F1 Micro: 0.9753, F1 Macro: 0.7946\n",
      "Epoch 7/10, Train Loss: 0.0545, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.7719\n",
      "Epoch 8/10, Train Loss: 0.0352, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.032, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.8215\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0277, Accuracy: 0.9776, F1 Micro: 0.9829, F1 Macro: 0.8059\n",
      "Model 1 - Iteration 370: Accuracy: 0.9776, F1 Micro: 0.9829, F1 Macro: 0.8059\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.92      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.81       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 96.72726583480835 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2434, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.168, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1619, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 4/10, Train Loss: 0.1152, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0829, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.778\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0669, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7672\n",
      "Epoch 7/10, Train Loss: 0.0547, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7769\n",
      "Epoch 8/10, Train Loss: 0.0323, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7762\n",
      "Epoch 9/10, Train Loss: 0.0284, Accuracy: 0.9647, F1 Micro: 0.9735, F1 Macro: 0.7506\n",
      "Epoch 10/10, Train Loss: 0.0274, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7791\n",
      "Model 2 - Iteration 370: Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 92.85315346717834 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2451, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1685, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1677, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1253, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.095, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0698, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7967\n",
      "Epoch 7/10, Train Loss: 0.059, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0351, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.781\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0302, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7998\n",
      "Epoch 10/10, Train Loss: 0.0254, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.768\n",
      "Model 3 - Iteration 370: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 98.06570649147034 s\n",
      "Averaged - Iteration 370: Accuracy: 0.9704, F1 Micro: 0.9774, F1 Macro: 0.7527\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.2488880157470703 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2534, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1531, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1442, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1262, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 5/10, Train Loss: 0.0994, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7958\n",
      "Epoch 6/10, Train Loss: 0.0652, Accuracy: 0.9679, F1 Micro: 0.9752, F1 Macro: 0.7943\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0531, Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.8227\n",
      "Epoch 8/10, Train Loss: 0.0367, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7662\n",
      "Epoch 9/10, Train Loss: 0.0286, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0253, Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.8227\n",
      "Model 1 - Iteration 380: Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.8227\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      1.00      1.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.83      0.82       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 96.05275511741638 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2403, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1508, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.142, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Epoch 4/10, Train Loss: 0.1289, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.6512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1023, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Epoch 6/10, Train Loss: 0.0669, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.7499\n",
      "Epoch 7/10, Train Loss: 0.057, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7577\n",
      "Epoch 8/10, Train Loss: 0.0352, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7642\n",
      "Epoch 9/10, Train Loss: 0.0297, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7671\n",
      "Epoch 10/10, Train Loss: 0.0279, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7577\n",
      "Model 2 - Iteration 380: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 92.62337017059326 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2467, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1519, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1486, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1351, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1108, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "Epoch 6/10, Train Loss: 0.0681, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.055, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "Epoch 8/10, Train Loss: 0.0326, Accuracy: 0.9535, F1 Micro: 0.9653, F1 Macro: 0.7187\n",
      "Epoch 9/10, Train Loss: 0.0236, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7981\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0244, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "Model 3 - Iteration 380: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 96.30256605148315 s\n",
      "Averaged - Iteration 380: Accuracy: 0.9705, F1 Micro: 0.9776, F1 Macro: 0.7549\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.7422828674316406 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.243, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1624, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1348, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1142, Accuracy: 0.9615, F1 Micro: 0.971, F1 Macro: 0.7384\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.093, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Epoch 6/10, Train Loss: 0.067, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.78\n",
      "Epoch 7/10, Train Loss: 0.046, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.798\n",
      "Epoch 8/10, Train Loss: 0.0383, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.766\n",
      "Epoch 9/10, Train Loss: 0.0324, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7459\n",
      "Epoch 10/10, Train Loss: 0.0197, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7622\n",
      "Model 1 - Iteration 390: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 94.43575119972229 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2273, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1587, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.129, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1143, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7394\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0906, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.066, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7671\n",
      "Epoch 7/10, Train Loss: 0.0434, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7576\n",
      "Epoch 8/10, Train Loss: 0.0376, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7511\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.033, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "Epoch 10/10, Train Loss: 0.0197, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.755\n",
      "Model 2 - Iteration 390: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.98      0.98       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 99.28946375846863 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2329, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1612, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1378, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1274, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1139, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.073, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0491, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.799\n",
      "Epoch 8/10, Train Loss: 0.0421, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7679\n",
      "Epoch 9/10, Train Loss: 0.0322, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.7946\n",
      "Epoch 10/10, Train Loss: 0.0215, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.756\n",
      "Model 3 - Iteration 390: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 98.97853541374207 s\n",
      "Averaged - Iteration 390: Accuracy: 0.9706, F1 Micro: 0.9776, F1 Macro: 0.7565\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.307748556137085 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2447, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1451, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1519, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1118, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 5/10, Train Loss: 0.0924, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0624, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 7/10, Train Loss: 0.0429, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7951\n",
      "Epoch 8/10, Train Loss: 0.0403, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Epoch 9/10, Train Loss: 0.0261, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7628\n",
      "Epoch 10/10, Train Loss: 0.022, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7882\n",
      "Model 1 - Iteration 400: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 97.20606017112732 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2338, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1428, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1463, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1084, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7236\n",
      "Epoch 5/10, Train Loss: 0.09, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7338\n",
      "Epoch 6/10, Train Loss: 0.0617, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7595\n",
      "Epoch 7/10, Train Loss: 0.0451, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7661\n",
      "Epoch 8/10, Train Loss: 0.0385, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.023, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8041\n",
      "Epoch 10/10, Train Loss: 0.0228, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.78\n",
      "Model 2 - Iteration 400: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8041\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 96.94665551185608 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2368, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1461, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1558, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1145, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0924, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7772\n",
      "Epoch 6/10, Train Loss: 0.0655, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7661\n",
      "Epoch 7/10, Train Loss: 0.0384, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7512\n",
      "Epoch 8/10, Train Loss: 0.0359, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.7937\n",
      "Epoch 9/10, Train Loss: 0.0246, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7948\n",
      "Epoch 10/10, Train Loss: 0.0212, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7661\n",
      "Model 3 - Iteration 400: Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.74      0.83      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 96.81163024902344 s\n",
      "Averaged - Iteration 400: Accuracy: 0.9707, F1 Micro: 0.9777, F1 Macro: 0.758\n",
      "Total sampling time: 161.96 seconds\n",
      "Total runtime: 5915.813260555267 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f146d61",
   "metadata": {
    "papermill": {
     "duration": 0.150131,
     "end_time": "2025-03-14T14:46:09.307725",
     "exception": false,
     "start_time": "2025-03-14T14:46:09.157594",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62388b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 3\n",
      "Random seed: [14, 7, 33]\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5339, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.361, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2712, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2079, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2244, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1625, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2034, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1394, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1358, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1462, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 1 - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 39.523131370544434 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6345, Accuracy: 0.9263, F1 Micro: 0.9407, F1 Macro: 0.6225\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3936, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2767, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2143, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2256, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.161, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2104, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1331, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1375, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1566, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 2 - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 38.405043601989746 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.535, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3536, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.265, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2017, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2273, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1566, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2122, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1356, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1444, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1701, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 3 - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 39.18589210510254 s\n",
      "Averaged - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 38\n",
      "Sampling duration: 14.545206308364868 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4419, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2472, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2084, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1504, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1312, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1582, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1017, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1071, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.14, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1062, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 1 - Iteration 63: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 46.36387348175049 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5084, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2584, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2137, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.148, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1299, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1528, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0993, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1057, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1334, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1075, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 2 - Iteration 63: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 45.389426946640015 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4137, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2393, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2065, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1445, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.135, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1565, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1035, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1096, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1577, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.117, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 3 - Iteration 63: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 44.80835151672363 s\n",
      "Averaged - Iteration 63: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 34\n",
      "Sampling duration: 15.369733095169067 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3845, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1983, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1864, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1309, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1334, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1492, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 7/10, Train Loss: 0.1304, Accuracy: 0.9599, F1 Micro: 0.969, F1 Macro: 0.6499\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1003, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1234, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Epoch 10/10, Train Loss: 0.0827, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6545\n",
      "Model 1 - Iteration 97: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.65      0.66      0.65       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 47.40594220161438 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4247, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1961, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1842, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.127, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1328, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.144, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1212, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0794, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.799\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.091, Accuracy: 0.9776, F1 Micro: 0.983, F1 Macro: 0.8237\n",
      "Epoch 10/10, Train Loss: 0.0672, Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.8206\n",
      "Model 2 - Iteration 97: Accuracy: 0.9776, F1 Micro: 0.983, F1 Macro: 0.8237\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      1.00      1.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      1.00      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.83      0.82       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 48.1750922203064 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3698, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1934, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1865, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1307, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.135, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1581, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.145, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1141, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1401, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.095, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Model 3 - Iteration 97: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.65      0.66      0.65       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 50.31864547729492 s\n",
      "Averaged - Iteration 97: Accuracy: 0.9655, F1 Micro: 0.9738, F1 Macro: 0.6722\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 31\n",
      "Sampling duration: 13.766622304916382 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3522, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1868, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1575, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1439, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1476, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1499, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1168, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0983, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Epoch 9/10, Train Loss: 0.0939, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Epoch 10/10, Train Loss: 0.0683, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7212\n",
      "Model 1 - Iteration 128: Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.67      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 52.24630165100098 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3856, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.187, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1563, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1423, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1427, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1368, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1055, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.6568\n",
      "Epoch 8/10, Train Loss: 0.0839, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7877\n",
      "Epoch 9/10, Train Loss: 0.0725, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7656\n",
      "Epoch 10/10, Train Loss: 0.0571, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7502\n",
      "Model 2 - Iteration 128: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.6568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.92      0.98      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.65      0.66      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 50.39483165740967 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3441, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1858, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1578, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1412, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1492, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.154, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1247, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Epoch 8/10, Train Loss: 0.1176, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Epoch 9/10, Train Loss: 0.1104, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Epoch 10/10, Train Loss: 0.0777, Accuracy: 0.9615, F1 Micro: 0.9703, F1 Macro: 0.7165\n",
      "Model 3 - Iteration 128: Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.67      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 49.97515106201172 s\n",
      "Averaged - Iteration 128: Accuracy: 0.9666, F1 Micro: 0.9746, F1 Macro: 0.6682\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 28\n",
      "Sampling duration: 12.454267501831055 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3295, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1785, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1803, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1589, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1565, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1502, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1232, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.6569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1061, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.6569\n",
      "Epoch 9/10, Train Loss: 0.0689, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0705, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7236\n",
      "Model 1 - Iteration 156: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.71      0.72       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 60.797688245773315 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3551, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1784, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1771, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1598, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1501, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 6/10, Train Loss: 0.1491, Accuracy: 0.9615, F1 Micro: 0.9703, F1 Macro: 0.6509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1186, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1012, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0652, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0675, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.8033\n",
      "Model 2 - Iteration 156: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.8033\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 60.35158848762512 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3155, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1754, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1812, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1595, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1585, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1573, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1245, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Epoch 8/10, Train Loss: 0.1088, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7198\n",
      "Epoch 9/10, Train Loss: 0.0748, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.717\n",
      "Epoch 10/10, Train Loss: 0.0694, Accuracy: 0.9567, F1 Micro: 0.9667, F1 Macro: 0.7037\n",
      "Model 3 - Iteration 156: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.66      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 57.07051944732666 s\n",
      "Averaged - Iteration 156: Accuracy: 0.9675, F1 Micro: 0.9753, F1 Macro: 0.6801\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 25\n",
      "Sampling duration: 11.13570761680603 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2979, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1958, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1513, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1656, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1649, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1303, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.655\n",
      "Epoch 7/10, Train Loss: 0.0805, Accuracy: 0.9551, F1 Micro: 0.9652, F1 Macro: 0.6467\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0764, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7661\n",
      "Epoch 9/10, Train Loss: 0.0686, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7992\n",
      "Epoch 10/10, Train Loss: 0.0572, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7502\n",
      "Model 1 - Iteration 181: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7661\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.74      0.77       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 60.34267568588257 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.322, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1929, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1523, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1608, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1616, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.127, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0798, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7662\n",
      "Epoch 8/10, Train Loss: 0.0717, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7551\n",
      "Epoch 9/10, Train Loss: 0.0694, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0581, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Model 2 - Iteration 181: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 61.881325006484985 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.288, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1956, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1517, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1682, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1744, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1416, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Epoch 7/10, Train Loss: 0.0954, Accuracy: 0.9567, F1 Micro: 0.9665, F1 Macro: 0.6478\n",
      "Epoch 8/10, Train Loss: 0.0999, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Epoch 9/10, Train Loss: 0.093, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0727, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7661\n",
      "Model 3 - Iteration 181: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7661\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.74      0.77       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 60.29368734359741 s\n",
      "Averaged - Iteration 181: Accuracy: 0.9682, F1 Micro: 0.9758, F1 Macro: 0.6952\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 22\n",
      "Sampling duration: 9.964573383331299 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2888, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1739, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1678, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1585, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.135, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1164, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1049, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7974\n",
      "Epoch 8/10, Train Loss: 0.0712, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7874\n",
      "Epoch 9/10, Train Loss: 0.0538, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7671\n",
      "Epoch 10/10, Train Loss: 0.0487, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7671\n",
      "Model 1 - Iteration 203: Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      1.00      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 65.41011118888855 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3155, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1728, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1644, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1585, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1281, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1007, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0918, Accuracy: 0.9728, F1 Micro: 0.9794, F1 Macro: 0.7782\n",
      "Epoch 8/10, Train Loss: 0.064, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7751\n",
      "Epoch 9/10, Train Loss: 0.0622, Accuracy: 0.9599, F1 Micro: 0.9696, F1 Macro: 0.7419\n",
      "Epoch 10/10, Train Loss: 0.0577, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7521\n",
      "Model 2 - Iteration 203: Accuracy: 0.9728, F1 Micro: 0.9794, F1 Macro: 0.7782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      1.00      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.74      0.83      0.78       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 65.44863438606262 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2812, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1732, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1687, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1612, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1361, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1202, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1194, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Epoch 8/10, Train Loss: 0.0848, Accuracy: 0.9535, F1 Micro: 0.9639, F1 Macro: 0.6456\n",
      "Epoch 9/10, Train Loss: 0.0663, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.7332\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0519, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7764\n",
      "Model 3 - Iteration 203: Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       407\n",
      "   macro avg       0.74      0.83      0.78       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 66.64270806312561 s\n",
      "Averaged - Iteration 203: Accuracy: 0.9686, F1 Micro: 0.9761, F1 Macro: 0.7079\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 20\n",
      "Sampling duration: 8.899450063705444 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2683, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1844, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1628, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1583, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 5/10, Train Loss: 0.1448, Accuracy: 0.9583, F1 Micro: 0.9677, F1 Macro: 0.6488\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1096, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0872, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.8031\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0553, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 9/10, Train Loss: 0.0513, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Epoch 10/10, Train Loss: 0.0437, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Model 1 - Iteration 223: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 68.79359793663025 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2911, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1805, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1596, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1567, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1385, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0936, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.8204\n",
      "Epoch 7/10, Train Loss: 0.0777, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7511\n",
      "Epoch 8/10, Train Loss: 0.0477, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7584\n",
      "Epoch 9/10, Train Loss: 0.0549, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.767\n",
      "Epoch 10/10, Train Loss: 0.0468, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7513\n",
      "Model 2 - Iteration 223: Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.8204\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      1.00      1.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       407\n",
      "   macro avg       0.81      0.83      0.82       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.96      0.99      0.98       407\n",
      "\n",
      "Training completed in 66.83628702163696 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2625, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1815, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.163, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1628, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1476, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.6539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1139, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1048, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0649, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7763\n",
      "Epoch 9/10, Train Loss: 0.058, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0447, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.82\n",
      "Model 3 - Iteration 223: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      1.00      1.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.83      0.82       407\n",
      "weighted avg       0.97      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 71.6074492931366 s\n",
      "Averaged - Iteration 223: Accuracy: 0.969, F1 Micro: 0.9764, F1 Macro: 0.721\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 18\n",
      "Sampling duration: 8.407406091690063 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2777, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1728, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1699, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1684, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1379, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Epoch 6/10, Train Loss: 0.1209, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Epoch 7/10, Train Loss: 0.0907, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0578, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7672\n",
      "Epoch 9/10, Train Loss: 0.0489, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7503\n",
      "Epoch 10/10, Train Loss: 0.0506, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7765\n",
      "Model 1 - Iteration 241: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.75      0.77       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 71.54045009613037 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2959, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1732, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1635, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1575, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1119, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0829, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7522\n",
      "Epoch 7/10, Train Loss: 0.0666, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7596\n",
      "Epoch 8/10, Train Loss: 0.0519, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7586\n",
      "Epoch 9/10, Train Loss: 0.0449, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7586\n",
      "Epoch 10/10, Train Loss: 0.0515, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7513\n",
      "Model 2 - Iteration 241: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7522\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      1.00      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.75      0.75       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 71.96396231651306 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2705, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1753, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1707, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1779, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1486, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.657\n",
      "Epoch 6/10, Train Loss: 0.1264, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.656\n",
      "Epoch 7/10, Train Loss: 0.101, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7795\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0593, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "Epoch 9/10, Train Loss: 0.048, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.777\n",
      "Epoch 10/10, Train Loss: 0.0497, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7493\n",
      "Model 3 - Iteration 241: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 71.11106824874878 s\n",
      "Averaged - Iteration 241: Accuracy: 0.9694, F1 Micro: 0.9768, F1 Macro: 0.7267\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 9\n",
      "Sampling duration: 7.549554109573364 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.268, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1697, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1647, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1452, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.657\n",
      "Epoch 5/10, Train Loss: 0.1649, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Epoch 6/10, Train Loss: 0.0896, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0716, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "Epoch 8/10, Train Loss: 0.0529, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7086\n",
      "Epoch 9/10, Train Loss: 0.0461, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Epoch 10/10, Train Loss: 0.0356, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7864\n",
      "Model 1 - Iteration 250: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 70.74283766746521 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2877, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1699, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1635, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1372, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1434, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0727, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7568\n",
      "Epoch 7/10, Train Loss: 0.0638, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7663\n",
      "Epoch 8/10, Train Loss: 0.0522, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.749\n",
      "Epoch 9/10, Train Loss: 0.0478, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7521\n",
      "Epoch 10/10, Train Loss: 0.0361, Accuracy: 0.9615, F1 Micro: 0.971, F1 Macro: 0.7393\n",
      "Model 2 - Iteration 250: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.92      0.98      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.73      0.79      0.76       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 72.34438896179199 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.26, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1689, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1633, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1496, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1782, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.108, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Epoch 7/10, Train Loss: 0.0865, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7483\n",
      "Epoch 8/10, Train Loss: 0.0583, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7556\n",
      "Epoch 9/10, Train Loss: 0.049, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7644\n",
      "Epoch 10/10, Train Loss: 0.0348, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.7503\n",
      "Model 3 - Iteration 250: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 72.27474594116211 s\n",
      "Averaged - Iteration 250: Accuracy: 0.9697, F1 Micro: 0.9769, F1 Macro: 0.7319\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 15\n",
      "Sampling duration: 7.184941291809082 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2849, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.178, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1824, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1577, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1225, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0877, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0607, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7812\n",
      "Epoch 8/10, Train Loss: 0.0548, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7673\n",
      "Epoch 9/10, Train Loss: 0.0432, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7773\n",
      "Epoch 10/10, Train Loss: 0.032, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7672\n",
      "Model 1 - Iteration 265: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 76.9653389453888 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3032, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.177, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1802, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1465, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Epoch 5/10, Train Loss: 0.1016, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7457\n",
      "Epoch 6/10, Train Loss: 0.0818, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7466\n",
      "Epoch 7/10, Train Loss: 0.0612, Accuracy: 0.9647, F1 Micro: 0.9735, F1 Macro: 0.7506\n",
      "Epoch 8/10, Train Loss: 0.0604, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7521\n",
      "Epoch 9/10, Train Loss: 0.0432, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7521\n",
      "Epoch 10/10, Train Loss: 0.0339, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7594\n",
      "Model 2 - Iteration 265: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 71.47379159927368 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2762, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1779, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1831, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1598, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1317, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1007, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Epoch 7/10, Train Loss: 0.063, Accuracy: 0.9647, F1 Micro: 0.9735, F1 Macro: 0.7741\n",
      "Epoch 8/10, Train Loss: 0.0614, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7671\n",
      "Epoch 9/10, Train Loss: 0.0445, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7651\n",
      "Epoch 10/10, Train Loss: 0.0329, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7449\n",
      "Model 3 - Iteration 265: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 75.82724642753601 s\n",
      "Averaged - Iteration 265: Accuracy: 0.9699, F1 Micro: 0.9771, F1 Macro: 0.7363\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 14\n",
      "Sampling duration: 6.5731682777404785 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2643, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1736, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1583, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1656, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1382, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7117\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0974, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0558, Accuracy: 0.9728, F1 Micro: 0.9794, F1 Macro: 0.7895\n",
      "Epoch 8/10, Train Loss: 0.0485, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7884\n",
      "Epoch 9/10, Train Loss: 0.0432, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7751\n",
      "Epoch 10/10, Train Loss: 0.0337, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7793\n",
      "Model 1 - Iteration 279: Accuracy: 0.9728, F1 Micro: 0.9794, F1 Macro: 0.7895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 78.4532790184021 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2805, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1712, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1553, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1553, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8041\n",
      "Epoch 5/10, Train Loss: 0.1175, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7672\n",
      "Epoch 6/10, Train Loss: 0.0786, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7893\n",
      "Epoch 7/10, Train Loss: 0.0478, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.768\n",
      "Epoch 8/10, Train Loss: 0.0433, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7584\n",
      "Epoch 9/10, Train Loss: 0.043, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0387, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7901\n",
      "Model 2 - Iteration 279: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7901\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.92      0.98      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 74.75378561019897 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2546, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1737, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1584, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1779, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1477, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7802\n",
      "Epoch 6/10, Train Loss: 0.1035, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7661\n",
      "Epoch 7/10, Train Loss: 0.057, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0474, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7893\n",
      "Epoch 9/10, Train Loss: 0.045, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.037, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7893\n",
      "Model 3 - Iteration 279: Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7893\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 77.7960696220398 s\n",
      "Averaged - Iteration 279: Accuracy: 0.9701, F1 Micro: 0.9773, F1 Macro: 0.7408\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 13\n",
      "Sampling duration: 5.779005527496338 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2747, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1805, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1754, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1444, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1233, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7489\n",
      "Epoch 6/10, Train Loss: 0.0886, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.7927\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0687, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0532, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7798\n",
      "Epoch 9/10, Train Loss: 0.0364, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0323, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7997\n",
      "Model 1 - Iteration 292: Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.92      0.98      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 84.23478031158447 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2884, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1794, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1699, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1322, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1157, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.799\n",
      "Epoch 6/10, Train Loss: 0.0841, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7948\n",
      "Epoch 7/10, Train Loss: 0.0714, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7553\n",
      "Epoch 8/10, Train Loss: 0.0555, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7594\n",
      "Epoch 9/10, Train Loss: 0.0429, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.767\n",
      "Epoch 10/10, Train Loss: 0.033, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7584\n",
      "Model 2 - Iteration 292: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 79.49072313308716 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2659, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1801, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1747, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.145, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.129, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7787\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0966, Accuracy: 0.9744, F1 Micro: 0.9803, F1 Macro: 0.7986\n",
      "Epoch 7/10, Train Loss: 0.0708, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7491\n",
      "Epoch 8/10, Train Loss: 0.0503, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7493\n",
      "Epoch 9/10, Train Loss: 0.0374, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7977\n",
      "Epoch 10/10, Train Loss: 0.0316, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.798\n",
      "Model 3 - Iteration 292: Accuracy: 0.9744, F1 Micro: 0.9803, F1 Macro: 0.7986\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.92      0.96      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.78      0.80       407\n",
      "weighted avg       0.97      0.98      0.98       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 79.3442587852478 s\n",
      "Averaged - Iteration 292: Accuracy: 0.9705, F1 Micro: 0.9775, F1 Macro: 0.7453\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 8\n",
      "Sampling duration: 5.4166905879974365 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2704, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.189, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1899, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1507, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.654\n",
      "Epoch 5/10, Train Loss: 0.1231, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0877, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7875\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0756, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.063, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0412, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 10/10, Train Loss: 0.0366, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.796\n",
      "Model 1 - Iteration 300: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 85.16825151443481 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.286, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1859, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.189, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1414, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1035, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7762\n",
      "Epoch 6/10, Train Loss: 0.0796, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7574\n",
      "Epoch 7/10, Train Loss: 0.0675, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0552, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7672\n",
      "Epoch 9/10, Train Loss: 0.0427, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.765\n",
      "Epoch 10/10, Train Loss: 0.0327, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.764\n",
      "Model 2 - Iteration 300: Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 82.03972172737122 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2629, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1888, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1943, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.156, Accuracy: 0.9615, F1 Micro: 0.9703, F1 Macro: 0.6509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1373, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7643\n",
      "Epoch 6/10, Train Loss: 0.1038, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7512\n",
      "Epoch 7/10, Train Loss: 0.0819, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7648\n",
      "Epoch 8/10, Train Loss: 0.0624, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.746\n",
      "Epoch 9/10, Train Loss: 0.0429, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7661\n",
      "Epoch 10/10, Train Loss: 0.0344, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7662\n",
      "Model 3 - Iteration 300: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7643\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.96      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.74      0.76       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 78.3489089012146 s\n",
      "Averaged - Iteration 300: Accuracy: 0.9705, F1 Micro: 0.9775, F1 Macro: 0.7475\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.964793920516968 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.271, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1781, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1784, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1617, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1303, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.722\n",
      "Epoch 6/10, Train Loss: 0.0912, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7791\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0564, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 8/10, Train Loss: 0.0493, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.754\n",
      "Epoch 9/10, Train Loss: 0.042, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Epoch 10/10, Train Loss: 0.0305, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7662\n",
      "Model 1 - Iteration 310: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 83.50103640556335 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2816, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1758, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1746, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1453, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7672\n",
      "Epoch 5/10, Train Loss: 0.1041, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.7618\n",
      "Epoch 6/10, Train Loss: 0.0772, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7662\n",
      "Epoch 7/10, Train Loss: 0.0521, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7449\n",
      "Epoch 8/10, Train Loss: 0.0463, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.767\n",
      "Epoch 9/10, Train Loss: 0.0397, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7447\n",
      "Epoch 10/10, Train Loss: 0.0304, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.767\n",
      "Model 2 - Iteration 310: Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      1.00      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       407\n",
      "   macro avg       0.73      0.83      0.77       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 79.90310025215149 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2635, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.176, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1817, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1705, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1318, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7643\n",
      "Epoch 6/10, Train Loss: 0.0923, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0547, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0484, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7789\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0398, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.78\n",
      "Epoch 10/10, Train Loss: 0.0334, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.756\n",
      "Model 3 - Iteration 310: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 86.7643837928772 s\n",
      "Averaged - Iteration 310: Accuracy: 0.9705, F1 Micro: 0.9776, F1 Macro: 0.7498\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.611476182937622 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2678, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.178, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.153, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1304, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1114, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7672\n",
      "Epoch 6/10, Train Loss: 0.0849, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7762\n",
      "Epoch 7/10, Train Loss: 0.0551, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7875\n",
      "Epoch 8/10, Train Loss: 0.0449, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.796\n",
      "Epoch 9/10, Train Loss: 0.0372, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7773\n",
      "Epoch 10/10, Train Loss: 0.0321, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7842\n",
      "Model 1 - Iteration 320: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.75      0.77       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 82.95367813110352 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2815, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1765, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1495, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1163, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.091, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7672\n",
      "Epoch 6/10, Train Loss: 0.0781, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7449\n",
      "Epoch 7/10, Train Loss: 0.0535, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7595\n",
      "Epoch 8/10, Train Loss: 0.045, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7595\n",
      "Epoch 9/10, Train Loss: 0.0388, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7439\n",
      "Epoch 10/10, Train Loss: 0.0365, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7585\n",
      "Model 2 - Iteration 320: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.75      0.77       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 83.06438064575195 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2599, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1791, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.157, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1375, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1158, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "Epoch 6/10, Train Loss: 0.0923, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0611, Accuracy: 0.9728, F1 Micro: 0.9794, F1 Macro: 0.7782\n",
      "Epoch 8/10, Train Loss: 0.0471, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Epoch 9/10, Train Loss: 0.0382, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.767\n",
      "Epoch 10/10, Train Loss: 0.0341, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.778\n",
      "Model 3 - Iteration 320: Accuracy: 0.9728, F1 Micro: 0.9794, F1 Macro: 0.7782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      1.00      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.74      0.83      0.78       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 84.59137344360352 s\n",
      "Averaged - Iteration 320: Accuracy: 0.9707, F1 Micro: 0.9777, F1 Macro: 0.7511\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.239307165145874 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2466, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1706, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1589, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1522, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1029, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 6/10, Train Loss: 0.0818, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0547, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 8/10, Train Loss: 0.0482, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7513\n",
      "Epoch 9/10, Train Loss: 0.0349, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7762\n",
      "Epoch 10/10, Train Loss: 0.025, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.756\n",
      "Model 1 - Iteration 330: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 87.09721565246582 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2582, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.167, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1568, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1326, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7576\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0887, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0804, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7987\n",
      "Epoch 7/10, Train Loss: 0.0572, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.753\n",
      "Epoch 8/10, Train Loss: 0.0511, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7689\n",
      "Epoch 9/10, Train Loss: 0.036, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7584\n",
      "Epoch 10/10, Train Loss: 0.0278, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.752\n",
      "Model 2 - Iteration 330: Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7987\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.98      0.98       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 87.61482405662537 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.24, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1706, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1643, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1643, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1194, Accuracy: 0.9679, F1 Micro: 0.9753, F1 Macro: 0.7946\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1032, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7808\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0621, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7818\n",
      "Epoch 8/10, Train Loss: 0.0517, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7671\n",
      "Epoch 9/10, Train Loss: 0.0361, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.781\n",
      "Epoch 10/10, Train Loss: 0.0277, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.778\n",
      "Model 3 - Iteration 330: Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.92      0.98      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.78      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 88.8497986793518 s\n",
      "Averaged - Iteration 330: Accuracy: 0.9709, F1 Micro: 0.9778, F1 Macro: 0.7536\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.740504026412964 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2367, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1696, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1634, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1287, Accuracy: 0.9679, F1 Micro: 0.9753, F1 Macro: 0.6548\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1008, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7217\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0813, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0576, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Epoch 8/10, Train Loss: 0.0412, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0317, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7902\n",
      "Epoch 10/10, Train Loss: 0.0228, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7893\n",
      "Model 1 - Iteration 340: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7902\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 91.76439189910889 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2462, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1653, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1592, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1069, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8041\n",
      "Epoch 5/10, Train Loss: 0.0846, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0743, Accuracy: 0.9776, F1 Micro: 0.9829, F1 Macro: 0.8236\n",
      "Epoch 7/10, Train Loss: 0.0537, Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7998\n",
      "Epoch 8/10, Train Loss: 0.0392, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7439\n",
      "Epoch 9/10, Train Loss: 0.0366, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.801\n",
      "Epoch 10/10, Train Loss: 0.0261, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7511\n",
      "Model 2 - Iteration 340: Accuracy: 0.9776, F1 Micro: 0.9829, F1 Macro: 0.8236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      1.00      1.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.83      0.82       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 86.71722650527954 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2298, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1684, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1675, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1356, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.657\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.113, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7663\n",
      "Epoch 6/10, Train Loss: 0.0886, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.7917\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0594, Accuracy: 0.976, F1 Micro: 0.9816, F1 Macro: 0.7997\n",
      "Epoch 8/10, Train Loss: 0.0411, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7448\n",
      "Epoch 9/10, Train Loss: 0.0338, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7448\n",
      "Epoch 10/10, Train Loss: 0.0251, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.78\n",
      "Model 3 - Iteration 340: Accuracy: 0.976, F1 Micro: 0.9816, F1 Macro: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.92      0.98      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 88.57661890983582 s\n",
      "Averaged - Iteration 340: Accuracy: 0.9711, F1 Micro: 0.978, F1 Macro: 0.7564\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.358186721801758 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2435, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1803, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1498, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1285, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7803\n",
      "Epoch 6/10, Train Loss: 0.0751, Accuracy: 0.9647, F1 Micro: 0.9735, F1 Macro: 0.7451\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0494, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7818\n",
      "Epoch 8/10, Train Loss: 0.0448, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7799\n",
      "Epoch 9/10, Train Loss: 0.0327, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7759\n",
      "Epoch 10/10, Train Loss: 0.0256, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7762\n",
      "Model 1 - Iteration 350: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.92      0.98      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 91.01940679550171 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2573, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1793, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1438, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1141, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0908, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0709, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7781\n",
      "Epoch 7/10, Train Loss: 0.047, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.775\n",
      "Epoch 8/10, Train Loss: 0.0455, Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.7977\n",
      "Epoch 9/10, Train Loss: 0.0368, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7502\n",
      "Epoch 10/10, Train Loss: 0.0307, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7772\n",
      "Model 2 - Iteration 350: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.74      0.83      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 90.2455985546112 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2359, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1823, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1508, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.138, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1118, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 6/10, Train Loss: 0.0828, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7512\n",
      "Epoch 7/10, Train Loss: 0.0549, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7584\n",
      "Epoch 8/10, Train Loss: 0.0476, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7491\n",
      "Epoch 9/10, Train Loss: 0.0328, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.766\n",
      "Epoch 10/10, Train Loss: 0.0266, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7679\n",
      "Model 3 - Iteration 350: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 88.43825697898865 s\n",
      "Averaged - Iteration 350: Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.758\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.052086114883423 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2621, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.173, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.149, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1418, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.657\n",
      "Epoch 5/10, Train Loss: 0.1049, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0771, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.046, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0401, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0321, Accuracy: 0.9744, F1 Micro: 0.9803, F1 Macro: 0.7986\n",
      "Epoch 10/10, Train Loss: 0.0247, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7672\n",
      "Model 1 - Iteration 360: Accuracy: 0.9744, F1 Micro: 0.9803, F1 Macro: 0.7986\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.92      0.96      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.78      0.80       407\n",
      "weighted avg       0.97      0.98      0.98       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 94.93015885353088 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2821, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1701, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1473, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1214, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.8208\n",
      "Epoch 5/10, Train Loss: 0.0826, Accuracy: 0.9583, F1 Micro: 0.9678, F1 Macro: 0.7887\n",
      "Epoch 6/10, Train Loss: 0.0691, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7521\n",
      "Epoch 7/10, Train Loss: 0.043, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7511\n",
      "Epoch 8/10, Train Loss: 0.0386, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.768\n",
      "Epoch 9/10, Train Loss: 0.0352, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7576\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0261, Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.8236\n",
      "Model 2 - Iteration 360: Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.8236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      1.00      1.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.82      0.83      0.82       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 89.8531424999237 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2571, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1744, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1534, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1589, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Epoch 5/10, Train Loss: 0.1238, Accuracy: 0.9599, F1 Micro: 0.9689, F1 Macro: 0.7587\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0976, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7672\n",
      "Epoch 7/10, Train Loss: 0.0557, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7969\n",
      "Epoch 8/10, Train Loss: 0.0441, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7577\n",
      "Epoch 9/10, Train Loss: 0.0361, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7651\n",
      "Epoch 10/10, Train Loss: 0.0277, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7551\n",
      "Model 3 - Iteration 360: Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 89.92605566978455 s\n",
      "Averaged - Iteration 360: Accuracy: 0.9714, F1 Micro: 0.9782, F1 Macro: 0.7599\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.661146402359009 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2507, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1551, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.153, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1415, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.096, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7662\n",
      "Epoch 6/10, Train Loss: 0.0767, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0418, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0347, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "Epoch 9/10, Train Loss: 0.0305, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7577\n",
      "Epoch 10/10, Train Loss: 0.0209, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.8033\n",
      "Model 1 - Iteration 370: Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 96.04048585891724 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2663, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1565, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.142, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1179, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8041\n",
      "Epoch 5/10, Train Loss: 0.0814, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7402\n",
      "Epoch 6/10, Train Loss: 0.0741, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "Epoch 7/10, Train Loss: 0.0425, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7773\n",
      "Epoch 8/10, Train Loss: 0.0394, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.747\n",
      "Epoch 9/10, Train Loss: 0.0355, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7392\n",
      "Epoch 10/10, Train Loss: 0.0257, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7689\n",
      "Model 2 - Iteration 370: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8041\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 92.02618765830994 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2462, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1568, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1553, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1537, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.655\n",
      "Epoch 5/10, Train Loss: 0.111, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0815, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7642\n",
      "Epoch 7/10, Train Loss: 0.045, Accuracy: 0.9599, F1 Micro: 0.9693, F1 Macro: 0.7711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0362, Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7998\n",
      "Epoch 9/10, Train Loss: 0.0329, Accuracy: 0.9583, F1 Micro: 0.9682, F1 Macro: 0.8191\n",
      "Epoch 10/10, Train Loss: 0.0254, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.8447\n",
      "Model 3 - Iteration 370: Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7998\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 94.28480553627014 s\n",
      "Averaged - Iteration 370: Accuracy: 0.9715, F1 Micro: 0.9783, F1 Macro: 0.7618\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.3829565048217773 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2453, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1597, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1534, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1433, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Epoch 5/10, Train Loss: 0.1051, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0742, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7982\n",
      "Epoch 7/10, Train Loss: 0.0525, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7586\n",
      "Epoch 8/10, Train Loss: 0.0447, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.797\n",
      "Epoch 9/10, Train Loss: 0.0335, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Epoch 10/10, Train Loss: 0.0219, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7884\n",
      "Model 1 - Iteration 380: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7982\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 94.03680324554443 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2585, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.157, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 3/10, Train Loss: 0.146, Accuracy: 0.9583, F1 Micro: 0.9688, F1 Macro: 0.7298\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1214, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7594\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0992, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0714, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.799\n",
      "Epoch 7/10, Train Loss: 0.0559, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.766\n",
      "Epoch 8/10, Train Loss: 0.046, Accuracy: 0.9631, F1 Micro: 0.9723, F1 Macro: 0.7449\n",
      "Epoch 9/10, Train Loss: 0.0397, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7771\n",
      "Epoch 10/10, Train Loss: 0.0273, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.778\n",
      "Model 2 - Iteration 380: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 93.78420090675354 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2403, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.158, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1578, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1526, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.657\n",
      "Epoch 5/10, Train Loss: 0.1159, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.7747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0887, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7982\n",
      "Epoch 7/10, Train Loss: 0.0659, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7791\n",
      "Epoch 8/10, Train Loss: 0.0497, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7762\n",
      "Epoch 9/10, Train Loss: 0.0356, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.781\n",
      "Epoch 10/10, Train Loss: 0.0239, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.755\n",
      "Model 3 - Iteration 380: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7982\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 96.20684266090393 s\n",
      "Averaged - Iteration 380: Accuracy: 0.9716, F1 Micro: 0.9784, F1 Macro: 0.7635\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.7653868198394775 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2439, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1727, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1679, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1394, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.657\n",
      "Epoch 5/10, Train Loss: 0.1242, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0807, Accuracy: 0.9744, F1 Micro: 0.9806, F1 Macro: 0.7903\n",
      "Epoch 7/10, Train Loss: 0.059, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.042, Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.805\n",
      "Epoch 9/10, Train Loss: 0.0296, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7894\n",
      "Epoch 10/10, Train Loss: 0.0237, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "Model 1 - Iteration 390: Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.81       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 100.03678345680237 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2543, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1714, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1651, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1207, Accuracy: 0.9663, F1 Micro: 0.9747, F1 Macro: 0.7459\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0994, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7874\n",
      "Epoch 6/10, Train Loss: 0.062, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0577, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0396, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.768\n",
      "Epoch 9/10, Train Loss: 0.0296, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7491\n",
      "Epoch 10/10, Train Loss: 0.025, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7448\n",
      "Model 2 - Iteration 390: Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      1.00      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.73      0.83      0.77       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 101.19283604621887 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2371, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1723, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1733, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1393, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1216, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Epoch 6/10, Train Loss: 0.0806, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7662\n",
      "Epoch 7/10, Train Loss: 0.0561, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7661\n",
      "Epoch 8/10, Train Loss: 0.0408, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7586\n",
      "Epoch 9/10, Train Loss: 0.0355, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7651\n",
      "Epoch 10/10, Train Loss: 0.0241, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7585\n",
      "Model 3 - Iteration 390: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 97.69438123703003 s\n",
      "Averaged - Iteration 390: Accuracy: 0.9717, F1 Micro: 0.9785, F1 Macro: 0.7644\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.2755649089813232 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2466, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1606, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.146, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1389, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Epoch 5/10, Train Loss: 0.1046, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0717, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.8215\n",
      "Epoch 7/10, Train Loss: 0.0564, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7883\n",
      "Epoch 8/10, Train Loss: 0.046, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8197\n",
      "Epoch 9/10, Train Loss: 0.0264, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7586\n",
      "Epoch 10/10, Train Loss: 0.0285, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Model 1 - Iteration 400: Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.8215\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      1.00      1.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.96      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.83      0.82       407\n",
      "weighted avg       0.97      0.98      0.98       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 97.51931738853455 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.261, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1591, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1398, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1178, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7514\n",
      "Epoch 5/10, Train Loss: 0.0949, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7502\n",
      "Epoch 6/10, Train Loss: 0.0747, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7639\n",
      "Epoch 7/10, Train Loss: 0.067, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7502\n",
      "Epoch 8/10, Train Loss: 0.0501, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7513\n",
      "Epoch 9/10, Train Loss: 0.0285, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7501\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0297, Accuracy: 0.976, F1 Micro: 0.9816, F1 Macro: 0.7997\n",
      "Model 2 - Iteration 400: Accuracy: 0.976, F1 Micro: 0.9816, F1 Macro: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.92      0.98      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 96.80181694030762 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2432, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1619, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.147, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1379, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1078, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7227\n",
      "Epoch 6/10, Train Loss: 0.0708, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7759\n",
      "Epoch 7/10, Train Loss: 0.0592, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7651\n",
      "Epoch 8/10, Train Loss: 0.0477, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.762\n",
      "Epoch 9/10, Train Loss: 0.0267, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7752\n",
      "Epoch 10/10, Train Loss: 0.0266, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.765\n",
      "Model 3 - Iteration 400: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7227\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.71      0.72       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 97.0147979259491 s\n",
      "Averaged - Iteration 400: Accuracy: 0.9718, F1 Micro: 0.9785, F1 Macro: 0.7651\n",
      "Total sampling time: 159.1 seconds\n",
      "Total runtime: 5879.289548397064 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfea240c",
   "metadata": {
    "papermill": {
     "duration": 0.151242,
     "end_time": "2025-03-14T14:46:09.915273",
     "exception": false,
     "start_time": "2025-03-14T14:46:09.764031",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79964f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 4\n",
      "Random seed: [3, 44, 85]\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5173, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3418, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2503, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1975, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2158, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1534, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1996, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1359, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1391, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1488, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 1 - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 38.724520683288574 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5685, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3582, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2587, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.197, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2159, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1493, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1968, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1304, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1332, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1498, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 2 - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 37.948076009750366 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5199, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3337, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2346, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1857, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2179, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1455, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1975, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1299, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1306, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1448, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 3 - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 38.67901968955994 s\n",
      "Averaged - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 38\n",
      "Sampling duration: 12.582094192504883 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4231, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2507, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2084, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1895, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1885, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1909, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1718, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1656, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1558, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1304, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 1 - Iteration 63: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 44.68383073806763 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4652, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2628, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2134, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1901, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.196, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1894, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1653, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1587, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1509, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 10/10, Train Loss: 0.1245, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.6529\n",
      "Model 2 - Iteration 63: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 41.91070008277893 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4158, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2492, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2092, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1853, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.192, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1864, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1615, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1622, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1453, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 10/10, Train Loss: 0.1249, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.6528\n",
      "Model 3 - Iteration 63: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 42.88215708732605 s\n",
      "Averaged - Iteration 63: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 34\n",
      "Sampling duration: 13.006588459014893 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3612, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2331, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2012, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1907, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1463, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.16, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1447, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 8/10, Train Loss: 0.1273, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.6528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0967, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6537\n",
      "Epoch 10/10, Train Loss: 0.0858, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.6514\n",
      "Model 1 - Iteration 97: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6537\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 48.316221714019775 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3972, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2369, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.199, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1858, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1446, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1574, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 7/10, Train Loss: 0.1402, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1274, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0982, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Epoch 10/10, Train Loss: 0.095, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.652\n",
      "Model 2 - Iteration 97: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.65      0.66      0.65       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 48.27297496795654 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3562, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2351, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1877, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1395, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 6/10, Train Loss: 0.1539, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.6528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1362, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Epoch 8/10, Train Loss: 0.1153, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Epoch 9/10, Train Loss: 0.0957, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0888, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Model 3 - Iteration 97: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.66      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 45.788498401641846 s\n",
      "Averaged - Iteration 97: Accuracy: 0.9642, F1 Micro: 0.9728, F1 Macro: 0.6535\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 31\n",
      "Sampling duration: 12.18937349319458 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3382, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2129, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.19, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1827, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1827, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1544, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 7/10, Train Loss: 0.1342, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.6518\n",
      "Epoch 8/10, Train Loss: 0.1301, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.6526\n",
      "Epoch 9/10, Train Loss: 0.1014, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.6528\n",
      "Epoch 10/10, Train Loss: 0.0859, Accuracy: 0.9551, F1 Micro: 0.9653, F1 Macro: 0.6469\n",
      "Model 1 - Iteration 128: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 47.927409648895264 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3681, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2169, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1875, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1838, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1817, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.147, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1293, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Epoch 8/10, Train Loss: 0.1242, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 9/10, Train Loss: 0.1113, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 10/10, Train Loss: 0.093, Accuracy: 0.9535, F1 Micro: 0.964, F1 Macro: 0.6459\n",
      "Model 2 - Iteration 128: Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.96      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       407\n",
      "   macro avg       0.65      0.66      0.65       407\n",
      "weighted avg       0.96      0.97      0.96       407\n",
      " samples avg       0.97      0.97      0.97       407\n",
      "\n",
      "Training completed in 49.37181830406189 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3324, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2137, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1906, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1809, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1748, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.149, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 7/10, Train Loss: 0.1249, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1036, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.656\n",
      "Epoch 9/10, Train Loss: 0.0945, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7219\n",
      "Epoch 10/10, Train Loss: 0.0803, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.654\n",
      "Model 3 - Iteration 128: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.65      0.66      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 49.57363510131836 s\n",
      "Averaged - Iteration 128: Accuracy: 0.9646, F1 Micro: 0.9731, F1 Macro: 0.6536\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 28\n",
      "Sampling duration: 11.201423168182373 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3253, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2279, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1873, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1975, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.175, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 6/10, Train Loss: 0.1471, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.651\n",
      "Epoch 7/10, Train Loss: 0.1409, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6525\n",
      "Epoch 8/10, Train Loss: 0.1071, Accuracy: 0.9583, F1 Micro: 0.9681, F1 Macro: 0.6496\n",
      "Epoch 9/10, Train Loss: 0.083, Accuracy: 0.9567, F1 Micro: 0.9667, F1 Macro: 0.6484\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0468, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7194\n",
      "Model 1 - Iteration 156: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      0.99      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.81      0.71      0.72       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.96      0.98      0.97       407\n",
      "\n",
      "Training completed in 55.23502492904663 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3428, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2272, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1897, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1941, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1688, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1372, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1399, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1035, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6553\n",
      "Epoch 9/10, Train Loss: 0.0962, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6544\n",
      "Epoch 10/10, Train Loss: 0.0668, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "Model 2 - Iteration 156: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.65      0.67      0.66       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.97      0.99      0.97       407\n",
      "\n",
      "Training completed in 58.26283574104309 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3262, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2277, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.186, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1921, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.169, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1279, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Epoch 7/10, Train Loss: 0.1262, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.094, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7116\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0788, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7394\n",
      "Epoch 10/10, Train Loss: 0.0442, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Model 3 - Iteration 156: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7394\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.50      0.50         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.73      0.75      0.74       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 58.276363134384155 s\n",
      "Averaged - Iteration 156: Accuracy: 0.965, F1 Micro: 0.9734, F1 Macro: 0.6638\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 25\n",
      "Sampling duration: 10.043607473373413 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2885, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2117, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1715, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1836, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1769, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1632, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 7/10, Train Loss: 0.1407, Accuracy: 0.9471, F1 Micro: 0.9588, F1 Macro: 0.6415\n",
      "Epoch 8/10, Train Loss: 0.0877, Accuracy: 0.9391, F1 Micro: 0.9523, F1 Macro: 0.6366\n",
      "Epoch 9/10, Train Loss: 0.0643, Accuracy: 0.9567, F1 Micro: 0.9676, F1 Macro: 0.7243\n",
      "Epoch 10/10, Train Loss: 0.055, Accuracy: 0.9567, F1 Micro: 0.9666, F1 Macro: 0.6482\n",
      "Model 1 - Iteration 181: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 58.72830581665039 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3087, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.212, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.172, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1868, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1742, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1591, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1442, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Epoch 8/10, Train Loss: 0.091, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.654\n",
      "Epoch 9/10, Train Loss: 0.0686, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0523, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7211\n",
      "Model 2 - Iteration 181: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7211\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.71      0.72       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 62.10861873626709 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2859, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.212, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1721, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1806, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1772, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1545, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1252, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.089, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7512\n",
      "Epoch 9/10, Train Loss: 0.0585, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7535\n",
      "Epoch 10/10, Train Loss: 0.0471, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7543\n",
      "Model 3 - Iteration 181: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7512\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.76      0.75      0.75       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 62.7069091796875 s\n",
      "Averaged - Iteration 181: Accuracy: 0.9654, F1 Micro: 0.9737, F1 Macro: 0.6713\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 22\n",
      "Sampling duration: 9.167821168899536 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2784, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1805, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1816, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1799, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1416, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1569, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1323, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0732, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7484\n",
      "Epoch 9/10, Train Loss: 0.0578, Accuracy: 0.9631, F1 Micro: 0.9722, F1 Macro: 0.7212\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0405, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7505\n",
      "Model 1 - Iteration 203: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.75      0.75       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 66.77823686599731 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2967, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1779, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1788, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1754, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1326, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 6/10, Train Loss: 0.1483, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.6523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1365, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "Epoch 8/10, Train Loss: 0.0761, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.736\n",
      "Epoch 9/10, Train Loss: 0.0644, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7362\n",
      "Epoch 10/10, Train Loss: 0.0385, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7193\n",
      "Model 2 - Iteration 203: Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.87      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.64      0.66      0.65       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 62.79947519302368 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.276, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1816, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.18, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1733, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1302, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Epoch 6/10, Train Loss: 0.1261, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7107\n",
      "Epoch 7/10, Train Loss: 0.1033, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7105\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0593, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7496\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0518, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7672\n",
      "Epoch 10/10, Train Loss: 0.0355, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Model 3 - Iteration 203: Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 63.75372648239136 s\n",
      "Averaged - Iteration 203: Accuracy: 0.9658, F1 Micro: 0.974, F1 Macro: 0.6788\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 20\n",
      "Sampling duration: 8.160532236099243 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.291, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1859, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1785, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1656, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1693, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1559, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1125, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7791\n",
      "Epoch 8/10, Train Loss: 0.0777, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7484\n",
      "Epoch 9/10, Train Loss: 0.0476, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7293\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0381, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7663\n",
      "Model 1 - Iteration 223: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.75      0.77       407\n",
      "weighted avg       0.97      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 69.61707091331482 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3072, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1869, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.177, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1597, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1652, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.139, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Epoch 7/10, Train Loss: 0.0938, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.7463\n",
      "Epoch 8/10, Train Loss: 0.0748, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.7177\n",
      "Epoch 9/10, Train Loss: 0.0428, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7484\n",
      "Epoch 10/10, Train Loss: 0.0407, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.7352\n",
      "Model 2 - Iteration 223: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.66      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 65.73921871185303 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2922, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1875, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1785, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1587, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1508, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Epoch 6/10, Train Loss: 0.1171, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7484\n",
      "Epoch 7/10, Train Loss: 0.0825, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.753\n",
      "Epoch 8/10, Train Loss: 0.0587, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7495\n",
      "Epoch 9/10, Train Loss: 0.0383, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.753\n",
      "Epoch 10/10, Train Loss: 0.0341, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.779\n",
      "Model 3 - Iteration 223: Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.67      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 65.24032831192017 s\n",
      "Averaged - Iteration 223: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6805\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 18\n",
      "Sampling duration: 7.509852170944214 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2802, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2015, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1915, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1952, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.168, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1297, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7375\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0911, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7623\n",
      "Epoch 8/10, Train Loss: 0.0691, Accuracy: 0.9567, F1 Micro: 0.9665, F1 Macro: 0.7134\n",
      "Epoch 9/10, Train Loss: 0.0402, Accuracy: 0.9631, F1 Micro: 0.9723, F1 Macro: 0.7496\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0311, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7461\n",
      "Model 1 - Iteration 241: Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7461\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.43      0.75      0.55         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       407\n",
      "   macro avg       0.72      0.79      0.75       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 73.99054861068726 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2945, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2019, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1899, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1841, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1507, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1205, Accuracy: 0.9567, F1 Micro: 0.9669, F1 Macro: 0.7115\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0854, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7653\n",
      "Epoch 8/10, Train Loss: 0.0739, Accuracy: 0.9615, F1 Micro: 0.9708, F1 Macro: 0.7365\n",
      "Epoch 9/10, Train Loss: 0.0397, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7494\n",
      "Epoch 10/10, Train Loss: 0.04, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7568\n",
      "Model 2 - Iteration 241: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7653\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.74      0.77       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 70.52134108543396 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2759, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1897, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1821, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1452, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7218\n",
      "Epoch 6/10, Train Loss: 0.1016, Accuracy: 0.9551, F1 Micro: 0.9661, F1 Macro: 0.7306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0807, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7791\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0578, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.781\n",
      "Epoch 9/10, Train Loss: 0.0347, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7791\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0304, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7672\n",
      "Model 3 - Iteration 241: Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 73.21397423744202 s\n",
      "Averaged - Iteration 241: Accuracy: 0.9666, F1 Micro: 0.9746, F1 Macro: 0.6893\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 9\n",
      "Sampling duration: 6.817776679992676 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.274, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1814, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1951, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1706, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1637, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1283, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7587\n",
      "Epoch 7/10, Train Loss: 0.0906, Accuracy: 0.9599, F1 Micro: 0.97, F1 Macro: 0.7338\n",
      "Epoch 8/10, Train Loss: 0.0617, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7952\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0424, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.796\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0354, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7962\n",
      "Model 1 - Iteration 250: Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7962\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 75.44921588897705 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2882, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1843, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1951, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.169, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1598, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Epoch 6/10, Train Loss: 0.1259, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.7179\n",
      "Epoch 7/10, Train Loss: 0.0946, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7523\n",
      "Epoch 8/10, Train Loss: 0.0651, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.7755\n",
      "Epoch 9/10, Train Loss: 0.0445, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0376, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7654\n",
      "Model 2 - Iteration 250: Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.75      0.77       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 71.58889818191528 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.274, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1824, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1932, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1579, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1231, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 6/10, Train Loss: 0.0976, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7939\n",
      "Epoch 7/10, Train Loss: 0.0727, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7469\n",
      "Epoch 8/10, Train Loss: 0.0577, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.755\n",
      "Epoch 9/10, Train Loss: 0.0352, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7662\n",
      "Epoch 10/10, Train Loss: 0.0322, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Model 3 - Iteration 250: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 69.54952573776245 s\n",
      "Averaged - Iteration 250: Accuracy: 0.967, F1 Micro: 0.9749, F1 Macro: 0.699\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 15\n",
      "Sampling duration: 6.419581413269043 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2668, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1876, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1731, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1689, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1473, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7498\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0966, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7655\n",
      "Epoch 7/10, Train Loss: 0.0747, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7551\n",
      "Epoch 8/10, Train Loss: 0.0476, Accuracy: 0.9615, F1 Micro: 0.9712, F1 Macro: 0.7387\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0456, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8041\n",
      "Epoch 10/10, Train Loss: 0.0383, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7512\n",
      "Model 1 - Iteration 265: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8041\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 77.08939504623413 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2791, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1889, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1722, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1605, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1272, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7772\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0872, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7663\n",
      "Epoch 7/10, Train Loss: 0.0666, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7292\n",
      "Epoch 8/10, Train Loss: 0.0409, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.7184\n",
      "Epoch 9/10, Train Loss: 0.0426, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7393\n",
      "Epoch 10/10, Train Loss: 0.0341, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7299\n",
      "Model 2 - Iteration 265: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.75      0.77       407\n",
      "weighted avg       0.97      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 75.51829242706299 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2684, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.19, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1698, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1596, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7228\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1217, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Epoch 6/10, Train Loss: 0.0786, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7471\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0658, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "Epoch 8/10, Train Loss: 0.0413, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.04, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7812\n",
      "Epoch 10/10, Train Loss: 0.0332, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7493\n",
      "Model 3 - Iteration 265: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 76.45475482940674 s\n",
      "Averaged - Iteration 265: Accuracy: 0.9675, F1 Micro: 0.9753, F1 Macro: 0.7067\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 14\n",
      "Sampling duration: 5.940645694732666 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2733, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2013, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2039, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1711, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1569, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7648\n",
      "Epoch 6/10, Train Loss: 0.1121, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7623\n",
      "Epoch 7/10, Train Loss: 0.0824, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7633\n",
      "Epoch 8/10, Train Loss: 0.057, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0431, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.798\n",
      "Epoch 10/10, Train Loss: 0.0289, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7494\n",
      "Model 1 - Iteration 279: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 75.62777614593506 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2877, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2007, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1628, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 5/10, Train Loss: 0.1451, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.72\n",
      "Epoch 6/10, Train Loss: 0.1114, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7773\n",
      "Epoch 7/10, Train Loss: 0.0703, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0581, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0454, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7661\n",
      "Epoch 10/10, Train Loss: 0.0317, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7376\n",
      "Model 2 - Iteration 279: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7661\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.74      0.77       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 75.86758422851562 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2715, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2004, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.199, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1547, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7219\n",
      "Epoch 5/10, Train Loss: 0.1183, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7952\n",
      "Epoch 6/10, Train Loss: 0.0918, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0611, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.047, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7971\n",
      "Epoch 9/10, Train Loss: 0.0388, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7541\n",
      "Epoch 10/10, Train Loss: 0.0283, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.754\n",
      "Model 3 - Iteration 279: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7971\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 75.88046526908875 s\n",
      "Averaged - Iteration 279: Accuracy: 0.9678, F1 Micro: 0.9755, F1 Macro: 0.7134\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 13\n",
      "Sampling duration: 5.48318886756897 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2574, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1715, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.181, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1535, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7196\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1183, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0865, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8218\n",
      "Epoch 7/10, Train Loss: 0.0709, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7662\n",
      "Epoch 8/10, Train Loss: 0.0416, Accuracy: 0.9567, F1 Micro: 0.9664, F1 Macro: 0.7565\n",
      "Epoch 9/10, Train Loss: 0.0328, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7642\n",
      "Epoch 10/10, Train Loss: 0.029, Accuracy: 0.9615, F1 Micro: 0.9706, F1 Macro: 0.762\n",
      "Model 1 - Iteration 292: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8218\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      1.00      1.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.83      0.82       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 80.7465648651123 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2724, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1721, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1783, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1565, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1197, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.768\n",
      "Epoch 6/10, Train Loss: 0.0789, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.796\n",
      "Epoch 7/10, Train Loss: 0.0668, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "Epoch 8/10, Train Loss: 0.0425, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7798\n",
      "Epoch 9/10, Train Loss: 0.0334, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 10/10, Train Loss: 0.0327, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Model 2 - Iteration 292: Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.75      0.77       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 78.23572540283203 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2589, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1731, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1724, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1425, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.799\n",
      "Epoch 5/10, Train Loss: 0.1017, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.7917\n",
      "Epoch 6/10, Train Loss: 0.0707, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7585\n",
      "Epoch 7/10, Train Loss: 0.0626, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Epoch 8/10, Train Loss: 0.0401, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7752\n",
      "Epoch 9/10, Train Loss: 0.0305, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7759\n",
      "Epoch 10/10, Train Loss: 0.0312, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7791\n",
      "Model 3 - Iteration 292: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 76.85549187660217 s\n",
      "Averaged - Iteration 292: Accuracy: 0.9683, F1 Micro: 0.9759, F1 Macro: 0.7198\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 8\n",
      "Sampling duration: 4.937946796417236 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2765, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1723, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1825, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1717, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 5/10, Train Loss: 0.1425, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.7361\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1072, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 7/10, Train Loss: 0.0803, Accuracy: 0.9583, F1 Micro: 0.9688, F1 Macro: 0.7472\n",
      "Epoch 8/10, Train Loss: 0.0545, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7663\n",
      "Epoch 9/10, Train Loss: 0.0456, Accuracy: 0.9567, F1 Micro: 0.9671, F1 Macro: 0.7454\n",
      "Epoch 10/10, Train Loss: 0.0275, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7578\n",
      "Model 1 - Iteration 300: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 78.6287248134613 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2846, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1715, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1826, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1636, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1274, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.781\n",
      "Epoch 6/10, Train Loss: 0.1002, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0726, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "Epoch 8/10, Train Loss: 0.0419, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7801\n",
      "Epoch 9/10, Train Loss: 0.0423, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7875\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0288, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "Model 2 - Iteration 300: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 81.83149075508118 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2746, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1738, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1824, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1655, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1244, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7812\n",
      "Epoch 6/10, Train Loss: 0.0995, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7969\n",
      "Epoch 7/10, Train Loss: 0.0705, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7553\n",
      "Epoch 8/10, Train Loss: 0.0472, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0426, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "Epoch 10/10, Train Loss: 0.0283, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7393\n",
      "Model 3 - Iteration 300: Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 80.94129967689514 s\n",
      "Averaged - Iteration 300: Accuracy: 0.9687, F1 Micro: 0.9762, F1 Macro: 0.7254\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.585392713546753 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2362, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2023, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1645, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1755, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1355, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0948, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0593, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7763\n",
      "Epoch 8/10, Train Loss: 0.0423, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7567\n",
      "Epoch 9/10, Train Loss: 0.0417, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7642\n",
      "Epoch 10/10, Train Loss: 0.0254, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7744\n",
      "Model 1 - Iteration 310: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.74      0.83      0.78       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 83.48200535774231 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2477, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2036, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1644, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1689, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1295, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 6/10, Train Loss: 0.0876, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7503\n",
      "Epoch 7/10, Train Loss: 0.0574, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.7917\n",
      "Epoch 8/10, Train Loss: 0.0408, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7672\n",
      "Epoch 9/10, Train Loss: 0.0407, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.8227\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0248, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.8347\n",
      "Model 2 - Iteration 310: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.8347\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.50      0.33      0.40         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.83      0.85      0.83       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 81.64126706123352 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2317, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.205, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1629, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1605, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Epoch 5/10, Train Loss: 0.1172, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.773\n",
      "Epoch 6/10, Train Loss: 0.0791, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.7335\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0563, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8042\n",
      "Epoch 8/10, Train Loss: 0.0408, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7661\n",
      "Epoch 9/10, Train Loss: 0.0402, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7651\n",
      "Epoch 10/10, Train Loss: 0.0226, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7989\n",
      "Model 3 - Iteration 310: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8042\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 80.04028129577637 s\n",
      "Averaged - Iteration 310: Accuracy: 0.9689, F1 Micro: 0.9764, F1 Macro: 0.7307\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.132565021514893 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2608, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.175, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1801, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.166, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.764\n",
      "Epoch 5/10, Train Loss: 0.1394, Accuracy: 0.9631, F1 Micro: 0.9723, F1 Macro: 0.7529\n",
      "Epoch 6/10, Train Loss: 0.0955, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0622, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0529, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7773\n",
      "Epoch 9/10, Train Loss: 0.0362, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7394\n",
      "Epoch 10/10, Train Loss: 0.0314, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7875\n",
      "Model 1 - Iteration 320: Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.74      0.83      0.78       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 83.09561729431152 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2677, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1756, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1803, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1644, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Epoch 5/10, Train Loss: 0.1437, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 6/10, Train Loss: 0.0902, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0607, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0543, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8042\n",
      "Epoch 9/10, Train Loss: 0.0359, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "Epoch 10/10, Train Loss: 0.0342, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "Model 2 - Iteration 320: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8042\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 83.06883215904236 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.255, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1749, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1759, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1398, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1078, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0727, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7791\n",
      "Epoch 7/10, Train Loss: 0.0479, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7643\n",
      "Epoch 8/10, Train Loss: 0.0437, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7576\n",
      "Epoch 9/10, Train Loss: 0.0308, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.753\n",
      "Epoch 10/10, Train Loss: 0.03, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7439\n",
      "Model 3 - Iteration 320: Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 82.7720136642456 s\n",
      "Averaged - Iteration 320: Accuracy: 0.9691, F1 Micro: 0.9765, F1 Macro: 0.7342\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.821641683578491 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2513, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1954, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1551, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1482, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1261, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7738\n",
      "Epoch 6/10, Train Loss: 0.1023, Accuracy: 0.9535, F1 Micro: 0.9647, F1 Macro: 0.7293\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0618, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7632\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0371, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0302, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.8031\n",
      "Epoch 10/10, Train Loss: 0.0229, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8197\n",
      "Model 1 - Iteration 330: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.8031\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 89.33149695396423 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.263, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1951, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1502, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1456, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1175, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7894\n",
      "Epoch 6/10, Train Loss: 0.0827, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7672\n",
      "Epoch 7/10, Train Loss: 0.0628, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7649\n",
      "Epoch 8/10, Train Loss: 0.04, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "Epoch 9/10, Train Loss: 0.0309, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "Epoch 10/10, Train Loss: 0.0258, Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.7977\n",
      "Model 2 - Iteration 330: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 84.13908767700195 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2507, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1977, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1505, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1329, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 5/10, Train Loss: 0.1022, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7773\n",
      "Epoch 6/10, Train Loss: 0.0767, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.775\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0583, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7672\n",
      "Epoch 8/10, Train Loss: 0.0367, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0273, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0222, Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.8227\n",
      "Model 3 - Iteration 330: Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.8227\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      1.00      1.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.83      0.82       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 87.39878606796265 s\n",
      "Averaged - Iteration 330: Accuracy: 0.9694, F1 Micro: 0.9767, F1 Macro: 0.7384\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.457153797149658 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2518, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1902, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1622, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1574, Accuracy: 0.9599, F1 Micro: 0.97, F1 Macro: 0.7481\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1267, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7787\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0817, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0592, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7662\n",
      "Epoch 8/10, Train Loss: 0.0395, Accuracy: 0.9583, F1 Micro: 0.9681, F1 Macro: 0.7492\n",
      "Epoch 9/10, Train Loss: 0.0348, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7951\n",
      "Epoch 10/10, Train Loss: 0.0278, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7513\n",
      "Model 1 - Iteration 340: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7662\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 87.99012017250061 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2632, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1888, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1602, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1531, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7664\n",
      "Epoch 5/10, Train Loss: 0.1188, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7219\n",
      "Epoch 6/10, Train Loss: 0.0766, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7789\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0606, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "Epoch 8/10, Train Loss: 0.0428, Accuracy: 0.9712, F1 Micro: 0.9778, F1 Macro: 0.7966\n",
      "Epoch 9/10, Train Loss: 0.0366, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7789\n",
      "Epoch 10/10, Train Loss: 0.0278, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7884\n",
      "Model 2 - Iteration 340: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 87.98023796081543 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2522, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1896, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1589, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1374, Accuracy: 0.976, F1 Micro: 0.9818, F1 Macro: 0.8051\n",
      "Epoch 5/10, Train Loss: 0.1072, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.782\n",
      "Epoch 6/10, Train Loss: 0.0685, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7949\n",
      "Epoch 7/10, Train Loss: 0.0539, Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.8227\n",
      "Epoch 8/10, Train Loss: 0.0348, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8042\n",
      "Epoch 9/10, Train Loss: 0.0351, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 10/10, Train Loss: 0.0274, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8041\n",
      "Model 3 - Iteration 340: Accuracy: 0.976, F1 Micro: 0.9818, F1 Macro: 0.8051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      1.00      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.81       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 85.22788739204407 s\n",
      "Averaged - Iteration 340: Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7412\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.1528265476226807 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2468, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1725, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1701, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1616, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1246, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 6/10, Train Loss: 0.0905, Accuracy: 0.9631, F1 Micro: 0.9723, F1 Macro: 0.7451\n",
      "Epoch 7/10, Train Loss: 0.06, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7763\n",
      "Epoch 8/10, Train Loss: 0.0337, Accuracy: 0.9631, F1 Micro: 0.9719, F1 Macro: 0.7845\n",
      "Epoch 9/10, Train Loss: 0.0254, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7632\n",
      "Epoch 10/10, Train Loss: 0.0255, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.853\n",
      "Model 1 - Iteration 350: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 88.52419948577881 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2563, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1719, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1647, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1486, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.118, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Epoch 6/10, Train Loss: 0.0799, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7755\n",
      "Epoch 7/10, Train Loss: 0.0556, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.755\n",
      "Epoch 8/10, Train Loss: 0.0329, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.763\n",
      "Epoch 9/10, Train Loss: 0.0296, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7752\n",
      "Epoch 10/10, Train Loss: 0.0276, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.8587\n",
      "Model 2 - Iteration 350: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 88.07141256332397 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2442, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1714, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1674, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1429, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7219\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1064, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0804, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0596, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7681\n",
      "Epoch 8/10, Train Loss: 0.0328, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7763\n",
      "Epoch 9/10, Train Loss: 0.0245, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7539\n",
      "Epoch 10/10, Train Loss: 0.0242, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7567\n",
      "Model 3 - Iteration 350: Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7681\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      1.00      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      1.00      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       407\n",
      "   macro avg       0.73      0.83      0.77       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 91.0504515171051 s\n",
      "Averaged - Iteration 350: Accuracy: 0.9697, F1 Micro: 0.9769, F1 Macro: 0.7437\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.768526792526245 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2387, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1692, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.165, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1409, Accuracy: 0.9535, F1 Micro: 0.9639, F1 Macro: 0.6456\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1265, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0815, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7969\n",
      "Epoch 7/10, Train Loss: 0.0532, Accuracy: 0.9615, F1 Micro: 0.971, F1 Macro: 0.744\n",
      "Epoch 8/10, Train Loss: 0.038, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.746\n",
      "Epoch 9/10, Train Loss: 0.0259, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7662\n",
      "Epoch 10/10, Train Loss: 0.0249, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7512\n",
      "Model 1 - Iteration 360: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7969\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.96      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.78      0.80       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 89.06431889533997 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2482, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1692, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1663, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1411, Accuracy: 0.9599, F1 Micro: 0.9689, F1 Macro: 0.6495\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1287, Accuracy: 0.9679, F1 Micro: 0.9753, F1 Macro: 0.7776\n",
      "Epoch 6/10, Train Loss: 0.0849, Accuracy: 0.9615, F1 Micro: 0.9705, F1 Macro: 0.7611\n",
      "Epoch 7/10, Train Loss: 0.058, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7751\n",
      "Epoch 8/10, Train Loss: 0.044, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0342, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7672\n",
      "Epoch 10/10, Train Loss: 0.0301, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7561\n",
      "Model 2 - Iteration 360: Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 89.38538408279419 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2368, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1685, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1629, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1343, Accuracy: 0.9535, F1 Micro: 0.9638, F1 Macro: 0.6454\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1173, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.7927\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0754, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.796\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0511, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7672\n",
      "Epoch 8/10, Train Loss: 0.0383, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7734\n",
      "Epoch 9/10, Train Loss: 0.0289, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7875\n",
      "Epoch 10/10, Train Loss: 0.0287, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7643\n",
      "Model 3 - Iteration 360: Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      1.00      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       407\n",
      "   macro avg       0.73      0.83      0.77       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 91.39674234390259 s\n",
      "Averaged - Iteration 360: Accuracy: 0.9697, F1 Micro: 0.977, F1 Macro: 0.7454\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.470200777053833 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2281, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.156, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1696, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1462, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7375\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1153, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Epoch 6/10, Train Loss: 0.0671, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.8197\n",
      "Epoch 7/10, Train Loss: 0.0444, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7577\n",
      "Epoch 8/10, Train Loss: 0.0388, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.7719\n",
      "Epoch 9/10, Train Loss: 0.0251, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7649\n",
      "Epoch 10/10, Train Loss: 0.0237, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.7494\n",
      "Model 1 - Iteration 370: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 92.90000033378601 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2383, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1569, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1682, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1339, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7212\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1081, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 6/10, Train Loss: 0.0711, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7939\n",
      "Epoch 7/10, Train Loss: 0.0533, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7894\n",
      "Epoch 8/10, Train Loss: 0.0423, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7769\n",
      "Epoch 9/10, Train Loss: 0.0333, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7769\n",
      "Epoch 10/10, Train Loss: 0.0319, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7632\n",
      "Model 2 - Iteration 370: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 92.76463890075684 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2251, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1564, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.166, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1229, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.782\n",
      "Epoch 5/10, Train Loss: 0.0941, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 6/10, Train Loss: 0.0589, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7959\n",
      "Epoch 7/10, Train Loss: 0.0464, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7596\n",
      "Epoch 8/10, Train Loss: 0.0397, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7653\n",
      "Epoch 9/10, Train Loss: 0.0263, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7653\n",
      "Epoch 10/10, Train Loss: 0.029, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7672\n",
      "Model 3 - Iteration 370: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      1.00      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 90.19117569923401 s\n",
      "Averaged - Iteration 370: Accuracy: 0.9699, F1 Micro: 0.9771, F1 Macro: 0.7476\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.188607931137085 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2214, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1629, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1586, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1527, Accuracy: 0.9567, F1 Micro: 0.9676, F1 Macro: 0.7243\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1113, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7887\n",
      "Epoch 6/10, Train Loss: 0.0786, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7791\n",
      "Epoch 7/10, Train Loss: 0.056, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7374\n",
      "Epoch 8/10, Train Loss: 0.0396, Accuracy: 0.9599, F1 Micro: 0.9698, F1 Macro: 0.7219\n",
      "Epoch 9/10, Train Loss: 0.0362, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.73\n",
      "Epoch 10/10, Train Loss: 0.0221, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.746\n",
      "Model 1 - Iteration 380: Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7887\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.96      0.99      0.98       407\n",
      "\n",
      "Training completed in 91.75020718574524 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2306, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1661, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1584, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1498, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.6522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1143, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0742, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "Epoch 7/10, Train Loss: 0.0553, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7556\n",
      "Epoch 8/10, Train Loss: 0.0382, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7551\n",
      "Epoch 9/10, Train Loss: 0.0343, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.7449\n",
      "Epoch 10/10, Train Loss: 0.0259, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Model 2 - Iteration 380: Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 93.60647058486938 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2197, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1648, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1526, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1342, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "Epoch 5/10, Train Loss: 0.0977, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7974\n",
      "Epoch 6/10, Train Loss: 0.0685, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Epoch 7/10, Train Loss: 0.0455, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7653\n",
      "Epoch 8/10, Train Loss: 0.0358, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7643\n",
      "Epoch 9/10, Train Loss: 0.0342, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0234, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7989\n",
      "Model 3 - Iteration 380: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 93.50700807571411 s\n",
      "Averaged - Iteration 380: Accuracy: 0.97, F1 Micro: 0.9772, F1 Macro: 0.7498\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.6322057247161865 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2304, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1798, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1577, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1265, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1144, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7662\n",
      "Epoch 6/10, Train Loss: 0.0654, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7992\n",
      "Epoch 7/10, Train Loss: 0.0492, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7654\n",
      "Epoch 8/10, Train Loss: 0.0274, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.832\n",
      "Epoch 9/10, Train Loss: 0.024, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7785\n",
      "Epoch 10/10, Train Loss: 0.0187, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7864\n",
      "Model 1 - Iteration 390: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7662\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 94.83971738815308 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.242, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1819, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1523, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Epoch 4/10, Train Loss: 0.1259, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1167, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 6/10, Train Loss: 0.0707, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.764\n",
      "Epoch 7/10, Train Loss: 0.0517, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.752\n",
      "Epoch 8/10, Train Loss: 0.0324, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7729\n",
      "Epoch 9/10, Train Loss: 0.0254, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 10/10, Train Loss: 0.0222, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.781\n",
      "Model 2 - Iteration 390: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 92.91418242454529 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2312, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1792, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1522, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1181, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.799\n",
      "Epoch 5/10, Train Loss: 0.1013, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7941\n",
      "Epoch 6/10, Train Loss: 0.0623, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.78\n",
      "Epoch 7/10, Train Loss: 0.047, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7763\n",
      "Epoch 8/10, Train Loss: 0.0286, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7763\n",
      "Epoch 9/10, Train Loss: 0.0238, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.801\n",
      "Epoch 10/10, Train Loss: 0.0199, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7763\n",
      "Model 3 - Iteration 390: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 92.52707648277283 s\n",
      "Averaged - Iteration 390: Accuracy: 0.9701, F1 Micro: 0.9773, F1 Macro: 0.7514\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.387807846069336 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2177, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1495, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1519, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1373, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.7097\n",
      "Epoch 5/10, Train Loss: 0.0887, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7196\n",
      "Epoch 6/10, Train Loss: 0.0829, Accuracy: 0.9631, F1 Micro: 0.9723, F1 Macro: 0.7496\n",
      "Epoch 7/10, Train Loss: 0.0442, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7566\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.031, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7867\n",
      "Epoch 9/10, Train Loss: 0.0254, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7646\n",
      "Epoch 10/10, Train Loss: 0.0191, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7857\n",
      "Model 1 - Iteration 400: Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.97      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.97       407\n",
      "\n",
      "Training completed in 96.04646396636963 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2294, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1516, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.147, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 4/10, Train Loss: 0.1314, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.7186\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0864, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 6/10, Train Loss: 0.0732, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7971\n",
      "Epoch 7/10, Train Loss: 0.0426, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7671\n",
      "Epoch 8/10, Train Loss: 0.0326, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.032, Accuracy: 0.976, F1 Micro: 0.9816, F1 Macro: 0.7539\n",
      "Epoch 10/10, Train Loss: 0.0247, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7977\n",
      "Model 2 - Iteration 400: Accuracy: 0.976, F1 Micro: 0.9816, F1 Macro: 0.7539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.93      0.99      0.96        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.76      0.75      0.75       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 95.91539740562439 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2158, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1508, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1419, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Epoch 4/10, Train Loss: 0.1155, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0654, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Epoch 6/10, Train Loss: 0.0598, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7375\n",
      "Epoch 7/10, Train Loss: 0.0369, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7875\n",
      "Epoch 8/10, Train Loss: 0.0282, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7651\n",
      "Epoch 9/10, Train Loss: 0.0271, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7773\n",
      "Epoch 10/10, Train Loss: 0.0213, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7752\n",
      "Model 3 - Iteration 400: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 94.35183811187744 s\n",
      "Averaged - Iteration 400: Accuracy: 0.9702, F1 Micro: 0.9774, F1 Macro: 0.7524\n",
      "Total sampling time: 143.06 seconds\n",
      "Total runtime: 5795.523910045624 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fcb1b7",
   "metadata": {
    "papermill": {
     "duration": 0.153155,
     "end_time": "2025-03-14T14:46:10.570872",
     "exception": false,
     "start_time": "2025-03-14T14:46:10.417717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1880c5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 5\n",
      "Random seed: [94, 21, 5]\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5721, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3554, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2554, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1954, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2173, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1465, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2033, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.128, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1336, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1486, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 1 - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 40.403403520584106 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5508, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3494, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2433, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1888, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2154, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1502, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.195, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1288, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1335, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.145, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 2 - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 41.417134523391724 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5872, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3649, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2613, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2079, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.226, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1624, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2171, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1384, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1439, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1661, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 3 - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 41.108956813812256 s\n",
      "Averaged - Iteration 25: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 38\n",
      "Sampling duration: 16.504886865615845 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4371, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2116, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1907, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1526, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1551, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1536, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1251, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1035, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1459, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0897, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 1 - Iteration 63: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 46.59791398048401 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4241, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2038, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1865, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1466, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1537, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1527, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1228, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.099, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.132, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0869, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 2 - Iteration 63: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 45.677438259124756 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.445, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2224, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2063, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1597, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1618, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.163, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1315, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1081, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.15, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0978, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Model 3 - Iteration 63: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.86      1.00      0.92        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.98      0.97       407\n",
      "   macro avg       0.64      0.67      0.65       407\n",
      "weighted avg       0.95      0.98      0.96       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 45.09849762916565 s\n",
      "Averaged - Iteration 63: Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 34\n",
      "Sampling duration: 14.27903151512146 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3837, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.235, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1905, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1726, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.179, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 6/10, Train Loss: 0.1351, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.6528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1503, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1373, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0814, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0939, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Model 1 - Iteration 97: Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.65      0.66      0.65       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 51.47653341293335 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3686, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.232, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1874, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1708, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1774, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1323, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1466, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.655\n",
      "Epoch 8/10, Train Loss: 0.1417, Accuracy: 0.9599, F1 Micro: 0.9691, F1 Macro: 0.65\n",
      "Epoch 9/10, Train Loss: 0.0758, Accuracy: 0.9455, F1 Micro: 0.9575, F1 Macro: 0.6404\n",
      "Epoch 10/10, Train Loss: 0.0857, Accuracy: 0.9519, F1 Micro: 0.9627, F1 Macro: 0.6448\n",
      "Model 2 - Iteration 97: Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.65      0.66      0.65       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.98      0.98      0.97       407\n",
      "\n",
      "Training completed in 49.28862762451172 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3952, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2467, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1965, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1757, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1826, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1377, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 7/10, Train Loss: 0.1619, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6519\n",
      "Epoch 8/10, Train Loss: 0.1609, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0929, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1178, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Model 3 - Iteration 97: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.65      0.66      0.65       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 48.35327124595642 s\n",
      "Averaged - Iteration 97: Accuracy: 0.9644, F1 Micro: 0.9729, F1 Macro: 0.6534\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 31\n",
      "Sampling duration: 12.880703449249268 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3689, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.191, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.172, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2027, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1636, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1659, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.108, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Epoch 8/10, Train Loss: 0.1166, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Epoch 9/10, Train Loss: 0.0969, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Epoch 10/10, Train Loss: 0.0772, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Model 1 - Iteration 128: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.66      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 50.95998167991638 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3582, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1876, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1718, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2057, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1631, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1619, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Epoch 7/10, Train Loss: 0.1135, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.653\n",
      "Epoch 8/10, Train Loss: 0.1126, Accuracy: 0.9583, F1 Micro: 0.9678, F1 Macro: 0.649\n",
      "Epoch 9/10, Train Loss: 0.0841, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.6522\n",
      "Epoch 10/10, Train Loss: 0.0763, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.6502\n",
      "Model 2 - Iteration 128: Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.66      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 49.75176644325256 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3749, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1979, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1774, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2085, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1658, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1631, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Epoch 7/10, Train Loss: 0.1217, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.6522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53d78d3f033642a88885431f65d22c19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 0.1192, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.6502\n",
      "Epoch 9/10, Train Loss: 0.0951, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.6512\n",
      "Epoch 10/10, Train Loss: 0.0897, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.652\n",
      "Model 3 - Iteration 128: Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.67      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 50.73548340797424 s\n",
      "Averaged - Iteration 128: Accuracy: 0.9655, F1 Micro: 0.9738, F1 Macro: 0.654\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 28\n",
      "Sampling duration: 11.352882862091064 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3474, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1982, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1759, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1836, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1566, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1473, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Epoch 7/10, Train Loss: 0.1181, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Epoch 8/10, Train Loss: 0.1005, Accuracy: 0.9599, F1 Micro: 0.9691, F1 Macro: 0.65\n",
      "Epoch 9/10, Train Loss: 0.0689, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.651\n",
      "Epoch 10/10, Train Loss: 0.062, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Model 1 - Iteration 156: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.66      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 56.00013065338135 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3424, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1976, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1732, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1851, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1563, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "Epoch 6/10, Train Loss: 0.141, Accuracy: 0.9615, F1 Micro: 0.9703, F1 Macro: 0.6509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1165, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Epoch 8/10, Train Loss: 0.0953, Accuracy: 0.9583, F1 Micro: 0.9677, F1 Macro: 0.6488\n",
      "Epoch 9/10, Train Loss: 0.0674, Accuracy: 0.9503, F1 Micro: 0.9613, F1 Macro: 0.6434\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0611, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Model 2 - Iteration 156: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.65      0.66      0.65       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 58.58651542663574 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3563, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2059, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1784, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1917, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1626, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1443, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Epoch 7/10, Train Loss: 0.1215, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Epoch 8/10, Train Loss: 0.1021, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.652\n",
      "Epoch 9/10, Train Loss: 0.0698, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.653\n",
      "Epoch 10/10, Train Loss: 0.065, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.654\n",
      "Model 3 - Iteration 156: Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.65      0.66      0.65       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 56.20792770385742 s\n",
      "Averaged - Iteration 156: Accuracy: 0.9659, F1 Micro: 0.974, F1 Macro: 0.6542\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 25\n",
      "Sampling duration: 10.377754926681519 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.307, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1854, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1564, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1584, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.17, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Epoch 6/10, Train Loss: 0.1251, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.6528\n",
      "Epoch 7/10, Train Loss: 0.1148, Accuracy: 0.9391, F1 Micro: 0.952, F1 Macro: 0.635\n",
      "Epoch 8/10, Train Loss: 0.1004, Accuracy: 0.9551, F1 Micro: 0.9653, F1 Macro: 0.6471\n",
      "Epoch 9/10, Train Loss: 0.0778, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Epoch 10/10, Train Loss: 0.0578, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Model 1 - Iteration 181: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.66      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 59.79255294799805 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3014, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1855, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1557, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1592, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1723, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Epoch 6/10, Train Loss: 0.1171, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Epoch 7/10, Train Loss: 0.1086, Accuracy: 0.9391, F1 Micro: 0.9521, F1 Macro: 0.6354\n",
      "Epoch 8/10, Train Loss: 0.1022, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7623\n",
      "Epoch 9/10, Train Loss: 0.0709, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0563, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Model 2 - Iteration 181: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.66      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 62.25899863243103 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3181, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1902, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1604, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.161, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1766, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1267, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Epoch 7/10, Train Loss: 0.1113, Accuracy: 0.9599, F1 Micro: 0.969, F1 Macro: 0.6499\n",
      "Epoch 8/10, Train Loss: 0.0908, Accuracy: 0.9583, F1 Micro: 0.9677, F1 Macro: 0.6486\n",
      "Epoch 9/10, Train Loss: 0.0733, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7086\n",
      "Epoch 10/10, Train Loss: 0.0576, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.6512\n",
      "Model 3 - Iteration 181: Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.67      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 61.18521213531494 s\n",
      "Averaged - Iteration 181: Accuracy: 0.9665, F1 Micro: 0.9745, F1 Macro: 0.6545\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 22\n",
      "Sampling duration: 9.377339124679565 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3024, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1563, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.17, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1547, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 5/10, Train Loss: 0.1664, Accuracy: 0.9599, F1 Micro: 0.969, F1 Macro: 0.6499\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.123, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1018, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Epoch 8/10, Train Loss: 0.0733, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Epoch 9/10, Train Loss: 0.0617, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.6512\n",
      "Epoch 10/10, Train Loss: 0.0422, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Model 1 - Iteration 203: Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.97       407\n",
      "   macro avg       0.65      0.66      0.65       407\n",
      "weighted avg       0.95      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 65.14908170700073 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2975, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1576, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.17, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1571, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 5/10, Train Loss: 0.1626, Accuracy: 0.9359, F1 Micro: 0.9495, F1 Macro: 0.6329\n",
      "Epoch 6/10, Train Loss: 0.1187, Accuracy: 0.9407, F1 Micro: 0.9533, F1 Macro: 0.6362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0986, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Epoch 8/10, Train Loss: 0.0737, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.6502\n",
      "Epoch 9/10, Train Loss: 0.0628, Accuracy: 0.9567, F1 Micro: 0.9665, F1 Macro: 0.648\n",
      "Epoch 10/10, Train Loss: 0.0421, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.6522\n",
      "Model 2 - Iteration 203: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.66      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 62.84398007392883 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3147, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1615, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1741, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1599, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1618, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.6539\n",
      "Epoch 6/10, Train Loss: 0.1248, Accuracy: 0.9631, F1 Micro: 0.9714, F1 Macro: 0.6516\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1095, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.657\n",
      "Epoch 8/10, Train Loss: 0.0809, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Epoch 9/10, Train Loss: 0.0686, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.6502\n",
      "Epoch 10/10, Train Loss: 0.0477, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.651\n",
      "Model 3 - Iteration 203: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      1.00      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.67      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 65.45336651802063 s\n",
      "Averaged - Iteration 203: Accuracy: 0.9669, F1 Micro: 0.9748, F1 Macro: 0.6547\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 20\n",
      "Sampling duration: 8.417540550231934 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2714, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1833, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1591, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1522, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Epoch 5/10, Train Loss: 0.1483, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.135, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0991, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Epoch 8/10, Train Loss: 0.0868, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6551\n",
      "Epoch 9/10, Train Loss: 0.0579, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.6512\n",
      "Epoch 10/10, Train Loss: 0.0427, Accuracy: 0.9599, F1 Micro: 0.9692, F1 Macro: 0.6502\n",
      "Model 1 - Iteration 223: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.66      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 66.88857865333557 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2684, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.182, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1605, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1567, Accuracy: 0.9631, F1 Micro: 0.972, F1 Macro: 0.6528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1466, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1384, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0937, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Epoch 8/10, Train Loss: 0.0806, Accuracy: 0.9551, F1 Micro: 0.9653, F1 Macro: 0.6471\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0555, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7208\n",
      "Epoch 10/10, Train Loss: 0.0378, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.7179\n",
      "Model 2 - Iteration 223: Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7208\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.97      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.81      0.70      0.72       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.97       407\n",
      "\n",
      "Training completed in 68.78159689903259 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2838, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1882, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1633, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.161, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1481, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1415, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Epoch 7/10, Train Loss: 0.1015, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Epoch 8/10, Train Loss: 0.0926, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7643\n",
      "Epoch 9/10, Train Loss: 0.06, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Epoch 10/10, Train Loss: 0.0375, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Model 3 - Iteration 223: Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.66      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.98      0.98       407\n",
      "\n",
      "Training completed in 67.73852896690369 s\n",
      "Averaged - Iteration 223: Accuracy: 0.9671, F1 Micro: 0.9749, F1 Macro: 0.6575\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 18\n",
      "Sampling duration: 7.708300352096558 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2846, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1854, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.163, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Epoch 4/10, Train Loss: 0.1565, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1279, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Epoch 6/10, Train Loss: 0.1066, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0697, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0464, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 9/10, Train Loss: 0.0315, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7671\n",
      "Epoch 10/10, Train Loss: 0.0305, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7459\n",
      "Model 1 - Iteration 241: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 72.50132870674133 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2781, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1859, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.167, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1606, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1254, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1041, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0641, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Epoch 8/10, Train Loss: 0.0501, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0334, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "Epoch 10/10, Train Loss: 0.0301, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7661\n",
      "Model 2 - Iteration 241: Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 77.04530048370361 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2918, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1935, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1692, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1689, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1449, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1225, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.657\n",
      "Epoch 7/10, Train Loss: 0.0857, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0602, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7236\n",
      "Epoch 9/10, Train Loss: 0.0453, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7502\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.034, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7236\n",
      "Model 3 - Iteration 241: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.25      0.40         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.71      0.72       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 77.4224922657013 s\n",
      "Averaged - Iteration 241: Accuracy: 0.9678, F1 Micro: 0.9754, F1 Macro: 0.6704\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Acquired samples: 9\n",
      "Sampling duration: 6.933287620544434 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2857, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1765, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1557, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.15, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Epoch 5/10, Train Loss: 0.142, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.6522\n",
      "Epoch 6/10, Train Loss: 0.1367, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Epoch 7/10, Train Loss: 0.077, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0544, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.8024\n",
      "Epoch 9/10, Train Loss: 0.0463, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7568\n",
      "Epoch 10/10, Train Loss: 0.0258, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7662\n",
      "Model 1 - Iteration 250: Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.8024\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.98      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.80       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 73.11342740058899 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2801, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1749, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1574, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1492, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1433, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1332, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7522\n",
      "Epoch 7/10, Train Loss: 0.0714, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.657\n",
      "Epoch 8/10, Train Loss: 0.054, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7236\n",
      "Epoch 9/10, Train Loss: 0.047, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.7177\n",
      "Epoch 10/10, Train Loss: 0.0275, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.7925\n",
      "Model 2 - Iteration 250: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7522\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      0.50      0.57         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      1.00      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.75      0.75       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 74.59084057807922 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2932, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1803, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1559, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1494, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Epoch 5/10, Train Loss: 0.137, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.653\n",
      "Epoch 6/10, Train Loss: 0.1338, Accuracy: 0.9631, F1 Micro: 0.9722, F1 Macro: 0.7321\n",
      "Epoch 7/10, Train Loss: 0.0775, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0577, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0529, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.768\n",
      "Epoch 10/10, Train Loss: 0.0304, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7948\n",
      "Model 3 - Iteration 250: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.60      0.75      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.75      0.79      0.77       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 75.2088713645935 s\n",
      "Averaged - Iteration 250: Accuracy: 0.9682, F1 Micro: 0.9758, F1 Macro: 0.6808\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 15\n",
      "Sampling duration: 6.471398115158081 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2611, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1802, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1641, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1459, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Epoch 5/10, Train Loss: 0.1144, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Epoch 6/10, Train Loss: 0.0865, Accuracy: 0.9599, F1 Micro: 0.969, F1 Macro: 0.6499\n",
      "Epoch 7/10, Train Loss: 0.0618, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7745\n",
      "Epoch 8/10, Train Loss: 0.0455, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0355, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7763\n",
      "Epoch 10/10, Train Loss: 0.0269, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7723\n",
      "Model 1 - Iteration 265: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.74      0.83      0.78       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 75.66038656234741 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2514, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1785, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1672, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1425, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Epoch 5/10, Train Loss: 0.1056, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0827, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0676, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Epoch 8/10, Train Loss: 0.0441, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7623\n",
      "Epoch 9/10, Train Loss: 0.0376, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7929\n",
      "Epoch 10/10, Train Loss: 0.0288, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7773\n",
      "Model 2 - Iteration 265: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 77.21620678901672 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.269, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1842, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1687, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1518, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Epoch 5/10, Train Loss: 0.114, Accuracy: 0.9663, F1 Micro: 0.9743, F1 Macro: 0.6543\n",
      "Epoch 6/10, Train Loss: 0.0913, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.765\n",
      "Epoch 7/10, Train Loss: 0.0716, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0517, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 9/10, Train Loss: 0.0444, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Epoch 10/10, Train Loss: 0.0306, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.796\n",
      "Model 3 - Iteration 265: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 75.70990014076233 s\n",
      "Averaged - Iteration 265: Accuracy: 0.9685, F1 Micro: 0.976, F1 Macro: 0.6903\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 14\n",
      "Sampling duration: 6.0340330600738525 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2694, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1929, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1674, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1297, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 5/10, Train Loss: 0.1258, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.6529\n",
      "Epoch 6/10, Train Loss: 0.0875, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.653\n",
      "Epoch 7/10, Train Loss: 0.053, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7187\n",
      "Epoch 8/10, Train Loss: 0.0496, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7636\n",
      "Epoch 9/10, Train Loss: 0.0318, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0297, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7577\n",
      "Model 1 - Iteration 279: Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.44      1.00      0.62         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       407\n",
      "   macro avg       0.72      0.83      0.76       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.96      0.99      0.97       407\n",
      "\n",
      "Training completed in 76.75678443908691 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.267, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1919, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1718, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1326, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.126, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.653\n",
      "Epoch 6/10, Train Loss: 0.0884, Accuracy: 0.9599, F1 Micro: 0.969, F1 Macro: 0.7155\n",
      "Epoch 7/10, Train Loss: 0.0552, Accuracy: 0.9567, F1 Micro: 0.9665, F1 Macro: 0.7874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0528, Accuracy: 0.9663, F1 Micro: 0.9741, F1 Macro: 0.7937\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0371, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.7958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0339, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.657\n",
      "Model 2 - Iteration 279: Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      1.00      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       407\n",
      "   macro avg       0.65      0.67      0.66       407\n",
      "weighted avg       0.96      0.98      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 82.28004574775696 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2743, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1974, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1718, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1432, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Epoch 5/10, Train Loss: 0.1432, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.654\n",
      "Epoch 6/10, Train Loss: 0.1089, Accuracy: 0.9615, F1 Micro: 0.9701, F1 Macro: 0.6505\n",
      "Epoch 7/10, Train Loss: 0.0648, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7643\n",
      "Epoch 8/10, Train Loss: 0.064, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0434, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0399, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7969\n",
      "Model 3 - Iteration 279: Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7969\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.96      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.78      0.80       407\n",
      "weighted avg       0.97      0.98      0.97       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 78.14420294761658 s\n",
      "Averaged - Iteration 279: Accuracy: 0.9686, F1 Micro: 0.9761, F1 Macro: 0.6942\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 13\n",
      "Sampling duration: 5.519036054611206 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2705, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1717, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1571, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1591, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1212, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0866, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7383\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0579, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 8/10, Train Loss: 0.0456, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.753\n",
      "Epoch 9/10, Train Loss: 0.0357, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7623\n",
      "Epoch 10/10, Train Loss: 0.0309, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.7623\n",
      "Model 1 - Iteration 292: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 84.27032947540283 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2692, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1732, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1588, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1609, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Epoch 5/10, Train Loss: 0.1175, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0817, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0585, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7561\n",
      "Epoch 8/10, Train Loss: 0.0503, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7653\n",
      "Epoch 9/10, Train Loss: 0.0405, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7449\n",
      "Epoch 10/10, Train Loss: 0.0346, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7782\n",
      "Model 2 - Iteration 292: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7561\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.50      0.75      0.60         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.73      0.79      0.76       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 82.96499061584473 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2785, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1766, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.161, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1614, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1243, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0886, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7502\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0581, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7893\n",
      "Epoch 8/10, Train Loss: 0.0487, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.768\n",
      "Epoch 9/10, Train Loss: 0.0442, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7671\n",
      "Epoch 10/10, Train Loss: 0.038, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7679\n",
      "Model 3 - Iteration 292: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7893\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 84.63390135765076 s\n",
      "Averaged - Iteration 292: Accuracy: 0.9689, F1 Micro: 0.9763, F1 Macro: 0.7009\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Acquired samples: 8\n",
      "Sampling duration: 5.128926515579224 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2575, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1752, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1792, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1641, Accuracy: 0.9567, F1 Micro: 0.9664, F1 Macro: 0.6476\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1218, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0923, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 7/10, Train Loss: 0.0578, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7949\n",
      "Epoch 8/10, Train Loss: 0.0347, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7654\n",
      "Epoch 9/10, Train Loss: 0.0356, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7218\n",
      "Epoch 10/10, Train Loss: 0.0233, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7662\n",
      "Model 1 - Iteration 300: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 81.25935769081116 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2562, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1752, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1791, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1547, Accuracy: 0.9631, F1 Micro: 0.9716, F1 Macro: 0.6519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1097, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0834, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7819\n",
      "Epoch 7/10, Train Loss: 0.054, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.78\n",
      "Epoch 8/10, Train Loss: 0.0396, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7662\n",
      "Epoch 9/10, Train Loss: 0.0394, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7661\n",
      "Epoch 10/10, Train Loss: 0.0229, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7672\n",
      "Model 2 - Iteration 300: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7819\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 83.90119290351868 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2691, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1791, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1804, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1663, Accuracy: 0.9615, F1 Micro: 0.9702, F1 Macro: 0.6507\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1258, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1053, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7226\n",
      "Epoch 7/10, Train Loss: 0.0675, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0436, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0412, Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.7977\n",
      "Epoch 10/10, Train Loss: 0.0249, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7671\n",
      "Model 3 - Iteration 300: Accuracy: 0.9728, F1 Micro: 0.9791, F1 Macro: 0.7977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.96      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.78      0.80       407\n",
      "weighted avg       0.97      0.98      0.98       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 85.64742279052734 s\n",
      "Averaged - Iteration 300: Accuracy: 0.9692, F1 Micro: 0.9765, F1 Macro: 0.7074\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.843979358673096 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2479, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1899, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1673, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1612, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Epoch 5/10, Train Loss: 0.1033, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Epoch 6/10, Train Loss: 0.0794, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7577\n",
      "Epoch 7/10, Train Loss: 0.0556, Accuracy: 0.9599, F1 Micro: 0.9697, F1 Macro: 0.7421\n",
      "Epoch 8/10, Train Loss: 0.0429, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7578\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0249, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7763\n",
      "Epoch 10/10, Train Loss: 0.0235, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7577\n",
      "Model 1 - Iteration 310: Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.74      0.83      0.78       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 83.09195685386658 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2423, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1891, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1696, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.164, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Epoch 5/10, Train Loss: 0.11, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Epoch 6/10, Train Loss: 0.0869, Accuracy: 0.9631, F1 Micro: 0.9722, F1 Macro: 0.744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0596, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8218\n",
      "Epoch 8/10, Train Loss: 0.0488, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 9/10, Train Loss: 0.0304, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0244, Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.8227\n",
      "Model 2 - Iteration 310: Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.8227\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      1.00      1.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.83      0.82       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 84.72635078430176 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2558, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.192, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1703, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1661, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1154, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.6558\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.091, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7892\n",
      "Epoch 7/10, Train Loss: 0.0625, Accuracy: 0.9679, F1 Micro: 0.9753, F1 Macro: 0.7997\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0495, Accuracy: 0.9776, F1 Micro: 0.9829, F1 Macro: 0.8236\n",
      "Epoch 9/10, Train Loss: 0.0306, Accuracy: 0.9679, F1 Micro: 0.9758, F1 Macro: 0.7586\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0294, Accuracy: 0.9776, F1 Micro: 0.9829, F1 Macro: 0.8236\n",
      "Model 3 - Iteration 310: Accuracy: 0.9776, F1 Micro: 0.9829, F1 Macro: 0.8236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      1.00      1.00         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.99      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.83      0.82       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 87.74639058113098 s\n",
      "Averaged - Iteration 310: Accuracy: 0.9695, F1 Micro: 0.9768, F1 Macro: 0.7141\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.292666673660278 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2486, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1756, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1766, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1468, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.6541\n",
      "Epoch 5/10, Train Loss: 0.1103, Accuracy: 0.9583, F1 Micro: 0.9681, F1 Macro: 0.749\n",
      "Epoch 6/10, Train Loss: 0.068, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7567\n",
      "Epoch 7/10, Train Loss: 0.0603, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0331, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Epoch 9/10, Train Loss: 0.0329, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0262, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Model 1 - Iteration 320: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 85.50640392303467 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2426, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1754, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1756, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1514, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Epoch 5/10, Train Loss: 0.1158, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.7187\n",
      "Epoch 6/10, Train Loss: 0.0734, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.778\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0593, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 8/10, Train Loss: 0.0331, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7884\n",
      "Epoch 9/10, Train Loss: 0.0345, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8207\n",
      "Epoch 10/10, Train Loss: 0.0256, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7662\n",
      "Model 2 - Iteration 320: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 84.0772294998169 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2564, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1785, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1774, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1518, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Epoch 5/10, Train Loss: 0.1273, Accuracy: 0.9583, F1 Micro: 0.9678, F1 Macro: 0.649\n",
      "Epoch 6/10, Train Loss: 0.0866, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0705, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Epoch 8/10, Train Loss: 0.0386, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.747\n",
      "Epoch 9/10, Train Loss: 0.0421, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7791\n",
      "Epoch 10/10, Train Loss: 0.0284, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Model 3 - Iteration 320: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 83.9038155078888 s\n",
      "Averaged - Iteration 320: Accuracy: 0.9698, F1 Micro: 0.977, F1 Macro: 0.719\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.020151853561401 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2407, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1685, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1512, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Epoch 4/10, Train Loss: 0.1275, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1082, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Epoch 6/10, Train Loss: 0.067, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7494\n",
      "Epoch 7/10, Train Loss: 0.0709, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7803\n",
      "Epoch 8/10, Train Loss: 0.0355, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7541\n",
      "Epoch 9/10, Train Loss: 0.0287, Accuracy: 0.9631, F1 Micro: 0.9722, F1 Macro: 0.7495\n",
      "Epoch 10/10, Train Loss: 0.025, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7577\n",
      "Model 1 - Iteration 330: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 85.68898248672485 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2342, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1677, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1543, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 4/10, Train Loss: 0.1305, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1062, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7673\n",
      "Epoch 6/10, Train Loss: 0.0655, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7671\n",
      "Epoch 7/10, Train Loss: 0.0673, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 8/10, Train Loss: 0.0341, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.781\n",
      "Epoch 9/10, Train Loss: 0.0258, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7763\n",
      "Epoch 10/10, Train Loss: 0.0201, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.781\n",
      "Model 2 - Iteration 330: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7673\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.75      0.77       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 85.9953191280365 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2469, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1703, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1554, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Epoch 4/10, Train Loss: 0.1313, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.6549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1179, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Epoch 6/10, Train Loss: 0.0748, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0754, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 8/10, Train Loss: 0.0409, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7959\n",
      "Epoch 9/10, Train Loss: 0.0315, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7561\n",
      "Epoch 10/10, Train Loss: 0.0246, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7801\n",
      "Model 3 - Iteration 330: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 87.05490970611572 s\n",
      "Averaged - Iteration 330: Accuracy: 0.9699, F1 Micro: 0.9771, F1 Macro: 0.7227\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.5814812183380127 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2439, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1696, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1529, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1404, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "Epoch 5/10, Train Loss: 0.0993, Accuracy: 0.9631, F1 Micro: 0.9718, F1 Macro: 0.763\n",
      "Epoch 6/10, Train Loss: 0.0763, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7875\n",
      "Epoch 7/10, Train Loss: 0.0559, Accuracy: 0.9631, F1 Micro: 0.9723, F1 Macro: 0.7441\n",
      "Epoch 8/10, Train Loss: 0.0396, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7778\n",
      "Epoch 9/10, Train Loss: 0.0289, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7875\n",
      "Epoch 10/10, Train Loss: 0.0288, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7438\n",
      "Model 1 - Iteration 340: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 86.90653204917908 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2389, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1687, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1555, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1497, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7673\n",
      "Epoch 5/10, Train Loss: 0.1097, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7951\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0876, Accuracy: 0.9744, F1 Micro: 0.9806, F1 Macro: 0.7903\n",
      "Epoch 7/10, Train Loss: 0.0614, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Epoch 8/10, Train Loss: 0.0449, Accuracy: 0.9583, F1 Micro: 0.9679, F1 Macro: 0.7046\n",
      "Epoch 9/10, Train Loss: 0.0273, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7672\n",
      "Epoch 10/10, Train Loss: 0.0317, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7949\n",
      "Model 2 - Iteration 340: Accuracy: 0.9744, F1 Micro: 0.9806, F1 Macro: 0.7903\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      1.00      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 88.59498047828674 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2505, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1735, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1549, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1535, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7218\n",
      "Epoch 5/10, Train Loss: 0.1146, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7651\n",
      "Epoch 6/10, Train Loss: 0.0879, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7503\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0664, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.78\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0456, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0284, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.781\n",
      "Epoch 10/10, Train Loss: 0.0323, Accuracy: 0.9647, F1 Micro: 0.9734, F1 Macro: 0.7448\n",
      "Model 3 - Iteration 340: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.77      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 92.54510021209717 s\n",
      "Averaged - Iteration 340: Accuracy: 0.9701, F1 Micro: 0.9772, F1 Macro: 0.7261\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.5583384037017822 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2487, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1604, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1399, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Epoch 4/10, Train Loss: 0.1488, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0975, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 6/10, Train Loss: 0.0784, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7494\n",
      "Epoch 7/10, Train Loss: 0.0507, Accuracy: 0.9647, F1 Micro: 0.9733, F1 Macro: 0.7535\n",
      "Epoch 8/10, Train Loss: 0.0407, Accuracy: 0.9679, F1 Micro: 0.9754, F1 Macro: 0.7949\n",
      "Epoch 9/10, Train Loss: 0.0349, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7763\n",
      "Epoch 10/10, Train Loss: 0.0243, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7875\n",
      "Model 1 - Iteration 350: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 88.64110684394836 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2447, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1617, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.141, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1486, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0978, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "Epoch 6/10, Train Loss: 0.0784, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.762\n",
      "Epoch 7/10, Train Loss: 0.0486, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.768\n",
      "Epoch 8/10, Train Loss: 0.0425, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7772\n",
      "Epoch 9/10, Train Loss: 0.036, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7672\n",
      "Epoch 10/10, Train Loss: 0.0208, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7978\n",
      "Model 2 - Iteration 350: Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 90.40447664260864 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2543, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1644, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1414, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1461, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0992, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "Epoch 6/10, Train Loss: 0.0806, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7584\n",
      "Epoch 7/10, Train Loss: 0.0547, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7459\n",
      "Epoch 8/10, Train Loss: 0.0499, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7969\n",
      "Epoch 9/10, Train Loss: 0.042, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.756\n",
      "Epoch 10/10, Train Loss: 0.0241, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7661\n",
      "Model 3 - Iteration 350: Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 90.8216073513031 s\n",
      "Averaged - Iteration 350: Accuracy: 0.9703, F1 Micro: 0.9774, F1 Macro: 0.7299\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.0615127086639404 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2425, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1657, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1582, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1279, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Epoch 5/10, Train Loss: 0.1076, Accuracy: 0.9583, F1 Micro: 0.9677, F1 Macro: 0.7578\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0693, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7672\n",
      "Epoch 7/10, Train Loss: 0.0516, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7643\n",
      "Epoch 8/10, Train Loss: 0.0388, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7883\n",
      "Epoch 9/10, Train Loss: 0.0277, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7578\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0189, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7773\n",
      "Model 1 - Iteration 360: Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.57      1.00      0.73         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.74      0.83      0.78       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 95.04280686378479 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2418, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1671, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1606, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1354, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1061, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7951\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0668, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0506, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0438, Accuracy: 0.9744, F1 Micro: 0.9806, F1 Macro: 0.8043\n",
      "Epoch 9/10, Train Loss: 0.03, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Epoch 10/10, Train Loss: 0.0208, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7989\n",
      "Model 2 - Iteration 360: Accuracy: 0.9744, F1 Micro: 0.9806, F1 Macro: 0.8043\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.80      1.00      0.89         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      1.00      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.78      0.83      0.80       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 97.37557029724121 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2518, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1691, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1605, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1343, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Epoch 5/10, Train Loss: 0.0985, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.7769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0747, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0515, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.781\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0451, Accuracy: 0.976, F1 Micro: 0.9816, F1 Macro: 0.7997\n",
      "Epoch 9/10, Train Loss: 0.033, Accuracy: 0.9712, F1 Micro: 0.9782, F1 Macro: 0.7773\n",
      "Epoch 10/10, Train Loss: 0.0274, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7828\n",
      "Model 3 - Iteration 360: Accuracy: 0.976, F1 Micro: 0.9816, F1 Macro: 0.7997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.92      0.98      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.82      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 95.43024277687073 s\n",
      "Averaged - Iteration 360: Accuracy: 0.9705, F1 Micro: 0.9775, F1 Macro: 0.7331\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.580832004547119 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2326, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1531, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1705, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.6553\n",
      "Epoch 4/10, Train Loss: 0.1387, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Epoch 5/10, Train Loss: 0.1171, Accuracy: 0.9647, F1 Micro: 0.9729, F1 Macro: 0.653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0727, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "Epoch 7/10, Train Loss: 0.0459, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7844\n",
      "Epoch 8/10, Train Loss: 0.0346, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7578\n",
      "Epoch 9/10, Train Loss: 0.0298, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.7533\n",
      "Epoch 10/10, Train Loss: 0.0236, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7541\n",
      "Model 1 - Iteration 370: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.89      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 93.03349733352661 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2312, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1538, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1702, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.6544\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1351, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7228\n",
      "Epoch 5/10, Train Loss: 0.1085, Accuracy: 0.9615, F1 Micro: 0.9704, F1 Macro: 0.651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0679, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 7/10, Train Loss: 0.0435, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.7969\n",
      "Epoch 8/10, Train Loss: 0.0349, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 9/10, Train Loss: 0.0345, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7978\n",
      "Epoch 10/10, Train Loss: 0.0276, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7772\n",
      "Model 2 - Iteration 370: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 94.71138548851013 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2388, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1581, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1748, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Epoch 4/10, Train Loss: 0.1397, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.6522\n",
      "Epoch 5/10, Train Loss: 0.1217, Accuracy: 0.9599, F1 Micro: 0.9689, F1 Macro: 0.6497\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.076, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7818\n",
      "Epoch 7/10, Train Loss: 0.0468, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7882\n",
      "Epoch 8/10, Train Loss: 0.0381, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.778\n",
      "Epoch 9/10, Train Loss: 0.0322, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.764\n",
      "Epoch 10/10, Train Loss: 0.0329, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7751\n",
      "Model 3 - Iteration 370: Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7818\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.75      0.75      0.75         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.92      0.98      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.78      0.79      0.78       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 92.6995484828949 s\n",
      "Averaged - Iteration 370: Accuracy: 0.9706, F1 Micro: 0.9776, F1 Macro: 0.736\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.166414260864258 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2551, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1705, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1538, Accuracy: 0.9647, F1 Micro: 0.9732, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1268, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7671\n",
      "Epoch 5/10, Train Loss: 0.0936, Accuracy: 0.9663, F1 Micro: 0.9746, F1 Macro: 0.7655\n",
      "Epoch 6/10, Train Loss: 0.0561, Accuracy: 0.9615, F1 Micro: 0.9707, F1 Macro: 0.7481\n",
      "Epoch 7/10, Train Loss: 0.0503, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7764\n",
      "Epoch 8/10, Train Loss: 0.0317, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7576\n",
      "Epoch 9/10, Train Loss: 0.0309, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7747\n",
      "Epoch 10/10, Train Loss: 0.022, Accuracy: 0.9631, F1 Micro: 0.9722, F1 Macro: 0.7495\n",
      "Model 1 - Iteration 380: Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.50      0.67         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.91      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       407\n",
      "   macro avg       0.82      0.75      0.77       407\n",
      "weighted avg       0.97      0.98      0.98       407\n",
      " samples avg       0.98      0.98      0.98       407\n",
      "\n",
      "Training completed in 94.13196539878845 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2522, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1722, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1601, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1402, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1064, Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7999\n",
      "Epoch 6/10, Train Loss: 0.0661, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.7871\n",
      "Epoch 7/10, Train Loss: 0.0564, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.7661\n",
      "Epoch 8/10, Train Loss: 0.0361, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.7566\n",
      "Epoch 9/10, Train Loss: 0.0323, Accuracy: 0.9696, F1 Micro: 0.977, F1 Macro: 0.7672\n",
      "Epoch 10/10, Train Loss: 0.0232, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7762\n",
      "Model 2 - Iteration 380: Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      1.00      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 96.70540070533752 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2615, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1746, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1616, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1416, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1106, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7894\n",
      "Epoch 6/10, Train Loss: 0.0655, Accuracy: 0.9647, F1 Micro: 0.9728, F1 Macro: 0.7525\n",
      "Epoch 7/10, Train Loss: 0.0563, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7411\n",
      "Epoch 8/10, Train Loss: 0.0381, Accuracy: 0.9647, F1 Micro: 0.9731, F1 Macro: 0.7539\n",
      "Epoch 9/10, Train Loss: 0.0382, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.7808\n",
      "Epoch 10/10, Train Loss: 0.028, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7671\n",
      "Model 3 - Iteration 380: Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 99.97478151321411 s\n",
      "Averaged - Iteration 380: Accuracy: 0.9708, F1 Micro: 0.9778, F1 Macro: 0.7382\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.8806781768798828 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2104, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1706, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.145, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1452, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1082, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7801\n",
      "Epoch 6/10, Train Loss: 0.0703, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7643\n",
      "Epoch 7/10, Train Loss: 0.0486, Accuracy: 0.9599, F1 Micro: 0.9695, F1 Macro: 0.7418\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0365, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7884\n",
      "Epoch 9/10, Train Loss: 0.0331, Accuracy: 0.9696, F1 Micro: 0.9769, F1 Macro: 0.7875\n",
      "Epoch 10/10, Train Loss: 0.0196, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7662\n",
      "Model 1 - Iteration 390: Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.98      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.96      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 98.98157691955566 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.205, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1701, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.145, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Epoch 4/10, Train Loss: 0.1425, Accuracy: 0.9631, F1 Micro: 0.9717, F1 Macro: 0.6522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1029, Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7999\n",
      "Epoch 6/10, Train Loss: 0.0651, Accuracy: 0.9663, F1 Micro: 0.9742, F1 Macro: 0.777\n",
      "Epoch 7/10, Train Loss: 0.047, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.7988\n",
      "Epoch 8/10, Train Loss: 0.0375, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7989\n",
      "Epoch 9/10, Train Loss: 0.0356, Accuracy: 0.9663, F1 Micro: 0.9744, F1 Macro: 0.7864\n",
      "Epoch 10/10, Train Loss: 0.0207, Accuracy: 0.9728, F1 Micro: 0.9793, F1 Macro: 0.7781\n",
      "Model 2 - Iteration 390: Accuracy: 0.976, F1 Micro: 0.9817, F1 Macro: 0.7999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      1.00      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 95.97002458572388 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2177, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1723, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1469, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1431, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.6532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1135, Accuracy: 0.9712, F1 Micro: 0.9779, F1 Macro: 0.6569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0784, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.803\n",
      "Epoch 7/10, Train Loss: 0.0531, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0388, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.8041\n",
      "Epoch 9/10, Train Loss: 0.0381, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0224, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7901\n",
      "Model 3 - Iteration 390: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7901\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.92      0.98      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 103.15895438194275 s\n",
      "Averaged - Iteration 390: Accuracy: 0.9709, F1 Micro: 0.9779, F1 Macro: 0.7406\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.4188885688781738 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2297, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1664, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1367, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1207, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0885, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7973\n",
      "Epoch 6/10, Train Loss: 0.0705, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7551\n",
      "Epoch 7/10, Train Loss: 0.0494, Accuracy: 0.9615, F1 Micro: 0.9709, F1 Macro: 0.7429\n",
      "Epoch 8/10, Train Loss: 0.0329, Accuracy: 0.9647, F1 Micro: 0.973, F1 Macro: 0.7087\n",
      "Epoch 9/10, Train Loss: 0.025, Accuracy: 0.9663, F1 Micro: 0.9745, F1 Macro: 0.7653\n",
      "Epoch 10/10, Train Loss: 0.0228, Accuracy: 0.9679, F1 Micro: 0.9757, F1 Macro: 0.7662\n",
      "Model 1 - Iteration 400: Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7973\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.88      0.99      0.93        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.96      0.99      0.97       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 98.96347832679749 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2273, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1667, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1388, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1229, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.6561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0903, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.7227\n",
      "Epoch 6/10, Train Loss: 0.067, Accuracy: 0.9696, F1 Micro: 0.9767, F1 Macro: 0.796\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0622, Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "Epoch 8/10, Train Loss: 0.0363, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.7951\n",
      "Epoch 9/10, Train Loss: 0.0267, Accuracy: 0.9728, F1 Micro: 0.9792, F1 Macro: 0.798\n",
      "Epoch 10/10, Train Loss: 0.0253, Accuracy: 0.9712, F1 Micro: 0.978, F1 Macro: 0.8023\n",
      "Model 2 - Iteration 400: Accuracy: 0.9744, F1 Micro: 0.9805, F1 Macro: 0.7989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       1.00      0.75      0.86         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.90      0.99      0.94        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.99      0.98       407\n",
      "   macro avg       0.81      0.79      0.80       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.97      0.99      0.98       407\n",
      "\n",
      "Training completed in 100.93117690086365 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.2383, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1688, Accuracy: 0.9631, F1 Micro: 0.9721, F1 Macro: 0.6529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1378, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1246, Accuracy: 0.9696, F1 Micro: 0.9768, F1 Macro: 0.6562\n",
      "Epoch 5/10, Train Loss: 0.0933, Accuracy: 0.9679, F1 Micro: 0.9755, F1 Macro: 0.6551\n",
      "Epoch 6/10, Train Loss: 0.071, Accuracy: 0.9679, F1 Micro: 0.9756, F1 Macro: 0.7751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0584, Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.79\n",
      "Epoch 8/10, Train Loss: 0.0371, Accuracy: 0.9696, F1 Micro: 0.9766, F1 Macro: 0.765\n",
      "Epoch 9/10, Train Loss: 0.0369, Accuracy: 0.9567, F1 Micro: 0.9674, F1 Macro: 0.7382\n",
      "Epoch 10/10, Train Loss: 0.0307, Accuracy: 0.9712, F1 Micro: 0.9781, F1 Macro: 0.7679\n",
      "Model 3 - Iteration 400: Accuracy: 0.9744, F1 Micro: 0.9804, F1 Macro: 0.79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       104\n",
      "        2-GI       0.67      1.00      0.80         4\n",
      "        3-PI       1.00      1.00      1.00       104\n",
      "        4-DM       0.92      0.97      0.95        89\n",
      "     5-EDTRB       0.99      1.00      1.00       103\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.98      0.99      0.98       407\n",
      "   macro avg       0.76      0.83      0.79       407\n",
      "weighted avg       0.97      0.99      0.98       407\n",
      " samples avg       0.98      0.99      0.98       407\n",
      "\n",
      "Training completed in 99.18401217460632 s\n",
      "Averaged - Iteration 400: Accuracy: 0.971, F1 Micro: 0.9779, F1 Macro: 0.7429\n",
      "Total sampling time: 152.39 seconds\n",
      "Total runtime: 6923.133186817169 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[4], 4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6862554,
     "sourceId": 11020795,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5856.739767,
   "end_time": "2025-03-14T14:46:14.472768",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-14T13:08:37.733001",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "053cce65ccc049bb93306c2864d80ac7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "075d4630758b45cfaf9ac70c91d35853": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "07b77bf09e3b46dca7f6aacec54aab80": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ef8a4f40da5a48149f20719a2f02b378",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_68cf192877354277a562ad8cfa4c1a5f",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json:â€‡100%"
      }
     },
     "0872c20e558845d69d64419bc7e37b7d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0aac7d77baab4ae59633d2d047fe636c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0e96547914754250bc1d830b05a82b0e",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_3eb492739b4e44789b45be431ac308fe",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json:â€‡100%"
      }
     },
     "0e96547914754250bc1d830b05a82b0e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "118f41095d9b4c99a90b5f88ba42d405": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "18bf93e7f8e94dd596cc0d9fba38d2ab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ae49db7729734b10a9a7b049fa17dba1",
       "max": 1534,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f62c05469b5541e0990e03f920217c91",
       "tabbable": null,
       "tooltip": null,
       "value": 1534
      }
     },
     "2685d5122d174839a9fb98514aac0837": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3730966d24114f4fbfa7517ff776028d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3eb2ac49116b44e9a6c44d7c6473b2a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3eb492739b4e44789b45be431ac308fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4157c0f25d2943688de579667a4812d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_075d4630758b45cfaf9ac70c91d35853",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_118f41095d9b4c99a90b5f88ba42d405",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡112/112â€‡[00:00&lt;00:00,â€‡12.6kB/s]"
      }
     },
     "48bc78e8f58741e895a855aeadb49ecb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "53aa3e38e1a34e739cf947046795e57d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_053cce65ccc049bb93306c2864d80ac7",
       "max": 112,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_63ccd05cbf614148a90b2d64f1ba9a51",
       "tabbable": null,
       "tooltip": null,
       "value": 112
      }
     },
     "5569bef99e984cd4bbf47be7ff36b61e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5829f9545f8747e7aafbfdb30191327d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_07b77bf09e3b46dca7f6aacec54aab80",
        "IPY_MODEL_90b2830d4d1d40aba1feefad9554077a",
        "IPY_MODEL_78696ceb6f4c412b95ae011364d8968e"
       ],
       "layout": "IPY_MODEL_6b0af32f89fd4f05a40cc73062f3185f",
       "tabbable": null,
       "tooltip": null
      }
     },
     "63ccd05cbf614148a90b2d64f1ba9a51": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "68cf192877354277a562ad8cfa4c1a5f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6b0af32f89fd4f05a40cc73062f3185f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6fa3ad2f7e114111a35d34c27197988e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_48bc78e8f58741e895a855aeadb49ecb",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_2685d5122d174839a9fb98514aac0837",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡229k/229kâ€‡[00:00&lt;00:00,â€‡1.84MB/s]"
      }
     },
     "78696ceb6f4c412b95ae011364d8968e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_eb0ae4e5e68345f9bfba1d601af80784",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_d69c07880dd040c3be32c8f84c0d149f",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡2.00/2.00â€‡[00:00&lt;00:00,â€‡176B/s]"
      }
     },
     "7a9f17578b21449db1819c9cced9fb0d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "90b2830d4d1d40aba1feefad9554077a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_98d225c415cb46ae96b32b259368b468",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3730966d24114f4fbfa7517ff776028d",
       "tabbable": null,
       "tooltip": null,
       "value": 2
      }
     },
     "98d225c415cb46ae96b32b259368b468": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9b1ad97c8a3a4c5f8c5960a29a84e066": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a5cd9e82ceee4ceeabad14233e368cbd",
        "IPY_MODEL_d9bedbd3b15b4fec9e95ded59fd6c4ce",
        "IPY_MODEL_6fa3ad2f7e114111a35d34c27197988e"
       ],
       "layout": "IPY_MODEL_c59733a824da4c389866d3957093a2f5",
       "tabbable": null,
       "tooltip": null
      }
     },
     "9d3bd2971d9a49d1a4f314bbfd344cb3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a12c3d5d043b4361aadcd998152321b5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b020f3fdd7bd496d8031de7db3faa731",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_0872c20e558845d69d64419bc7e37b7d",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json:â€‡100%"
      }
     },
     "a5cd9e82ceee4ceeabad14233e368cbd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7a9f17578b21449db1819c9cced9fb0d",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_f35b56ec984c4ea5852a2f7836560de9",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt:â€‡100%"
      }
     },
     "ae49db7729734b10a9a7b049fa17dba1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b020f3fdd7bd496d8031de7db3faa731": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bfc6b52a06dc4ff0a664c055fdd66fdb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c4508888d1b44bd9a8bfe0996fb0bb9a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0aac7d77baab4ae59633d2d047fe636c",
        "IPY_MODEL_53aa3e38e1a34e739cf947046795e57d",
        "IPY_MODEL_4157c0f25d2943688de579667a4812d1"
       ],
       "layout": "IPY_MODEL_5569bef99e984cd4bbf47be7ff36b61e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "c59733a824da4c389866d3957093a2f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d69c07880dd040c3be32c8f84c0d149f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d9ad7542c5e041ff97a53b70e9c84dc2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a12c3d5d043b4361aadcd998152321b5",
        "IPY_MODEL_18bf93e7f8e94dd596cc0d9fba38d2ab",
        "IPY_MODEL_ee8337bdd1584deab5c0572d83d79abe"
       ],
       "layout": "IPY_MODEL_9d3bd2971d9a49d1a4f314bbfd344cb3",
       "tabbable": null,
       "tooltip": null
      }
     },
     "d9bedbd3b15b4fec9e95ded59fd6c4ce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e1953bc013454814924d24766b6f62e7",
       "max": 229167,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_bfc6b52a06dc4ff0a664c055fdd66fdb",
       "tabbable": null,
       "tooltip": null,
       "value": 229167
      }
     },
     "e1953bc013454814924d24766b6f62e7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eb0ae4e5e68345f9bfba1d601af80784": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ee8337bdd1584deab5c0572d83d79abe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fe0d5e2648fd443fb95e5f985a3ae007",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_3eb2ac49116b44e9a6c44d7c6473b2a2",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡1.53k/1.53kâ€‡[00:00&lt;00:00,â€‡159kB/s]"
      }
     },
     "ef8a4f40da5a48149f20719a2f02b378": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f35b56ec984c4ea5852a2f7836560de9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f62c05469b5541e0990e03f920217c91": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "fe0d5e2648fd443fb95e5f985a3ae007": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
