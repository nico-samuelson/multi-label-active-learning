{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82db90fa",
   "metadata": {
    "papermill": {
     "duration": 0.012094,
     "end_time": "2025-01-08T13:17:22.452816",
     "exception": false,
     "start_time": "2025-01-08T13:17:22.440722",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2938a86b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T13:17:22.476089Z",
     "iopub.status.busy": "2025-01-08T13:17:22.475809Z",
     "iopub.status.idle": "2025-01-08T13:17:35.082073Z",
     "shell.execute_reply": "2025-01-08T13:17:35.081330Z"
    },
    "papermill": {
     "duration": 12.619677,
     "end_time": "2025-01-08T13:17:35.083779",
     "exception": false,
     "start_time": "2025-01-08T13:17:22.464102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd40493",
   "metadata": {
    "papermill": {
     "duration": 0.012817,
     "end_time": "2025-01-08T13:17:35.108496",
     "exception": false,
     "start_time": "2025-01-08T13:17:35.095679",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "323831d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T13:17:35.132026Z",
     "iopub.status.busy": "2025-01-08T13:17:35.131665Z",
     "iopub.status.idle": "2025-01-08T13:17:35.134764Z",
     "shell.execute_reply": "2025-01-08T13:17:35.134174Z"
    },
    "papermill": {
     "duration": 0.01629,
     "end_time": "2025-01-08T13:17:35.135954",
     "exception": false,
     "start_time": "2025-01-08T13:17:35.119664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "936c69ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T13:17:35.159364Z",
     "iopub.status.busy": "2025-01-08T13:17:35.159141Z",
     "iopub.status.idle": "2025-01-08T13:17:35.162882Z",
     "shell.execute_reply": "2025-01-08T13:17:35.162290Z"
    },
    "papermill": {
     "duration": 0.016528,
     "end_time": "2025-01-08T13:17:35.163952",
     "exception": false,
     "start_time": "2025-01-08T13:17:35.147424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/working/results') == False:\n",
    "    os.mkdir('/kaggle/working/results')\n",
    "\n",
    "if os.path.exists('/kaggle/working/acquired_data') == False:\n",
    "    os.mkdir('/kaggle/working/acquired_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b91363d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T13:17:35.188263Z",
     "iopub.status.busy": "2025-01-08T13:17:35.188031Z",
     "iopub.status.idle": "2025-01-08T13:17:35.198735Z",
     "shell.execute_reply": "2025-01-08T13:17:35.198139Z"
    },
    "papermill": {
     "duration": 0.024636,
     "end_time": "2025-01-08T13:17:35.199824",
     "exception": false,
     "start_time": "2025-01-08T13:17:35.175188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6985d376",
   "metadata": {
    "papermill": {
     "duration": 0.01097,
     "end_time": "2025-01-08T13:17:35.222071",
     "exception": false,
     "start_time": "2025-01-08T13:17:35.211101",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77cd0d53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T13:17:35.245254Z",
     "iopub.status.busy": "2025-01-08T13:17:35.245017Z",
     "iopub.status.idle": "2025-01-08T13:17:35.291391Z",
     "shell.execute_reply": "2025-01-08T13:17:35.289995Z"
    },
    "papermill": {
     "duration": 0.059661,
     "end_time": "2025-01-08T13:17:35.292806",
     "exception": false,
     "start_time": "2025-01-08T13:17:35.233145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Shared resources\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "data_used = manager.list()\n",
    "sampling_dur = manager.list()\n",
    "new_samples = manager.list()\n",
    "\n",
    "# Non shared resources\n",
    "filename = 'netifier-kmeans'\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "sequence_length = 96"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d2b508",
   "metadata": {
    "papermill": {
     "duration": 0.010961,
     "end_time": "2025-01-08T13:17:35.315286",
     "exception": false,
     "start_time": "2025-01-08T13:17:35.304325",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2f8ee7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T13:17:35.339075Z",
     "iopub.status.busy": "2025-01-08T13:17:35.338723Z",
     "iopub.status.idle": "2025-01-08T13:17:35.467612Z",
     "shell.execute_reply": "2025-01-08T13:17:35.466693Z"
    },
    "papermill": {
     "duration": 0.142431,
     "end_time": "2025-01-08T13:17:35.469070",
     "exception": false,
     "start_time": "2025-01-08T13:17:35.326639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>answer</th>\n",
       "      <th>1-FR</th>\n",
       "      <th>2-GI</th>\n",
       "      <th>3-PI</th>\n",
       "      <th>4-DM</th>\n",
       "      <th>5-EDTRB</th>\n",
       "      <th>6-RE</th>\n",
       "      <th>Text_Clean</th>\n",
       "      <th>filtered_text</th>\n",
       "      <th>token</th>\n",
       "      <th>tokens_stemmed</th>\n",
       "      <th>Process_Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Halo Rizal,Radang tenggorokan umunya disebabka...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo rizal radang tenggorokan umunya disebabka...</td>\n",
       "      <td>halo rizal radang tenggorokan umunya disebabka...</td>\n",
       "      <td>['halo', 'rizal', 'radang', 'tenggorokan', 'um...</td>\n",
       "      <td>['halo', 'rizal', 'radang', 'tenggorok', 'umu'...</td>\n",
       "      <td>halo rizal radang tenggorok umu sebab infeksi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Halo Hellas,Cacar air merupakan suatu penyakit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo hellas cacar air merupakan suatu penyakit...</td>\n",
       "      <td>halo hellas cacar air penyakit disebabkan viru...</td>\n",
       "      <td>['halo', 'hellas', 'cacar', 'air', 'penyakit',...</td>\n",
       "      <td>['halo', 'hellas', 'cacar', 'air', 'sakit', 's...</td>\n",
       "      <td>halo hellas cacar air sakit sebab virus varise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Halo Rory.......Terimakasih atas pertanyaan An...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo rory terimakasih atas pertanyaan anda per...</td>\n",
       "      <td>halo rory terimakasih ketahui gangguan kulit s...</td>\n",
       "      <td>['halo', 'rory', 'terimakasih', 'ketahui', 'ga...</td>\n",
       "      <td>['halo', 'rory', 'terimakasih', 'tahu', 'gangg...</td>\n",
       "      <td>halo rory terimakasih tahu ganggu kulit rangka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Alo AfriYani, Terimakasih atas pertanyaannya. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>alo afriyani terimakasih atas pertanyaannya ku...</td>\n",
       "      <td>alo afriyani terimakasih pertanyaannya kuku ja...</td>\n",
       "      <td>['alo', 'afriyani', 'terimakasih', 'pertanyaan...</td>\n",
       "      <td>['alo', 'afriyani', 'terimakasih', 'tanya', 'k...</td>\n",
       "      <td>alo afriyani terimakasih tanya kuku jari kaki ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Halo,Telinga berdenging atau  tinitus  merupak...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo telinga berdenging atau tinitus merupakan...</td>\n",
       "      <td>halo telinga berdenging tinitus sensasi penden...</td>\n",
       "      <td>['halo', 'telinga', 'berdenging', 'tinitus', '...</td>\n",
       "      <td>['halo', 'telinga', 'denging', 'tinitus', 'sen...</td>\n",
       "      <td>halo telinga denging tinitus sensasi dengar de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No                                             answer  1-FR  2-GI  3-PI  \\\n",
       "0   1  Halo Rizal,Radang tenggorokan umunya disebabka...     1     0     1   \n",
       "1   2  Halo Hellas,Cacar air merupakan suatu penyakit...     1     0     1   \n",
       "2   3  Halo Rory.......Terimakasih atas pertanyaan An...     1     0     1   \n",
       "3   4  Alo AfriYani, Terimakasih atas pertanyaannya. ...     1     0     1   \n",
       "4   5  Halo,Telinga berdenging atau  tinitus  merupak...     1     0     1   \n",
       "\n",
       "   4-DM  5-EDTRB  6-RE                                         Text_Clean  \\\n",
       "0     1        1     0  halo rizal radang tenggorokan umunya disebabka...   \n",
       "1     1        1     0  halo hellas cacar air merupakan suatu penyakit...   \n",
       "2     1        1     0  halo rory terimakasih atas pertanyaan anda per...   \n",
       "3     1        1     0  alo afriyani terimakasih atas pertanyaannya ku...   \n",
       "4     1        1     0  halo telinga berdenging atau tinitus merupakan...   \n",
       "\n",
       "                                       filtered_text  \\\n",
       "0  halo rizal radang tenggorokan umunya disebabka...   \n",
       "1  halo hellas cacar air penyakit disebabkan viru...   \n",
       "2  halo rory terimakasih ketahui gangguan kulit s...   \n",
       "3  alo afriyani terimakasih pertanyaannya kuku ja...   \n",
       "4  halo telinga berdenging tinitus sensasi penden...   \n",
       "\n",
       "                                               token  \\\n",
       "0  ['halo', 'rizal', 'radang', 'tenggorokan', 'um...   \n",
       "1  ['halo', 'hellas', 'cacar', 'air', 'penyakit',...   \n",
       "2  ['halo', 'rory', 'terimakasih', 'ketahui', 'ga...   \n",
       "3  ['alo', 'afriyani', 'terimakasih', 'pertanyaan...   \n",
       "4  ['halo', 'telinga', 'berdenging', 'tinitus', '...   \n",
       "\n",
       "                                      tokens_stemmed  \\\n",
       "0  ['halo', 'rizal', 'radang', 'tenggorok', 'umu'...   \n",
       "1  ['halo', 'hellas', 'cacar', 'air', 'sakit', 's...   \n",
       "2  ['halo', 'rory', 'terimakasih', 'tahu', 'gangg...   \n",
       "3  ['alo', 'afriyani', 'terimakasih', 'tanya', 'k...   \n",
       "4  ['halo', 'telinga', 'denging', 'tinitus', 'sen...   \n",
       "\n",
       "                                        Process_Data  \n",
       "0  halo rizal radang tenggorok umu sebab infeksi ...  \n",
       "1  halo hellas cacar air sakit sebab virus varise...  \n",
       "2  halo rory terimakasih tahu ganggu kulit rangka...  \n",
       "3  alo afriyani terimakasih tanya kuku jari kaki ...  \n",
       "4  halo telinga denging tinitus sensasi dengar de...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/kaggle/input/doctors-answer-text-dataset/Indo-Online Health Consultation-Medical Interview-Clean.csv', encoding='latin-1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7116ef70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T13:17:35.494739Z",
     "iopub.status.busy": "2025-01-08T13:17:35.494490Z",
     "iopub.status.idle": "2025-01-08T13:17:35.519778Z",
     "shell.execute_reply": "2025-01-08T13:17:35.518964Z"
    },
    "papermill": {
     "duration": 0.03934,
     "end_time": "2025-01-08T13:17:35.521042",
     "exception": false,
     "start_time": "2025-01-08T13:17:35.481702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,) (400, 6)\n",
      "(100,) (100, 6)\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "train_labels = train_data.columns[2:8]\n",
    "val_labels = val_data.columns[2:8]\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['Text_Clean'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['Text_Clean'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9659a73",
   "metadata": {
    "papermill": {
     "duration": 0.011564,
     "end_time": "2025-01-08T13:17:35.544169",
     "exception": false,
     "start_time": "2025-01-08T13:17:35.532605",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BUILD DATASET & DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26cd806e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T13:17:35.568075Z",
     "iopub.status.busy": "2025-01-08T13:17:35.567850Z",
     "iopub.status.idle": "2025-01-08T13:17:36.380270Z",
     "shell.execute_reply": "2025-01-08T13:17:36.379378Z"
    },
    "papermill": {
     "duration": 0.826125,
     "end_time": "2025-01-08T13:17:36.381599",
     "exception": false,
     "start_time": "2025-01-08T13:17:35.555474",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd0fe0e0b47468fb352eff6e337786e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "751cf2478f5d407db271ed22a3423080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79821dacd6b84524a9d84420eafb47b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f491c162ae241c99f46ffdb009ccabd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class DoctorAnswerDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=256, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        labels = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(labels, dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "# Initialize BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6160fdc0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T13:17:36.406817Z",
     "iopub.status.busy": "2025-01-08T13:17:36.406563Z",
     "iopub.status.idle": "2025-01-08T13:17:36.410921Z",
     "shell.execute_reply": "2025-01-08T13:17:36.410170Z"
    },
    "papermill": {
     "duration": 0.018046,
     "end_time": "2025-01-08T13:17:36.412069",
     "exception": false,
     "start_time": "2025-01-08T13:17:36.394023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataloaders(X_train, y_train, X_val, y_val, sequence_length=256, num_workers=4):\n",
    "    train_dataset = DoctorAnswerDataset(X_train, y_train, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = DoctorAnswerDataset(X_val, y_val, tokenizer, max_length=sequence_length)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffdde7f",
   "metadata": {
    "papermill": {
     "duration": 0.011509,
     "end_time": "2025-01-08T13:17:36.435366",
     "exception": false,
     "start_time": "2025-01-08T13:17:36.423857",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90e9b02d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T13:17:36.461073Z",
     "iopub.status.busy": "2025-01-08T13:17:36.460798Z",
     "iopub.status.idle": "2025-01-08T13:17:36.464627Z",
     "shell.execute_reply": "2025-01-08T13:17:36.463837Z"
    },
    "papermill": {
     "duration": 0.017377,
     "end_time": "2025-01-08T13:17:36.465893",
     "exception": false,
     "start_time": "2025-01-08T13:17:36.448516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "369705b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T13:17:36.490839Z",
     "iopub.status.busy": "2025-01-08T13:17:36.490622Z",
     "iopub.status.idle": "2025-01-08T13:17:36.495257Z",
     "shell.execute_reply": "2025-01-08T13:17:36.494495Z"
    },
    "papermill": {
     "duration": 0.018296,
     "end_time": "2025-01-08T13:17:36.496558",
     "exception": false,
     "start_time": "2025-01-08T13:17:36.478262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        target_names=['1-FR', '2-GI', '3-PI', '4-DM', '5-EDTRB', '6-RE'],\n",
    "        zero_division=0\n",
    "    )  \n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba519ac8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T13:17:36.520933Z",
     "iopub.status.busy": "2025-01-08T13:17:36.520737Z",
     "iopub.status.idle": "2025-01-08T13:17:36.532300Z",
     "shell.execute_reply": "2025-01-08T13:17:36.531719Z"
    },
    "papermill": {
     "duration": 0.025114,
     "end_time": "2025-01-08T13:17:36.533574",
     "exception": false,
     "start_time": "2025-01-08T13:17:36.508460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, metrics, trials, seed):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "\n",
    "    accelerator.print(accelerator.distributed_type)\n",
    "\n",
    "    with accelerator.main_process_first():\n",
    "        model = BertForSequenceClassification.from_pretrained(\n",
    "            'indobenchmark/indobert-base-p2',\n",
    "            num_labels=len(train_labels),\n",
    "            problem_type=\"multi_label_classification\"\n",
    "        )\n",
    "\n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Define DataLoaders\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    train_loader, val_loader = get_dataloaders(current_X_train, current_y_train, X_val, y_val)\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Prepare everything with Accelerator\n",
    "    model, optimizer, train_loader, val_loader = accelerator.prepare(\n",
    "        model, optimizer, train_loader, val_loader\n",
    "    )\n",
    "\n",
    "    best_result = None\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key != 'labels'}\n",
    "            labels = batch['labels']\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key != 'labels'}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "        result = compute_metrics(type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}))\n",
    "\n",
    "        if best_result is None or result['f1_micro'] >= best_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'{filename}-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "            best_result = result\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    accelerator.print(f\"Iteration {current_train_size}: Accuracy: {round(best_result['accuracy'], 4)}, F1 Micro: {round(best_result['f1_micro'], 4)}, F1 Macro: {round(best_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(best_result['report'])\n",
    "    accelerator.print(f\"Training completed in {duration} s\")\n",
    "\n",
    "    # Update the shared lists\n",
    "    if accelerator.is_local_main_process:\n",
    "        metrics[0].append(current_train_size)\n",
    "        metrics[1].append(best_result['accuracy'])\n",
    "        metrics[2].append(best_result['f1_micro'])\n",
    "        metrics[3].append(best_result['f1_macro'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d51dc5",
   "metadata": {
    "papermill": {
     "duration": 0.011389,
     "end_time": "2025-01-08T13:17:36.556614",
     "exception": false,
     "start_time": "2025-01-08T13:17:36.545225",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PLOT THE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04ff4707",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T13:17:36.580737Z",
     "iopub.status.busy": "2025-01-08T13:17:36.580538Z",
     "iopub.status.idle": "2025-01-08T13:17:36.585804Z",
     "shell.execute_reply": "2025-01-08T13:17:36.585207Z"
    },
    "papermill": {
     "duration": 0.018566,
     "end_time": "2025-01-08T13:17:36.586886",
     "exception": false,
     "start_time": "2025-01-08T13:17:36.568320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4a66dd",
   "metadata": {
    "papermill": {
     "duration": 0.011946,
     "end_time": "2025-01-08T13:17:36.610519",
     "exception": false,
     "start_time": "2025-01-08T13:17:36.598573",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QUERY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17a7e972",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T13:17:36.635734Z",
     "iopub.status.busy": "2025-01-08T13:17:36.635524Z",
     "iopub.status.idle": "2025-01-08T13:17:36.648837Z",
     "shell.execute_reply": "2025-01-08T13:17:36.648039Z"
    },
    "papermill": {
     "duration": 0.027539,
     "end_time": "2025-01-08T13:17:36.650146",
     "exception": false,
     "start_time": "2025-01-08T13:17:36.622607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kmeans_clustering_sampling(model, X_pool, train_indices, remaining_indices, tokenizer, sampling_dur, new_samples, trials, n_clusters=min_increment):\n",
    "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "    device = accelerator.device\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    current_train_size = len(train_indices)\n",
    "    dataset = DoctorAnswerDataset(X_pool, np.zeros((len(X_pool), 6)), tokenizer, max_length=sequence_length)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    embeddings = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            input_ids = data['input_ids'].to(device)\n",
    "            attention_mask = data['attention_mask'].to(device)\n",
    "            outputs = model.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            hidden_states = outputs.last_hidden_state.mean(dim=1)  # Mean of hidden states for vector representation\n",
    "            embeddings.append(hidden_states.cpu().numpy())\n",
    "    \n",
    "    # Convert embeddings list to numpy array\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    embeddings = np.array(embeddings)\n",
    "    collected_indices = set()  # Initialize set to store selected indices\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "\n",
    "    if accelerator.is_local_main_process:\n",
    "        num_of_candidates = len(embeddings[:math.ceil(0.1 * len(embeddings))])\n",
    "    \n",
    "        # Check nearest checkpoint\n",
    "        nearest_cp = 0\n",
    "        arrived_at_cp = False\n",
    "        for cp in checkpoints:\n",
    "            if cp > current_train_size:\n",
    "                nearest_cp = cp\n",
    "                break\n",
    "    \n",
    "        # Determine number of clusters\n",
    "        if num_of_candidates <= n_clusters and n_clusters < nearest_cp - current_train_size:\n",
    "            n_clusters = n_clusters\n",
    "        elif num_of_candidates > n_clusters and num_of_candidates < nearest_cp - current_train_size:\n",
    "            n_clusters = num_of_candidates\n",
    "        else:\n",
    "            arrived_at_cp = True\n",
    "            n_clusters = nearest_cp - current_train_size\n",
    "            \n",
    "        kmeans=KMeans(n_clusters=n_clusters, n_init=1)\n",
    "        kmeans.fit(embeddings)\n",
    "    \n",
    "        if current_train_size > checkpoints[len(checkpoints)-1] - min_increment:\n",
    "            end_time = time.time()\n",
    "            duration = end_time - start_time\n",
    "            \n",
    "            temp = train_indices.copy()\n",
    "            temp.extend(remaining_indices)\n",
    "            \n",
    "            # Save acquired data up to checkpoint\n",
    "            acquired_data = pd.DataFrame({\n",
    "                'processed_text': [X_train[i] for i in temp],\n",
    "                '1-FR': [y_train[i][0] for i in temp],\n",
    "                '2-GI': [y_train[i][1] for i in temp],\n",
    "                '3-PI': [y_train[i][2] for i in temp],\n",
    "                '4-DM': [y_train[i][3] for i in temp],\n",
    "                '5-EDTRB': [y_train[i][4] for i in temp],\n",
    "                '6-RE': [y_train[i][5] for i in temp],\n",
    "            })\n",
    "            acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "\n",
    "            print(\"Nearest checkpoint:\", nearest_cp)\n",
    "            print(\"Samples above threshold:\", num_of_candidates)\n",
    "            print(\"Acquired samples:\", len(remaining_indices))\n",
    "            print(f\"Sampling duration: {duration} seconds\")\n",
    "            \n",
    "            sampling_dur.append(duration)\n",
    "            for i in remaining_indices:\n",
    "                new_samples.append(i)\n",
    "        else:\n",
    "            for cluster_id in range(n_clusters):\n",
    "                # Cluster center and indices of samples in the current cluster\n",
    "                cluster_center = kmeans.cluster_centers_[cluster_id]\n",
    "                cluster_indices = np.where(kmeans.labels_ == cluster_id)[0]  # Indices of samples in the current cluster\n",
    "                \n",
    "                if cluster_indices.size == 0:\n",
    "                    # Skip clusters with no members\n",
    "                    print(f\"Cluster {cluster_id} has no members, skipping.\")\n",
    "                    continue\n",
    "            \n",
    "                # Calculate distances to the cluster center\n",
    "                cluster_distances = np.linalg.norm(embeddings[cluster_indices] - cluster_center, axis=1)\n",
    "                closest_sample_index = cluster_indices[np.argmin(cluster_distances)]  # Closest sample index\n",
    "                collected_indices.add(closest_sample_index)\n",
    "\n",
    "            end_time = time.time() \n",
    "            duration = end_time - start_time \n",
    "    \n",
    "            if arrived_at_cp:\n",
    "                temp = train_indices.copy()\n",
    "                temp.extend(collected_indices)\n",
    "                \n",
    "                # Save acquired data up to checkpoint\n",
    "                acquired_data = pd.DataFrame({\n",
    "                    'processed_text': [X_train[i] for i in temp],\n",
    "                    'pornografi': [y_train[i][0] for i in temp],\n",
    "                    'sara': [y_train[i][1] for i in temp],\n",
    "                    'radikalisme': [y_train[i][2] for i in temp],\n",
    "                    'pencemaran_nama_baik': [y_train[i][3] for i in temp],\n",
    "                })\n",
    "        \n",
    "                acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "            \n",
    "            print(\"Nearest checkpoint:\", nearest_cp)\n",
    "            print(\"Samples above threshold:\", num_of_candidates)\n",
    "            print(\"Acquired samples:\", len(collected_indices))\n",
    "            print(f\"Sampling duration: {duration} seconds\")\n",
    "        \n",
    "            sampling_dur.append(duration)\n",
    "            for i in collected_indices:\n",
    "                new_samples.append(remaining_indices[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7b2872",
   "metadata": {
    "papermill": {
     "duration": 0.011627,
     "end_time": "2025-01-08T13:17:36.673507",
     "exception": false,
     "start_time": "2025-01-08T13:17:36.661880",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f205d25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T13:17:36.697947Z",
     "iopub.status.busy": "2025-01-08T13:17:36.697721Z",
     "iopub.status.idle": "2025-01-08T13:17:36.705527Z",
     "shell.execute_reply": "2025-01-08T13:17:36.704742Z"
    },
    "papermill": {
     "duration": 0.021399,
     "end_time": "2025-01-08T13:17:36.706830",
     "exception": false,
     "start_time": "2025-01-08T13:17:36.685431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i):\n",
    "    accuracies = manager.list()\n",
    "    f1_micros = manager.list()\n",
    "    f1_macros = manager.list()\n",
    "    data_used = manager.list()\n",
    "    sampling_dur = manager.list()\n",
    "    new_samples = manager.list()\n",
    "\n",
    "    set_seed(seed)\n",
    "    \n",
    "    print(\"===============================================\")\n",
    "    print(\"TRIAL {}\".format(i+1))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        # Train the model\n",
    "        args = (current_train_size, train_indices, (data_used, accuracies, f1_micros, f1_macros), i, seed)\n",
    "        notebook_launcher(train_model, args, num_processes=2)\n",
    "        \n",
    "        model = BertForSequenceClassification.from_pretrained(f'{filename}-{i + 1}-model')\n",
    "    \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples = manager.list()\n",
    "        sampling_args = (model, [X_train[i] for i in remaining_indices], train_indices, remaining_indices, tokenizer, sampling_dur, new_samples, i)\n",
    "        notebook_launcher(kmeans_clustering_sampling, sampling_args, num_processes=2)\n",
    "        new_samples = list(new_samples)\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    args = (current_train_size, train_indices, (data_used, accuracies, f1_micros, f1_macros), i, seed)\n",
    "    notebook_launcher(train_model, args, num_processes=2)\n",
    "    data_used, accuracies, f1_micros, f1_macros, sampling_dur = list(data_used), list(accuracies), list(f1_micros), list(f1_macros), list(sampling_dur)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    \n",
    "    sampling_dur.insert(0, 0)\n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    results.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b75ada10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T13:17:36.730833Z",
     "iopub.status.busy": "2025-01-08T13:17:36.730618Z",
     "iopub.status.idle": "2025-01-08T13:17:36.733876Z",
     "shell.execute_reply": "2025-01-08T13:17:36.733137Z"
    },
    "papermill": {
     "duration": 0.016744,
     "end_time": "2025-01-08T13:17:36.735177",
     "exception": false,
     "start_time": "2025-01-08T13:17:36.718433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [50, 81, 14, 3, 94]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcc33df",
   "metadata": {
    "papermill": {
     "duration": 0.011454,
     "end_time": "2025-01-08T13:17:36.758404",
     "exception": false,
     "start_time": "2025-01-08T13:17:36.746950",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2288e78d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T13:17:36.782554Z",
     "iopub.status.busy": "2025-01-08T13:17:36.782358Z",
     "iopub.status.idle": "2025-01-08T13:43:07.071517Z",
     "shell.execute_reply": "2025-01-08T13:43:07.070802Z"
    },
    "papermill": {
     "duration": 1530.302886,
     "end_time": "2025-01-08T13:43:07.072889",
     "exception": false,
     "start_time": "2025-01-08T13:17:36.770003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 1\n",
      "Random seed: 50\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475d3402c8dc4af881145d1dff9ef22c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7417, Accuracy: 0.8438, F1 Micro: 0.8861, F1 Macro: 0.6509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6068, Accuracy: 0.931, F1 Micro: 0.949, F1 Macro: 0.6633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5321, Accuracy: 0.9609, F1 Micro: 0.9705, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4626, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3907, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3555, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3257, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2884, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2649, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2384, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 25: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 51.38762354850769 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 38\n",
      "Sampling duration: 4.712616682052612 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7366, Accuracy: 0.8464, F1 Micro: 0.888, F1 Macro: 0.6516\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6044, Accuracy: 0.9323, F1 Micro: 0.95, F1 Macro: 0.6639\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5471, Accuracy: 0.9635, F1 Micro: 0.9724, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4709, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4143, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3651, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3201, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3141, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2722, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2466, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 63: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 39.55842924118042 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 34\n",
      "Acquired samples: 34\n",
      "Sampling duration: 4.761643886566162 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6726, Accuracy: 0.9258, F1 Micro: 0.9453, F1 Macro: 0.6621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5123, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3945, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3196, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2764, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2371, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2312, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2015, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.175, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1843, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 97: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 43.4595627784729 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 31\n",
      "Acquired samples: 31\n",
      "Sampling duration: 4.486509323120117 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6746, Accuracy: 0.9362, F1 Micro: 0.9527, F1 Macro: 0.665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5099, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3983, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3312, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2931, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.22, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2058, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2067, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1804, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2062, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 128: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 43.94105076789856 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 28\n",
      "Acquired samples: 28\n",
      "Sampling duration: 4.069854736328125 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6337, Accuracy: 0.9609, F1 Micro: 0.9705, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4269, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3138, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2496, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2378, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1986, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1997, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1775, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1759, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1814, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 156: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 48.6328239440918 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 25\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.7939453125 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6297, Accuracy: 0.9609, F1 Micro: 0.9705, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4165, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3049, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2522, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2332, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1879, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1844, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2079, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1735, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1722, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 181: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 50.70720052719116 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 22\n",
      "Sampling duration: 3.5287394523620605 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5919, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3565, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2685, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.214, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2143, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1815, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1894, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1497, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1474, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1676, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 203: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 53.52631425857544 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 20\n",
      "Sampling duration: 3.437087297439575 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5911, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3671, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2716, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2321, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1836, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1838, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1768, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1752, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1822, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1492, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 223: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 53.54308891296387 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 18\n",
      "Sampling duration: 3.014828681945801 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5935, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3595, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2618, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2191, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1946, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1666, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1605, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1635, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1919, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1572, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 241: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 55.15951108932495 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 16\n",
      "Acquired samples: 9\n",
      "Sampling duration: 2.8734090328216553 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5926, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3627, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2569, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2248, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1891, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1921, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1688, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1702, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1527, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1619, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 250: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 54.228607177734375 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 15\n",
      "Sampling duration: 2.861785888671875 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.562, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3139, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2254, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2029, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1769, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1612, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1716, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1765, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.17, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.162, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 265: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 60.17374777793884 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 14\n",
      "Acquired samples: 14\n",
      "Sampling duration: 2.6912994384765625 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5593, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3284, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2422, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1937, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1718, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1561, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1698, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1595, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1692, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1586, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 279: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.56877303123474 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 13\n",
      "Acquired samples: 13\n",
      "Sampling duration: 2.4915947914123535 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5602, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3252, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2381, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2069, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1935, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1613, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.181, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1603, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1609, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1672, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 292: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.973031759262085 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 8\n",
      "Sampling duration: 2.3859987258911133 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5514, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3247, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2368, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1982, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.186, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1677, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1689, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1625, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1541, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1596, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 300: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.645670890808105 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 10\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.108912229537964 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.561, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3223, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2403, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.211, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2006, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1582, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.175, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1735, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1766, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1684, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 310: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 58.654855728149414 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.9785716533660889 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5536, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3049, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2268, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2061, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2032, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1899, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1779, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1755, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1544, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1641, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 320: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 58.89941072463989 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 8\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.9635229110717773 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5323, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2964, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2333, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1783, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1956, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1782, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1698, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1712, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1746, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1472, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 330: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 64.92770195007324 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 7\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.789616584777832 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5293, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2922, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2098, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1843, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1766, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1832, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1714, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1737, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.155, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1305, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 340: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.183483600616455 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.7061986923217773 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5218, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2922, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2129, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1926, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1896, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1733, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1718, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1606, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1561, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1493, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 350: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 64.5039553642273 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 5\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.6234087944030762 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5233, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2853, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2061, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1967, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1827, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1757, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1594, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1691, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1602, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1477, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 360: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.85244703292847 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.6782176494598389 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.527, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2921, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2167, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2002, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1797, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1631, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.164, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1677, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1708, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1553, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 370: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 64.05585384368896 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 3\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.7745587825775146 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5293, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2942, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2068, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1822, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1699, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1582, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1523, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1554, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1384, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1539, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 380: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.765613317489624 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 2\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.5359148979187012 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5013, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2547, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2135, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1825, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1576, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1692, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1671, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1492, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.149, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1428, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 390: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 67.52786469459534 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.4181549549102783 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5051, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.258, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.192, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1925, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1844, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.174, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1625, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1533, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.161, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1464, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 400: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 67.15245342254639 s\n",
      "Total sampling time: 62.69 seconds\n",
      "Total runtime: 1529.182951450348 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a7a7a4",
   "metadata": {
    "papermill": {
     "duration": 0.07856,
     "end_time": "2025-01-08T13:43:07.273488",
     "exception": false,
     "start_time": "2025-01-08T13:43:07.194928",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93c17287",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T13:43:07.432985Z",
     "iopub.status.busy": "2025-01-08T13:43:07.432683Z",
     "iopub.status.idle": "2025-01-08T14:08:48.698972Z",
     "shell.execute_reply": "2025-01-08T14:08:48.698285Z"
    },
    "papermill": {
     "duration": 1541.34793,
     "end_time": "2025-01-08T14:08:48.700486",
     "exception": false,
     "start_time": "2025-01-08T13:43:07.352556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 2\n",
      "Random seed: 81\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7759, Accuracy: 0.6276, F1 Micro: 0.7129, F1 Macro: 0.4886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6568, Accuracy: 0.9193, F1 Micro: 0.9405, F1 Macro: 0.6604\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5443, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4694, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3976, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3515, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.312, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2775, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2811, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2409, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 25: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 38.30255365371704 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 38\n",
      "Sampling duration: 5.539722919464111 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7696, Accuracy: 0.6289, F1 Micro: 0.7141, F1 Macro: 0.4893\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6583, Accuracy: 0.9062, F1 Micro: 0.9306, F1 Macro: 0.6541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5356, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4493, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3957, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3357, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3231, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2782, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2568, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2366, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 63: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 38.28119516372681 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 34\n",
      "Acquired samples: 34\n",
      "Sampling duration: 4.642752647399902 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7092, Accuracy: 0.8867, F1 Micro: 0.9174, F1 Macro: 0.6519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4992, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3865, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3085, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2592, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2431, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2162, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1895, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1932, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1668, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 97: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 44.54495429992676 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 31\n",
      "Acquired samples: 31\n",
      "Sampling duration: 4.425673484802246 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7041, Accuracy: 0.8815, F1 Micro: 0.9134, F1 Macro: 0.6497\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5094, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3663, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3014, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2584, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2245, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2006, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2178, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1975, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1786, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 128: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 44.882237672805786 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 28\n",
      "Acquired samples: 28\n",
      "Sampling duration: 4.3479087352752686 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6554, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4097, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3093, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2478, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2307, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2092, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2037, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1651, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.17, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1621, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 156: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 50.566675424575806 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 25\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.828251838684082 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6545, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4116, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3018, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.235, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2196, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2063, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.194, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1853, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1905, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1815, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 181: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 50.764995098114014 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 22\n",
      "Sampling duration: 3.5730791091918945 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.604, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.343, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2569, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2156, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1984, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2018, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1901, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1652, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1628, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1667, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 203: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 55.5588493347168 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 20\n",
      "Sampling duration: 3.3573474884033203 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6039, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3462, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2569, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2173, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2018, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1862, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1666, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1968, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1765, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.158, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 223: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 55.425105571746826 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 18\n",
      "Sampling duration: 3.1305394172668457 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.604, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3459, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2513, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1971, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1963, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1865, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.162, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1721, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1691, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1748, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 241: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 56.07705283164978 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 16\n",
      "Acquired samples: 9\n",
      "Sampling duration: 2.813325881958008 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6014, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3433, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2649, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2121, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1994, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1834, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1687, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1793, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.178, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1698, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 250: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 55.74059295654297 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 15\n",
      "Sampling duration: 2.8551290035247803 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5622, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2987, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2189, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2077, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2058, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1778, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1621, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1505, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.155, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1602, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 265: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 61.554800271987915 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 14\n",
      "Acquired samples: 14\n",
      "Sampling duration: 2.6357126235961914 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5618, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3117, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2223, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.21, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1875, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.188, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1662, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1809, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1558, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1529, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 279: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 60.97485065460205 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 13\n",
      "Acquired samples: 13\n",
      "Sampling duration: 2.421647310256958 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5602, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3029, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2159, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1888, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1942, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1695, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1702, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1452, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1583, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1517, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 292: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 60.633989095687866 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 8\n",
      "Sampling duration: 2.3278422355651855 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.572, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3076, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2293, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.185, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1807, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1772, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1903, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1599, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1531, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1505, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 300: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 60.511791706085205 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 10\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.2094171047210693 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.564, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3033, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2451, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1996, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1792, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1788, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1856, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1678, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1699, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1525, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 310: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 60.947354793548584 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.083988904953003 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5688, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3008, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2381, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1991, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.185, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1498, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1662, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1747, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1901, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1714, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 320: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 61.27211403846741 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 8\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.9287974834442139 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.526, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2763, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.222, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1734, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1663, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1743, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1627, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1816, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1572, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1425, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 330: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 65.68906474113464 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 7\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.1749322414398193 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5331, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2784, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2112, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.181, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1847, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1755, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1715, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1823, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1646, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1414, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 340: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 65.23448514938354 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.965332269668579 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5288, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.279, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2081, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1979, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1846, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1647, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1569, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1781, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1471, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1364, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 350: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 64.40655660629272 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 5\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.8857805728912354 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5299, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2766, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2089, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1818, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1796, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1673, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1694, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1543, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1467, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1362, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 360: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 65.0170087814331 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.7714290618896484 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5362, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2693, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2067, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1943, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.179, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1733, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1533, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.154, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1697, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1579, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 370: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 64.58058953285217 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 3\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.6623234748840332 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5341, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2696, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.207, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1887, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1707, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1535, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1745, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1589, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1472, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.169, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 380: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 64.95387482643127 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 2\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.5201122760772705 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5042, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2515, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2053, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1777, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1738, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1653, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1719, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1631, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1679, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1534, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 390: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 69.70802211761475 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.1931135654449463 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5047, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2584, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2025, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1782, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1687, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1738, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1584, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1468, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1513, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1373, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 400: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 69.648357629776 s\n",
      "Total sampling time: 64.29 seconds\n",
      "Total runtime: 1540.482274055481 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294e5682",
   "metadata": {
    "papermill": {
     "duration": 0.196246,
     "end_time": "2025-01-08T14:08:49.045281",
     "exception": false,
     "start_time": "2025-01-08T14:08:48.849035",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91affce1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T14:08:49.340963Z",
     "iopub.status.busy": "2025-01-08T14:08:49.340660Z",
     "iopub.status.idle": "2025-01-08T14:34:38.895582Z",
     "shell.execute_reply": "2025-01-08T14:34:38.894821Z"
    },
    "papermill": {
     "duration": 1549.705246,
     "end_time": "2025-01-08T14:34:38.897187",
     "exception": false,
     "start_time": "2025-01-08T14:08:49.191941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 3\n",
      "Random seed: 14\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6708, Accuracy: 0.832, F1 Micro: 0.8709, F1 Macro: 0.6144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5673, Accuracy: 0.9609, F1 Micro: 0.9702, F1 Macro: 0.6503\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4855, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4136, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3704, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.322, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2931, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.267, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.243, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2233, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 25: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 39.849631786346436 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 38\n",
      "Sampling duration: 5.011893272399902 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.686, Accuracy: 0.8385, F1 Micro: 0.8787, F1 Macro: 0.6279\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.56, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4876, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4097, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3715, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3283, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2898, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2489, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.238, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2434, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 63: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 39.36375045776367 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 34\n",
      "Acquired samples: 34\n",
      "Sampling duration: 4.6285693645477295 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6267, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4612, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3582, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2779, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2515, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.222, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2062, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1862, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1653, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1628, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 97: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 45.38109731674194 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 31\n",
      "Acquired samples: 31\n",
      "Sampling duration: 4.493954420089722 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6215, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4633, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3505, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.285, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2521, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2477, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2246, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2256, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2042, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1774, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 128: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 45.18172764778137 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 28\n",
      "Acquired samples: 28\n",
      "Sampling duration: 4.627455711364746 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5823, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3802, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.286, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2391, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2192, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1804, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1895, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1899, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1752, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1587, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 156: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 50.35022163391113 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 25\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.774606466293335 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5854, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3813, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.285, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2401, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1916, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2002, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1874, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1666, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1635, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1373, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 181: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 51.74365758895874 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 22\n",
      "Sampling duration: 3.55915904045105 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5435, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3167, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2204, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1851, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1894, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1793, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1677, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1734, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1516, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1557, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 203: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 58.53076171875 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 20\n",
      "Sampling duration: 3.2758545875549316 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5438, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3229, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2483, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1954, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1919, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1877, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1674, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1691, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1585, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1445, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 223: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 56.302340269088745 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 18\n",
      "Sampling duration: 3.0648443698883057 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5452, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3189, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2426, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2097, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1932, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1686, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1564, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1669, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1733, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1495, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 241: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 56.333736181259155 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 16\n",
      "Acquired samples: 9\n",
      "Sampling duration: 2.7973198890686035 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5449, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3263, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2344, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2141, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1707, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1805, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1762, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1408, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1492, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1491, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 250: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 56.69004988670349 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 15\n",
      "Sampling duration: 2.8831963539123535 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5116, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2896, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2135, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.181, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1642, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1724, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1579, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1304, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1553, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1547, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 265: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 61.13801050186157 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 14\n",
      "Acquired samples: 14\n",
      "Sampling duration: 2.614670515060425 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5082, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.288, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2303, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1824, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1683, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.159, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.175, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.144, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1489, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1598, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 279: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 61.747997760772705 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 13\n",
      "Acquired samples: 13\n",
      "Sampling duration: 2.398591995239258 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5073, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2776, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2216, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1967, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1737, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1621, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1428, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1445, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1439, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1655, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 292: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 61.25765681266785 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 8\n",
      "Sampling duration: 2.2713990211486816 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5131, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2937, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2232, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.194, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1785, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1596, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1661, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.148, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1528, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1405, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 300: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 60.34013223648071 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 10\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.741980791091919 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.511, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2842, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2338, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1836, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1862, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1577, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1686, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1617, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1543, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1658, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 310: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 61.44289255142212 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.298957586288452 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5076, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.29, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2269, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1816, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.201, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1813, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1553, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1714, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1441, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1562, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 320: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 60.850120067596436 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 8\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.174665927886963 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4828, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2657, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.22, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1743, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1728, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1811, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1391, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1403, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1529, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1398, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 330: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 66.02337431907654 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 7\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.095984697341919 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4766, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2675, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2122, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1898, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1674, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.158, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.167, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1775, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1568, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1319, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 340: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 64.76926970481873 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.9916369915008545 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4883, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2608, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1936, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.181, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1663, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1635, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1703, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1506, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1484, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1588, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 350: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 64.01974105834961 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 5\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.844247817993164 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4847, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2695, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2032, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1979, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1736, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1778, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1611, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1504, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1573, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1488, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 360: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 64.7974123954773 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.5429530143737793 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4856, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2629, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2186, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1887, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1874, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1746, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1533, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1573, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1653, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1628, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 370: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 65.58483958244324 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 3\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.3865950107574463 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.479, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2743, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2076, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1944, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1816, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1695, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1454, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1613, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1544, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1494, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 380: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 64.81992602348328 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 2\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.243227243423462 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4612, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.24, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2091, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1734, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1638, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1789, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1644, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1488, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1622, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Epoch 10/10, Train Loss: 0.134, Accuracy: 0.9661, F1 Micro: 0.9742, F1 Macro: 0.6533\n",
      "Iteration 390: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 68.02371859550476 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.184467077255249 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4629, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.247, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1999, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1793, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1841, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1656, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1571, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1507, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1586, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1442, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 400: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 70.16272735595703 s\n",
      "Total sampling time: 63.91 seconds\n",
      "Total runtime: 1548.7810854911804 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85250ce4",
   "metadata": {
    "papermill": {
     "duration": 0.213964,
     "end_time": "2025-01-08T14:34:39.330883",
     "exception": false,
     "start_time": "2025-01-08T14:34:39.116919",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "043a70a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T14:34:39.806511Z",
     "iopub.status.busy": "2025-01-08T14:34:39.806178Z",
     "iopub.status.idle": "2025-01-08T15:00:25.725590Z",
     "shell.execute_reply": "2025-01-08T15:00:25.724840Z"
    },
    "papermill": {
     "duration": 1546.135461,
     "end_time": "2025-01-08T15:00:25.726897",
     "exception": false,
     "start_time": "2025-01-08T14:34:39.591436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 4\n",
      "Random seed: 3\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6467, Accuracy: 0.9648, F1 Micro: 0.9733, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5398, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4478, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3936, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3431, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.31, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2886, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2554, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2562, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2399, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 25: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 38.71924924850464 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 38\n",
      "Sampling duration: 5.104460716247559 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6463, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.542, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4515, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3924, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3384, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3114, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2849, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2595, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2652, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2295, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 63: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 38.87818741798401 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 34\n",
      "Acquired samples: 34\n",
      "Sampling duration: 5.031126976013184 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5964, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.417, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.328, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2697, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2148, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2305, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2127, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1892, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1733, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1732, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 97: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 44.73708534240723 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 31\n",
      "Acquired samples: 31\n",
      "Sampling duration: 4.4435296058654785 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5996, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4235, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3281, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2709, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2381, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2356, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2106, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2121, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1939, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1655, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 128: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 46.540138244628906 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 28\n",
      "Acquired samples: 28\n",
      "Sampling duration: 4.232424974441528 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5444, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3453, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2554, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2228, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2137, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1883, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1894, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1858, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1521, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1558, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 156: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 51.216681241989136 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 25\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.8279013633728027 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5554, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3557, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2637, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2313, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2032, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2002, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1721, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1723, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1756, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1736, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 181: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 50.78456902503967 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 22\n",
      "Sampling duration: 3.7011845111846924 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5118, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3027, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.228, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1932, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1905, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1947, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1819, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1693, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.172, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1418, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 203: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 55.69462990760803 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 20\n",
      "Sampling duration: 3.353278875350952 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5162, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3068, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2385, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2201, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1949, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1925, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1755, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1841, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1621, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1632, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 223: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 55.99961733818054 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 18\n",
      "Sampling duration: 3.0437657833099365 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5149, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3066, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.239, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2038, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1843, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1932, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1783, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.181, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1567, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1747, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 241: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 55.73219180107117 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 16\n",
      "Acquired samples: 9\n",
      "Sampling duration: 2.8905646800994873 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5091, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3012, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2452, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1957, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1873, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1687, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1849, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1498, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.149, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1452, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 250: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 56.14433670043945 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 15\n",
      "Sampling duration: 2.810792922973633 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.478, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2761, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2102, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1956, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1843, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.17, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1721, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1415, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1649, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1619, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 265: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 60.911349058151245 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 14\n",
      "Acquired samples: 14\n",
      "Sampling duration: 3.0043771266937256 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4757, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2745, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2197, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1768, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1814, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1783, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1791, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1746, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1629, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1674, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 279: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 60.99062633514404 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 13\n",
      "Acquired samples: 13\n",
      "Sampling duration: 2.7665834426879883 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4776, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2756, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2172, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1874, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1852, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1944, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1736, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1636, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1638, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1566, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 292: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 60.41972899436951 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 8\n",
      "Sampling duration: 2.6024365425109863 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.478, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2788, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2369, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1781, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1741, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1731, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1675, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1634, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1679, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1693, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 300: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 60.74073529243469 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 10\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.5187900066375732 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.48, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2708, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.207, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1763, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1823, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1759, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.174, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1518, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1608, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1543, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 310: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 61.45787286758423 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.4393632411956787 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4779, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2709, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2055, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1839, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1786, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1747, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1591, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.168, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1567, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1751, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 320: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 61.50534200668335 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 8\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.053577423095703 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4539, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2474, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2047, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1705, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1846, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1554, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1558, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1637, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1655, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1761, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 330: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 65.2166268825531 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 7\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.867051124572754 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4475, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2452, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2076, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1893, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1786, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1651, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1827, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1597, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1573, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1673, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 340: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 64.7011730670929 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.7390432357788086 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4521, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.26, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1949, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1981, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1857, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1814, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1682, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1436, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1755, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.166, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 350: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 65.46484351158142 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 5\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.6328485012054443 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4556, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2538, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1996, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1961, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1845, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1548, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1511, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.163, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.161, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1574, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 360: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 64.59707593917847 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.5284621715545654 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4493, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2428, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1952, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.18, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1713, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1574, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1759, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1747, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1706, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1645, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 370: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 65.3469398021698 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 3\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.452033281326294 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4518, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2549, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1965, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1833, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.175, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1745, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1639, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1632, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1505, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1725, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 380: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 66.00632119178772 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 2\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.3081581592559814 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4324, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2353, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1945, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1667, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1756, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1573, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1571, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1629, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1519, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1528, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 390: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 69.42873191833496 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.1236379146575928 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4303, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2317, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1936, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1673, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1632, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1643, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1675, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1606, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1497, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1532, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 400: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 69.0891170501709 s\n",
      "Total sampling time: 64.48 seconds\n",
      "Total runtime: 1545.1469588279724 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8627ac6",
   "metadata": {
    "papermill": {
     "duration": 0.288375,
     "end_time": "2025-01-08T15:00:26.303756",
     "exception": false,
     "start_time": "2025-01-08T15:00:26.015381",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f23de01d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T15:00:26.929821Z",
     "iopub.status.busy": "2025-01-08T15:00:26.929511Z",
     "iopub.status.idle": "2025-01-08T15:26:16.255831Z",
     "shell.execute_reply": "2025-01-08T15:26:16.255008Z"
    },
    "papermill": {
     "duration": 1549.669938,
     "end_time": "2025-01-08T15:26:16.257478",
     "exception": false,
     "start_time": "2025-01-08T15:00:26.587540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 5\n",
      "Random seed: 94\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7246, Accuracy: 0.8529, F1 Micro: 0.8964, F1 Macro: 0.6595\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5992, Accuracy: 0.9492, F1 Micro: 0.962, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5024, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4281, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3713, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3311, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3032, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2839, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.259, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2665, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 25: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 39.27005577087402 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 38\n",
      "Sampling duration: 5.012269496917725 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7312, Accuracy: 0.8698, F1 Micro: 0.906, F1 Macro: 0.6499\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6036, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4984, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4157, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3621, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3463, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2781, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.281, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2587, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2571, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 63: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 39.74798059463501 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 34\n",
      "Acquired samples: 34\n",
      "Sampling duration: 4.733819961547852 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6591, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4573, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3528, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2692, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2438, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2302, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2184, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.176, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1845, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1906, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 97: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 45.102336168289185 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 31\n",
      "Acquired samples: 31\n",
      "Sampling duration: 4.85411524772644 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6611, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4601, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3364, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2718, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2501, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2119, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2179, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2037, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1854, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1762, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 128: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 45.33395195007324 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 28\n",
      "Acquired samples: 28\n",
      "Sampling duration: 4.250090599060059 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6068, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3762, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2623, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2376, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1968, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1832, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1989, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1672, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1846, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1714, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 156: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 50.874347448349 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 25\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.906604766845703 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.603, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3699, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2695, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2335, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2022, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1829, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1893, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1937, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1528, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1759, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 181: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 52.67139649391174 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 22\n",
      "Sampling duration: 3.5306689739227295 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5671, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3206, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2476, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1997, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1751, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1572, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1938, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1745, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1647, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1552, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 203: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 56.199108600616455 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 20\n",
      "Sampling duration: 3.624425172805786 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5629, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3241, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2359, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2072, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1852, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1821, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.174, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1821, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1776, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1683, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 223: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 56.278250217437744 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 18\n",
      "Sampling duration: 3.4274303913116455 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.567, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3292, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2385, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2133, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2025, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1874, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.175, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1804, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1733, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1658, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 241: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 55.87207818031311 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Samples above threshold: 16\n",
      "Acquired samples: 9\n",
      "Sampling duration: 3.1299846172332764 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5585, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3294, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.224, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2059, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1896, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1792, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1627, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1762, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1653, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1471, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 250: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 56.517003774642944 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 15\n",
      "Sampling duration: 3.0323097705841064 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5149, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2726, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2112, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1852, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1916, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1776, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1582, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1528, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1479, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1332, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 265: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 61.23303985595703 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 14\n",
      "Acquired samples: 14\n",
      "Sampling duration: 2.8748879432678223 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5224, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.283, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2057, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2018, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1761, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1557, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1674, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1633, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1702, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1705, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 279: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 61.01613211631775 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 13\n",
      "Acquired samples: 13\n",
      "Sampling duration: 2.7646560668945312 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5146, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2844, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2204, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1995, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1813, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1806, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1705, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1628, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1521, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1469, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 292: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 60.963538646698 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 8\n",
      "Sampling duration: 2.320056438446045 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5202, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2735, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2172, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1978, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1831, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1671, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1788, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1523, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1598, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1526, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 300: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 60.98198056221008 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 10\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.1396279335021973 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5268, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2772, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2149, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1903, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1777, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1747, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1776, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1633, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1661, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1489, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 310: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 61.617661237716675 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.0392942428588867 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5302, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2762, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2199, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2034, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1949, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1752, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1581, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1715, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1703, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1642, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 320: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 60.60152864456177 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 8\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.0104758739471436 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4881, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2445, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2012, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2005, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1777, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1817, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1799, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1432, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1648, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1664, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 330: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 65.03079271316528 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 7\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.8350145816802979 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4864, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2495, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1945, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1744, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1616, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.19, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1566, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1552, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1677, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1556, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 340: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 64.79599213600159 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.7126643657684326 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4912, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2526, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.199, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1916, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1746, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1739, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1628, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1502, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1523, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1534, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 350: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 65.2289822101593 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 5\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.6136603355407715 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4881, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2481, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2021, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1819, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1737, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.154, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1482, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1689, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1522, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1469, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 360: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 64.4868094921112 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.5088517665863037 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.494, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2561, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1927, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1807, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1695, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1649, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1781, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1489, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.17, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1584, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 370: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 64.6041054725647 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 3\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.394007921218872 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4892, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2404, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1883, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1716, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1608, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.175, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1723, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1526, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1453, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1376, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 380: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 65.1689682006836 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 2\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.2891566753387451 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.463, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2284, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2042, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1686, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1659, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1694, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1655, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1416, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1439, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1379, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 390: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 70.52780818939209 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.1865003108978271 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4644, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2263, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1812, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1622, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1763, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1717, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1473, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1616, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1612, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1486, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 400: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 68.99100518226624 s\n",
      "Total sampling time: 64.19 seconds\n",
      "Total runtime: 1548.5626337528229 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[4], 4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6155806,
     "sourceId": 10000921,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7740.623748,
   "end_time": "2025-01-08T15:26:19.989639",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-08T13:17:19.365891",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0bcdb56af99a48cd9bf8f741bc77bcaf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1913b60d71b5483da17f5fd9457b2f57": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1b2725e1ac4e4922a06a319c97d9a5b8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1cd0fe0e0b47468fb352eff6e337786e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a885b189b84d44a39d7670da35ba6681",
        "IPY_MODEL_242ea27769ea4e25a77905c37897ebd9",
        "IPY_MODEL_3ba6521513de408caee02f27c6383de7"
       ],
       "layout": "IPY_MODEL_cfec87ab5a004e668396d118d7bcd745",
       "tabbable": null,
       "tooltip": null
      }
     },
     "21bb0e3cd5424ade9d46b2d1caff5783": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "21e89ad0984445a79f682f2136851ef9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_807eda7e80ca49db8c678aed25046037",
       "placeholder": "​",
       "style": "IPY_MODEL_aa34cd238ef740a690a36ae66a5d666f",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "22136dd09bda41f990af69f369e8a3c3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "242ea27769ea4e25a77905c37897ebd9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3741042c79b54ee5aa05409a0222d9dc",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_67ae89b710264f938c9460ce2d3fce70",
       "tabbable": null,
       "tooltip": null,
       "value": 2.0
      }
     },
     "357b4ffb6db1410dad779f7d58a5de24": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3741042c79b54ee5aa05409a0222d9dc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "37daabd44d9e4f7d953cccac6861f115": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3ba6521513de408caee02f27c6383de7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c6b810b276904bf4a4d1699134db88f3",
       "placeholder": "​",
       "style": "IPY_MODEL_357b4ffb6db1410dad779f7d58a5de24",
       "tabbable": null,
       "tooltip": null,
       "value": " 2.00/2.00 [00:00&lt;00:00, 175B/s]"
      }
     },
     "43a6328bd6d04ab38cbdac42f7efead9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "475d3402c8dc4af881145d1dff9ef22c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5c0a14cbcefa4dae9702e9d1a7bf7c52",
        "IPY_MODEL_7da226e002bc4e5183d92087dc420fe9",
        "IPY_MODEL_ef4a0367ec1943ca932d9e8b5395f298"
       ],
       "layout": "IPY_MODEL_efc56a6841b6490a9b6ac3316d3308eb",
       "tabbable": null,
       "tooltip": null
      }
     },
     "477b8039527c46699c679ea753b2dca0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4f491c162ae241c99f46ffdb009ccabd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_21e89ad0984445a79f682f2136851ef9",
        "IPY_MODEL_feddcb879ca44d40b533e525c52ccc8f",
        "IPY_MODEL_9f12da15aec14f9db23d0fa650da5049"
       ],
       "layout": "IPY_MODEL_5f0ef050bc6d4fc486c3a0bb8752601e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "54e2f9b9bf1d48e1b9627dbdaf775a19": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5c0a14cbcefa4dae9702e9d1a7bf7c52": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b5e0cb94a1a24c0ab67b6a28ea1735fd",
       "placeholder": "​",
       "style": "IPY_MODEL_0bcdb56af99a48cd9bf8f741bc77bcaf",
       "tabbable": null,
       "tooltip": null,
       "value": "pytorch_model.bin: 100%"
      }
     },
     "5f0ef050bc6d4fc486c3a0bb8752601e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "67ae89b710264f938c9460ce2d3fce70": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "68291a5f6f6f403f8fce542d2f48ea0c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6ba525e87a4c4e408bcfd7b1dfe9cd13": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "751cf2478f5d407db271ed22a3423080": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7b13be97d4584788807a658c8e89432f",
        "IPY_MODEL_dcb06ae6faba4a4eb7eaf8179c3c6af1",
        "IPY_MODEL_b057109deab2450780de655e32ea4c47"
       ],
       "layout": "IPY_MODEL_8ddb691657aa43b093c84fe7c9165917",
       "tabbable": null,
       "tooltip": null
      }
     },
     "782ceef72182467985cd393ed2576cef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "79821dacd6b84524a9d84420eafb47b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e1941d3ba2404dfb98ba4662d0df8189",
        "IPY_MODEL_b08c5c854f984aeca48634c35baf263c",
        "IPY_MODEL_c5d24f82ffb44b88a1557c66e64acd19"
       ],
       "layout": "IPY_MODEL_979136adc1744068bd21b267ecbf183d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "7b13be97d4584788807a658c8e89432f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8ffe2a0fa86d4d3fad8af3a72a031253",
       "placeholder": "​",
       "style": "IPY_MODEL_37daabd44d9e4f7d953cccac6861f115",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: 100%"
      }
     },
     "7da226e002bc4e5183d92087dc420fe9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ae7d884e54e24c118d82dbd9ebd3f032",
       "max": 497810400.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7eed80dfe69541179bac586464d13611",
       "tabbable": null,
       "tooltip": null,
       "value": 497810400.0
      }
     },
     "7eed80dfe69541179bac586464d13611": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "807eda7e80ca49db8c678aed25046037": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8ddb691657aa43b093c84fe7c9165917": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8ffe2a0fa86d4d3fad8af3a72a031253": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "979136adc1744068bd21b267ecbf183d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9ab49ee57f4a4f2e9648b0ab344bd31c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9f12da15aec14f9db23d0fa650da5049": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1b2725e1ac4e4922a06a319c97d9a5b8",
       "placeholder": "​",
       "style": "IPY_MODEL_21bb0e3cd5424ade9d46b2d1caff5783",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.53k/1.53k [00:00&lt;00:00, 159kB/s]"
      }
     },
     "a885b189b84d44a39d7670da35ba6681": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9ab49ee57f4a4f2e9648b0ab344bd31c",
       "placeholder": "​",
       "style": "IPY_MODEL_f08d11b331b947baa46e7d4a17639739",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "aa34cd238ef740a690a36ae66a5d666f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ae7d884e54e24c118d82dbd9ebd3f032": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b057109deab2450780de655e32ea4c47": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_22136dd09bda41f990af69f369e8a3c3",
       "placeholder": "​",
       "style": "IPY_MODEL_b1172fb2b4c44c12901be7f949e94289",
       "tabbable": null,
       "tooltip": null,
       "value": " 229k/229k [00:00&lt;00:00, 5.90MB/s]"
      }
     },
     "b08c5c854f984aeca48634c35baf263c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_43a6328bd6d04ab38cbdac42f7efead9",
       "max": 112.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_da1e8c858e6f4207a77289e1a1ffb9e4",
       "tabbable": null,
       "tooltip": null,
       "value": 112.0
      }
     },
     "b1172fb2b4c44c12901be7f949e94289": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b5e0cb94a1a24c0ab67b6a28ea1735fd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c5d24f82ffb44b88a1557c66e64acd19": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e490d7b39a444273846b33e39d95b3ce",
       "placeholder": "​",
       "style": "IPY_MODEL_fe7596c7824b4197914fa62fe17952ff",
       "tabbable": null,
       "tooltip": null,
       "value": " 112/112 [00:00&lt;00:00, 9.32kB/s]"
      }
     },
     "c6b810b276904bf4a4d1699134db88f3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cfec87ab5a004e668396d118d7bcd745": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "da1e8c858e6f4207a77289e1a1ffb9e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "dbb71a786be6411db19db8be7cd69f95": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dcb06ae6faba4a4eb7eaf8179c3c6af1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_dbb71a786be6411db19db8be7cd69f95",
       "max": 229167.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_54e2f9b9bf1d48e1b9627dbdaf775a19",
       "tabbable": null,
       "tooltip": null,
       "value": 229167.0
      }
     },
     "e159edf232914e2bb9b7b0a33643f345": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e1941d3ba2404dfb98ba4662d0df8189": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e159edf232914e2bb9b7b0a33643f345",
       "placeholder": "​",
       "style": "IPY_MODEL_782ceef72182467985cd393ed2576cef",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json: 100%"
      }
     },
     "e490d7b39a444273846b33e39d95b3ce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ef4a0367ec1943ca932d9e8b5395f298": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1913b60d71b5483da17f5fd9457b2f57",
       "placeholder": "​",
       "style": "IPY_MODEL_6ba525e87a4c4e408bcfd7b1dfe9cd13",
       "tabbable": null,
       "tooltip": null,
       "value": " 498M/498M [00:02&lt;00:00, 233MB/s]"
      }
     },
     "efc56a6841b6490a9b6ac3316d3308eb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f08d11b331b947baa46e7d4a17639739": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fe7596c7824b4197914fa62fe17952ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "feddcb879ca44d40b533e525c52ccc8f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_68291a5f6f6f403f8fce542d2f48ea0c",
       "max": 1534.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_477b8039527c46699c679ea753b2dca0",
       "tabbable": null,
       "tooltip": null,
       "value": 1534.0
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
