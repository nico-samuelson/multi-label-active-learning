{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3cb6539",
   "metadata": {
    "papermill": {
     "duration": 0.013197,
     "end_time": "2025-01-08T08:42:12.956784",
     "exception": false,
     "start_time": "2025-01-08T08:42:12.943587",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df39728b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:42:12.981171Z",
     "iopub.status.busy": "2025-01-08T08:42:12.980957Z",
     "iopub.status.idle": "2025-01-08T08:42:20.091340Z",
     "shell.execute_reply": "2025-01-08T08:42:20.090673Z"
    },
    "papermill": {
     "duration": 7.124815,
     "end_time": "2025-01-08T08:42:20.092894",
     "exception": false,
     "start_time": "2025-01-08T08:42:12.968079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f7e8a4",
   "metadata": {
    "papermill": {
     "duration": 0.01108,
     "end_time": "2025-01-08T08:42:20.115799",
     "exception": false,
     "start_time": "2025-01-08T08:42:20.104719",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bcc415e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:42:20.138685Z",
     "iopub.status.busy": "2025-01-08T08:42:20.138281Z",
     "iopub.status.idle": "2025-01-08T08:42:20.141702Z",
     "shell.execute_reply": "2025-01-08T08:42:20.140914Z"
    },
    "papermill": {
     "duration": 0.016159,
     "end_time": "2025-01-08T08:42:20.142903",
     "exception": false,
     "start_time": "2025-01-08T08:42:20.126744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f44db24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:42:20.166593Z",
     "iopub.status.busy": "2025-01-08T08:42:20.166311Z",
     "iopub.status.idle": "2025-01-08T08:42:20.170066Z",
     "shell.execute_reply": "2025-01-08T08:42:20.169258Z"
    },
    "papermill": {
     "duration": 0.016608,
     "end_time": "2025-01-08T08:42:20.171186",
     "exception": false,
     "start_time": "2025-01-08T08:42:20.154578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/working/results') == False:\n",
    "    os.mkdir('/kaggle/working/results')\n",
    "\n",
    "if os.path.exists('/kaggle/working/acquired_data') == False:\n",
    "    os.mkdir('/kaggle/working/acquired_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7946bc8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:42:20.193861Z",
     "iopub.status.busy": "2025-01-08T08:42:20.193625Z",
     "iopub.status.idle": "2025-01-08T08:42:20.201815Z",
     "shell.execute_reply": "2025-01-08T08:42:20.201006Z"
    },
    "papermill": {
     "duration": 0.02087,
     "end_time": "2025-01-08T08:42:20.203054",
     "exception": false,
     "start_time": "2025-01-08T08:42:20.182184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc69be98",
   "metadata": {
    "papermill": {
     "duration": 0.010816,
     "end_time": "2025-01-08T08:42:20.225204",
     "exception": false,
     "start_time": "2025-01-08T08:42:20.214388",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c540858c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:42:20.247866Z",
     "iopub.status.busy": "2025-01-08T08:42:20.247657Z",
     "iopub.status.idle": "2025-01-08T08:42:20.288359Z",
     "shell.execute_reply": "2025-01-08T08:42:20.286788Z"
    },
    "papermill": {
     "duration": 0.054132,
     "end_time": "2025-01-08T08:42:20.290230",
     "exception": false,
     "start_time": "2025-01-08T08:42:20.236098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Shared resources\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "data_used = manager.list()\n",
    "sampling_dur = manager.list()\n",
    "new_samples = manager.list()\n",
    "\n",
    "# Non shared resources\n",
    "filename = 'dat-lc'\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "sequence_length = 96"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d94160c",
   "metadata": {
    "papermill": {
     "duration": 0.010675,
     "end_time": "2025-01-08T08:42:20.311981",
     "exception": false,
     "start_time": "2025-01-08T08:42:20.301306",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ee3ab2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:42:20.335055Z",
     "iopub.status.busy": "2025-01-08T08:42:20.334759Z",
     "iopub.status.idle": "2025-01-08T08:42:20.447326Z",
     "shell.execute_reply": "2025-01-08T08:42:20.446478Z"
    },
    "papermill": {
     "duration": 0.125869,
     "end_time": "2025-01-08T08:42:20.448741",
     "exception": false,
     "start_time": "2025-01-08T08:42:20.322872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>answer</th>\n",
       "      <th>1-FR</th>\n",
       "      <th>2-GI</th>\n",
       "      <th>3-PI</th>\n",
       "      <th>4-DM</th>\n",
       "      <th>5-EDTRB</th>\n",
       "      <th>6-RE</th>\n",
       "      <th>Text_Clean</th>\n",
       "      <th>filtered_text</th>\n",
       "      <th>token</th>\n",
       "      <th>tokens_stemmed</th>\n",
       "      <th>Process_Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Halo Rizal,Radang tenggorokan umunya disebabka...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo rizal radang tenggorokan umunya disebabka...</td>\n",
       "      <td>halo rizal radang tenggorokan umunya disebabka...</td>\n",
       "      <td>['halo', 'rizal', 'radang', 'tenggorokan', 'um...</td>\n",
       "      <td>['halo', 'rizal', 'radang', 'tenggorok', 'umu'...</td>\n",
       "      <td>halo rizal radang tenggorok umu sebab infeksi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Halo Hellas,Cacar air merupakan suatu penyakit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo hellas cacar air merupakan suatu penyakit...</td>\n",
       "      <td>halo hellas cacar air penyakit disebabkan viru...</td>\n",
       "      <td>['halo', 'hellas', 'cacar', 'air', 'penyakit',...</td>\n",
       "      <td>['halo', 'hellas', 'cacar', 'air', 'sakit', 's...</td>\n",
       "      <td>halo hellas cacar air sakit sebab virus varise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Halo Rory.......Terimakasih atas pertanyaan An...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo rory terimakasih atas pertanyaan anda per...</td>\n",
       "      <td>halo rory terimakasih ketahui gangguan kulit s...</td>\n",
       "      <td>['halo', 'rory', 'terimakasih', 'ketahui', 'ga...</td>\n",
       "      <td>['halo', 'rory', 'terimakasih', 'tahu', 'gangg...</td>\n",
       "      <td>halo rory terimakasih tahu ganggu kulit rangka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Alo AfriYani, Terimakasih atas pertanyaannya. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>alo afriyani terimakasih atas pertanyaannya ku...</td>\n",
       "      <td>alo afriyani terimakasih pertanyaannya kuku ja...</td>\n",
       "      <td>['alo', 'afriyani', 'terimakasih', 'pertanyaan...</td>\n",
       "      <td>['alo', 'afriyani', 'terimakasih', 'tanya', 'k...</td>\n",
       "      <td>alo afriyani terimakasih tanya kuku jari kaki ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Halo,Telinga berdenging atau  tinitus  merupak...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo telinga berdenging atau tinitus merupakan...</td>\n",
       "      <td>halo telinga berdenging tinitus sensasi penden...</td>\n",
       "      <td>['halo', 'telinga', 'berdenging', 'tinitus', '...</td>\n",
       "      <td>['halo', 'telinga', 'denging', 'tinitus', 'sen...</td>\n",
       "      <td>halo telinga denging tinitus sensasi dengar de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No                                             answer  1-FR  2-GI  3-PI  \\\n",
       "0   1  Halo Rizal,Radang tenggorokan umunya disebabka...     1     0     1   \n",
       "1   2  Halo Hellas,Cacar air merupakan suatu penyakit...     1     0     1   \n",
       "2   3  Halo Rory.......Terimakasih atas pertanyaan An...     1     0     1   \n",
       "3   4  Alo AfriYani, Terimakasih atas pertanyaannya. ...     1     0     1   \n",
       "4   5  Halo,Telinga berdenging atau  tinitus  merupak...     1     0     1   \n",
       "\n",
       "   4-DM  5-EDTRB  6-RE                                         Text_Clean  \\\n",
       "0     1        1     0  halo rizal radang tenggorokan umunya disebabka...   \n",
       "1     1        1     0  halo hellas cacar air merupakan suatu penyakit...   \n",
       "2     1        1     0  halo rory terimakasih atas pertanyaan anda per...   \n",
       "3     1        1     0  alo afriyani terimakasih atas pertanyaannya ku...   \n",
       "4     1        1     0  halo telinga berdenging atau tinitus merupakan...   \n",
       "\n",
       "                                       filtered_text  \\\n",
       "0  halo rizal radang tenggorokan umunya disebabka...   \n",
       "1  halo hellas cacar air penyakit disebabkan viru...   \n",
       "2  halo rory terimakasih ketahui gangguan kulit s...   \n",
       "3  alo afriyani terimakasih pertanyaannya kuku ja...   \n",
       "4  halo telinga berdenging tinitus sensasi penden...   \n",
       "\n",
       "                                               token  \\\n",
       "0  ['halo', 'rizal', 'radang', 'tenggorokan', 'um...   \n",
       "1  ['halo', 'hellas', 'cacar', 'air', 'penyakit',...   \n",
       "2  ['halo', 'rory', 'terimakasih', 'ketahui', 'ga...   \n",
       "3  ['alo', 'afriyani', 'terimakasih', 'pertanyaan...   \n",
       "4  ['halo', 'telinga', 'berdenging', 'tinitus', '...   \n",
       "\n",
       "                                      tokens_stemmed  \\\n",
       "0  ['halo', 'rizal', 'radang', 'tenggorok', 'umu'...   \n",
       "1  ['halo', 'hellas', 'cacar', 'air', 'sakit', 's...   \n",
       "2  ['halo', 'rory', 'terimakasih', 'tahu', 'gangg...   \n",
       "3  ['alo', 'afriyani', 'terimakasih', 'tanya', 'k...   \n",
       "4  ['halo', 'telinga', 'denging', 'tinitus', 'sen...   \n",
       "\n",
       "                                        Process_Data  \n",
       "0  halo rizal radang tenggorok umu sebab infeksi ...  \n",
       "1  halo hellas cacar air sakit sebab virus varise...  \n",
       "2  halo rory terimakasih tahu ganggu kulit rangka...  \n",
       "3  alo afriyani terimakasih tanya kuku jari kaki ...  \n",
       "4  halo telinga denging tinitus sensasi dengar de...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/kaggle/input/doctors-answer-text-dataset/Indo-Online Health Consultation-Medical Interview-Clean.csv', encoding='latin-1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da6328a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:42:20.472743Z",
     "iopub.status.busy": "2025-01-08T08:42:20.472393Z",
     "iopub.status.idle": "2025-01-08T08:42:20.491252Z",
     "shell.execute_reply": "2025-01-08T08:42:20.490494Z"
    },
    "papermill": {
     "duration": 0.031732,
     "end_time": "2025-01-08T08:42:20.492424",
     "exception": false,
     "start_time": "2025-01-08T08:42:20.460692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,) (400, 6)\n",
      "(100,) (100, 6)\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "train_labels = train_data.columns[2:8]\n",
    "val_labels = val_data.columns[2:8]\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['Text_Clean'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['Text_Clean'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190e0e7d",
   "metadata": {
    "papermill": {
     "duration": 0.011281,
     "end_time": "2025-01-08T08:42:20.515526",
     "exception": false,
     "start_time": "2025-01-08T08:42:20.504245",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BUILD DATASET & DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd09da3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:42:20.539142Z",
     "iopub.status.busy": "2025-01-08T08:42:20.538937Z",
     "iopub.status.idle": "2025-01-08T08:42:30.200168Z",
     "shell.execute_reply": "2025-01-08T08:42:30.199523Z"
    },
    "papermill": {
     "duration": 9.674572,
     "end_time": "2025-01-08T08:42:30.201680",
     "exception": false,
     "start_time": "2025-01-08T08:42:20.527108",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c07e422b8fe426c9f814fc3da2d73c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f991cfaa703431198b80b3a07a84510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53eb496c75f5456c906ace783eb784ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2af4ffa339ca42c29ae5c0db3efa45cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Define custom Dataset class\n",
    "class DoctorAnswerDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=256, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        labels = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(labels, dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "# Initialize BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d47795bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:42:30.227072Z",
     "iopub.status.busy": "2025-01-08T08:42:30.226588Z",
     "iopub.status.idle": "2025-01-08T08:42:30.231109Z",
     "shell.execute_reply": "2025-01-08T08:42:30.230290Z"
    },
    "papermill": {
     "duration": 0.01822,
     "end_time": "2025-01-08T08:42:30.232249",
     "exception": false,
     "start_time": "2025-01-08T08:42:30.214029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataloaders(X_train, y_train, X_val, y_val, sequence_length=256, num_workers=4):\n",
    "    train_dataset = DoctorAnswerDataset(X_train, y_train, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = DoctorAnswerDataset(X_val, y_val, tokenizer, max_length=sequence_length)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fe4b5c",
   "metadata": {
    "papermill": {
     "duration": 0.011721,
     "end_time": "2025-01-08T08:42:30.255759",
     "exception": false,
     "start_time": "2025-01-08T08:42:30.244038",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d330037",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:42:30.280110Z",
     "iopub.status.busy": "2025-01-08T08:42:30.279872Z",
     "iopub.status.idle": "2025-01-08T08:42:30.283499Z",
     "shell.execute_reply": "2025-01-08T08:42:30.282727Z"
    },
    "papermill": {
     "duration": 0.017248,
     "end_time": "2025-01-08T08:42:30.284746",
     "exception": false,
     "start_time": "2025-01-08T08:42:30.267498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c311d599",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:42:30.308842Z",
     "iopub.status.busy": "2025-01-08T08:42:30.308627Z",
     "iopub.status.idle": "2025-01-08T08:42:30.312850Z",
     "shell.execute_reply": "2025-01-08T08:42:30.312225Z"
    },
    "papermill": {
     "duration": 0.017602,
     "end_time": "2025-01-08T08:42:30.313982",
     "exception": false,
     "start_time": "2025-01-08T08:42:30.296380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        target_names=['1-FR', '2-GI', '3-PI', '4-DM', '5-EDTRB', '6-RE'],\n",
    "        zero_division=0\n",
    "    )  \n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46c5d006",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:42:30.338812Z",
     "iopub.status.busy": "2025-01-08T08:42:30.338594Z",
     "iopub.status.idle": "2025-01-08T08:42:30.349783Z",
     "shell.execute_reply": "2025-01-08T08:42:30.349181Z"
    },
    "papermill": {
     "duration": 0.024934,
     "end_time": "2025-01-08T08:42:30.350944",
     "exception": false,
     "start_time": "2025-01-08T08:42:30.326010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, metrics, trials, seed):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "\n",
    "    accelerator.print(accelerator.distributed_type)\n",
    "\n",
    "    with accelerator.main_process_first():\n",
    "        model = BertForSequenceClassification.from_pretrained(\n",
    "            'indobenchmark/indobert-base-p2',\n",
    "            num_labels=len(train_labels),\n",
    "            problem_type=\"multi_label_classification\"\n",
    "        )\n",
    "\n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Define DataLoaders\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    train_loader, val_loader = get_dataloaders(current_X_train, current_y_train, X_val, y_val)\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Prepare everything with Accelerator\n",
    "    model, optimizer, train_loader, val_loader = accelerator.prepare(\n",
    "        model, optimizer, train_loader, val_loader\n",
    "    )\n",
    "\n",
    "    best_result = None\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key != 'labels'}\n",
    "            labels = batch['labels']\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key != 'labels'}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "        result = compute_metrics(type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}))\n",
    "\n",
    "        if best_result is None or result['f1_micro'] >= best_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'{filename}-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "            best_result = result\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    accelerator.print(f\"Iteration {current_train_size}: Accuracy: {round(best_result['accuracy'], 4)}, F1 Micro: {round(best_result['f1_micro'], 4)}, F1 Macro: {round(best_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(best_result['report'])\n",
    "    accelerator.print(f\"Training completed in {duration} s\")\n",
    "\n",
    "    # Update the shared lists\n",
    "    if accelerator.is_local_main_process:\n",
    "        metrics[0].append(current_train_size)\n",
    "        metrics[1].append(best_result['accuracy'])\n",
    "        metrics[2].append(best_result['f1_micro'])\n",
    "        metrics[3].append(best_result['f1_macro'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad63bbf",
   "metadata": {
    "papermill": {
     "duration": 0.011466,
     "end_time": "2025-01-08T08:42:30.374073",
     "exception": false,
     "start_time": "2025-01-08T08:42:30.362607",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PLOT THE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67c9a678",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:42:30.398111Z",
     "iopub.status.busy": "2025-01-08T08:42:30.397910Z",
     "iopub.status.idle": "2025-01-08T08:42:30.403130Z",
     "shell.execute_reply": "2025-01-08T08:42:30.402322Z"
    },
    "papermill": {
     "duration": 0.018565,
     "end_time": "2025-01-08T08:42:30.404248",
     "exception": false,
     "start_time": "2025-01-08T08:42:30.385683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21ceea7",
   "metadata": {
    "papermill": {
     "duration": 0.011472,
     "end_time": "2025-01-08T08:42:30.427380",
     "exception": false,
     "start_time": "2025-01-08T08:42:30.415908",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QUERY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56960e17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:42:30.451726Z",
     "iopub.status.busy": "2025-01-08T08:42:30.451416Z",
     "iopub.status.idle": "2025-01-08T08:42:30.461025Z",
     "shell.execute_reply": "2025-01-08T08:42:30.460222Z"
    },
    "papermill": {
     "duration": 0.023208,
     "end_time": "2025-01-08T08:42:30.462247",
     "exception": false,
     "start_time": "2025-01-08T08:42:30.439039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def least_confidence_sampling(model, X_pool, train_indices, remaining_indices, sampling_dur, new_samples, trials, n_samples=min_increment):\n",
    "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "    device = accelerator.device\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    current_train_size = len(train_indices)\n",
    "    dataset = DoctorAnswerDataset(X_pool, np.zeros((len(X_pool), 6)), tokenizer, max_length=sequence_length)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    \n",
    "    uncertainties = []\n",
    "    for data in dataloader:\n",
    "        input_ids = data['input_ids'].to(device, non_blocking=True)\n",
    "        attention_mask = data['attention_mask'].to(device, non_blocking=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask).logits\n",
    "\n",
    "        for output in outputs:\n",
    "            probs = torch.sigmoid(output).cpu().numpy()\n",
    "            uncertainty = np.absolute(1 - np.max(probs))\n",
    "            uncertainties.append(uncertainty)\n",
    "    \n",
    "    uncertainties = np.array(uncertainties)\n",
    "    sorted_unc = np.argsort(uncertainties)\n",
    "    sorted_unc = sorted_unc[::-1]\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "\n",
    "    if accelerator.is_local_main_process:\n",
    "        threshold = np.percentile(uncertainties, 90)\n",
    "        items_greater_than_average = uncertainties[uncertainties >= threshold]\n",
    "        num_of_candidates = len(items_greater_than_average)\n",
    "    \n",
    "        # Check nearest checkpoint\n",
    "        nearest_cp = 0\n",
    "        for cp in checkpoints:\n",
    "            if cp > current_train_size:\n",
    "                nearest_cp = cp\n",
    "                break\n",
    "        \n",
    "        if num_of_candidates <= n_samples and n_samples < nearest_cp - current_train_size:\n",
    "            least_confident_indices = sorted_unc[:n_samples]\n",
    "        elif num_of_candidates > n_samples and num_of_candidates < nearest_cp - current_train_size:\n",
    "             least_confident_indices = sorted_unc[:max(n_samples, min(math.ceil(0.1*len(sorted_unc)), num_of_candidates))]\n",
    "        else:\n",
    "            least_confident_indices = sorted_unc[:nearest_cp - current_train_size]\n",
    "    \n",
    "            temp = train_indices.copy()\n",
    "            temp.extend(least_confident_indices)\n",
    "            \n",
    "            # Save acquired data up to checkpoint\n",
    "            acquired_data = pd.DataFrame({\n",
    "                'processed_text': [X_train[i] for i in temp],\n",
    "                '1-FR': [y_train[i][0] for i in temp],\n",
    "                '2-GI': [y_train[i][1] for i in temp],\n",
    "                '3-PI': [y_train[i][2] for i in temp],\n",
    "                '4-DM': [y_train[i][3] for i in temp],\n",
    "                '5-EDTRB': [y_train[i][4] for i in temp],\n",
    "                '6-RE': [y_train[i][5] for i in temp],\n",
    "            })\n",
    "    \n",
    "            acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "    \n",
    "        end_time = time.time() \n",
    "        duration = end_time - start_time\n",
    "    \n",
    "        sampling_dur.append(duration)\n",
    "        for i in least_confident_indices:\n",
    "            new_samples.append(remaining_indices[i])\n",
    "            \n",
    "        print(\"Nearest checkpoint:\", nearest_cp)\n",
    "        print(\"Threshold:\", threshold)\n",
    "        print(\"Samples above threshold:\", num_of_candidates)\n",
    "        print(\"Acquired samples:\", len(least_confident_indices))\n",
    "        print(f\"Sampling duration: {duration} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527baf70",
   "metadata": {
    "papermill": {
     "duration": 0.01145,
     "end_time": "2025-01-08T08:42:30.485438",
     "exception": false,
     "start_time": "2025-01-08T08:42:30.473988",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d0274b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:42:30.509358Z",
     "iopub.status.busy": "2025-01-08T08:42:30.509140Z",
     "iopub.status.idle": "2025-01-08T08:42:30.516742Z",
     "shell.execute_reply": "2025-01-08T08:42:30.515951Z"
    },
    "papermill": {
     "duration": 0.020949,
     "end_time": "2025-01-08T08:42:30.517973",
     "exception": false,
     "start_time": "2025-01-08T08:42:30.497024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i):\n",
    "    accuracies = manager.list()\n",
    "    f1_micros = manager.list()\n",
    "    f1_macros = manager.list()\n",
    "    data_used = manager.list()\n",
    "    sampling_dur = manager.list()\n",
    "    new_samples = manager.list()\n",
    "\n",
    "    set_seed(seed)\n",
    "    \n",
    "    print(\"===============================================\")\n",
    "    print(\"TRIAL {}\".format(i+1))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        # Train the model\n",
    "        args = (current_train_size, train_indices, (data_used, accuracies, f1_micros, f1_macros), i, seed)\n",
    "        notebook_launcher(train_model, args, num_processes=2)\n",
    "        \n",
    "        model = BertForSequenceClassification.from_pretrained(f'{filename}-{i + 1}-model')\n",
    "    \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples = manager.list()\n",
    "        sampling_args = (model, [X_train[i] for i in remaining_indices], train_indices, remaining_indices, sampling_dur, new_samples, i)\n",
    "        notebook_launcher(least_confidence_sampling, sampling_args, num_processes=2)\n",
    "        new_samples = list(new_samples)\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    args = (current_train_size, train_indices, (data_used, accuracies, f1_micros, f1_macros), i, seed)\n",
    "    notebook_launcher(train_model, args, num_processes=2)\n",
    "    data_used, accuracies, f1_micros, f1_macros, sampling_dur = list(data_used), list(accuracies), list(f1_micros), list(f1_macros), list(sampling_dur)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    \n",
    "    sampling_dur.insert(0, 0)\n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    results.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c08ddf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:42:30.542499Z",
     "iopub.status.busy": "2025-01-08T08:42:30.542281Z",
     "iopub.status.idle": "2025-01-08T08:42:30.545317Z",
     "shell.execute_reply": "2025-01-08T08:42:30.544737Z"
    },
    "papermill": {
     "duration": 0.016662,
     "end_time": "2025-01-08T08:42:30.546496",
     "exception": false,
     "start_time": "2025-01-08T08:42:30.529834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [50, 81, 14, 3, 94]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e8d599",
   "metadata": {
    "papermill": {
     "duration": 0.011706,
     "end_time": "2025-01-08T08:42:30.569824",
     "exception": false,
     "start_time": "2025-01-08T08:42:30.558118",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78de5ed9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:42:30.593816Z",
     "iopub.status.busy": "2025-01-08T08:42:30.593614Z",
     "iopub.status.idle": "2025-01-08T09:07:33.864212Z",
     "shell.execute_reply": "2025-01-08T09:07:33.863448Z"
    },
    "papermill": {
     "duration": 1503.283995,
     "end_time": "2025-01-08T09:07:33.865516",
     "exception": false,
     "start_time": "2025-01-08T08:42:30.581521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 1\n",
      "Random seed: 50\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0311b432c82a4afdbdca8195c90c52b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7417, Accuracy: 0.8438, F1 Micro: 0.8861, F1 Macro: 0.6509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6068, Accuracy: 0.931, F1 Micro: 0.949, F1 Macro: 0.6633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5321, Accuracy: 0.9609, F1 Micro: 0.9705, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4626, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3907, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3555, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3257, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2884, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2649, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2384, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 25: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 36.42771124839783 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.1627177119255066\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 38\n",
      "Sampling duration: 4.278597831726074 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7419, Accuracy: 0.8763, F1 Micro: 0.9098, F1 Macro: 0.6629\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6067, Accuracy: 0.9492, F1 Micro: 0.962, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5587, Accuracy: 0.9648, F1 Micro: 0.9733, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4888, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4306, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3835, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3422, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3237, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2914, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2713, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 63: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 36.54919099807739 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.1376049041748047\n",
      "Samples above threshold: 34\n",
      "Acquired samples: 34\n",
      "Sampling duration: 4.1805031299591064 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6862, Accuracy: 0.9336, F1 Micro: 0.9509, F1 Macro: 0.6643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5233, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4162, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3457, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2989, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2575, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2396, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2283, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2156, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2213, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 97: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 42.56542086601257 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.06999672651290893\n",
      "Samples above threshold: 31\n",
      "Acquired samples: 31\n",
      "Sampling duration: 4.063357830047607 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6829, Accuracy: 0.944, F1 Micro: 0.9582, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5297, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4124, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3479, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2923, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2624, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2672, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2352, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2317, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2089, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 128: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 42.327741861343384 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.06860350370407105\n",
      "Samples above threshold: 28\n",
      "Acquired samples: 28\n",
      "Sampling duration: 3.842768669128418 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6331, Accuracy: 0.9648, F1 Micro: 0.9733, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4276, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3144, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.283, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2489, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2157, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2136, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1915, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1925, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1966, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 156: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 48.384676933288574 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.043608492612838744\n",
      "Samples above threshold: 25\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.6363704204559326 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6411, Accuracy: 0.9635, F1 Micro: 0.9724, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4327, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3239, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2689, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2419, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.221, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2121, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2045, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1849, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1876, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 181: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 48.9534170627594 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.04445294141769409\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 22\n",
      "Sampling duration: 3.504908800125122 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6027, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3709, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2807, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2177, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2197, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1914, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1933, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2026, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1648, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1689, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 203: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 52.8321418762207 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.030587029457092286\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 20\n",
      "Sampling duration: 3.189310073852539 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5987, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3727, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2714, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2385, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2272, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2169, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1982, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1908, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.188, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1846, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 223: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 53.33337116241455 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.029691600799560548\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 18\n",
      "Sampling duration: 3.0724949836730957 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6043, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3634, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2873, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2358, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2146, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2059, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1768, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1807, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1894, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1916, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 241: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 53.86127185821533 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.030096280574798583\n",
      "Samples above threshold: 16\n",
      "Acquired samples: 9\n",
      "Sampling duration: 2.7814738750457764 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6081, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3808, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2739, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2389, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.221, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2041, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2004, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1879, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1865, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1932, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 250: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 53.56648302078247 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 0.029949796199798585\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 15\n",
      "Sampling duration: 2.684471607208252 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5622, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.341, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2399, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2205, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.207, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1882, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1921, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1657, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1809, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1744, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 265: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 58.87500977516174 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 0.024904346466064452\n",
      "Samples above threshold: 14\n",
      "Acquired samples: 14\n",
      "Sampling duration: 3.05229115486145 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5606, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3282, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2554, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2128, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2081, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1815, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1688, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.192, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1927, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1685, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 279: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 60.86040949821472 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 0.023161649703979492\n",
      "Samples above threshold: 13\n",
      "Acquired samples: 13\n",
      "Sampling duration: 2.858572483062744 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5661, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3236, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.245, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2199, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1966, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1863, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1768, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1718, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1761, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1661, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 292: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 60.756765604019165 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 0.02432616353034973\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 8\n",
      "Sampling duration: 2.7917981147766113 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5592, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3309, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2379, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2108, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2001, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1787, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1799, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1781, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1798, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.184, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 300: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.40002107620239 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 0.023432886600494383\n",
      "Samples above threshold: 10\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.6601006984710693 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5661, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3141, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2495, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2168, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1918, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.197, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1844, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1958, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1755, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1726, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 310: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.10989761352539 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 0.023405629396438598\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.904391050338745 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5597, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3248, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.236, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.211, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1989, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2096, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1766, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1866, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1811, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1733, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 320: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 58.984243869781494 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 0.023689502477645875\n",
      "Samples above threshold: 8\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.346266984939575 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5361, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2985, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2281, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2094, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1941, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1908, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1854, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1766, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1832, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1519, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 330: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.643253803253174 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 0.02045876979827881\n",
      "Samples above threshold: 7\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.7567033767700195 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5278, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2946, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2206, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2203, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.214, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1878, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1669, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1766, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1602, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1474, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 340: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.0781192779541 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 0.020082682371139526\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.715480089187622 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5317, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2966, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2149, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2044, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2084, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1739, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1756, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1557, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1684, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1713, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 350: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.7929265499115 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.01987435817718506\n",
      "Samples above threshold: 5\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.5385382175445557 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5269, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2897, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2213, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1935, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1851, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1767, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.182, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1779, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1579, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1644, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 360: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.1134397983551 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.019333499670028686\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.4390881061553955 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.53, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3037, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.218, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2125, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1838, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1752, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1665, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1753, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1549, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1576, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 370: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.207167863845825 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.019881397485733032\n",
      "Samples above threshold: 3\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.3302838802337646 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5312, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2901, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2214, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1865, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1688, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1816, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1698, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1688, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1564, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1584, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 380: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.61255598068237 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.020325392484664917\n",
      "Samples above threshold: 2\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.205967903137207 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4998, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2535, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1994, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1795, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1822, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.154, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1693, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1552, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1568, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1538, Accuracy: 0.9674, F1 Micro: 0.9753, F1 Macro: 0.6541\n",
      "Iteration 390: Accuracy: 0.9674, F1 Micro: 0.9753, F1 Macro: 0.6541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 68.1839509010315 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.018392139673233034\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.190972089767456 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4999, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2566, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2179, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1869, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1552, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1645, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1664, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1664, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1617, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1544, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 400: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 67.38610219955444 s\n",
      "Total sampling time: 62.02 seconds\n",
      "Total runtime: 1502.4217801094055 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68c5c17",
   "metadata": {
    "papermill": {
     "duration": 0.081671,
     "end_time": "2025-01-08T09:07:34.030889",
     "exception": false,
     "start_time": "2025-01-08T09:07:33.949218",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76a9e646",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T09:07:34.193581Z",
     "iopub.status.busy": "2025-01-08T09:07:34.193266Z",
     "iopub.status.idle": "2025-01-08T09:32:27.296495Z",
     "shell.execute_reply": "2025-01-08T09:32:27.295761Z"
    },
    "papermill": {
     "duration": 1493.186453,
     "end_time": "2025-01-08T09:32:27.297821",
     "exception": false,
     "start_time": "2025-01-08T09:07:34.111368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 2\n",
      "Random seed: 81\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7759, Accuracy: 0.6276, F1 Micro: 0.7129, F1 Macro: 0.4886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6568, Accuracy: 0.9193, F1 Micro: 0.9405, F1 Macro: 0.6604\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5443, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4694, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3976, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3515, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.312, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2775, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2811, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2409, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 25: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 36.46837067604065 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.1618048906326294\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 38\n",
      "Sampling duration: 4.951330900192261 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7684, Accuracy: 0.6263, F1 Micro: 0.7116, F1 Macro: 0.4878\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.655, Accuracy: 0.9193, F1 Micro: 0.9405, F1 Macro: 0.6604\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5414, Accuracy: 0.9648, F1 Micro: 0.9733, F1 Macro: 0.6527\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4596, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.405, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3574, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3179, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2835, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2849, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2551, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 63: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 35.82608485221863 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.15117276906967164\n",
      "Samples above threshold: 34\n",
      "Acquired samples: 34\n",
      "Sampling duration: 4.580508232116699 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7099, Accuracy: 0.8932, F1 Micro: 0.9221, F1 Macro: 0.6537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4993, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3906, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3112, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2703, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2519, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2255, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2108, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2056, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1637, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 97: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 42.603126764297485 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.06398411989212036\n",
      "Samples above threshold: 31\n",
      "Acquired samples: 31\n",
      "Sampling duration: 4.4172327518463135 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7055, Accuracy: 0.8815, F1 Micro: 0.9149, F1 Macro: 0.6563\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5018, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3813, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3003, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2428, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2339, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2219, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.231, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2042, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2213, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 128: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 41.72351050376892 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.062289655208587646\n",
      "Samples above threshold: 28\n",
      "Acquired samples: 28\n",
      "Sampling duration: 4.1346728801727295 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6531, Accuracy: 0.9648, F1 Micro: 0.9733, F1 Macro: 0.6527\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4083, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2933, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2463, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2338, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2075, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1908, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1844, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1759, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1586, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 156: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 48.042574882507324 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.04279126524925232\n",
      "Samples above threshold: 25\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.875012159347534 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6496, Accuracy: 0.9648, F1 Micro: 0.9733, F1 Macro: 0.6527\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4098, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2988, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2595, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2225, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1972, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1845, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.165, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.163, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1506, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 181: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 49.92800188064575 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.04335200786590576\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 22\n",
      "Sampling duration: 3.7967264652252197 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.602, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3335, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2289, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2183, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1959, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1862, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1787, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1527, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1707, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1467, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 203: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 53.67186188697815 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.03129421472549439\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 20\n",
      "Sampling duration: 3.406306028366089 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6013, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3401, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2522, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2108, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.201, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1861, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1892, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1775, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1742, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1689, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 223: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 53.13518452644348 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.03165106773376465\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 18\n",
      "Sampling duration: 3.057745933532715 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5997, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3487, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2738, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2157, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2154, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1956, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1769, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1687, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1603, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1727, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 241: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 53.31655526161194 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.029522633552551268\n",
      "Samples above threshold: 16\n",
      "Acquired samples: 9\n",
      "Sampling duration: 2.8669159412384033 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.603, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.348, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2484, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2262, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1975, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1995, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1913, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.166, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1742, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1754, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 250: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 53.55137777328491 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 0.030573666095733643\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 15\n",
      "Sampling duration: 2.775709629058838 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5644, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3083, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2215, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1985, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1883, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1862, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1519, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.161, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.151, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1536, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 265: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 58.221991300582886 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 0.025609242916107177\n",
      "Samples above threshold: 14\n",
      "Acquired samples: 14\n",
      "Sampling duration: 2.5868234634399414 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5583, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3094, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2295, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1867, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1844, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1775, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1812, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1736, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1752, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1848, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 279: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 58.45638155937195 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 0.024560749530792236\n",
      "Samples above threshold: 13\n",
      "Acquired samples: 13\n",
      "Sampling duration: 2.428964853286743 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5612, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2873, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2143, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1956, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1715, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1553, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1616, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1562, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.154, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1703, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 292: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.32547354698181 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 0.024780863523483278\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 8\n",
      "Sampling duration: 2.3511264324188232 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5595, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3048, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2211, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1915, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1897, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1629, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1648, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1554, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1516, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1591, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 300: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.286027669906616 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 0.02514849305152893\n",
      "Samples above threshold: 10\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.214484691619873 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5619, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2978, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2259, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1975, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1729, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1752, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1654, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1492, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1591, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1446, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 310: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.35122990608215 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 0.024150359630584716\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.031949520111084 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5589, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2088, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1911, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1723, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1643, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1677, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.159, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1787, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1522, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 320: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 57.93016290664673 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 0.025621956586837767\n",
      "Samples above threshold: 8\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.014047622680664 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5363, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2765, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2109, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1795, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.164, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1549, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1673, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.15, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.159, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1426, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 330: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.32444739341736 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 0.022048872709274293\n",
      "Samples above threshold: 7\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.8913419246673584 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5304, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2619, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2223, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1856, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1698, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1751, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1655, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1694, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1694, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1446, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 340: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 62.996681451797485 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 0.022201108932495116\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.687584638595581 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5285, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2686, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2111, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1813, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1717, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1655, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1562, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.181, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1503, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1497, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 350: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.43909215927124 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.022574907541275026\n",
      "Samples above threshold: 5\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.6433265209197998 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5308, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2776, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2129, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1742, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1696, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1615, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1596, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1449, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.146, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1428, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 360: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.916924715042114 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.02245994806289673\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.457798719406128 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5306, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2767, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2012, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1833, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1783, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1813, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1728, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.153, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1524, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1638, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 370: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 62.75017738342285 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.0208654522895813\n",
      "Samples above threshold: 3\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.3655006885528564 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5312, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2626, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2158, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1915, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1855, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.167, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1687, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1686, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1562, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1457, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 380: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.831637382507324 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.021795177459716798\n",
      "Samples above threshold: 2\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.239311695098877 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4961, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2442, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2057, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1793, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1837, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.157, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1658, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.155, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.164, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1477, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 390: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 67.7063672542572 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.02004179358482361\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.1934750080108643 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5061, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2538, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2073, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1761, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1623, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1719, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1548, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1643, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1494, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1634, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 400: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 67.94014191627502 s\n",
      "Total sampling time: 61.97 seconds\n",
      "Total runtime: 1492.3649353981018 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACCoAAAHqCAYAAADInz0eAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACJdUlEQVR4nOz9fZjVZbk3/r9nBmYGRdBEhgdRkDSfQVEJLc07lNTb1LuUdrghKkscEmXvFErBbMvULglTErVNkmFSPuUdhts9lmWiJGg7b0U0TNgkoF9zJlEBZ9bvj34uG3mIQVjA8Hodx+c4XNc6r+tzXsM8nE3nXJ+yQqFQCAAAAAAAAABACZRv6wQAAAAAAAAAgJ2HRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJaNRAQAAAAAAAAAoGY0KAAAAAAAAAEDJaFQAAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAYLv2mc98Jr17997WaQAAAABbiEYFgM30ve99L2VlZRk4cOC2TgUAAN6Tm2++OWVlZeu9xo0bV4z7z//8z3zuc5/LoYcemoqKilY3D7y95uc///n1vv/Vr361GPPyyy+/ly0BALATUc8C7HjabesEAHZUM2fOTO/evTNv3rw899xzef/737+tUwIAgPfkyiuvTJ8+fVqMHXroocX/vvXWWzNr1qwceeSR6dGjx2bdo7q6OnfccUe+973vpbKyssV7P/7xj1NdXZ0333yzxfhNN92U5ubmzbofAAA7j+21ngVgXU5UANgMzz//fB5++OFMnjw5e+21V2bOnLmtU1qvVatWbesUAADYgZxyyik599xzW1z9+/cvvj9p0qQ0Njbmt7/9bfr167dZ9/jYxz6WxsbG/OIXv2gx/vDDD+f555/Paaedts6c9u3bp6qqarPu9/eam5v90hgAoA3bXuvZrc3vgYEdkUYFgM0wc+bM7LHHHjnttNPyyU9+cr2NCq+++mouvvji9O7dO1VVVdl7770zfPjwFkd+vfnmm7niiitywAEHpLq6Ot27d8//+T//J3/84x+TJL/61a9SVlaWX/3qVy3W/tOf/pSysrLcfPPNxbHPfOYz6dixY/74xz/m1FNPzW677ZZhw4YlSX7zm9/k7LPPzj777JOqqqr06tUrF198cd5444118l64cGHOOeec7LXXXunQoUM+8IEP5Ktf/WqS5Je//GXKyspy1113rTPv1ltvTVlZWebOndvqjycAADuGHj16pH379u9pjZ49e+b444/Prbfe2mJ85syZOeyww1r8xdvbPvOZz6xzLG9zc3OuueaaHHbYYamurs5ee+2Vj33sY3nssceKMWVlZRk9enRmzpyZQw45JFVVVZkzZ06S5PHHH88pp5ySTp06pWPHjvnoRz+aRx555D3tDQCA7du2qme31O9nk+SKK65IWVlZnnrqqXz605/OHnvskQ996ENJkrfeeitf//rX07dv31RVVaV37975yle+ktWrV7+nPQNsDR79ALAZZs6cmf/zf/5PKisr80//9E+5/vrr87vf/S5HH310kuS1117Lhz/84Tz99NP57Gc/myOPPDIvv/xy7rnnnvzP//xPunTpkqampvzv//2/U19fn0996lMZM2ZM/vrXv+b+++/Pk08+mb59+7Y6r7feeitDhgzJhz70oXz729/OLrvskiT56U9/mtdffz2jRo3KnnvumXnz5uXaa6/N//zP/+SnP/1pcf5///d/58Mf/nDat2+fL3zhC+ndu3f++Mc/5v/+3/+bq666Kh/5yEfSq1evzJw5M2edddY6H5O+fftm0KBB7+EjCwDAttTQ0LDOs3S7dOmyxe/z6U9/OmPGjMlrr72Wjh075q233spPf/rTjB07dpNPPPjc5z6Xm2++Oaeccko+//nP56233spvfvObPPLIIznqqKOKcQ888EB+8pOfZPTo0enSpUt69+6d//f//l8+/OEPp1OnTrnkkkvSvn373HDDDfnIRz6SBx98MAMHDtziewYAYOvbXuvZLfX72b939tlnZ//998+kSZNSKBSSJJ///OczY8aMfPKTn8y//Mu/5NFHH01dXV2efvrp9f7xGcC2pFEBoJXmz5+fhQsX5tprr02SfOhDH8ree++dmTNnFhsVvvWtb+XJJ5/MnXfe2eL/0L/sssuKReMPf/jD1NfXZ/Lkybn44ouLMePGjSvGtNbq1atz9tlnp66ursX4N7/5zXTo0KH4+gtf+ELe//735ytf+UqWLFmSffbZJ0nypS99KYVCIQsWLCiOJck3vvGNJH/7i7Rzzz03kydPTkNDQzp37pwkeemll/Kf//mfLTp7AQDY8QwePHidsc2tTTfmk5/8ZEaPHp2777475557bv7zP/8zL7/8cv7pn/4pP/jBD/7h/F/+8pe5+eabc+GFF+aaa64pjv/Lv/zLOvk+88wz+cMf/pCDDz64OHbWWWdl7dq1eeihh7LffvslSYYPH54PfOADueSSS/Lggw9uoZ0CAFBK22s9u6V+P/v3+vXr1+JUh9///veZMWNGPv/5z+emm25KklxwwQXp2rVrvv3tb+eXv/xlTjzxxC32MQB4rzz6AaCVZs6cmZqammJRV1ZWlqFDh+a2225LU1NTkuSOO+5Iv3791jl14O34t2O6dOmSL33pSxuM2RyjRo1aZ+zvi+BVq1bl5ZdfzrHHHptCoZDHH388yd+aDX7961/ns5/9bIsi+N35DB8+PKtXr87tt99eHJs1a1beeuutnHvuuZudNwAA297UqVNz//33t7i2hj322CMf+9jH8uMf/zjJ3x4jduyxx2bffffdpPl33HFHysrKMnHixHXee3ctfcIJJ7RoUmhqasp//ud/5swzzyw2KSRJ9+7d8+lPfzoPPfRQGhsbN2dbAABsY9trPbslfz/7tvPPP7/F63vvvTdJMnbs2Bbj//Iv/5IkmT17dmu2CLDVOVEBoBWamppy22235cQTT8zzzz9fHB84cGCuvvrq1NfX5+STT84f//jHfOITn9joWn/84x/zgQ98IO3abblvxe3atcvee++9zviSJUsyYcKE3HPPPfnLX/7S4r2GhoYkyeLFi5Nkvc9Q+3sHHnhgjj766MycOTOf+9znkvyteeODH/xg3v/+92+JbQAAsI0cc8wxLR6bsDV9+tOfzj//8z9nyZIlufvuu/Pv//7vmzz3j3/8Y3r06JH3ve99/zC2T58+LV6/9NJLef311/OBD3xgndiDDjoozc3NWbp0aQ455JBNzgcAgO3D9lrPbsnfz77t3XXuCy+8kPLy8nV+R9utW7fsvvvueeGFFzZpXYBS0agA0AoPPPBAXnzxxdx222257bbb1nl/5syZOfnkk7fY/TZ0ssLbJze8W1VVVcrLy9eJPemkk/LKK6/k0ksvzYEHHphdd901y5Yty2c+85k0Nze3Oq/hw4dnzJgx+Z//+Z+sXr06jzzySK677rpWrwMAwM7r4x//eKqqqjJixIisXr0655xzzla5z9//9RoAAGwpm1rPbo3fzyYbrnPfy2m9AKWkUQGgFWbOnJmuXbtm6tSp67x355135q677sq0adPSt2/fPPnkkxtdq2/fvnn00Uezdu3atG/ffr0xe+yxR5Lk1VdfbTHemu7XP/zhD1m0aFFmzJiR4cOHF8fffezZ28fe/qO8k+RTn/pUxo4dmx//+Md544030r59+wwdOnSTcwIAgA4dOuTMM8/Mj370o5xyyinp0qXLJs/t27dv7rvvvrzyyiubdKrC39trr72yyy675JlnnlnnvYULF6a8vDy9evVq1ZoAAOx8NrWe3Rq/n12ffffdN83NzXn22Wdz0EEHFcdXrFiRV199dZMfswZQKuX/OASAJHnjjTdy55135n//7/+dT37yk+tco0ePzl//+tfcc889+cQnPpHf//73ueuuu9ZZp1AoJEk+8YlP5OWXX17vSQRvx+y7776pqKjIr3/96xbvf+9739vkvCsqKlqs+fZ/X3PNNS3i9tprrxx//PGZPn16lixZst583talS5eccsop+dGPfpSZM2fmYx/7WKt+sQwAAEnyr//6r5k4cWIuv/zyVs37xCc+kUKhkK997WvrvPfu2vXdKioqcvLJJ+dnP/tZ/vSnPxXHV6xYkVtvvTUf+tCH0qlTp1blAwDAzmlT6tmt8fvZ9Tn11FOTJFOmTGkxPnny5CTJaaed9g/XACglJyoAbKJ77rknf/3rX/Pxj398ve9/8IMfzF577ZWZM2fm1ltvze23356zzz47n/3sZzNgwIC88sorueeeezJt2rT069cvw4cPzw9/+MOMHTs28+bNy4c//OGsWrUq//Vf/5ULLrggZ5xxRjp37pyzzz471157bcrKytK3b9/8/Oc/z8qVKzc57wMPPDB9+/bNv/7rv2bZsmXp1KlT7rjjjnWehZYk3/3ud/OhD30oRx55ZL7whS+kT58++dOf/pTZs2fniSeeaBE7fPjwfPKTn0ySfP3rX9/0DyQAADus//7v/84999yTJHnuuefS0NCQf/u3f0uS9OvXL6effnqr1uvXr1/69evX6jxOPPHE/PM//3O++93v5tlnn83HPvaxNDc35ze/+U1OPPHEjB49eqPz/+3f/i33339/PvShD+WCCy5Iu3btcsMNN2T16tUbfbYwAAA7tm1Rz26t38+uL5cRI0bkxhtvzKuvvpoTTjgh8+bNy4wZM3LmmWfmxBNPbNXeALY2jQoAm2jmzJmprq7OSSedtN73y8vLc9ppp2XmzJlZvXp1fvOb32TixIm56667MmPGjHTt2jUf/ehHs/feeyf5Wyftvffem6uuuiq33npr7rjjjuy555750Ic+lMMOO6y47rXXXpu1a9dm2rRpqaqqyjnnnJNvfetbOfTQQzcp7/bt2+f//t//mwsvvDB1dXWprq7OWWedldGjR69TRPfr1y+PPPJILr/88lx//fV58803s++++673+Wqnn3569thjjzQ3N2+weQMAgLZlwYIF6/y12NuvR4wY0epf7L4XP/jBD3L44YfnP/7jP/LlL385nTt3zlFHHZVjjz32H8495JBD8pvf/Cbjx49PXV1dmpubM3DgwPzoRz/KwIEDS5A9AADbwraoZ7fW72fX5/vf/37222+/3HzzzbnrrrvSrVu3jB8/PhMnTtzi+wJ4r8oKm3JeDAC8y1tvvZUePXrk9NNPz3/8x39s63QAAAAAAADYQZRv6wQA2DHdfffdeemllzJ8+PBtnQoAAAAAAAA7ECcqANAqjz76aP77v/87X//619OlS5csWLBgW6cEAAAAAADADsSJCgC0yvXXX59Ro0ala9eu+eEPf7it0wEAAAAAAGAH40QFAAAAAAAAAKBknKgAAAAAAAAAAJSMRgUAAAAAAAAAoGTabesEtpTm5ub8+c9/zm677ZaysrJtnQ4AAFtRoVDIX//61/To0SPl5W2v91ZtCwCw81DbAgDQVrSmtm0zjQp//vOf06tXr22dBgAAJbR06dLsvffe2zqNLU5tCwCw81HbAgDQVmxKbdtmGhV22223JH/bdKdOnbZxNgAAbE2NjY3p1atXsQZsa9S2AAA7D7UtAABtRWtq2zbTqPD2sWGdOnVS8AIA7CTa6tGxalsAgJ2P2hYAgLZiU2rbtvfQMwAAAAAAAABgu6VRAQAAAAAAAAAoGY0KAAAAAAAAAEDJaFQAAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAAAAAAKBkNCoAAAAAAAAAACWjUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAAAAAAAAQMloVAAAAAAAAAAASkajAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAHZav/71r3P66aenR48eKSsry9133/0P5/zqV7/KkUcemaqqqrz//e/PzTff3OL9urq6HH300dltt93StWvXnHnmmXnmmWe2zgYAAAAAAHZAGhUAANhprVq1Kv369cvUqVM3Kf7555/PaaedlhNPPDFPPPFELrroonz+85/PfffdV4x58MEHU1tbm0ceeST3339/1q5dm5NPPjmrVq3aWtsAAAAAANihtNvWCQAAwLZyyimn5JRTTtnk+GnTpqVPnz65+uqrkyQHHXRQHnrooXznO9/JkCFDkiRz5sxpMefmm29O165dM3/+/Bx//PFbLnkAAAAAgB2UExUAAGATzZ07N4MHD24xNmTIkMydO3eDcxoaGpIk73vf+zYYs3r16jQ2Nra4AAAAAADaKo0KAACwiZYvX56ampoWYzU1NWlsbMwbb7yxTnxzc3MuuuiiHHfccTn00EM3uG5dXV06d+5cvHr16rXFcwcAAAAA2F5oVAAAgK2ktrY2Tz75ZG677baNxo0fPz4NDQ3Fa+nSpSXKEAAAAACg9Npt6wQAAGBH0a1bt6xYsaLF2IoVK9KpU6d06NChxfjo0aPz85//PL/+9a+z9957b3TdqqqqVFVVbfF8AQAAAAC2R05UAACATTRo0KDU19e3GLv//vszaNCg4utCoZDRo0fnrrvuygMPPJA+ffqUOk0AAAAAgO2aRgUAAHZar732Wp544ok88cQTSZLnn38+TzzxRJYsWZLkb49kGD58eDH+/PPPz+LFi3PJJZdk4cKF+d73vpef/OQnufjii4sxtbW1+dGPfpRbb701u+22W5YvX57ly5fnjTfeKOneAAAAAAC2VxoVAADYaT322GM54ogjcsQRRyRJxo4dmyOOOCITJkxIkrz44ovFpoUk6dOnT2bPnp37778//fr1y9VXX53vf//7GTJkSDHm+uuvT0NDQz7ykY+ke/fuxWvWrFml3RwAAAAAwHaq3bZOAAAAtpWPfOQjKRQKG3z/5ptvXu+cxx9/fINzNrYeAAAAAABOVAAAAAAAAAAASkijAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJaNRAQAAAAAAAAAoGY0KAAAAAAAAAEDJaFQAAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAAIA2YOrUqendu3eqq6szcODAzJs3b6Pxr776ampra9O9e/dUVVXlgAMOyL333lt8v6mpKZdffnn69OmTDh06pG/fvvn617+eQqGwtbcCAEAb125bJwAAAAAAwHsza9asjB07NtOmTcvAgQMzZcqUDBkyJM8880y6du26TvyaNWty0kknpWvXrrn99tvTs2fPvPDCC9l9992LMd/85jdz/fXXZ8aMGTnkkEPy2GOPZeTIkencuXMuvPDCEu4OAIC2RqMCAAAAAMAObvLkyTnvvPMycuTIJMm0adMye/bsTJ8+PePGjVsnfvr06XnllVfy8MMPp3379kmS3r17t4h5+OGHc8YZZ+S0004rvv/jH//4H57UAAAA/4hHPwAAAAAA7MDWrFmT+fPnZ/DgwcWx8vLyDB48OHPnzl3vnHvuuSeDBg1KbW1tampqcuihh2bSpElpamoqxhx77LGpr6/PokWLkiS///3v89BDD+WUU07ZYC6rV69OY2NjiwsAAN7NiQoAAAAAADuwl19+OU1NTampqWkxXlNTk4ULF653zuLFi/PAAw9k2LBhuffee/Pcc8/lggsuyNq1azNx4sQkybhx49LY2JgDDzwwFRUVaWpqylVXXZVhw4ZtMJe6urp87Wtf23KbAwCgTXKiAgAAAADATqa5uTldu3bNjTfemAEDBmTo0KH56le/mmnTphVjfvKTn2TmzJm59dZbs2DBgsyYMSPf/va3M2PGjA2uO378+DQ0NBSvpUuXlmI7AADsYJyoAAAAAACwA+vSpUsqKiqyYsWKFuMrVqxIt27d1june/fuad++fSoqKopjBx10UJYvX541a9aksrIyX/7ylzNu3Lh86lOfSpIcdthheeGFF1JXV5cRI0asd92qqqpUVVVtoZ0BANBWOVEBAAAAAGAHVllZmQEDBqS+vr441tzcnPr6+gwaNGi9c4477rg899xzaW5uLo4tWrQo3bt3T2VlZZLk9ddfT3l5y18hV1RUtJgDAACbQ6MCAAAAAMAObuzYsbnpppsyY8aMPP300xk1alRWrVqVkSNHJkmGDx+e8ePHF+NHjRqVV155JWPGjMmiRYsye/bsTJo0KbW1tcWY008/PVdddVVmz56dP/3pT7nrrrsyefLknHXWWSXfHwAAbYtHPwAAAAAA7OCGDh2al156KRMmTMjy5cvTv3//zJkzJzU1NUmSJUuWtDgdoVevXrnvvvty8cUX5/DDD0/Pnj0zZsyYXHrppcWYa6+9NpdffnkuuOCCrFy5Mj169MgXv/jFTJgwoeT7AwCgbSkrFAqFbZ3EltDY2JjOnTunoaEhnTp12tbpAACwFbX12q+t7w8AgHe09dqvre8PAIB3tKb28+gHAAAAAAAAAKBkNCoAAAAAAAAAACWjUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZFrdqPDrX/86p59+enr06JGysrLcfffd/3DOr371qxx55JGpqqrK+9///tx8883rxEydOjW9e/dOdXV1Bg4cmHnz5rU2NQAAAAAAAABgO9fqRoVVq1alX79+mTp16ibFP//88znttNNy4okn5oknnshFF12Uz3/+87nvvvuKMbNmzcrYsWMzceLELFiwIP369cuQIUOycuXK1qYHAAAAAAAAAGzH2rV2wimnnJJTTjllk+OnTZuWPn365Oqrr06SHHTQQXnooYfyne98J0OGDEmSTJ48Oeedd15GjhxZnDN79uxMnz4948aNa22KAAAAAAAAAMB2qtUnKrTW3LlzM3jw4BZjQ4YMydy5c5Mka9asyfz581vElJeXZ/DgwcUYAAAAAAAAAKBtaPWJCq21fPny1NTUtBirqalJY2Nj3njjjfzlL39JU1PTemMWLly4wXVXr16d1atXF183NjZu2cQBAAAAAAAAgC1uq5+osLXU1dWlc+fOxatXr17bOiUAAAAAAAAA4B/Y6o0K3bp1y4oVK1qMrVixIp06dUqHDh3SpUuXVFRUrDemW7duG1x3/PjxaWhoKF5Lly7dKvkDAAAAAAAAAFvOVm9UGDRoUOrr61uM3X///Rk0aFCSpLKyMgMGDGgR09zcnPr6+mLM+lRVVaVTp04tLgAAAAAAAABg+9bqRoXXXnstTzzxRJ544okkyfPPP58nnngiS5YsSfK3kw6GDx9ejD///POzePHiXHLJJVm4cGG+973v5Sc/+UkuvvjiYszYsWNz0003ZcaMGXn66aczatSorFq1KiNHjnyP2wMAAAAAAAAAtiftWjvhsccey4knnlh8PXbs2CTJiBEjcvPNN+fFF18sNi0kSZ8+fTJ79uxcfPHFueaaa7L33nvn+9//foYMGVKMGTp0aF566aVMmDAhy5cvT//+/TNnzpzU1NS8l70BAAAAAAAAANuZskKhUNjWSWwJjY2N6dy5cxoaGjwGAgCgjWvrtV9b3x8AAO9o67VfW98fAADvaE3t1+pHPwAAAAAAAAAAbC6NCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAAAAAAAAQMloVAAAAAAAAAAASkajAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJaNRAQAAAAAAAAAoGY0KAAAAAAAAAEDJaFQAAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAADATuvXv/51Tj/99PTo0SNlZWW5++67/+GcX/3qVznyyCNTVVWV97///bn55pvXiZk6dWp69+6d6urqDBw4MPPmzdvyyQMAAAAA7KA0KgAAsNNatWpV+vXrl6lTp25S/PPPP5/TTjstJ554Yp544olcdNFF+fznP5/77ruvGDNr1qyMHTs2EydOzIIFC9KvX78MGTIkK1eu3FrbAAAAAADYobTb1gkAAMC2csopp+SUU07Z5Php06alT58+ufrqq5MkBx10UB566KF85zvfyZAhQ5IkkydPznnnnZeRI0cW58yePTvTp0/PuHHjtvwmAAAAAAB2ME5UAACATTR37twMHjy4xdiQIUMyd+7cJMmaNWsyf/78FjHl5eUZPHhwMQYAAAAAYGenUQEAADbR8uXLU1NT02KspqYmjY2NeeONN/Lyyy+nqalpvTHLly/f4LqrV69OY2NjiwsAAFpr6tSp6d27d6qrqzNw4MDMmzdvo/Gvvvpqamtr071791RVVeWAAw7IvffeW3y/d+/eKSsrW+eqra3d2lsBAKCN06gAAADbWF1dXTp37ly8evXqta1TAgBgBzNr1qyMHTs2EydOzIIFC9KvX78MGTIkK1euXG/8mjVrctJJJ+VPf/pTbr/99jzzzDO56aab0rNnz2LM7373u7z44ovF6/7770+SnH322SXZEwAAbVe7bZ0AAADsKLp165YVK1a0GFuxYkU6deqUDh06pKKiIhUVFeuN6dat2wbXHT9+fMaOHVt83djYqFkBAIBWmTx5cs4777yMHDkySTJt2rTMnj0706dPz7hx49aJnz59el555ZU8/PDDad++fZK/naDw9/baa68Wr7/xjW+kb9++OeGEE7bOJgAA2Gk4UQEAADbRoEGDUl9f32Ls/vvvz6BBg5IklZWVGTBgQIuY5ubm1NfXF2PWp6qqKp06dWpxAQDAplqzZk3mz5+fwYMHF8fKy8szePDgzJ07d71z7rnnngwaNCi1tbWpqanJoYcemkmTJqWpqWmD9/jRj36Uz372sykrK9sq+wAAYOfhRAUAAHZar732Wp577rni6+effz5PPPFE3ve+92WfffbJ+PHjs2zZsvzwhz9Mkpx//vm57rrrcskll+Szn/1sHnjggfzkJz/J7Nmzi2uMHTs2I0aMyFFHHZVjjjkmU6ZMyapVq4p/2QYAAFvayy+/nKamptTU1LQYr6mpycKFC9c7Z/HixXnggQcybNiw3HvvvXnuuedywQUXZO3atZk4ceI68XfffXdeffXVfOYzn9loLqtXr87q1auLrxsbG1u/IQAA2jyNCgAA7LQee+yxnHjiicXXbz9+YcSIEbn55pvz4osvZsmSJcX3+/Tpk9mzZ+fiiy/ONddck7333jvf//73M2TIkGLM0KFD89JLL2XChAlZvnx5+vfvnzlz5qzzS2MAANiWmpub07Vr19x4442pqKjIgAEDsmzZsnzrW99ab6PCf/zHf+SUU05Jjx49NrpuXV1dvva1r22ttAEAaCM0KgAAsNP6yEc+kkKhsMH3b7755vXOefzxxze67ujRozN69Oj3mh4AAGySLl26pKKiIitWrGgxvmLFinTr1m29c7p375727dunoqKiOHbQQQdl+fLlWbNmTSorK4vjL7zwQv7rv/4rd9555z/MZfz48cUG4ORvJyr06tWrtVsCAKCNK9/WCQAAAAAAsPkqKyszYMCA1NfXF8eam5tTX1+fQYMGrXfOcccdl+eeey7Nzc3FsUWLFqV79+4tmhSS5Ac/+EG6du2a00477R/mUlVVlU6dOrW4AADg3TQqAAAAAADs4MaOHZubbropM2bMyNNPP51Ro0Zl1apVGTlyZJJk+PDhGT9+fDF+1KhReeWVVzJmzJgsWrQos2fPzqRJk1JbW9ti3ebm5vzgBz/IiBEj0q6dA3oBANgyVJYAAAAAADu4oUOH5qWXXsqECROyfPny9O/fP3PmzElNTU2SZMmSJSkvf+fv1nr16pX77rsvF198cQ4//PD07NkzY8aMyaWXXtpi3f/6r//KkiVL8tnPfrak+wEAoG0rK2zsobw7kMbGxnTu3DkNDQ2OEwMAaOPaeu3X1vcHAMA72nrt19b3BwDAO1pT+3n0AwAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJaNRAQAAAAAAAAAoGY0KAAAAAAAAAEDJaFQAAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAAAAAAKBkNCoAAAAAAAAAACWjUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAAAAAAAAQMloVAAAAAAAAAAASkajAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJbNZjQpTp05N7969U11dnYEDB2bevHkbjF27dm2uvPLK9O3bN9XV1enXr1/mzJnTIqapqSmXX355+vTpkw4dOqRv3775+te/nkKhsDnpAQAAAAAAAADbqVY3KsyaNStjx47NxIkTs2DBgvTr1y9DhgzJypUr1xt/2WWX5YYbbsi1116bp556Kueff37OOuusPP7448WYb37zm7n++utz3XXX5emnn843v/nN/Pu//3uuvfbazd8ZAAAAAAAAALDdaXWjwuTJk3Peeedl5MiROfjggzNt2rTssssumT59+nrjb7nllnzlK1/Jqaeemv322y+jRo3KqaeemquvvroY8/DDD+eMM87Iaaedlt69e+eTn/xkTj755I2e1AAAAAAAAAAA7Hha1aiwZs2azJ8/P4MHD35ngfLyDB48OHPnzl3vnNWrV6e6urrFWIcOHfLQQw8VXx977LGpr6/PokWLkiS///3v89BDD+WUU05pTXoAAAAAAAAAwHauXWuCX3755TQ1NaWmpqbFeE1NTRYuXLjeOUOGDMnkyZNz/PHHp2/fvqmvr8+dd96ZpqamYsy4cePS2NiYAw88MBUVFWlqaspVV12VYcOGbTCX1atXZ/Xq1cXXjY2NrdkKAAAAAAAAALANtPrRD611zTXXZP/998+BBx6YysrKjB49OiNHjkx5+Tu3/slPfpKZM2fm1ltvzYIFCzJjxox8+9vfzowZMza4bl1dXTp37ly8evXqtbW3AgAAAAAAAAC8R61qVOjSpUsqKiqyYsWKFuMrVqxIt27d1jtnr732yt13351Vq1blhRdeyMKFC9OxY8fst99+xZgvf/nLGTduXD71qU/lsMMOyz//8z/n4osvTl1d3QZzGT9+fBoaGorX0qVLW7MVAAAAAAAAAGAbaFWjQmVlZQYMGJD6+vriWHNzc+rr6zNo0KCNzq2urk7Pnj3z1ltv5Y477sgZZ5xRfO/1119vccJCklRUVKS5uXmD61VVVaVTp04tLgAAAAAAAABg+9autRPGjh2bESNG5KijjsoxxxyTKVOmZNWqVRk5cmSSZPjw4enZs2fxNIRHH300y5YtS//+/bNs2bJcccUVaW5uziWXXFJc8/TTT89VV12VffbZJ4ccckgef/zxTJ48OZ/97Ge30DYBAAAAAAAAgO1BqxsVhg4dmpdeeikTJkzI8uXL079//8yZMyc1NTVJkiVLlrQ4HeHNN9/MZZddlsWLF6djx4459dRTc8stt2T33Xcvxlx77bW5/PLLc8EFF2TlypXp0aNHvvjFL2bChAnvfYcAAAAAAAAAwHajrFAoFLZ1EltCY2NjOnfunIaGBo+BAABo49p67dfW9wcAwDvaeu3X1vcHAMA7WlP7lW/0XQAAAAAAAACALUijAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAtAFTp05N7969U11dnYEDB2bevHkbjX/11VdTW1ub7t27p6qqKgcccEDuvffeFjHLli3Lueeemz333DMdOnTIYYcdlscee2xrbgMAgJ1Au22dAAAAAAAA782sWbMyduzYTJs2LQMHDsyUKVMyZMiQPPPMM+nates68WvWrMlJJ52Url275vbbb0/Pnj3zwgsvZPfddy/G/OUvf8lxxx2XE088Mb/4xS+y11575dlnn80ee+xRwp0BANAWaVQAAAAAANjBTZ48Oeedd15GjhyZJJk2bVpmz56d6dOnZ9y4cevET58+Pa+88koefvjhtG/fPknSu3fvFjHf/OY306tXr/zgBz8ojvXp02frbQIAgJ2GRz8AAAAAAOzA1qxZk/nz52fw4MHFsfLy8gwePDhz585d75x77rkngwYNSm1tbWpqanLooYdm0qRJaWpqahFz1FFH5eyzz07Xrl1zxBFH5Kabbtrq+wEAoO3TqAAAAAAAsAN7+eWX09TUlJqamhbjNTU1Wb58+XrnLF68OLfffnuamppy77335vLLL8/VV1+df/u3f2sRc/3112f//ffPfffdl1GjRuXCCy/MjBkzNpjL6tWr09jY2OICAIB38+gHAAAAAICdTHNzc7p27Zobb7wxFRUVGTBgQJYtW5ZvfetbmThxYjHmqKOOyqRJk5IkRxxxRJ588slMmzYtI0aMWO+6dXV1+drXvlayfQAAsGNyogIAAAAAwA6sS5cuqaioyIoVK1qMr1ixIt26dVvvnO7du+eAAw5IRUVFceyggw7K8uXLs2bNmmLMwQcf3GLeQQcdlCVLlmwwl/Hjx6ehoaF4LV26dHO3BQBAG6ZRAQAAAABgB1ZZWZkBAwakvr6+ONbc3Jz6+voMGjRovXOOO+64PPfcc2lubi6OLVq0KN27d09lZWUx5plnnmkxb9GiRdl33303mEtVVVU6derU4gIAgHfTqAAAAAAAsIMbO3ZsbrrppsyYMSNPP/10Ro0alVWrVmXkyJFJkuHDh2f8+PHF+FGjRuWVV17JmDFjsmjRosyePTuTJk1KbW1tMebiiy/OI488kkmTJuW5557LrbfemhtvvLFFDAAAbI522zoBAAAAAADem6FDh+all17KhAkTsnz58vTv3z9z5sxJTU1NkmTJkiUpL3/n79Z69eqV++67LxdffHEOP/zw9OzZM2PGjMmll15ajDn66KNz1113Zfz48bnyyivTp0+fTJkyJcOGDSv5/gAAaFvKCoVCYVsnsSU0Njamc+fOaWhocJwYAEAb19Zrv7a+PwAA3tHWa7+2vj8AAN7RmtrPox8AAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAOzUpk6dmt69e6e6ujoDBw7MvHnzNhi7du3aXHnllenbt2+qq6vTr1+/zJkzp0VMU1NTLr/88vTp0ycdOnRI37598/Wvfz2FQmFrbwUAAAAAYIegUQEAgJ3WrFmzMnbs2EycODELFixIv379MmTIkKxcuXK98ZdddlluuOGGXHvttXnqqady/vnn56yzzsrjjz9ejPnmN7+Z66+/Ptddd12efvrpfPOb38y///u/59prry3VtgAAAAAAtmsaFQAA2GlNnjw55513XkaOHJmDDz4406ZNyy677JLp06evN/6WW27JV77ylZx66qnZb7/9MmrUqJx66qm5+uqrizEPP/xwzjjjjJx22mnp3bt3PvnJT+bkk0/e6EkNAAAAAAA7E40KAADslNasWZP58+dn8ODBxbHy8vIMHjw4c+fOXe+c1atXp7q6usVYhw4d8tBDDxVfH3vssamvr8+iRYuSJL///e/z0EMP5ZRTTtlgLqtXr05jY2OLCwAAAACgrWq3rRMAAIBt4eWXX05TU1NqampajNfU1GThwoXrnTNkyJBMnjw5xx9/fPr27Zv6+vrceeedaWpqKsaMGzcujY2NOfDAA1NRUZGmpqZcddVVGTZs2AZzqaury9e+9rUtszEAAAAAgO2cExUAAGATXXPNNdl///1z4IEHprKyMqNHj87IkSNTXv5OWf2Tn/wkM2fOzK233poFCxZkxowZ+fa3v50ZM2ZscN3x48enoaGheC1durQU2wEAAAAA2CacqAAAwE6pS5cuqaioyIoVK1qMr1ixIt26dVvvnL322it333133nzzzfx//9//lx49emTcuHHZb7/9ijFf/vKXM27cuHzqU59Kkhx22GF54YUXUldXlxEjRqx33aqqqlRVVW2hnQEAAAAAbN+cqAAAwE6psrIyAwYMSH19fXGsubk59fX1GTRo0EbnVldXp2fPnnnrrbdyxx135Iwzzii+9/rrr7c4YSFJKioq0tzcvGU3AAAAAACwg3KiAgAAO62xY8dmxIgROeqoo3LMMcdkypQpWbVqVUaOHJkkGT58eHr27Jm6urokyaOPPpply5alf//+WbZsWa644oo0NzfnkksuKa55+umn56qrrso+++yTQw45JI8//ngmT56cz372s9tkjwAAAAAA2xuNCgAA7LSGDh2al156KRMmTMjy5cvTv3//zJkzJzU1NUmSJUuWtDgd4c0338xll12WxYsXp2PHjjn11FNzyy23ZPfddy/GXHvttbn88stzwQUXZOXKlenRo0e++MUvZsKECaXeHgAAAADAdqmsUCgUtnUSW0JjY2M6d+6choaGdOrUaVunAwDAVtTWa7+2vj8AAN7R1mu/tr4/AADe0Zrar3yj7wIAAAAAAAAAbEEaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAAAAAAKBkNCoAAAAAAAAAACWjUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAl025bJ7CjKhSS11/f1lkAAGw/dtklKSvb1lmwWQqFpElxCwBQVKG43VEVCoW8vlZtCwDwtl3a75Ky7bC21aiwmV5/PenYcVtnAQCw/XjttWTXXbd1FmyWpteTnyhuAQCKznktaae43RG9vvb1dKxT2wIAvO218a9l18rtr7b16AcAAAAAAAAAoGScqLCZdtnlb381CADA3+yyy7bOgM1Wscvf/moQAIC/qVDc7qh2ab9LXhuvtgUAeNsu7bfP2lajwmYqK3O0MQAAbURZmaONAQBoE8rKyrbLo40BAGjJox8AAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAAAAAAAAQMloVAAAAAAAAAAASkajAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJaNRAQAAAACgDZg6dWp69+6d6urqDBw4MPPmzdto/Kuvvpra2tp07949VVVVOeCAA3LvvfcW37/iiitSVlbW4jrwwAO39jYAANgJtNvWCQAAAAAA8N7MmjUrY8eOzbRp0zJw4MBMmTIlQ4YMyTPPPJOuXbuuE79mzZqcdNJJ6dq1a26//fb07NkzL7zwQnbfffcWcYccckj+67/+q/i6XTu/UgYA4L1TVQIAAAAA7OAmT56c8847LyNHjkySTJs2LbNnz8706dMzbty4deKnT5+eV155JQ8//HDat2+fJOndu/c6ce3atUu3bt22au4AAOx8NuvRD605Qmzt2rW58sor07dv31RXV6dfv36ZM2fOOnHLli3Lueeemz333DMdOnTIYYcdlscee2xz0gMAAAAA2GmsWbMm8+fPz+DBg4tj5eXlGTx4cObOnbveOffcc08GDRqU2tra1NTU5NBDD82kSZPS1NTUIu7ZZ59Njx49st9++2XYsGFZsmTJRnNZvXp1GhsbW1wAAPBurW5UePsIsYkTJ2bBggXp169fhgwZkpUrV643/rLLLssNN9yQa6+9Nk899VTOP//8nHXWWXn88ceLMX/5y19y3HHHpX379vnFL36Rp556KldffXX22GOPzd8ZAAAAAMBO4OWXX05TU1NqampajNfU1GT58uXrnbN48eLcfvvtaWpqyr333pvLL788V199df7t3/6tGDNw4MDcfPPNmTNnTq6//vo8//zz+fCHP5y//vWvG8ylrq4unTt3Ll69evXaMpsEAKBNKSsUCoXWTBg4cGCOPvroXHfddUmS5ubm9OrVK1/60pfWe4RYjx498tWvfjW1tbXFsU984hPp0KFDfvSjHyVJxo0bl9/+9rf5zW9+s9kbaWxsTOfOndPQ0JBOnTpt9joAAGz/2nrt19b3BwDAO7ZE7ffnP/85PXv2zMMPP5xBgwYVxy+55JI8+OCDefTRR9eZc8ABB+TNN9/M888/n4qKiiR/e3zEt771rbz44ovrvc+rr76afffdN5MnT87nPve59casXr06q1evbrG/Xr16qW0BAHYCraltW3WiwuYcIbZ69epUV1e3GOvQoUMeeuih4ut77rknRx11VM4+++x07do1RxxxRG666abWpAYAAAAAsFPq0qVLKioqsmLFihbjK1asSLdu3dY7p3v37jnggAOKTQpJctBBB2X58uVZs2bNeufsvvvuOeCAA/Lcc89tMJeqqqp06tSpxQUAAO/WqkaFzTlCbMiQIZk8eXKeffbZNDc35/7778+dd97Zoit38eLFuf7667P//vvnvvvuy6hRo3LhhRdmxowZG8zFs84AAAAAAJLKysoMGDAg9fX1xbHm5ubU19e3OGHh7x133HF57rnn0tzcXBxbtGhRunfvnsrKyvXOee211/LHP/4x3bt337IbAABgp9OqRoXNcc0112T//ffPgQcemMrKyowePTojR45Mefk7t25ubs6RRx6ZSZMm5YgjjsgXvvCFnHfeeZk2bdoG1/WsMwAAAACAvxk7dmxuuummzJgxI08//XRGjRqVVatWZeTIkUmS4cOHZ/z48cX4UaNG5ZVXXsmYMWOyaNGizJ49O5MmTWrxCN9//dd/zYMPPpg//elPefjhh3PWWWeloqIi//RP/1Ty/QEA0La0qlFhc44Q22uvvXL33Xdn1apVeeGFF7Jw4cJ07Ngx++23XzGme/fuOfjgg1vMO+igg7JkyZIN5jJ+/Pg0NDQUr6VLl7ZmKwAAAAAAbcbQoUPz7W9/OxMmTEj//v3zxBNPZM6cOcXTcZcsWdLilNtevXrlvvvuy+9+97scfvjhufDCCzNmzJiMGzeuGPM///M/+ad/+qd84AMfyDnnnJM999wzjzzySPbaa6+S7w8AgLalXWuC//4IsTPPPDPJO0eIjR49eqNzq6ur07Nnz6xduzZ33HFHzjnnnOJ7xx13XJ555pkW8YsWLcq+++67wfWqqqpSVVXVmvQBAAAAANqs0aNHb/D3tL/61a/WGRs0aFAeeeSRDa532223banUAACghVY1KiR/O0JsxIgROeqoo3LMMcdkypQp6xwh1rNnz9TV1SVJHn300Sxbtiz9+/fPsmXLcsUVV6S5uTmXXHJJcc2LL744xx57bCZNmpRzzjkn8+bNy4033pgbb7xxC20TAAAAAAAAANgetLpRYejQoXnppZcyYcKELF++PP3791/nCLHy8neeKPHmm2/msssuy+LFi9OxY8eceuqpueWWW7L77rsXY44++ujcddddGT9+fK688sr06dMnU6ZMybBhw977DgEAAAAAAACA7UZZoVAobOsktoTGxsZ07tw5DQ0N6dSp07ZOBwCArait135tfX8AALyjrdd+bX1/AAC8ozW1X/lG3wUAAAAAAAAA2II0KgAAAAAAAAAAJaNRAQAAAAAAAAAoGY0KAAAAAAAAAEDJaFQAAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAAAAAAKBkNCoAAAAAAAAAACWjUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAAAAAAAAQMloVAAAYKc2derU9O7dO9XV1Rk4cGDmzZu3wdi1a9fmyiuvTN++fVNdXZ1+/fplzpw568QtW7Ys5557bvbcc8906NAhhx12WB577LGtuQ0AAAAAgB2GRgUAAHZas2bNytixYzNx4sQsWLAg/fr1y5AhQ7Jy5cr1xl922WW54YYbcu211+app57K+eefn7POOiuPP/54MeYvf/lLjjvuuLRv3z6/+MUv8tRTT+Xqq6/OHnvsUaptAQAAAABs18oKhUJhWyexJTQ2NqZz585paGhIp06dtnU6AABsRVuq9hs4cGCOPvroXHfddUmS5ubm9OrVK1/60pcybty4deJ79OiRr371q6mtrS2OfeITn0iHDh3yox/9KEkybty4/Pa3v81vfvObzc5LbQsAsPNo67VfW98fAADvaE3t50QFAAB2SmvWrMn8+fMzePDg4lh5eXkGDx6cuXPnrnfO6tWrU11d3WKsQ4cOeeihh4qv77nnnhx11FE5++yz07Vr1xxxxBG56aabts4mAAAAAAB2QBoVAADYKb388stpampKTU1Ni/GamposX758vXOGDBmSyZMn59lnn01zc3Puv//+3HnnnXnxxReLMYsXL87111+f/fffP/fdd19GjRqVCy+8MDNmzNhgLqtXr05jY2OLCwAAAACgrdKoAAAAm+iaa67J/vvvnwMPPDCVlZUZPXp0Ro4cmfLyd8rq5ubmHHnkkZk0aVKOOOKIfOELX8h5552XadOmbXDdurq6dO7cuXj16tWrFNsBAAAAANgmNCoAALBT6tKlSyoqKrJixYoW4ytWrEi3bt3WO2evvfbK3XffnVWrVuWFF17IwoUL07Fjx+y3337FmO7du+fggw9uMe+ggw7KkiVLNpjL+PHj09DQULyWLl36HnYGAAAAALB906gAAMBOqbKyMgMGDEh9fX1xrLm5OfX19Rk0aNBG51ZXV6dnz5556623cscdd+SMM84ovnfcccflmWeeaRG/aNGi7Lvvvhtcr6qqKp06dWpxAQAAAAC0Ve22dQIAALCtjB07NiNGjMhRRx2VY445JlOmTMmqVasycuTIJMnw4cPTs2fP1NXVJUkeffTRLFu2LP3798+yZctyxRVXpLm5OZdccklxzYsvvjjHHntsJk2alHPOOSfz5s3LjTfemBtvvHGb7BEAAAAAYHujUQEAgJ3W0KFD89JLL2XChAlZvnx5+vfvnzlz5qSmpiZJsmTJkpSXv3MI2ZtvvpnLLrssixcvTseOHXPqqafmlltuye67716MOfroo3PXXXdl/PjxufLKK9OnT59MmTIlw4YNK/X2AAAAAAC2S2WFQqGwrZPYEhobG9O5c+c0NDQ4KhcAoI1r67VfW98fAADvaOu1X1vfHwAA72hN7Ve+0XcBAAAAAAAAALYgjQoAAAAAAAAAQMloVAAAAAAAAAAASkajAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJaNRAQAAAAAAAAAoGY0KAAAAAAAAAEDJaFQAAAAAAAAAAEpGowIAAAAAQBswderU9O7dO9XV1Rk4cGDmzZu30fhXX301tbW16d69e6qqqnLAAQfk3nvvXW/sN77xjZSVleWiiy7aCpkDALCzabetEwAAAAAA4L2ZNWtWxo4dm2nTpmXgwIGZMmVKhgwZkmeeeSZdu3ZdJ37NmjU56aST0rVr19x+++3p2bNnXnjhhey+++7rxP7ud7/LDTfckMMPP7wEOwEAYGfgRAUAAAAAgB3c5MmTc95552XkyJE5+OCDM23atOyyyy6ZPn36euOnT5+eV155JXfffXeOO+649O7dOyeccEL69evXIu61117LsGHDctNNN2WPPfYoxVYAANgJaFQAAAAAANiBrVmzJvPnz8/gwYOLY+Xl5Rk8eHDmzp273jn33HNPBg0alNra2tTU1OTQQw/NpEmT0tTU1CKutrY2p512Wou1N2b16tVpbGxscQEAwLt59AMAAAAAwA7s5ZdfTlNTU2pqalqM19TUZOHCheuds3jx4jzwwAMZNmxY7r333jz33HO54IILsnbt2kycODFJctttt2XBggX53e9+t8m51NXV5Wtf+9rmbwYAgJ2CExUAAAAAAHYyzc3N6dq1a2688cYMGDAgQ4cOzVe/+tVMmzYtSbJ06dKMGTMmM2fOTHV19SavO378+DQ0NBSvpUuXbq0tAACwA3OiAgAAAADADqxLly6pqKjIihUrWoyvWLEi3bp1W++c7t27p3379qmoqCiOHXTQQVm+fHnxURIrV67MkUceWXy/qakpv/71r3Pddddl9erVLea+raqqKlVVVVtoZwAAtFVOVAAAAAAA2IFVVlZmwIABqa+vL441Nzenvr4+gwYNWu+c4447Ls8991yam5uLY4sWLUr37t1TWVmZj370o/nDH/6QJ554ongdddRRGTZsWJ544on1NikAAMCmcqICAAAAAMAObuzYsRkxYkSOOuqoHHPMMZkyZUpWrVqVkSNHJkmGDx+enj17pq6uLkkyatSoXHfddRkzZky+9KUv5dlnn82kSZNy4YUXJkl22223HHrooS3useuuu2bPPfdcZxwAAFpLowIAAAAAwA5u6NCheemllzJhwoQsX748/fv3z5w5c1JTU5MkWbJkScrL3zlgt1evXrnvvvty8cUX5/DDD0/Pnj0zZsyYXHrppdtqCwAA7ETKCoVCYVsnsSU0Njamc+fOaWhoSKdOnbZ1OgAAbEVtvfZr6/sDAOAdbb32a+v7AwDgHa2p/co3+i4AAAAAAAAAwBakUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAAAAAAAAQMloVAAAAAAAAAAASkajAgAAAAAAAABQMpvVqDB16tT07t071dXVGThwYObNm7fB2LVr1+bKK69M3759U11dnX79+mXOnDkbjP/GN76RsrKyXHTRRZuTGgAAAAAAAACwHWt1o8KsWbMyduzYTJw4MQsWLEi/fv0yZMiQrFy5cr3xl112WW644YZce+21eeqpp3L++efnrLPOyuOPP75O7O9+97vccMMNOfzww1u/EwAAAAAAAABgu9fqRoXJkyfnvPPOy8iRI3PwwQdn2rRp2WWXXTJ9+vT1xt9yyy35yle+klNPPTX77bdfRo0alVNPPTVXX311i7jXXnstw4YNy0033ZQ99thj83YDAAAAAAAAAGzXWtWosGbNmsyfPz+DBw9+Z4Hy8gwePDhz585d75zVq1enurq6xViHDh3y0EMPtRirra3Naaed1mLtjVm9enUaGxtbXAAAAAAAAADA9q1VjQovv/xympqaUlNT02K8pqYmy5cvX++cIUOGZPLkyXn22WfT3Nyc+++/P3feeWdefPHFYsxtt92WBQsWpK6ubpNzqaurS+fOnYtXr169WrMVAAAAAAAAAGAbaPWjH1rrmmuuyf77758DDzwwlZWVGT16dEaOHJny8r/deunSpRkzZkxmzpy5zskLGzN+/Pg0NDQUr6VLl26tLQAAAAAAAAAAW0irGhW6dOmSioqKrFixosX4ihUr0q1bt/XO2WuvvXL33Xdn1apVeeGFF7Jw4cJ07Ngx++23X5Jk/vz5WblyZY488si0a9cu7dq1y4MPPpjvfve7adeuXZqamta7blVVVTp16tTiAgAAAAAAAAC2b61qVKisrMyAAQNSX19fHGtubk59fX0GDRq00bnV1dXp2bNn3nrrrdxxxx0544wzkiQf/ehH84c//CFPPPFE8TrqqKMybNiwPPHEE6moqNiMbQEAAAAAAAAA26N2rZ0wduzYjBgxIkcddVSOOeaYTJkyJatWrcrIkSOTJMOHD0/Pnj1TV1eXJHn00UezbNmy9O/fP8uWLcsVV1yR5ubmXHLJJUmS3XbbLYceemiLe+y6667Zc8891xkHAAAAAAAAAHZsrW5UGDp0aF566aVMmDAhy5cvT//+/TNnzpzU1NQkSZYsWZLy8ncOanjzzTdz2WWXZfHixenYsWNOPfXU3HLLLdl999232CYAAAAAAAAAgB1DWaFQKGzrJLaExsbGdO7cOQ0NDenUqdO2TgcAgK2ordd+bX1/AAC8o63Xfm19fwAAvKM1tV/5Rt8FAAAAAAAAANiCNCoAAAAAAAAAACWjUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAAAAAAAAQMloVAAAAAAAAAAASkajAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJaNRAQCAndrUqVPTu3fvVFdXZ+DAgZk3b94GY9euXZsrr7wyffv2TXV1dfr165c5c+ZsMP4b3/hGysrKctFFF22FzAEAAAAAdkwaFQAA2GnNmjUrY8eOzcSJE7NgwYL069cvQ4YMycqVK9cbf9lll+WGG27Itddem6eeeirnn39+zjrrrDz++OPrxP7ud7/LDTfckMMPP3xrbwMAAAAAYIeiUQEAgJ3W5MmTc95552XkyJE5+OCDM23atOyyyy6ZPn36euNvueWWfOUrX8mpp56a/fbbL6NGjcqpp56aq6++ukXca6+9lmHDhuWmm27KHnvsUYqtAAAAAADsMDQqAACwU1qzZk3mz5+fwYMHF8fKy8szePDgzJ07d71zVq9enerq6hZjHTp0yEMPPdRirLa2NqeddlqLtQEAYGtrzWPNkuTVV19NbW1tunfvnqqqqhxwwAG59957i+9ff/31Ofzww9OpU6d06tQpgwYNyi9+8YutvQ0AAHYC7bZ1AgAAsC28/PLLaWpqSk1NTYvxmpqaLFy4cL1zhgwZksmTJ+f4449P3759U19fnzvvvDNNTU3FmNtuuy0LFizI7373u03OZfXq1Vm9enXxdWNjYyt3AwDAzu7tx5pNmzYtAwcOzJQpUzJkyJA888wz6dq16zrxa9asyUknnZSuXbvm9ttvT8+ePfPCCy9k9913L8bsvffe+cY3vpH9998/hUIhM2bMyBlnnJHHH388hxxySAl3BwBAW+NEBQAA2ETXXHNN9t9//xx44IGprKzM6NGjM3LkyJSX/62sXrp0acaMGZOZM2euc/LCxtTV1aVz587Fq1evXltrCwAAtFGtfazZ9OnT88orr+Tuu+/Occcdl969e+eEE05Iv379ijGnn356Tj311Oy///454IADctVVV6Vjx4555JFHSrUtAADaKI0KAADslLp06ZKKioqsWLGixfiKFSvSrVu39c7Za6+9cvfdd2fVqlV54YUXsnDhwnTs2DH77bdfkmT+/PlZuXJljjzyyLRr1y7t2rXLgw8+mO9+97tp165di5MX/t748ePT0NBQvJYuXbplNwsAQJu2OY81u+eeezJo0KDU1tampqYmhx56aCZNmrTBmrWpqSm33XZbVq1alUGDBm2VfQAAsPPw6AcAAHZKlZWVGTBgQOrr63PmmWcmSZqbm1NfX5/Ro0dvdG51dXV69uyZtWvX5o477sg555yTJPnoRz+aP/zhDy1iR44cmQMPPDCXXnppKioq1rteVVVVqqqq3vumAADYKW3OY80WL16cBx54IMOGDcu9996b5557LhdccEHWrl2biRMnFuP+8Ic/ZNCgQXnzzTfTsWPH3HXXXTn44IM3mIvHmgEAsCk0KgAAsNMaO3ZsRowYkaOOOirHHHNMpkyZklWrVmXkyJFJkuHDh6dnz56pq6tLkjz66KNZtmxZ+vfvn2XLluWKK65Ic3NzLrnkkiTJbrvtlkMPPbTFPXbdddfsueee64wDAMC21NzcnK5du+bGG29MRUVFBgwYkGXLluVb3/pWi0aFD3zgA3niiSfS0NCQ22+/PSNGjMiDDz64wWaFurq6fO1rXyvVNgAA2EFpVAAAYKc1dOjQvPTSS5kwYUKWL1+e/v37Z86cOcW/RFuyZEnKy995Wtqbb76Zyy67LIsXL07Hjh1z6qmn5pZbbsnuu+++jXYAAACb91iz7t27p3379i1O/TrooIOyfPnyrFmzJpWVlUn+dhLZ+9///iTJgAED8rvf/S7XXHNNbrjhhvWuO378+IwdO7b4urGxMb169XpP+wMAoO3RqAAAwE5t9OjRG3zUw69+9asWr0844YQ89dRTrVr/3WsAAMCWtjmPNTvuuONy6623prm5udicu2jRonTv3r3YpLA+zc3NLR7t8G4eawYAwKYo/8chAAAAAABsz8aOHZubbropM2bMyNNPP51Ro0at81iz8ePHF+NHjRqVV155JWPGjMmiRYsye/bsTJo0KbW1tcWY8ePH59e//nX+9Kc/5Q9/+EPGjx+fX/3qVxk2bFjJ9wcAQNviRAUAAAAAgB1cax9r1qtXr9x33325+OKLc/jhh6dnz54ZM2ZMLr300mLMypUrM3z48Lz44ovp3LlzDj/88Nx333056aSTSr4/AADalrJCoVDY1klsCY2NjencuXMaGhrSqVOnbZ0OAABbUVuv/dr6/gAAeEdbr/3a+v4AAHhHa2o/j34AAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAAAAAAKBkNCoAAAAAAAAAACWjUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAAAAAAAAQMloVAAAAAAAAAAASkajAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJaNRAQAAAAAAAAAoGY0KAAAAAAAAAEDJaFQAAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAAAAAAKBkNCoAAAAAAAAAACWjUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKZrMaFaZOnZrevXunuro6AwcOzLx58zYYu3bt2lx55ZXp27dvqqur069fv8yZM6dFTF1dXY4++ujstttu6dq1a84888w888wzm5MaAAAAAAAAALAda3WjwqxZszJ27NhMnDgxCxYsSL9+/TJkyJCsXLlyvfGXXXZZbrjhhlx77bV56qmncv755+ess87K448/Xox58MEHU1tbm0ceeST3339/1q5dm5NPPjmrVq3a/J0BAAAAAAAAANudskKhUGjNhIEDB+boo4/OddddlyRpbm5Or1698qUvfSnjxo1bJ75Hjx756le/mtra2uLYJz7xiXTo0CE/+tGP1nuPl156KV27ds2DDz6Y448/fpPyamxsTOfOndPQ0JBOnTq1ZksAAOxg2nrt19b3BwDAO9p67dfW9wcAwDtaU/u16kSFNWvWZP78+Rk8ePA7C5SXZ/DgwZk7d+5656xevTrV1dUtxjp06JCHHnpog/dpaGhIkrzvfe/bYMzq1avT2NjY4gIAAAAAAAAAtm+talR4+eWX09TUlJqamhbjNTU1Wb58+XrnDBkyJJMnT86zzz6b5ubm3H///bnzzjvz4osvrje+ubk5F110UY477rgceuihG8ylrq4unTt3Ll69evVqzVYAAAAAAAAAgG2gVY0Km+Oaa67J/vvvnwMPPDCVlZUZPXp0Ro4cmfLy9d+6trY2Tz75ZG677baNrjt+/Pg0NDQUr6VLl26N9AEAAAAAAACALahVjQpdunRJRUVFVqxY0WJ8xYoV6dat23rn7LXXXrn77ruzatWqvPDCC1m4cGE6duyY/fbbb53Y0aNH5+c//3l++ctfZu+9995oLlVVVenUqVOLCwAAAAAAAADYvrWqUaGysjIDBgxIfX19cay5uTn19fUZNGjQRudWV1enZ8+eeeutt3LHHXfkjDPOKL5XKBQyevTo3HXXXXnggQfSp0+fVm4DAAAAAAAAANgRtGvthLFjx2bEiBE56qijcswxx2TKlClZtWpVRo4cmSQZPnx4evbsmbq6uiTJo48+mmXLlqV///5ZtmxZrrjiijQ3N+eSSy4prllbW5tbb701P/vZz7Lbbrtl+fLlSZLOnTunQ4cOW2KfAAAAAAAAAMB2oNWNCkOHDs1LL72UCRMmZPny5enfv3/mzJmTmpqaJMmSJUtSXv7OQQ1vvvlmLrvssixevDgdO3bMqaeemltuuSW77757Meb6669PknzkIx9pca8f/OAH+cxnPtP6XQEAAAAAAAAA26WyQqFQ2NZJbAmNjY3p3LlzGhoa0qlTp22dDgAAW1Fbr/3a+v4AAHhHW6/92vr+AAB4R2tqv/KNvgsAAAAAAAAAsAVpVAAAAAAAaAOmTp2a3r17p7q6OgMHDsy8efM2Gv/qq6+mtrY23bt3T1VVVQ444IDce++9xffr6upy9NFHZ7fddkvXrl1z5pln5plnntna2wAAYCegUQEAAAAAYAc3a9asjB07NhMnTsyCBQvSr1+/DBkyJCtXrlxv/Jo1a3LSSSflT3/6U26//fY888wzuemmm9KzZ89izIMPPpja2to88sgjuf/++7N27dqcfPLJWbVqVam2BQBAG9VuWycAAAAAAMB7M3ny5Jx33nkZOXJkkmTatGmZPXt2pk+fnnHjxq0TP3369Lzyyit5+OGH0759+yRJ7969W8TMmTOnxeubb745Xbt2zfz583P88cdvnY0AALBTcKICAAAAAMAObM2aNZk/f34GDx5cHCsvL8/gwYMzd+7c9c655557MmjQoNTW1qampiaHHnpoJk2alKampg3ep6GhIUnyvve9b8tuAACAnY4TFQAAAAAAdmAvv/xympqaUlNT02K8pqYmCxcuXO+cxYsX54EHHsiwYcNy77335rnnnssFF1yQtWvXZuLEievENzc356KLLspxxx2XQw89dIO5rF69OqtXry6+bmxs3MxdAQDQlmlUAAAAAADYyTQ3N6dr16658cYbU1FRkQEDBmTZsmX51re+td5Ghdra2jz55JN56KGHNrpuXV1dvva1r22ttAEAaCM8+gEAAAAAYAfWpUuXVFRUZMWKFS3GV6xYkW7duq13Tvfu3XPAAQekoqKiOHbQQQdl+fLlWbNmTYvY0aNH5+c//3l++ctfZu+9995oLuPHj09DQ0PxWrp06WbuCgCAtkyjAgAAAADADqyysjIDBgxIfX19cay5uTn19fUZNGjQeuccd9xxee6559Lc3FwcW7RoUbp3757KysokSaFQyOjRo3PXXXflgQceSJ8+ff5hLlVVVenUqVOLCwAA3k2jAgAAAADADm7s2LG56aabMmPGjDz99NMZNWpUVq1alZEjRyZJhg8fnvHjxxfjR40alVdeeSVjxozJokWLMnv27EyaNCm1tbXFmNra2vzoRz/Krbfemt122y3Lly/P8uXL88Ybb5R8fwAAtC3ttnUCAAAAAAC8N0OHDs1LL72UCRMmZPny5enfv3/mzJmTmpqaJMmSJUtSXv7O36316tUr9913Xy6++OIcfvjh6dmzZ8aMGZNLL720GHP99dcnST7ykY+0uNcPfvCDfOYzn9nqewIAoO0qKxQKhW2dxJbQ2NiYzp07p6GhwXFiAABtXFuv/dr6/gAAeEdbr/3a+v4AAHhHa2o/j34AAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAAAAAAKBkNCoAAAAAAAAAACWjUQEAAAAAAAAAKJl22zqBLaVQKCRJGhsbt3EmAABsbW/XfG/XgG2N2hYAYOehtgUAoK1oTW3bZhoV/vrXvyZJevXqtY0zAQCgVP7617+mc+fO2zqNLU5tCwCw81HbAgDQVmxKbVtWaCOtus3Nzfnzn/+c3XbbLWVlZSW5Z2NjY3r16pWlS5emU6dOJbnnttLW9rqj72dHy397zXd7ymtb5lLKe2/uvbZ2jltj/e1hzfeSw3vN373de2srFAr561//mh49eqS8vO09zUxtu3W1tb3u6PvZ0fLfXvPdnvJS226dedty/e1hzR211nHvnevem0ttu+VtTz8Xt7a2ttcdfT87Wv7ba77bU15q260zb1uuvz2suaPWOu69c917c7Wmtm0zJyqUl5dn77333ib37tSp0zb/YVkqbW2vO/p+drT8t9d8t6e8tmUupbz35t5ra+e4NdbfHtZ8Lzm81/zd2723prb412ZvU9uWRlvb646+nx0t/+013+0pL7Xt1pm3LdffHtbcUWsd99657r051LZbx/b0c3Fra2t73dH3s6Plv73muz3lpbbdOvO25frbw5o7aq3j3jvXvTfHpta2ba9FFwAAAAAAAADYbmlUAAAAAAAAAABKRqPCe1BVVZWJEyemqqpqW6ey1bW1ve7o+9nR8t9e892e8tqWuZTy3pt7r62d49ZYf3tY873k8F7zd2/3ZsezM/07trW97uj72dHy317z3Z7yUttunXnbcv3tYc0dtdZx753r3mw/dqZ/x7a21x19Pzta/ttrvttTXmrbrTNvW66/Pay5o9Y67r1z3bsUygqFQmFbJwEAAAAAAAAA7BycqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1FhA6644oqUlZW1uA488MCNzvnpT3+aAw88MNXV1TnssMNy7733lijb1vn1r3+d008/PT169EhZWVnuvvvu4ntr167NpZdemsMOOyy77rprevTokeHDh+fPf/7zP1x32bJlOffcc7PnnnumQ4cOOeyww/LYY49txZ38zcb2kyQrVqzIZz7zmfTo0SO77LJLPvaxj+XZZ5/d5PVvu+22lJWV5cwzz9yyif//1dXV5eijj85uu+2Wrl275swzz8wzzzzTIuYjH/nIOp+P559//j9c++mnn87HP/7xdO7cObvuumuOPvroLFmyZLNzvf7663P44YenU6dO6dSpUwYNGpRf/OIXxfdvvPHGfOQjH0mnTp1SVlaWV1999R+uuSn73xK5JcncuXPzv/7X/8quu+6aTp065fjjj88bb7yxVXP7xje+kbKyslx00UXFsTfffDO1tbXZc88907Fjx3ziE5/IihUr/uFarf33XN+931YoFHLKKaes92tmc++9vvstX748//zP/5xu3bpl1113zZFHHplzzjlno99fr7zyynTt2rX4Xo8ePfLb3/52o/kVCoVMmDAhHTt23OjaX/ziF9O3b9906NAhe+21V84444wsXLjwH659wgknbHTd1n6Nru9nTFVVVaZNm7bBj9sdd9zxD7/Pvv1xePtrcJ999il+v9vY3O9+97vp3LlzysvLU1FRkb322mud7/0bmj916tT07t071dXVGThwYObNm5fzzz8/ZWVlmTJlyj+899vzKysrs8cee6Rjx44tPsc2NvenP/1pDjjggFRUVKR9+/apqqrKwQcfXPw49u7de52Pc1lZWWpra1vMbdeuXTp06LDO1+KG5h999NGpqalJu3btsuuuu6a6ujr77LNPLrzwwjQ0NGx07gUXXJAJEyake/fu6dChQz760Y/m+OOPX+drcWP3fnvu0UcfnUGDBq3zPW1j+546dWp69eqVioqKVFZWpkOHDsXPr7c1NTXl8ssvT58+fdKhQ4f07ds3X//613PdddcV/62POeaYfO5znyvmMnjw4E362bq+zxdKQ22rtn2b2vYdalu1rdpWbau2VduqbXdMalu17dvUtu9Q26pt1bZqW7Wt2naHrG0LrNfEiRMLhxxySOHFF18sXi+99NIG43/7298WKioqCv/+7/9eeOqppwqXXXZZoX379oU//OEPJcx609x7772Fr371q4U777yzkKRw1113Fd979dVXC4MHDy7MmjWrsHDhwsLcuXMLxxxzTGHAgAEbXfOVV14p7LvvvoXPfOYzhUcffbSwePHiwn333Vd47rnntvJuNr6f5ubmwgc/+MHChz/84cK8efMKCxcuLHzhC18o7LPPPoXXXnvtH679/PPPF3r27Fn48Ic/XDjjjDO2Sv5Dhgwp/OAHPyg8+eSThSeeeKJw6qmnrpPfCSecUDjvvPNafD42NDRsdN3nnnuu8L73va/w5S9/ubBgwYLCc889V/jZz35WWLFixWbnes899xRmz55dWLRoUeGZZ54pfOUrXym0b9++8OSTTxYKhULhO9/5TqGurq5QV1dXSFL4y1/+skX2vyVye/jhhwudOnUq1NXVFZ588snCwoULC7NmzSq8+eabWy23efPmFXr37l04/PDDC2PGjCmOn3/++YVevXoV6uvrC4899ljhgx/8YOHYY4/d6Fqt/ffc0L3fNnny5MIpp5yyztfM5t57Q/c76aSTCkcffXTh0UcfLfzxj38sfP3rXy8kKfTt23eD31979epVeN/73lf4j//4j8Ktt95a2H333QuVlZUb/bh/4xvfKHTu3LkwdOjQQt++fQsnn3xyoVevXoXnn3++xdo33HBD4cEHHyw8//zzhfnz5xdOP/30Qq9evQpvvfXWRteuqqoq7LPPPoX6+vri2kuXLi3GtPZrdOLEiYU99tijsO+++xbuuOOOwrx58wpXX311oaKiovCzn/1svR+3srKyQvfu3Tf6ffYb3/hGoWPHjoWuXbsW9t9//8J+++1X6NOnT+HPf/7zBr9H33bbbYX27dsXDj744MLVV19dOPvsswsdO3YsHHHEEcXv/Rv6Hj9lypRCZWVlYfr06YX/9//+X+G8884r7LLLLoVDDjmk0KNHj8J3vvOdjf58uO222wqVlZXFf7/DDz+80LFjx8Kjjz5a+NnPflZ45plnNjj37Z+7xxxzTKFXr16Fc889t9CuXbvChAkTih/HlStXtvg3uf/++wtJCtdee22hoqKi8MEPfrDQrVu3wrBhwwrt2rUrHH744S2+Fjc0f9dddy1cc801hY9+9KOFY445prD33nsXfvGLXxT233//wic+8YmNzj3vvPMKnTt3Ltx9992F3//+94VDDjmk0KFDh3W+Fjd277vvvrvwwx/+sNCuXbvCHnvsUZg/f36L72kbmnv55ZcXKisrC4ccckjh0EMPLZxxxhmF3XbbrXDppZcWysvLCwsWLCgUCoXCVVddVdhzzz0LP//5zwvPP/984ac//Wmhurq6UFFRUfy3PvroowtJCjfffHPh97//feHjH/94oU+fPoU33nhjg5/3b/97//3ny+677/6efi6x6dS2attCQW37bmpbta3aVm2rtlXbqm13TGpbtW2hoLZ9N7Wt2lZtq7ZV26ptd8TaVqPCBkycOLHQr1+/TY4/55xzCqeddlqLsYEDBxa++MUvbuHMtqxN+WE3b968QpLCCy+8sMGYSy+9tPChD31oC2fXeu/ezzPPPFNIUix6CoVCoampqbDXXnsVbrrppo2u9dZbbxWOPfbYwve///3CiBEjtlrB+24rV64sJCk8+OCDxbETTjhhvUXLxgwdOrRw7rnnbuHs1rXHHnsUvv/977cY++Uvf7nJBe+7rW//WyK3gQMHFi677LL3tF5rcvvrX/9a2H///Qv3339/i3+/V199tdC+ffvCT3/602Ls008/XUhSmDt37gbXa82/54bu/bbHH3+80LNnz8KLL764Sd8D/tG9N3a/XXfdtfDDH/6wRXx1dXVh7733Xu9a6/v4/Pa3vy0kKXzve99b75zm5uZCt27dCt/61reK37tfffXVQlVVVeHHP/7xRvf2+9//vpBkg//j/O21TzrppOLPhPWt3dqv0YkTJxaqq6sLV155ZYvxI488svDVr351gx+397///Rtcs7m5uVBTU1Po0qVL8d/i/PPPL1RVVRU+/vGPb/B79DHHHFOora0tvm5qair06NGjcMEFFxS/92/oe/y75y5ZsqRQXl5euOiiiwr77rtv4Tvf+c5Gfz68Pf/tz7G3711XV1coFDb+s+Xtn7uHHHJI8eP49s/dtz+O7zZmzJhC3759C2effXbh5JNPbvG5NnDgwMI555yz0a/FCy+8sPjLrbf9/efDT37yk0JlZWVh7dq1G7x3TU1N4Vvf+lahUPjb12KPHj0KlZWV//Br8d33HjhwYOFf//VfN+nz/O17H3300YXa2tri59fff7zf9773FX8unnbaaYXPfvazLdbYY489CgcccEChUHjn6+LtXyK8++OwIRv6XHt7DbYute071LZq241R266f2vZv1Lbrp7ZtOV9tq7Zl61PbvkNtq7bdGLXt+qlt/0Ztu35q25bz1bZq263Nox824tlnn02PHj2y3377ZdiwYRs9qmfu3LkZPHhwi7EhQ4Zk7ty5WzvNra6hoSFlZWXZfffdNxhzzz335KijjsrZZ5+drl275ogjjshNN91UuiQ3YPXq1UmS6urq4lh5eXmqqqry0EMPbXTu28cYfe5zn9uqOb7b28fPvO9972sxPnPmzHTp0iWHHnpoxo8fn9dff32DazQ3N2f27Nk54IADMmTIkHTt2jUDBw7cpKOiNlVTU1Nuu+22rFq1KoMGDdpi625o/63x7txWrlyZRx99NF27ds2xxx6bmpqanHDCCf/wc+C95FZbW5vTTjttne8L8+fPz9q1a1uMH3jggdlnn302+P2itf+eG7p3krz++uv59Kc/nalTp6Zbt27/cB+bcu+N3e/YY4/NrFn/v/buPaqqMn8D+HPu3BUvIHJRFEEtdARvaF5B1AxBC00dodSwFB3LuzVKOWlOFzLL0pnCStOoFC1NQxQzTQUFyTJARG0IdeXlp3gB5Xx/f7DOHjacA2iK2TyftVirs/d59/vud7/7PY+td+39Kc6fPw+z2Yx169bh5s2bOHfunNX51Vr/uLm5AQAKCwuttrGwsBCnT59WyuTn56Ndu3bQaDRISEiwOXdfuXIFSUlJ8PX1hbe3d43HbtWqlfKb0KlTJ7i4uOCbb75RffdW7lEAuHnzJhYuXIgWLVpgzJgxWLduHfLy8hAeHm6130pLS/HQQw/ZnGcLCwtx5swZhIeHK31hMpnQrVs37N692+ocXVZWhoMHD6r6W6vVIiwsDFlZWcrcb22Of/fdd1VlzWYzYmNjERwcjOPHjyvHs/X7YKm7f//+yhgbPHgwzp8/jyVLliAlJaXG3xbL726PHj2wadMmFBUVITw8HKmpqUo/VlZWVobVq1dj3Lhx2LdvH/z8/FRjbeDAgfj5559t3otlZWX4+OOPUV5ejgEDBijbGzRogG7duuH777/H//3f/8HFxQV6vd5q3VFRUThz5gzCwsKUe3H58uXo3r17jWOlat2WOc3Hxwcmkwnjxo2zOadZ6o6NjcWhQ4eUPvv0009x8eJFhIaG4vPPP8f169fRt29fABX3bVpaGvLy8gAAmZmZuHDhAh5++GFlrJ0+fRq9e/dW+qpyP9g6B1tj7c+Qle4XzLYVmG2Zba1htq0Zs20FZlvbmG2ZbZltmW3rG7NtBWZbZltrmG1rxmxbgdnWNmZbZltm23rMtnd9KcR9asuWLZKcnCyHDx+WrVu3SkhIiPj4+MilS5esft9gMMgnn3yi2vbOO++Im5tbfTT3tqGWlUDXrl2ToKAgGT16dI3HMZlMYjKZZO7cuXLo0CFZsWKF2NnZyapVq+5wi2tW9XzKysrEx8dHoqOj5fz581JaWiqvvPKKAJDw8HCbx9m9e7d4enoqjx6qr5W55eXlMmTIEOnZs6dq+4oVK2Tr1q2Sk5Mjq1evFk9PTxk2bJjN41hWXDo4OMgbb7whWVlZsnjxYtFoNJKenv672piTkyOOjo6i0+mkQYMGsnnz5mrfud2VubbO//e27fvvvxcA0qhRI/nggw/k0KFDMm3aNDEajZKXl3fH27Z27Vp58MEHlUfpVF61uWbNGjEajdXKdOnSRWbNmmX1eLdyPWuqW0QkLi5Oxo8fr3yubQ6ore7a6rtw4YKEh4cLANHr9eLi4iL/+Mc/bM6vVfvH0u9OTk42+8eycvfXX39Vzd29evWSxo0bV5u733nnHXF0dBQAEhAQUOOjDi3HXr16tarNjRs3FgcHB+W4t3qPbtmyRdasWSMRERECQPl77733bPabwWCocZ598cUXBYAcP35cdS2io6NFq9VaLZuYmCgAZO/evar2Pfvss+Lg4KDM/bbm+MplFy1aJAMGDJAZM2ZI165dlZW5tspa6v7yyy9VYywmJka8vLxEo9HUeM6W393r169LTEyMABCtVisA5MMPP6zW559++qnodDopKioSg8EgkydPVo01y2+2rXvRUt4y1iqLjo6WyMhI8fHxkXnz5tksm5KSopSvfC9GR0fXeC9WrbvynNa5c2cZMGCAzTnNUvbgwYPK9ao8vrRareh0Otm2bZtSpry8XGbPni0ajUb0er1oNBrVtbbcF88884x07dpV1Q8jRoyweg5FRUVWx9rMmTNVx6C7h9m2ArMts21VzLbMtsy2zLbMtsy2zLb3H2bbCsy2zLZVMdsy2zLbMtsy2zLb3m/ZlgsV6ujChQvi4uJS7VFJFn/GwFtWViYRERHSqVOnWt+rZTAYJCQkRLVtypQp0r179zvV1Dqxdj6ZmZnSsWNHASA6nU4GDhwogwcPlkGDBlk9xqVLl6Rly5ayZcsWZVt9Bd6nn35aWrRooXqHkjVpaWk1PvbIMrGMGjVKtT0iIkIef/zx39XG0tJSyc/Pl8zMTJkzZ440adJEfvzxR9V3bjfw1vX8b7Vtlsl57ty5qu8HBgbKnDlz7mjbTp06JW5ubnL48GFl2+8NvHW9nrXVvXHjRvHz85PLly8r+2sLvDXVHRERUWN9IiLx8fHStWtX2b59u2RnZ0tCQoI0aNBAcnJylO9Unl+r9o+l3zt27FinwFtZdHS0REVFVZu7L168KHl5ebJr1y6JiIiQoKAgm+9nsnXsyMhIMRgMNn8TartHRUReffVV8ff3l02bNsnu3bvFzs5OTCaTpKamWu03ANUebWmZZ0+dOiWurq6qtlYNvNbm6KCgoGohpKysTFq3bi0ODg7K3G9tjh83bpxSNjMzU9zd3aWoqEgJMJbAa+v3wVL3xo0bVWPMUj4iIsJmu7t376787lbux3nz5omTk5M4OTlJamqqqlx4eLg88sgjyvncauANDw+Xnj17Wh0PUVFR0qhRIxk0aJCUlZVZLfvII48o4ykpKUl1L9YWeKvWXXlOqxwyrc1plrorB87K4ys2NlY8PT1V9+XatWvFy8tL1q5dKzk5ObJ06VIBoDyG8X4MvFQdsy2zLbNtBWZbZltL3cy2zLbMthWYbUU5D2bb+wezLbMts20FZltmW0vdzLbMtsy2FZhtRTmPP2q25UKFW9C5c2ebP47e3t6SmJio2jZ//nzp0KFDPbTs9tm6wcrKyiQqKko6dOggv/32W63H8fHxUa32ExFZvny5NG/e/E41tU5qmjAuXrwoZ8+eFZGK961MmjTJ6veysrKUcGz502g0otFoRKfT1fgD9ntMnjxZvLy8lFV1NSkpKREAsnXrVqv7S0tLRa/Xy8KFC1XbZ82aJT169Lgj7bUIDQ2VuLg41bbbCby3cv632rbjx48LAPn4449V+0eMGFHrqvNbbduGDRuqjR8AyvjZvn271b7x8fGRN954w+ox63o9a6s7Pj5e+e/K+7VarfTp0+eW6w4ICKixvmPHjgmgftegSMV1qfoeSMv8agmKFy5cUPV7Tf1TUFAgACQrK0u1vXfv3jJ16tQa5+7S0lJxcHCo9j8s6nJsNzc3m8et7R69evWqGAwG+eqrr1R90KFDB+nVq5fVfrOzs5O2bduqtlnmWcu1r7zS0nItAIizs7PNOVqn0ynzpmXud3V1Vf1PAWtz/FtvvaXMuYmJicp1t8yXldtSU93JycmqMRYTEyNDhw6VWbNmidFotFnW29tblixZoupHy+/u+PHjZeDAgUqZEydOiFarlZSUFBGp+M22vMvNci9ayloba5by7733XrXxcOnSJXFxcRFvb2+r/3CqXLdlPI0ePVp1L1a+dlXvRWt1V57TLONcpPqcVrnu0tJS0el0snz5ctX4svR35fvSy8tL3n77beU4paWlotFoxNPTU0T+e1888sgjMnToUOV7ldtSlaX+qr/Rlvrp3mC2tY3Z9vdjtmW2ZbZltmW2ZbZltqX6xGxrG7Pt78dsy2zLbMtsy2zLbMtse3doQXVSUlKCgoICeHh4WN0fEhKCtLQ01bbU1NQ7+g6o+nLjxg2MGDEC+fn52L59Oxo3blxrmZ49eyI3N1e1LS8vDy1atLhbzbxlDRo0QNOmTZGfn4/MzExERkZa/V7btm3xww8/IDs7W/kbOnQo+vXrh+zsbJvvRLpdIoL4+Hhs2LABO3bsgK+vb61lsrOzAcDmeDQajejSpUu9XBOz2ay8U+523M7532rbWrZsiebNm99yf9xO20JDQ6uNn86dO2PMmDHKfxsMBtV8kZubi1OnTtmcL+p6PWur+/nnn0dOTo5qPwAkJiYiKSnplusODAyssT7Lu760WvVPjU6ng9lsVj5Xnl+Dg4NhMBgwatQopd/Lyspq7B9fX180a9ZM1aeXLl3C/v370alTpxrnbqlYsGdzDNs69r59+3DlyhWbx63tHr1x4wZu3Lih9I2lD5ycnHDjxg0A1futYcOGuHDhgmqbZQyEhoYiJycHTZo0wXPPPadci+joaBiNRgQGBtocP8HBwUhLS1PN/SaTCX369FG+a22OP378OJycnJCWloaxY8ciJycHhw4dQtOmTTF16lQ0b94cM2fOxKBBg2qs+9tvv1XGmNlsRlpaGkJCQpCXlwcPDw+bZUNCQrBjxw5VP1p+d6uOsaSkJLi5uWHIkCEAKn6zCwoKVPdiamoq2rVrZ3WsWcqPGzdONR4uXbqE0NBQXL58GQsXLlS9V9Na3Zbx5Ofnp9yL3333HQwGAwDr96K1ui1zWk5ODvbv36+0t+qcULluo9Go9DdQMb4q93flPrt69apq/BmNRnh6eqKkpATAf++Lb7/9Vqnbcs/VNI9ZxppF5fqp/jHb1ozZ9vYx2zLbMtsy2zLbMtsCzLZUv5hta8Zse/uYbZltmW2ZbZltmW0BZtu76q4vhbhPTZ8+XdLT06WwsFD27NkjYWFh0qRJE2Vl59ixY1Ursvbs2SN6vV5ee+01OXr0qCxYsEAMBoP88MMP9+oUbLp8+bJkZWUpK1At7y86efKklJWVydChQ8XLy0uys7OluLhY+SstLVWO0b9/f1m2bJny+cCBA6LX6+Xll1+W/Px8WbNmjTg4OMjq1avv6fmIiCQnJ8vOnTuloKBAUlJSpEWLFjJ8+HDVMapez6ru5iPEnnnmGWnQoIGkp6er+vvq1asiInLs2DF56aWXJDMzUwoLC2Xjxo3SqlUr6d27t+o4AQEBsn79euXz+vXrxWAwyMqVKyU/P1+WLVsmOp1Odu/efdttnTNnjuzatUsKCwslJydH5syZIxqNRr755hsRqXgvVlZWlvzrX/8SAPLtt99KVlaWnDt3TjlG1bFT2/nfqbYlJiaKi4uLfPbZZ5Kfny8vvPCC2NnZqVZa3622VX2s1tNPPy0+Pj6yY8cOyczMlJCQkGqPSbpT17Nq3VXBymr231N35frKysrEz89PevXqJfv375djx47Ja6+9JgDklVdeUeZXV1dXcXJyUubX9u3bi0ajkcTERNm6dat07txZOnfurOr3qm185ZVXpGHDhhIVFSUffPCBDBgwQDw8PKR///7K3F1QUCCLFi2SzMxMOXnypOzZs0ciIiKkUaNGcubMmRqPbTKZ5OWXX5avv/5aevXqJXZ2dspxb+cenT59unTs2FHatGkjy5Ytk549e4qTk5OYTCZZtmyZzX7T6XTKPNu+fXsxGo2qedbSDxs3bpTg4GBp1aqV+Pr6yu7du5U5unv37hIbG6vM0evWrROj0SidOnWSZs2ayaOPPiouLi6Sk5OjzP2WOb5Vq1Yyf/58ZY6Pj48Xk8kkq1atkp9++kni4uKkYcOGcvr0aeURYpV/H6zVbTKZZMqUKaLX66VXr17i7OwsL7/8suh0Olm5cqVSNjIyUiIiIpSylt/dVq1aiZ+fn8TGxiorfO3s7GT58uUiUvHeLkdHR9UjLS1lQ0JCxMPDQ2JiYkSv10vHjh2r3Yv+/v7SpEkTmT17tqqP165dK4GBgeLi4iJeXl5SWFiozBE3b95U6tbr9ar33lW+Rjk5ORIZGSm+vr5W70VbdW/cuFFmzpwper1e3Nzc5MiRI9XmtPLycjGZTBIWFqYcz3Kt3d3dJTg4WKKiosTZ2VkWLFggGo1GeT9kbGysmEwmmThxohQWFsr69evF2dlZdDqdcq27du0qGo1GPvzwQ9V5VF6dXHVOtVxva+OF7j5mW2bbyphtKzDbMtsy2zLbMtsy2zLb3p+YbZltK2O2rcBsy2zLbMtsy2zLbHs/ZlsuVLBh5MiR4uHhIUajUTw9PWXkyJGqH8Y+ffpIbGysqkxycrL4+/uL0WiUBx54QBk4fzSWxztV/YuNjZXCwkKr+wDIzp07lWO0aNFCFixYoDrul19+KQ8++KCYTCZp27atrFy58p6fj4jI0qVLxcvLSwwGg/j4+MgLL7ygCu8i1q9nZXcz8Nrq76SkJBGpeH9V7969pVGjRmIymcTPz09mzpxZ7f1zlctYvP/+++Ln5yd2dnbSsWNH5fE5t2vcuHHSokULMRqN0rRpUwkNDVUCpYjIggULajwXkepjp7bzv1NtExFZvHixeHl5iYODg4SEhFQLbHerbVVD57Vr12TSpEni6uoqDg4OMmzYMCkuLlaVuVPX83YC7++pu2p9eXl5Mnz4cHFzcxMHBwfp0KGDdOvWTTW/Ojg4yJQpU1T119bvVT+bzWb5+9//LiaTSXl0lru7u2ruLioqksGDB4ubm5sYDAbx8vKS0aNHy88//1zj+ZvNZmnfvr1otVoBICaTSR5++GHluLdzj44cOVLc3d1Fq9Uqf76+vvL666+L2Wy22m8fffSRap7V6/XKu7uq9oO7u7toNBrx9vaW3NxcEfnvHA1AmjRpopqjLe9Sq2nu//LLL8VgMIhOp1PN8cuWLRMfHx8xGo3StWtX2bdvn4iIEnhrq9tSXqfTiclkEpPJpBpjlrIajUYaNGigKpucnCytWrUSrVYrer1ejEajBAQEKP0oIrJt2zYBIFFRUaq+Sk5OFj8/P+UxZyaTyea9CEDpR0sfW94tZ+2vsLBQVffixYutXiOTySShoaGSm5tr8160VrelbOvWraVZs2ZW5zRL3fHx8apjLlu2TDw8PESj0Yherxc7OztlfFlcunRJnJ2dpUGDBmJnZyetWrWS559/XhITE5Vr3aVLFxk3bly186jMWlawNV7o7mO2ZbatjNm2ArMtsy2zLbMtsy2zLbPt/YnZltm2MmbbCsy2zLbMtsy2zLbMtvdjttWIiICIiIiIiIiIiIiIiIiIiIioHmhr/woRERERERERERERERERERHRncGFCkRERERERERERERERERERFRvuFCBiIiIiIiIiIiIiIiIiIiI6g0XKhAREREREREREREREREREVG94UIFIiIiIiIiIiIiIiIiIiIiqjdcqEBERERERERERERERERERET1hgsViIiIiIiIiIiIiIiIiIiIqN5woQIRERERERERERERERERERHVGy5UICL6k0tISIC7uzs0Gg1SUlLqVCY9PR0ajQYXL168q237I2nZsiXefPPNe90MIiIiIqoBs23dMNsSERER/fEx29YNsy3RnxcXKhBRvXviiSeg0Wig0WhgNBrh5+eHl156CTdv3rzXTavVrYTGP4KjR4/ixRdfxIoVK1BcXIzBgwfftbr69u2LadOm3bXjExEREf0RMdvWH2ZbIiIioruL2bb+MNsSEQH6e90AIvrfNGjQICQlJaG0tBRbtmzB5MmTYTAYMHfu3Fs+Vnl5OTQaDbRarr2qqqCgAAAQGRkJjUZzj1tDRERE9OfEbFs/mG2JiIiI7j5m2/rBbEtExCcqENE9YjKZ0KxZM7Ro0QLPPPMMwsLCsGnTJgBAaWkpZsyYAU9PTzg6OqJbt25IT09Xyq5atQoNGzbEpk2b0L59e5hMJpw6dQqlpaWYPXs2vL29YTKZ4Ofnh/fff18pd+TIEQwePBhOTk5wd3fH2LFj8dtvvyn7+/bti6lTp2LWrFlo1KgRmjVrhoSEBGV/y5YtAQDDhg2DRqNRPhcUFCAyMhLu7u5wcnJCly5dsH37dtX5FhcXY8iQIbC3t4evry8++eSTao+sunjxIiZMmICmTZvCxcUF/fv3x+HDh2vsxx9++AH9+/eHvb09GjdujLi4OJSUlACoeHRYREQEAECr1dYYeLds2QJ/f3/Y29ujX79+OHHihGr/uXPnMGrUKHh6esLBwQGBgYFYu3atsv+JJ57Arl27sHTpUmXV9YkTJ1BeXo7x48fD19cX9vb2CAgIwNKlS2s8J8v1rSwlJUXV/sOHD6Nfv35wdnaGi4sLgoODkZmZqez/7rvv0KtXL9jb28Pb2xtTp07FlStXlP1nz55FRESEcj3WrFlTY5uIiIiIasJsy2xrC7MtERER3W+YbZltbWG2JaI7jQsViOgPwd7eHmVlZQCA+Ph4fP/991i3bh1ycnIQHR2NQYMGIT8/X/n+1atXsWTJEvz73//Gjz/+CDc3N8TExGDt2rV46623cPToUaxYsQJOTk4AKsJk//790alTJ2RmZmLr1q04c+YMRowYoWrHhx9+CEdHR+zfvx///Oc/8dJLLyE1NRUAkJGRAQBISkpCcXGx8rmkpAQPP/ww0tLSkJWVhUGDBiEiIgKnTp1SjhsTE4Nff/0V6enp+OKLL7By5UqcPXtWVXd0dDTOnj2Lr7/+GgcPHkRQUBBCQ0Nx/vx5q3125coVDBw4EK6ursjIyMBnn32G7du3Iz4+HgAwY8YMJCUlAagI3MXFxVaP88svv2D48OGIiIhAdnY2JkyYgDlz5qi+c/36dQQHB2Pz5s04cuQI4uLiMHbsWBw4cAAAsHTpUoSEhOCpp55S6vL29obZbIaXlxc+++wz/PTTT5g/fz7mzZuH5ORkq22pqzFjxsDLywsZGRk4ePAg5syZA4PBAKDiHyCDBg3Co48+ipycHHz66af47rvvlH4BKgL6L7/8gp07d+Lzzz/H8uXLq10PIiIiotvFbMtseyuYbYmIiOiPjNmW2fZWMNsS0S0RIqJ6FhsbK5GRkSIiYjabJTU1VUwmk8yYMUNOnjwpOp1OioqKVGVCQ0Nl7ty5IiKSlJQkACQ7O1vZn5ubKwAkNTXVap0LFy6U8PBw1bZffvlFAEhubq6IiPTp00ceeugh1Xe6dOkis2fPVj4DkA0bNtR6jg888IAsW7ZMRESOHj0qACQjI0PZn5+fLwAkMTFRRER2794tLi4ucv36ddVxWrduLStWrLBax8qVK8XV1VVKSkqUbZs3bxatViunT58WEZENGzZIbVP93LlzpX379qpts2fPFgBy4cIFm+WGDBki06dPVz736dNH/va3v9VYl4jI5MmT5dFHH7W5PykpSRo0aKDaVvU8nJ2dZdWqVVbLjx8/XuLi4lTbdu/eLVqtVq5du6aMlQMHDij7LdfIcj2IiIiI6orZltmW2ZaIiIj+LJhtmW2ZbYmoPunv+koIIiIrvvrqKzg5OeHGjRswm80YPXo0EhISkJ6ejvLycvj7+6u+X1paisaNGyufjUYjOnTooHzOzs6GTqdDnz59rNZ3+PBh7Ny5U1mpW1lBQYFSX+VjAoCHh0etKzZLSkqQkJCAzZs3o7i4GDdv3sS1a9eUlbm5ubnQ6/UICgpSyvj5+cHV1VXVvpKSEtU5AsC1a9eU95VVdfToUXTs2BGOjo7Ktp49e8JsNiM3Nxfu7u41trvycbp166baFhISovpcXl6ORYsWITk5GUVFRSgrK0NpaSkcHBxqPf4777yDDz74AKdOncK1a9dQVlaGv/zlL3Vqmy3PPfccJkyYgI8//hhhYWGIjo5G69atAVT0ZU5OjuqxYCICs9mMwsJC5OXlQa/XIzg4WNnftm3bao8tIyIiIqorZltm29+D2ZaIiIj+SJhtmW1/D2ZbIroVXKhARPdEv3798O6778JoNKJ58+bQ6yumo5KSEuh0Ohw8eBA6nU5VpnJYtbe3V737yt7evsb6SkpKEBERgSVLllTb5+Hhofy35TFUFhqNBmazucZjz5gxA6mpqXjttdfg5+cHe3t7PPbYY8oj0eqipKQEHh4eqne6WfwRgtirr76KpUuX4s0330RgYCAcHR0xbdq0Ws9x3bp1mDFjBl5//XWEhITA2dkZr776Kvbv32+zjFarhYiott24cUP1OSEhAaNHj8bmzZvx9ddfY8GCBVi3bh2GDRuGkpISTJw4EVOnTq12bB8fH+Tl5d3CmRMRERHVjtm2evuYbSsw2xIREdH9htm2evuYbSsw2xLRncaFCkR0Tzg6OsLPz6/a9k6dOqG8vBxnz55Fr1696ny8wMBAmM1m7Nq1C2FhYdX2BwUF4YsvvkDLli2VcH07DAYDysvLVdv27NmDJ554AsOGDQNQEV5PnDih7A8ICMDNmzeRlZWlrAY9duwYLly4oGrf6dOnodfr0bJlyzq1pV27dli1ahWuXLmirM7ds2cPtFotAgIC6nxO7dq1w6ZNm1Tb9u3bV+0cIyMj8de//hUAYDabkZeXh/bt2yvfMRqNVvumR48emDRpkrLN1kpji6ZNm+Ly5cuq88rOzq72PX9/f/j7++PZZ5/FqFGjkJSUhGHDhiEoKAg//fST1fEFVKzCvXnzJg4ePIguXboAqFg9ffHixRrbRURERGQLsy2zrS3MtkRERHS/YbZltrWF2ZaI7jTtvW4AEVFl/v7+GDNmDGJiYrB+/XoUFhbiwIEDWLx4MTZv3myzXMuWLREbG4tx48YhJSUFhYWFSE9PR3JyMgBg8uTJOH/+PEaNGoWMjAwUFBRg27ZtePLJJ6uFtJq0bNkSaWlpOH36tBJY27Rpg/Xr1yM7OxuHDx/G6NGjVat527Zti7CwMMTFxeHAgQPIyspCXFycanVxWFgYQkJCEBUVhW+++QYnTpzA3r178fzzzyMzM9NqW8aMGQM7OzvExsbiyJEj2LlzJ6ZMmYKxY8fW+fFhAPD0008jPz8fM2fORG5uLj755BOsWrVK9Z02bdogNTUVe/fuxdGjRzFx4kScOXOmWt/s378fJ06cwG+//Qaz2Yw2bdogMzMT27ZtQ15eHv7+978jIyOjxvZ069YNDg4OmDdvHgoKCqq159q1a4iPj0d6ejpOnjyJPXv2ICMjA+3atQMAzJ49G3v37kV8fDyys7ORn5+PjRs3Ij4+HkDFP0AGDRqEiRMnYv/+/Th48CAmTJhQ6+puIiIiolvFbMtsy2xLREREfxbMtsy2zLZEdKdxoQIR/eEkJSUhJiYG06dPR0BAAKKiopCRkQEfH58ay7377rt47LHHMGnSJLRt2xZPPfUUrly5AgBo3rw59uzZg/LycoSHhyMwMBDTpk1Dw4YNodXWfSp8/fXXkZqaCm9vb3Tq1AkA8MYbb8DV1RU9evRAREQEBg4cqHqvGQB89NFHcHd3R+/evTFs2DA89dRTcHZ2hp2dHYCKR5Vt2bIFvXv3xpNPPgl/f388/vjjOHnypM3w6uDggG3btuH8+fPo0qULHnvsMYSGhuLtt9+u8/kAFY/V+uKLL5CSkoKOHTvivffew6JFi1TfeeGFFxAUFISBAweib9++aNasGaKiolTfmTFjBnQ6Hdq3b4+mTZvi1KlTmDhxIoYPH46RI0eiW7duOHfunGqVrjWNGjXC6tWrsWXLFgQGBmLt2rVISEhQ9ut0Opw7dw4xMTHw9/fHiBEjMHjwYLz44osAKt5Xt2vXLuTl5aFXr17o1KkT5s+fj+bNmyvHSEpKQvPmzdGnTx8MHz4ccXFxcHNzu6V+IyIiIqoLZltmW2ZbIiIi+rNgtmW2ZbYlojtJI1VfKENERHfdf/7zH3h7e2P79u0IDQ29180hIiIiIrptzLZERERE9GfBbEtEVH+4UIGIqB7s2LEDJSUlCAwMRHFxMWbNmoWioiLk5eXBYDDc6+YREREREdUZsy0RERER/Vkw2xIR3Tv6e90AIqL/BTdu3MC8efNw/PhxODs7o0ePHlizZg3DLhERERHdd5htiYiIiOjPgtmWiOje4RMViIiIiIiIiIiIiIiIiIiIqN5o73UDiIiIiIiIiIiIiIiIiIiI6H8HFyoQERERERERERERERERERFRveFCBSIiIiIiIiIiIiIiIiIiIqo3XKhARERERERERERERERERERE9YYLFYiIiIiIiIiIiIiIiIiIiKjecKECERERERERERERERERERER1RsuVCAiIiIiIiIiIiIiIiIiIqJ6w4UKREREREREREREREREREREVG+4UIGIiIiIiIiIiIiIiIiIiIjqzf8DH5RjArHZmbAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66c5104",
   "metadata": {
    "papermill": {
     "duration": 0.150706,
     "end_time": "2025-01-08T09:32:27.604840",
     "exception": false,
     "start_time": "2025-01-08T09:32:27.454134",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a6912af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T09:32:27.905840Z",
     "iopub.status.busy": "2025-01-08T09:32:27.905551Z",
     "iopub.status.idle": "2025-01-08T09:57:32.087006Z",
     "shell.execute_reply": "2025-01-08T09:57:32.086230Z"
    },
    "papermill": {
     "duration": 1504.334069,
     "end_time": "2025-01-08T09:57:32.088445",
     "exception": false,
     "start_time": "2025-01-08T09:32:27.754376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 3\n",
      "Random seed: 14\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6708, Accuracy: 0.832, F1 Micro: 0.8709, F1 Macro: 0.6144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5673, Accuracy: 0.9609, F1 Micro: 0.9702, F1 Macro: 0.6503\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4855, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4136, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3704, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.322, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2931, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.267, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.243, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2233, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 25: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 36.87833881378174 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.1612812638282776\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 38\n",
      "Sampling duration: 5.2698822021484375 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6807, Accuracy: 0.8047, F1 Micro: 0.8558, F1 Macro: 0.6203\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5624, Accuracy: 0.9622, F1 Micro: 0.9713, F1 Macro: 0.6512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4999, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4305, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3849, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3364, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3263, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2763, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2801, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2544, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 63: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 36.53790593147278 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.14697309732437133\n",
      "Samples above threshold: 34\n",
      "Acquired samples: 34\n",
      "Sampling duration: 4.967960596084595 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6272, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.465, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3688, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3127, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2796, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2394, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2183, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2115, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.199, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1871, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 97: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 42.10099220275879 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.06895221471786499\n",
      "Samples above threshold: 31\n",
      "Acquired samples: 31\n",
      "Sampling duration: 4.844598054885864 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6269, Accuracy: 0.9648, F1 Micro: 0.9733, F1 Macro: 0.6527\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4621, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3597, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3036, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2769, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2266, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2248, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1965, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2047, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1792, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 128: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 42.47267770767212 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.0658433198928833\n",
      "Samples above threshold: 28\n",
      "Acquired samples: 28\n",
      "Sampling duration: 4.5238847732543945 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5835, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3948, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2969, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2471, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2283, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2287, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.203, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1749, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1806, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1905, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 156: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 47.999945640563965 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.04419600367546082\n",
      "Samples above threshold: 25\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.7981514930725098 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.585, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3893, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3001, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2427, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2374, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1963, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1901, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1694, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1784, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.179, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 181: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 49.21348595619202 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.04281461238861084\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 22\n",
      "Sampling duration: 3.554950714111328 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5515, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3341, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2604, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2226, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2266, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1925, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1634, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.159, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1506, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1893, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 203: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 54.5223867893219 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.033528125286102294\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 20\n",
      "Sampling duration: 3.4289438724517822 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5438, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3272, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2527, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2264, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1976, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2099, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.186, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1641, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1725, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1657, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 223: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 54.62274622917175 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.03323719501495361\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 18\n",
      "Sampling duration: 3.077955722808838 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5403, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3304, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2487, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2007, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2067, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1797, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1784, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1673, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.166, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1653, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 241: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 53.838449478149414 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.03157142400741577\n",
      "Samples above threshold: 16\n",
      "Acquired samples: 9\n",
      "Sampling duration: 2.936370372772217 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5447, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3261, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2588, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2258, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2204, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1882, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1681, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1752, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1823, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1675, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 250: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 54.07383584976196 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 0.0316809356212616\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 15\n",
      "Sampling duration: 2.7395739555358887 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5151, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2285, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1966, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1923, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1848, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1712, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1701, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1723, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.162, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 265: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.63436007499695 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 0.027288830280303954\n",
      "Samples above threshold: 14\n",
      "Acquired samples: 14\n",
      "Sampling duration: 2.608778953552246 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5135, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2934, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2424, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2049, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1907, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1778, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.185, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.169, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1663, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1569, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 279: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.93277549743652 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 0.02604997158050537\n",
      "Samples above threshold: 13\n",
      "Acquired samples: 13\n",
      "Sampling duration: 2.4235737323760986 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5177, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2931, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2213, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1959, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1984, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1945, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1851, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.171, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1675, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1814, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 292: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 58.80432391166687 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 0.02584478259086609\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 8\n",
      "Sampling duration: 2.385648250579834 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5115, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2923, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2377, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1993, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2002, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1758, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1771, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1886, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1586, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1707, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 300: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 58.7568142414093 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 0.02493566870689392\n",
      "Samples above threshold: 10\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.571300745010376 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5146, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2931, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2246, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2205, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1831, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1742, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1898, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.159, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1602, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.164, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 310: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.39218473434448 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 0.025847262144088744\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.0618836879730225 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5103, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3109, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2347, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.207, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1762, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1796, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1691, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1727, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1577, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1565, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 320: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.482600927352905 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 0.02485477924346924\n",
      "Samples above threshold: 8\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.8481013774871826 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4866, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2707, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.219, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2231, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1836, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1808, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1823, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1694, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.167, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Epoch 10/10, Train Loss: 0.1667, Accuracy: 0.9635, F1 Micro: 0.9723, F1 Macro: 0.652\n",
      "Iteration 330: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 62.0080087184906 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 0.023504430055618288\n",
      "Samples above threshold: 7\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.7868707180023193 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4906, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2791, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2124, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2015, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.177, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1783, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1566, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1596, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.184, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1707, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 340: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.558451652526855 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 0.023795807361602785\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.740966558456421 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4907, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2727, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2195, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1972, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1821, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1757, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1695, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1588, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1719, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1593, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 350: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 62.83299684524536 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.02393317222595215\n",
      "Samples above threshold: 5\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.5428109169006348 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4846, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2813, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2153, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1957, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.186, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1688, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1709, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1736, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1462, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1546, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 360: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.74885320663452 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.024102765321731567\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.5574958324432373 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4881, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2598, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2202, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1955, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1756, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1589, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.168, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1662, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1707, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1307, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 370: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.90579271316528 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.02195513844490051\n",
      "Samples above threshold: 3\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.3929243087768555 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4854, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2769, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1994, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1958, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1824, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.16, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1771, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.151, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1586, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1463, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 380: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.9667272567749 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.02262144088745117\n",
      "Samples above threshold: 2\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.3327252864837646 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4662, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2421, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1928, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1791, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1638, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1719, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1529, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1521, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1509, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1422, Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6546\n",
      "Iteration 390: Accuracy: 0.9688, F1 Micro: 0.9761, F1 Macro: 0.6546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.89      0.98      0.94       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.97      0.98      0.98       500\n",
      "   macro avg       0.65      0.66      0.65       500\n",
      "weighted avg       0.96      0.98      0.97       500\n",
      " samples avg       0.97      0.98      0.97       500\n",
      "\n",
      "Training completed in 67.72493267059326 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.021783745288848876\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.135634183883667 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4596, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2534, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2063, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1724, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1567, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1737, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1656, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1474, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1594, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Epoch 10/10, Train Loss: 0.1399, Accuracy: 0.9635, F1 Micro: 0.9723, F1 Macro: 0.652\n",
      "Iteration 400: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 66.1114547252655 s\n",
      "Total sampling time: 63.53 seconds\n",
      "Total runtime: 1503.3879988193512 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015fccf0",
   "metadata": {
    "papermill": {
     "duration": 0.222108,
     "end_time": "2025-01-08T09:57:32.538504",
     "exception": false,
     "start_time": "2025-01-08T09:57:32.316396",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db482257",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T09:57:32.982233Z",
     "iopub.status.busy": "2025-01-08T09:57:32.981894Z",
     "iopub.status.idle": "2025-01-08T10:22:45.656352Z",
     "shell.execute_reply": "2025-01-08T10:22:45.655550Z"
    },
    "papermill": {
     "duration": 1512.896975,
     "end_time": "2025-01-08T10:22:45.657773",
     "exception": false,
     "start_time": "2025-01-08T09:57:32.760798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 4\n",
      "Random seed: 3\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6467, Accuracy: 0.9648, F1 Micro: 0.9733, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5398, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4478, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3936, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3431, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.31, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2886, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2554, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2562, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2399, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 25: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 35.88699746131897 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.11278802156448364\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 38\n",
      "Sampling duration: 4.879842042922974 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6416, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5409, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4579, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3902, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3506, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3085, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3051, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2669, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2726, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2215, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 63: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 36.55190134048462 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.10644690990447998\n",
      "Samples above threshold: 34\n",
      "Acquired samples: 34\n",
      "Sampling duration: 4.594078302383423 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5994, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4256, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3337, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.28, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2459, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2156, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2071, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2032, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1876, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.171, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 97: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 41.65456700325012 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.05387058258056641\n",
      "Samples above threshold: 31\n",
      "Acquired samples: 31\n",
      "Sampling duration: 4.5177905559539795 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5939, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4423, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.33, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.295, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2484, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2274, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2108, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2101, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2067, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2056, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 128: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 42.03994536399841 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.05184352397918701\n",
      "Samples above threshold: 28\n",
      "Acquired samples: 28\n",
      "Sampling duration: 4.169515132904053 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.551, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3601, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2843, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.234, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2156, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2036, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1837, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1735, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1731, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1815, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 156: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 49.92494869232178 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.03084811568260193\n",
      "Samples above threshold: 25\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.750854730606079 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5498, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3551, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2793, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2293, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2386, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2091, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1926, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1863, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1903, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1916, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 181: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 47.946515798568726 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.030877530574798584\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 22\n",
      "Sampling duration: 3.524686098098755 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5134, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3173, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2179, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2392, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.204, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1924, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1893, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1776, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1821, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1721, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 203: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 53.42837452888489 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.02341001033782959\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 20\n",
      "Sampling duration: 3.508399248123169 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5164, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.304, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2465, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.212, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2118, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1868, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1843, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1831, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1636, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1586, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 223: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 53.59081506729126 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.022626519203186035\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 18\n",
      "Sampling duration: 3.0441031455993652 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5137, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2986, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2301, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2055, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1994, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1882, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1875, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1816, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1881, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1664, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 241: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 54.32040619850159 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.02189556360244751\n",
      "Samples above threshold: 16\n",
      "Acquired samples: 9\n",
      "Sampling duration: 2.8668227195739746 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5091, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3145, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2384, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2047, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1928, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1893, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1816, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.171, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1858, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1767, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 250: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 54.090615034103394 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 0.022037422657012938\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 15\n",
      "Sampling duration: 2.823976755142212 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4748, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2826, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2327, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1873, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1634, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1924, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.186, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1688, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1722, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1527, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 265: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.95457053184509 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 0.016851425170898438\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 14\n",
      "Sampling duration: 2.631061553955078 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4779, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2748, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2125, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1937, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1968, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1811, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1623, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1706, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1701, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1569, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 279: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 58.83885049819946 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 0.01748061180114746\n",
      "Samples above threshold: 13\n",
      "Acquired samples: 13\n",
      "Sampling duration: 3.1904494762420654 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4819, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2774, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2136, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1963, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1979, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1838, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1701, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1717, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1618, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1653, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 292: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.81871318817139 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 0.0177190363407135\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 8\n",
      "Sampling duration: 2.785491943359375 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4793, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2885, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2214, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1879, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1911, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1758, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1733, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1834, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.156, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1597, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 300: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.026625633239746 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 0.01757858395576477\n",
      "Samples above threshold: 10\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.738783121109009 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4833, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2763, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2197, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.199, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1891, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1785, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1885, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1783, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1471, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.159, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 310: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 58.94317603111267 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 0.017257559299468993\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.662572145462036 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4757, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2812, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.204, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1877, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1879, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1855, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1719, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1577, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1792, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1757, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 320: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 60.55513119697571 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 0.017811667919158936\n",
      "Samples above threshold: 8\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.506129026412964 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4513, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2494, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1991, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1957, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.192, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1836, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1731, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1614, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1636, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1683, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 330: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.9660279750824 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 0.015296411514282227\n",
      "Samples above threshold: 7\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.276871681213379 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4526, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2512, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.202, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1988, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1762, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1652, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1673, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1549, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1768, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1538, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 340: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.83067488670349 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 0.015284830331802368\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.253357410430908 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4491, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2415, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2088, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1871, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1701, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1698, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1693, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1553, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1767, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1664, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 350: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.890578746795654 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.015304404497146606\n",
      "Samples above threshold: 5\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.6487159729003906 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4485, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2454, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2057, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1787, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1782, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1561, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1557, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1599, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1679, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1465, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 360: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.29839015007019 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.014678072929382325\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.4909651279449463 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4622, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2364, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2056, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1936, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1777, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1623, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1665, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1573, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1592, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.163, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 370: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 62.88180923461914 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.015364921092987061\n",
      "Samples above threshold: 3\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.370032787322998 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4556, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2452, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2111, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1885, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.177, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1605, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1733, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1805, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1475, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.16, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 380: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 62.9467134475708 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.015036183595657348\n",
      "Samples above threshold: 2\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.2773394584655762 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.426, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2388, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1752, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1768, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1561, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1632, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1589, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1537, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1536, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1688, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 390: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 68.1748275756836 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.013716679811477662\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.1352097988128662 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4293, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2326, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2037, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1834, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1693, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1651, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1606, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.166, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1575, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1502, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 400: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 67.94774961471558 s\n",
      "Total sampling time: 65.65 seconds\n",
      "Total runtime: 1511.9142150878906 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ff09a3",
   "metadata": {
    "papermill": {
     "duration": 0.352623,
     "end_time": "2025-01-08T10:22:46.310557",
     "exception": false,
     "start_time": "2025-01-08T10:22:45.957934",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77ec1232",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T10:22:46.899979Z",
     "iopub.status.busy": "2025-01-08T10:22:46.899654Z",
     "iopub.status.idle": "2025-01-08T10:47:51.623340Z",
     "shell.execute_reply": "2025-01-08T10:47:51.622623Z"
    },
    "papermill": {
     "duration": 1505.022369,
     "end_time": "2025-01-08T10:47:51.624732",
     "exception": false,
     "start_time": "2025-01-08T10:22:46.602363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 5\n",
      "Random seed: 94\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7246, Accuracy: 0.8529, F1 Micro: 0.8964, F1 Macro: 0.6595\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5992, Accuracy: 0.9492, F1 Micro: 0.962, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5024, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4281, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3713, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3311, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3032, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2839, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.259, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2665, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 25: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 36.27127528190613 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.12755829095840454\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 38\n",
      "Sampling duration: 4.936751127243042 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7299, Accuracy: 0.8711, F1 Micro: 0.9063, F1 Macro: 0.6477\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6047, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5033, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4168, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3632, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3296, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2957, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2935, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2462, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2567, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 63: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 36.38306546211243 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.12463263273239136\n",
      "Samples above threshold: 34\n",
      "Acquired samples: 34\n",
      "Sampling duration: 4.537949323654175 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6583, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4546, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.343, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2855, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2536, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2243, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2242, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1766, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1881, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1926, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 97: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 42.38722825050354 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.055981779098510744\n",
      "Samples above threshold: 31\n",
      "Acquired samples: 31\n",
      "Sampling duration: 4.363050222396851 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.662, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4664, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3359, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2852, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2369, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2452, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2201, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2139, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1851, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1648, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 128: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 42.30639696121216 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.05462909936904907\n",
      "Samples above threshold: 28\n",
      "Acquired samples: 28\n",
      "Sampling duration: 4.213910102844238 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6093, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3737, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2692, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2332, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1955, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1944, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1875, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1796, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1662, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1653, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 156: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 49.06783580780029 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.034584718942642215\n",
      "Samples above threshold: 25\n",
      "Acquired samples: 25\n",
      "Sampling duration: 3.839526653289795 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6089, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3649, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2773, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2263, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1831, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1872, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.184, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1545, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1673, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1536, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 181: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 49.65725088119507 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.03577456474304199\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 22\n",
      "Sampling duration: 3.6548876762390137 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5636, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3133, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2226, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1807, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1722, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1629, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.187, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1619, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.158, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.163, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 203: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 53.70553779602051 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.02727177143096924\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 20\n",
      "Sampling duration: 3.337749719619751 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5633, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3135, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2348, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2101, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1912, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1735, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.176, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1585, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1727, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1701, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 223: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 53.55699944496155 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.0266038179397583\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 18\n",
      "Sampling duration: 3.079477071762085 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5602, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3158, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2484, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1956, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.177, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.183, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1857, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1617, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1548, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1514, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 241: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 53.913047075271606 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.026051855087280272\n",
      "Samples above threshold: 16\n",
      "Acquired samples: 9\n",
      "Sampling duration: 2.964923143386841 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5605, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3175, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2386, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2114, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1714, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1611, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1622, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1297, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1619, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1465, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 250: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 53.84138083457947 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 0.026271647214889525\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 15\n",
      "Sampling duration: 2.757089614868164 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5283, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2803, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2161, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1936, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1833, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1854, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1608, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1643, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1683, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1555, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 265: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 60.178964376449585 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 0.022020483016967775\n",
      "Samples above threshold: 14\n",
      "Acquired samples: 14\n",
      "Sampling duration: 2.671137809753418 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5245, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2731, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2175, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1982, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1764, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1762, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.182, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1613, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1775, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.167, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 279: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 58.811700105667114 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 0.0212552547454834\n",
      "Samples above threshold: 13\n",
      "Acquired samples: 13\n",
      "Sampling duration: 2.4817869663238525 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5269, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2632, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2235, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1864, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1672, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1736, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1639, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1566, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1594, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1622, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 292: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.30214858055115 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 0.020874738693237305\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 8\n",
      "Sampling duration: 2.3348052501678467 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5211, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2841, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2214, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2084, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1574, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1641, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1816, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.161, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1667, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.155, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 300: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 58.96827530860901 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 0.02176746129989624\n",
      "Samples above threshold: 10\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.2875771522521973 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5187, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2722, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2115, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1926, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1858, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1822, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1708, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1652, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1553, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1499, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 310: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.52897548675537 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 0.021275931596755983\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.0953598022460938 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5241, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2788, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.217, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1927, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1747, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1743, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1613, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1775, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1711, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1511, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 320: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 58.845518350601196 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 0.020953798294067384\n",
      "Samples above threshold: 8\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.0529820919036865 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4907, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2599, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2005, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.178, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1611, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1425, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1646, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1512, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1363, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.158, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 330: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.85705757141113 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 0.019935953617095947\n",
      "Samples above threshold: 7\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.8471293449401855 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4852, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2462, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2102, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1843, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1829, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1658, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1692, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1547, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1545, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1531, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 340: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 64.06481957435608 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 0.0186664879322052\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.7820470333099365 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4862, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2493, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1939, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1647, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1757, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1541, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1665, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1648, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1729, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1472, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 350: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.642892360687256 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.017818921804428102\n",
      "Samples above threshold: 5\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.635571002960205 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4849, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2526, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1954, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1759, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1926, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.167, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1684, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.154, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1606, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1453, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 360: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 62.972203731536865 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.019726490974426268\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.573256492614746 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4857, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2518, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2111, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1877, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1927, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1614, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1579, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1642, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1571, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1649, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 370: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.68022394180298 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.016867446899414062\n",
      "Samples above threshold: 3\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.4235882759094238 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4908, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2545, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1853, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1795, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1739, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1738, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1624, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1534, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1583, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1787, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 380: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 64.41447591781616 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.016890960931777953\n",
      "Samples above threshold: 2\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.2977821826934814 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4593, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2315, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.203, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1703, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1697, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1759, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1635, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1471, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1593, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1428, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 390: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 70.25746631622314 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.016206645965576173\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.360206127166748 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4642, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2248, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.195, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1859, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1632, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1613, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1725, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1464, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1529, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1387, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 400: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 69.3303554058075 s\n",
      "Total sampling time: 62.53 seconds\n",
      "Total runtime: 1503.9807631969452 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[4], 4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6155806,
     "sourceId": 10000921,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7544.187175,
   "end_time": "2025-01-08T10:47:54.964182",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-08T08:42:10.777007",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0311b432c82a4afdbdca8195c90c52b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1a1f4e1f2292467fa1096881a1753569",
        "IPY_MODEL_17952fcd50e64a8181a1a8d3305a8ad5",
        "IPY_MODEL_1333421d95f3410e9c27b72c2137cfbe"
       ],
       "layout": "IPY_MODEL_f6dfdc781de44a2eb9283980961cbec2",
       "tabbable": null,
       "tooltip": null
      }
     },
     "0b697f977f84479399086ab68e5dbdce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_73e0675d06ee4d5cb45c07fca81d5a76",
       "placeholder": "",
       "style": "IPY_MODEL_55bb66d1007b4dc6a172e697c4b84a2f",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json:100%"
      }
     },
     "0d709052b7e84ca19457948c40386505": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0face37fdd524cd8ad53a73618bf721c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1333421d95f3410e9c27b72c2137cfbe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4d197a26370448f8bbe2d5ae5947e0cb",
       "placeholder": "",
       "style": "IPY_MODEL_2d014a2980bc4ffea5113a155db08888",
       "tabbable": null,
       "tooltip": null,
       "value": "498M/498M[00:02&lt;00:00,243MB/s]"
      }
     },
     "17952fcd50e64a8181a1a8d3305a8ad5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_29f4632313994470842233395af6ff9c",
       "max": 497810400.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8dc50605582446b9b837bd43f14308b0",
       "tabbable": null,
       "tooltip": null,
       "value": 497810400.0
      }
     },
     "1a1f4e1f2292467fa1096881a1753569": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ee34aa332f254d20b4d57308ca86e404",
       "placeholder": "",
       "style": "IPY_MODEL_8e5b0c80fe4a409cb3845576dcebd398",
       "tabbable": null,
       "tooltip": null,
       "value": "pytorch_model.bin:100%"
      }
     },
     "21713d6a5b58403abecd116ebbb03bbc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "29f4632313994470842233395af6ff9c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2af4ffa339ca42c29ae5c0db3efa45cc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0b697f977f84479399086ab68e5dbdce",
        "IPY_MODEL_db50728250504dc8a7f6fcfccb188adc",
        "IPY_MODEL_bf769c9f61ac4c0d8929bd369474d58b"
       ],
       "layout": "IPY_MODEL_d2cd4f45253b47e5ae20d9c2eff2af3b",
       "tabbable": null,
       "tooltip": null
      }
     },
     "2d014a2980bc4ffea5113a155db08888": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3e45108c531f4aa1b8e85a5df780adc0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "446bb523c44c4449bc969a5a1ab02fe4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8e0f252e6a624676950029117815c6f1",
       "placeholder": "",
       "style": "IPY_MODEL_dab8947555d7400c9f01684cadbfa654",
       "tabbable": null,
       "tooltip": null,
       "value": "229k/229k[00:00&lt;00:00,6.93MB/s]"
      }
     },
     "44f2a787c3174000a1cb67317de71164": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_740ce70e921142cf92f3262bfa492757",
       "placeholder": "",
       "style": "IPY_MODEL_6f1b6f712aad4080ae3dc3fddefa2e67",
       "tabbable": null,
       "tooltip": null,
       "value": "2.00/2.00[00:00&lt;00:00,215B/s]"
      }
     },
     "45d524ae83694c10ab4bdda1372b766f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d9e42fa1756446df96c8f900b2d4f5ff",
       "max": 112.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f90432b1742040bc80b6ed4e70cc1b9c",
       "tabbable": null,
       "tooltip": null,
       "value": 112.0
      }
     },
     "4c07e422b8fe426c9f814fc3da2d73c0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a2748d4e9e8f4874a3b0c72d1193cc82",
        "IPY_MODEL_b566c6880bf74d2d8400a7be9f659d1f",
        "IPY_MODEL_44f2a787c3174000a1cb67317de71164"
       ],
       "layout": "IPY_MODEL_d9f70146f6494dfdb9a1b709760f3982",
       "tabbable": null,
       "tooltip": null
      }
     },
     "4d197a26370448f8bbe2d5ae5947e0cb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "53eb496c75f5456c906ace783eb784ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_61ed626090ec4a8385b827ffce96144d",
        "IPY_MODEL_45d524ae83694c10ab4bdda1372b766f",
        "IPY_MODEL_9c3530d74cea4a7781ed467b35f9d895"
       ],
       "layout": "IPY_MODEL_e193ed1c685043f5a2c74cfd76b69fd1",
       "tabbable": null,
       "tooltip": null
      }
     },
     "55bb66d1007b4dc6a172e697c4b84a2f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6119c0e2a0684716acde71ff70e5dfae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "61ed626090ec4a8385b827ffce96144d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9500e03716314ea3a3df52f2ec94a34c",
       "placeholder": "",
       "style": "IPY_MODEL_aa1d18e59d2945ef90b2e2ecb1679758",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json:100%"
      }
     },
     "6f1b6f712aad4080ae3dc3fddefa2e67": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6f991cfaa703431198b80b3a07a84510": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e8fd1940ddc84e78a4dfcca66b8fa418",
        "IPY_MODEL_83f79ec7290e449ea559b6b721966320",
        "IPY_MODEL_446bb523c44c4449bc969a5a1ab02fe4"
       ],
       "layout": "IPY_MODEL_becc47b8aefd4291a680ad7f51ed956f",
       "tabbable": null,
       "tooltip": null
      }
     },
     "73e0675d06ee4d5cb45c07fca81d5a76": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "740ce70e921142cf92f3262bfa492757": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "83f79ec7290e449ea559b6b721966320": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a98d661126d74ca7bcce2a911cc2d0c0",
       "max": 229167.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ac60f21238964058b30f1d5007174ead",
       "tabbable": null,
       "tooltip": null,
       "value": 229167.0
      }
     },
     "8dc50605582446b9b837bd43f14308b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8e0f252e6a624676950029117815c6f1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8e5b0c80fe4a409cb3845576dcebd398": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9500e03716314ea3a3df52f2ec94a34c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9b4c7c25bec545b584565bfee8cfb055": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9c3530d74cea4a7781ed467b35f9d895": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0d709052b7e84ca19457948c40386505",
       "placeholder": "",
       "style": "IPY_MODEL_e05848e18a2b479d8ae0f7bb4de400f6",
       "tabbable": null,
       "tooltip": null,
       "value": "112/112[00:00&lt;00:00,12.1kB/s]"
      }
     },
     "a0fc9e39f2e34f1ab2a9bcb25a3e3510": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a2748d4e9e8f4874a3b0c72d1193cc82": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0face37fdd524cd8ad53a73618bf721c",
       "placeholder": "",
       "style": "IPY_MODEL_6119c0e2a0684716acde71ff70e5dfae",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json:100%"
      }
     },
     "a98d661126d74ca7bcce2a911cc2d0c0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aa1d18e59d2945ef90b2e2ecb1679758": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ac60f21238964058b30f1d5007174ead": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b14aaa18885642938198b8160a7db1ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b238b00f91d9468d88ab783b0aa70c16": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b566c6880bf74d2d8400a7be9f659d1f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d6d72a0983064802bca11ef175bb6a7d",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_21713d6a5b58403abecd116ebbb03bbc",
       "tabbable": null,
       "tooltip": null,
       "value": 2.0
      }
     },
     "becc47b8aefd4291a680ad7f51ed956f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bf769c9f61ac4c0d8929bd369474d58b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b238b00f91d9468d88ab783b0aa70c16",
       "placeholder": "",
       "style": "IPY_MODEL_a0fc9e39f2e34f1ab2a9bcb25a3e3510",
       "tabbable": null,
       "tooltip": null,
       "value": "1.53k/1.53k[00:00&lt;00:00,166kB/s]"
      }
     },
     "d0d8844fd82a4165b2aa8433d7861c55": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d2cd4f45253b47e5ae20d9c2eff2af3b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d6d72a0983064802bca11ef175bb6a7d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d9e42fa1756446df96c8f900b2d4f5ff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d9f70146f6494dfdb9a1b709760f3982": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dab8947555d7400c9f01684cadbfa654": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "db50728250504dc8a7f6fcfccb188adc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d0d8844fd82a4165b2aa8433d7861c55",
       "max": 1534.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b14aaa18885642938198b8160a7db1ed",
       "tabbable": null,
       "tooltip": null,
       "value": 1534.0
      }
     },
     "e05848e18a2b479d8ae0f7bb4de400f6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e193ed1c685043f5a2c74cfd76b69fd1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e8fd1940ddc84e78a4dfcca66b8fa418": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9b4c7c25bec545b584565bfee8cfb055",
       "placeholder": "",
       "style": "IPY_MODEL_3e45108c531f4aa1b8e85a5df780adc0",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt:100%"
      }
     },
     "ee34aa332f254d20b4d57308ca86e404": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f6dfdc781de44a2eb9283980961cbec2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f90432b1742040bc80b6ed4e70cc1b9c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
