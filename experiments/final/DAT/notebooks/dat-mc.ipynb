{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b1e2271",
   "metadata": {
    "papermill": {
     "duration": 0.013505,
     "end_time": "2025-01-08T08:31:53.656285",
     "exception": false,
     "start_time": "2025-01-08T08:31:53.642780",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07728a91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:31:53.680360Z",
     "iopub.status.busy": "2025-01-08T08:31:53.680075Z",
     "iopub.status.idle": "2025-01-08T08:31:59.983008Z",
     "shell.execute_reply": "2025-01-08T08:31:59.982345Z"
    },
    "papermill": {
     "duration": 6.316774,
     "end_time": "2025-01-08T08:31:59.984572",
     "exception": false,
     "start_time": "2025-01-08T08:31:53.667798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5da8fb",
   "metadata": {
    "papermill": {
     "duration": 0.011037,
     "end_time": "2025-01-08T08:32:00.007452",
     "exception": false,
     "start_time": "2025-01-08T08:31:59.996415",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a69fddb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:32:00.030794Z",
     "iopub.status.busy": "2025-01-08T08:32:00.030420Z",
     "iopub.status.idle": "2025-01-08T08:32:00.033834Z",
     "shell.execute_reply": "2025-01-08T08:32:00.033107Z"
    },
    "papermill": {
     "duration": 0.016519,
     "end_time": "2025-01-08T08:32:00.035224",
     "exception": false,
     "start_time": "2025-01-08T08:32:00.018705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad1e54d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:32:00.058921Z",
     "iopub.status.busy": "2025-01-08T08:32:00.058681Z",
     "iopub.status.idle": "2025-01-08T08:32:00.062420Z",
     "shell.execute_reply": "2025-01-08T08:32:00.061833Z"
    },
    "papermill": {
     "duration": 0.016698,
     "end_time": "2025-01-08T08:32:00.063568",
     "exception": false,
     "start_time": "2025-01-08T08:32:00.046870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/working/results') == False:\n",
    "    os.mkdir('/kaggle/working/results')\n",
    "\n",
    "if os.path.exists('/kaggle/working/acquired_data') == False:\n",
    "    os.mkdir('/kaggle/working/acquired_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "501a6190",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:32:00.086730Z",
     "iopub.status.busy": "2025-01-08T08:32:00.086504Z",
     "iopub.status.idle": "2025-01-08T08:32:00.094717Z",
     "shell.execute_reply": "2025-01-08T08:32:00.093944Z"
    },
    "papermill": {
     "duration": 0.021033,
     "end_time": "2025-01-08T08:32:00.095882",
     "exception": false,
     "start_time": "2025-01-08T08:32:00.074849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2660c622",
   "metadata": {
    "papermill": {
     "duration": 0.01118,
     "end_time": "2025-01-08T08:32:00.118540",
     "exception": false,
     "start_time": "2025-01-08T08:32:00.107360",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b59d064f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:32:00.141918Z",
     "iopub.status.busy": "2025-01-08T08:32:00.141680Z",
     "iopub.status.idle": "2025-01-08T08:32:00.181889Z",
     "shell.execute_reply": "2025-01-08T08:32:00.180551Z"
    },
    "papermill": {
     "duration": 0.053565,
     "end_time": "2025-01-08T08:32:00.183327",
     "exception": false,
     "start_time": "2025-01-08T08:32:00.129762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Shared resources\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "data_used = manager.list()\n",
    "sampling_dur = manager.list()\n",
    "new_samples = manager.list()\n",
    "\n",
    "# Non shared resources\n",
    "filename = 'dat-mc'\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "sequence_length = 96"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9b0f8d",
   "metadata": {
    "papermill": {
     "duration": 0.011098,
     "end_time": "2025-01-08T08:32:00.205547",
     "exception": false,
     "start_time": "2025-01-08T08:32:00.194449",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6bf6c83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:32:00.229080Z",
     "iopub.status.busy": "2025-01-08T08:32:00.228783Z",
     "iopub.status.idle": "2025-01-08T08:32:00.333443Z",
     "shell.execute_reply": "2025-01-08T08:32:00.332662Z"
    },
    "papermill": {
     "duration": 0.117986,
     "end_time": "2025-01-08T08:32:00.334726",
     "exception": false,
     "start_time": "2025-01-08T08:32:00.216740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>answer</th>\n",
       "      <th>1-FR</th>\n",
       "      <th>2-GI</th>\n",
       "      <th>3-PI</th>\n",
       "      <th>4-DM</th>\n",
       "      <th>5-EDTRB</th>\n",
       "      <th>6-RE</th>\n",
       "      <th>Text_Clean</th>\n",
       "      <th>filtered_text</th>\n",
       "      <th>token</th>\n",
       "      <th>tokens_stemmed</th>\n",
       "      <th>Process_Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Halo Rizal,Radang tenggorokan umunya disebabka...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo rizal radang tenggorokan umunya disebabka...</td>\n",
       "      <td>halo rizal radang tenggorokan umunya disebabka...</td>\n",
       "      <td>['halo', 'rizal', 'radang', 'tenggorokan', 'um...</td>\n",
       "      <td>['halo', 'rizal', 'radang', 'tenggorok', 'umu'...</td>\n",
       "      <td>halo rizal radang tenggorok umu sebab infeksi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Halo Hellas,Cacar air merupakan suatu penyakit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo hellas cacar air merupakan suatu penyakit...</td>\n",
       "      <td>halo hellas cacar air penyakit disebabkan viru...</td>\n",
       "      <td>['halo', 'hellas', 'cacar', 'air', 'penyakit',...</td>\n",
       "      <td>['halo', 'hellas', 'cacar', 'air', 'sakit', 's...</td>\n",
       "      <td>halo hellas cacar air sakit sebab virus varise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Halo Rory.......Terimakasih atas pertanyaan An...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo rory terimakasih atas pertanyaan anda per...</td>\n",
       "      <td>halo rory terimakasih ketahui gangguan kulit s...</td>\n",
       "      <td>['halo', 'rory', 'terimakasih', 'ketahui', 'ga...</td>\n",
       "      <td>['halo', 'rory', 'terimakasih', 'tahu', 'gangg...</td>\n",
       "      <td>halo rory terimakasih tahu ganggu kulit rangka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Alo AfriYani, Terimakasih atas pertanyaannya. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>alo afriyani terimakasih atas pertanyaannya ku...</td>\n",
       "      <td>alo afriyani terimakasih pertanyaannya kuku ja...</td>\n",
       "      <td>['alo', 'afriyani', 'terimakasih', 'pertanyaan...</td>\n",
       "      <td>['alo', 'afriyani', 'terimakasih', 'tanya', 'k...</td>\n",
       "      <td>alo afriyani terimakasih tanya kuku jari kaki ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Halo,Telinga berdenging atau  tinitus  merupak...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo telinga berdenging atau tinitus merupakan...</td>\n",
       "      <td>halo telinga berdenging tinitus sensasi penden...</td>\n",
       "      <td>['halo', 'telinga', 'berdenging', 'tinitus', '...</td>\n",
       "      <td>['halo', 'telinga', 'denging', 'tinitus', 'sen...</td>\n",
       "      <td>halo telinga denging tinitus sensasi dengar de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No                                             answer  1-FR  2-GI  3-PI  \\\n",
       "0   1  Halo Rizal,Radang tenggorokan umunya disebabka...     1     0     1   \n",
       "1   2  Halo Hellas,Cacar air merupakan suatu penyakit...     1     0     1   \n",
       "2   3  Halo Rory.......Terimakasih atas pertanyaan An...     1     0     1   \n",
       "3   4  Alo AfriYani, Terimakasih atas pertanyaannya. ...     1     0     1   \n",
       "4   5  Halo,Telinga berdenging atau  tinitus  merupak...     1     0     1   \n",
       "\n",
       "   4-DM  5-EDTRB  6-RE                                         Text_Clean  \\\n",
       "0     1        1     0  halo rizal radang tenggorokan umunya disebabka...   \n",
       "1     1        1     0  halo hellas cacar air merupakan suatu penyakit...   \n",
       "2     1        1     0  halo rory terimakasih atas pertanyaan anda per...   \n",
       "3     1        1     0  alo afriyani terimakasih atas pertanyaannya ku...   \n",
       "4     1        1     0  halo telinga berdenging atau tinitus merupakan...   \n",
       "\n",
       "                                       filtered_text  \\\n",
       "0  halo rizal radang tenggorokan umunya disebabka...   \n",
       "1  halo hellas cacar air penyakit disebabkan viru...   \n",
       "2  halo rory terimakasih ketahui gangguan kulit s...   \n",
       "3  alo afriyani terimakasih pertanyaannya kuku ja...   \n",
       "4  halo telinga berdenging tinitus sensasi penden...   \n",
       "\n",
       "                                               token  \\\n",
       "0  ['halo', 'rizal', 'radang', 'tenggorokan', 'um...   \n",
       "1  ['halo', 'hellas', 'cacar', 'air', 'penyakit',...   \n",
       "2  ['halo', 'rory', 'terimakasih', 'ketahui', 'ga...   \n",
       "3  ['alo', 'afriyani', 'terimakasih', 'pertanyaan...   \n",
       "4  ['halo', 'telinga', 'berdenging', 'tinitus', '...   \n",
       "\n",
       "                                      tokens_stemmed  \\\n",
       "0  ['halo', 'rizal', 'radang', 'tenggorok', 'umu'...   \n",
       "1  ['halo', 'hellas', 'cacar', 'air', 'sakit', 's...   \n",
       "2  ['halo', 'rory', 'terimakasih', 'tahu', 'gangg...   \n",
       "3  ['alo', 'afriyani', 'terimakasih', 'tanya', 'k...   \n",
       "4  ['halo', 'telinga', 'denging', 'tinitus', 'sen...   \n",
       "\n",
       "                                        Process_Data  \n",
       "0  halo rizal radang tenggorok umu sebab infeksi ...  \n",
       "1  halo hellas cacar air sakit sebab virus varise...  \n",
       "2  halo rory terimakasih tahu ganggu kulit rangka...  \n",
       "3  alo afriyani terimakasih tanya kuku jari kaki ...  \n",
       "4  halo telinga denging tinitus sensasi dengar de...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/kaggle/input/doctors-answer-dataset/Indo-Online Health Consultation-Medical Interview-Clean.csv', encoding='latin-1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c2a0223",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:32:00.358375Z",
     "iopub.status.busy": "2025-01-08T08:32:00.358162Z",
     "iopub.status.idle": "2025-01-08T08:32:00.368120Z",
     "shell.execute_reply": "2025-01-08T08:32:00.367363Z"
    },
    "papermill": {
     "duration": 0.023183,
     "end_time": "2025-01-08T08:32:00.369455",
     "exception": false,
     "start_time": "2025-01-08T08:32:00.346272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No</th>\n",
       "      <th>answer</th>\n",
       "      <th>1-FR</th>\n",
       "      <th>2-GI</th>\n",
       "      <th>3-PI</th>\n",
       "      <th>4-DM</th>\n",
       "      <th>5-EDTRB</th>\n",
       "      <th>6-RE</th>\n",
       "      <th>Text_Clean</th>\n",
       "      <th>filtered_text</th>\n",
       "      <th>token</th>\n",
       "      <th>tokens_stemmed</th>\n",
       "      <th>Process_Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Halo Rizal,Radang tenggorokan umunya disebabka...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo rizal radang tenggorokan umunya disebabka...</td>\n",
       "      <td>halo rizal radang tenggorokan umunya disebabka...</td>\n",
       "      <td>['halo', 'rizal', 'radang', 'tenggorokan', 'um...</td>\n",
       "      <td>['halo', 'rizal', 'radang', 'tenggorok', 'umu'...</td>\n",
       "      <td>halo rizal radang tenggorok umu sebab infeksi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Halo Hellas,Cacar air merupakan suatu penyakit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo hellas cacar air merupakan suatu penyakit...</td>\n",
       "      <td>halo hellas cacar air penyakit disebabkan viru...</td>\n",
       "      <td>['halo', 'hellas', 'cacar', 'air', 'penyakit',...</td>\n",
       "      <td>['halo', 'hellas', 'cacar', 'air', 'sakit', 's...</td>\n",
       "      <td>halo hellas cacar air sakit sebab virus varise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Halo Rory.......Terimakasih atas pertanyaan An...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo rory terimakasih atas pertanyaan anda per...</td>\n",
       "      <td>halo rory terimakasih ketahui gangguan kulit s...</td>\n",
       "      <td>['halo', 'rory', 'terimakasih', 'ketahui', 'ga...</td>\n",
       "      <td>['halo', 'rory', 'terimakasih', 'tahu', 'gangg...</td>\n",
       "      <td>halo rory terimakasih tahu ganggu kulit rangka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Alo AfriYani, Terimakasih atas pertanyaannya. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>alo afriyani terimakasih atas pertanyaannya ku...</td>\n",
       "      <td>alo afriyani terimakasih pertanyaannya kuku ja...</td>\n",
       "      <td>['alo', 'afriyani', 'terimakasih', 'pertanyaan...</td>\n",
       "      <td>['alo', 'afriyani', 'terimakasih', 'tanya', 'k...</td>\n",
       "      <td>alo afriyani terimakasih tanya kuku jari kaki ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Halo,Telinga berdenging atau  tinitus  merupak...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>halo telinga berdenging atau tinitus merupakan...</td>\n",
       "      <td>halo telinga berdenging tinitus sensasi penden...</td>\n",
       "      <td>['halo', 'telinga', 'berdenging', 'tinitus', '...</td>\n",
       "      <td>['halo', 'telinga', 'denging', 'tinitus', 'sen...</td>\n",
       "      <td>halo telinga denging tinitus sensasi dengar de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   No                                             answer  1-FR  2-GI  3-PI  \\\n",
       "0   1  Halo Rizal,Radang tenggorokan umunya disebabka...     1     0     1   \n",
       "1   2  Halo Hellas,Cacar air merupakan suatu penyakit...     1     0     1   \n",
       "2   3  Halo Rory.......Terimakasih atas pertanyaan An...     1     0     1   \n",
       "3   4  Alo AfriYani, Terimakasih atas pertanyaannya. ...     1     0     1   \n",
       "4   5  Halo,Telinga berdenging atau  tinitus  merupak...     1     0     1   \n",
       "\n",
       "   4-DM  5-EDTRB  6-RE                                         Text_Clean  \\\n",
       "0     1        1     0  halo rizal radang tenggorokan umunya disebabka...   \n",
       "1     1        1     0  halo hellas cacar air merupakan suatu penyakit...   \n",
       "2     1        1     0  halo rory terimakasih atas pertanyaan anda per...   \n",
       "3     1        1     0  alo afriyani terimakasih atas pertanyaannya ku...   \n",
       "4     1        1     0  halo telinga berdenging atau tinitus merupakan...   \n",
       "\n",
       "                                       filtered_text  \\\n",
       "0  halo rizal radang tenggorokan umunya disebabka...   \n",
       "1  halo hellas cacar air penyakit disebabkan viru...   \n",
       "2  halo rory terimakasih ketahui gangguan kulit s...   \n",
       "3  alo afriyani terimakasih pertanyaannya kuku ja...   \n",
       "4  halo telinga berdenging tinitus sensasi penden...   \n",
       "\n",
       "                                               token  \\\n",
       "0  ['halo', 'rizal', 'radang', 'tenggorokan', 'um...   \n",
       "1  ['halo', 'hellas', 'cacar', 'air', 'penyakit',...   \n",
       "2  ['halo', 'rory', 'terimakasih', 'ketahui', 'ga...   \n",
       "3  ['alo', 'afriyani', 'terimakasih', 'pertanyaan...   \n",
       "4  ['halo', 'telinga', 'berdenging', 'tinitus', '...   \n",
       "\n",
       "                                      tokens_stemmed  \\\n",
       "0  ['halo', 'rizal', 'radang', 'tenggorok', 'umu'...   \n",
       "1  ['halo', 'hellas', 'cacar', 'air', 'sakit', 's...   \n",
       "2  ['halo', 'rory', 'terimakasih', 'tahu', 'gangg...   \n",
       "3  ['alo', 'afriyani', 'terimakasih', 'tanya', 'k...   \n",
       "4  ['halo', 'telinga', 'denging', 'tinitus', 'sen...   \n",
       "\n",
       "                                        Process_Data  \n",
       "0  halo rizal radang tenggorok umu sebab infeksi ...  \n",
       "1  halo hellas cacar air sakit sebab virus varise...  \n",
       "2  halo rory terimakasih tahu ganggu kulit rangka...  \n",
       "3  alo afriyani terimakasih tanya kuku jari kaki ...  \n",
       "4  halo telinga denging tinitus sensasi dengar de...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1029ec05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:32:00.393388Z",
     "iopub.status.busy": "2025-01-08T08:32:00.393191Z",
     "iopub.status.idle": "2025-01-08T08:32:00.409477Z",
     "shell.execute_reply": "2025-01-08T08:32:00.408642Z"
    },
    "papermill": {
     "duration": 0.029776,
     "end_time": "2025-01-08T08:32:00.410860",
     "exception": false,
     "start_time": "2025-01-08T08:32:00.381084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,) (400, 6)\n",
      "(100,) (100, 6)\n"
     ]
    }
   ],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "train_labels = train_data.columns[2:8]\n",
    "val_labels = val_data.columns[2:8]\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['Text_Clean'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['Text_Clean'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f66fbfb",
   "metadata": {
    "papermill": {
     "duration": 0.011459,
     "end_time": "2025-01-08T08:32:00.434839",
     "exception": false,
     "start_time": "2025-01-08T08:32:00.423380",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BUILD DATASET & DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9660230a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:32:00.459024Z",
     "iopub.status.busy": "2025-01-08T08:32:00.458752Z",
     "iopub.status.idle": "2025-01-08T08:32:09.653693Z",
     "shell.execute_reply": "2025-01-08T08:32:09.652827Z"
    },
    "papermill": {
     "duration": 9.208687,
     "end_time": "2025-01-08T08:32:09.655228",
     "exception": false,
     "start_time": "2025-01-08T08:32:00.446541",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a9e3ec1e4849dfa8b3f185c37c05a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89a923bb929c47948e233006fe5a8131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "515a37a7b50d444283f9bf7195a4cdf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b584bc31c443a890fcb794bcba53ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Define custom Dataset class\n",
    "class DoctorAnswerDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=256, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        labels = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(labels, dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "# Initialize BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45e768b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:32:09.681186Z",
     "iopub.status.busy": "2025-01-08T08:32:09.680686Z",
     "iopub.status.idle": "2025-01-08T08:32:09.684872Z",
     "shell.execute_reply": "2025-01-08T08:32:09.684285Z"
    },
    "papermill": {
     "duration": 0.018175,
     "end_time": "2025-01-08T08:32:09.686125",
     "exception": false,
     "start_time": "2025-01-08T08:32:09.667950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataloaders(X_train, y_train, X_val, y_val, sequence_length=256, num_workers=4):\n",
    "    train_dataset = DoctorAnswerDataset(X_train, y_train, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = DoctorAnswerDataset(X_val, y_val, tokenizer, max_length=sequence_length)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9817312b",
   "metadata": {
    "papermill": {
     "duration": 0.012079,
     "end_time": "2025-01-08T08:32:09.710446",
     "exception": false,
     "start_time": "2025-01-08T08:32:09.698367",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "566f2e9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:32:09.735619Z",
     "iopub.status.busy": "2025-01-08T08:32:09.735405Z",
     "iopub.status.idle": "2025-01-08T08:32:09.738947Z",
     "shell.execute_reply": "2025-01-08T08:32:09.738336Z"
    },
    "papermill": {
     "duration": 0.017732,
     "end_time": "2025-01-08T08:32:09.740237",
     "exception": false,
     "start_time": "2025-01-08T08:32:09.722505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1cf4715f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:32:09.765457Z",
     "iopub.status.busy": "2025-01-08T08:32:09.765017Z",
     "iopub.status.idle": "2025-01-08T08:32:09.769924Z",
     "shell.execute_reply": "2025-01-08T08:32:09.769344Z"
    },
    "papermill": {
     "duration": 0.018679,
     "end_time": "2025-01-08T08:32:09.771070",
     "exception": false,
     "start_time": "2025-01-08T08:32:09.752391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        target_names=['1-FR', '2-GI', '3-PI', '4-DM', '5-EDTRB', '6-RE'],\n",
    "        zero_division=0\n",
    "    )  \n",
    "\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "165d55b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:32:09.795823Z",
     "iopub.status.busy": "2025-01-08T08:32:09.795621Z",
     "iopub.status.idle": "2025-01-08T08:32:09.806822Z",
     "shell.execute_reply": "2025-01-08T08:32:09.806222Z"
    },
    "papermill": {
     "duration": 0.024998,
     "end_time": "2025-01-08T08:32:09.808061",
     "exception": false,
     "start_time": "2025-01-08T08:32:09.783063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, metrics, trials, seed):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "\n",
    "    accelerator.print(accelerator.distributed_type)\n",
    "\n",
    "    with accelerator.main_process_first():\n",
    "        model = BertForSequenceClassification.from_pretrained(\n",
    "            'indobenchmark/indobert-base-p2',\n",
    "            num_labels=len(train_labels),\n",
    "            problem_type=\"multi_label_classification\"\n",
    "        )\n",
    "\n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Define DataLoaders\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    train_loader, val_loader = get_dataloaders(current_X_train, current_y_train, X_val, y_val)\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Prepare everything with Accelerator\n",
    "    model, optimizer, train_loader, val_loader = accelerator.prepare(\n",
    "        model, optimizer, train_loader, val_loader\n",
    "    )\n",
    "\n",
    "    best_result = None\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key != 'labels'}\n",
    "            labels = batch['labels']\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key != 'labels'}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "        result = compute_metrics(type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}))\n",
    "\n",
    "        if best_result is None or result['f1_micro'] >= best_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'{filename}-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "            best_result = result\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    accelerator.print(f\"Iteration {current_train_size}: Accuracy: {round(best_result['accuracy'], 4)}, F1 Micro: {round(best_result['f1_micro'], 4)}, F1 Macro: {round(best_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(best_result['report'])\n",
    "    accelerator.print(f\"Training completed in {duration} s\")\n",
    "\n",
    "    # Update the shared lists\n",
    "    if accelerator.is_local_main_process:\n",
    "        metrics[0].append(current_train_size)\n",
    "        metrics[1].append(best_result['accuracy'])\n",
    "        metrics[2].append(best_result['f1_micro'])\n",
    "        metrics[3].append(best_result['f1_macro'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b73f2d",
   "metadata": {
    "papermill": {
     "duration": 0.011996,
     "end_time": "2025-01-08T08:32:09.832339",
     "exception": false,
     "start_time": "2025-01-08T08:32:09.820343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PLOT THE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5eec874c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:32:09.857457Z",
     "iopub.status.busy": "2025-01-08T08:32:09.857252Z",
     "iopub.status.idle": "2025-01-08T08:32:09.862144Z",
     "shell.execute_reply": "2025-01-08T08:32:09.861538Z"
    },
    "papermill": {
     "duration": 0.018983,
     "end_time": "2025-01-08T08:32:09.863367",
     "exception": false,
     "start_time": "2025-01-08T08:32:09.844384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71935a1d",
   "metadata": {
    "papermill": {
     "duration": 0.011944,
     "end_time": "2025-01-08T08:32:09.889156",
     "exception": false,
     "start_time": "2025-01-08T08:32:09.877212",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QUERY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91b0f20b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:32:09.914394Z",
     "iopub.status.busy": "2025-01-08T08:32:09.914194Z",
     "iopub.status.idle": "2025-01-08T08:32:09.924255Z",
     "shell.execute_reply": "2025-01-08T08:32:09.923614Z"
    },
    "papermill": {
     "duration": 0.023956,
     "end_time": "2025-01-08T08:32:09.925502",
     "exception": false,
     "start_time": "2025-01-08T08:32:09.901546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def monte_carlo_dropout_sampling(model, X_pool, train_indices, remaining_indices, sampling_dur, new_samples, trials, mc_passes=3, n_samples=min_increment):\n",
    "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "    device = accelerator.device\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    current_train_size = len(train_indices)\n",
    "    dataset = DoctorAnswerDataset(X_pool, np.zeros((len(X_pool), 6)), tokenizer, max_length=sequence_length)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "\n",
    "    confidences = []\n",
    "    for data in dataloader:\n",
    "        # Collect multiple predictions to calculate uncertainty\n",
    "        batch_probs = []\n",
    "        input_ids = data['input_ids'].to(device)\n",
    "        attention_mask = data['attention_mask'].to(device)\n",
    "\n",
    "        for _ in range(mc_passes):\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask).logits\n",
    "            probs = torch.sigmoid(outputs).cpu().numpy()  # Shape: (batch_size, num_classes)\n",
    "            batch_probs.append(probs)\n",
    "\n",
    "        # Stack the probabilities from multiple MC passes\n",
    "        batch_probs = np.stack(batch_probs, axis=0)  # Shape: (mc_passes, batch_size, num_classes)\n",
    "\n",
    "        # Calculate mean probability and uncertainty for each sample in the batch\n",
    "        mean_probs = np.mean(batch_probs, axis=0)  # Shape: (batch_size, num_classes)\n",
    "        uncertainties = np.mean(np.var(batch_probs, axis=0), axis=1)  # Shape: (batch_size,)\n",
    "\n",
    "        # Append the uncertainties to the confidences list\n",
    "        confidences.extend(uncertainties)\n",
    "    \n",
    "    uncertainties = np.array(confidences)\n",
    "    sorted_unc = np.argsort(confidences)\n",
    "    sorted_unc = sorted_unc[::-1]\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "\n",
    "    if accelerator.is_local_main_process:\n",
    "        threshold = np.percentile(confidences, 90)\n",
    "        items_greater_than_average = uncertainties[confidences >= threshold]\n",
    "        num_of_candidates = len(items_greater_than_average)\n",
    "    \n",
    "        # Check nearest checkpoint\n",
    "        nearest_cp = 0\n",
    "        for cp in checkpoints:\n",
    "            if cp > current_train_size:\n",
    "                nearest_cp = cp\n",
    "                break\n",
    "        \n",
    "        if num_of_candidates <= n_samples and n_samples < nearest_cp - current_train_size:\n",
    "            most_uncertain_indices = sorted_unc[:n_samples]\n",
    "        elif num_of_candidates > n_samples and num_of_candidates < nearest_cp - current_train_size:\n",
    "            most_uncertain_indices = sorted_unc[:max(n_samples, min(math.ceil(0.1*len(sorted_unc)), num_of_candidates))]\n",
    "        else:\n",
    "            most_uncertain_indices = sorted_unc[:nearest_cp - current_train_size]\n",
    "    \n",
    "            temp = train_indices.copy()\n",
    "            temp.extend(most_uncertain_indices)\n",
    "            \n",
    "            # Save acquired data up to checkpoint\n",
    "            acquired_data = pd.DataFrame({\n",
    "                'processed_text': [X_train[i] for i in temp],\n",
    "                '1-FR': [y_train[i][0] for i in temp],\n",
    "                '2-GI': [y_train[i][1] for i in temp],\n",
    "                '3-PI': [y_train[i][2] for i in temp],\n",
    "                '4-DM': [y_train[i][3] for i in temp],\n",
    "                '5-EDTRB': [y_train[i][4] for i in temp],\n",
    "                '6-RE': [y_train[i][5] for i in temp],\n",
    "            })\n",
    "    \n",
    "            acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "    \n",
    "        end_time = time.time() \n",
    "        duration = end_time - start_time\n",
    "    \n",
    "        sampling_dur.append(duration)\n",
    "        for i in most_uncertain_indices:\n",
    "            new_samples.append(remaining_indices[i])\n",
    "            \n",
    "        print(\"Nearest checkpoint:\", nearest_cp)\n",
    "        print(\"Threshold:\", threshold)\n",
    "        print(\"Samples above threshold:\", num_of_candidates)\n",
    "        print(\"Acquired samples:\", len(most_uncertain_indices))\n",
    "        print(f\"Sampling duration: {duration} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b420acd3",
   "metadata": {
    "papermill": {
     "duration": 0.013257,
     "end_time": "2025-01-08T08:32:09.950702",
     "exception": false,
     "start_time": "2025-01-08T08:32:09.937445",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2be91bcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:32:09.975742Z",
     "iopub.status.busy": "2025-01-08T08:32:09.975541Z",
     "iopub.status.idle": "2025-01-08T08:32:09.982910Z",
     "shell.execute_reply": "2025-01-08T08:32:09.982310Z"
    },
    "papermill": {
     "duration": 0.021377,
     "end_time": "2025-01-08T08:32:09.984155",
     "exception": false,
     "start_time": "2025-01-08T08:32:09.962778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i):\n",
    "    accuracies = manager.list()\n",
    "    f1_micros = manager.list()\n",
    "    f1_macros = manager.list()\n",
    "    data_used = manager.list()\n",
    "    sampling_dur = manager.list()\n",
    "    new_samples = manager.list()\n",
    "\n",
    "    set_seed(seed)\n",
    "    \n",
    "    print(\"===============================================\")\n",
    "    print(\"TRIAL {}\".format(i+1))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        # Train the model\n",
    "        args = (current_train_size, train_indices, (data_used, accuracies, f1_micros, f1_macros), i, seed)\n",
    "        notebook_launcher(train_model, args, num_processes=2)\n",
    "        \n",
    "        model = BertForSequenceClassification.from_pretrained(f'{filename}-{i + 1}-model')\n",
    "    \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples = manager.list()\n",
    "        sampling_args = (model, [X_train[i] for i in remaining_indices], train_indices, remaining_indices, sampling_dur, new_samples, i)\n",
    "        notebook_launcher(monte_carlo_dropout_sampling, sampling_args, num_processes=2)\n",
    "        new_samples = list(new_samples)\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    args = (current_train_size, train_indices, (data_used, accuracies, f1_micros, f1_macros), i, seed)\n",
    "    notebook_launcher(train_model, args, num_processes=2)\n",
    "    data_used, accuracies, f1_micros, f1_macros, sampling_dur = list(data_used), list(accuracies), list(f1_micros), list(f1_macros), list(sampling_dur)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    \n",
    "    sampling_dur.insert(0, 0)\n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    results.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f95319f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:32:10.009371Z",
     "iopub.status.busy": "2025-01-08T08:32:10.009162Z",
     "iopub.status.idle": "2025-01-08T08:32:10.012163Z",
     "shell.execute_reply": "2025-01-08T08:32:10.011536Z"
    },
    "papermill": {
     "duration": 0.017151,
     "end_time": "2025-01-08T08:32:10.013324",
     "exception": false,
     "start_time": "2025-01-08T08:32:09.996173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [50, 81, 14, 3, 94]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1833ea75",
   "metadata": {
    "papermill": {
     "duration": 0.011897,
     "end_time": "2025-01-08T08:32:10.037355",
     "exception": false,
     "start_time": "2025-01-08T08:32:10.025458",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30a97d0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:32:10.062135Z",
     "iopub.status.busy": "2025-01-08T08:32:10.061904Z",
     "iopub.status.idle": "2025-01-08T08:58:00.200956Z",
     "shell.execute_reply": "2025-01-08T08:58:00.200001Z"
    },
    "papermill": {
     "duration": 1550.153252,
     "end_time": "2025-01-08T08:58:00.202606",
     "exception": false,
     "start_time": "2025-01-08T08:32:10.049354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 1\n",
      "Random seed: 50\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bfec68a75374e39a571d7c3e0380f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7417, Accuracy: 0.8438, F1 Micro: 0.8861, F1 Macro: 0.6509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6068, Accuracy: 0.931, F1 Micro: 0.949, F1 Macro: 0.6633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5321, Accuracy: 0.9609, F1 Micro: 0.9705, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4626, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3907, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3555, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3257, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2884, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2649, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2384, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 25: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 38.515180349349976 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.00039225444779731337\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 38\n",
      "Sampling duration: 8.09130048751831 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7416, Accuracy: 0.8581, F1 Micro: 0.8969, F1 Macro: 0.6564\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6102, Accuracy: 0.9323, F1 Micro: 0.95, F1 Macro: 0.6639\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5466, Accuracy: 0.9635, F1 Micro: 0.9724, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4775, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4127, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3524, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3227, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3023, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2629, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2396, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 63: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 36.777217388153076 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.00034250673488713803\n",
      "Samples above threshold: 34\n",
      "Acquired samples: 34\n",
      "Sampling duration: 7.780582666397095 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6781, Accuracy: 0.9401, F1 Micro: 0.9555, F1 Macro: 0.6663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.506, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3861, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.325, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2704, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2377, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2189, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2092, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1946, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.169, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 97: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 42.79695534706116 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.00013335750263649971\n",
      "Samples above threshold: 31\n",
      "Acquired samples: 31\n",
      "Sampling duration: 7.679036855697632 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6765, Accuracy: 0.9453, F1 Micro: 0.9591, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5043, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3871, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.33, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2697, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2525, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2174, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.193, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1765, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1673, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 128: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 43.46444344520569 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.0001231747926794924\n",
      "Samples above threshold: 28\n",
      "Acquired samples: 28\n",
      "Sampling duration: 7.2867865562438965 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6284, Accuracy: 0.9635, F1 Micro: 0.9724, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4234, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3125, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2488, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1962, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1951, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1797, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1612, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1663, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1612, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 156: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 48.07077217102051 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 9.721035967231729e-05\n",
      "Samples above threshold: 25\n",
      "Acquired samples: 25\n",
      "Sampling duration: 7.518159866333008 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6257, Accuracy: 0.9609, F1 Micro: 0.9705, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4113, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3104, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2526, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2052, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1805, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1896, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1826, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1896, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1611, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 181: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 49.76110339164734 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.000119726883713156\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 22\n",
      "Sampling duration: 6.8335511684417725 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5936, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3649, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2647, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2183, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1744, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1831, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1805, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1809, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1617, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1444, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 203: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 53.89859056472778 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 8.315639133797959e-05\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 20\n",
      "Sampling duration: 6.078280925750732 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5987, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3723, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2532, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2218, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2164, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1929, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1665, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1744, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1645, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1658, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 223: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 54.79411315917969 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 8.711778646102175e-05\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 18\n",
      "Sampling duration: 5.494700908660889 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6004, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3696, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2775, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2419, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1998, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1922, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1903, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1689, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1835, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1486, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 241: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 54.323490381240845 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 8.954831864684821e-05\n",
      "Samples above threshold: 16\n",
      "Acquired samples: 9\n",
      "Sampling duration: 5.077103853225708 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5898, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3585, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.26, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.207, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1975, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1826, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1774, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1535, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1757, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1771, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 250: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 53.99740171432495 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 0.00010242359130643308\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 15\n",
      "Sampling duration: 4.740220785140991 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.56, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3204, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2417, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2042, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1842, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1684, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1704, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1601, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1576, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1617, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 265: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 60.09946250915527 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 9.791730990400539e-05\n",
      "Samples above threshold: 14\n",
      "Acquired samples: 14\n",
      "Sampling duration: 5.251616477966309 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5637, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.321, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2386, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2019, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1887, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1734, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1887, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1531, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1594, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1673, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 279: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.124263525009155 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 9.870032226899639e-05\n",
      "Samples above threshold: 13\n",
      "Acquired samples: 13\n",
      "Sampling duration: 4.526759386062622 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5581, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3303, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2452, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2017, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1823, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1938, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1787, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.157, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1639, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1493, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 292: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.58435535430908 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 8.399741491302847e-05\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 8\n",
      "Sampling duration: 4.2909979820251465 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5524, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3132, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2237, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2112, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1962, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1679, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1599, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1609, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.177, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1663, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 300: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 58.627583742141724 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 8.99808743270114e-05\n",
      "Samples above threshold: 10\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.080949068069458 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5643, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3229, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2193, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1945, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1982, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1827, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1571, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1873, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1637, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1636, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 310: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.75384068489075 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 7.829999740351924e-05\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.718391180038452 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5683, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3204, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2463, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1901, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1839, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1949, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1756, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1764, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.177, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1636, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 320: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 58.88886046409607 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 9.201678331010047e-05\n",
      "Samples above threshold: 8\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.5736491680145264 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5316, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2879, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2251, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1911, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1729, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1637, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1514, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1582, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1789, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1612, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 330: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 62.81089401245117 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 8.205330013879574e-05\n",
      "Samples above threshold: 7\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.804420232772827 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5288, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2958, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2183, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1944, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1875, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1703, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1714, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1632, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1573, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.161, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 340: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.078460693359375 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 9.97017719782889e-05\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.536851406097412 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5272, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2979, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2106, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1926, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1817, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1681, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1825, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1633, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.168, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1441, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 350: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 62.853718757629395 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 8.759024931350724e-05\n",
      "Samples above threshold: 5\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.3556578159332275 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.529, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2893, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2216, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2016, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1701, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1754, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1724, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1659, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1631, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1612, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 360: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.69207954406738 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 7.664157601539048e-05\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.9882817268371582 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5356, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2868, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2162, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1963, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.173, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1677, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1587, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1564, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1739, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1661, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 370: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 64.56904816627502 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.0001089814104489051\n",
      "Samples above threshold: 3\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.8161835670471191 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5326, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2904, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2216, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1979, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.172, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.165, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1578, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1427, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1461, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1576, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 380: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.7330961227417 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 6.0561627833521925e-05\n",
      "Samples above threshold: 2\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.4749515056610107 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.506, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2643, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2102, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1764, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1799, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1616, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1564, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1492, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1566, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1515, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 390: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 68.12385773658752 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.0001421587337972596\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.300567388534546 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4994, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2507, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.207, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1918, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.188, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1576, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1538, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.139, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1558, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1451, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 400: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 68.10059070587158 s\n",
      "Total sampling time: 106.3 seconds\n",
      "Total runtime: 1549.3214702606201 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACCoAAAHqCAYAAADInz0eAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACJdUlEQVR4nOz9fZjVZbk3/r9nBmYGRdBEhgdRkDSfQVEJLc07lNTb1LuUdrghKkscEmXvFErBbMvULglTErVNkmFSPuUdhts9lmWiJGg7b0U0TNgkoF9zJlEBZ9bvj34uG3mIQVjA8Hodx+c4XNc6r+tzXsM8nE3nXJ+yQqFQCAAAAAAAAABACZRv6wQAAAAAAAAAgJ2HRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJaNRAQAAAAAAAAAoGY0KAAAAAAAAAEDJaFQAAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAYLv2mc98Jr17997WaQAAAABbiEYFgM30ve99L2VlZRk4cOC2TgUAAN6Tm2++OWVlZeu9xo0bV4z7z//8z3zuc5/LoYcemoqKilY3D7y95uc///n1vv/Vr361GPPyyy+/ly0BALATUc8C7HjabesEAHZUM2fOTO/evTNv3rw899xzef/737+tUwIAgPfkyiuvTJ8+fVqMHXroocX/vvXWWzNr1qwceeSR6dGjx2bdo7q6OnfccUe+973vpbKyssV7P/7xj1NdXZ0333yzxfhNN92U5ubmzbofAAA7j+21ngVgXU5UANgMzz//fB5++OFMnjw5e+21V2bOnLmtU1qvVatWbesUAADYgZxyyik599xzW1z9+/cvvj9p0qQ0Njbmt7/9bfr167dZ9/jYxz6WxsbG/OIXv2gx/vDDD+f555/Paaedts6c9u3bp6qqarPu9/eam5v90hgAoA3bXuvZrc3vgYEdkUYFgM0wc+bM7LHHHjnttNPyyU9+cr2NCq+++mouvvji9O7dO1VVVdl7770zfPjwFkd+vfnmm7niiitywAEHpLq6Ot27d8//+T//J3/84x+TJL/61a9SVlaWX/3qVy3W/tOf/pSysrLcfPPNxbHPfOYz6dixY/74xz/m1FNPzW677ZZhw4YlSX7zm9/k7LPPzj777JOqqqr06tUrF198cd5444118l64cGHOOeec7LXXXunQoUM+8IEP5Ktf/WqS5Je//GXKyspy1113rTPv1ltvTVlZWebOndvqjycAADuGHj16pH379u9pjZ49e+b444/Prbfe2mJ85syZOeyww1r8xdvbPvOZz6xzLG9zc3OuueaaHHbYYamurs5ee+2Vj33sY3nssceKMWVlZRk9enRmzpyZQw45JFVVVZkzZ06S5PHHH88pp5ySTp06pWPHjvnoRz+aRx555D3tDQCA7du2qme31O9nk+SKK65IWVlZnnrqqXz605/OHnvskQ996ENJkrfeeitf//rX07dv31RVVaV37975yle+ktWrV7+nPQNsDR79ALAZZs6cmf/zf/5PKisr80//9E+5/vrr87vf/S5HH310kuS1117Lhz/84Tz99NP57Gc/myOPPDIvv/xy7rnnnvzP//xPunTpkqampvzv//2/U19fn0996lMZM2ZM/vrXv+b+++/Pk08+mb59+7Y6r7feeitDhgzJhz70oXz729/OLrvskiT56U9/mtdffz2jRo3KnnvumXnz5uXaa6/N//zP/+SnP/1pcf5///d/58Mf/nDat2+fL3zhC+ndu3f++Mc/5v/+3/+bq666Kh/5yEfSq1evzJw5M2edddY6H5O+fftm0KBB7+EjCwDAttTQ0LDOs3S7dOmyxe/z6U9/OmPGjMlrr72Wjh075q233spPf/rTjB07dpNPPPjc5z6Xm2++Oaeccko+//nP56233spvfvObPPLIIznqqKOKcQ888EB+8pOfZPTo0enSpUt69+6d//f//l8+/OEPp1OnTrnkkkvSvn373HDDDfnIRz6SBx98MAMHDtziewYAYOvbXuvZLfX72b939tlnZ//998+kSZNSKBSSJJ///OczY8aMfPKTn8y//Mu/5NFHH01dXV2efvrp9f7xGcC2pFEBoJXmz5+fhQsX5tprr02SfOhDH8ree++dmTNnFhsVvvWtb+XJJ5/MnXfe2eL/0L/sssuKReMPf/jD1NfXZ/Lkybn44ouLMePGjSvGtNbq1atz9tlnp66ursX4N7/5zXTo0KH4+gtf+ELe//735ytf+UqWLFmSffbZJ0nypS99KYVCIQsWLCiOJck3vvGNJH/7i7Rzzz03kydPTkNDQzp37pwkeemll/Kf//mfLTp7AQDY8QwePHidsc2tTTfmk5/8ZEaPHp2777475557bv7zP/8zL7/8cv7pn/4pP/jBD/7h/F/+8pe5+eabc+GFF+aaa64pjv/Lv/zLOvk+88wz+cMf/pCDDz64OHbWWWdl7dq1eeihh7LffvslSYYPH54PfOADueSSS/Lggw9uoZ0CAFBK22s9u6V+P/v3+vXr1+JUh9///veZMWNGPv/5z+emm25KklxwwQXp2rVrvv3tb+eXv/xlTjzxxC32MQB4rzz6AaCVZs6cmZqammJRV1ZWlqFDh+a2225LU1NTkuSOO+5Iv3791jl14O34t2O6dOmSL33pSxuM2RyjRo1aZ+zvi+BVq1bl5ZdfzrHHHptCoZDHH388yd+aDX7961/ns5/9bIsi+N35DB8+PKtXr87tt99eHJs1a1beeuutnHvuuZudNwAA297UqVNz//33t7i2hj322CMf+9jH8uMf/zjJ3x4jduyxx2bffffdpPl33HFHysrKMnHixHXee3ctfcIJJ7RoUmhqasp//ud/5swzzyw2KSRJ9+7d8+lPfzoPPfRQGhsbN2dbAABsY9trPbslfz/7tvPPP7/F63vvvTdJMnbs2Bbj//Iv/5IkmT17dmu2CLDVOVEBoBWamppy22235cQTT8zzzz9fHB84cGCuvvrq1NfX5+STT84f//jHfOITn9joWn/84x/zgQ98IO3abblvxe3atcvee++9zviSJUsyYcKE3HPPPfnLX/7S4r2GhoYkyeLFi5Nkvc9Q+3sHHnhgjj766MycOTOf+9znkvyteeODH/xg3v/+92+JbQAAsI0cc8wxLR6bsDV9+tOfzj//8z9nyZIlufvuu/Pv//7vmzz3j3/8Y3r06JH3ve99/zC2T58+LV6/9NJLef311/OBD3xgndiDDjoozc3NWbp0aQ455JBNzgcAgO3D9lrPbsnfz77t3XXuCy+8kPLy8nV+R9utW7fsvvvueeGFFzZpXYBS0agA0AoPPPBAXnzxxdx222257bbb1nl/5syZOfnkk7fY/TZ0ssLbJze8W1VVVcrLy9eJPemkk/LKK6/k0ksvzYEHHphdd901y5Yty2c+85k0Nze3Oq/hw4dnzJgx+Z//+Z+sXr06jzzySK677rpWrwMAwM7r4x//eKqqqjJixIisXr0655xzzla5z9//9RoAAGwpm1rPbo3fzyYbrnPfy2m9AKWkUQGgFWbOnJmuXbtm6tSp67x355135q677sq0adPSt2/fPPnkkxtdq2/fvnn00Uezdu3atG/ffr0xe+yxR5Lk1VdfbTHemu7XP/zhD1m0aFFmzJiR4cOHF8fffezZ28fe/qO8k+RTn/pUxo4dmx//+Md544030r59+wwdOnSTcwIAgA4dOuTMM8/Mj370o5xyyinp0qXLJs/t27dv7rvvvrzyyiubdKrC39trr72yyy675JlnnlnnvYULF6a8vDy9evVq1ZoAAOx8NrWe3Rq/n12ffffdN83NzXn22Wdz0EEHFcdXrFiRV199dZMfswZQKuX/OASAJHnjjTdy55135n//7/+dT37yk+tco0ePzl//+tfcc889+cQnPpHf//73ueuuu9ZZp1AoJEk+8YlP5OWXX17vSQRvx+y7776pqKjIr3/96xbvf+9739vkvCsqKlqs+fZ/X3PNNS3i9tprrxx//PGZPn16lixZst583talS5eccsop+dGPfpSZM2fmYx/7WKt+sQwAAEnyr//6r5k4cWIuv/zyVs37xCc+kUKhkK997WvrvPfu2vXdKioqcvLJJ+dnP/tZ/vSnPxXHV6xYkVtvvTUf+tCH0qlTp1blAwDAzmlT6tmt8fvZ9Tn11FOTJFOmTGkxPnny5CTJaaed9g/XACglJyoAbKJ77rknf/3rX/Pxj398ve9/8IMfzF577ZWZM2fm1ltvze23356zzz47n/3sZzNgwIC88sorueeeezJt2rT069cvw4cPzw9/+MOMHTs28+bNy4c//OGsWrUq//Vf/5ULLrggZ5xxRjp37pyzzz471157bcrKytK3b9/8/Oc/z8qVKzc57wMPPDB9+/bNv/7rv2bZsmXp1KlT7rjjjnWehZYk3/3ud/OhD30oRx55ZL7whS+kT58++dOf/pTZs2fniSeeaBE7fPjwfPKTn0ySfP3rX9/0DyQAADus//7v/84999yTJHnuuefS0NCQf/u3f0uS9OvXL6effnqr1uvXr1/69evX6jxOPPHE/PM//3O++93v5tlnn83HPvaxNDc35ze/+U1OPPHEjB49eqPz/+3f/i33339/PvShD+WCCy5Iu3btcsMNN2T16tUbfbYwAAA7tm1Rz26t38+uL5cRI0bkxhtvzKuvvpoTTjgh8+bNy4wZM3LmmWfmxBNPbNXeALY2jQoAm2jmzJmprq7OSSedtN73y8vLc9ppp2XmzJlZvXp1fvOb32TixIm56667MmPGjHTt2jUf/ehHs/feeyf5Wyftvffem6uuuiq33npr7rjjjuy555750Ic+lMMOO6y47rXXXpu1a9dm2rRpqaqqyjnnnJNvfetbOfTQQzcp7/bt2+f//t//mwsvvDB1dXWprq7OWWedldGjR69TRPfr1y+PPPJILr/88lx//fV58803s++++673+Wqnn3569thjjzQ3N2+weQMAgLZlwYIF6/y12NuvR4wY0epf7L4XP/jBD3L44YfnP/7jP/LlL385nTt3zlFHHZVjjz32H8495JBD8pvf/Cbjx49PXV1dmpubM3DgwPzoRz/KwIEDS5A9AADbwraoZ7fW72fX5/vf/37222+/3HzzzbnrrrvSrVu3jB8/PhMnTtzi+wJ4r8oKm3JeDAC8y1tvvZUePXrk9NNPz3/8x39s63QAAAAAAADYQZRv6wQA2DHdfffdeemllzJ8+PBtnQoAAAAAAAA7ECcqANAqjz76aP77v/87X//619OlS5csWLBgW6cEAAAAAADADsSJCgC0yvXXX59Ro0ala9eu+eEPf7it0wEAAAAAAGAH40QFAAAAAAAAAKBknKgAAAAAAAAAAJSMRgUAAAAAAAAAoGTabesEtpTm5ub8+c9/zm677ZaysrJtnQ4AAFtRoVDIX//61/To0SPl5W2v91ZtCwCw81DbAgDQVrSmtm0zjQp//vOf06tXr22dBgAAJbR06dLsvffe2zqNLU5tCwCw81HbAgDQVmxKbdtmGhV22223JH/bdKdOnbZxNgAAbE2NjY3p1atXsQZsa9S2AAA7D7UtAABtRWtq2zbTqPD2sWGdOnVS8AIA7CTa6tGxalsAgJ2P2hYAgLZiU2rbtvfQMwAAAAAAAABgu6VRAQAAAAAAAAAoGY0KAAAAAAAAAEDJaFQAAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAAAAAAKBkNCoAAAAAAAAAACWjUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAAAAAAAAQMloVAAAAAAAAAAASkajAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAHZav/71r3P66aenR48eKSsry9133/0P5/zqV7/KkUcemaqqqrz//e/PzTff3OL9urq6HH300dltt93StWvXnHnmmXnmmWe2zgYAAAAAAHZAGhUAANhprVq1Kv369cvUqVM3Kf7555/PaaedlhNPPDFPPPFELrroonz+85/PfffdV4x58MEHU1tbm0ceeST3339/1q5dm5NPPjmrVq3aWtsAAAAAANihtNvWCQAAwLZyyimn5JRTTtnk+GnTpqVPnz65+uqrkyQHHXRQHnrooXznO9/JkCFDkiRz5sxpMefmm29O165dM3/+/Bx//PFbLnkAAAAAgB2UExUAAGATzZ07N4MHD24xNmTIkMydO3eDcxoaGpIk73vf+zYYs3r16jQ2Nra4AAAAAADaKo0KAACwiZYvX56ampoWYzU1NWlsbMwbb7yxTnxzc3MuuuiiHHfccTn00EM3uG5dXV06d+5cvHr16rXFcwcAAAAA2F5oVAAAgK2ktrY2Tz75ZG677baNxo0fPz4NDQ3Fa+nSpSXKEAAAAACg9Npt6wQAAGBH0a1bt6xYsaLF2IoVK9KpU6d06NChxfjo0aPz85//PL/+9a+z9957b3TdqqqqVFVVbfF8AQAAAAC2R05UAACATTRo0KDU19e3GLv//vszaNCg4utCoZDRo0fnrrvuygMPPJA+ffqUOk0AAAAAgO2aRgUAAHZar732Wp544ok88cQTSZLnn38+TzzxRJYsWZLkb49kGD58eDH+/PPPz+LFi3PJJZdk4cKF+d73vpef/OQnufjii4sxtbW1+dGPfpRbb701u+22W5YvX57ly5fnjTfeKOneAAAAAAC2VxoVAADYaT322GM54ogjcsQRRyRJxo4dmyOOOCITJkxIkrz44ovFpoUk6dOnT2bPnp37778//fr1y9VXX53vf//7GTJkSDHm+uuvT0NDQz7ykY+ke/fuxWvWrFml3RwAAAAAwHaq3bZOAAAAtpWPfOQjKRQKG3z/5ptvXu+cxx9/fINzNrYeAAAAAABOVAAAAAAAAAAASkijAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJaNRAQAAAAAAAAAoGY0KAAAAAAAAAEDJaFQAAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAAIA2YOrUqendu3eqq6szcODAzJs3b6Pxr776ampra9O9e/dUVVXlgAMOyL333lt8v6mpKZdffnn69OmTDh06pG/fvvn617+eQqGwtbcCAEAb125bJwAAAAAAwHsza9asjB07NtOmTcvAgQMzZcqUDBkyJM8880y6du26TvyaNWty0kknpWvXrrn99tvTs2fPvPDCC9l9992LMd/85jdz/fXXZ8aMGTnkkEPy2GOPZeTIkencuXMuvPDCEu4OAIC2RqMCAAAAAMAObvLkyTnvvPMycuTIJMm0adMye/bsTJ8+PePGjVsnfvr06XnllVfy8MMPp3379kmS3r17t4h5+OGHc8YZZ+S0004rvv/jH//4H57UAAAA/4hHPwAAAAAA7MDWrFmT+fPnZ/DgwcWx8vLyDB48OHPnzl3vnHvuuSeDBg1KbW1tampqcuihh2bSpElpamoqxhx77LGpr6/PokWLkiS///3v89BDD+WUU07ZYC6rV69OY2NjiwsAAN7NiQoAAAAAADuwl19+OU1NTampqWkxXlNTk4ULF653zuLFi/PAAw9k2LBhuffee/Pcc8/lggsuyNq1azNx4sQkybhx49LY2JgDDzwwFRUVaWpqylVXXZVhw4ZtMJe6urp87Wtf23KbAwCgTXKiAgAAAADATqa5uTldu3bNjTfemAEDBmTo0KH56le/mmnTphVjfvKTn2TmzJm59dZbs2DBgsyYMSPf/va3M2PGjA2uO378+DQ0NBSvpUuXlmI7AADsYJyoAAAAAACwA+vSpUsqKiqyYsWKFuMrVqxIt27d1june/fuad++fSoqKopjBx10UJYvX541a9aksrIyX/7ylzNu3Lh86lOfSpIcdthheeGFF1JXV5cRI0asd92qqqpUVVVtoZ0BANBWOVEBAAAAAGAHVllZmQEDBqS+vr441tzcnPr6+gwaNGi9c4477rg899xzaW5uLo4tWrQo3bt3T2VlZZLk9ddfT3l5y18hV1RUtJgDAACbQ6MCAAAAAMAObuzYsbnpppsyY8aMPP300xk1alRWrVqVkSNHJkmGDx+e8ePHF+NHjRqVV155JWPGjMmiRYsye/bsTJo0KbW1tcWY008/PVdddVVmz56dP/3pT7nrrrsyefLknHXWWSXfHwAAbYtHPwAAAAAA7OCGDh2al156KRMmTMjy5cvTv3//zJkzJzU1NUmSJUuWtDgdoVevXrnvvvty8cUX5/DDD0/Pnj0zZsyYXHrppcWYa6+9NpdffnkuuOCCrFy5Mj169MgXv/jFTJgwoeT7AwCgbSkrFAqFbZ3EltDY2JjOnTunoaEhnTp12tbpAACwFbX12q+t7w8AgHe09dqvre8PAIB3tKb28+gHAAAAAAAAAKBkNCoAAAAAAAAAACWjUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZFrdqPDrX/86p59+enr06JGysrLcfffd/3DOr371qxx55JGpqqrK+9///tx8883rxEydOjW9e/dOdXV1Bg4cmHnz5rU2NQAAAAAAAABgO9fqRoVVq1alX79+mTp16ibFP//88znttNNy4okn5oknnshFF12Uz3/+87nvvvuKMbNmzcrYsWMzceLELFiwIP369cuQIUOycuXK1qYHAAAAAAAAAGzH2rV2wimnnJJTTjllk+OnTZuWPn365Oqrr06SHHTQQXnooYfyne98J0OGDEmSTJ48Oeedd15GjhxZnDN79uxMnz4948aNa22KAAAAAAAAAMB2qtUnKrTW3LlzM3jw4BZjQ4YMydy5c5Mka9asyfz581vElJeXZ/DgwcUYAAAAAAAAAKBtaPWJCq21fPny1NTUtBirqalJY2Nj3njjjfzlL39JU1PTemMWLly4wXVXr16d1atXF183NjZu2cQBAAAAAAAAgC1uq5+osLXU1dWlc+fOxatXr17bOiUAAAAAAAAA4B/Y6o0K3bp1y4oVK1qMrVixIp06dUqHDh3SpUuXVFRUrDemW7duG1x3/PjxaWhoKF5Lly7dKvkDAAAAAAAAAFvOVm9UGDRoUOrr61uM3X///Rk0aFCSpLKyMgMGDGgR09zcnPr6+mLM+lRVVaVTp04tLgAAAAAAAABg+9bqRoXXXnstTzzxRJ544okkyfPPP58nnngiS5YsSfK3kw6GDx9ejD///POzePHiXHLJJVm4cGG+973v5Sc/+UkuvvjiYszYsWNz0003ZcaMGXn66aczatSorFq1KiNHjnyP2wMAAAAAAAAAtiftWjvhsccey4knnlh8PXbs2CTJiBEjcvPNN+fFF18sNi0kSZ8+fTJ79uxcfPHFueaaa7L33nvn+9//foYMGVKMGTp0aF566aVMmDAhy5cvT//+/TNnzpzU1NS8l70BAAAAAAAAANuZskKhUNjWSWwJjY2N6dy5cxoaGjwGAgCgjWvrtV9b3x8AAO9o67VfW98fAADvaE3t1+pHPwAAAAAAAAAAbC6NCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAAAAAAAAQMloVAAAAAAAAAAASkajAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJaNRAQAAAAAAAAAoGY0KAAAAAAAAAEDJaFQAAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAADATuvXv/51Tj/99PTo0SNlZWW5++67/+GcX/3qVznyyCNTVVWV97///bn55pvXiZk6dWp69+6d6urqDBw4MPPmzdvyyQMAAAAA7KA0KgAAsNNatWpV+vXrl6lTp25S/PPPP5/TTjstJ554Yp544olcdNFF+fznP5/77ruvGDNr1qyMHTs2EydOzIIFC9KvX78MGTIkK1eu3FrbAAAAAADYobTb1gkAAMC2csopp+SUU07Z5Php06alT58+ufrqq5MkBx10UB566KF85zvfyZAhQ5IkkydPznnnnZeRI0cW58yePTvTp0/PuHHjtvwmAAAAAAB2ME5UAACATTR37twMHjy4xdiQIUMyd+7cJMmaNWsyf/78FjHl5eUZPHhwMQYAAAAAYGenUQEAADbR8uXLU1NT02KspqYmjY2NeeONN/Lyyy+nqalpvTHLly/f4LqrV69OY2NjiwsAAFpr6tSp6d27d6qrqzNw4MDMmzdvo/Gvvvpqamtr071791RVVeWAAw7IvffeW3y/d+/eKSsrW+eqra3d2lsBAKCN06gAAADbWF1dXTp37ly8evXqta1TAgBgBzNr1qyMHTs2EydOzIIFC9KvX78MGTIkK1euXG/8mjVrctJJJ+VPf/pTbr/99jzzzDO56aab0rNnz2LM7373u7z44ovF6/7770+SnH322SXZEwAAbVe7bZ0AAADsKLp165YVK1a0GFuxYkU6deqUDh06pKKiIhUVFeuN6dat2wbXHT9+fMaOHVt83djYqFkBAIBWmTx5cs4777yMHDkySTJt2rTMnj0706dPz7hx49aJnz59el555ZU8/PDDad++fZK/naDw9/baa68Wr7/xjW+kb9++OeGEE7bOJgAA2Gk4UQEAADbRoEGDUl9f32Ls/vvvz6BBg5IklZWVGTBgQIuY5ubm1NfXF2PWp6qqKp06dWpxAQDAplqzZk3mz5+fwYMHF8fKy8szePDgzJ07d71z7rnnngwaNCi1tbWpqanJoYcemkmTJqWpqWmD9/jRj36Uz372sykrK9sq+wAAYOfhRAUAAHZar732Wp577rni6+effz5PPPFE3ve+92WfffbJ+PHjs2zZsvzwhz9Mkpx//vm57rrrcskll+Szn/1sHnjggfzkJz/J7Nmzi2uMHTs2I0aMyFFHHZVjjjkmU6ZMyapVq4p/2QYAAFvayy+/nKamptTU1LQYr6mpycKFC9c7Z/HixXnggQcybNiw3HvvvXnuuedywQUXZO3atZk4ceI68XfffXdeffXVfOYzn9loLqtXr87q1auLrxsbG1u/IQAA2jyNCgAA7LQee+yxnHjiicXXbz9+YcSIEbn55pvz4osvZsmSJcX3+/Tpk9mzZ+fiiy/ONddck7333jvf//73M2TIkGLM0KFD89JLL2XChAlZvnx5+vfvnzlz5qzzS2MAANiWmpub07Vr19x4442pqKjIgAEDsmzZsnzrW99ab6PCf/zHf+SUU05Jjx49NrpuXV1dvva1r22ttAEAaCM0KgAAsNP6yEc+kkKhsMH3b7755vXOefzxxze67ujRozN69Oj3mh4AAGySLl26pKKiIitWrGgxvmLFinTr1m29c7p375727dunoqKiOHbQQQdl+fLlWbNmTSorK4vjL7zwQv7rv/4rd9555z/MZfz48cUG4ORvJyr06tWrtVsCAKCNK9/WCQAAAAAAsPkqKyszYMCA1NfXF8eam5tTX1+fQYMGrXfOcccdl+eeey7Nzc3FsUWLFqV79+4tmhSS5Ac/+EG6du2a00477R/mUlVVlU6dOrW4AADg3TQqAAAAAADs4MaOHZubbropM2bMyNNPP51Ro0Zl1apVGTlyZJJk+PDhGT9+fDF+1KhReeWVVzJmzJgsWrQos2fPzqRJk1JbW9ti3ebm5vzgBz/IiBEj0q6dA3oBANgyVJYAAAAAADu4oUOH5qWXXsqECROyfPny9O/fP3PmzElNTU2SZMmSJSkvf+fv1nr16pX77rsvF198cQ4//PD07NkzY8aMyaWXXtpi3f/6r//KkiVL8tnPfrak+wEAoG0rK2zsobw7kMbGxnTu3DkNDQ2OEwMAaOPaeu3X1vcHAMA72nrt19b3BwDAO1pT+3n0AwAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJaNRAQAAAAAAAAAoGY0KAAAAAAAAAEDJaFQAAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAAAAAAKBkNCoAAAAAAAAAACWjUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAAAAAAAAQMloVAAAAAAAAAAASkajAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJbNZjQpTp05N7969U11dnYEDB2bevHkbjF27dm2uvPLK9O3bN9XV1enXr1/mzJnTIqapqSmXX355+vTpkw4dOqRv3775+te/nkKhsDnpAQAAAAAAAADbqVY3KsyaNStjx47NxIkTs2DBgvTr1y9DhgzJypUr1xt/2WWX5YYbbsi1116bp556Kueff37OOuusPP7448WYb37zm7n++utz3XXX5emnn843v/nN/Pu//3uuvfbazd8ZAAAAAAAAALDdaXWjwuTJk3Peeedl5MiROfjggzNt2rTssssumT59+nrjb7nllnzlK1/Jqaeemv322y+jRo3KqaeemquvvroY8/DDD+eMM87Iaaedlt69e+eTn/xkTj755I2e1AAAAAAAAAAA7Hha1aiwZs2azJ8/P4MHD35ngfLyDB48OHPnzl3vnNWrV6e6urrFWIcOHfLQQw8VXx977LGpr6/PokWLkiS///3v89BDD+WUU05pTXoAAAAAAAAAwHauXWuCX3755TQ1NaWmpqbFeE1NTRYuXLjeOUOGDMnkyZNz/PHHp2/fvqmvr8+dd96ZpqamYsy4cePS2NiYAw88MBUVFWlqaspVV12VYcOGbTCX1atXZ/Xq1cXXjY2NrdkKAAAAAAAAALANtPrRD611zTXXZP/998+BBx6YysrKjB49OiNHjkx5+Tu3/slPfpKZM2fm1ltvzYIFCzJjxox8+9vfzowZMza4bl1dXTp37ly8evXqtbW3AgAAAAAAAAC8R61qVOjSpUsqKiqyYsWKFuMrVqxIt27d1jtnr732yt13351Vq1blhRdeyMKFC9OxY8fst99+xZgvf/nLGTduXD71qU/lsMMOyz//8z/n4osvTl1d3QZzGT9+fBoaGorX0qVLW7MVAAAAAAAAAGAbaFWjQmVlZQYMGJD6+vriWHNzc+rr6zNo0KCNzq2urk7Pnj3z1ltv5Y477sgZZ5xRfO/1119vccJCklRUVKS5uXmD61VVVaVTp04tLgAAAAAAAABg+9autRPGjh2bESNG5KijjsoxxxyTKVOmZNWqVRk5cmSSZPjw4enZs2fxNIRHH300y5YtS//+/bNs2bJcccUVaW5uziWXXFJc8/TTT89VV12VffbZJ4ccckgef/zxTJ48OZ/97Ge30DYBAAAAAAAAgO1BqxsVhg4dmpdeeikTJkzI8uXL079//8yZMyc1NTVJkiVLlrQ4HeHNN9/MZZddlsWLF6djx4459dRTc8stt2T33Xcvxlx77bW5/PLLc8EFF2TlypXp0aNHvvjFL2bChAnvfYcAAAAAAAAAwHajrFAoFLZ1EltCY2NjOnfunIaGBo+BAABo49p67dfW9wcAwDvaeu3X1vcHAMA7WlP7lW/0XQAAAAAAAACALUijAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAtAFTp05N7969U11dnYEDB2bevHkbjX/11VdTW1ub7t27p6qqKgcccEDuvffeFjHLli3Lueeemz333DMdOnTIYYcdlscee2xrbgMAgJ1Au22dAAAAAAAA782sWbMyduzYTJs2LQMHDsyUKVMyZMiQPPPMM+nates68WvWrMlJJ52Url275vbbb0/Pnj3zwgsvZPfddy/G/OUvf8lxxx2XE088Mb/4xS+y11575dlnn80ee+xRwp0BANAWaVQAAAAAANjBTZ48Oeedd15GjhyZJJk2bVpmz56d6dOnZ9y4cevET58+Pa+88koefvjhtG/fPknSu3fvFjHf/OY306tXr/zgBz8ojvXp02frbQIAgJ2GRz8AAAAAAOzA1qxZk/nz52fw4MHFsfLy8gwePDhz585d75x77rkngwYNSm1tbWpqanLooYdm0qRJaWpqahFz1FFH5eyzz07Xrl1zxBFH5Kabbtrq+wEAoO3TqAAAAAAAsAN7+eWX09TUlJqamhbjNTU1Wb58+XrnLF68OLfffnuamppy77335vLLL8/VV1+df/u3f2sRc/3112f//ffPfffdl1GjRuXCCy/MjBkzNpjL6tWr09jY2OICAIB38+gHAAAAAICdTHNzc7p27Zobb7wxFRUVGTBgQJYtW5ZvfetbmThxYjHmqKOOyqRJk5IkRxxxRJ588slMmzYtI0aMWO+6dXV1+drXvlayfQAAsGNyogIAAAAAwA6sS5cuqaioyIoVK1qMr1ixIt26dVvvnO7du+eAAw5IRUVFceyggw7K8uXLs2bNmmLMwQcf3GLeQQcdlCVLlmwwl/Hjx6ehoaF4LV26dHO3BQBAG6ZRAQAAAABgB1ZZWZkBAwakvr6+ONbc3Jz6+voMGjRovXOOO+64PPfcc2lubi6OLVq0KN27d09lZWUx5plnnmkxb9GiRdl33303mEtVVVU6derU4gIAgHfTqAAAAAAAsIMbO3ZsbrrppsyYMSNPP/10Ro0alVWrVmXkyJFJkuHDh2f8+PHF+FGjRuWVV17JmDFjsmjRosyePTuTJk1KbW1tMebiiy/OI488kkmTJuW5557LrbfemhtvvLFFDAAAbI522zoBAAAAAADem6FDh+all17KhAkTsnz58vTv3z9z5sxJTU1NkmTJkiUpL3/n79Z69eqV++67LxdffHEOP/zw9OzZM2PGjMmll15ajDn66KNz1113Zfz48bnyyivTp0+fTJkyJcOGDSv5/gAAaFvKCoVCYVsnsSU0Njamc+fOaWhocJwYAEAb19Zrv7a+PwAA3tHWa7+2vj8AAN7RmtrPox8AAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAOzUpk6dmt69e6e6ujoDBw7MvHnzNhi7du3aXHnllenbt2+qq6vTr1+/zJkzp0VMU1NTLr/88vTp0ycdOnRI37598/Wvfz2FQmFrbwUAAAAAYIegUQEAgJ3WrFmzMnbs2EycODELFixIv379MmTIkKxcuXK98ZdddlluuOGGXHvttXnqqady/vnn56yzzsrjjz9ejPnmN7+Z66+/Ptddd12efvrpfPOb38y///u/59prry3VtgAAAAAAtmsaFQAA2GlNnjw55513XkaOHJmDDz4406ZNyy677JLp06evN/6WW27JV77ylZx66qnZb7/9MmrUqJx66qm5+uqrizEPP/xwzjjjjJx22mnp3bt3PvnJT+bkk0/e6EkNAAAAAAA7E40KAADslNasWZP58+dn8ODBxbHy8vIMHjw4c+fOXe+c1atXp7q6usVYhw4d8tBDDxVfH3vssamvr8+iRYuSJL///e/z0EMP5ZRTTtlgLqtXr05jY2OLCwAAAACgrWq3rRMAAIBt4eWXX05TU1NqampajNfU1GThwoXrnTNkyJBMnjw5xx9/fPr27Zv6+vrceeedaWpqKsaMGzcujY2NOfDAA1NRUZGmpqZcddVVGTZs2AZzqaury9e+9rUtszEAAAAAgO2cExUAAGATXXPNNdl///1z4IEHprKyMqNHj87IkSNTXv5OWf2Tn/wkM2fOzK233poFCxZkxowZ+fa3v50ZM2ZscN3x48enoaGheC1durQU2wEAAAAA2CacqAAAwE6pS5cuqaioyIoVK1qMr1ixIt26dVvvnL322it333133nzzzfx//9//lx49emTcuHHZb7/9ijFf/vKXM27cuHzqU59Kkhx22GF54YUXUldXlxEjRqx33aqqqlRVVW2hnQEAAAAAbN+cqAAAwE6psrIyAwYMSH19fXGsubk59fX1GTRo0EbnVldXp2fPnnnrrbdyxx135Iwzzii+9/rrr7c4YSFJKioq0tzcvGU3AAAAAACwg3KiAgAAO62xY8dmxIgROeqoo3LMMcdkypQpWbVqVUaOHJkkGT58eHr27Jm6urokyaOPPpply5alf//+WbZsWa644oo0NzfnkksuKa55+umn56qrrso+++yTQw45JI8//ngmT56cz372s9tkjwAAAAAA2xuNCgAA7LSGDh2al156KRMmTMjy5cvTv3//zJkzJzU1NUmSJUuWtDgd4c0338xll12WxYsXp2PHjjn11FNzyy23ZPfddy/GXHvttbn88stzwQUXZOXKlenRo0e++MUvZsKECaXeHgAAAADAdqmsUCgUtnUSW0JjY2M6d+6choaGdOrUaVunAwDAVtTWa7+2vj8AAN7R1mu/tr4/AADe0Zrar3yj7wIAAAAAAAAAbEEaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAAAAAAKBkNCoAAAAAAAAAACWjUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAl025bJ7CjKhSS11/f1lkAAGw/dtklKSvb1lmwWQqFpElxCwBQVKG43VEVCoW8vlZtCwDwtl3a75Ky7bC21aiwmV5/PenYcVtnAQCw/XjttWTXXbd1FmyWpteTnyhuAQCKznktaae43RG9vvb1dKxT2wIAvO218a9l18rtr7b16AcAAAAAAAAAoGScqLCZdtnlb381CADA3+yyy7bOgM1Wscvf/moQAIC/qVDc7qh2ab9LXhuvtgUAeNsu7bfP2lajwmYqK3O0MQAAbURZmaONAQBoE8rKyrbLo40BAGjJox8AAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAAAAAAAAQMloVAAAAAAAAAAASkajAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJaNRAQAAAACgDZg6dWp69+6d6urqDBw4MPPmzdto/Kuvvpra2tp07949VVVVOeCAA3LvvfcW37/iiitSVlbW4jrwwAO39jYAANgJtNvWCQAAAAAA8N7MmjUrY8eOzbRp0zJw4MBMmTIlQ4YMyTPPPJOuXbuuE79mzZqcdNJJ6dq1a26//fb07NkzL7zwQnbfffcWcYccckj+67/+q/i6XTu/UgYA4L1TVQIAAAAA7OAmT56c8847LyNHjkySTJs2LbNnz8706dMzbty4deKnT5+eV155JQ8//HDat2+fJOndu/c6ce3atUu3bt22au4AAOx8NuvRD605Qmzt2rW58sor07dv31RXV6dfv36ZM2fOOnHLli3Lueeemz333DMdOnTIYYcdlscee2xz0gMAAAAA2GmsWbMm8+fPz+DBg4tj5eXlGTx4cObOnbveOffcc08GDRqU2tra1NTU5NBDD82kSZPS1NTUIu7ZZ59Njx49st9++2XYsGFZsmTJRnNZvXp1GhsbW1wAAPBurW5UePsIsYkTJ2bBggXp169fhgwZkpUrV643/rLLLssNN9yQa6+9Nk899VTOP//8nHXWWXn88ceLMX/5y19y3HHHpX379vnFL36Rp556KldffXX22GOPzd8ZAAAAAMBO4OWXX05TU1NqampajNfU1GT58uXrnbN48eLcfvvtaWpqyr333pvLL788V199df7t3/6tGDNw4MDcfPPNmTNnTq6//vo8//zz+fCHP5y//vWvG8ylrq4unTt3Ll69evXaMpsEAKBNKSsUCoXWTBg4cGCOPvroXHfddUmS5ubm9OrVK1/60pfWe4RYjx498tWvfjW1tbXFsU984hPp0KFDfvSjHyVJxo0bl9/+9rf5zW9+s9kbaWxsTOfOndPQ0JBOnTpt9joAAGz/2nrt19b3BwDAO7ZE7ffnP/85PXv2zMMPP5xBgwYVxy+55JI8+OCDefTRR9eZc8ABB+TNN9/M888/n4qKiiR/e3zEt771rbz44ovrvc+rr76afffdN5MnT87nPve59casXr06q1evbrG/Xr16qW0BAHYCraltW3WiwuYcIbZ69epUV1e3GOvQoUMeeuih4ut77rknRx11VM4+++x07do1RxxxRG666abWpAYAAAAAsFPq0qVLKioqsmLFihbjK1asSLdu3dY7p3v37jnggAOKTQpJctBBB2X58uVZs2bNeufsvvvuOeCAA/Lcc89tMJeqqqp06tSpxQUAAO/WqkaFzTlCbMiQIZk8eXKeffbZNDc35/7778+dd97Zoit38eLFuf7667P//vvnvvvuy6hRo3LhhRdmxowZG8zFs84AAAAAAJLKysoMGDAg9fX1xbHm5ubU19e3OGHh7x133HF57rnn0tzcXBxbtGhRunfvnsrKyvXOee211/LHP/4x3bt337IbAABgp9OqRoXNcc0112T//ffPgQcemMrKyowePTojR45Mefk7t25ubs6RRx6ZSZMm5YgjjsgXvvCFnHfeeZk2bdoG1/WsMwAAAACAvxk7dmxuuummzJgxI08//XRGjRqVVatWZeTIkUmS4cOHZ/z48cX4UaNG5ZVXXsmYMWOyaNGizJ49O5MmTWrxCN9//dd/zYMPPpg//elPefjhh3PWWWeloqIi//RP/1Ty/QEA0La0qlFhc44Q22uvvXL33Xdn1apVeeGFF7Jw4cJ07Ngx++23XzGme/fuOfjgg1vMO+igg7JkyZIN5jJ+/Pg0NDQUr6VLl7ZmKwAAAAAAbcbQoUPz7W9/OxMmTEj//v3zxBNPZM6cOcXTcZcsWdLilNtevXrlvvvuy+9+97scfvjhufDCCzNmzJiMGzeuGPM///M/+ad/+qd84AMfyDnnnJM999wzjzzySPbaa6+S7w8AgLalXWuC//4IsTPPPDPJO0eIjR49eqNzq6ur07Nnz6xduzZ33HFHzjnnnOJ7xx13XJ555pkW8YsWLcq+++67wfWqqqpSVVXVmvQBAAAAANqs0aNHb/D3tL/61a/WGRs0aFAeeeSRDa532223banUAACghVY1KiR/O0JsxIgROeqoo3LMMcdkypQp6xwh1rNnz9TV1SVJHn300Sxbtiz9+/fPsmXLcsUVV6S5uTmXXHJJcc2LL744xx57bCZNmpRzzjkn8+bNy4033pgbb7xxC20TAAAAAAAAANgetLpRYejQoXnppZcyYcKELF++PP3791/nCLHy8neeKPHmm2/msssuy+LFi9OxY8eceuqpueWWW7L77rsXY44++ujcddddGT9+fK688sr06dMnU6ZMybBhw977DgEAAAAAAACA7UZZoVAobOsktoTGxsZ07tw5DQ0N6dSp07ZOBwCArait135tfX8AALyjrdd+bX1/AAC8ozW1X/lG3wUAAAAAAAAA2II0KgAAAAAAAAAAJaNRAQAAAAAAAAAoGY0KAAAAAAAAAEDJaFQAAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAAAAAAKBkNCoAAAAAAAAAACWjUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAAAAAAAAQMloVAAAYKc2derU9O7dO9XV1Rk4cGDmzZu3wdi1a9fmyiuvTN++fVNdXZ1+/fplzpw568QtW7Ys5557bvbcc8906NAhhx12WB577LGtuQ0AAAAAgB2GRgUAAHZas2bNytixYzNx4sQsWLAg/fr1y5AhQ7Jy5cr1xl922WW54YYbcu211+app57K+eefn7POOiuPP/54MeYvf/lLjjvuuLRv3z6/+MUv8tRTT+Xqq6/OHnvsUaptAQAAAABs18oKhUJhWyexJTQ2NqZz585paGhIp06dtnU6AABsRVuq9hs4cGCOPvroXHfddUmS5ubm9OrVK1/60pcybty4deJ79OiRr371q6mtrS2OfeITn0iHDh3yox/9KEkybty4/Pa3v81vfvObzc5LbQsAsPNo67VfW98fAADvaE3t50QFAAB2SmvWrMn8+fMzePDg4lh5eXkGDx6cuXPnrnfO6tWrU11d3WKsQ4cOeeihh4qv77nnnhx11FE5++yz07Vr1xxxxBG56aabts4mAAAAAAB2QBoVAADYKb388stpampKTU1Ni/GamposX758vXOGDBmSyZMn59lnn01zc3Puv//+3HnnnXnxxReLMYsXL87111+f/fffP/fdd19GjRqVCy+8MDNmzNhgLqtXr05jY2OLCwAAAACgrdKoAAAAm+iaa67J/vvvnwMPPDCVlZUZPXp0Ro4cmfLyd8rq5ubmHHnkkZk0aVKOOOKIfOELX8h5552XadOmbXDdurq6dO7cuXj16tWrFNsBAAAAANgmNCoAALBT6tKlSyoqKrJixYoW4ytWrEi3bt3WO2evvfbK3XffnVWrVuWFF17IwoUL07Fjx+y3337FmO7du+fggw9uMe+ggw7KkiVLNpjL+PHj09DQULyWLl36HnYGAAAAALB906gAAMBOqbKyMgMGDEh9fX1xrLm5OfX19Rk0aNBG51ZXV6dnz5556623cscdd+SMM84ovnfcccflmWeeaRG/aNGi7Lvvvhtcr6qqKp06dWpxAQAAAAC0Ve22dQIAALCtjB07NiNGjMhRRx2VY445JlOmTMmqVasycuTIJMnw4cPTs2fP1NXVJUkeffTRLFu2LP3798+yZctyxRVXpLm5OZdccklxzYsvvjjHHntsJk2alHPOOSfz5s3LjTfemBtvvHGb7BEAAAAAYHujUQEAgJ3W0KFD89JLL2XChAlZvnx5+vfvnzlz5qSmpiZJsmTJkpSXv3MI2ZtvvpnLLrssixcvTseOHXPqqafmlltuye67716MOfroo3PXXXdl/PjxufLKK9OnT59MmTIlw4YNK/X2AAAAAAC2S2WFQqGwrZPYEhobG9O5c+c0NDQ4KhcAoI1r67VfW98fAADvaOu1X1vfHwAA72hN7Ve+0XcBAAAAAAAAALYgjQoAAAAAAAAAQMloVAAAAAAAAAAASkajAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJaNRAQAAAAAAAAAoGY0KAAAAAAAAAEDJaFQAAAAAAAAAAEpGowIAAAAAQBswderU9O7dO9XV1Rk4cGDmzZu30fhXX301tbW16d69e6qqqnLAAQfk3nvvXW/sN77xjZSVleWiiy7aCpkDALCzabetEwAAAAAA4L2ZNWtWxo4dm2nTpmXgwIGZMmVKhgwZkmeeeSZdu3ZdJ37NmjU56aST0rVr19x+++3p2bNnXnjhhey+++7rxP7ud7/LDTfckMMPP7wEOwEAYGfgRAUAAAAAgB3c5MmTc95552XkyJE5+OCDM23atOyyyy6ZPn36euOnT5+eV155JXfffXeOO+649O7dOyeccEL69evXIu61117LsGHDctNNN2WPPfYoxVYAANgJaFQAAAAAANiBrVmzJvPnz8/gwYOLY+Xl5Rk8eHDmzp273jn33HNPBg0alNra2tTU1OTQQw/NpEmT0tTU1CKutrY2p512Wou1N2b16tVpbGxscQEAwLt59AMAAAAAwA7s5ZdfTlNTU2pqalqM19TUZOHCheuds3jx4jzwwAMZNmxY7r333jz33HO54IILsnbt2kycODFJctttt2XBggX53e9+t8m51NXV5Wtf+9rmbwYAgJ2CExUAAAAAAHYyzc3N6dq1a2688cYMGDAgQ4cOzVe/+tVMmzYtSbJ06dKMGTMmM2fOTHV19SavO378+DQ0NBSvpUuXbq0tAACwA3OiAgAAAADADqxLly6pqKjIihUrWoyvWLEi3bp1W++c7t27p3379qmoqCiOHXTQQVm+fHnxURIrV67MkUceWXy/qakpv/71r3Pddddl9erVLea+raqqKlVVVVtoZwAAtFVOVAAAAAAA2IFVVlZmwIABqa+vL441Nzenvr4+gwYNWu+c4447Ls8991yam5uLY4sWLUr37t1TWVmZj370o/nDH/6QJ554ongdddRRGTZsWJ544on1NikAAMCmcqICAAAAAMAObuzYsRkxYkSOOuqoHHPMMZkyZUpWrVqVkSNHJkmGDx+enj17pq6uLkkyatSoXHfddRkzZky+9KUv5dlnn82kSZNy4YUXJkl22223HHrooS3useuuu2bPPfdcZxwAAFpLowIAAAAAwA5u6NCheemllzJhwoQsX748/fv3z5w5c1JTU5MkWbJkScrL3zlgt1evXrnvvvty8cUX5/DDD0/Pnj0zZsyYXHrppdtqCwAA7ETKCoVCYVsnsSU0Njamc+fOaWhoSKdOnbZ1OgAAbEVtvfZr6/sDAOAdbb32a+v7AwDgHa2p/co3+i4AAAAAAAAAwBakUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAAAAAAAAQMloVAAAAAAAAAAASkajAgAAAAAAAABQMpvVqDB16tT07t071dXVGThwYObNm7fB2LVr1+bKK69M3759U11dnX79+mXOnDkbjP/GN76RsrKyXHTRRZuTGgAAAAAAAACwHWt1o8KsWbMyduzYTJw4MQsWLEi/fv0yZMiQrFy5cr3xl112WW644YZce+21eeqpp3L++efnrLPOyuOPP75O7O9+97vccMMNOfzww1u/EwAAAAAAAABgu9fqRoXJkyfnvPPOy8iRI3PwwQdn2rRp2WWXXTJ9+vT1xt9yyy35yle+klNPPTX77bdfRo0alVNPPTVXX311i7jXXnstw4YNy0033ZQ99thj83YDAAAAAAAAAGzXWtWosGbNmsyfPz+DBw9+Z4Hy8gwePDhz585d75zVq1enurq6xViHDh3y0EMPtRirra3Naaed1mLtjVm9enUaGxtbXAAAAAAAAADA9q1VjQovv/xympqaUlNT02K8pqYmy5cvX++cIUOGZPLkyXn22WfT3Nyc+++/P3feeWdefPHFYsxtt92WBQsWpK6ubpNzqaurS+fOnYtXr169WrMVAAAAAAAAAGAbaPWjH1rrmmuuyf77758DDzwwlZWVGT16dEaOHJny8r/deunSpRkzZkxmzpy5zskLGzN+/Pg0NDQUr6VLl26tLQAAAAAAAAAAW0irGhW6dOmSioqKrFixosX4ihUr0q1bt/XO2WuvvXL33Xdn1apVeeGFF7Jw4cJ07Ngx++23X5Jk/vz5WblyZY488si0a9cu7dq1y4MPPpjvfve7adeuXZqamta7blVVVTp16tTiAgAAAAAAAAC2b61qVKisrMyAAQNSX19fHGtubk59fX0GDRq00bnV1dXp2bNn3nrrrdxxxx0544wzkiQf/ehH84c//CFPPPFE8TrqqKMybNiwPPHEE6moqNiMbQEAAAAAAAAA26N2rZ0wduzYjBgxIkcddVSOOeaYTJkyJatWrcrIkSOTJMOHD0/Pnj1TV1eXJHn00UezbNmy9O/fP8uWLcsVV1yR5ubmXHLJJUmS3XbbLYceemiLe+y6667Zc8891xkHAAAAAAAAAHZsrW5UGDp0aF566aVMmDAhy5cvT//+/TNnzpzU1NQkSZYsWZLy8ncOanjzzTdz2WWXZfHixenYsWNOPfXU3HLLLdl999232CYAAAAAAAAAgB1DWaFQKGzrJLaExsbGdO7cOQ0NDenUqdO2TgcAgK2ordd+bX1/AAC8o63Xfm19fwAAvKM1tV/5Rt8FAAAAAAAAANiCNCoAAAAAAAAAACWjUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAAAAAAAAQMloVAAAAAAAAAAASkajAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJaNRAQCAndrUqVPTu3fvVFdXZ+DAgZk3b94GY9euXZsrr7wyffv2TXV1dfr165c5c+ZsMP4b3/hGysrKctFFF22FzAEAAAAAdkwaFQAA2GnNmjUrY8eOzcSJE7NgwYL069cvQ4YMycqVK9cbf9lll+WGG27Itddem6eeeirnn39+zjrrrDz++OPrxP7ud7/LDTfckMMPP3xrbwMAAAAAYIeiUQEAgJ3W5MmTc95552XkyJE5+OCDM23atOyyyy6ZPn36euNvueWWfOUrX8mpp56a/fbbL6NGjcqpp56aq6++ukXca6+9lmHDhuWmm27KHnvsUYqtAAAAAADsMDQqAACwU1qzZk3mz5+fwYMHF8fKy8szePDgzJ07d71zVq9enerq6hZjHTp0yEMPPdRirLa2NqeddlqLtQEAYGtrzWPNkuTVV19NbW1tunfvnqqqqhxwwAG59957i+9ff/31Ofzww9OpU6d06tQpgwYNyi9+8YutvQ0AAHYC7bZ1AgAAsC28/PLLaWpqSk1NTYvxmpqaLFy4cL1zhgwZksmTJ+f4449P3759U19fnzvvvDNNTU3FmNtuuy0LFizI7373u03OZfXq1Vm9enXxdWNjYyt3AwDAzu7tx5pNmzYtAwcOzJQpUzJkyJA888wz6dq16zrxa9asyUknnZSuXbvm9ttvT8+ePfPCCy9k9913L8bsvffe+cY3vpH9998/hUIhM2bMyBlnnJHHH388hxxySAl3BwBAW+NEBQAA2ETXXHNN9t9//xx44IGprKzM6NGjM3LkyJSX/62sXrp0acaMGZOZM2euc/LCxtTV1aVz587Fq1evXltrCwAAtFGtfazZ9OnT88orr+Tuu+/Occcdl969e+eEE05Iv379ijGnn356Tj311Oy///454IADctVVV6Vjx4555JFHSrUtAADaKI0KAADslLp06ZKKioqsWLGixfiKFSvSrVu39c7Za6+9cvfdd2fVqlV54YUXsnDhwnTs2DH77bdfkmT+/PlZuXJljjzyyLRr1y7t2rXLgw8+mO9+97tp165di5MX/t748ePT0NBQvJYuXbplNwsAQJu2OY81u+eeezJo0KDU1tampqYmhx56aCZNmrTBmrWpqSm33XZbVq1alUGDBm2VfQAAsPPw6AcAAHZKlZWVGTBgQOrr63PmmWcmSZqbm1NfX5/Ro0dvdG51dXV69uyZtWvX5o477sg555yTJPnoRz+aP/zhDy1iR44cmQMPPDCXXnppKioq1rteVVVVqqqq3vumAADYKW3OY80WL16cBx54IMOGDcu9996b5557LhdccEHWrl2biRMnFuP+8Ic/ZNCgQXnzzTfTsWPH3HXXXTn44IM3mIvHmgEAsCk0KgAAsNMaO3ZsRowYkaOOOirHHHNMpkyZklWrVmXkyJFJkuHDh6dnz56pq6tLkjz66KNZtmxZ+vfvn2XLluWKK65Ic3NzLrnkkiTJbrvtlkMPPbTFPXbdddfsueee64wDAMC21NzcnK5du+bGG29MRUVFBgwYkGXLluVb3/pWi0aFD3zgA3niiSfS0NCQ22+/PSNGjMiDDz64wWaFurq6fO1rXyvVNgAA2EFpVAAAYKc1dOjQvPTSS5kwYUKWL1+e/v37Z86cOcW/RFuyZEnKy995Wtqbb76Zyy67LIsXL07Hjh1z6qmn5pZbbsnuu+++jXYAAACb91iz7t27p3379i1O/TrooIOyfPnyrFmzJpWVlUn+dhLZ+9///iTJgAED8rvf/S7XXHNNbrjhhvWuO378+IwdO7b4urGxMb169XpP+wMAoO3RqAAAwE5t9OjRG3zUw69+9asWr0844YQ89dRTrVr/3WsAAMCWtjmPNTvuuONy6623prm5udicu2jRonTv3r3YpLA+zc3NLR7t8G4eawYAwKYo/8chAAAAAABsz8aOHZubbropM2bMyNNPP51Ro0at81iz8ePHF+NHjRqVV155JWPGjMmiRYsye/bsTJo0KbW1tcWY8ePH59e//nX+9Kc/5Q9/+EPGjx+fX/3qVxk2bFjJ9wcAQNviRAUAAAAAgB1cax9r1qtXr9x33325+OKLc/jhh6dnz54ZM2ZMLr300mLMypUrM3z48Lz44ovp3LlzDj/88Nx333056aSTSr4/AADalrJCoVDY1klsCY2NjencuXMaGhrSqVOnbZ0OAABbUVuv/dr6/gAAeEdbr/3a+v4AAHhHa2o/j34AAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAAAAAAKBkNCoAAAAAAAAAACWjUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAAAAAAAAQMloVAAAAAAAAAAASkajAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJaNRAQAAAAAAAAAoGY0KAAAAAAAAAEDJaFQAAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAAAAAAKBkNCoAAAAAAAAAACWjUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKZrMaFaZOnZrevXunuro6AwcOzLx58zYYu3bt2lx55ZXp27dvqqur069fv8yZM6dFTF1dXY4++ujstttu6dq1a84888w888wzm5MaAAAAAAAAALAda3WjwqxZszJ27NhMnDgxCxYsSL9+/TJkyJCsXLlyvfGXXXZZbrjhhlx77bV56qmncv755+ess87K448/Xox58MEHU1tbm0ceeST3339/1q5dm5NPPjmrVq3a/J0BAAAAAAAAANudskKhUGjNhIEDB+boo4/OddddlyRpbm5Or1698qUvfSnjxo1bJ75Hjx756le/mtra2uLYJz7xiXTo0CE/+tGP1nuPl156KV27ds2DDz6Y448/fpPyamxsTOfOndPQ0JBOnTq1ZksAAOxg2nrt19b3BwDAO9p67dfW9wcAwDtaU/u16kSFNWvWZP78+Rk8ePA7C5SXZ/DgwZk7d+5656xevTrV1dUtxjp06JCHHnpog/dpaGhIkrzvfe/bYMzq1avT2NjY4gIAAAAAAAAAtm+talR4+eWX09TUlJqamhbjNTU1Wb58+XrnDBkyJJMnT86zzz6b5ubm3H///bnzzjvz4osvrje+ubk5F110UY477rgceuihG8ylrq4unTt3Ll69evVqzVYAAAAAAAAAgG2gVY0Km+Oaa67J/vvvnwMPPDCVlZUZPXp0Ro4cmfLy9d+6trY2Tz75ZG677baNrjt+/Pg0NDQUr6VLl26N9AEAAAAAAACALahVjQpdunRJRUVFVqxY0WJ8xYoV6dat23rn7LXXXrn77ruzatWqvPDCC1m4cGE6duyY/fbbb53Y0aNH5+c//3l++ctfZu+9995oLlVVVenUqVOLCwAAAAAAAADYvrWqUaGysjIDBgxIfX19cay5uTn19fUZNGjQRudWV1enZ8+eeeutt3LHHXfkjDPOKL5XKBQyevTo3HXXXXnggQfSp0+fVm4DAAAAAAAAANgRtGvthLFjx2bEiBE56qijcswxx2TKlClZtWpVRo4cmSQZPnx4evbsmbq6uiTJo48+mmXLlqV///5ZtmxZrrjiijQ3N+eSSy4prllbW5tbb701P/vZz7Lbbrtl+fLlSZLOnTunQ4cOW2KfAAAAAAAAAMB2oNWNCkOHDs1LL72UCRMmZPny5enfv3/mzJmTmpqaJMmSJUtSXv7OQQ1vvvlmLrvssixevDgdO3bMqaeemltuuSW77757Meb6669PknzkIx9pca8f/OAH+cxnPtP6XQEAAAAAAAAA26WyQqFQ2NZJbAmNjY3p3LlzGhoa0qlTp22dDgAAW1Fbr/3a+v4AAHhHW6/92vr+AAB4R2tqv/KNvgsAAAAAAAAAsAVpVAAAAAAAaAOmTp2a3r17p7q6OgMHDsy8efM2Gv/qq6+mtrY23bt3T1VVVQ444IDce++9xffr6upy9NFHZ7fddkvXrl1z5pln5plnntna2wAAYCegUQEAAAAAYAc3a9asjB07NhMnTsyCBQvSr1+/DBkyJCtXrlxv/Jo1a3LSSSflT3/6U26//fY888wzuemmm9KzZ89izIMPPpja2to88sgjuf/++7N27dqcfPLJWbVqVam2BQBAG9VuWycAAAAAAMB7M3ny5Jx33nkZOXJkkmTatGmZPXt2pk+fnnHjxq0TP3369Lzyyit5+OGH0759+yRJ7969W8TMmTOnxeubb745Xbt2zfz583P88cdvnY0AALBTcKICAAAAAMAObM2aNZk/f34GDx5cHCsvL8/gwYMzd+7c9c655557MmjQoNTW1qampiaHHnpoJk2alKampg3ep6GhIUnyvve9b8tuAACAnY4TFQAAAAAAdmAvv/xympqaUlNT02K8pqYmCxcuXO+cxYsX54EHHsiwYcNy77335rnnnssFF1yQtWvXZuLEievENzc356KLLspxxx2XQw89dIO5rF69OqtXry6+bmxs3MxdAQDQlmlUAAAAAADYyTQ3N6dr16658cYbU1FRkQEDBmTZsmX51re+td5Ghdra2jz55JN56KGHNrpuXV1dvva1r22ttAEAaCM8+gEAAAAAYAfWpUuXVFRUZMWKFS3GV6xYkW7duq13Tvfu3XPAAQekoqKiOHbQQQdl+fLlWbNmTYvY0aNH5+c//3l++ctfZu+9995oLuPHj09DQ0PxWrp06WbuCgCAtkyjAgAAAADADqyysjIDBgxIfX19cay5uTn19fUZNGjQeuccd9xxee6559Lc3FwcW7RoUbp3757KysokSaFQyOjRo3PXXXflgQceSJ8+ff5hLlVVVenUqVOLCwAA3k2jAgAAAADADm7s2LG56aabMmPGjDz99NMZNWpUVq1alZEjRyZJhg8fnvHjxxfjR40alVdeeSVjxozJokWLMnv27EyaNCm1tbXFmNra2vzoRz/Krbfemt122y3Lly/P8uXL88Ybb5R8fwAAtC3ttnUCAAAAAAC8N0OHDs1LL72UCRMmZPny5enfv3/mzJmTmpqaJMmSJUtSXv7O36316tUr9913Xy6++OIcfvjh6dmzZ8aMGZNLL720GHP99dcnST7ykY+0uNcPfvCDfOYzn9nqewIAoO0qKxQKhW2dxJbQ2NiYzp07p6GhwXFiAABtXFuv/dr6/gAAeEdbr/3a+v4AAHhHa2o/j34AAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAAAAAAKBkNCoAAAAAAAAAACWjUQEAAAAAAAAAKJl22zqBLaVQKCRJGhsbt3EmAABsbW/XfG/XgG2N2hYAYOehtgUAoK1oTW3bZhoV/vrXvyZJevXqtY0zAQCgVP7617+mc+fO2zqNLU5tCwCw81HbAgDQVmxKbVtWaCOtus3Nzfnzn/+c3XbbLWVlZSW5Z2NjY3r16pWlS5emU6dOJbnnttLW9rqj72dHy397zXd7ymtb5lLKe2/uvbZ2jltj/e1hzfeSw3vN373de2srFAr561//mh49eqS8vO09zUxtu3W1tb3u6PvZ0fLfXvPdnvJS226dedty/e1hzR211nHvnevem0ttu+VtTz8Xt7a2ttcdfT87Wv7ba77bU15q260zb1uuvz2suaPWOu69c917c7Wmtm0zJyqUl5dn77333ib37tSp0zb/YVkqbW2vO/p+drT8t9d8t6e8tmUupbz35t5ra+e4NdbfHtZ8Lzm81/zd2723prb412ZvU9uWRlvb646+nx0t/+013+0pL7Xt1pm3LdffHtbcUWsd99657r051LZbx/b0c3Fra2t73dH3s6Plv73muz3lpbbdOvO25frbw5o7aq3j3jvXvTfHpta2ba9FFwAAAAAAAADYbmlUAAAAAAAAAABKRqPCe1BVVZWJEyemqqpqW6ey1bW1ve7o+9nR8t9e892e8tqWuZTy3pt7r62d49ZYf3tY873k8F7zd2/3ZsezM/07trW97uj72dHy317z3Z7yUttunXnbcv3tYc0dtdZx753r3mw/dqZ/x7a21x19Pzta/ttrvttTXmrbrTNvW66/Pay5o9Y67r1z3bsUygqFQmFbJwEAAAAAAAAA7BycqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1FhA6644oqUlZW1uA488MCNzvnpT3+aAw88MNXV1TnssMNy7733lijb1vn1r3+d008/PT169EhZWVnuvvvu4ntr167NpZdemsMOOyy77rprevTokeHDh+fPf/7zP1x32bJlOffcc7PnnnumQ4cOOeyww/LYY49txZ38zcb2kyQrVqzIZz7zmfTo0SO77LJLPvaxj+XZZ5/d5PVvu+22lJWV5cwzz9yyif//1dXV5eijj85uu+2Wrl275swzz8wzzzzTIuYjH/nIOp+P559//j9c++mnn87HP/7xdO7cObvuumuOPvroLFmyZLNzvf7663P44YenU6dO6dSpUwYNGpRf/OIXxfdvvPHGfOQjH0mnTp1SVlaWV1999R+uuSn73xK5JcncuXPzv/7X/8quu+6aTp065fjjj88bb7yxVXP7xje+kbKyslx00UXFsTfffDO1tbXZc88907Fjx3ziE5/IihUr/uFarf33XN+931YoFHLKKaes92tmc++9vvstX748//zP/5xu3bpl1113zZFHHplzzjlno99fr7zyynTt2rX4Xo8ePfLb3/52o/kVCoVMmDAhHTt23OjaX/ziF9O3b9906NAhe+21V84444wsXLjwH659wgknbHTd1n6Nru9nTFVVVaZNm7bBj9sdd9zxD7/Pvv1xePtrcJ999il+v9vY3O9+97vp3LlzysvLU1FRkb322mud7/0bmj916tT07t071dXVGThwYObNm5fzzz8/ZWVlmTJlyj+899vzKysrs8cee6Rjx44tPsc2NvenP/1pDjjggFRUVKR9+/apqqrKwQcfXPw49u7de52Pc1lZWWpra1vMbdeuXTp06LDO1+KG5h999NGpqalJu3btsuuuu6a6ujr77LNPLrzwwjQ0NGx07gUXXJAJEyake/fu6dChQz760Y/m+OOPX+drcWP3fnvu0UcfnUGDBq3zPW1j+546dWp69eqVioqKVFZWpkOHDsXPr7c1NTXl8ssvT58+fdKhQ4f07ds3X//613PdddcV/62POeaYfO5znyvmMnjw4E362bq+zxdKQ22rtn2b2vYdalu1rdpWbau2VduqbXdMalu17dvUtu9Q26pt1bZqW7Wt2naHrG0LrNfEiRMLhxxySOHFF18sXi+99NIG43/7298WKioqCv/+7/9eeOqppwqXXXZZoX379oU//OEPJcx609x7772Fr371q4U777yzkKRw1113Fd979dVXC4MHDy7MmjWrsHDhwsLcuXMLxxxzTGHAgAEbXfOVV14p7LvvvoXPfOYzhUcffbSwePHiwn333Vd47rnntvJuNr6f5ubmwgc/+MHChz/84cK8efMKCxcuLHzhC18o7LPPPoXXXnvtH679/PPPF3r27Fn48Ic/XDjjjDO2Sv5Dhgwp/OAHPyg8+eSThSeeeKJw6qmnrpPfCSecUDjvvPNafD42NDRsdN3nnnuu8L73va/w5S9/ubBgwYLCc889V/jZz35WWLFixWbnes899xRmz55dWLRoUeGZZ54pfOUrXym0b9++8OSTTxYKhULhO9/5TqGurq5QV1dXSFL4y1/+skX2vyVye/jhhwudOnUq1NXVFZ588snCwoULC7NmzSq8+eabWy23efPmFXr37l04/PDDC2PGjCmOn3/++YVevXoV6uvrC4899ljhgx/8YOHYY4/d6Fqt/ffc0L3fNnny5MIpp5yyztfM5t57Q/c76aSTCkcffXTh0UcfLfzxj38sfP3rXy8kKfTt23eD31979epVeN/73lf4j//4j8Ktt95a2H333QuVlZUb/bh/4xvfKHTu3LkwdOjQQt++fQsnn3xyoVevXoXnn3++xdo33HBD4cEHHyw8//zzhfnz5xdOP/30Qq9evQpvvfXWRteuqqoq7LPPPoX6+vri2kuXLi3GtPZrdOLEiYU99tijsO+++xbuuOOOwrx58wpXX311oaKiovCzn/1svR+3srKyQvfu3Tf6ffYb3/hGoWPHjoWuXbsW9t9//8J+++1X6NOnT+HPf/7zBr9H33bbbYX27dsXDj744MLVV19dOPvsswsdO3YsHHHEEcXv/Rv6Hj9lypRCZWVlYfr06YX/9//+X+G8884r7LLLLoVDDjmk0KNHj8J3vvOdjf58uO222wqVlZXFf7/DDz+80LFjx8Kjjz5a+NnPflZ45plnNjj37Z+7xxxzTKFXr16Fc889t9CuXbvChAkTih/HlStXtvg3uf/++wtJCtdee22hoqKi8MEPfrDQrVu3wrBhwwrt2rUrHH744S2+Fjc0f9dddy1cc801hY9+9KOFY445prD33nsXfvGLXxT233//wic+8YmNzj3vvPMKnTt3Ltx9992F3//+94VDDjmk0KFDh3W+Fjd277vvvrvwwx/+sNCuXbvCHnvsUZg/f36L72kbmnv55ZcXKisrC4ccckjh0EMPLZxxxhmF3XbbrXDppZcWysvLCwsWLCgUCoXCVVddVdhzzz0LP//5zwvPP/984ac//Wmhurq6UFFRUfy3PvroowtJCjfffHPh97//feHjH/94oU+fPoU33nhjg5/3b/97//3ny+677/6efi6x6dS2attCQW37bmpbta3aVm2rtlXbqm13TGpbtW2hoLZ9N7Wt2lZtq7ZV26ptd8TaVqPCBkycOLHQr1+/TY4/55xzCqeddlqLsYEDBxa++MUvbuHMtqxN+WE3b968QpLCCy+8sMGYSy+9tPChD31oC2fXeu/ezzPPPFNIUix6CoVCoampqbDXXnsVbrrppo2u9dZbbxWOPfbYwve///3CiBEjtlrB+24rV64sJCk8+OCDxbETTjhhvUXLxgwdOrRw7rnnbuHs1rXHHnsUvv/977cY++Uvf7nJBe+7rW//WyK3gQMHFi677LL3tF5rcvvrX/9a2H///Qv3339/i3+/V199tdC+ffvCT3/602Ls008/XUhSmDt37gbXa82/54bu/bbHH3+80LNnz8KLL764Sd8D/tG9N3a/XXfdtfDDH/6wRXx1dXVh7733Xu9a6/v4/Pa3vy0kKXzve99b75zm5uZCt27dCt/61reK37tfffXVQlVVVeHHP/7xRvf2+9//vpBkg//j/O21TzrppOLPhPWt3dqv0YkTJxaqq6sLV155ZYvxI488svDVr351gx+397///Rtcs7m5uVBTU1Po0qVL8d/i/PPPL1RVVRU+/vGPb/B79DHHHFOora0tvm5qair06NGjcMEFFxS/92/oe/y75y5ZsqRQXl5euOiiiwr77rtv4Tvf+c5Gfz68Pf/tz7G3711XV1coFDb+s+Xtn7uHHHJI8eP49s/dtz+O7zZmzJhC3759C2effXbh5JNPbvG5NnDgwMI555yz0a/FCy+8sPjLrbf9/efDT37yk0JlZWVh7dq1G7x3TU1N4Vvf+lahUPjb12KPHj0KlZWV//Br8d33HjhwYOFf//VfN+nz/O17H3300YXa2tri59fff7zf9773FX8unnbaaYXPfvazLdbYY489CgcccEChUHjn6+LtXyK8++OwIRv6XHt7DbYute071LZq241R266f2vZv1Lbrp7ZtOV9tq7Zl61PbvkNtq7bdGLXt+qlt/0Ztu35q25bz1bZq263Nox824tlnn02PHj2y3377ZdiwYRs9qmfu3LkZPHhwi7EhQ4Zk7ty5WzvNra6hoSFlZWXZfffdNxhzzz335KijjsrZZ5+drl275ogjjshNN91UuiQ3YPXq1UmS6urq4lh5eXmqqqry0EMPbXTu28cYfe5zn9uqOb7b28fPvO9972sxPnPmzHTp0iWHHnpoxo8fn9dff32DazQ3N2f27Nk54IADMmTIkHTt2jUDBw7cpKOiNlVTU1Nuu+22rFq1KoMGDdpi625o/63x7txWrlyZRx99NF27ds2xxx6bmpqanHDCCf/wc+C95FZbW5vTTjttne8L8+fPz9q1a1uMH3jggdlnn302+P2itf+eG7p3krz++uv59Kc/nalTp6Zbt27/cB+bcu+N3e/YY4/NrFn/v/buPaqqMn8D+HPu3BUvIHJRFEEtdARvaF5B1AxBC00dodSwFB3LuzVKOWlOFzLL0pnCStOoFC1NQxQzTQUFyTJARG0IdeXlp3gB5Xx/f7DOHjacA2iK2TyftVirs/d59/vud7/7PY+td+39Kc6fPw+z2Yx169bh5s2bOHfunNX51Vr/uLm5AQAKCwuttrGwsBCnT59WyuTn56Ndu3bQaDRISEiwOXdfuXIFSUlJ8PX1hbe3d43HbtWqlfKb0KlTJ7i4uOCbb75RffdW7lEAuHnzJhYuXIgWLVpgzJgxWLduHfLy8hAeHm6130pLS/HQQw/ZnGcLCwtx5swZhIeHK31hMpnQrVs37N692+ocXVZWhoMHD6r6W6vVIiwsDFlZWcrcb22Of/fdd1VlzWYzYmNjERwcjOPHjyvHs/X7YKm7f//+yhgbPHgwzp8/jyVLliAlJaXG3xbL726PHj2wadMmFBUVITw8HKmpqUo/VlZWVobVq1dj3Lhx2LdvH/z8/FRjbeDAgfj5559t3otlZWX4+OOPUV5ejgEDBijbGzRogG7duuH777/H//3f/8HFxQV6vd5q3VFRUThz5gzCwsKUe3H58uXo3r17jWOlat2WOc3Hxwcmkwnjxo2zOadZ6o6NjcWhQ4eUPvv0009x8eJFhIaG4vPPP8f169fRt29fABX3bVpaGvLy8gAAmZmZuHDhAh5++GFlrJ0+fRq9e/dW+qpyP9g6B1tj7c+Qle4XzLYVmG2Zba1htq0Zs20FZlvbmG2ZbZltmW3rG7NtBWZbZltrmG1rxmxbgdnWNmZbZltm23rMtnd9KcR9asuWLZKcnCyHDx+WrVu3SkhIiPj4+MilS5esft9gMMgnn3yi2vbOO++Im5tbfTT3tqGWlUDXrl2ToKAgGT16dI3HMZlMYjKZZO7cuXLo0CFZsWKF2NnZyapVq+5wi2tW9XzKysrEx8dHoqOj5fz581JaWiqvvPKKAJDw8HCbx9m9e7d4enoqjx6qr5W55eXlMmTIEOnZs6dq+4oVK2Tr1q2Sk5Mjq1evFk9PTxk2bJjN41hWXDo4OMgbb7whWVlZsnjxYtFoNJKenv672piTkyOOjo6i0+mkQYMGsnnz5mrfud2VubbO//e27fvvvxcA0qhRI/nggw/k0KFDMm3aNDEajZKXl3fH27Z27Vp58MEHlUfpVF61uWbNGjEajdXKdOnSRWbNmmX1eLdyPWuqW0QkLi5Oxo8fr3yubQ6ore7a6rtw4YKEh4cLANHr9eLi4iL/+Mc/bM6vVfvH0u9OTk42+8eycvfXX39Vzd29evWSxo0bV5u733nnHXF0dBQAEhAQUOOjDi3HXr16tarNjRs3FgcHB+W4t3qPbtmyRdasWSMRERECQPl77733bPabwWCocZ598cUXBYAcP35cdS2io6NFq9VaLZuYmCgAZO/evar2Pfvss+Lg4KDM/bbm+MplFy1aJAMGDJAZM2ZI165dlZW5tspa6v7yyy9VYywmJka8vLxEo9HUeM6W393r169LTEyMABCtVisA5MMPP6zW559++qnodDopKioSg8EgkydPVo01y2+2rXvRUt4y1iqLjo6WyMhI8fHxkXnz5tksm5KSopSvfC9GR0fXeC9WrbvynNa5c2cZMGCAzTnNUvbgwYPK9ao8vrRareh0Otm2bZtSpry8XGbPni0ajUb0er1oNBrVtbbcF88884x07dpV1Q8jRoyweg5FRUVWx9rMmTNVx6C7h9m2ArMts21VzLbMtsy2zLbMtsy2zLb3H2bbCsy2zLZVMdsy2zLbMtsy2zLb3m/ZlgsV6ujChQvi4uJS7VFJFn/GwFtWViYRERHSqVOnWt+rZTAYJCQkRLVtypQp0r179zvV1Dqxdj6ZmZnSsWNHASA6nU4GDhwogwcPlkGDBlk9xqVLl6Rly5ayZcsWZVt9Bd6nn35aWrRooXqHkjVpaWk1PvbIMrGMGjVKtT0iIkIef/zx39XG0tJSyc/Pl8zMTJkzZ440adJEfvzxR9V3bjfw1vX8b7Vtlsl57ty5qu8HBgbKnDlz7mjbTp06JW5ubnL48GFl2+8NvHW9nrXVvXHjRvHz85PLly8r+2sLvDXVHRERUWN9IiLx8fHStWtX2b59u2RnZ0tCQoI0aNBAcnJylO9Unl+r9o+l3zt27FinwFtZdHS0REVFVZu7L168KHl5ebJr1y6JiIiQoKAgm+9nsnXsyMhIMRgMNn8TartHRUReffVV8ff3l02bNsnu3bvFzs5OTCaTpKamWu03ANUebWmZZ0+dOiWurq6qtlYNvNbm6KCgoGohpKysTFq3bi0ODg7K3G9tjh83bpxSNjMzU9zd3aWoqEgJMJbAa+v3wVL3xo0bVWPMUj4iIsJmu7t376787lbux3nz5omTk5M4OTlJamqqqlx4eLg88sgjyvncauANDw+Xnj17Wh0PUVFR0qhRIxk0aJCUlZVZLfvII48o4ykpKUl1L9YWeKvWXXlOqxwyrc1plrorB87K4ys2NlY8PT1V9+XatWvFy8tL1q5dKzk5ObJ06VIBoDyG8X4MvFQdsy2zLbNtBWZbZltL3cy2zLbMthWYbUU5D2bb+wezLbMts20FZltmW0vdzLbMtsy2FZhtRTmPP2q25UKFW9C5c2ebP47e3t6SmJio2jZ//nzp0KFDPbTs9tm6wcrKyiQqKko6dOggv/32W63H8fHxUa32ExFZvny5NG/e/E41tU5qmjAuXrwoZ8+eFZGK961MmjTJ6veysrKUcGz502g0otFoRKfT1fgD9ntMnjxZvLy8lFV1NSkpKREAsnXrVqv7S0tLRa/Xy8KFC1XbZ82aJT169Lgj7bUIDQ2VuLg41bbbCby3cv632rbjx48LAPn4449V+0eMGFHrqvNbbduGDRuqjR8AyvjZvn271b7x8fGRN954w+ox63o9a6s7Pj5e+e/K+7VarfTp0+eW6w4ICKixvmPHjgmgftegSMV1qfoeSMv8agmKFy5cUPV7Tf1TUFAgACQrK0u1vXfv3jJ16tQa5+7S0lJxcHCo9j8s6nJsNzc3m8et7R69evWqGAwG+eqrr1R90KFDB+nVq5fVfrOzs5O2bduqtlnmWcu1r7zS0nItAIizs7PNOVqn0ynzpmXud3V1Vf1PAWtz/FtvvaXMuYmJicp1t8yXldtSU93JycmqMRYTEyNDhw6VWbNmidFotFnW29tblixZoupHy+/u+PHjZeDAgUqZEydOiFarlZSUFBGp+M22vMvNci9ayloba5by7733XrXxcOnSJXFxcRFvb2+r/3CqXLdlPI0ePVp1L1a+dlXvRWt1V57TLONcpPqcVrnu0tJS0el0snz5ctX4svR35fvSy8tL3n77beU4paWlotFoxNPTU0T+e1888sgjMnToUOV7ldtSlaX+qr/Rlvrp3mC2tY3Z9vdjtmW2ZbZltmW2ZbZltqX6xGxrG7Pt78dsy2zLbMtsy2zLbMtse3doQXVSUlKCgoICeHh4WN0fEhKCtLQ01bbU1NQ7+g6o+nLjxg2MGDEC+fn52L59Oxo3blxrmZ49eyI3N1e1LS8vDy1atLhbzbxlDRo0QNOmTZGfn4/MzExERkZa/V7btm3xww8/IDs7W/kbOnQo+vXrh+zsbJvvRLpdIoL4+Hhs2LABO3bsgK+vb61lsrOzAcDmeDQajejSpUu9XBOz2ay8U+523M7532rbWrZsiebNm99yf9xO20JDQ6uNn86dO2PMmDHKfxsMBtV8kZubi1OnTtmcL+p6PWur+/nnn0dOTo5qPwAkJiYiKSnplusODAyssT7Lu760WvVPjU6ng9lsVj5Xnl+Dg4NhMBgwatQopd/Lyspq7B9fX180a9ZM1aeXLl3C/v370alTpxrnbqlYsGdzDNs69r59+3DlyhWbx63tHr1x4wZu3Lih9I2lD5ycnHDjxg0A1futYcOGuHDhgmqbZQyEhoYiJycHTZo0wXPPPadci+joaBiNRgQGBtocP8HBwUhLS1PN/SaTCX369FG+a22OP378OJycnJCWloaxY8ciJycHhw4dQtOmTTF16lQ0b94cM2fOxKBBg2qs+9tvv1XGmNlsRlpaGkJCQpCXlwcPDw+bZUNCQrBjxw5VP1p+d6uOsaSkJLi5uWHIkCEAKn6zCwoKVPdiamoq2rVrZ3WsWcqPGzdONR4uXbqE0NBQXL58GQsXLlS9V9Na3Zbx5Ofnp9yL3333HQwGAwDr96K1ui1zWk5ODvbv36+0t+qcULluo9Go9DdQMb4q93flPrt69apq/BmNRnh6eqKkpATAf++Lb7/9Vqnbcs/VNI9ZxppF5fqp/jHb1ozZ9vYx2zLbMtsy2zLbMtsCzLZUv5hta8Zse/uYbZltmW2ZbZltmW0BZtu76q4vhbhPTZ8+XdLT06WwsFD27NkjYWFh0qRJE2Vl59ixY1Ursvbs2SN6vV5ee+01OXr0qCxYsEAMBoP88MMP9+oUbLp8+bJkZWUpK1At7y86efKklJWVydChQ8XLy0uys7OluLhY+SstLVWO0b9/f1m2bJny+cCBA6LX6+Xll1+W/Px8WbNmjTg4OMjq1avv6fmIiCQnJ8vOnTuloKBAUlJSpEWLFjJ8+HDVMapez6ru5iPEnnnmGWnQoIGkp6er+vvq1asiInLs2DF56aWXJDMzUwoLC2Xjxo3SqlUr6d27t+o4AQEBsn79euXz+vXrxWAwyMqVKyU/P1+WLVsmOp1Odu/efdttnTNnjuzatUsKCwslJydH5syZIxqNRr755hsRqXgvVlZWlvzrX/8SAPLtt99KVlaWnDt3TjlG1bFT2/nfqbYlJiaKi4uLfPbZZ5Kfny8vvPCC2NnZqVZa3622VX2s1tNPPy0+Pj6yY8cOyczMlJCQkGqPSbpT17Nq3VXBymr231N35frKysrEz89PevXqJfv375djx47Ja6+9JgDklVdeUeZXV1dXcXJyUubX9u3bi0ajkcTERNm6dat07txZOnfurOr3qm185ZVXpGHDhhIVFSUffPCBDBgwQDw8PKR///7K3F1QUCCLFi2SzMxMOXnypOzZs0ciIiKkUaNGcubMmRqPbTKZ5OWXX5avv/5aevXqJXZ2dspxb+cenT59unTs2FHatGkjy5Ytk549e4qTk5OYTCZZtmyZzX7T6XTKPNu+fXsxGo2qedbSDxs3bpTg4GBp1aqV+Pr6yu7du5U5unv37hIbG6vM0evWrROj0SidOnWSZs2ayaOPPiouLi6Sk5OjzP2WOb5Vq1Yyf/58ZY6Pj48Xk8kkq1atkp9++kni4uKkYcOGcvr0aeURYpV/H6zVbTKZZMqUKaLX66VXr17i7OwsL7/8suh0Olm5cqVSNjIyUiIiIpSylt/dVq1aiZ+fn8TGxiorfO3s7GT58uUiUvHeLkdHR9UjLS1lQ0JCxMPDQ2JiYkSv10vHjh2r3Yv+/v7SpEkTmT17tqqP165dK4GBgeLi4iJeXl5SWFiozBE3b95U6tbr9ar33lW+Rjk5ORIZGSm+vr5W70VbdW/cuFFmzpwper1e3Nzc5MiRI9XmtPLycjGZTBIWFqYcz3Kt3d3dJTg4WKKiosTZ2VkWLFggGo1GeT9kbGysmEwmmThxohQWFsr69evF2dlZdDqdcq27du0qGo1GPvzwQ9V5VF6dXHVOtVxva+OF7j5mW2bbyphtKzDbMtsy2zLbMtsy2zLb3p+YbZltK2O2rcBsy2zLbMtsy2zLbHs/ZlsuVLBh5MiR4uHhIUajUTw9PWXkyJGqH8Y+ffpIbGysqkxycrL4+/uL0WiUBx54QBk4fzSWxztV/YuNjZXCwkKr+wDIzp07lWO0aNFCFixYoDrul19+KQ8++KCYTCZp27atrFy58p6fj4jI0qVLxcvLSwwGg/j4+MgLL7ygCu8i1q9nZXcz8Nrq76SkJBGpeH9V7969pVGjRmIymcTPz09mzpxZ7f1zlctYvP/+++Ln5yd2dnbSsWNH5fE5t2vcuHHSokULMRqN0rRpUwkNDVUCpYjIggULajwXkepjp7bzv1NtExFZvHixeHl5iYODg4SEhFQLbHerbVVD57Vr12TSpEni6uoqDg4OMmzYMCkuLlaVuVPX83YC7++pu2p9eXl5Mnz4cHFzcxMHBwfp0KGDdOvWTTW/Ojg4yJQpU1T119bvVT+bzWb5+9//LiaTSXl0lru7u2ruLioqksGDB4ubm5sYDAbx8vKS0aNHy88//1zj+ZvNZmnfvr1otVoBICaTSR5++GHluLdzj44cOVLc3d1Fq9Uqf76+vvL666+L2Wy22m8fffSRap7V6/XKu7uq9oO7u7toNBrx9vaW3NxcEfnvHA1AmjRpopqjLe9Sq2nu//LLL8VgMIhOp1PN8cuWLRMfHx8xGo3StWtX2bdvn4iIEnhrq9tSXqfTiclkEpPJpBpjlrIajUYaNGigKpucnCytWrUSrVYrer1ejEajBAQEKP0oIrJt2zYBIFFRUaq+Sk5OFj8/P+UxZyaTyea9CEDpR0sfW94tZ+2vsLBQVffixYutXiOTySShoaGSm5tr8160VrelbOvWraVZs2ZW5zRL3fHx8apjLlu2TDw8PESj0Yherxc7OztlfFlcunRJnJ2dpUGDBmJnZyetWrWS559/XhITE5Vr3aVLFxk3bly186jMWlawNV7o7mO2ZbatjNm2ArMtsy2zLbMtsy2zLbPt/YnZltm2MmbbCsy2zLbMtsy2zLbMtvdjttWIiICIiIiIiIiIiIiIiIiIiIioHmhr/woRERERERERERERERERERHRncGFCkRERERERERERERERERERFRvuFCBiIiIiIiIiIiIiIiIiIiI6g0XKhAREREREREREREREREREVG94UIFIiIiIiIiIiIiIiIiIiIiqjdcqEBERERERERERERERERERET1hgsViIiIiIiIiIiIiIiIiIiIqN5woQIRERERERERERERERERERHVGy5UICL6k0tISIC7uzs0Gg1SUlLqVCY9PR0ajQYXL168q237I2nZsiXefPPNe90MIiIiIqoBs23dMNsSERER/fEx29YNsy3RnxcXKhBRvXviiSeg0Wig0WhgNBrh5+eHl156CTdv3rzXTavVrYTGP4KjR4/ixRdfxIoVK1BcXIzBgwfftbr69u2LadOm3bXjExEREf0RMdvWH2ZbIiIioruL2bb+MNsSEQH6e90AIvrfNGjQICQlJaG0tBRbtmzB5MmTYTAYMHfu3Fs+Vnl5OTQaDbRarr2qqqCgAAAQGRkJjUZzj1tDRERE9OfEbFs/mG2JiIiI7j5m2/rBbEtExCcqENE9YjKZ0KxZM7Ro0QLPPPMMwsLCsGnTJgBAaWkpZsyYAU9PTzg6OqJbt25IT09Xyq5atQoNGzbEpk2b0L59e5hMJpw6dQqlpaWYPXs2vL29YTKZ4Ofnh/fff18pd+TIEQwePBhOTk5wd3fH2LFj8dtvvyn7+/bti6lTp2LWrFlo1KgRmjVrhoSEBGV/y5YtAQDDhg2DRqNRPhcUFCAyMhLu7u5wcnJCly5dsH37dtX5FhcXY8iQIbC3t4evry8++eSTao+sunjxIiZMmICmTZvCxcUF/fv3x+HDh2vsxx9++AH9+/eHvb09GjdujLi4OJSUlACoeHRYREQEAECr1dYYeLds2QJ/f3/Y29ujX79+OHHihGr/uXPnMGrUKHh6esLBwQGBgYFYu3atsv+JJ57Arl27sHTpUmXV9YkTJ1BeXo7x48fD19cX9vb2CAgIwNKlS2s8J8v1rSwlJUXV/sOHD6Nfv35wdnaGi4sLgoODkZmZqez/7rvv0KtXL9jb28Pb2xtTp07FlStXlP1nz55FRESEcj3WrFlTY5uIiIiIasJsy2xrC7MtERER3W+YbZltbWG2JaI7jQsViOgPwd7eHmVlZQCA+Ph4fP/991i3bh1ycnIQHR2NQYMGIT8/X/n+1atXsWTJEvz73//Gjz/+CDc3N8TExGDt2rV46623cPToUaxYsQJOTk4AKsJk//790alTJ2RmZmLr1q04c+YMRowYoWrHhx9+CEdHR+zfvx///Oc/8dJLLyE1NRUAkJGRAQBISkpCcXGx8rmkpAQPP/ww0tLSkJWVhUGDBiEiIgKnTp1SjhsTE4Nff/0V6enp+OKLL7By5UqcPXtWVXd0dDTOnj2Lr7/+GgcPHkRQUBBCQ0Nx/vx5q3125coVDBw4EK6ursjIyMBnn32G7du3Iz4+HgAwY8YMJCUlAagI3MXFxVaP88svv2D48OGIiIhAdnY2JkyYgDlz5qi+c/36dQQHB2Pz5s04cuQI4uLiMHbsWBw4cAAAsHTpUoSEhOCpp55S6vL29obZbIaXlxc+++wz/PTTT5g/fz7mzZuH5ORkq22pqzFjxsDLywsZGRk4ePAg5syZA4PBAKDiHyCDBg3Co48+ipycHHz66af47rvvlH4BKgL6L7/8gp07d+Lzzz/H8uXLq10PIiIiotvFbMtseyuYbYmIiOiPjNmW2fZWMNsS0S0RIqJ6FhsbK5GRkSIiYjabJTU1VUwmk8yYMUNOnjwpOp1OioqKVGVCQ0Nl7ty5IiKSlJQkACQ7O1vZn5ubKwAkNTXVap0LFy6U8PBw1bZffvlFAEhubq6IiPTp00ceeugh1Xe6dOkis2fPVj4DkA0bNtR6jg888IAsW7ZMRESOHj0qACQjI0PZn5+fLwAkMTFRRER2794tLi4ucv36ddVxWrduLStWrLBax8qVK8XV1VVKSkqUbZs3bxatViunT58WEZENGzZIbVP93LlzpX379qpts2fPFgBy4cIFm+WGDBki06dPVz736dNH/va3v9VYl4jI5MmT5dFHH7W5PykpSRo0aKDaVvU8nJ2dZdWqVVbLjx8/XuLi4lTbdu/eLVqtVq5du6aMlQMHDij7LdfIcj2IiIiI6orZltmW2ZaIiIj+LJhtmW2ZbYmoPunv+koIIiIrvvrqKzg5OeHGjRswm80YPXo0EhISkJ6ejvLycvj7+6u+X1paisaNGyufjUYjOnTooHzOzs6GTqdDnz59rNZ3+PBh7Ny5U1mpW1lBQYFSX+VjAoCHh0etKzZLSkqQkJCAzZs3o7i4GDdv3sS1a9eUlbm5ubnQ6/UICgpSyvj5+cHV1VXVvpKSEtU5AsC1a9eU95VVdfToUXTs2BGOjo7Ktp49e8JsNiM3Nxfu7u41trvycbp166baFhISovpcXl6ORYsWITk5GUVFRSgrK0NpaSkcHBxqPf4777yDDz74AKdOncK1a9dQVlaGv/zlL3Vqmy3PPfccJkyYgI8//hhhYWGIjo5G69atAVT0ZU5OjuqxYCICs9mMwsJC5OXlQa/XIzg4WNnftm3bao8tIyIiIqorZltm29+D2ZaIiIj+SJhtmW1/D2ZbIroVXKhARPdEv3798O6778JoNKJ58+bQ6yumo5KSEuh0Ohw8eBA6nU5VpnJYtbe3V737yt7evsb6SkpKEBERgSVLllTb5+Hhofy35TFUFhqNBmazucZjz5gxA6mpqXjttdfg5+cHe3t7PPbYY8oj0eqipKQEHh4eqne6WfwRgtirr76KpUuX4s0330RgYCAcHR0xbdq0Ws9x3bp1mDFjBl5//XWEhITA2dkZr776Kvbv32+zjFarhYiott24cUP1OSEhAaNHj8bmzZvx9ddfY8GCBVi3bh2GDRuGkpISTJw4EVOnTq12bB8fH+Tl5d3CmRMRERHVjtm2evuYbSsw2xIREdH9htm2evuYbSsw2xLRncaFCkR0Tzg6OsLPz6/a9k6dOqG8vBxnz55Fr1696ny8wMBAmM1m7Nq1C2FhYdX2BwUF4YsvvkDLli2VcH07DAYDysvLVdv27NmDJ554AsOGDQNQEV5PnDih7A8ICMDNmzeRlZWlrAY9duwYLly4oGrf6dOnodfr0bJlyzq1pV27dli1ahWuXLmirM7ds2cPtFotAgIC6nxO7dq1w6ZNm1Tb9u3bV+0cIyMj8de//hUAYDabkZeXh/bt2yvfMRqNVvumR48emDRpkrLN1kpji6ZNm+Ly5cuq88rOzq72PX9/f/j7++PZZ5/FqFGjkJSUhGHDhiEoKAg//fST1fEFVKzCvXnzJg4ePIguXboAqFg9ffHixRrbRURERGQLsy2zrS3MtkRERHS/YbZltrWF2ZaI7jTtvW4AEVFl/v7+GDNmDGJiYrB+/XoUFhbiwIEDWLx4MTZv3myzXMuWLREbG4tx48YhJSUFhYWFSE9PR3JyMgBg8uTJOH/+PEaNGoWMjAwUFBRg27ZtePLJJ6uFtJq0bNkSaWlpOH36tBJY27Rpg/Xr1yM7OxuHDx/G6NGjVat527Zti7CwMMTFxeHAgQPIyspCXFycanVxWFgYQkJCEBUVhW+++QYnTpzA3r178fzzzyMzM9NqW8aMGQM7OzvExsbiyJEj2LlzJ6ZMmYKxY8fW+fFhAPD0008jPz8fM2fORG5uLj755BOsWrVK9Z02bdogNTUVe/fuxdGjRzFx4kScOXOmWt/s378fJ06cwG+//Qaz2Yw2bdogMzMT27ZtQ15eHv7+978jIyOjxvZ069YNDg4OmDdvHgoKCqq159q1a4iPj0d6ejpOnjyJPXv2ICMjA+3atQMAzJ49G3v37kV8fDyys7ORn5+PjRs3Ij4+HkDFP0AGDRqEiRMnYv/+/Th48CAmTJhQ6+puIiIiolvFbMtsy2xLREREfxbMtsy2zLZEdKdxoQIR/eEkJSUhJiYG06dPR0BAAKKiopCRkQEfH58ay7377rt47LHHMGnSJLRt2xZPPfUUrly5AgBo3rw59uzZg/LycoSHhyMwMBDTpk1Dw4YNodXWfSp8/fXXkZqaCm9vb3Tq1AkA8MYbb8DV1RU9evRAREQEBg4cqHqvGQB89NFHcHd3R+/evTFs2DA89dRTcHZ2hp2dHYCKR5Vt2bIFvXv3xpNPPgl/f388/vjjOHnypM3w6uDggG3btuH8+fPo0qULHnvsMYSGhuLtt9+u8/kAFY/V+uKLL5CSkoKOHTvivffew6JFi1TfeeGFFxAUFISBAweib9++aNasGaKiolTfmTFjBnQ6Hdq3b4+mTZvi1KlTmDhxIoYPH46RI0eiW7duOHfunGqVrjWNGjXC6tWrsWXLFgQGBmLt2rVISEhQ9ut0Opw7dw4xMTHw9/fHiBEjMHjwYLz44osAKt5Xt2vXLuTl5aFXr17o1KkT5s+fj+bNmyvHSEpKQvPmzdGnTx8MHz4ccXFxcHNzu6V+IyIiIqoLZltmW2ZbIiIi+rNgtmW2ZbYlojtJI1VfKENERHfdf/7zH3h7e2P79u0IDQ29180hIiIiIrptzLZERERE9GfBbEtEVH+4UIGIqB7s2LEDJSUlCAwMRHFxMWbNmoWioiLk5eXBYDDc6+YREREREdUZsy0RERER/Vkw2xIR3Tv6e90AIqL/BTdu3MC8efNw/PhxODs7o0ePHlizZg3DLhERERHdd5htiYiIiOjPgtmWiOje4RMViIiIiIiIiIiIiIiIiIiIqN5o73UDiIiIiIiIiIiIiIiIiIiI6H8HFyoQERERERERERERERERERFRveFCBSIiIiIiIiIiIiIiIiIiIqo3XKhARERERERERERERERERERE9YYLFYiIiIiIiIiIiIiIiIiIiKjecKECERERERERERERERERERER1RsuVCAiIiIiIiIiIiIiIiIiIqJ6w4UKREREREREREREREREREREVG+4UIGIiIiIiIiIiIiIiIiIiIjqzf8DH5RjArHZmbAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef8166d",
   "metadata": {
    "papermill": {
     "duration": 0.0823,
     "end_time": "2025-01-08T08:58:00.412854",
     "exception": false,
     "start_time": "2025-01-08T08:58:00.330554",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4dfb8b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T08:58:00.579529Z",
     "iopub.status.busy": "2025-01-08T08:58:00.579199Z",
     "iopub.status.idle": "2025-01-08T09:23:43.739541Z",
     "shell.execute_reply": "2025-01-08T09:23:43.738732Z"
    },
    "papermill": {
     "duration": 1543.245912,
     "end_time": "2025-01-08T09:23:43.740853",
     "exception": false,
     "start_time": "2025-01-08T08:58:00.494941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 2\n",
      "Random seed: 81\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7759, Accuracy: 0.6276, F1 Micro: 0.7129, F1 Macro: 0.4886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6568, Accuracy: 0.9193, F1 Micro: 0.9405, F1 Macro: 0.6604\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5443, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4694, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3976, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3515, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.312, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2775, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2811, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2409, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 25: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 37.04449772834778 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.00034193125902675097\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 38\n",
      "Sampling duration: 10.003066301345825 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7729, Accuracy: 0.6328, F1 Micro: 0.718, F1 Macro: 0.4914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6625, Accuracy: 0.9167, F1 Micro: 0.9386, F1 Macro: 0.6595\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.551, Accuracy: 0.9648, F1 Micro: 0.9733, F1 Macro: 0.6527\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.466, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.42, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3576, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3252, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2924, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2866, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2624, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 63: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 37.145113468170166 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.0003218027704861015\n",
      "Samples above threshold: 34\n",
      "Acquired samples: 34\n",
      "Sampling duration: 9.099311113357544 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7114, Accuracy: 0.9167, F1 Micro: 0.9387, F1 Macro: 0.66\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5005, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3902, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3052, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2609, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2555, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2161, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.211, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2091, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.182, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 97: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 42.3074004650116 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.00014378802734427154\n",
      "Samples above threshold: 31\n",
      "Acquired samples: 31\n",
      "Sampling duration: 8.521729707717896 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7137, Accuracy: 0.9128, F1 Micro: 0.9359, F1 Macro: 0.659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5046, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3808, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3092, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2565, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2359, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.22, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2245, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1962, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1953, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 128: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 42.67727613449097 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.00016030679107643665\n",
      "Samples above threshold: 28\n",
      "Acquired samples: 28\n",
      "Sampling duration: 7.829782962799072 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6549, Accuracy: 0.9648, F1 Micro: 0.9733, F1 Macro: 0.6527\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4044, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2944, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2363, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2278, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1984, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1884, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1588, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1716, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1818, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 156: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 47.99647855758667 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.000107083929469809\n",
      "Samples above threshold: 25\n",
      "Acquired samples: 25\n",
      "Sampling duration: 6.995973587036133 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6582, Accuracy: 0.9648, F1 Micro: 0.9733, F1 Macro: 0.6527\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4105, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3017, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2469, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2174, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2036, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1921, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1664, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1694, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1939, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 181: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 48.5337860584259 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.00012615444429684434\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 22\n",
      "Sampling duration: 6.490320920944214 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6098, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3422, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2437, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2201, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2054, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1885, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1804, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1652, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1535, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1792, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 203: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 54.558058738708496 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.00014997265243437143\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 20\n",
      "Sampling duration: 5.855282783508301 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6099, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.353, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2614, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2154, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2022, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1771, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1874, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1635, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1701, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1614, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 223: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 54.08494687080383 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.00010339188302168623\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 18\n",
      "Sampling duration: 5.348360538482666 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6071, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3477, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2604, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2324, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.203, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1953, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1904, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1759, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1821, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1558, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 241: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 53.94641709327698 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.00011597880657063806\n",
      "Samples above threshold: 16\n",
      "Acquired samples: 9\n",
      "Sampling duration: 5.12155556678772 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6053, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3434, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2582, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2085, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1775, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1878, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1896, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1569, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.181, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1771, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 250: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 54.42283344268799 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 0.00011077491653850302\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 15\n",
      "Sampling duration: 4.804368734359741 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5727, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3101, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2181, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2153, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1885, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1584, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.165, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1503, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1576, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1692, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 265: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.746472120285034 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 9.52519796555862e-05\n",
      "Samples above threshold: 14\n",
      "Acquired samples: 14\n",
      "Sampling duration: 4.558324337005615 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5611, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3093, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2331, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2028, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1743, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1809, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1638, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1872, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1761, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1754, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 279: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.19928002357483 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 0.00010052040306618437\n",
      "Samples above threshold: 13\n",
      "Acquired samples: 13\n",
      "Sampling duration: 3.9627041816711426 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5634, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3002, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2142, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2049, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.174, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1651, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1556, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1555, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1546, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1618, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 292: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 60.66516447067261 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 9.629721607780082e-05\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.727539539337158 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5632, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3008, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2227, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1916, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1784, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1721, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1744, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1565, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1618, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1551, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 300: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 58.99168825149536 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 9.078258590307088e-05\n",
      "Samples above threshold: 10\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.4200425148010254 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.566, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3029, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2108, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2033, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1741, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1842, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1568, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1611, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1592, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1508, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 310: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.645041704177856 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 8.444570194114933e-05\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.129485845565796 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5689, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3018, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2321, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1948, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.19, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1698, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1661, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1714, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.174, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1687, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 320: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.6555061340332 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 7.468864496331663e-05\n",
      "Samples above threshold: 8\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.049572229385376 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5312, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2537, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2112, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1799, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1687, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1477, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1603, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1602, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1681, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1561, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 330: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.95357942581177 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 9.845976455835626e-05\n",
      "Samples above threshold: 7\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.7805731296539307 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5333, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2626, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2081, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1934, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1925, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1709, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1706, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1594, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1536, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.161, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 340: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.396087646484375 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 0.00010428623427287677\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.4941396713256836 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5302, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2768, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2132, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1955, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.181, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1685, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1595, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1642, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1708, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.153, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 350: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.93158578872681 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.000154760479927063\n",
      "Samples above threshold: 5\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.2940855026245117 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5327, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2758, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2098, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1752, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1851, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1692, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1826, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1665, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1602, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1514, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 360: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.11516332626343 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 9.51324596826453e-05\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.0243918895721436 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5344, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.269, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2159, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1993, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1787, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1717, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1761, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1634, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1765, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1604, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 370: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.73858904838562 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 8.407604982494381e-05\n",
      "Samples above threshold: 3\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.7390453815460205 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5328, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2736, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2059, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1977, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.168, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1621, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1622, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1577, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1617, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1627, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 380: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.64682412147522 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.00011920417382498272\n",
      "Samples above threshold: 2\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.5330321788787842 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5032, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2508, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.202, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1806, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1865, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1695, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1716, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1402, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1487, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1523, Accuracy: 0.9674, F1 Micro: 0.9753, F1 Macro: 0.6541\n",
      "Iteration 390: Accuracy: 0.9674, F1 Micro: 0.9753, F1 Macro: 0.6541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.98       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 69.443186044693 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.00014200354780768973\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.252032995223999 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4995, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2547, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1991, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1674, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1684, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1685, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1555, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1752, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1404, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1447, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 400: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 68.71019721031189 s\n",
      "Total sampling time: 106.03 seconds\n",
      "Total runtime: 1542.3710064888 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db23b2e5",
   "metadata": {
    "papermill": {
     "duration": 0.153137,
     "end_time": "2025-01-08T09:23:44.050574",
     "exception": false,
     "start_time": "2025-01-08T09:23:43.897437",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "914a49a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T09:23:44.361304Z",
     "iopub.status.busy": "2025-01-08T09:23:44.360941Z",
     "iopub.status.idle": "2025-01-08T09:49:34.901635Z",
     "shell.execute_reply": "2025-01-08T09:49:34.900839Z"
    },
    "papermill": {
     "duration": 1550.69876,
     "end_time": "2025-01-08T09:49:34.903284",
     "exception": false,
     "start_time": "2025-01-08T09:23:44.204524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 3\n",
      "Random seed: 14\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6708, Accuracy: 0.832, F1 Micro: 0.8709, F1 Macro: 0.6144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5673, Accuracy: 0.9609, F1 Micro: 0.9702, F1 Macro: 0.6503\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4855, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4136, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3704, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.322, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2931, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.267, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.243, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2233, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 25: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 36.60012435913086 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.00047238526749424645\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 38\n",
      "Sampling duration: 10.518910884857178 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6783, Accuracy: 0.8268, F1 Micro: 0.8732, F1 Macro: 0.6333\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5611, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4958, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4175, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3782, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3385, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.307, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2685, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2734, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2343, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 63: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 36.63331627845764 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.0003516822413075716\n",
      "Samples above threshold: 34\n",
      "Acquired samples: 34\n",
      "Sampling duration: 9.602325677871704 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.627, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4659, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3562, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3013, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2638, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2457, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2176, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1903, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2001, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1917, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 97: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 43.786890506744385 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.00016697535756975417\n",
      "Samples above threshold: 31\n",
      "Acquired samples: 31\n",
      "Sampling duration: 9.015269041061401 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6241, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4648, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.355, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2852, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2564, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2357, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2213, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.198, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1923, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1924, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 128: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 42.533663749694824 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.00017553283832967282\n",
      "Samples above threshold: 28\n",
      "Acquired samples: 28\n",
      "Sampling duration: 8.196603775024414 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5844, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.38, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2843, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2444, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.227, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2037, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1824, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1886, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.181, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1818, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 156: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 48.477317810058594 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.0001273559522815049\n",
      "Samples above threshold: 25\n",
      "Acquired samples: 25\n",
      "Sampling duration: 7.245445966720581 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5844, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3803, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2922, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2434, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2315, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2014, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1918, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.186, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1841, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1769, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 181: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 48.55097484588623 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.0001094924882636406\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 22\n",
      "Sampling duration: 6.659022092819214 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5441, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3235, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2482, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2075, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1868, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1726, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1725, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.161, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1605, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1463, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 203: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 54.84483456611633 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 9.901490266202017e-05\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 20\n",
      "Sampling duration: 5.935353755950928 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5488, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3328, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2434, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2087, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1968, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1745, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1772, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1796, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1503, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1675, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 223: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 53.942851066589355 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 9.04572501895018e-05\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 18\n",
      "Sampling duration: 5.514543771743774 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5469, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3213, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.25, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2153, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1991, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1788, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1695, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1703, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1425, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1468, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 241: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 54.01867651939392 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 9.905720798997208e-05\n",
      "Samples above threshold: 16\n",
      "Acquired samples: 9\n",
      "Sampling duration: 5.0003578662872314 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5509, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.326, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2344, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2272, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2038, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1696, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1719, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1723, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1691, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1612, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 250: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 54.088265895843506 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 0.00010263181466143575\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 15\n",
      "Sampling duration: 4.787689924240112 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5142, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2846, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2245, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1944, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1678, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.183, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1501, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1578, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1553, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1578, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 265: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.16804480552673 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 0.00010898433101829142\n",
      "Samples above threshold: 14\n",
      "Acquired samples: 14\n",
      "Sampling duration: 4.497237205505371 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5116, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2851, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2252, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1959, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1632, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1692, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1748, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1654, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1542, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.148, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 279: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 60.21535515785217 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 0.00013564550317823887\n",
      "Samples above threshold: 13\n",
      "Acquired samples: 13\n",
      "Sampling duration: 3.991115093231201 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5089, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2868, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2285, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2064, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1891, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1641, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1678, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1599, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1524, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1595, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 292: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 60.21486258506775 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 0.00010565996344666927\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.7755184173583984 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5147, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2905, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2109, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1959, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1869, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1853, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1738, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1493, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1723, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1708, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 300: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.39149069786072 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 0.00011605563704506497\n",
      "Samples above threshold: 10\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.529721736907959 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5134, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.287, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2351, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1898, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1753, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1802, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1564, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.164, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1738, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1501, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 310: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.65044689178467 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 0.00011606034458964132\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.2143073081970215 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5094, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2879, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.232, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1968, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.165, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1718, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.151, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1448, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1703, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1555, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 320: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.2198588848114 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 0.0001394419698044659\n",
      "Samples above threshold: 8\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.0627310276031494 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4807, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2539, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2185, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1837, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1613, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1621, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1688, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1542, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1365, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.133, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 330: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 64.64151883125305 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 0.00026463094109203673\n",
      "Samples above threshold: 7\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.774921178817749 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4856, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2611, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2057, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1891, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1639, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1718, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1555, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1646, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1706, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1521, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 340: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 64.21304678916931 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 0.00012830747436964884\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.5535733699798584 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4827, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2574, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2131, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1896, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1573, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.168, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1574, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1539, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1312, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1474, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 350: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 64.33425521850586 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.00015236966864904395\n",
      "Samples above threshold: 5\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.3087801933288574 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4839, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2855, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2154, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1901, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1895, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1786, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1659, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1568, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.164, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1633, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 360: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.476381063461304 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.0002395745148533024\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.00333571434021 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4879, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2613, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2043, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1771, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1744, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.182, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1563, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1555, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.151, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1347, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 370: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 64.28706455230713 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.00014668771618744366\n",
      "Samples above threshold: 3\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.7917609214782715 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4837, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2671, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1974, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.177, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1738, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1693, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1574, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1655, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1631, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1422, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 380: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.616644859313965 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 8.10364101198502e-05\n",
      "Samples above threshold: 2\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.551788091659546 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4569, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2421, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2017, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1823, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.18, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1589, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1591, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1452, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1608, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1386, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 390: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 67.46239948272705 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.00018574809364508833\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.3510448932647705 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4589, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2407, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2073, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2043, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1666, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1711, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1684, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1599, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1475, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1633, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 400: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 68.0412232875824 s\n",
      "Total sampling time: 108.88 seconds\n",
      "Total runtime: 1549.7801849842072 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACCoAAAHqCAYAAADInz0eAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACJdUlEQVR4nOz9fZjVZbk3/r9nBmYGRdBEhgdRkDSfQVEJLc07lNTb1LuUdrghKkscEmXvFErBbMvULglTErVNkmFSPuUdhts9lmWiJGg7b0U0TNgkoF9zJlEBZ9bvj34uG3mIQVjA8Hodx+c4XNc6r+tzXsM8nE3nXJ+yQqFQCAAAAAAAAABACZRv6wQAAAAAAAAAgJ2HRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJaNRAQAAAAAAAAAoGY0KAAAAAAAAAEDJaFQAAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAYLv2mc98Jr17997WaQAAAABbiEYFgM30ve99L2VlZRk4cOC2TgUAAN6Tm2++OWVlZeu9xo0bV4z7z//8z3zuc5/LoYcemoqKilY3D7y95uc///n1vv/Vr361GPPyyy+/ly0BALATUc8C7HjabesEAHZUM2fOTO/evTNv3rw899xzef/737+tUwIAgPfkyiuvTJ8+fVqMHXroocX/vvXWWzNr1qwceeSR6dGjx2bdo7q6OnfccUe+973vpbKyssV7P/7xj1NdXZ0333yzxfhNN92U5ubmzbofAAA7j+21ngVgXU5UANgMzz//fB5++OFMnjw5e+21V2bOnLmtU1qvVatWbesUAADYgZxyyik599xzW1z9+/cvvj9p0qQ0Njbmt7/9bfr167dZ9/jYxz6WxsbG/OIXv2gx/vDDD+f555/Paaedts6c9u3bp6qqarPu9/eam5v90hgAoA3bXuvZrc3vgYEdkUYFgM0wc+bM7LHHHjnttNPyyU9+cr2NCq+++mouvvji9O7dO1VVVdl7770zfPjwFkd+vfnmm7niiitywAEHpLq6Ot27d8//+T//J3/84x+TJL/61a9SVlaWX/3qVy3W/tOf/pSysrLcfPPNxbHPfOYz6dixY/74xz/m1FNPzW677ZZhw4YlSX7zm9/k7LPPzj777JOqqqr06tUrF198cd5444118l64cGHOOeec7LXXXunQoUM+8IEP5Ktf/WqS5Je//GXKyspy1113rTPv1ltvTVlZWebOndvqjycAADuGHj16pH379u9pjZ49e+b444/Prbfe2mJ85syZOeyww1r8xdvbPvOZz6xzLG9zc3OuueaaHHbYYamurs5ee+2Vj33sY3nssceKMWVlZRk9enRmzpyZQw45JFVVVZkzZ06S5PHHH88pp5ySTp06pWPHjvnoRz+aRx555D3tDQCA7du2qme31O9nk+SKK65IWVlZnnrqqXz605/OHnvskQ996ENJkrfeeitf//rX07dv31RVVaV37975yle+ktWrV7+nPQNsDR79ALAZZs6cmf/zf/5PKisr80//9E+5/vrr87vf/S5HH310kuS1117Lhz/84Tz99NP57Gc/myOPPDIvv/xy7rnnnvzP//xPunTpkqampvzv//2/U19fn0996lMZM2ZM/vrXv+b+++/Pk08+mb59+7Y6r7feeitDhgzJhz70oXz729/OLrvskiT56U9/mtdffz2jRo3KnnvumXnz5uXaa6/N//zP/+SnP/1pcf5///d/58Mf/nDat2+fL3zhC+ndu3f++Mc/5v/+3/+bq666Kh/5yEfSq1evzJw5M2edddY6H5O+fftm0KBB7+EjCwDAttTQ0LDOs3S7dOmyxe/z6U9/OmPGjMlrr72Wjh075q233spPf/rTjB07dpNPPPjc5z6Xm2++Oaeccko+//nP56233spvfvObPPLIIznqqKOKcQ888EB+8pOfZPTo0enSpUt69+6d//f//l8+/OEPp1OnTrnkkkvSvn373HDDDfnIRz6SBx98MAMHDtziewYAYOvbXuvZLfX72b939tlnZ//998+kSZNSKBSSJJ///OczY8aMfPKTn8y//Mu/5NFHH01dXV2efvrp9f7xGcC2pFEBoJXmz5+fhQsX5tprr02SfOhDH8ree++dmTNnFhsVvvWtb+XJJ5/MnXfe2eL/0L/sssuKReMPf/jD1NfXZ/Lkybn44ouLMePGjSvGtNbq1atz9tlnp66ursX4N7/5zXTo0KH4+gtf+ELe//735ytf+UqWLFmSffbZJ0nypS99KYVCIQsWLCiOJck3vvGNJH/7i7Rzzz03kydPTkNDQzp37pwkeemll/Kf//mfLTp7AQDY8QwePHidsc2tTTfmk5/8ZEaPHp2777475557bv7zP/8zL7/8cv7pn/4pP/jBD/7h/F/+8pe5+eabc+GFF+aaa64pjv/Lv/zLOvk+88wz+cMf/pCDDz64OHbWWWdl7dq1eeihh7LffvslSYYPH54PfOADueSSS/Lggw9uoZ0CAFBK22s9u6V+P/v3+vXr1+JUh9///veZMWNGPv/5z+emm25KklxwwQXp2rVrvv3tb+eXv/xlTjzxxC32MQB4rzz6AaCVZs6cmZqammJRV1ZWlqFDh+a2225LU1NTkuSOO+5Iv3791jl14O34t2O6dOmSL33pSxuM2RyjRo1aZ+zvi+BVq1bl5ZdfzrHHHptCoZDHH388yd+aDX7961/ns5/9bIsi+N35DB8+PKtXr87tt99eHJs1a1beeuutnHvuuZudNwAA297UqVNz//33t7i2hj322CMf+9jH8uMf/zjJ3x4jduyxx2bffffdpPl33HFHysrKMnHixHXee3ctfcIJJ7RoUmhqasp//ud/5swzzyw2KSRJ9+7d8+lPfzoPPfRQGhsbN2dbAABsY9trPbslfz/7tvPPP7/F63vvvTdJMnbs2Bbj//Iv/5IkmT17dmu2CLDVOVEBoBWamppy22235cQTT8zzzz9fHB84cGCuvvrq1NfX5+STT84f//jHfOITn9joWn/84x/zgQ98IO3abblvxe3atcvee++9zviSJUsyYcKE3HPPPfnLX/7S4r2GhoYkyeLFi5Nkvc9Q+3sHHnhgjj766MycOTOf+9znkvyteeODH/xg3v/+92+JbQAAsI0cc8wxLR6bsDV9+tOfzj//8z9nyZIlufvuu/Pv//7vmzz3j3/8Y3r06JH3ve99/zC2T58+LV6/9NJLef311/OBD3xgndiDDjoozc3NWbp0aQ455JBNzgcAgO3D9lrPbsnfz77t3XXuCy+8kPLy8nV+R9utW7fsvvvueeGFFzZpXYBS0agA0AoPPPBAXnzxxdx222257bbb1nl/5syZOfnkk7fY/TZ0ssLbJze8W1VVVcrLy9eJPemkk/LKK6/k0ksvzYEHHphdd901y5Yty2c+85k0Nze3Oq/hw4dnzJgx+Z//+Z+sXr06jzzySK677rpWrwMAwM7r4x//eKqqqjJixIisXr0655xzzla5z9//9RoAAGwpm1rPbo3fzyYbrnPfy2m9AKWkUQGgFWbOnJmuXbtm6tSp67x355135q677sq0adPSt2/fPPnkkxtdq2/fvnn00Uezdu3atG/ffr0xe+yxR5Lk1VdfbTHemu7XP/zhD1m0aFFmzJiR4cOHF8fffezZ28fe/qO8k+RTn/pUxo4dmx//+Md544030r59+wwdOnSTcwIAgA4dOuTMM8/Mj370o5xyyinp0qXLJs/t27dv7rvvvrzyyiubdKrC39trr72yyy675JlnnlnnvYULF6a8vDy9evVq1ZoAAOx8NrWe3Rq/n12ffffdN83NzXn22Wdz0EEHFcdXrFiRV199dZMfswZQKuX/OASAJHnjjTdy55135n//7/+dT37yk+tco0ePzl//+tfcc889+cQnPpHf//73ueuuu9ZZp1AoJEk+8YlP5OWXX17vSQRvx+y7776pqKjIr3/96xbvf+9739vkvCsqKlqs+fZ/X3PNNS3i9tprrxx//PGZPn16lixZst583talS5eccsop+dGPfpSZM2fmYx/7WKt+sQwAAEnyr//6r5k4cWIuv/zyVs37xCc+kUKhkK997WvrvPfu2vXdKioqcvLJJ+dnP/tZ/vSnPxXHV6xYkVtvvTUf+tCH0qlTp1blAwDAzmlT6tmt8fvZ9Tn11FOTJFOmTGkxPnny5CTJaaed9g/XACglJyoAbKJ77rknf/3rX/Pxj398ve9/8IMfzF577ZWZM2fm1ltvze23356zzz47n/3sZzNgwIC88sorueeeezJt2rT069cvw4cPzw9/+MOMHTs28+bNy4c//OGsWrUq//Vf/5ULLrggZ5xxRjp37pyzzz471157bcrKytK3b9/8/Oc/z8qVKzc57wMPPDB9+/bNv/7rv2bZsmXp1KlT7rjjjnWehZYk3/3ud/OhD30oRx55ZL7whS+kT58++dOf/pTZs2fniSeeaBE7fPjwfPKTn0ySfP3rX9/0DyQAADus//7v/84999yTJHnuuefS0NCQf/u3f0uS9OvXL6effnqr1uvXr1/69evX6jxOPPHE/PM//3O++93v5tlnn83HPvaxNDc35ze/+U1OPPHEjB49eqPz/+3f/i33339/PvShD+WCCy5Iu3btcsMNN2T16tUbfbYwAAA7tm1Rz26t38+uL5cRI0bkxhtvzKuvvpoTTjgh8+bNy4wZM3LmmWfmxBNPbNXeALY2jQoAm2jmzJmprq7OSSedtN73y8vLc9ppp2XmzJlZvXp1fvOb32TixIm56667MmPGjHTt2jUf/ehHs/feeyf5Wyftvffem6uuuiq33npr7rjjjuy555750Ic+lMMOO6y47rXXXpu1a9dm2rRpqaqqyjnnnJNvfetbOfTQQzcp7/bt2+f//t//mwsvvDB1dXWprq7OWWedldGjR69TRPfr1y+PPPJILr/88lx//fV58803s++++673+Wqnn3569thjjzQ3N2+weQMAgLZlwYIF6/y12NuvR4wY0epf7L4XP/jBD3L44YfnP/7jP/LlL385nTt3zlFHHZVjjz32H8495JBD8pvf/Cbjx49PXV1dmpubM3DgwPzoRz/KwIEDS5A9AADbwraoZ7fW72fX5/vf/37222+/3HzzzbnrrrvSrVu3jB8/PhMnTtzi+wJ4r8oKm3JeDAC8y1tvvZUePXrk9NNPz3/8x39s63QAAAAAAADYQZRv6wQA2DHdfffdeemllzJ8+PBtnQoAAAAAAAA7ECcqANAqjz76aP77v/87X//619OlS5csWLBgW6cEAAAAAADADsSJCgC0yvXXX59Ro0ala9eu+eEPf7it0wEAAAAAAGAH40QFAAAAAAAAAKBknKgAAAAAAAAAAJSMRgUAAAAAAAAAoGTabesEtpTm5ub8+c9/zm677ZaysrJtnQ4AAFtRoVDIX//61/To0SPl5W2v91ZtCwCw81DbAgDQVrSmtm0zjQp//vOf06tXr22dBgAAJbR06dLsvffe2zqNLU5tCwCw81HbAgDQVmxKbdtmGhV22223JH/bdKdOnbZxNgAAbE2NjY3p1atXsQZsa9S2AAA7D7UtAABtRWtq2zbTqPD2sWGdOnVS8AIA7CTa6tGxalsAgJ2P2hYAgLZiU2rbtvfQMwAAAAAAAABgu6VRAQAAAAAAAAAoGY0KAAAAAAAAAEDJaFQAAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAAAAAAKBkNCoAAAAAAAAAACWjUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAAAAAAAAQMloVAAAAAAAAAAASkajAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAHZav/71r3P66aenR48eKSsry9133/0P5/zqV7/KkUcemaqqqrz//e/PzTff3OL9urq6HH300dltt93StWvXnHnmmXnmmWe2zgYAAAAAAHZAGhUAANhprVq1Kv369cvUqVM3Kf7555/PaaedlhNPPDFPPPFELrroonz+85/PfffdV4x58MEHU1tbm0ceeST3339/1q5dm5NPPjmrVq3aWtsAAAAAANihtNvWCQAAwLZyyimn5JRTTtnk+GnTpqVPnz65+uqrkyQHHXRQHnrooXznO9/JkCFDkiRz5sxpMefmm29O165dM3/+/Bx//PFbLnkAAAAAgB2UExUAAGATzZ07N4MHD24xNmTIkMydO3eDcxoaGpIk73vf+zYYs3r16jQ2Nra4AAAAAADaKo0KAACwiZYvX56ampoWYzU1NWlsbMwbb7yxTnxzc3MuuuiiHHfccTn00EM3uG5dXV06d+5cvHr16rXFcwcAAAAA2F5oVAAAgK2ktrY2Tz75ZG677baNxo0fPz4NDQ3Fa+nSpSXKEAAAAACg9Npt6wQAAGBH0a1bt6xYsaLF2IoVK9KpU6d06NChxfjo0aPz85//PL/+9a+z9957b3TdqqqqVFVVbfF8AQAAAAC2R05UAACATTRo0KDU19e3GLv//vszaNCg4utCoZDRo0fnrrvuygMPPJA+ffqUOk0AAAAAgO2aRgUAAHZar732Wp544ok88cQTSZLnn38+TzzxRJYsWZLkb49kGD58eDH+/PPPz+LFi3PJJZdk4cKF+d73vpef/OQnufjii4sxtbW1+dGPfpRbb701u+22W5YvX57ly5fnjTfeKOneAAAAAAC2VxoVAADYaT322GM54ogjcsQRRyRJxo4dmyOOOCITJkxIkrz44ovFpoUk6dOnT2bPnp37778//fr1y9VXX53vf//7GTJkSDHm+uuvT0NDQz7ykY+ke/fuxWvWrFml3RwAAAAAwHaq3bZOAAAAtpWPfOQjKRQKG3z/5ptvXu+cxx9/fINzNrYeAAAAAABOVAAAAAAAAAAASkijAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJaNRAQAAAAAAAAAoGY0KAAAAAAAAAEDJaFQAAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAAIA2YOrUqendu3eqq6szcODAzJs3b6Pxr776ampra9O9e/dUVVXlgAMOyL333lt8v6mpKZdffnn69OmTDh06pG/fvvn617+eQqGwtbcCAEAb125bJwAAAAAAwHsza9asjB07NtOmTcvAgQMzZcqUDBkyJM8880y6du26TvyaNWty0kknpWvXrrn99tvTs2fPvPDCC9l9992LMd/85jdz/fXXZ8aMGTnkkEPy2GOPZeTIkencuXMuvPDCEu4OAIC2RqMCAAAAAMAObvLkyTnvvPMycuTIJMm0adMye/bsTJ8+PePGjVsnfvr06XnllVfy8MMPp3379kmS3r17t4h5+OGHc8YZZ+S0004rvv/jH//4H57UAAAA/4hHPwAAAAAA7MDWrFmT+fPnZ/DgwcWx8vLyDB48OHPnzl3vnHvuuSeDBg1KbW1tampqcuihh2bSpElpamoqxhx77LGpr6/PokWLkiS///3v89BDD+WUU07ZYC6rV69OY2NjiwsAAN7NiQoAAAAAADuwl19+OU1NTampqWkxXlNTk4ULF653zuLFi/PAAw9k2LBhuffee/Pcc8/lggsuyNq1azNx4sQkybhx49LY2JgDDzwwFRUVaWpqylVXXZVhw4ZtMJe6urp87Wtf23KbAwCgTXKiAgAAAADATqa5uTldu3bNjTfemAEDBmTo0KH56le/mmnTphVjfvKTn2TmzJm59dZbs2DBgsyYMSPf/va3M2PGjA2uO378+DQ0NBSvpUuXlmI7AADsYJyoAAAAAACwA+vSpUsqKiqyYsWKFuMrVqxIt27d1june/fuad++fSoqKopjBx10UJYvX541a9aksrIyX/7ylzNu3Lh86lOfSpIcdthheeGFF1JXV5cRI0asd92qqqpUVVVtoZ0BANBWOVEBAAAAAGAHVllZmQEDBqS+vr441tzcnPr6+gwaNGi9c4477rg899xzaW5uLo4tWrQo3bt3T2VlZZLk9ddfT3l5y18hV1RUtJgDAACbQ6MCAAAAAMAObuzYsbnpppsyY8aMPP300xk1alRWrVqVkSNHJkmGDx+e8ePHF+NHjRqVV155JWPGjMmiRYsye/bsTJo0KbW1tcWY008/PVdddVVmz56dP/3pT7nrrrsyefLknHXWWSXfHwAAbYtHPwAAAAAA7OCGDh2al156KRMmTMjy5cvTv3//zJkzJzU1NUmSJUuWtDgdoVevXrnvvvty8cUX5/DDD0/Pnj0zZsyYXHrppcWYa6+9NpdffnkuuOCCrFy5Mj169MgXv/jFTJgwoeT7AwCgbSkrFAqFbZ3EltDY2JjOnTunoaEhnTp12tbpAACwFbX12q+t7w8AgHe09dqvre8PAIB3tKb28+gHAAAAAAAAAKBkNCoAAAAAAAAAACWjUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZFrdqPDrX/86p59+enr06JGysrLcfffd/3DOr371qxx55JGpqqrK+9///tx8883rxEydOjW9e/dOdXV1Bg4cmHnz5rU2NQAAAAAAAABgO9fqRoVVq1alX79+mTp16ibFP//88znttNNy4okn5oknnshFF12Uz3/+87nvvvuKMbNmzcrYsWMzceLELFiwIP369cuQIUOycuXK1qYHAAAAAAAAAGzH2rV2wimnnJJTTjllk+OnTZuWPn365Oqrr06SHHTQQXnooYfyne98J0OGDEmSTJ48Oeedd15GjhxZnDN79uxMnz4948aNa22KAAAAAAAAAMB2qtUnKrTW3LlzM3jw4BZjQ4YMydy5c5Mka9asyfz581vElJeXZ/DgwcUYAAAAAAAAAKBtaPWJCq21fPny1NTUtBirqalJY2Nj3njjjfzlL39JU1PTemMWLly4wXVXr16d1atXF183NjZu2cQBAAAAAAAAgC1uq5+osLXU1dWlc+fOxatXr17bOiUAAAAAAAAA4B/Y6o0K3bp1y4oVK1qMrVixIp06dUqHDh3SpUuXVFRUrDemW7duG1x3/PjxaWhoKF5Lly7dKvkDAAAAAAAAAFvOVm9UGDRoUOrr61uM3X///Rk0aFCSpLKyMgMGDGgR09zcnPr6+mLM+lRVVaVTp04tLgAAAAAAAABg+9bqRoXXXnstTzzxRJ544okkyfPPP58nnngiS5YsSfK3kw6GDx9ejD///POzePHiXHLJJVm4cGG+973v5Sc/+UkuvvjiYszYsWNz0003ZcaMGXn66aczatSorFq1KiNHjnyP2wMAAAAAAAAAtiftWjvhsccey4knnlh8PXbs2CTJiBEjcvPNN+fFF18sNi0kSZ8+fTJ79uxcfPHFueaaa7L33nvn+9//foYMGVKMGTp0aF566aVMmDAhy5cvT//+/TNnzpzU1NS8l70BAAAAAAAAANuZskKhUNjWSWwJjY2N6dy5cxoaGjwGAgCgjWvrtV9b3x8AAO9o67VfW98fAADvaE3t1+pHPwAAAAAAAAAAbC6NCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAAAAAAAAQMloVAAAAAAAAAAASkajAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJaNRAQAAAAAAAAAoGY0KAAAAAAAAAEDJaFQAAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAADATuvXv/51Tj/99PTo0SNlZWW5++67/+GcX/3qVznyyCNTVVWV97///bn55pvXiZk6dWp69+6d6urqDBw4MPPmzdvyyQMAAAAA7KA0KgAAsNNatWpV+vXrl6lTp25S/PPPP5/TTjstJ554Yp544olcdNFF+fznP5/77ruvGDNr1qyMHTs2EydOzIIFC9KvX78MGTIkK1eu3FrbAAAAAADYobTb1gkAAMC2csopp+SUU07Z5Php06alT58+ufrqq5MkBx10UB566KF85zvfyZAhQ5IkkydPznnnnZeRI0cW58yePTvTp0/PuHHjtvwmAAAAAAB2ME5UAACATTR37twMHjy4xdiQIUMyd+7cJMmaNWsyf/78FjHl5eUZPHhwMQYAAAAAYGenUQEAADbR8uXLU1NT02KspqYmjY2NeeONN/Lyyy+nqalpvTHLly/f4LqrV69OY2NjiwsAAFpr6tSp6d27d6qrqzNw4MDMmzdvo/Gvvvpqamtr071791RVVeWAAw7IvffeW3y/d+/eKSsrW+eqra3d2lsBAKCN06gAAADbWF1dXTp37ly8evXqta1TAgBgBzNr1qyMHTs2EydOzIIFC9KvX78MGTIkK1euXG/8mjVrctJJJ+VPf/pTbr/99jzzzDO56aab0rNnz2LM7373u7z44ovF6/7770+SnH322SXZEwAAbVe7bZ0AAADsKLp165YVK1a0GFuxYkU6deqUDh06pKKiIhUVFeuN6dat2wbXHT9+fMaOHVt83djYqFkBAIBWmTx5cs4777yMHDkySTJt2rTMnj0706dPz7hx49aJnz59el555ZU8/PDDad++fZK/naDw9/baa68Wr7/xjW+kb9++OeGEE7bOJgAA2Gk4UQEAADbRoEGDUl9f32Ls/vvvz6BBg5IklZWVGTBgQIuY5ubm1NfXF2PWp6qqKp06dWpxAQDAplqzZk3mz5+fwYMHF8fKy8szePDgzJ07d71z7rnnngwaNCi1tbWpqanJoYcemkmTJqWpqWmD9/jRj36Uz372sykrK9sq+wAAYOfhRAUAAHZar732Wp577rni6+effz5PPPFE3ve+92WfffbJ+PHjs2zZsvzwhz9Mkpx//vm57rrrcskll+Szn/1sHnjggfzkJz/J7Nmzi2uMHTs2I0aMyFFHHZVjjjkmU6ZMyapVq4p/2QYAAFvayy+/nKamptTU1LQYr6mpycKFC9c7Z/HixXnggQcybNiw3HvvvXnuuedywQUXZO3atZk4ceI68XfffXdeffXVfOYzn9loLqtXr87q1auLrxsbG1u/IQAA2jyNCgAA7LQee+yxnHjiicXXbz9+YcSIEbn55pvz4osvZsmSJcX3+/Tpk9mzZ+fiiy/ONddck7333jvf//73M2TIkGLM0KFD89JLL2XChAlZvnx5+vfvnzlz5qzzS2MAANiWmpub07Vr19x4442pqKjIgAEDsmzZsnzrW99ab6PCf/zHf+SUU05Jjx49NrpuXV1dvva1r22ttAEAaCM0KgAAsNP6yEc+kkKhsMH3b7755vXOefzxxze67ujRozN69Oj3mh4AAGySLl26pKKiIitWrGgxvmLFinTr1m29c7p375727dunoqKiOHbQQQdl+fLlWbNmTSorK4vjL7zwQv7rv/4rd9555z/MZfz48cUG4ORvJyr06tWrtVsCAKCNK9/WCQAAAAAAsPkqKyszYMCA1NfXF8eam5tTX1+fQYMGrXfOcccdl+eeey7Nzc3FsUWLFqV79+4tmhSS5Ac/+EG6du2a00477R/mUlVVlU6dOrW4AADg3TQqAAAAAADs4MaOHZubbropM2bMyNNPP51Ro0Zl1apVGTlyZJJk+PDhGT9+fDF+1KhReeWVVzJmzJgsWrQos2fPzqRJk1JbW9ti3ebm5vzgBz/IiBEj0q6dA3oBANgyVJYAAAAAADu4oUOH5qWXXsqECROyfPny9O/fP3PmzElNTU2SZMmSJSkvf+fv1nr16pX77rsvF198cQ4//PD07NkzY8aMyaWXXtpi3f/6r//KkiVL8tnPfrak+wEAoG0rK2zsobw7kMbGxnTu3DkNDQ2OEwMAaOPaeu3X1vcHAMA72nrt19b3BwDAO1pT+3n0AwAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJaNRAQAAAAAAAAAoGY0KAAAAAAAAAEDJaFQAAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAAAAAAKBkNCoAAAAAAAAAACWjUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAAAAAAAAQMloVAAAAAAAAAAASkajAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJbNZjQpTp05N7969U11dnYEDB2bevHkbjF27dm2uvPLK9O3bN9XV1enXr1/mzJnTIqapqSmXX355+vTpkw4dOqRv3775+te/nkKhsDnpAQAAAAAAAADbqVY3KsyaNStjx47NxIkTs2DBgvTr1y9DhgzJypUr1xt/2WWX5YYbbsi1116bp556Kueff37OOuusPP7448WYb37zm7n++utz3XXX5emnn843v/nN/Pu//3uuvfbazd8ZAAAAAAAAALDdaXWjwuTJk3Peeedl5MiROfjggzNt2rTssssumT59+nrjb7nllnzlK1/Jqaeemv322y+jRo3KqaeemquvvroY8/DDD+eMM87Iaaedlt69e+eTn/xkTj755I2e1AAAAAAAAAAA7Hha1aiwZs2azJ8/P4MHD35ngfLyDB48OHPnzl3vnNWrV6e6urrFWIcOHfLQQw8VXx977LGpr6/PokWLkiS///3v89BDD+WUU05pTXoAAAAAAAAAwHauXWuCX3755TQ1NaWmpqbFeE1NTRYuXLjeOUOGDMnkyZNz/PHHp2/fvqmvr8+dd96ZpqamYsy4cePS2NiYAw88MBUVFWlqaspVV12VYcOGbTCX1atXZ/Xq1cXXjY2NrdkKAAAAAAAAALANtPrRD611zTXXZP/998+BBx6YysrKjB49OiNHjkx5+Tu3/slPfpKZM2fm1ltvzYIFCzJjxox8+9vfzowZMza4bl1dXTp37ly8evXqtbW3AgAAAAAAAAC8R61qVOjSpUsqKiqyYsWKFuMrVqxIt27d1jtnr732yt13351Vq1blhRdeyMKFC9OxY8fst99+xZgvf/nLGTduXD71qU/lsMMOyz//8z/n4osvTl1d3QZzGT9+fBoaGorX0qVLW7MVAAAAAAAAAGAbaFWjQmVlZQYMGJD6+vriWHNzc+rr6zNo0KCNzq2urk7Pnj3z1ltv5Y477sgZZ5xRfO/1119vccJCklRUVKS5uXmD61VVVaVTp04tLgAAAAAAAABg+9autRPGjh2bESNG5KijjsoxxxyTKVOmZNWqVRk5cmSSZPjw4enZs2fxNIRHH300y5YtS//+/bNs2bJcccUVaW5uziWXXFJc8/TTT89VV12VffbZJ4ccckgef/zxTJ48OZ/97Ge30DYBAAAAAAAAgO1BqxsVhg4dmpdeeikTJkzI8uXL079//8yZMyc1NTVJkiVLlrQ4HeHNN9/MZZddlsWLF6djx4459dRTc8stt2T33Xcvxlx77bW5/PLLc8EFF2TlypXp0aNHvvjFL2bChAnvfYcAAAAAAAAAwHajrFAoFLZ1EltCY2NjOnfunIaGBo+BAABo49p67dfW9wcAwDvaeu3X1vcHAMA7WlP7lW/0XQAAAAAAAACALUijAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAtAFTp05N7969U11dnYEDB2bevHkbjX/11VdTW1ub7t27p6qqKgcccEDuvffeFjHLli3Lueeemz333DMdOnTIYYcdlscee2xrbgMAgJ1Au22dAAAAAAAA782sWbMyduzYTJs2LQMHDsyUKVMyZMiQPPPMM+nates68WvWrMlJJ52Url275vbbb0/Pnj3zwgsvZPfddy/G/OUvf8lxxx2XE088Mb/4xS+y11575dlnn80ee+xRwp0BANAWaVQAAAAAANjBTZ48Oeedd15GjhyZJJk2bVpmz56d6dOnZ9y4cevET58+Pa+88koefvjhtG/fPknSu3fvFjHf/OY306tXr/zgBz8ojvXp02frbQIAgJ2GRz8AAAAAAOzA1qxZk/nz52fw4MHFsfLy8gwePDhz585d75x77rkngwYNSm1tbWpqanLooYdm0qRJaWpqahFz1FFH5eyzz07Xrl1zxBFH5Kabbtrq+wEAoO3TqAAAAAAAsAN7+eWX09TUlJqamhbjNTU1Wb58+XrnLF68OLfffnuamppy77335vLLL8/VV1+df/u3f2sRc/3112f//ffPfffdl1GjRuXCCy/MjBkzNpjL6tWr09jY2OICAIB38+gHAAAAAICdTHNzc7p27Zobb7wxFRUVGTBgQJYtW5ZvfetbmThxYjHmqKOOyqRJk5IkRxxxRJ588slMmzYtI0aMWO+6dXV1+drXvlayfQAAsGNyogIAAAAAwA6sS5cuqaioyIoVK1qMr1ixIt26dVvvnO7du+eAAw5IRUVFceyggw7K8uXLs2bNmmLMwQcf3GLeQQcdlCVLlmwwl/Hjx6ehoaF4LV26dHO3BQBAG6ZRAQAAAABgB1ZZWZkBAwakvr6+ONbc3Jz6+voMGjRovXOOO+64PPfcc2lubi6OLVq0KN27d09lZWUx5plnnmkxb9GiRdl33303mEtVVVU6derU4gIAgHfTqAAAAAAAsIMbO3ZsbrrppsyYMSNPP/10Ro0alVWrVmXkyJFJkuHDh2f8+PHF+FGjRuWVV17JmDFjsmjRosyePTuTJk1KbW1tMebiiy/OI488kkmTJuW5557LrbfemhtvvLFFDAAAbI522zoBAAAAAADem6FDh+all17KhAkTsnz58vTv3z9z5sxJTU1NkmTJkiUpL3/n79Z69eqV++67LxdffHEOP/zw9OzZM2PGjMmll15ajDn66KNz1113Zfz48bnyyivTp0+fTJkyJcOGDSv5/gAAaFvKCoVCYVsnsSU0Njamc+fOaWhocJwYAEAb19Zrv7a+PwAA3tHWa7+2vj8AAN7RmtrPox8AAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAOzUpk6dmt69e6e6ujoDBw7MvHnzNhi7du3aXHnllenbt2+qq6vTr1+/zJkzp0VMU1NTLr/88vTp0ycdOnRI37598/Wvfz2FQmFrbwUAAAAAYIegUQEAgJ3WrFmzMnbs2EycODELFixIv379MmTIkKxcuXK98ZdddlluuOGGXHvttXnqqady/vnn56yzzsrjjz9ejPnmN7+Z66+/Ptddd12efvrpfPOb38y///u/59prry3VtgAAAAAAtmsaFQAA2GlNnjw55513XkaOHJmDDz4406ZNyy677JLp06evN/6WW27JV77ylZx66qnZb7/9MmrUqJx66qm5+uqrizEPP/xwzjjjjJx22mnp3bt3PvnJT+bkk0/e6EkNAAAAAAA7E40KAADslNasWZP58+dn8ODBxbHy8vIMHjw4c+fOXe+c1atXp7q6usVYhw4d8tBDDxVfH3vssamvr8+iRYuSJL///e/z0EMP5ZRTTtlgLqtXr05jY2OLCwAAAACgrWq3rRMAAIBt4eWXX05TU1NqampajNfU1GThwoXrnTNkyJBMnjw5xx9/fPr27Zv6+vrceeedaWpqKsaMGzcujY2NOfDAA1NRUZGmpqZcddVVGTZs2AZzqaury9e+9rUtszEAAAAAgO2cExUAAGATXXPNNdl///1z4IEHprKyMqNHj87IkSNTXv5OWf2Tn/wkM2fOzK233poFCxZkxowZ+fa3v50ZM2ZscN3x48enoaGheC1durQU2wEAAAAA2CacqAAAwE6pS5cuqaioyIoVK1qMr1ixIt26dVvvnL322it333133nzzzfx//9//lx49emTcuHHZb7/9ijFf/vKXM27cuHzqU59Kkhx22GF54YUXUldXlxEjRqx33aqqqlRVVW2hnQEAAAAAbN+cqAAAwE6psrIyAwYMSH19fXGsubk59fX1GTRo0EbnVldXp2fPnnnrrbdyxx135Iwzzii+9/rrr7c4YSFJKioq0tzcvGU3AAAAAACwg3KiAgAAO62xY8dmxIgROeqoo3LMMcdkypQpWbVqVUaOHJkkGT58eHr27Jm6urokyaOPPpply5alf//+WbZsWa644oo0NzfnkksuKa55+umn56qrrso+++yTQw45JI8//ngmT56cz372s9tkjwAAAAAA2xuNCgAA7LSGDh2al156KRMmTMjy5cvTv3//zJkzJzU1NUmSJUuWtDgd4c0338xll12WxYsXp2PHjjn11FNzyy23ZPfddy/GXHvttbn88stzwQUXZOXKlenRo0e++MUvZsKECaXeHgAAAADAdqmsUCgUtnUSW0JjY2M6d+6choaGdOrUaVunAwDAVtTWa7+2vj8AAN7R1mu/tr4/AADe0Zrar3yj7wIAAAAAAAAAbEEaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAAAAAAKBkNCoAAAAAAAAAACWjUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAl025bJ7CjKhSS11/f1lkAAGw/dtklKSvb1lmwWQqFpElxCwBQVKG43VEVCoW8vlZtCwDwtl3a75Ky7bC21aiwmV5/PenYcVtnAQCw/XjttWTXXbd1FmyWpteTnyhuAQCKznktaae43RG9vvb1dKxT2wIAvO218a9l18rtr7b16AcAAAAAAAAAoGScqLCZdtnlb381CADA3+yyy7bOgM1Wscvf/moQAIC/qVDc7qh2ab9LXhuvtgUAeNsu7bfP2lajwmYqK3O0MQAAbURZmaONAQBoE8rKyrbLo40BAGjJox8AAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAAAAAAAAQMloVAAAAAAAAAAASkajAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJaNRAQAAAACgDZg6dWp69+6d6urqDBw4MPPmzdto/Kuvvpra2tp07949VVVVOeCAA3LvvfcW37/iiitSVlbW4jrwwAO39jYAANgJtNvWCQAAAAAA8N7MmjUrY8eOzbRp0zJw4MBMmTIlQ4YMyTPPPJOuXbuuE79mzZqcdNJJ6dq1a26//fb07NkzL7zwQnbfffcWcYccckj+67/+q/i6XTu/UgYA4L1TVQIAAAAA7OAmT56c8847LyNHjkySTJs2LbNnz8706dMzbty4deKnT5+eV155JQ8//HDat2+fJOndu/c6ce3atUu3bt22au4AAOx8NuvRD605Qmzt2rW58sor07dv31RXV6dfv36ZM2fOOnHLli3Lueeemz333DMdOnTIYYcdlscee2xz0gMAAAAA2GmsWbMm8+fPz+DBg4tj5eXlGTx4cObOnbveOffcc08GDRqU2tra1NTU5NBDD82kSZPS1NTUIu7ZZ59Njx49st9++2XYsGFZsmTJRnNZvXp1GhsbW1wAAPBurW5UePsIsYkTJ2bBggXp169fhgwZkpUrV643/rLLLssNN9yQa6+9Nk899VTOP//8nHXWWXn88ceLMX/5y19y3HHHpX379vnFL36Rp556KldffXX22GOPzd8ZAAAAAMBO4OWXX05TU1NqampajNfU1GT58uXrnbN48eLcfvvtaWpqyr333pvLL788V199df7t3/6tGDNw4MDcfPPNmTNnTq6//vo8//zz+fCHP5y//vWvG8ylrq4unTt3Ll69evXaMpsEAKBNKSsUCoXWTBg4cGCOPvroXHfddUmS5ubm9OrVK1/60pfWe4RYjx498tWvfjW1tbXFsU984hPp0KFDfvSjHyVJxo0bl9/+9rf5zW9+s9kbaWxsTOfOndPQ0JBOnTpt9joAAGz/2nrt19b3BwDAO7ZE7ffnP/85PXv2zMMPP5xBgwYVxy+55JI8+OCDefTRR9eZc8ABB+TNN9/M888/n4qKiiR/e3zEt771rbz44ovrvc+rr76afffdN5MnT87nPve59casXr06q1evbrG/Xr16qW0BAHYCraltW3WiwuYcIbZ69epUV1e3GOvQoUMeeuih4ut77rknRx11VM4+++x07do1RxxxRG666abWpAYAAAAAsFPq0qVLKioqsmLFihbjK1asSLdu3dY7p3v37jnggAOKTQpJctBBB2X58uVZs2bNeufsvvvuOeCAA/Lcc89tMJeqqqp06tSpxQUAAO/WqkaFzTlCbMiQIZk8eXKeffbZNDc35/7778+dd97Zoit38eLFuf7667P//vvnvvvuy6hRo3LhhRdmxowZG8zFs84AAAAAAJLKysoMGDAg9fX1xbHm5ubU19e3OGHh7x133HF57rnn0tzcXBxbtGhRunfvnsrKyvXOee211/LHP/4x3bt337IbAABgp9OqRoXNcc0112T//ffPgQcemMrKyowePTojR45Mefk7t25ubs6RRx6ZSZMm5YgjjsgXvvCFnHfeeZk2bdoG1/WsMwAAAACAvxk7dmxuuummzJgxI08//XRGjRqVVatWZeTIkUmS4cOHZ/z48cX4UaNG5ZVXXsmYMWOyaNGizJ49O5MmTWrxCN9//dd/zYMPPpg//elPefjhh3PWWWeloqIi//RP/1Ty/QEA0La0qlFhc44Q22uvvXL33Xdn1apVeeGFF7Jw4cJ07Ngx++23XzGme/fuOfjgg1vMO+igg7JkyZIN5jJ+/Pg0NDQUr6VLl7ZmKwAAAAAAbcbQoUPz7W9/OxMmTEj//v3zxBNPZM6cOcXTcZcsWdLilNtevXrlvvvuy+9+97scfvjhufDCCzNmzJiMGzeuGPM///M/+ad/+qd84AMfyDnnnJM999wzjzzySPbaa6+S7w8AgLalXWuC//4IsTPPPDPJO0eIjR49eqNzq6ur07Nnz6xduzZ33HFHzjnnnOJ7xx13XJ555pkW8YsWLcq+++67wfWqqqpSVVXVmvQBAAAAANqs0aNHb/D3tL/61a/WGRs0aFAeeeSRDa532223banUAACghVY1KiR/O0JsxIgROeqoo3LMMcdkypQp6xwh1rNnz9TV1SVJHn300Sxbtiz9+/fPsmXLcsUVV6S5uTmXXHJJcc2LL744xx57bCZNmpRzzjkn8+bNy4033pgbb7xxC20TAAAAAAAAANgetLpRYejQoXnppZcyYcKELF++PP3791/nCLHy8neeKPHmm2/msssuy+LFi9OxY8eceuqpueWWW7L77rsXY44++ujcddddGT9+fK688sr06dMnU6ZMybBhw977DgEAAAAAAACA7UZZoVAobOsktoTGxsZ07tw5DQ0N6dSp07ZOBwCArait135tfX8AALyjrdd+bX1/AAC8ozW1X/lG3wUAAAAAAAAA2II0KgAAAAAAAAAAJaNRAQAAAAAAAAAoGY0KAAAAAAAAAEDJaFQAAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAAAAAAKBkNCoAAAAAAAAAACWjUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAAAAAAAAQMloVAAAYKc2derU9O7dO9XV1Rk4cGDmzZu3wdi1a9fmyiuvTN++fVNdXZ1+/fplzpw568QtW7Ys5557bvbcc8906NAhhx12WB577LGtuQ0AAAAAgB2GRgUAAHZas2bNytixYzNx4sQsWLAg/fr1y5AhQ7Jy5cr1xl922WW54YYbcu211+app57K+eefn7POOiuPP/54MeYvf/lLjjvuuLRv3z6/+MUv8tRTT+Xqq6/OHnvsUaptAQAAAABs18oKhUJhWyexJTQ2NqZz585paGhIp06dtnU6AABsRVuq9hs4cGCOPvroXHfddUmS5ubm9OrVK1/60pcybty4deJ79OiRr371q6mtrS2OfeITn0iHDh3yox/9KEkybty4/Pa3v81vfvObzc5LbQsAsPNo67VfW98fAADvaE3t50QFAAB2SmvWrMn8+fMzePDg4lh5eXkGDx6cuXPnrnfO6tWrU11d3WKsQ4cOeeihh4qv77nnnhx11FE5++yz07Vr1xxxxBG56aabts4mAAAAAAB2QBoVAADYKb388stpampKTU1Ni/GamposX758vXOGDBmSyZMn59lnn01zc3Puv//+3HnnnXnxxReLMYsXL87111+f/fffP/fdd19GjRqVCy+8MDNmzNhgLqtXr05jY2OLCwAAAACgrdKoAAAAm+iaa67J/vvvnwMPPDCVlZUZPXp0Ro4cmfLyd8rq5ubmHHnkkZk0aVKOOOKIfOELX8h5552XadOmbXDdurq6dO7cuXj16tWrFNsBAAAAANgmNCoAALBT6tKlSyoqKrJixYoW4ytWrEi3bt3WO2evvfbK3XffnVWrVuWFF17IwoUL07Fjx+y3337FmO7du+fggw9uMe+ggw7KkiVLNpjL+PHj09DQULyWLl36HnYGAAAAALB906gAAMBOqbKyMgMGDEh9fX1xrLm5OfX19Rk0aNBG51ZXV6dnz5556623cscdd+SMM84ovnfcccflmWeeaRG/aNGi7Lvvvhtcr6qqKp06dWpxAQAAAAC0Ve22dQIAALCtjB07NiNGjMhRRx2VY445JlOmTMmqVasycuTIJMnw4cPTs2fP1NXVJUkeffTRLFu2LP3798+yZctyxRVXpLm5OZdccklxzYsvvjjHHntsJk2alHPOOSfz5s3LjTfemBtvvHGb7BEAAAAAYHujUQEAgJ3W0KFD89JLL2XChAlZvnx5+vfvnzlz5qSmpiZJsmTJkpSXv3MI2ZtvvpnLLrssixcvTseOHXPqqafmlltuye67716MOfroo3PXXXdl/PjxufLKK9OnT59MmTIlw4YNK/X2AAAAAAC2S2WFQqGwrZPYEhobG9O5c+c0NDQ4KhcAoI1r67VfW98fAADvaOu1X1vfHwAA72hN7Ve+0XcBAAAAAAAAALYgjQoAAAAAAAAAQMloVAAAAAAAAAAASkajAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJaNRAQAAAAAAAAAoGY0KAAAAAAAAAEDJaFQAAAAAAAAAAEpGowIAAAAAQBswderU9O7dO9XV1Rk4cGDmzZu30fhXX301tbW16d69e6qqqnLAAQfk3nvvXW/sN77xjZSVleWiiy7aCpkDALCzabetEwAAAAAA4L2ZNWtWxo4dm2nTpmXgwIGZMmVKhgwZkmeeeSZdu3ZdJ37NmjU56aST0rVr19x+++3p2bNnXnjhhey+++7rxP7ud7/LDTfckMMPP7wEOwEAYGfgRAUAAAAAgB3c5MmTc95552XkyJE5+OCDM23atOyyyy6ZPn36euOnT5+eV155JXfffXeOO+649O7dOyeccEL69evXIu61117LsGHDctNNN2WPPfYoxVYAANgJaFQAAAAAANiBrVmzJvPnz8/gwYOLY+Xl5Rk8eHDmzp273jn33HNPBg0alNra2tTU1OTQQw/NpEmT0tTU1CKutrY2p512Wou1N2b16tVpbGxscQEAwLt59AMAAAAAwA7s5ZdfTlNTU2pqalqM19TUZOHCheuds3jx4jzwwAMZNmxY7r333jz33HO54IILsnbt2kycODFJctttt2XBggX53e9+t8m51NXV5Wtf+9rmbwYAgJ2CExUAAAAAAHYyzc3N6dq1a2688cYMGDAgQ4cOzVe/+tVMmzYtSbJ06dKMGTMmM2fOTHV19SavO378+DQ0NBSvpUuXbq0tAACwA3OiAgAAAADADqxLly6pqKjIihUrWoyvWLEi3bp1W++c7t27p3379qmoqCiOHXTQQVm+fHnxURIrV67MkUceWXy/qakpv/71r3Pddddl9erVLea+raqqKlVVVVtoZwAAtFVOVAAAAAAA2IFVVlZmwIABqa+vL441Nzenvr4+gwYNWu+c4447Ls8991yam5uLY4sWLUr37t1TWVmZj370o/nDH/6QJ554ongdddRRGTZsWJ544on1NikAAMCmcqICAAAAAMAObuzYsRkxYkSOOuqoHHPMMZkyZUpWrVqVkSNHJkmGDx+enj17pq6uLkkyatSoXHfddRkzZky+9KUv5dlnn82kSZNy4YUXJkl22223HHrooS3useuuu2bPPfdcZxwAAFpLowIAAAAAwA5u6NCheemllzJhwoQsX748/fv3z5w5c1JTU5MkWbJkScrL3zlgt1evXrnvvvty8cUX5/DDD0/Pnj0zZsyYXHrppdtqCwAA7ETKCoVCYVsnsSU0Njamc+fOaWhoSKdOnbZ1OgAAbEVtvfZr6/sDAOAdbb32a+v7AwDgHa2p/co3+i4AAAAAAAAAwBakUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAAAAAAAAQMloVAAAAAAAAAAASkajAgAAAAAAAABQMpvVqDB16tT07t071dXVGThwYObNm7fB2LVr1+bKK69M3759U11dnX79+mXOnDkbjP/GN76RsrKyXHTRRZuTGgAAAAAAAACwHWt1o8KsWbMyduzYTJw4MQsWLEi/fv0yZMiQrFy5cr3xl112WW644YZce+21eeqpp3L++efnrLPOyuOPP75O7O9+97vccMMNOfzww1u/EwAAAAAAAABgu9fqRoXJkyfnvPPOy8iRI3PwwQdn2rRp2WWXXTJ9+vT1xt9yyy35yle+klNPPTX77bdfRo0alVNPPTVXX311i7jXXnstw4YNy0033ZQ99thj83YDAAAAAAAAAGzXWtWosGbNmsyfPz+DBw9+Z4Hy8gwePDhz585d75zVq1enurq6xViHDh3y0EMPtRirra3Naaed1mLtjVm9enUaGxtbXAAAAAAAAADA9q1VjQovv/xympqaUlNT02K8pqYmy5cvX++cIUOGZPLkyXn22WfT3Nyc+++/P3feeWdefPHFYsxtt92WBQsWpK6ubpNzqaurS+fOnYtXr169WrMVAAAAAAAAAGAbaPWjH1rrmmuuyf77758DDzwwlZWVGT16dEaOHJny8r/deunSpRkzZkxmzpy5zskLGzN+/Pg0NDQUr6VLl26tLQAAAAAAAAAAW0irGhW6dOmSioqKrFixosX4ihUr0q1bt/XO2WuvvXL33Xdn1apVeeGFF7Jw4cJ07Ngx++23X5Jk/vz5WblyZY488si0a9cu7dq1y4MPPpjvfve7adeuXZqamta7blVVVTp16tTiAgAAAAAAAAC2b61qVKisrMyAAQNSX19fHGtubk59fX0GDRq00bnV1dXp2bNn3nrrrdxxxx0544wzkiQf/ehH84c//CFPPPFE8TrqqKMybNiwPPHEE6moqNiMbQEAAAAAAAAA26N2rZ0wduzYjBgxIkcddVSOOeaYTJkyJatWrcrIkSOTJMOHD0/Pnj1TV1eXJHn00UezbNmy9O/fP8uWLcsVV1yR5ubmXHLJJUmS3XbbLYceemiLe+y6667Zc8891xkHAAAAAAAAAHZsrW5UGDp0aF566aVMmDAhy5cvT//+/TNnzpzU1NQkSZYsWZLy8ncOanjzzTdz2WWXZfHixenYsWNOPfXU3HLLLdl999232CYAAAAAAAAAgB1DWaFQKGzrJLaExsbGdO7cOQ0NDenUqdO2TgcAgK2ordd+bX1/AAC8o63Xfm19fwAAvKM1tV/5Rt8FAAAAAAAAANiCNCoAAAAAAAAAACWjUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAAAAAAAAQMloVAAAAAAAAAAASkajAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJaNRAQCAndrUqVPTu3fvVFdXZ+DAgZk3b94GY9euXZsrr7wyffv2TXV1dfr165c5c+ZsMP4b3/hGysrKctFFF22FzAEAAAAAdkwaFQAA2GnNmjUrY8eOzcSJE7NgwYL069cvQ4YMycqVK9cbf9lll+WGG27Itddem6eeeirnn39+zjrrrDz++OPrxP7ud7/LDTfckMMPP3xrbwMAAAAAYIeiUQEAgJ3W5MmTc95552XkyJE5+OCDM23atOyyyy6ZPn36euNvueWWfOUrX8mpp56a/fbbL6NGjcqpp56aq6++ukXca6+9lmHDhuWmm27KHnvsUYqtAAAAAADsMDQqAACwU1qzZk3mz5+fwYMHF8fKy8szePDgzJ07d71zVq9enerq6hZjHTp0yEMPPdRirLa2NqeddlqLtQEAYGtrzWPNkuTVV19NbW1tunfvnqqqqhxwwAG59957i+9ff/31Ofzww9OpU6d06tQpgwYNyi9+8YutvQ0AAHYC7bZ1AgAAsC28/PLLaWpqSk1NTYvxmpqaLFy4cL1zhgwZksmTJ+f4449P3759U19fnzvvvDNNTU3FmNtuuy0LFizI7373u03OZfXq1Vm9enXxdWNjYyt3AwDAzu7tx5pNmzYtAwcOzJQpUzJkyJA888wz6dq16zrxa9asyUknnZSuXbvm9ttvT8+ePfPCCy9k9913L8bsvffe+cY3vpH9998/hUIhM2bMyBlnnJHHH388hxxySAl3BwBAW+NEBQAA2ETXXHNN9t9//xx44IGprKzM6NGjM3LkyJSX/62sXrp0acaMGZOZM2euc/LCxtTV1aVz587Fq1evXltrCwAAtFGtfazZ9OnT88orr+Tuu+/Occcdl969e+eEE05Iv379ijGnn356Tj311Oy///454IADctVVV6Vjx4555JFHSrUtAADaKI0KAADslLp06ZKKioqsWLGixfiKFSvSrVu39c7Za6+9cvfdd2fVqlV54YUXsnDhwnTs2DH77bdfkmT+/PlZuXJljjzyyLRr1y7t2rXLgw8+mO9+97tp165di5MX/t748ePT0NBQvJYuXbplNwsAQJu2OY81u+eeezJo0KDU1tampqYmhx56aCZNmrTBmrWpqSm33XZbVq1alUGDBm2VfQAAsPPw6AcAAHZKlZWVGTBgQOrr63PmmWcmSZqbm1NfX5/Ro0dvdG51dXV69uyZtWvX5o477sg555yTJPnoRz+aP/zhDy1iR44cmQMPPDCXXnppKioq1rteVVVVqqqq3vumAADYKW3OY80WL16cBx54IMOGDcu9996b5557LhdccEHWrl2biRMnFuP+8Ic/ZNCgQXnzzTfTsWPH3HXXXTn44IM3mIvHmgEAsCk0KgAAsNMaO3ZsRowYkaOOOirHHHNMpkyZklWrVmXkyJFJkuHDh6dnz56pq6tLkjz66KNZtmxZ+vfvn2XLluWKK65Ic3NzLrnkkiTJbrvtlkMPPbTFPXbdddfsueee64wDAMC21NzcnK5du+bGG29MRUVFBgwYkGXLluVb3/pWi0aFD3zgA3niiSfS0NCQ22+/PSNGjMiDDz64wWaFurq6fO1rXyvVNgAA2EFpVAAAYKc1dOjQvPTSS5kwYUKWL1+e/v37Z86cOcW/RFuyZEnKy995Wtqbb76Zyy67LIsXL07Hjh1z6qmn5pZbbsnuu+++jXYAAACb91iz7t27p3379i1O/TrooIOyfPnyrFmzJpWVlUn+dhLZ+9///iTJgAED8rvf/S7XXHNNbrjhhvWuO378+IwdO7b4urGxMb169XpP+wMAoO3RqAAAwE5t9OjRG3zUw69+9asWr0844YQ89dRTrVr/3WsAAMCWtjmPNTvuuONy6623prm5udicu2jRonTv3r3YpLA+zc3NLR7t8G4eawYAwKYo/8chAAAAAABsz8aOHZubbropM2bMyNNPP51Ro0at81iz8ePHF+NHjRqVV155JWPGjMmiRYsye/bsTJo0KbW1tcWY8ePH59e//nX+9Kc/5Q9/+EPGjx+fX/3qVxk2bFjJ9wcAQNviRAUAAAAAgB1cax9r1qtXr9x33325+OKLc/jhh6dnz54ZM2ZMLr300mLMypUrM3z48Lz44ovp3LlzDj/88Nx333056aSTSr4/AADalrJCoVDY1klsCY2NjencuXMaGhrSqVOnbZ0OAABbUVuv/dr6/gAAeEdbr/3a+v4AAHhHa2o/j34AAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAAAAAAKBkNCoAAAAAAAAAACWjUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAAAAAAAAQMloVAAAAAAAAAAASkajAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJaNRAQAAAAAAAAAoGY0KAAAAAAAAAEDJaFQAAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAAAAAAKBkNCoAAAAAAAAAACWjUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKZrMaFaZOnZrevXunuro6AwcOzLx58zYYu3bt2lx55ZXp27dvqqur069fv8yZM6dFTF1dXY4++ujstttu6dq1a84888w888wzm5MaAAAAAAAAALAda3WjwqxZszJ27NhMnDgxCxYsSL9+/TJkyJCsXLlyvfGXXXZZbrjhhlx77bV56qmncv755+ess87K448/Xox58MEHU1tbm0ceeST3339/1q5dm5NPPjmrVq3a/J0BAAAAAAAAANudskKhUGjNhIEDB+boo4/OddddlyRpbm5Or1698qUvfSnjxo1bJ75Hjx756le/mtra2uLYJz7xiXTo0CE/+tGP1nuPl156KV27ds2DDz6Y448/fpPyamxsTOfOndPQ0JBOnTq1ZksAAOxg2nrt19b3BwDAO9p67dfW9wcAwDtaU/u16kSFNWvWZP78+Rk8ePA7C5SXZ/DgwZk7d+5656xevTrV1dUtxjp06JCHHnpog/dpaGhIkrzvfe/bYMzq1avT2NjY4gIAAAAAAAAAtm+talR4+eWX09TUlJqamhbjNTU1Wb58+XrnDBkyJJMnT86zzz6b5ubm3H///bnzzjvz4osvrje+ubk5F110UY477rgceuihG8ylrq4unTt3Ll69evVqzVYAAAAAAAAAgG2gVY0Km+Oaa67J/vvvnwMPPDCVlZUZPXp0Ro4cmfLy9d+6trY2Tz75ZG677baNrjt+/Pg0NDQUr6VLl26N9AEAAAAAAACALahVjQpdunRJRUVFVqxY0WJ8xYoV6dat23rn7LXXXrn77ruzatWqvPDCC1m4cGE6duyY/fbbb53Y0aNH5+c//3l++ctfZu+9995oLlVVVenUqVOLCwAAAAAAAADYvrWqUaGysjIDBgxIfX19cay5uTn19fUZNGjQRudWV1enZ8+eeeutt3LHHXfkjDPOKL5XKBQyevTo3HXXXXnggQfSp0+fVm4DAAAAAAAAANgRtGvthLFjx2bEiBE56qijcswxx2TKlClZtWpVRo4cmSQZPnx4evbsmbq6uiTJo48+mmXLlqV///5ZtmxZrrjiijQ3N+eSSy4prllbW5tbb701P/vZz7Lbbrtl+fLlSZLOnTunQ4cOW2KfAAAAAAAAAMB2oNWNCkOHDs1LL72UCRMmZPny5enfv3/mzJmTmpqaJMmSJUtSXv7OQQ1vvvlmLrvssixevDgdO3bMqaeemltuuSW77757Meb6669PknzkIx9pca8f/OAH+cxnPtP6XQEAAAAAAAAA26WyQqFQ2NZJbAmNjY3p3LlzGhoa0qlTp22dDgAAW1Fbr/3a+v4AAHhHW6/92vr+AAB4R2tqv/KNvgsAAAAAAAAAsAVpVAAAAAAAaAOmTp2a3r17p7q6OgMHDsy8efM2Gv/qq6+mtrY23bt3T1VVVQ444IDce++9xffr6upy9NFHZ7fddkvXrl1z5pln5plnntna2wAAYCegUQEAAAAAYAc3a9asjB07NhMnTsyCBQvSr1+/DBkyJCtXrlxv/Jo1a3LSSSflT3/6U26//fY888wzuemmm9KzZ89izIMPPpja2to88sgjuf/++7N27dqcfPLJWbVqVam2BQBAG9VuWycAAAAAAMB7M3ny5Jx33nkZOXJkkmTatGmZPXt2pk+fnnHjxq0TP3369Lzyyit5+OGH0759+yRJ7969W8TMmTOnxeubb745Xbt2zfz583P88cdvnY0AALBTcKICAAAAAMAObM2aNZk/f34GDx5cHCsvL8/gwYMzd+7c9c655557MmjQoNTW1qampiaHHnpoJk2alKampg3ep6GhIUnyvve9b8tuAACAnY4TFQAAAAAAdmAvv/xympqaUlNT02K8pqYmCxcuXO+cxYsX54EHHsiwYcNy77335rnnnssFF1yQtWvXZuLEievENzc356KLLspxxx2XQw89dIO5rF69OqtXry6+bmxs3MxdAQDQlmlUAAAAAADYyTQ3N6dr16658cYbU1FRkQEDBmTZsmX51re+td5Ghdra2jz55JN56KGHNrpuXV1dvva1r22ttAEAaCM8+gEAAAAAYAfWpUuXVFRUZMWKFS3GV6xYkW7duq13Tvfu3XPAAQekoqKiOHbQQQdl+fLlWbNmTYvY0aNH5+c//3l++ctfZu+9995oLuPHj09DQ0PxWrp06WbuCgCAtkyjAgAAAADADqyysjIDBgxIfX19cay5uTn19fUZNGjQeuccd9xxee6559Lc3FwcW7RoUbp3757KysokSaFQyOjRo3PXXXflgQceSJ8+ff5hLlVVVenUqVOLCwAA3k2jAgAAAADADm7s2LG56aabMmPGjDz99NMZNWpUVq1alZEjRyZJhg8fnvHjxxfjR40alVdeeSVjxozJokWLMnv27EyaNCm1tbXFmNra2vzoRz/Krbfemt122y3Lly/P8uXL88Ybb5R8fwAAtC3ttnUCAAAAAAC8N0OHDs1LL72UCRMmZPny5enfv3/mzJmTmpqaJMmSJUtSXv7O36316tUr9913Xy6++OIcfvjh6dmzZ8aMGZNLL720GHP99dcnST7ykY+0uNcPfvCDfOYzn9nqewIAoO0qKxQKhW2dxJbQ2NiYzp07p6GhwXFiAABtXFuv/dr6/gAAeEdbr/3a+v4AAHhHa2o/j34AAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAAAAAAKBkNCoAAAAAAAAAACWjUQEAAAAAAAAAKJl22zqBLaVQKCRJGhsbt3EmAABsbW/XfG/XgG2N2hYAYOehtgUAoK1oTW3bZhoV/vrXvyZJevXqtY0zAQCgVP7617+mc+fO2zqNLU5tCwCw81HbAgDQVmxKbVtWaCOtus3Nzfnzn/+c3XbbLWVlZSW5Z2NjY3r16pWlS5emU6dOJbnnttLW9rqj72dHy397zXd7ymtb5lLKe2/uvbZ2jltj/e1hzfeSw3vN373de2srFAr561//mh49eqS8vO09zUxtu3W1tb3u6PvZ0fLfXvPdnvJS226dedty/e1hzR211nHvnevem0ttu+VtTz8Xt7a2ttcdfT87Wv7ba77bU15q260zb1uuvz2suaPWOu69c917c7Wmtm0zJyqUl5dn77333ib37tSp0zb/YVkqbW2vO/p+drT8t9d8t6e8tmUupbz35t5ra+e4NdbfHtZ8Lzm81/zd2723prb412ZvU9uWRlvb646+nx0t/+013+0pL7Xt1pm3LdffHtbcUWsd99657r051LZbx/b0c3Fra2t73dH3s6Plv73muz3lpbbdOvO25frbw5o7aq3j3jvXvTfHpta2ba9FFwAAAAAAAADYbmlUAAAAAAAAAABKRqPCe1BVVZWJEyemqqpqW6ey1bW1ve7o+9nR8t9e892e8tqWuZTy3pt7r62d49ZYf3tY873k8F7zd2/3ZsezM/07trW97uj72dHy317z3Z7yUttunXnbcv3tYc0dtdZx753r3mw/dqZ/x7a21x19Pzta/ttrvttTXmrbrTNvW66/Pay5o9Y67r1z3bsUygqFQmFbJwEAAAAAAAAA7BycqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1FhA6644oqUlZW1uA488MCNzvnpT3+aAw88MNXV1TnssMNy7733lijb1vn1r3+d008/PT169EhZWVnuvvvu4ntr167NpZdemsMOOyy77rprevTokeHDh+fPf/7zP1x32bJlOffcc7PnnnumQ4cOOeyww/LYY49txZ38zcb2kyQrVqzIZz7zmfTo0SO77LJLPvaxj+XZZ5/d5PVvu+22lJWV5cwzz9yyif//1dXV5eijj85uu+2Wrl275swzz8wzzzzTIuYjH/nIOp+P559//j9c++mnn87HP/7xdO7cObvuumuOPvroLFmyZLNzvf7663P44YenU6dO6dSpUwYNGpRf/OIXxfdvvPHGfOQjH0mnTp1SVlaWV1999R+uuSn73xK5JcncuXPzv/7X/8quu+6aTp065fjjj88bb7yxVXP7xje+kbKyslx00UXFsTfffDO1tbXZc88907Fjx3ziE5/IihUr/uFarf33XN+931YoFHLKKaes92tmc++9vvstX748//zP/5xu3bpl1113zZFHHplzzjlno99fr7zyynTt2rX4Xo8ePfLb3/52o/kVCoVMmDAhHTt23OjaX/ziF9O3b9906NAhe+21V84444wsXLjwH659wgknbHTd1n6Nru9nTFVVVaZNm7bBj9sdd9zxD7/Pvv1xePtrcJ999il+v9vY3O9+97vp3LlzysvLU1FRkb322mud7/0bmj916tT07t071dXVGThwYObNm5fzzz8/ZWVlmTJlyj+899vzKysrs8cee6Rjx44tPsc2NvenP/1pDjjggFRUVKR9+/apqqrKwQcfXPw49u7de52Pc1lZWWpra1vMbdeuXTp06LDO1+KG5h999NGpqalJu3btsuuuu6a6ujr77LNPLrzwwjQ0NGx07gUXXJAJEyake/fu6dChQz760Y/m+OOPX+drcWP3fnvu0UcfnUGDBq3zPW1j+546dWp69eqVioqKVFZWpkOHDsXPr7c1NTXl8ssvT58+fdKhQ4f07ds3X//613PdddcV/62POeaYfO5znyvmMnjw4E362bq+zxdKQ22rtn2b2vYdalu1rdpWbau2VduqbXdMalu17dvUtu9Q26pt1bZqW7Wt2naHrG0LrNfEiRMLhxxySOHFF18sXi+99NIG43/7298WKioqCv/+7/9eeOqppwqXXXZZoX379oU//OEPJcx609x7772Fr371q4U777yzkKRw1113Fd979dVXC4MHDy7MmjWrsHDhwsLcuXMLxxxzTGHAgAEbXfOVV14p7LvvvoXPfOYzhUcffbSwePHiwn333Vd47rnntvJuNr6f5ubmwgc/+MHChz/84cK8efMKCxcuLHzhC18o7LPPPoXXXnvtH679/PPPF3r27Fn48Ic/XDjjjDO2Sv5Dhgwp/OAHPyg8+eSThSeeeKJw6qmnrpPfCSecUDjvvPNafD42NDRsdN3nnnuu8L73va/w5S9/ubBgwYLCc889V/jZz35WWLFixWbnes899xRmz55dWLRoUeGZZ54pfOUrXym0b9++8OSTTxYKhULhO9/5TqGurq5QV1dXSFL4y1/+skX2vyVye/jhhwudOnUq1NXVFZ588snCwoULC7NmzSq8+eabWy23efPmFXr37l04/PDDC2PGjCmOn3/++YVevXoV6uvrC4899ljhgx/8YOHYY4/d6Fqt/ffc0L3fNnny5MIpp5yyztfM5t57Q/c76aSTCkcffXTh0UcfLfzxj38sfP3rXy8kKfTt23eD31979epVeN/73lf4j//4j8Ktt95a2H333QuVlZUb/bh/4xvfKHTu3LkwdOjQQt++fQsnn3xyoVevXoXnn3++xdo33HBD4cEHHyw8//zzhfnz5xdOP/30Qq9evQpvvfXWRteuqqoq7LPPPoX6+vri2kuXLi3GtPZrdOLEiYU99tijsO+++xbuuOOOwrx58wpXX311oaKiovCzn/1svR+3srKyQvfu3Tf6ffYb3/hGoWPHjoWuXbsW9t9//8J+++1X6NOnT+HPf/7zBr9H33bbbYX27dsXDj744MLVV19dOPvsswsdO3YsHHHEEcXv/Rv6Hj9lypRCZWVlYfr06YX/9//+X+G8884r7LLLLoVDDjmk0KNHj8J3vvOdjf58uO222wqVlZXFf7/DDz+80LFjx8Kjjz5a+NnPflZ45plnNjj37Z+7xxxzTKFXr16Fc889t9CuXbvChAkTih/HlStXtvg3uf/++wtJCtdee22hoqKi8MEPfrDQrVu3wrBhwwrt2rUrHH744S2+Fjc0f9dddy1cc801hY9+9KOFY445prD33nsXfvGLXxT233//wic+8YmNzj3vvPMKnTt3Ltx9992F3//+94VDDjmk0KFDh3W+Fjd277vvvrvwwx/+sNCuXbvCHnvsUZg/f36L72kbmnv55ZcXKisrC4ccckjh0EMPLZxxxhmF3XbbrXDppZcWysvLCwsWLCgUCoXCVVddVdhzzz0LP//5zwvPP/984ac//Wmhurq6UFFRUfy3PvroowtJCjfffHPh97//feHjH/94oU+fPoU33nhjg5/3b/97//3ny+677/6efi6x6dS2attCQW37bmpbta3aVm2rtlXbqm13TGpbtW2hoLZ9N7Wt2lZtq7ZV26ptd8TaVqPCBkycOLHQr1+/TY4/55xzCqeddlqLsYEDBxa++MUvbuHMtqxN+WE3b968QpLCCy+8sMGYSy+9tPChD31oC2fXeu/ezzPPPFNIUix6CoVCoampqbDXXnsVbrrppo2u9dZbbxWOPfbYwve///3CiBEjtlrB+24rV64sJCk8+OCDxbETTjhhvUXLxgwdOrRw7rnnbuHs1rXHHnsUvv/977cY++Uvf7nJBe+7rW//WyK3gQMHFi677LL3tF5rcvvrX/9a2H///Qv3339/i3+/V199tdC+ffvCT3/602Ls008/XUhSmDt37gbXa82/54bu/bbHH3+80LNnz8KLL764Sd8D/tG9N3a/XXfdtfDDH/6wRXx1dXVh7733Xu9a6/v4/Pa3vy0kKXzve99b75zm5uZCt27dCt/61reK37tfffXVQlVVVeHHP/7xRvf2+9//vpBkg//j/O21TzrppOLPhPWt3dqv0YkTJxaqq6sLV155ZYvxI488svDVr351gx+397///Rtcs7m5uVBTU1Po0qVL8d/i/PPPL1RVVRU+/vGPb/B79DHHHFOora0tvm5qair06NGjcMEFFxS/92/oe/y75y5ZsqRQXl5euOiiiwr77rtv4Tvf+c5Gfz68Pf/tz7G3711XV1coFDb+s+Xtn7uHHHJI8eP49s/dtz+O7zZmzJhC3759C2effXbh5JNPbvG5NnDgwMI555yz0a/FCy+8sPjLrbf9/efDT37yk0JlZWVh7dq1G7x3TU1N4Vvf+lahUPjb12KPHj0KlZWV//Br8d33HjhwYOFf//VfN+nz/O17H3300YXa2tri59fff7zf9773FX8unnbaaYXPfvazLdbYY489CgcccEChUHjn6+LtXyK8++OwIRv6XHt7DbYute071LZq241R266f2vZv1Lbrp7ZtOV9tq7Zl61PbvkNtq7bdGLXt+qlt/0Ztu35q25bz1bZq263Nox824tlnn02PHj2y3377ZdiwYRs9qmfu3LkZPHhwi7EhQ4Zk7ty5WzvNra6hoSFlZWXZfffdNxhzzz335KijjsrZZ5+drl275ogjjshNN91UuiQ3YPXq1UmS6urq4lh5eXmqqqry0EMPbXTu28cYfe5zn9uqOb7b28fPvO9972sxPnPmzHTp0iWHHnpoxo8fn9dff32DazQ3N2f27Nk54IADMmTIkHTt2jUDBw7cpKOiNlVTU1Nuu+22rFq1KoMGDdpi625o/63x7txWrlyZRx99NF27ds2xxx6bmpqanHDCCf/wc+C95FZbW5vTTjttne8L8+fPz9q1a1uMH3jggdlnn302+P2itf+eG7p3krz++uv59Kc/nalTp6Zbt27/cB+bcu+N3e/YY4/NrFn/v/buPaqqMn8D+HPu3BUvIHJRFEEtdARvaF5B1AxBC00dodSwFB3LuzVKOWlOFzLL0pnCStOoFC1NQxQzTQUFyTJARG0IdeXlp3gB5Xx/f7DOHjacA2iK2TyftVirs/d59/vud7/7PY+td+39Kc6fPw+z2Yx169bh5s2bOHfunNX51Vr/uLm5AQAKCwuttrGwsBCnT59WyuTn56Ndu3bQaDRISEiwOXdfuXIFSUlJ8PX1hbe3d43HbtWqlfKb0KlTJ7i4uOCbb75RffdW7lEAuHnzJhYuXIgWLVpgzJgxWLduHfLy8hAeHm6130pLS/HQQw/ZnGcLCwtx5swZhIeHK31hMpnQrVs37N692+ocXVZWhoMHD6r6W6vVIiwsDFlZWcrcb22Of/fdd1VlzWYzYmNjERwcjOPHjyvHs/X7YKm7f//+yhgbPHgwzp8/jyVLliAlJaXG3xbL726PHj2wadMmFBUVITw8HKmpqUo/VlZWVobVq1dj3Lhx2LdvH/z8/FRjbeDAgfj5559t3otlZWX4+OOPUV5ejgEDBijbGzRogG7duuH777/H//3f/8HFxQV6vd5q3VFRUThz5gzCwsKUe3H58uXo3r17jWOlat2WOc3Hxwcmkwnjxo2zOadZ6o6NjcWhQ4eUPvv0009x8eJFhIaG4vPPP8f169fRt29fABX3bVpaGvLy8gAAmZmZuHDhAh5++GFlrJ0+fRq9e/dW+qpyP9g6B1tj7c+Qle4XzLYVmG2Zba1htq0Zs20FZlvbmG2ZbZltmW3rG7NtBWZbZltrmG1rxmxbgdnWNmZbZltm23rMtnd9KcR9asuWLZKcnCyHDx+WrVu3SkhIiPj4+MilS5esft9gMMgnn3yi2vbOO++Im5tbfTT3tqGWlUDXrl2ToKAgGT16dI3HMZlMYjKZZO7cuXLo0CFZsWKF2NnZyapVq+5wi2tW9XzKysrEx8dHoqOj5fz581JaWiqvvPKKAJDw8HCbx9m9e7d4enoqjx6qr5W55eXlMmTIEOnZs6dq+4oVK2Tr1q2Sk5Mjq1evFk9PTxk2bJjN41hWXDo4OMgbb7whWVlZsnjxYtFoNJKenv672piTkyOOjo6i0+mkQYMGsnnz5mrfud2VubbO//e27fvvvxcA0qhRI/nggw/k0KFDMm3aNDEajZKXl3fH27Z27Vp58MEHlUfpVF61uWbNGjEajdXKdOnSRWbNmmX1eLdyPWuqW0QkLi5Oxo8fr3yubQ6ore7a6rtw4YKEh4cLANHr9eLi4iL/+Mc/bM6vVfvH0u9OTk42+8eycvfXX39Vzd29evWSxo0bV5u733nnHXF0dBQAEhAQUOOjDi3HXr16tarNjRs3FgcHB+W4t3qPbtmyRdasWSMRERECQPl77733bPabwWCocZ598cUXBYAcP35cdS2io6NFq9VaLZuYmCgAZO/evar2Pfvss+Lg4KDM/bbm+MplFy1aJAMGDJAZM2ZI165dlZW5tspa6v7yyy9VYywmJka8vLxEo9HUeM6W393r169LTEyMABCtVisA5MMPP6zW559++qnodDopKioSg8EgkydPVo01y2+2rXvRUt4y1iqLjo6WyMhI8fHxkXnz5tksm5KSopSvfC9GR0fXeC9WrbvynNa5c2cZMGCAzTnNUvbgwYPK9ao8vrRareh0Otm2bZtSpry8XGbPni0ajUb0er1oNBrVtbbcF88884x07dpV1Q8jRoyweg5FRUVWx9rMmTNVx6C7h9m2ArMts21VzLbMtsy2zLbMtsy2zLb3H2bbCsy2zLZVMdsy2zLbMtsy2zLb3m/ZlgsV6ujChQvi4uJS7VFJFn/GwFtWViYRERHSqVOnWt+rZTAYJCQkRLVtypQp0r179zvV1Dqxdj6ZmZnSsWNHASA6nU4GDhwogwcPlkGDBlk9xqVLl6Rly5ayZcsWZVt9Bd6nn35aWrRooXqHkjVpaWk1PvbIMrGMGjVKtT0iIkIef/zx39XG0tJSyc/Pl8zMTJkzZ440adJEfvzxR9V3bjfw1vX8b7Vtlsl57ty5qu8HBgbKnDlz7mjbTp06JW5ubnL48GFl2+8NvHW9nrXVvXHjRvHz85PLly8r+2sLvDXVHRERUWN9IiLx8fHStWtX2b59u2RnZ0tCQoI0aNBAcnJylO9Unl+r9o+l3zt27FinwFtZdHS0REVFVZu7L168KHl5ebJr1y6JiIiQoKAgm+9nsnXsyMhIMRgMNn8TartHRUReffVV8ff3l02bNsnu3bvFzs5OTCaTpKamWu03ANUebWmZZ0+dOiWurq6qtlYNvNbm6KCgoGohpKysTFq3bi0ODg7K3G9tjh83bpxSNjMzU9zd3aWoqEgJMJbAa+v3wVL3xo0bVWPMUj4iIsJmu7t376787lbux3nz5omTk5M4OTlJamqqqlx4eLg88sgjyvncauANDw+Xnj17Wh0PUVFR0qhRIxk0aJCUlZVZLfvII48o4ykpKUl1L9YWeKvWXXlOqxwyrc1plrorB87K4ys2NlY8PT1V9+XatWvFy8tL1q5dKzk5ObJ06VIBoDyG8X4MvFQdsy2zLbNtBWZbZltL3cy2zLbMthWYbUU5D2bb+wezLbMts20FZltmW0vdzLbMtsy2FZhtRTmPP2q25UKFW9C5c2ebP47e3t6SmJio2jZ//nzp0KFDPbTs9tm6wcrKyiQqKko6dOggv/32W63H8fHxUa32ExFZvny5NG/e/E41tU5qmjAuXrwoZ8+eFZGK961MmjTJ6veysrKUcGz502g0otFoRKfT1fgD9ntMnjxZvLy8lFV1NSkpKREAsnXrVqv7S0tLRa/Xy8KFC1XbZ82aJT169Lgj7bUIDQ2VuLg41bbbCby3cv632rbjx48LAPn4449V+0eMGFHrqvNbbduGDRuqjR8AyvjZvn271b7x8fGRN954w+ox63o9a6s7Pj5e+e/K+7VarfTp0+eW6w4ICKixvmPHjgmgftegSMV1qfoeSMv8agmKFy5cUPV7Tf1TUFAgACQrK0u1vXfv3jJ16tQa5+7S0lJxcHCo9j8s6nJsNzc3m8et7R69evWqGAwG+eqrr1R90KFDB+nVq5fVfrOzs5O2bduqtlnmWcu1r7zS0nItAIizs7PNOVqn0ynzpmXud3V1Vf1PAWtz/FtvvaXMuYmJicp1t8yXldtSU93JycmqMRYTEyNDhw6VWbNmidFotFnW29tblixZoupHy+/u+PHjZeDAgUqZEydOiFarlZSUFBGp+M22vMvNci9ayloba5by7733XrXxcOnSJXFxcRFvb2+r/3CqXLdlPI0ePVp1L1a+dlXvRWt1V57TLONcpPqcVrnu0tJS0el0snz5ctX4svR35fvSy8tL3n77beU4paWlotFoxNPTU0T+e1888sgjMnToUOV7ldtSlaX+qr/Rlvrp3mC2tY3Z9vdjtmW2ZbZltmW2ZbZltqX6xGxrG7Pt78dsy2zLbMtsy2zLbMtse3doQXVSUlKCgoICeHh4WN0fEhKCtLQ01bbU1NQ7+g6o+nLjxg2MGDEC+fn52L59Oxo3blxrmZ49eyI3N1e1LS8vDy1atLhbzbxlDRo0QNOmTZGfn4/MzExERkZa/V7btm3xww8/IDs7W/kbOnQo+vXrh+zsbJvvRLpdIoL4+Hhs2LABO3bsgK+vb61lsrOzAcDmeDQajejSpUu9XBOz2ay8U+523M7532rbWrZsiebNm99yf9xO20JDQ6uNn86dO2PMmDHKfxsMBtV8kZubi1OnTtmcL+p6PWur+/nnn0dOTo5qPwAkJiYiKSnplusODAyssT7Lu760WvVPjU6ng9lsVj5Xnl+Dg4NhMBgwatQopd/Lyspq7B9fX180a9ZM1aeXLl3C/v370alTpxrnbqlYsGdzDNs69r59+3DlyhWbx63tHr1x4wZu3Lih9I2lD5ycnHDjxg0A1futYcOGuHDhgmqbZQyEhoYiJycHTZo0wXPPPadci+joaBiNRgQGBtocP8HBwUhLS1PN/SaTCX369FG+a22OP378OJycnJCWloaxY8ciJycHhw4dQtOmTTF16lQ0b94cM2fOxKBBg2qs+9tvv1XGmNlsRlpaGkJCQpCXlwcPDw+bZUNCQrBjxw5VP1p+d6uOsaSkJLi5uWHIkCEAKn6zCwoKVPdiamoq2rVrZ3WsWcqPGzdONR4uXbqE0NBQXL58GQsXLlS9V9Na3Zbx5Ofnp9yL3333HQwGAwDr96K1ui1zWk5ODvbv36+0t+qcULluo9Go9DdQMb4q93flPrt69apq/BmNRnh6eqKkpATAf++Lb7/9Vqnbcs/VNI9ZxppF5fqp/jHb1ozZ9vYx2zLbMtsy2zLbMtsCzLZUv5hta8Zse/uYbZltmW2ZbZltmW0BZtu76q4vhbhPTZ8+XdLT06WwsFD27NkjYWFh0qRJE2Vl59ixY1Ursvbs2SN6vV5ee+01OXr0qCxYsEAMBoP88MMP9+oUbLp8+bJkZWUpK1At7y86efKklJWVydChQ8XLy0uys7OluLhY+SstLVWO0b9/f1m2bJny+cCBA6LX6+Xll1+W/Px8WbNmjTg4OMjq1avv6fmIiCQnJ8vOnTuloKBAUlJSpEWLFjJ8+HDVMapez6ru5iPEnnnmGWnQoIGkp6er+vvq1asiInLs2DF56aWXJDMzUwoLC2Xjxo3SqlUr6d27t+o4AQEBsn79euXz+vXrxWAwyMqVKyU/P1+WLVsmOp1Odu/efdttnTNnjuzatUsKCwslJydH5syZIxqNRr755hsRqXgvVlZWlvzrX/8SAPLtt99KVlaWnDt3TjlG1bFT2/nfqbYlJiaKi4uLfPbZZ5Kfny8vvPCC2NnZqVZa3622VX2s1tNPPy0+Pj6yY8cOyczMlJCQkGqPSbpT17Nq3VXBymr231N35frKysrEz89PevXqJfv375djx47Ja6+9JgDklVdeUeZXV1dXcXJyUubX9u3bi0ajkcTERNm6dat07txZOnfurOr3qm185ZVXpGHDhhIVFSUffPCBDBgwQDw8PKR///7K3F1QUCCLFi2SzMxMOXnypOzZs0ciIiKkUaNGcubMmRqPbTKZ5OWXX5avv/5aevXqJXZ2dspxb+cenT59unTs2FHatGkjy5Ytk549e4qTk5OYTCZZtmyZzX7T6XTKPNu+fXsxGo2qedbSDxs3bpTg4GBp1aqV+Pr6yu7du5U5unv37hIbG6vM0evWrROj0SidOnWSZs2ayaOPPiouLi6Sk5OjzP2WOb5Vq1Yyf/58ZY6Pj48Xk8kkq1atkp9++kni4uKkYcOGcvr0aeURYpV/H6zVbTKZZMqUKaLX66VXr17i7OwsL7/8suh0Olm5cqVSNjIyUiIiIpSylt/dVq1aiZ+fn8TGxiorfO3s7GT58uUiUvHeLkdHR9UjLS1lQ0JCxMPDQ2JiYkSv10vHjh2r3Yv+/v7SpEkTmT17tqqP165dK4GBgeLi4iJeXl5SWFiozBE3b95U6tbr9ar33lW+Rjk5ORIZGSm+vr5W70VbdW/cuFFmzpwper1e3Nzc5MiRI9XmtPLycjGZTBIWFqYcz3Kt3d3dJTg4WKKiosTZ2VkWLFggGo1GeT9kbGysmEwmmThxohQWFsr69evF2dlZdDqdcq27du0qGo1GPvzwQ9V5VF6dXHVOtVxva+OF7j5mW2bbyphtKzDbMtsy2zLbMtsy2zLb3p+YbZltK2O2rcBsy2zLbMtsy2zLbHs/ZlsuVLBh5MiR4uHhIUajUTw9PWXkyJGqH8Y+ffpIbGysqkxycrL4+/uL0WiUBx54QBk4fzSWxztV/YuNjZXCwkKr+wDIzp07lWO0aNFCFixYoDrul19+KQ8++KCYTCZp27atrFy58p6fj4jI0qVLxcvLSwwGg/j4+MgLL7ygCu8i1q9nZXcz8Nrq76SkJBGpeH9V7969pVGjRmIymcTPz09mzpxZ7f1zlctYvP/+++Ln5yd2dnbSsWNH5fE5t2vcuHHSokULMRqN0rRpUwkNDVUCpYjIggULajwXkepjp7bzv1NtExFZvHixeHl5iYODg4SEhFQLbHerbVVD57Vr12TSpEni6uoqDg4OMmzYMCkuLlaVuVPX83YC7++pu2p9eXl5Mnz4cHFzcxMHBwfp0KGDdOvWTTW/Ojg4yJQpU1T119bvVT+bzWb5+9//LiaTSXl0lru7u2ruLioqksGDB4ubm5sYDAbx8vKS0aNHy88//1zj+ZvNZmnfvr1otVoBICaTSR5++GHluLdzj44cOVLc3d1Fq9Uqf76+vvL666+L2Wy22m8fffSRap7V6/XKu7uq9oO7u7toNBrx9vaW3NxcEfnvHA1AmjRpopqjLe9Sq2nu//LLL8VgMIhOp1PN8cuWLRMfHx8xGo3StWtX2bdvn4iIEnhrq9tSXqfTiclkEpPJpBpjlrIajUYaNGigKpucnCytWrUSrVYrer1ejEajBAQEKP0oIrJt2zYBIFFRUaq+Sk5OFj8/P+UxZyaTyea9CEDpR0sfW94tZ+2vsLBQVffixYutXiOTySShoaGSm5tr8160VrelbOvWraVZs2ZW5zRL3fHx8apjLlu2TDw8PESj0Yherxc7OztlfFlcunRJnJ2dpUGDBmJnZyetWrWS559/XhITE5Vr3aVLFxk3bly186jMWlawNV7o7mO2ZbatjNm2ArMtsy2zLbMtsy2zLbPt/YnZltm2MmbbCsy2zLbMtsy2zLbMtvdjttWIiICIiIiIiIiIiIiIiIiIiIioHmhr/woRERERERERERERERERERHRncGFCkRERERERERERERERERERFRvuFCBiIiIiIiIiIiIiIiIiIiI6g0XKhAREREREREREREREREREVG94UIFIiIiIiIiIiIiIiIiIiIiqjdcqEBERERERERERERERERERET1hgsViIiIiIiIiIiIiIiIiIiIqN5woQIRERERERERERERERERERHVGy5UICL6k0tISIC7uzs0Gg1SUlLqVCY9PR0ajQYXL168q237I2nZsiXefPPNe90MIiIiIqoBs23dMNsSERER/fEx29YNsy3RnxcXKhBRvXviiSeg0Wig0WhgNBrh5+eHl156CTdv3rzXTavVrYTGP4KjR4/ixRdfxIoVK1BcXIzBgwfftbr69u2LadOm3bXjExEREf0RMdvWH2ZbIiIioruL2bb+MNsSEQH6e90AIvrfNGjQICQlJaG0tBRbtmzB5MmTYTAYMHfu3Fs+Vnl5OTQaDbRarr2qqqCgAAAQGRkJjUZzj1tDRERE9OfEbFs/mG2JiIiI7j5m2/rBbEtExCcqENE9YjKZ0KxZM7Ro0QLPPPMMwsLCsGnTJgBAaWkpZsyYAU9PTzg6OqJbt25IT09Xyq5atQoNGzbEpk2b0L59e5hMJpw6dQqlpaWYPXs2vL29YTKZ4Ofnh/fff18pd+TIEQwePBhOTk5wd3fH2LFj8dtvvyn7+/bti6lTp2LWrFlo1KgRmjVrhoSEBGV/y5YtAQDDhg2DRqNRPhcUFCAyMhLu7u5wcnJCly5dsH37dtX5FhcXY8iQIbC3t4evry8++eSTao+sunjxIiZMmICmTZvCxcUF/fv3x+HDh2vsxx9++AH9+/eHvb09GjdujLi4OJSUlACoeHRYREQEAECr1dYYeLds2QJ/f3/Y29ujX79+OHHihGr/uXPnMGrUKHh6esLBwQGBgYFYu3atsv+JJ57Arl27sHTpUmXV9YkTJ1BeXo7x48fD19cX9vb2CAgIwNKlS2s8J8v1rSwlJUXV/sOHD6Nfv35wdnaGi4sLgoODkZmZqez/7rvv0KtXL9jb28Pb2xtTp07FlStXlP1nz55FRESEcj3WrFlTY5uIiIiIasJsy2xrC7MtERER3W+YbZltbWG2JaI7jQsViOgPwd7eHmVlZQCA+Ph4fP/991i3bh1ycnIQHR2NQYMGIT8/X/n+1atXsWTJEvz73//Gjz/+CDc3N8TExGDt2rV46623cPToUaxYsQJOTk4AKsJk//790alTJ2RmZmLr1q04c+YMRowYoWrHhx9+CEdHR+zfvx///Oc/8dJLLyE1NRUAkJGRAQBISkpCcXGx8rmkpAQPP/ww0tLSkJWVhUGDBiEiIgKnTp1SjhsTE4Nff/0V6enp+OKLL7By5UqcPXtWVXd0dDTOnj2Lr7/+GgcPHkRQUBBCQ0Nx/vx5q3125coVDBw4EK6ursjIyMBnn32G7du3Iz4+HgAwY8YMJCUlAagI3MXFxVaP88svv2D48OGIiIhAdnY2JkyYgDlz5qi+c/36dQQHB2Pz5s04cuQI4uLiMHbsWBw4cAAAsHTpUoSEhOCpp55S6vL29obZbIaXlxc+++wz/PTTT5g/fz7mzZuH5ORkq22pqzFjxsDLywsZGRk4ePAg5syZA4PBAKDiHyCDBg3Co48+ipycHHz66af47rvvlH4BKgL6L7/8gp07d+Lzzz/H8uXLq10PIiIiotvFbMtseyuYbYmIiOiPjNmW2fZWMNsS0S0RIqJ6FhsbK5GRkSIiYjabJTU1VUwmk8yYMUNOnjwpOp1OioqKVGVCQ0Nl7ty5IiKSlJQkACQ7O1vZn5ubKwAkNTXVap0LFy6U8PBw1bZffvlFAEhubq6IiPTp00ceeugh1Xe6dOkis2fPVj4DkA0bNtR6jg888IAsW7ZMRESOHj0qACQjI0PZn5+fLwAkMTFRRER2794tLi4ucv36ddVxWrduLStWrLBax8qVK8XV1VVKSkqUbZs3bxatViunT58WEZENGzZIbVP93LlzpX379qpts2fPFgBy4cIFm+WGDBki06dPVz736dNH/va3v9VYl4jI5MmT5dFHH7W5PykpSRo0aKDaVvU8nJ2dZdWqVVbLjx8/XuLi4lTbdu/eLVqtVq5du6aMlQMHDij7LdfIcj2IiIiI6orZltmW2ZaIiIj+LJhtmW2ZbYmoPunv+koIIiIrvvrqKzg5OeHGjRswm80YPXo0EhISkJ6ejvLycvj7+6u+X1paisaNGyufjUYjOnTooHzOzs6GTqdDnz59rNZ3+PBh7Ny5U1mpW1lBQYFSX+VjAoCHh0etKzZLSkqQkJCAzZs3o7i4GDdv3sS1a9eUlbm5ubnQ6/UICgpSyvj5+cHV1VXVvpKSEtU5AsC1a9eU95VVdfToUXTs2BGOjo7Ktp49e8JsNiM3Nxfu7u41trvycbp166baFhISovpcXl6ORYsWITk5GUVFRSgrK0NpaSkcHBxqPf4777yDDz74AKdOncK1a9dQVlaGv/zlL3Vqmy3PPfccJkyYgI8//hhhYWGIjo5G69atAVT0ZU5OjuqxYCICs9mMwsJC5OXlQa/XIzg4WNnftm3bao8tIyIiIqorZltm29+D2ZaIiIj+SJhtmW1/D2ZbIroVXKhARPdEv3798O6778JoNKJ58+bQ6yumo5KSEuh0Ohw8eBA6nU5VpnJYtbe3V737yt7evsb6SkpKEBERgSVLllTb5+Hhofy35TFUFhqNBmazucZjz5gxA6mpqXjttdfg5+cHe3t7PPbYY8oj0eqipKQEHh4eqne6WfwRgtirr76KpUuX4s0330RgYCAcHR0xbdq0Ws9x3bp1mDFjBl5//XWEhITA2dkZr776Kvbv32+zjFarhYiott24cUP1OSEhAaNHj8bmzZvx9ddfY8GCBVi3bh2GDRuGkpISTJw4EVOnTq12bB8fH+Tl5d3CmRMRERHVjtm2evuYbSsw2xIREdH9htm2evuYbSsw2xLRncaFCkR0Tzg6OsLPz6/a9k6dOqG8vBxnz55Fr1696ny8wMBAmM1m7Nq1C2FhYdX2BwUF4YsvvkDLli2VcH07DAYDysvLVdv27NmDJ554AsOGDQNQEV5PnDih7A8ICMDNmzeRlZWlrAY9duwYLly4oGrf6dOnodfr0bJlyzq1pV27dli1ahWuXLmirM7ds2cPtFotAgIC6nxO7dq1w6ZNm1Tb9u3bV+0cIyMj8de//hUAYDabkZeXh/bt2yvfMRqNVvumR48emDRpkrLN1kpji6ZNm+Ly5cuq88rOzq72PX9/f/j7++PZZ5/FqFGjkJSUhGHDhiEoKAg//fST1fEFVKzCvXnzJg4ePIguXboAqFg9ffHixRrbRURERGQLsy2zrS3MtkRERHS/YbZltrWF2ZaI7jTtvW4AEVFl/v7+GDNmDGJiYrB+/XoUFhbiwIEDWLx4MTZv3myzXMuWLREbG4tx48YhJSUFhYWFSE9PR3JyMgBg8uTJOH/+PEaNGoWMjAwUFBRg27ZtePLJJ6uFtJq0bNkSaWlpOH36tBJY27Rpg/Xr1yM7OxuHDx/G6NGjVat527Zti7CwMMTFxeHAgQPIyspCXFycanVxWFgYQkJCEBUVhW+++QYnTpzA3r178fzzzyMzM9NqW8aMGQM7OzvExsbiyJEj2LlzJ6ZMmYKxY8fW+fFhAPD0008jPz8fM2fORG5uLj755BOsWrVK9Z02bdogNTUVe/fuxdGjRzFx4kScOXOmWt/s378fJ06cwG+//Qaz2Yw2bdogMzMT27ZtQ15eHv7+978jIyOjxvZ069YNDg4OmDdvHgoKCqq159q1a4iPj0d6ejpOnjyJPXv2ICMjA+3atQMAzJ49G3v37kV8fDyys7ORn5+PjRs3Ij4+HkDFP0AGDRqEiRMnYv/+/Th48CAmTJhQ6+puIiIiolvFbMtsy2xLREREfxbMtsy2zLZEdKdxoQIR/eEkJSUhJiYG06dPR0BAAKKiopCRkQEfH58ay7377rt47LHHMGnSJLRt2xZPPfUUrly5AgBo3rw59uzZg/LycoSHhyMwMBDTpk1Dw4YNodXWfSp8/fXXkZqaCm9vb3Tq1AkA8MYbb8DV1RU9evRAREQEBg4cqHqvGQB89NFHcHd3R+/evTFs2DA89dRTcHZ2hp2dHYCKR5Vt2bIFvXv3xpNPPgl/f388/vjjOHnypM3w6uDggG3btuH8+fPo0qULHnvsMYSGhuLtt9+u8/kAFY/V+uKLL5CSkoKOHTvivffew6JFi1TfeeGFFxAUFISBAweib9++aNasGaKiolTfmTFjBnQ6Hdq3b4+mTZvi1KlTmDhxIoYPH46RI0eiW7duOHfunGqVrjWNGjXC6tWrsWXLFgQGBmLt2rVISEhQ9ut0Opw7dw4xMTHw9/fHiBEjMHjwYLz44osAKt5Xt2vXLuTl5aFXr17o1KkT5s+fj+bNmyvHSEpKQvPmzdGnTx8MHz4ccXFxcHNzu6V+IyIiIqoLZltmW2ZbIiIi+rNgtmW2ZbYlojtJI1VfKENERHfdf/7zH3h7e2P79u0IDQ29180hIiIiIrptzLZERERE9GfBbEtEVH+4UIGIqB7s2LEDJSUlCAwMRHFxMWbNmoWioiLk5eXBYDDc6+YREREREdUZsy0RERER/Vkw2xIR3Tv6e90AIqL/BTdu3MC8efNw/PhxODs7o0ePHlizZg3DLhERERHdd5htiYiIiOjPgtmWiOje4RMViIiIiIiIiIiIiIiIiIiIqN5o73UDiIiIiIiIiIiIiIiIiIiI6H8HFyoQERERERERERERERERERFRveFCBSIiIiIiIiIiIiIiIiIiIqo3XKhARERERERERERERERERERE9YYLFYiIiIiIiIiIiIiIiIiIiKjecKECERERERERERERERERERER1RsuVCAiIiIiIiIiIiIiIiIiIqJ6w4UKREREREREREREREREREREVG+4UIGIiIiIiIiIiIiIiIiIiIjqzf8DH5RjArHZmbAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61646a1",
   "metadata": {
    "papermill": {
     "duration": 0.224515,
     "end_time": "2025-01-08T09:49:35.408813",
     "exception": false,
     "start_time": "2025-01-08T09:49:35.184298",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "398a19d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T09:49:35.859558Z",
     "iopub.status.busy": "2025-01-08T09:49:35.859230Z",
     "iopub.status.idle": "2025-01-08T10:15:33.242720Z",
     "shell.execute_reply": "2025-01-08T10:15:33.241970Z"
    },
    "papermill": {
     "duration": 1557.611011,
     "end_time": "2025-01-08T10:15:33.244266",
     "exception": false,
     "start_time": "2025-01-08T09:49:35.633255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 4\n",
      "Random seed: 3\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6467, Accuracy: 0.9648, F1 Micro: 0.9733, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5398, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4478, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3936, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3431, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.31, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2886, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2554, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2562, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2399, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 25: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 36.34053421020508 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.0002947527274955064\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 38\n",
      "Sampling duration: 9.910701036453247 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6503, Accuracy: 0.9648, F1 Micro: 0.9733, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5493, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4456, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4051, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.326, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.335, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.305, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2752, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2651, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2387, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 63: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 36.710079193115234 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.0002807081735227259\n",
      "Samples above threshold: 34\n",
      "Acquired samples: 34\n",
      "Sampling duration: 9.06727409362793 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5962, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4198, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3274, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2714, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2381, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2238, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1978, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1884, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1877, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.14, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 97: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 42.71461820602417 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.00012136387376813219\n",
      "Samples above threshold: 31\n",
      "Acquired samples: 31\n",
      "Sampling duration: 8.583097696304321 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6012, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.429, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3256, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2523, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2437, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2069, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1805, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1729, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2107, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1904, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 128: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 43.137507915496826 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.0001120391461881809\n",
      "Samples above threshold: 28\n",
      "Acquired samples: 28\n",
      "Sampling duration: 7.770595073699951 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5451, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3448, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2594, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.222, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1899, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1737, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1776, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1795, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1514, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1431, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 156: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 48.30084419250488 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 8.140557038132103e-05\n",
      "Samples above threshold: 25\n",
      "Acquired samples: 25\n",
      "Sampling duration: 7.224468231201172 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5482, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3538, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2723, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2197, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2183, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1961, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1827, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1848, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2055, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1553, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 181: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 48.75464200973511 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 9.613248839741577e-05\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 22\n",
      "Sampling duration: 6.542664051055908 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5091, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3068, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2175, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1922, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1779, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1596, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1672, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.176, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1623, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1813, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 203: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 53.93681073188782 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 8.397361816605554e-05\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 20\n",
      "Sampling duration: 5.907520294189453 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5075, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2929, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2395, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1986, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1762, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1723, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1678, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1558, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.151, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1412, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 223: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 54.20457744598389 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 8.588729833718391e-05\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 18\n",
      "Sampling duration: 5.357295274734497 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5114, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3053, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2255, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.211, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1928, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1721, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1766, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1683, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1695, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1549, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 241: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 54.334763526916504 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 8.450234890915456e-05\n",
      "Samples above threshold: 16\n",
      "Acquired samples: 9\n",
      "Sampling duration: 5.096691131591797 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5065, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3129, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2319, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2136, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2017, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1879, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1848, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1749, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1613, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1728, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 250: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 55.08729863166809 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 8.373935488634742e-05\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 15\n",
      "Sampling duration: 4.858916521072388 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.48, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2773, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2266, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1951, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.198, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.185, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1686, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.169, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1529, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1655, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 265: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 60.75343370437622 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 8.955619705375285e-05\n",
      "Samples above threshold: 14\n",
      "Acquired samples: 14\n",
      "Sampling duration: 4.472834587097168 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4801, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2745, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2218, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1958, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1748, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1549, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1825, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1645, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1732, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1681, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 279: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.462549686431885 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 8.093499491224065e-05\n",
      "Samples above threshold: 13\n",
      "Acquired samples: 13\n",
      "Sampling duration: 4.576338529586792 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4733, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2714, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2152, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1813, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1865, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1711, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1581, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1597, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1714, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.152, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 292: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.16804099082947 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 8.133691735565662e-05\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 8\n",
      "Sampling duration: 4.285471677780151 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4786, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.275, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2093, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1817, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1763, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1778, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1762, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1541, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1576, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1663, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 300: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.82999134063721 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 9.044033358804885e-05\n",
      "Samples above threshold: 10\n",
      "Acquired samples: 10\n",
      "Sampling duration: 4.001828670501709 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4758, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2703, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2133, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2038, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1724, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1721, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1633, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.168, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1546, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1522, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 310: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 62.37575721740723 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 8.14957711554598e-05\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.6970505714416504 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4779, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2774, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.21, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1828, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1756, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1577, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1622, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1583, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1828, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1649, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 320: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.80694508552551 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 7.550034788437188e-05\n",
      "Samples above threshold: 8\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.440269708633423 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4464, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2515, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1942, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2017, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1862, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1629, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1513, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1612, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1609, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1513, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 330: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.845821380615234 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 8.182173041859643e-05\n",
      "Samples above threshold: 7\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.7913451194763184 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4498, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2615, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2037, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1887, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1704, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.165, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1602, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1467, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.16, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1712, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 340: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.763766050338745 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 9.11609698960092e-05\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.4805800914764404 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4478, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2413, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2052, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1891, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1623, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1732, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1785, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1663, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1544, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1693, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 350: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.53671216964722 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 6.390430353349074e-05\n",
      "Samples above threshold: 5\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.250230312347412 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4516, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.256, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2072, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1747, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1757, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1715, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1521, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.167, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1558, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1693, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 360: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.79363298416138 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 6.170748238218949e-05\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.0520715713500977 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4501, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2415, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2195, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1889, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1736, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1711, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1671, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1531, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1734, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1659, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 370: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 65.31628584861755 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 5.6853565183701e-05\n",
      "Samples above threshold: 3\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.7509942054748535 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4516, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2404, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2077, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1877, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1661, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1713, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1626, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1579, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1494, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1514, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 380: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 64.16980123519897 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 5.7787402693065865e-05\n",
      "Samples above threshold: 2\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.5561976432800293 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.43, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2474, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1954, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1811, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.171, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1628, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1612, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1486, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1591, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1474, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 390: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 68.60252666473389 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.0001797631804947741\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.3639893531799316 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4294, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2282, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1896, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1807, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1764, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.156, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1781, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.157, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.165, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1402, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 400: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 67.7205138206482 s\n",
      "Total sampling time: 109.04 seconds\n",
      "Total runtime: 1556.6066043376923 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACCoAAAHqCAYAAADInz0eAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACJdUlEQVR4nOz9fZjVZbk3/r9nBmYGRdBEhgdRkDSfQVEJLc07lNTb1LuUdrghKkscEmXvFErBbMvULglTErVNkmFSPuUdhts9lmWiJGg7b0U0TNgkoF9zJlEBZ9bvj34uG3mIQVjA8Hodx+c4XNc6r+tzXsM8nE3nXJ+yQqFQCAAAAAAAAABACZRv6wQAAAAAAAAAgJ2HRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJaNRAQAAAAAAAAAoGY0KAAAAAAAAAEDJaFQAAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAYLv2mc98Jr17997WaQAAAABbiEYFgM30ve99L2VlZRk4cOC2TgUAAN6Tm2++OWVlZeu9xo0bV4z7z//8z3zuc5/LoYcemoqKilY3D7y95uc///n1vv/Vr361GPPyyy+/ly0BALATUc8C7HjabesEAHZUM2fOTO/evTNv3rw899xzef/737+tUwIAgPfkyiuvTJ8+fVqMHXroocX/vvXWWzNr1qwceeSR6dGjx2bdo7q6OnfccUe+973vpbKyssV7P/7xj1NdXZ0333yzxfhNN92U5ubmzbofAAA7j+21ngVgXU5UANgMzz//fB5++OFMnjw5e+21V2bOnLmtU1qvVatWbesUAADYgZxyyik599xzW1z9+/cvvj9p0qQ0Njbmt7/9bfr167dZ9/jYxz6WxsbG/OIXv2gx/vDDD+f555/Paaedts6c9u3bp6qqarPu9/eam5v90hgAoA3bXuvZrc3vgYEdkUYFgM0wc+bM7LHHHjnttNPyyU9+cr2NCq+++mouvvji9O7dO1VVVdl7770zfPjwFkd+vfnmm7niiitywAEHpLq6Ot27d8//+T//J3/84x+TJL/61a9SVlaWX/3qVy3W/tOf/pSysrLcfPPNxbHPfOYz6dixY/74xz/m1FNPzW677ZZhw4YlSX7zm9/k7LPPzj777JOqqqr06tUrF198cd5444118l64cGHOOeec7LXXXunQoUM+8IEP5Ktf/WqS5Je//GXKyspy1113rTPv1ltvTVlZWebOndvqjycAADuGHj16pH379u9pjZ49e+b444/Prbfe2mJ85syZOeyww1r8xdvbPvOZz6xzLG9zc3OuueaaHHbYYamurs5ee+2Vj33sY3nssceKMWVlZRk9enRmzpyZQw45JFVVVZkzZ06S5PHHH88pp5ySTp06pWPHjvnoRz+aRx555D3tDQCA7du2qme31O9nk+SKK65IWVlZnnrqqXz605/OHnvskQ996ENJkrfeeitf//rX07dv31RVVaV37975yle+ktWrV7+nPQNsDR79ALAZZs6cmf/zf/5PKisr80//9E+5/vrr87vf/S5HH310kuS1117Lhz/84Tz99NP57Gc/myOPPDIvv/xy7rnnnvzP//xPunTpkqampvzv//2/U19fn0996lMZM2ZM/vrXv+b+++/Pk08+mb59+7Y6r7feeitDhgzJhz70oXz729/OLrvskiT56U9/mtdffz2jRo3KnnvumXnz5uXaa6/N//zP/+SnP/1pcf5///d/58Mf/nDat2+fL3zhC+ndu3f++Mc/5v/+3/+bq666Kh/5yEfSq1evzJw5M2edddY6H5O+fftm0KBB7+EjCwDAttTQ0LDOs3S7dOmyxe/z6U9/OmPGjMlrr72Wjh075q233spPf/rTjB07dpNPPPjc5z6Xm2++Oaeccko+//nP56233spvfvObPPLIIznqqKOKcQ888EB+8pOfZPTo0enSpUt69+6d//f//l8+/OEPp1OnTrnkkkvSvn373HDDDfnIRz6SBx98MAMHDtziewYAYOvbXuvZLfX72b939tlnZ//998+kSZNSKBSSJJ///OczY8aMfPKTn8y//Mu/5NFHH01dXV2efvrp9f7xGcC2pFEBoJXmz5+fhQsX5tprr02SfOhDH8ree++dmTNnFhsVvvWtb+XJJ5/MnXfe2eL/0L/sssuKReMPf/jD1NfXZ/Lkybn44ouLMePGjSvGtNbq1atz9tlnp66ursX4N7/5zXTo0KH4+gtf+ELe//735ytf+UqWLFmSffbZJ0nypS99KYVCIQsWLCiOJck3vvGNJH/7i7Rzzz03kydPTkNDQzp37pwkeemll/Kf//mfLTp7AQDY8QwePHidsc2tTTfmk5/8ZEaPHp2777475557bv7zP/8zL7/8cv7pn/4pP/jBD/7h/F/+8pe5+eabc+GFF+aaa64pjv/Lv/zLOvk+88wz+cMf/pCDDz64OHbWWWdl7dq1eeihh7LffvslSYYPH54PfOADueSSS/Lggw9uoZ0CAFBK22s9u6V+P/v3+vXr1+JUh9///veZMWNGPv/5z+emm25KklxwwQXp2rVrvv3tb+eXv/xlTjzxxC32MQB4rzz6AaCVZs6cmZqammJRV1ZWlqFDh+a2225LU1NTkuSOO+5Iv3791jl14O34t2O6dOmSL33pSxuM2RyjRo1aZ+zvi+BVq1bl5ZdfzrHHHptCoZDHH388yd+aDX7961/ns5/9bIsi+N35DB8+PKtXr87tt99eHJs1a1beeuutnHvuuZudNwAA297UqVNz//33t7i2hj322CMf+9jH8uMf/zjJ3x4jduyxx2bffffdpPl33HFHysrKMnHixHXee3ctfcIJJ7RoUmhqasp//ud/5swzzyw2KSRJ9+7d8+lPfzoPPfRQGhsbN2dbAABsY9trPbslfz/7tvPPP7/F63vvvTdJMnbs2Bbj//Iv/5IkmT17dmu2CLDVOVEBoBWamppy22235cQTT8zzzz9fHB84cGCuvvrq1NfX5+STT84f//jHfOITn9joWn/84x/zgQ98IO3abblvxe3atcvee++9zviSJUsyYcKE3HPPPfnLX/7S4r2GhoYkyeLFi5Nkvc9Q+3sHHnhgjj766MycOTOf+9znkvyteeODH/xg3v/+92+JbQAAsI0cc8wxLR6bsDV9+tOfzj//8z9nyZIlufvuu/Pv//7vmzz3j3/8Y3r06JH3ve99/zC2T58+LV6/9NJLef311/OBD3xgndiDDjoozc3NWbp0aQ455JBNzgcAgO3D9lrPbsnfz77t3XXuCy+8kPLy8nV+R9utW7fsvvvueeGFFzZpXYBS0agA0AoPPPBAXnzxxdx222257bbb1nl/5syZOfnkk7fY/TZ0ssLbJze8W1VVVcrLy9eJPemkk/LKK6/k0ksvzYEHHphdd901y5Yty2c+85k0Nze3Oq/hw4dnzJgx+Z//+Z+sXr06jzzySK677rpWrwMAwM7r4x//eKqqqjJixIisXr0655xzzla5z9//9RoAAGwpm1rPbo3fzyYbrnPfy2m9AKWkUQGgFWbOnJmuXbtm6tSp67x355135q677sq0adPSt2/fPPnkkxtdq2/fvnn00Uezdu3atG/ffr0xe+yxR5Lk1VdfbTHemu7XP/zhD1m0aFFmzJiR4cOHF8fffezZ28fe/qO8k+RTn/pUxo4dmx//+Md544030r59+wwdOnSTcwIAgA4dOuTMM8/Mj370o5xyyinp0qXLJs/t27dv7rvvvrzyyiubdKrC39trr72yyy675JlnnlnnvYULF6a8vDy9evVq1ZoAAOx8NrWe3Rq/n12ffffdN83NzXn22Wdz0EEHFcdXrFiRV199dZMfswZQKuX/OASAJHnjjTdy55135n//7/+dT37yk+tco0ePzl//+tfcc889+cQnPpHf//73ueuuu9ZZp1AoJEk+8YlP5OWXX17vSQRvx+y7776pqKjIr3/96xbvf+9739vkvCsqKlqs+fZ/X3PNNS3i9tprrxx//PGZPn16lixZst583talS5eccsop+dGPfpSZM2fmYx/7WKt+sQwAAEnyr//6r5k4cWIuv/zyVs37xCc+kUKhkK997WvrvPfu2vXdKioqcvLJJ+dnP/tZ/vSnPxXHV6xYkVtvvTUf+tCH0qlTp1blAwDAzmlT6tmt8fvZ9Tn11FOTJFOmTGkxPnny5CTJaaed9g/XACglJyoAbKJ77rknf/3rX/Pxj398ve9/8IMfzF577ZWZM2fm1ltvze23356zzz47n/3sZzNgwIC88sorueeeezJt2rT069cvw4cPzw9/+MOMHTs28+bNy4c//OGsWrUq//Vf/5ULLrggZ5xxRjp37pyzzz471157bcrKytK3b9/8/Oc/z8qVKzc57wMPPDB9+/bNv/7rv2bZsmXp1KlT7rjjjnWehZYk3/3ud/OhD30oRx55ZL7whS+kT58++dOf/pTZs2fniSeeaBE7fPjwfPKTn0ySfP3rX9/0DyQAADus//7v/84999yTJHnuuefS0NCQf/u3f0uS9OvXL6effnqr1uvXr1/69evX6jxOPPHE/PM//3O++93v5tlnn83HPvaxNDc35ze/+U1OPPHEjB49eqPz/+3f/i33339/PvShD+WCCy5Iu3btcsMNN2T16tUbfbYwAAA7tm1Rz26t38+uL5cRI0bkxhtvzKuvvpoTTjgh8+bNy4wZM3LmmWfmxBNPbNXeALY2jQoAm2jmzJmprq7OSSedtN73y8vLc9ppp2XmzJlZvXp1fvOb32TixIm56667MmPGjHTt2jUf/ehHs/feeyf5Wyftvffem6uuuiq33npr7rjjjuy555750Ic+lMMOO6y47rXXXpu1a9dm2rRpqaqqyjnnnJNvfetbOfTQQzcp7/bt2+f//t//mwsvvDB1dXWprq7OWWedldGjR69TRPfr1y+PPPJILr/88lx//fV58803s++++673+Wqnn3569thjjzQ3N2+weQMAgLZlwYIF6/y12NuvR4wY0epf7L4XP/jBD3L44YfnP/7jP/LlL385nTt3zlFHHZVjjz32H8495JBD8pvf/Cbjx49PXV1dmpubM3DgwPzoRz/KwIEDS5A9AADbwraoZ7fW72fX5/vf/37222+/3HzzzbnrrrvSrVu3jB8/PhMnTtzi+wJ4r8oKm3JeDAC8y1tvvZUePXrk9NNPz3/8x39s63QAAAAAAADYQZRv6wQA2DHdfffdeemllzJ8+PBtnQoAAAAAAAA7ECcqANAqjz76aP77v/87X//619OlS5csWLBgW6cEAAAAAADADsSJCgC0yvXXX59Ro0ala9eu+eEPf7it0wEAAAAAAGAH40QFAAAAAAAAAKBknKgAAAAAAAAAAJSMRgUAAAAAAAAAoGTabesEtpTm5ub8+c9/zm677ZaysrJtnQ4AAFtRoVDIX//61/To0SPl5W2v91ZtCwCw81DbAgDQVrSmtm0zjQp//vOf06tXr22dBgAAJbR06dLsvffe2zqNLU5tCwCw81HbAgDQVmxKbdtmGhV22223JH/bdKdOnbZxNgAAbE2NjY3p1atXsQZsa9S2AAA7D7UtAABtRWtq2zbTqPD2sWGdOnVS8AIA7CTa6tGxalsAgJ2P2hYAgLZiU2rbtvfQMwAAAAAAAABgu6VRAQAAAAAAAAAoGY0KAAAAAAAAAEDJaFQAAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAAAAAAKBkNCoAAAAAAAAAACWjUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAAAAAAAAQMloVAAAAAAAAAAASkajAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAHZav/71r3P66aenR48eKSsry9133/0P5/zqV7/KkUcemaqqqrz//e/PzTff3OL9urq6HH300dltt93StWvXnHnmmXnmmWe2zgYAAAAAAHZAGhUAANhprVq1Kv369cvUqVM3Kf7555/PaaedlhNPPDFPPPFELrroonz+85/PfffdV4x58MEHU1tbm0ceeST3339/1q5dm5NPPjmrVq3aWtsAAAAAANihtNvWCQAAwLZyyimn5JRTTtnk+GnTpqVPnz65+uqrkyQHHXRQHnrooXznO9/JkCFDkiRz5sxpMefmm29O165dM3/+/Bx//PFbLnkAAAAAgB2UExUAAGATzZ07N4MHD24xNmTIkMydO3eDcxoaGpIk73vf+zYYs3r16jQ2Nra4AAAAAADaKo0KAACwiZYvX56ampoWYzU1NWlsbMwbb7yxTnxzc3MuuuiiHHfccTn00EM3uG5dXV06d+5cvHr16rXFcwcAAAAA2F5oVAAAgK2ktrY2Tz75ZG677baNxo0fPz4NDQ3Fa+nSpSXKEAAAAACg9Npt6wQAAGBH0a1bt6xYsaLF2IoVK9KpU6d06NChxfjo0aPz85//PL/+9a+z9957b3TdqqqqVFVVbfF8AQAAAAC2R05UAACATTRo0KDU19e3GLv//vszaNCg4utCoZDRo0fnrrvuygMPPJA+ffqUOk0AAAAAgO2aRgUAAHZar732Wp544ok88cQTSZLnn38+TzzxRJYsWZLkb49kGD58eDH+/PPPz+LFi3PJJZdk4cKF+d73vpef/OQnufjii4sxtbW1+dGPfpRbb701u+22W5YvX57ly5fnjTfeKOneAAAAAAC2VxoVAADYaT322GM54ogjcsQRRyRJxo4dmyOOOCITJkxIkrz44ovFpoUk6dOnT2bPnp37778//fr1y9VXX53vf//7GTJkSDHm+uuvT0NDQz7ykY+ke/fuxWvWrFml3RwAAAAAwHaq3bZOAAAAtpWPfOQjKRQKG3z/5ptvXu+cxx9/fINzNrYeAAAAAABOVAAAAAAAAAAASkijAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJaNRAQAAAAAAAAAoGY0KAAAAAAAAAEDJaFQAAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAAIA2YOrUqendu3eqq6szcODAzJs3b6Pxr776ampra9O9e/dUVVXlgAMOyL333lt8v6mpKZdffnn69OmTDh06pG/fvvn617+eQqGwtbcCAEAb125bJwAAAAAAwHsza9asjB07NtOmTcvAgQMzZcqUDBkyJM8880y6du26TvyaNWty0kknpWvXrrn99tvTs2fPvPDCC9l9992LMd/85jdz/fXXZ8aMGTnkkEPy2GOPZeTIkencuXMuvPDCEu4OAIC2RqMCAAAAAMAObvLkyTnvvPMycuTIJMm0adMye/bsTJ8+PePGjVsnfvr06XnllVfy8MMPp3379kmS3r17t4h5+OGHc8YZZ+S0004rvv/jH//4H57UAAAA/4hHPwAAAAAA7MDWrFmT+fPnZ/DgwcWx8vLyDB48OHPnzl3vnHvuuSeDBg1KbW1tampqcuihh2bSpElpamoqxhx77LGpr6/PokWLkiS///3v89BDD+WUU07ZYC6rV69OY2NjiwsAAN7NiQoAAAAAADuwl19+OU1NTampqWkxXlNTk4ULF653zuLFi/PAAw9k2LBhuffee/Pcc8/lggsuyNq1azNx4sQkybhx49LY2JgDDzwwFRUVaWpqylVXXZVhw4ZtMJe6urp87Wtf23KbAwCgTXKiAgAAAADATqa5uTldu3bNjTfemAEDBmTo0KH56le/mmnTphVjfvKTn2TmzJm59dZbs2DBgsyYMSPf/va3M2PGjA2uO378+DQ0NBSvpUuXlmI7AADsYJyoAAAAAACwA+vSpUsqKiqyYsWKFuMrVqxIt27d1june/fuad++fSoqKopjBx10UJYvX541a9aksrIyX/7ylzNu3Lh86lOfSpIcdthheeGFF1JXV5cRI0asd92qqqpUVVVtoZ0BANBWOVEBAAAAAGAHVllZmQEDBqS+vr441tzcnPr6+gwaNGi9c4477rg899xzaW5uLo4tWrQo3bt3T2VlZZLk9ddfT3l5y18hV1RUtJgDAACbQ6MCAAAAAMAObuzYsbnpppsyY8aMPP300xk1alRWrVqVkSNHJkmGDx+e8ePHF+NHjRqVV155JWPGjMmiRYsye/bsTJo0KbW1tcWY008/PVdddVVmz56dP/3pT7nrrrsyefLknHXWWSXfHwAAbYtHPwAAAAAA7OCGDh2al156KRMmTMjy5cvTv3//zJkzJzU1NUmSJUuWtDgdoVevXrnvvvty8cUX5/DDD0/Pnj0zZsyYXHrppcWYa6+9NpdffnkuuOCCrFy5Mj169MgXv/jFTJgwoeT7AwCgbSkrFAqFbZ3EltDY2JjOnTunoaEhnTp12tbpAACwFbX12q+t7w8AgHe09dqvre8PAIB3tKb28+gHAAAAAAAAAKBkNCoAAAAAAAAAACWjUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZFrdqPDrX/86p59+enr06JGysrLcfffd/3DOr371qxx55JGpqqrK+9///tx8883rxEydOjW9e/dOdXV1Bg4cmHnz5rU2NQAAAAAAAABgO9fqRoVVq1alX79+mTp16ibFP//88znttNNy4okn5oknnshFF12Uz3/+87nvvvuKMbNmzcrYsWMzceLELFiwIP369cuQIUOycuXK1qYHAAAAAAAAAGzH2rV2wimnnJJTTjllk+OnTZuWPn365Oqrr06SHHTQQXnooYfyne98J0OGDEmSTJ48Oeedd15GjhxZnDN79uxMnz4948aNa22KAAAAAAAAAMB2qtUnKrTW3LlzM3jw4BZjQ4YMydy5c5Mka9asyfz581vElJeXZ/DgwcUYAAAAAAAAAKBtaPWJCq21fPny1NTUtBirqalJY2Nj3njjjfzlL39JU1PTemMWLly4wXVXr16d1atXF183NjZu2cQBAAAAAAAAgC1uq5+osLXU1dWlc+fOxatXr17bOiUAAAAAAAAA4B/Y6o0K3bp1y4oVK1qMrVixIp06dUqHDh3SpUuXVFRUrDemW7duG1x3/PjxaWhoKF5Lly7dKvkDAAAAAAAAAFvOVm9UGDRoUOrr61uM3X///Rk0aFCSpLKyMgMGDGgR09zcnPr6+mLM+lRVVaVTp04tLgAAAAAAAABg+9bqRoXXXnstTzzxRJ544okkyfPPP58nnngiS5YsSfK3kw6GDx9ejD///POzePHiXHLJJVm4cGG+973v5Sc/+UkuvvjiYszYsWNz0003ZcaMGXn66aczatSorFq1KiNHjnyP2wMAAAAAAAAAtiftWjvhsccey4knnlh8PXbs2CTJiBEjcvPNN+fFF18sNi0kSZ8+fTJ79uxcfPHFueaaa7L33nvn+9//foYMGVKMGTp0aF566aVMmDAhy5cvT//+/TNnzpzU1NS8l70BAAAAAAAAANuZskKhUNjWSWwJjY2N6dy5cxoaGjwGAgCgjWvrtV9b3x8AAO9o67VfW98fAADvaE3t1+pHPwAAAAAAAAAAbC6NCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAAAAAAAAQMloVAAAAAAAAAAASkajAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJaNRAQAAAAAAAAAoGY0KAAAAAAAAAEDJaFQAAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAADATuvXv/51Tj/99PTo0SNlZWW5++67/+GcX/3qVznyyCNTVVWV97///bn55pvXiZk6dWp69+6d6urqDBw4MPPmzdvyyQMAAAAA7KA0KgAAsNNatWpV+vXrl6lTp25S/PPPP5/TTjstJ554Yp544olcdNFF+fznP5/77ruvGDNr1qyMHTs2EydOzIIFC9KvX78MGTIkK1eu3FrbAAAAAADYobTb1gkAAMC2csopp+SUU07Z5Php06alT58+ufrqq5MkBx10UB566KF85zvfyZAhQ5IkkydPznnnnZeRI0cW58yePTvTp0/PuHHjtvwmAAAAAAB2ME5UAACATTR37twMHjy4xdiQIUMyd+7cJMmaNWsyf/78FjHl5eUZPHhwMQYAAAAAYGenUQEAADbR8uXLU1NT02KspqYmjY2NeeONN/Lyyy+nqalpvTHLly/f4LqrV69OY2NjiwsAAFpr6tSp6d27d6qrqzNw4MDMmzdvo/Gvvvpqamtr071791RVVeWAAw7IvffeW3y/d+/eKSsrW+eqra3d2lsBAKCN06gAAADbWF1dXTp37ly8evXqta1TAgBgBzNr1qyMHTs2EydOzIIFC9KvX78MGTIkK1euXG/8mjVrctJJJ+VPf/pTbr/99jzzzDO56aab0rNnz2LM7373u7z44ovF6/7770+SnH322SXZEwAAbVe7bZ0AAADsKLp165YVK1a0GFuxYkU6deqUDh06pKKiIhUVFeuN6dat2wbXHT9+fMaOHVt83djYqFkBAIBWmTx5cs4777yMHDkySTJt2rTMnj0706dPz7hx49aJnz59el555ZU8/PDDad++fZK/naDw9/baa68Wr7/xjW+kb9++OeGEE7bOJgAA2Gk4UQEAADbRoEGDUl9f32Ls/vvvz6BBg5IklZWVGTBgQIuY5ubm1NfXF2PWp6qqKp06dWpxAQDAplqzZk3mz5+fwYMHF8fKy8szePDgzJ07d71z7rnnngwaNCi1tbWpqanJoYcemkmTJqWpqWmD9/jRj36Uz372sykrK9sq+wAAYOfhRAUAAHZar732Wp577rni6+effz5PPPFE3ve+92WfffbJ+PHjs2zZsvzwhz9Mkpx//vm57rrrcskll+Szn/1sHnjggfzkJz/J7Nmzi2uMHTs2I0aMyFFHHZVjjjkmU6ZMyapVq4p/2QYAAFvayy+/nKamptTU1LQYr6mpycKFC9c7Z/HixXnggQcybNiw3HvvvXnuuedywQUXZO3atZk4ceI68XfffXdeffXVfOYzn9loLqtXr87q1auLrxsbG1u/IQAA2jyNCgAA7LQee+yxnHjiicXXbz9+YcSIEbn55pvz4osvZsmSJcX3+/Tpk9mzZ+fiiy/ONddck7333jvf//73M2TIkGLM0KFD89JLL2XChAlZvnx5+vfvnzlz5qzzS2MAANiWmpub07Vr19x4442pqKjIgAEDsmzZsnzrW99ab6PCf/zHf+SUU05Jjx49NrpuXV1dvva1r22ttAEAaCM0KgAAsNP6yEc+kkKhsMH3b7755vXOefzxxze67ujRozN69Oj3mh4AAGySLl26pKKiIitWrGgxvmLFinTr1m29c7p375727dunoqKiOHbQQQdl+fLlWbNmTSorK4vjL7zwQv7rv/4rd9555z/MZfz48cUG4ORvJyr06tWrtVsCAKCNK9/WCQAAAAAAsPkqKyszYMCA1NfXF8eam5tTX1+fQYMGrXfOcccdl+eeey7Nzc3FsUWLFqV79+4tmhSS5Ac/+EG6du2a00477R/mUlVVlU6dOrW4AADg3TQqAAAAAADs4MaOHZubbropM2bMyNNPP51Ro0Zl1apVGTlyZJJk+PDhGT9+fDF+1KhReeWVVzJmzJgsWrQos2fPzqRJk1JbW9ti3ebm5vzgBz/IiBEj0q6dA3oBANgyVJYAAAAAADu4oUOH5qWXXsqECROyfPny9O/fP3PmzElNTU2SZMmSJSkvf+fv1nr16pX77rsvF198cQ4//PD07NkzY8aMyaWXXtpi3f/6r//KkiVL8tnPfrak+wEAoG0rK2zsobw7kMbGxnTu3DkNDQ2OEwMAaOPaeu3X1vcHAMA72nrt19b3BwDAO1pT+3n0AwAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJaNRAQAAAAAAAAAoGY0KAAAAAAAAAEDJaFQAAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAAAAAAKBkNCoAAAAAAAAAACWjUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAAAAAAAAQMloVAAAAAAAAAAASkajAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJbNZjQpTp05N7969U11dnYEDB2bevHkbjF27dm2uvPLK9O3bN9XV1enXr1/mzJnTIqapqSmXX355+vTpkw4dOqRv3775+te/nkKhsDnpAQAAAAAAAADbqVY3KsyaNStjx47NxIkTs2DBgvTr1y9DhgzJypUr1xt/2WWX5YYbbsi1116bp556Kueff37OOuusPP7448WYb37zm7n++utz3XXX5emnn843v/nN/Pu//3uuvfbazd8ZAAAAAAAAALDdaXWjwuTJk3Peeedl5MiROfjggzNt2rTssssumT59+nrjb7nllnzlK1/Jqaeemv322y+jRo3KqaeemquvvroY8/DDD+eMM87Iaaedlt69e+eTn/xkTj755I2e1AAAAAAAAAAA7Hha1aiwZs2azJ8/P4MHD35ngfLyDB48OHPnzl3vnNWrV6e6urrFWIcOHfLQQw8VXx977LGpr6/PokWLkiS///3v89BDD+WUU05pTXoAAAAAAAAAwHauXWuCX3755TQ1NaWmpqbFeE1NTRYuXLjeOUOGDMnkyZNz/PHHp2/fvqmvr8+dd96ZpqamYsy4cePS2NiYAw88MBUVFWlqaspVV12VYcOGbTCX1atXZ/Xq1cXXjY2NrdkKAAAAAAAAALANtPrRD611zTXXZP/998+BBx6YysrKjB49OiNHjkx5+Tu3/slPfpKZM2fm1ltvzYIFCzJjxox8+9vfzowZMza4bl1dXTp37ly8evXqtbW3AgAAAAAAAAC8R61qVOjSpUsqKiqyYsWKFuMrVqxIt27d1jtnr732yt13351Vq1blhRdeyMKFC9OxY8fst99+xZgvf/nLGTduXD71qU/lsMMOyz//8z/n4osvTl1d3QZzGT9+fBoaGorX0qVLW7MVAAAAAAAAAGAbaFWjQmVlZQYMGJD6+vriWHNzc+rr6zNo0KCNzq2urk7Pnj3z1ltv5Y477sgZZ5xRfO/1119vccJCklRUVKS5uXmD61VVVaVTp04tLgAAAAAAAABg+9autRPGjh2bESNG5KijjsoxxxyTKVOmZNWqVRk5cmSSZPjw4enZs2fxNIRHH300y5YtS//+/bNs2bJcccUVaW5uziWXXFJc8/TTT89VV12VffbZJ4ccckgef/zxTJ48OZ/97Ge30DYBAAAAAAAAgO1BqxsVhg4dmpdeeikTJkzI8uXL079//8yZMyc1NTVJkiVLlrQ4HeHNN9/MZZddlsWLF6djx4459dRTc8stt2T33Xcvxlx77bW5/PLLc8EFF2TlypXp0aNHvvjFL2bChAnvfYcAAAAAAAAAwHajrFAoFLZ1EltCY2NjOnfunIaGBo+BAABo49p67dfW9wcAwDvaeu3X1vcHAMA7WlP7lW/0XQAAAAAAAACALUijAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAtAFTp05N7969U11dnYEDB2bevHkbjX/11VdTW1ub7t27p6qqKgcccEDuvffeFjHLli3Lueeemz333DMdOnTIYYcdlscee2xrbgMAgJ1Au22dAAAAAAAA782sWbMyduzYTJs2LQMHDsyUKVMyZMiQPPPMM+nates68WvWrMlJJ52Url275vbbb0/Pnj3zwgsvZPfddy/G/OUvf8lxxx2XE088Mb/4xS+y11575dlnn80ee+xRwp0BANAWaVQAAAAAANjBTZ48Oeedd15GjhyZJJk2bVpmz56d6dOnZ9y4cevET58+Pa+88koefvjhtG/fPknSu3fvFjHf/OY306tXr/zgBz8ojvXp02frbQIAgJ2GRz8AAAAAAOzA1qxZk/nz52fw4MHFsfLy8gwePDhz585d75x77rkngwYNSm1tbWpqanLooYdm0qRJaWpqahFz1FFH5eyzz07Xrl1zxBFH5Kabbtrq+wEAoO3TqAAAAAAAsAN7+eWX09TUlJqamhbjNTU1Wb58+XrnLF68OLfffnuamppy77335vLLL8/VV1+df/u3f2sRc/3112f//ffPfffdl1GjRuXCCy/MjBkzNpjL6tWr09jY2OICAIB38+gHAAAAAICdTHNzc7p27Zobb7wxFRUVGTBgQJYtW5ZvfetbmThxYjHmqKOOyqRJk5IkRxxxRJ588slMmzYtI0aMWO+6dXV1+drXvlayfQAAsGNyogIAAAAAwA6sS5cuqaioyIoVK1qMr1ixIt26dVvvnO7du+eAAw5IRUVFceyggw7K8uXLs2bNmmLMwQcf3GLeQQcdlCVLlmwwl/Hjx6ehoaF4LV26dHO3BQBAG6ZRAQAAAABgB1ZZWZkBAwakvr6+ONbc3Jz6+voMGjRovXOOO+64PPfcc2lubi6OLVq0KN27d09lZWUx5plnnmkxb9GiRdl33303mEtVVVU6derU4gIAgHfTqAAAAAAAsIMbO3ZsbrrppsyYMSNPP/10Ro0alVWrVmXkyJFJkuHDh2f8+PHF+FGjRuWVV17JmDFjsmjRosyePTuTJk1KbW1tMebiiy/OI488kkmTJuW5557LrbfemhtvvLFFDAAAbI522zoBAAAAAADem6FDh+all17KhAkTsnz58vTv3z9z5sxJTU1NkmTJkiUpL3/n79Z69eqV++67LxdffHEOP/zw9OzZM2PGjMmll15ajDn66KNz1113Zfz48bnyyivTp0+fTJkyJcOGDSv5/gAAaFvKCoVCYVsnsSU0Njamc+fOaWhocJwYAEAb19Zrv7a+PwAA3tHWa7+2vj8AAN7RmtrPox8AAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAOzUpk6dmt69e6e6ujoDBw7MvHnzNhi7du3aXHnllenbt2+qq6vTr1+/zJkzp0VMU1NTLr/88vTp0ycdOnRI37598/Wvfz2FQmFrbwUAAAAAYIegUQEAgJ3WrFmzMnbs2EycODELFixIv379MmTIkKxcuXK98ZdddlluuOGGXHvttXnqqady/vnn56yzzsrjjz9ejPnmN7+Z66+/Ptddd12efvrpfPOb38y///u/59prry3VtgAAAAAAtmsaFQAA2GlNnjw55513XkaOHJmDDz4406ZNyy677JLp06evN/6WW27JV77ylZx66qnZb7/9MmrUqJx66qm5+uqrizEPP/xwzjjjjJx22mnp3bt3PvnJT+bkk0/e6EkNAAAAAAA7E40KAADslNasWZP58+dn8ODBxbHy8vIMHjw4c+fOXe+c1atXp7q6usVYhw4d8tBDDxVfH3vssamvr8+iRYuSJL///e/z0EMP5ZRTTtlgLqtXr05jY2OLCwAAAACgrWq3rRMAAIBt4eWXX05TU1NqampajNfU1GThwoXrnTNkyJBMnjw5xx9/fPr27Zv6+vrceeedaWpqKsaMGzcujY2NOfDAA1NRUZGmpqZcddVVGTZs2AZzqaury9e+9rUtszEAAAAAgO2cExUAAGATXXPNNdl///1z4IEHprKyMqNHj87IkSNTXv5OWf2Tn/wkM2fOzK233poFCxZkxowZ+fa3v50ZM2ZscN3x48enoaGheC1durQU2wEAAAAA2CacqAAAwE6pS5cuqaioyIoVK1qMr1ixIt26dVvvnL322it333133nzzzfx//9//lx49emTcuHHZb7/9ijFf/vKXM27cuHzqU59Kkhx22GF54YUXUldXlxEjRqx33aqqqlRVVW2hnQEAAAAAbN+cqAAAwE6psrIyAwYMSH19fXGsubk59fX1GTRo0EbnVldXp2fPnnnrrbdyxx135Iwzzii+9/rrr7c4YSFJKioq0tzcvGU3AAAAAACwg3KiAgAAO62xY8dmxIgROeqoo3LMMcdkypQpWbVqVUaOHJkkGT58eHr27Jm6urokyaOPPpply5alf//+WbZsWa644oo0NzfnkksuKa55+umn56qrrso+++yTQw45JI8//ngmT56cz372s9tkjwAAAAAA2xuNCgAA7LSGDh2al156KRMmTMjy5cvTv3//zJkzJzU1NUmSJUuWtDgd4c0338xll12WxYsXp2PHjjn11FNzyy23ZPfddy/GXHvttbn88stzwQUXZOXKlenRo0e++MUvZsKECaXeHgAAAADAdqmsUCgUtnUSW0JjY2M6d+6choaGdOrUaVunAwDAVtTWa7+2vj8AAN7R1mu/tr4/AADe0Zrar3yj7wIAAAAAAAAAbEEaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAAAAAAKBkNCoAAAAAAAAAACWjUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAl025bJ7CjKhSS11/f1lkAAGw/dtklKSvb1lmwWQqFpElxCwBQVKG43VEVCoW8vlZtCwDwtl3a75Ky7bC21aiwmV5/PenYcVtnAQCw/XjttWTXXbd1FmyWpteTnyhuAQCKznktaae43RG9vvb1dKxT2wIAvO218a9l18rtr7b16AcAAAAAAAAAoGScqLCZdtnlb381CADA3+yyy7bOgM1Wscvf/moQAIC/qVDc7qh2ab9LXhuvtgUAeNsu7bfP2lajwmYqK3O0MQAAbURZmaONAQBoE8rKyrbLo40BAGjJox8AAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAAAAAAAAQMloVAAAAAAAAAAASkajAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJaNRAQAAAACgDZg6dWp69+6d6urqDBw4MPPmzdto/Kuvvpra2tp07949VVVVOeCAA3LvvfcW37/iiitSVlbW4jrwwAO39jYAANgJtNvWCQAAAAAA8N7MmjUrY8eOzbRp0zJw4MBMmTIlQ4YMyTPPPJOuXbuuE79mzZqcdNJJ6dq1a26//fb07NkzL7zwQnbfffcWcYccckj+67/+q/i6XTu/UgYA4L1TVQIAAAAA7OAmT56c8847LyNHjkySTJs2LbNnz8706dMzbty4deKnT5+eV155JQ8//HDat2+fJOndu/c6ce3atUu3bt22au4AAOx8NuvRD605Qmzt2rW58sor07dv31RXV6dfv36ZM2fOOnHLli3Lueeemz333DMdOnTIYYcdlscee2xz0gMAAAAA2GmsWbMm8+fPz+DBg4tj5eXlGTx4cObOnbveOffcc08GDRqU2tra1NTU5NBDD82kSZPS1NTUIu7ZZ59Njx49st9++2XYsGFZsmTJRnNZvXp1GhsbW1wAAPBurW5UePsIsYkTJ2bBggXp169fhgwZkpUrV643/rLLLssNN9yQa6+9Nk899VTOP//8nHXWWXn88ceLMX/5y19y3HHHpX379vnFL36Rp556KldffXX22GOPzd8ZAAAAAMBO4OWXX05TU1NqampajNfU1GT58uXrnbN48eLcfvvtaWpqyr333pvLL788V199df7t3/6tGDNw4MDcfPPNmTNnTq6//vo8//zz+fCHP5y//vWvG8ylrq4unTt3Ll69evXaMpsEAKBNKSsUCoXWTBg4cGCOPvroXHfddUmS5ubm9OrVK1/60pfWe4RYjx498tWvfjW1tbXFsU984hPp0KFDfvSjHyVJxo0bl9/+9rf5zW9+s9kbaWxsTOfOndPQ0JBOnTpt9joAAGz/2nrt19b3BwDAO7ZE7ffnP/85PXv2zMMPP5xBgwYVxy+55JI8+OCDefTRR9eZc8ABB+TNN9/M888/n4qKiiR/e3zEt771rbz44ovrvc+rr76afffdN5MnT87nPve59casXr06q1evbrG/Xr16qW0BAHYCraltW3WiwuYcIbZ69epUV1e3GOvQoUMeeuih4ut77rknRx11VM4+++x07do1RxxxRG666abWpAYAAAAAsFPq0qVLKioqsmLFihbjK1asSLdu3dY7p3v37jnggAOKTQpJctBBB2X58uVZs2bNeufsvvvuOeCAA/Lcc89tMJeqqqp06tSpxQUAAO/WqkaFzTlCbMiQIZk8eXKeffbZNDc35/7778+dd97Zoit38eLFuf7667P//vvnvvvuy6hRo3LhhRdmxowZG8zFs84AAAAAAJLKysoMGDAg9fX1xbHm5ubU19e3OGHh7x133HF57rnn0tzcXBxbtGhRunfvnsrKyvXOee211/LHP/4x3bt337IbAABgp9OqRoXNcc0112T//ffPgQcemMrKyowePTojR45Mefk7t25ubs6RRx6ZSZMm5YgjjsgXvvCFnHfeeZk2bdoG1/WsMwAAAACAvxk7dmxuuummzJgxI08//XRGjRqVVatWZeTIkUmS4cOHZ/z48cX4UaNG5ZVXXsmYMWOyaNGizJ49O5MmTWrxCN9//dd/zYMPPpg//elPefjhh3PWWWeloqIi//RP/1Ty/QEA0La0qlFhc44Q22uvvXL33Xdn1apVeeGFF7Jw4cJ07Ngx++23XzGme/fuOfjgg1vMO+igg7JkyZIN5jJ+/Pg0NDQUr6VLl7ZmKwAAAAAAbcbQoUPz7W9/OxMmTEj//v3zxBNPZM6cOcXTcZcsWdLilNtevXrlvvvuy+9+97scfvjhufDCCzNmzJiMGzeuGPM///M/+ad/+qd84AMfyDnnnJM999wzjzzySPbaa6+S7w8AgLalXWuC//4IsTPPPDPJO0eIjR49eqNzq6ur07Nnz6xduzZ33HFHzjnnnOJ7xx13XJ555pkW8YsWLcq+++67wfWqqqpSVVXVmvQBAAAAANqs0aNHb/D3tL/61a/WGRs0aFAeeeSRDa532223banUAACghVY1KiR/O0JsxIgROeqoo3LMMcdkypQp6xwh1rNnz9TV1SVJHn300Sxbtiz9+/fPsmXLcsUVV6S5uTmXXHJJcc2LL744xx57bCZNmpRzzjkn8+bNy4033pgbb7xxC20TAAAAAAAAANgetLpRYejQoXnppZcyYcKELF++PP3791/nCLHy8neeKPHmm2/msssuy+LFi9OxY8eceuqpueWWW7L77rsXY44++ujcddddGT9+fK688sr06dMnU6ZMybBhw977DgEAAAAAAACA7UZZoVAobOsktoTGxsZ07tw5DQ0N6dSp07ZOBwCArait135tfX8AALyjrdd+bX1/AAC8ozW1X/lG3wUAAAAAAAAA2II0KgAAAAAAAAAAJaNRAQAAAAAAAAAoGY0KAAAAAAAAAEDJaFQAAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAAAAAAKBkNCoAAAAAAAAAACWjUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAAAAAAAAQMloVAAAYKc2derU9O7dO9XV1Rk4cGDmzZu3wdi1a9fmyiuvTN++fVNdXZ1+/fplzpw568QtW7Ys5557bvbcc8906NAhhx12WB577LGtuQ0AAAAAgB2GRgUAAHZas2bNytixYzNx4sQsWLAg/fr1y5AhQ7Jy5cr1xl922WW54YYbcu211+app57K+eefn7POOiuPP/54MeYvf/lLjjvuuLRv3z6/+MUv8tRTT+Xqq6/OHnvsUaptAQAAAABs18oKhUJhWyexJTQ2NqZz585paGhIp06dtnU6AABsRVuq9hs4cGCOPvroXHfddUmS5ubm9OrVK1/60pcybty4deJ79OiRr371q6mtrS2OfeITn0iHDh3yox/9KEkybty4/Pa3v81vfvObzc5LbQsAsPNo67VfW98fAADvaE3t50QFAAB2SmvWrMn8+fMzePDg4lh5eXkGDx6cuXPnrnfO6tWrU11d3WKsQ4cOeeihh4qv77nnnhx11FE5++yz07Vr1xxxxBG56aabts4mAAAAAAB2QBoVAADYKb388stpampKTU1Ni/GamposX758vXOGDBmSyZMn59lnn01zc3Puv//+3HnnnXnxxReLMYsXL87111+f/fffP/fdd19GjRqVCy+8MDNmzNhgLqtXr05jY2OLCwAAAACgrdKoAAAAm+iaa67J/vvvnwMPPDCVlZUZPXp0Ro4cmfLyd8rq5ubmHHnkkZk0aVKOOOKIfOELX8h5552XadOmbXDdurq6dO7cuXj16tWrFNsBAAAAANgmNCoAALBT6tKlSyoqKrJixYoW4ytWrEi3bt3WO2evvfbK3XffnVWrVuWFF17IwoUL07Fjx+y3337FmO7du+fggw9uMe+ggw7KkiVLNpjL+PHj09DQULyWLl36HnYGAAAAALB906gAAMBOqbKyMgMGDEh9fX1xrLm5OfX19Rk0aNBG51ZXV6dnz5556623cscdd+SMM84ovnfcccflmWeeaRG/aNGi7Lvvvhtcr6qqKp06dWpxAQAAAAC0Ve22dQIAALCtjB07NiNGjMhRRx2VY445JlOmTMmqVasycuTIJMnw4cPTs2fP1NXVJUkeffTRLFu2LP3798+yZctyxRVXpLm5OZdccklxzYsvvjjHHntsJk2alHPOOSfz5s3LjTfemBtvvHGb7BEAAAAAYHujUQEAgJ3W0KFD89JLL2XChAlZvnx5+vfvnzlz5qSmpiZJsmTJkpSXv3MI2ZtvvpnLLrssixcvTseOHXPqqafmlltuye67716MOfroo3PXXXdl/PjxufLKK9OnT59MmTIlw4YNK/X2AAAAAAC2S2WFQqGwrZPYEhobG9O5c+c0NDQ4KhcAoI1r67VfW98fAADvaOu1X1vfHwAA72hN7Ve+0XcBAAAAAAAAALYgjQoAAAAAAAAAQMloVAAAAAAAAAAASkajAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJaNRAQAAAAAAAAAoGY0KAAAAAAAAAEDJaFQAAAAAAAAAAEpGowIAAAAAQBswderU9O7dO9XV1Rk4cGDmzZu30fhXX301tbW16d69e6qqqnLAAQfk3nvvXW/sN77xjZSVleWiiy7aCpkDALCzabetEwAAAAAA4L2ZNWtWxo4dm2nTpmXgwIGZMmVKhgwZkmeeeSZdu3ZdJ37NmjU56aST0rVr19x+++3p2bNnXnjhhey+++7rxP7ud7/LDTfckMMPP7wEOwEAYGfgRAUAAAAAgB3c5MmTc95552XkyJE5+OCDM23atOyyyy6ZPn36euOnT5+eV155JXfffXeOO+649O7dOyeccEL69evXIu61117LsGHDctNNN2WPPfYoxVYAANgJaFQAAAAAANiBrVmzJvPnz8/gwYOLY+Xl5Rk8eHDmzp273jn33HNPBg0alNra2tTU1OTQQw/NpEmT0tTU1CKutrY2p512Wou1N2b16tVpbGxscQEAwLt59AMAAAAAwA7s5ZdfTlNTU2pqalqM19TUZOHCheuds3jx4jzwwAMZNmxY7r333jz33HO54IILsnbt2kycODFJctttt2XBggX53e9+t8m51NXV5Wtf+9rmbwYAgJ2CExUAAAAAAHYyzc3N6dq1a2688cYMGDAgQ4cOzVe/+tVMmzYtSbJ06dKMGTMmM2fOTHV19SavO378+DQ0NBSvpUuXbq0tAACwA3OiAgAAAADADqxLly6pqKjIihUrWoyvWLEi3bp1W++c7t27p3379qmoqCiOHXTQQVm+fHnxURIrV67MkUceWXy/qakpv/71r3Pddddl9erVLea+raqqKlVVVVtoZwAAtFVOVAAAAAAA2IFVVlZmwIABqa+vL441Nzenvr4+gwYNWu+c4447Ls8991yam5uLY4sWLUr37t1TWVmZj370o/nDH/6QJ554ongdddRRGTZsWJ544on1NikAAMCmcqICAAAAAMAObuzYsRkxYkSOOuqoHHPMMZkyZUpWrVqVkSNHJkmGDx+enj17pq6uLkkyatSoXHfddRkzZky+9KUv5dlnn82kSZNy4YUXJkl22223HHrooS3useuuu2bPPfdcZxwAAFpLowIAAAAAwA5u6NCheemllzJhwoQsX748/fv3z5w5c1JTU5MkWbJkScrL3zlgt1evXrnvvvty8cUX5/DDD0/Pnj0zZsyYXHrppdtqCwAA7ETKCoVCYVsnsSU0Njamc+fOaWhoSKdOnbZ1OgAAbEVtvfZr6/sDAOAdbb32a+v7AwDgHa2p/co3+i4AAAAAAAAAwBakUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAAAAAAAAQMloVAAAAAAAAAAASkajAgAAAAAAAABQMpvVqDB16tT07t071dXVGThwYObNm7fB2LVr1+bKK69M3759U11dnX79+mXOnDkbjP/GN76RsrKyXHTRRZuTGgAAAAAAAACwHWt1o8KsWbMyduzYTJw4MQsWLEi/fv0yZMiQrFy5cr3xl112WW644YZce+21eeqpp3L++efnrLPOyuOPP75O7O9+97vccMMNOfzww1u/EwAAAAAAAABgu9fqRoXJkyfnvPPOy8iRI3PwwQdn2rRp2WWXXTJ9+vT1xt9yyy35yle+klNPPTX77bdfRo0alVNPPTVXX311i7jXXnstw4YNy0033ZQ99thj83YDAAAAAAAAAGzXWtWosGbNmsyfPz+DBw9+Z4Hy8gwePDhz585d75zVq1enurq6xViHDh3y0EMPtRirra3Naaed1mLtjVm9enUaGxtbXAAAAAAAAADA9q1VjQovv/xympqaUlNT02K8pqYmy5cvX++cIUOGZPLkyXn22WfT3Nyc+++/P3feeWdefPHFYsxtt92WBQsWpK6ubpNzqaurS+fOnYtXr169WrMVAAAAAAAAAGAbaPWjH1rrmmuuyf77758DDzwwlZWVGT16dEaOHJny8r/deunSpRkzZkxmzpy5zskLGzN+/Pg0NDQUr6VLl26tLQAAAAAAAAAAW0irGhW6dOmSioqKrFixosX4ihUr0q1bt/XO2WuvvXL33Xdn1apVeeGFF7Jw4cJ07Ngx++23X5Jk/vz5WblyZY488si0a9cu7dq1y4MPPpjvfve7adeuXZqamta7blVVVTp16tTiAgAAAAAAAAC2b61qVKisrMyAAQNSX19fHGtubk59fX0GDRq00bnV1dXp2bNn3nrrrdxxxx0544wzkiQf/ehH84c//CFPPPFE8TrqqKMybNiwPPHEE6moqNiMbQEAAAAAAAAA26N2rZ0wduzYjBgxIkcddVSOOeaYTJkyJatWrcrIkSOTJMOHD0/Pnj1TV1eXJHn00UezbNmy9O/fP8uWLcsVV1yR5ubmXHLJJUmS3XbbLYceemiLe+y6667Zc8891xkHAAAAAAAAAHZsrW5UGDp0aF566aVMmDAhy5cvT//+/TNnzpzU1NQkSZYsWZLy8ncOanjzzTdz2WWXZfHixenYsWNOPfXU3HLLLdl999232CYAAAAAAAAAgB1DWaFQKGzrJLaExsbGdO7cOQ0NDenUqdO2TgcAgK2ordd+bX1/AAC8o63Xfm19fwAAvKM1tV/5Rt8FAAAAAAAAANiCNCoAAAAAAAAAACWjUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAAAAAAAAQMloVAAAAAAAAAAASkajAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJaNRAQCAndrUqVPTu3fvVFdXZ+DAgZk3b94GY9euXZsrr7wyffv2TXV1dfr165c5c+ZsMP4b3/hGysrKctFFF22FzAEAAAAAdkwaFQAA2GnNmjUrY8eOzcSJE7NgwYL069cvQ4YMycqVK9cbf9lll+WGG27Itddem6eeeirnn39+zjrrrDz++OPrxP7ud7/LDTfckMMPP3xrbwMAAAAAYIeiUQEAgJ3W5MmTc95552XkyJE5+OCDM23atOyyyy6ZPn36euNvueWWfOUrX8mpp56a/fbbL6NGjcqpp56aq6++ukXca6+9lmHDhuWmm27KHnvsUYqtAAAAAADsMDQqAACwU1qzZk3mz5+fwYMHF8fKy8szePDgzJ07d71zVq9enerq6hZjHTp0yEMPPdRirLa2NqeddlqLtQEAYGtrzWPNkuTVV19NbW1tunfvnqqqqhxwwAG59957i+9ff/31Ofzww9OpU6d06tQpgwYNyi9+8YutvQ0AAHYC7bZ1AgAAsC28/PLLaWpqSk1NTYvxmpqaLFy4cL1zhgwZksmTJ+f4449P3759U19fnzvvvDNNTU3FmNtuuy0LFizI7373u03OZfXq1Vm9enXxdWNjYyt3AwDAzu7tx5pNmzYtAwcOzJQpUzJkyJA888wz6dq16zrxa9asyUknnZSuXbvm9ttvT8+ePfPCCy9k9913L8bsvffe+cY3vpH9998/hUIhM2bMyBlnnJHHH388hxxySAl3BwBAW+NEBQAA2ETXXHNN9t9//xx44IGprKzM6NGjM3LkyJSX/62sXrp0acaMGZOZM2euc/LCxtTV1aVz587Fq1evXltrCwAAtFGtfazZ9OnT88orr+Tuu+/Occcdl969e+eEE05Iv379ijGnn356Tj311Oy///454IADctVVV6Vjx4555JFHSrUtAADaKI0KAADslLp06ZKKioqsWLGixfiKFSvSrVu39c7Za6+9cvfdd2fVqlV54YUXsnDhwnTs2DH77bdfkmT+/PlZuXJljjzyyLRr1y7t2rXLgw8+mO9+97tp165di5MX/t748ePT0NBQvJYuXbplNwsAQJu2OY81u+eeezJo0KDU1tampqYmhx56aCZNmrTBmrWpqSm33XZbVq1alUGDBm2VfQAAsPPw6AcAAHZKlZWVGTBgQOrr63PmmWcmSZqbm1NfX5/Ro0dvdG51dXV69uyZtWvX5o477sg555yTJPnoRz+aP/zhDy1iR44cmQMPPDCXXnppKioq1rteVVVVqqqq3vumAADYKW3OY80WL16cBx54IMOGDcu9996b5557LhdccEHWrl2biRMnFuP+8Ic/ZNCgQXnzzTfTsWPH3HXXXTn44IM3mIvHmgEAsCk0KgAAsNMaO3ZsRowYkaOOOirHHHNMpkyZklWrVmXkyJFJkuHDh6dnz56pq6tLkjz66KNZtmxZ+vfvn2XLluWKK65Ic3NzLrnkkiTJbrvtlkMPPbTFPXbdddfsueee64wDAMC21NzcnK5du+bGG29MRUVFBgwYkGXLluVb3/pWi0aFD3zgA3niiSfS0NCQ22+/PSNGjMiDDz64wWaFurq6fO1rXyvVNgAA2EFpVAAAYKc1dOjQvPTSS5kwYUKWL1+e/v37Z86cOcW/RFuyZEnKy995Wtqbb76Zyy67LIsXL07Hjh1z6qmn5pZbbsnuu+++jXYAAACb91iz7t27p3379i1O/TrooIOyfPnyrFmzJpWVlUn+dhLZ+9///iTJgAED8rvf/S7XXHNNbrjhhvWuO378+IwdO7b4urGxMb169XpP+wMAoO3RqAAAwE5t9OjRG3zUw69+9asWr0844YQ89dRTrVr/3WsAAMCWtjmPNTvuuONy6623prm5udicu2jRonTv3r3YpLA+zc3NLR7t8G4eawYAwKYo/8chAAAAAABsz8aOHZubbropM2bMyNNPP51Ro0at81iz8ePHF+NHjRqVV155JWPGjMmiRYsye/bsTJo0KbW1tcWY8ePH59e//nX+9Kc/5Q9/+EPGjx+fX/3qVxk2bFjJ9wcAQNviRAUAAAAAgB1cax9r1qtXr9x33325+OKLc/jhh6dnz54ZM2ZMLr300mLMypUrM3z48Lz44ovp3LlzDj/88Nx333056aSTSr4/AADalrJCoVDY1klsCY2NjencuXMaGhrSqVOnbZ0OAABbUVuv/dr6/gAAeEdbr/3a+v4AAHhHa2o/j34AAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAAAAAAKBkNCoAAAAAAAAAACWjUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKRqMCAAAAAAAAAFAyGhUAAAAAAAAAgJLRqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1EBAAAAAAAAACgZjQoAAAAAAAAAQMloVAAAAAAAAAAASkajAgAAAAAAAABQMhoVAAAAAAAAAICS0agAAAAAAAAAAJSMRgUAAAAAAAAAoGQ0KgAAAAAAAAAAJaNRAQAAAAAAAAAoGY0KAAAAAAAAAEDJaFQAAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAAAAAAKBkNCoAAAAAAAAAACWjUQEAAAAAAAAAKBmNCgAAAAAAAABAyWhUAAAAAAAAAABKZrMaFaZOnZrevXunuro6AwcOzLx58zYYu3bt2lx55ZXp27dvqqur069fv8yZM6dFTF1dXY4++ujstttu6dq1a84888w888wzm5MaAAAAAAAAALAda3WjwqxZszJ27NhMnDgxCxYsSL9+/TJkyJCsXLlyvfGXXXZZbrjhhlx77bV56qmncv755+ess87K448/Xox58MEHU1tbm0ceeST3339/1q5dm5NPPjmrVq3a/J0BAAAAAAAAANudskKhUGjNhIEDB+boo4/OddddlyRpbm5Or1698qUvfSnjxo1bJ75Hjx756le/mtra2uLYJz7xiXTo0CE/+tGP1nuPl156KV27ds2DDz6Y448/fpPyamxsTOfOndPQ0JBOnTq1ZksAAOxg2nrt19b3BwDAO9p67dfW9wcAwDtaU/u16kSFNWvWZP78+Rk8ePA7C5SXZ/DgwZk7d+5656xevTrV1dUtxjp06JCHHnpog/dpaGhIkrzvfe/bYMzq1avT2NjY4gIAAAAAAAAAtm+talR4+eWX09TUlJqamhbjNTU1Wb58+XrnDBkyJJMnT86zzz6b5ubm3H///bnzzjvz4osvrje+ubk5F110UY477rgceuihG8ylrq4unTt3Ll69evVqzVYAAAAAAAAAgG2gVY0Km+Oaa67J/vvvnwMPPDCVlZUZPXp0Ro4cmfLy9d+6trY2Tz75ZG677baNrjt+/Pg0NDQUr6VLl26N9AEAAAAAAACALahVjQpdunRJRUVFVqxY0WJ8xYoV6dat23rn7LXXXrn77ruzatWqvPDCC1m4cGE6duyY/fbbb53Y0aNH5+c//3l++ctfZu+9995oLlVVVenUqVOLCwAAAAAAAADYvrWqUaGysjIDBgxIfX19cay5uTn19fUZNGjQRudWV1enZ8+eeeutt3LHHXfkjDPOKL5XKBQyevTo3HXXXXnggQfSp0+fVm4DAAAAAAAAANgRtGvthLFjx2bEiBE56qijcswxx2TKlClZtWpVRo4cmSQZPnx4evbsmbq6uiTJo48+mmXLlqV///5ZtmxZrrjiijQ3N+eSSy4prllbW5tbb701P/vZz7Lbbrtl+fLlSZLOnTunQ4cOW2KfAAAAAAAAAMB2oNWNCkOHDs1LL72UCRMmZPny5enfv3/mzJmTmpqaJMmSJUtSXv7OQQ1vvvlmLrvssixevDgdO3bMqaeemltuuSW77757Meb6669PknzkIx9pca8f/OAH+cxnPtP6XQEAAAAAAAAA26WyQqFQ2NZJbAmNjY3p3LlzGhoa0qlTp22dDgAAW1Fbr/3a+v4AAHhHW6/92vr+AAB4R2tqv/KNvgsAAAAAAAAAsAVpVAAAAAAAaAOmTp2a3r17p7q6OgMHDsy8efM2Gv/qq6+mtrY23bt3T1VVVQ444IDce++9xffr6upy9NFHZ7fddkvXrl1z5pln5plnntna2wAAYCegUQEAAAAAYAc3a9asjB07NhMnTsyCBQvSr1+/DBkyJCtXrlxv/Jo1a3LSSSflT3/6U26//fY888wzuemmm9KzZ89izIMPPpja2to88sgjuf/++7N27dqcfPLJWbVqVam2BQBAG9VuWycAAAAAAMB7M3ny5Jx33nkZOXJkkmTatGmZPXt2pk+fnnHjxq0TP3369Lzyyit5+OGH0759+yRJ7969W8TMmTOnxeubb745Xbt2zfz583P88cdvnY0AALBTcKICAAAAAMAObM2aNZk/f34GDx5cHCsvL8/gwYMzd+7c9c655557MmjQoNTW1qampiaHHnpoJk2alKampg3ep6GhIUnyvve9b8tuAACAnY4TFQAAAAAAdmAvv/xympqaUlNT02K8pqYmCxcuXO+cxYsX54EHHsiwYcNy77335rnnnssFF1yQtWvXZuLEievENzc356KLLspxxx2XQw89dIO5rF69OqtXry6+bmxs3MxdAQDQlmlUAAAAAADYyTQ3N6dr16658cYbU1FRkQEDBmTZsmX51re+td5Ghdra2jz55JN56KGHNrpuXV1dvva1r22ttAEAaCM8+gEAAAAAYAfWpUuXVFRUZMWKFS3GV6xYkW7duq13Tvfu3XPAAQekoqKiOHbQQQdl+fLlWbNmTYvY0aNH5+c//3l++ctfZu+9995oLuPHj09DQ0PxWrp06WbuCgCAtkyjAgAAAADADqyysjIDBgxIfX19cay5uTn19fUZNGjQeuccd9xxee6559Lc3FwcW7RoUbp3757KysokSaFQyOjRo3PXXXflgQceSJ8+ff5hLlVVVenUqVOLCwAA3k2jAgAAAADADm7s2LG56aabMmPGjDz99NMZNWpUVq1alZEjRyZJhg8fnvHjxxfjR40alVdeeSVjxozJokWLMnv27EyaNCm1tbXFmNra2vzoRz/Krbfemt122y3Lly/P8uXL88Ybb5R8fwAAtC3ttnUCAAAAAAC8N0OHDs1LL72UCRMmZPny5enfv3/mzJmTmpqaJMmSJUtSXv7O36316tUr9913Xy6++OIcfvjh6dmzZ8aMGZNLL720GHP99dcnST7ykY+0uNcPfvCDfOYzn9nqewIAoO0qKxQKhW2dxJbQ2NiYzp07p6GhwXFiAABtXFuv/dr6/gAAeEdbr/3a+v4AAHhHa2o/j34AAAAAAAAAAEpGowIAAAAAAAAAUDIaFQAAAAAAAACAktGoAAAAAAAAAACUjEYFAAAAAAAAAKBkNCoAAAAAAAAAACWjUQEAAAAAAAAAKJl22zqBLaVQKCRJGhsbt3EmAABsbW/XfG/XgG2N2hYAYOehtgUAoK1oTW3bZhoV/vrXvyZJevXqtY0zAQCgVP7617+mc+fO2zqNLU5tCwCw81HbAgDQVmxKbVtWaCOtus3Nzfnzn/+c3XbbLWVlZSW5Z2NjY3r16pWlS5emU6dOJbnnttLW9rqj72dHy397zXd7ymtb5lLKe2/uvbZ2jltj/e1hzfeSw3vN373de2srFAr561//mh49eqS8vO09zUxtu3W1tb3u6PvZ0fLfXvPdnvJS226dedty/e1hzR211nHvnevem0ttu+VtTz8Xt7a2ttcdfT87Wv7ba77bU15q260zb1uuvz2suaPWOu69c917c7Wmtm0zJyqUl5dn77333ib37tSp0zb/YVkqbW2vO/p+drT8t9d8t6e8tmUupbz35t5ra+e4NdbfHtZ8Lzm81/zd2723prb412ZvU9uWRlvb646+nx0t/+013+0pL7Xt1pm3LdffHtbcUWsd99657r051LZbx/b0c3Fra2t73dH3s6Plv73muz3lpbbdOvO25frbw5o7aq3j3jvXvTfHpta2ba9FFwAAAAAAAADYbmlUAAAAAAAAAABKRqPCe1BVVZWJEyemqqpqW6ey1bW1ve7o+9nR8t9e892e8tqWuZTy3pt7r62d49ZYf3tY873k8F7zd2/3ZsezM/07trW97uj72dHy317z3Z7yUttunXnbcv3tYc0dtdZx753r3mw/dqZ/x7a21x19Pzta/ttrvttTXmrbrTNvW66/Pay5o9Y67r1z3bsUygqFQmFbJwEAAAAAAAAA7BycqAAAAAAAAAAAlIxGBQAAAAAAAACgZDQqAAAAAAAAAAAlo1FhA6644oqUlZW1uA488MCNzvnpT3+aAw88MNXV1TnssMNy7733lijb1vn1r3+d008/PT169EhZWVnuvvvu4ntr167NpZdemsMOOyy77rprevTokeHDh+fPf/7zP1x32bJlOffcc7PnnnumQ4cOOeyww/LYY49txZ38zcb2kyQrVqzIZz7zmfTo0SO77LJLPvaxj+XZZ5/d5PVvu+22lJWV5cwzz9yyif//1dXV5eijj85uu+2Wrl275swzz8wzzzzTIuYjH/nIOp+P559//j9c++mnn87HP/7xdO7cObvuumuOPvroLFmyZLNzvf7663P44YenU6dO6dSpUwYNGpRf/OIXxfdvvPHGfOQjH0mnTp1SVlaWV1999R+uuSn73xK5JcncuXPzv/7X/8quu+6aTp065fjjj88bb7yxVXP7xje+kbKyslx00UXFsTfffDO1tbXZc88907Fjx3ziE5/IihUr/uFarf33XN+931YoFHLKKaes92tmc++9vvstX748//zP/5xu3bpl1113zZFHHplzzjlno99fr7zyynTt2rX4Xo8ePfLb3/52o/kVCoVMmDAhHTt23OjaX/ziF9O3b9906NAhe+21V84444wsXLjwH659wgknbHTd1n6Nru9nTFVVVaZNm7bBj9sdd9zxD7/Pvv1xePtrcJ999il+v9vY3O9+97vp3LlzysvLU1FRkb322mud7/0bmj916tT07t071dXVGThwYObNm5fzzz8/ZWVlmTJlyj+899vzKysrs8cee6Rjx44tPsc2NvenP/1pDjjggFRUVKR9+/apqqrKwQcfXPw49u7de52Pc1lZWWpra1vMbdeuXTp06LDO1+KG5h999NGpqalJu3btsuuuu6a6ujr77LNPLrzwwjQ0NGx07gUXXJAJEyake/fu6dChQz760Y/m+OOPX+drcWP3fnvu0UcfnUGDBq3zPW1j+546dWp69eqVioqKVFZWpkOHDsXPr7c1NTXl8ssvT58+fdKhQ4f07ds3X//613PdddcV/62POeaYfO5znyvmMnjw4E362bq+zxdKQ22rtn2b2vYdalu1rdpWbau2VduqbXdMalu17dvUtu9Q26pt1bZqW7Wt2naHrG0LrNfEiRMLhxxySOHFF18sXi+99NIG43/7298WKioqCv/+7/9eeOqppwqXXXZZoX379oU//OEPJcx609x7772Fr371q4U777yzkKRw1113Fd979dVXC4MHDy7MmjWrsHDhwsLcuXMLxxxzTGHAgAEbXfOVV14p7LvvvoXPfOYzhUcffbSwePHiwn333Vd47rnntvJuNr6f5ubmwgc/+MHChz/84cK8efMKCxcuLHzhC18o7LPPPoXXXnvtH679/PPPF3r27Fn48Ic/XDjjjDO2Sv5Dhgwp/OAHPyg8+eSThSeeeKJw6qmnrpPfCSecUDjvvPNafD42NDRsdN3nnnuu8L73va/w5S9/ubBgwYLCc889V/jZz35WWLFixWbnes899xRmz55dWLRoUeGZZ54pfOUrXym0b9++8OSTTxYKhULhO9/5TqGurq5QV1dXSFL4y1/+skX2vyVye/jhhwudOnUq1NXVFZ588snCwoULC7NmzSq8+eabWy23efPmFXr37l04/PDDC2PGjCmOn3/++YVevXoV6uvrC4899ljhgx/8YOHYY4/d6Fqt/ffc0L3fNnny5MIpp5yyztfM5t57Q/c76aSTCkcffXTh0UcfLfzxj38sfP3rXy8kKfTt23eD31979epVeN/73lf4j//4j8Ktt95a2H333QuVlZUb/bh/4xvfKHTu3LkwdOjQQt++fQsnn3xyoVevXoXnn3++xdo33HBD4cEHHyw8//zzhfnz5xdOP/30Qq9evQpvvfXWRteuqqoq7LPPPoX6+vri2kuXLi3GtPZrdOLEiYU99tijsO+++xbuuOOOwrx58wpXX311oaKiovCzn/1svR+3srKyQvfu3Tf6ffYb3/hGoWPHjoWuXbsW9t9//8J+++1X6NOnT+HPf/7zBr9H33bbbYX27dsXDj744MLVV19dOPvsswsdO3YsHHHEEcXv/Rv6Hj9lypRCZWVlYfr06YX/9//+X+G8884r7LLLLoVDDjmk0KNHj8J3vvOdjf58uO222wqVlZXFf7/DDz+80LFjx8Kjjz5a+NnPflZ45plnNjj37Z+7xxxzTKFXr16Fc889t9CuXbvChAkTih/HlStXtvg3uf/++wtJCtdee22hoqKi8MEPfrDQrVu3wrBhwwrt2rUrHH744S2+Fjc0f9dddy1cc801hY9+9KOFY445prD33nsXfvGLXxT233//wic+8YmNzj3vvPMKnTt3Ltx9992F3//+94VDDjmk0KFDh3W+Fjd277vvvrvwwx/+sNCuXbvCHnvsUZg/f36L72kbmnv55ZcXKisrC4ccckjh0EMPLZxxxhmF3XbbrXDppZcWysvLCwsWLCgUCoXCVVddVdhzzz0LP//5zwvPP/984ac//Wmhurq6UFFRUfy3PvroowtJCjfffHPh97//feHjH/94oU+fPoU33nhjg5/3b/97//3ny+677/6efi6x6dS2attCQW37bmpbta3aVm2rtlXbqm13TGpbtW2hoLZ9N7Wt2lZtq7ZV26ptd8TaVqPCBkycOLHQr1+/TY4/55xzCqeddlqLsYEDBxa++MUvbuHMtqxN+WE3b968QpLCCy+8sMGYSy+9tPChD31oC2fXeu/ezzPPPFNIUix6CoVCoampqbDXXnsVbrrppo2u9dZbbxWOPfbYwve///3CiBEjtlrB+24rV64sJCk8+OCDxbETTjhhvUXLxgwdOrRw7rnnbuHs1rXHHnsUvv/977cY++Uvf7nJBe+7rW//WyK3gQMHFi677LL3tF5rcvvrX/9a2H///Qv3339/i3+/V199tdC+ffvCT3/602Ls008/XUhSmDt37gbXa82/54bu/bbHH3+80LNnz8KLL764Sd8D/tG9N3a/XXfdtfDDH/6wRXx1dXVh7733Xu9a6/v4/Pa3vy0kKXzve99b75zm5uZCt27dCt/61reK37tfffXVQlVVVeHHP/7xRvf2+9//vpBkg//j/O21TzrppOLPhPWt3dqv0YkTJxaqq6sLV155ZYvxI488svDVr351gx+397///Rtcs7m5uVBTU1Po0qVL8d/i/PPPL1RVVRU+/vGPb/B79DHHHFOora0tvm5qair06NGjcMEFFxS/92/oe/y75y5ZsqRQXl5euOiiiwr77rtv4Tvf+c5Gfz68Pf/tz7G3711XV1coFDb+s+Xtn7uHHHJI8eP49s/dtz+O7zZmzJhC3759C2effXbh5JNPbvG5NnDgwMI555yz0a/FCy+8sPjLrbf9/efDT37yk0JlZWVh7dq1G7x3TU1N4Vvf+lahUPjb12KPHj0KlZWV//Br8d33HjhwYOFf//VfN+nz/O17H3300YXa2tri59fff7zf9773FX8unnbaaYXPfvazLdbYY489CgcccEChUHjn6+LtXyK8++OwIRv6XHt7DbYute071LZq241R266f2vZv1Lbrp7ZtOV9tq7Zl61PbvkNtq7bdGLXt+qlt/0Ztu35q25bz1bZq263Nox824tlnn02PHj2y3377ZdiwYRs9qmfu3LkZPHhwi7EhQ4Zk7ty5WzvNra6hoSFlZWXZfffdNxhzzz335KijjsrZZ5+drl275ogjjshNN91UuiQ3YPXq1UmS6urq4lh5eXmqqqry0EMPbXTu28cYfe5zn9uqOb7b28fPvO9972sxPnPmzHTp0iWHHnpoxo8fn9dff32DazQ3N2f27Nk54IADMmTIkHTt2jUDBw7cpKOiNlVTU1Nuu+22rFq1KoMGDdpi625o/63x7txWrlyZRx99NF27ds2xxx6bmpqanHDCCf/wc+C95FZbW5vTTjttne8L8+fPz9q1a1uMH3jggdlnn302+P2itf+eG7p3krz++uv59Kc/nalTp6Zbt27/cB+bcu+N3e/YY4/NrFn/v/buPaqqMn8D+HPu3BUvIHJRFEEtdARvaF5B1AxBC00dodSwFB3LuzVKOWlOFzLL0pnCStOoFC1NQxQzTQUFyTJARG0IdeXlp3gB5Xx/f7DOHjacA2iK2TyftVirs/d59/vud7/7PY+td+39Kc6fPw+z2Yx169bh5s2bOHfunNX51Vr/uLm5AQAKCwuttrGwsBCnT59WyuTn56Ndu3bQaDRISEiwOXdfuXIFSUlJ8PX1hbe3d43HbtWqlfKb0KlTJ7i4uOCbb75RffdW7lEAuHnzJhYuXIgWLVpgzJgxWLduHfLy8hAeHm6130pLS/HQQw/ZnGcLCwtx5swZhIeHK31hMpnQrVs37N692+ocXVZWhoMHD6r6W6vVIiwsDFlZWcrcb22Of/fdd1VlzWYzYmNjERwcjOPHjyvHs/X7YKm7f//+yhgbPHgwzp8/jyVLliAlJaXG3xbL726PHj2wadMmFBUVITw8HKmpqUo/VlZWVobVq1dj3Lhx2LdvH/z8/FRjbeDAgfj5559t3otlZWX4+OOPUV5ejgEDBijbGzRogG7duuH777/H//3f/8HFxQV6vd5q3VFRUThz5gzCwsKUe3H58uXo3r17jWOlat2WOc3Hxwcmkwnjxo2zOadZ6o6NjcWhQ4eUPvv0009x8eJFhIaG4vPPP8f169fRt29fABX3bVpaGvLy8gAAmZmZuHDhAh5++GFlrJ0+fRq9e/dW+qpyP9g6B1tj7c+Qle4XzLYVmG2Zba1htq0Zs20FZlvbmG2ZbZltmW3rG7NtBWZbZltrmG1rxmxbgdnWNmZbZltm23rMtnd9KcR9asuWLZKcnCyHDx+WrVu3SkhIiPj4+MilS5esft9gMMgnn3yi2vbOO++Im5tbfTT3tqGWlUDXrl2ToKAgGT16dI3HMZlMYjKZZO7cuXLo0CFZsWKF2NnZyapVq+5wi2tW9XzKysrEx8dHoqOj5fz581JaWiqvvPKKAJDw8HCbx9m9e7d4enoqjx6qr5W55eXlMmTIEOnZs6dq+4oVK2Tr1q2Sk5Mjq1evFk9PTxk2bJjN41hWXDo4OMgbb7whWVlZsnjxYtFoNJKenv672piTkyOOjo6i0+mkQYMGsnnz5mrfud2VubbO//e27fvvvxcA0qhRI/nggw/k0KFDMm3aNDEajZKXl3fH27Z27Vp58MEHlUfpVF61uWbNGjEajdXKdOnSRWbNmmX1eLdyPWuqW0QkLi5Oxo8fr3yubQ6ore7a6rtw4YKEh4cLANHr9eLi4iL/+Mc/bM6vVfvH0u9OTk42+8eycvfXX39Vzd29evWSxo0bV5u733nnHXF0dBQAEhAQUOOjDi3HXr16tarNjRs3FgcHB+W4t3qPbtmyRdasWSMRERECQPl77733bPabwWCocZ598cUXBYAcP35cdS2io6NFq9VaLZuYmCgAZO/evar2Pfvss+Lg4KDM/bbm+MplFy1aJAMGDJAZM2ZI165dlZW5tspa6v7yyy9VYywmJka8vLxEo9HUeM6W393r169LTEyMABCtVisA5MMPP6zW559++qnodDopKioSg8EgkydPVo01y2+2rXvRUt4y1iqLjo6WyMhI8fHxkXnz5tksm5KSopSvfC9GR0fXeC9WrbvynNa5c2cZMGCAzTnNUvbgwYPK9ao8vrRareh0Otm2bZtSpry8XGbPni0ajUb0er1oNBrVtbbcF88884x07dpV1Q8jRoyweg5FRUVWx9rMmTNVx6C7h9m2ArMts21VzLbMtsy2zLbMtsy2zLb3H2bbCsy2zLZVMdsy2zLbMtsy2zLb3m/ZlgsV6ujChQvi4uJS7VFJFn/GwFtWViYRERHSqVOnWt+rZTAYJCQkRLVtypQp0r179zvV1Dqxdj6ZmZnSsWNHASA6nU4GDhwogwcPlkGDBlk9xqVLl6Rly5ayZcsWZVt9Bd6nn35aWrRooXqHkjVpaWk1PvbIMrGMGjVKtT0iIkIef/zx39XG0tJSyc/Pl8zMTJkzZ440adJEfvzxR9V3bjfw1vX8b7Vtlsl57ty5qu8HBgbKnDlz7mjbTp06JW5ubnL48GFl2+8NvHW9nrXVvXHjRvHz85PLly8r+2sLvDXVHRERUWN9IiLx8fHStWtX2b59u2RnZ0tCQoI0aNBAcnJylO9Unl+r9o+l3zt27FinwFtZdHS0REVFVZu7L168KHl5ebJr1y6JiIiQoKAgm+9nsnXsyMhIMRgMNn8TartHRUReffVV8ff3l02bNsnu3bvFzs5OTCaTpKamWu03ANUebWmZZ0+dOiWurq6qtlYNvNbm6KCgoGohpKysTFq3bi0ODg7K3G9tjh83bpxSNjMzU9zd3aWoqEgJMJbAa+v3wVL3xo0bVWPMUj4iIsJmu7t376787lbux3nz5omTk5M4OTlJamqqqlx4eLg88sgjyvncauANDw+Xnj17Wh0PUVFR0qhRIxk0aJCUlZVZLfvII48o4ykpKUl1L9YWeKvWXXlOqxwyrc1plrorB87K4ys2NlY8PT1V9+XatWvFy8tL1q5dKzk5ObJ06VIBoDyG8X4MvFQdsy2zLbNtBWZbZltL3cy2zLbMthWYbUU5D2bb+wezLbMts20FZltmW0vdzLbMtsy2FZhtRTmPP2q25UKFW9C5c2ebP47e3t6SmJio2jZ//nzp0KFDPbTs9tm6wcrKyiQqKko6dOggv/32W63H8fHxUa32ExFZvny5NG/e/E41tU5qmjAuXrwoZ8+eFZGK961MmjTJ6veysrKUcGz502g0otFoRKfT1fgD9ntMnjxZvLy8lFV1NSkpKREAsnXrVqv7S0tLRa/Xy8KFC1XbZ82aJT169Lgj7bUIDQ2VuLg41bbbCby3cv632rbjx48LAPn4449V+0eMGFHrqvNbbduGDRuqjR8AyvjZvn271b7x8fGRN954w+ox63o9a6s7Pj5e+e/K+7VarfTp0+eW6w4ICKixvmPHjgmgftegSMV1qfoeSMv8agmKFy5cUPV7Tf1TUFAgACQrK0u1vXfv3jJ16tQa5+7S0lJxcHCo9j8s6nJsNzc3m8et7R69evWqGAwG+eqrr1R90KFDB+nVq5fVfrOzs5O2bduqtlnmWcu1r7zS0nItAIizs7PNOVqn0ynzpmXud3V1Vf1PAWtz/FtvvaXMuYmJicp1t8yXldtSU93JycmqMRYTEyNDhw6VWbNmidFotFnW29tblixZoupHy+/u+PHjZeDAgUqZEydOiFarlZSUFBGp+M22vMvNci9ayloba5by7733XrXxcOnSJXFxcRFvb2+r/3CqXLdlPI0ePVp1L1a+dlXvRWt1V57TLONcpPqcVrnu0tJS0el0snz5ctX4svR35fvSy8tL3n77beU4paWlotFoxNPTU0T+e1888sgjMnToUOV7ldtSlaX+qr/Rlvrp3mC2tY3Z9vdjtmW2ZbZltmW2ZbZltqX6xGxrG7Pt78dsy2zLbMtsy2zLbMtse3doQXVSUlKCgoICeHh4WN0fEhKCtLQ01bbU1NQ7+g6o+nLjxg2MGDEC+fn52L59Oxo3blxrmZ49eyI3N1e1LS8vDy1atLhbzbxlDRo0QNOmTZGfn4/MzExERkZa/V7btm3xww8/IDs7W/kbOnQo+vXrh+zsbJvvRLpdIoL4+Hhs2LABO3bsgK+vb61lsrOzAcDmeDQajejSpUu9XBOz2ay8U+523M7532rbWrZsiebNm99yf9xO20JDQ6uNn86dO2PMmDHKfxsMBtV8kZubi1OnTtmcL+p6PWur+/nnn0dOTo5qPwAkJiYiKSnplusODAyssT7Lu760WvVPjU6ng9lsVj5Xnl+Dg4NhMBgwatQopd/Lyspq7B9fX180a9ZM1aeXLl3C/v370alTpxrnbqlYsGdzDNs69r59+3DlyhWbx63tHr1x4wZu3Lih9I2lD5ycnHDjxg0A1futYcOGuHDhgmqbZQyEhoYiJycHTZo0wXPPPadci+joaBiNRgQGBtocP8HBwUhLS1PN/SaTCX369FG+a22OP378OJycnJCWloaxY8ciJycHhw4dQtOmTTF16lQ0b94cM2fOxKBBg2qs+9tvv1XGmNlsRlpaGkJCQpCXlwcPDw+bZUNCQrBjxw5VP1p+d6uOsaSkJLi5uWHIkCEAKn6zCwoKVPdiamoq2rVrZ3WsWcqPGzdONR4uXbqE0NBQXL58GQsXLlS9V9Na3Zbx5Ofnp9yL3333HQwGAwDr96K1ui1zWk5ODvbv36+0t+qcULluo9Go9DdQMb4q93flPrt69apq/BmNRnh6eqKkpATAf++Lb7/9Vqnbcs/VNI9ZxppF5fqp/jHb1ozZ9vYx2zLbMtsy2zLbMtsCzLZUv5hta8Zse/uYbZltmW2ZbZltmW0BZtu76q4vhbhPTZ8+XdLT06WwsFD27NkjYWFh0qRJE2Vl59ixY1Ursvbs2SN6vV5ee+01OXr0qCxYsEAMBoP88MMP9+oUbLp8+bJkZWUpK1At7y86efKklJWVydChQ8XLy0uys7OluLhY+SstLVWO0b9/f1m2bJny+cCBA6LX6+Xll1+W/Px8WbNmjTg4OMjq1avv6fmIiCQnJ8vOnTuloKBAUlJSpEWLFjJ8+HDVMapez6ru5iPEnnnmGWnQoIGkp6er+vvq1asiInLs2DF56aWXJDMzUwoLC2Xjxo3SqlUr6d27t+o4AQEBsn79euXz+vXrxWAwyMqVKyU/P1+WLVsmOp1Odu/efdttnTNnjuzatUsKCwslJydH5syZIxqNRr755hsRqXgvVlZWlvzrX/8SAPLtt99KVlaWnDt3TjlG1bFT2/nfqbYlJiaKi4uLfPbZZ5Kfny8vvPCC2NnZqVZa3622VX2s1tNPPy0+Pj6yY8cOyczMlJCQkGqPSbpT17Nq3VXBymr231N35frKysrEz89PevXqJfv375djx47Ja6+9JgDklVdeUeZXV1dXcXJyUubX9u3bi0ajkcTERNm6dat07txZOnfurOr3qm185ZVXpGHDhhIVFSUffPCBDBgwQDw8PKR///7K3F1QUCCLFi2SzMxMOXnypOzZs0ciIiKkUaNGcubMmRqPbTKZ5OWXX5avv/5aevXqJXZ2dspxb+cenT59unTs2FHatGkjy5Ytk549e4qTk5OYTCZZtmyZzX7T6XTKPNu+fXsxGo2qedbSDxs3bpTg4GBp1aqV+Pr6yu7du5U5unv37hIbG6vM0evWrROj0SidOnWSZs2ayaOPPiouLi6Sk5OjzP2WOb5Vq1Yyf/58ZY6Pj48Xk8kkq1atkp9++kni4uKkYcOGcvr0aeURYpV/H6zVbTKZZMqUKaLX66VXr17i7OwsL7/8suh0Olm5cqVSNjIyUiIiIpSylt/dVq1aiZ+fn8TGxiorfO3s7GT58uUiUvHeLkdHR9UjLS1lQ0JCxMPDQ2JiYkSv10vHjh2r3Yv+/v7SpEkTmT17tqqP165dK4GBgeLi4iJeXl5SWFiozBE3b95U6tbr9ar33lW+Rjk5ORIZGSm+vr5W70VbdW/cuFFmzpwper1e3Nzc5MiRI9XmtPLycjGZTBIWFqYcz3Kt3d3dJTg4WKKiosTZ2VkWLFggGo1GeT9kbGysmEwmmThxohQWFsr69evF2dlZdDqdcq27du0qGo1GPvzwQ9V5VF6dXHVOtVxva+OF7j5mW2bbyphtKzDbMtsy2zLbMtsy2zLb3p+YbZltK2O2rcBsy2zLbMtsy2zLbHs/ZlsuVLBh5MiR4uHhIUajUTw9PWXkyJGqH8Y+ffpIbGysqkxycrL4+/uL0WiUBx54QBk4fzSWxztV/YuNjZXCwkKr+wDIzp07lWO0aNFCFixYoDrul19+KQ8++KCYTCZp27atrFy58p6fj4jI0qVLxcvLSwwGg/j4+MgLL7ygCu8i1q9nZXcz8Nrq76SkJBGpeH9V7969pVGjRmIymcTPz09mzpxZ7f1zlctYvP/+++Ln5yd2dnbSsWNH5fE5t2vcuHHSokULMRqN0rRpUwkNDVUCpYjIggULajwXkepjp7bzv1NtExFZvHixeHl5iYODg4SEhFQLbHerbVVD57Vr12TSpEni6uoqDg4OMmzYMCkuLlaVuVPX83YC7++pu2p9eXl5Mnz4cHFzcxMHBwfp0KGDdOvWTTW/Ojg4yJQpU1T119bvVT+bzWb5+9//LiaTSXl0lru7u2ruLioqksGDB4ubm5sYDAbx8vKS0aNHy88//1zj+ZvNZmnfvr1otVoBICaTSR5++GHluLdzj44cOVLc3d1Fq9Uqf76+vvL666+L2Wy22m8fffSRap7V6/XKu7uq9oO7u7toNBrx9vaW3NxcEfnvHA1AmjRpopqjLe9Sq2nu//LLL8VgMIhOp1PN8cuWLRMfHx8xGo3StWtX2bdvn4iIEnhrq9tSXqfTiclkEpPJpBpjlrIajUYaNGigKpucnCytWrUSrVYrer1ejEajBAQEKP0oIrJt2zYBIFFRUaq+Sk5OFj8/P+UxZyaTyea9CEDpR0sfW94tZ+2vsLBQVffixYutXiOTySShoaGSm5tr8160VrelbOvWraVZs2ZW5zRL3fHx8apjLlu2TDw8PESj0Yherxc7OztlfFlcunRJnJ2dpUGDBmJnZyetWrWS559/XhITE5Vr3aVLFxk3bly186jMWlawNV7o7mO2ZbatjNm2ArMtsy2zLbMtsy2zLbPt/YnZltm2MmbbCsy2zLbMtsy2zLbMtvdjttWIiICIiIiIiIiIiIiIiIiIiIioHmhr/woRERERERERERERERERERHRncGFCkRERERERERERERERERERFRvuFCBiIiIiIiIiIiIiIiIiIiI6g0XKhAREREREREREREREREREVG94UIFIiIiIiIiIiIiIiIiIiIiqjdcqEBERERERERERERERERERET1hgsViIiIiIiIiIiIiIiIiIiIqN5woQIRERERERERERERERERERHVGy5UICL6k0tISIC7uzs0Gg1SUlLqVCY9PR0ajQYXL168q237I2nZsiXefPPNe90MIiIiIqoBs23dMNsSERER/fEx29YNsy3RnxcXKhBRvXviiSeg0Wig0WhgNBrh5+eHl156CTdv3rzXTavVrYTGP4KjR4/ixRdfxIoVK1BcXIzBgwfftbr69u2LadOm3bXjExEREf0RMdvWH2ZbIiIioruL2bb+MNsSEQH6e90AIvrfNGjQICQlJaG0tBRbtmzB5MmTYTAYMHfu3Fs+Vnl5OTQaDbRarr2qqqCgAAAQGRkJjUZzj1tDRERE9OfEbFs/mG2JiIiI7j5m2/rBbEtExCcqENE9YjKZ0KxZM7Ro0QLPPPMMwsLCsGnTJgBAaWkpZsyYAU9PTzg6OqJbt25IT09Xyq5atQoNGzbEpk2b0L59e5hMJpw6dQqlpaWYPXs2vL29YTKZ4Ofnh/fff18pd+TIEQwePBhOTk5wd3fH2LFj8dtvvyn7+/bti6lTp2LWrFlo1KgRmjVrhoSEBGV/y5YtAQDDhg2DRqNRPhcUFCAyMhLu7u5wcnJCly5dsH37dtX5FhcXY8iQIbC3t4evry8++eSTao+sunjxIiZMmICmTZvCxcUF/fv3x+HDh2vsxx9++AH9+/eHvb09GjdujLi4OJSUlACoeHRYREQEAECr1dYYeLds2QJ/f3/Y29ujX79+OHHihGr/uXPnMGrUKHh6esLBwQGBgYFYu3atsv+JJ57Arl27sHTpUmXV9YkTJ1BeXo7x48fD19cX9vb2CAgIwNKlS2s8J8v1rSwlJUXV/sOHD6Nfv35wdnaGi4sLgoODkZmZqez/7rvv0KtXL9jb28Pb2xtTp07FlStXlP1nz55FRESEcj3WrFlTY5uIiIiIasJsy2xrC7MtERER3W+YbZltbWG2JaI7jQsViOgPwd7eHmVlZQCA+Ph4fP/991i3bh1ycnIQHR2NQYMGIT8/X/n+1atXsWTJEvz73//Gjz/+CDc3N8TExGDt2rV46623cPToUaxYsQJOTk4AKsJk//790alTJ2RmZmLr1q04c+YMRowYoWrHhx9+CEdHR+zfvx///Oc/8dJLLyE1NRUAkJGRAQBISkpCcXGx8rmkpAQPP/ww0tLSkJWVhUGDBiEiIgKnTp1SjhsTE4Nff/0V6enp+OKLL7By5UqcPXtWVXd0dDTOnj2Lr7/+GgcPHkRQUBBCQ0Nx/vx5q3125coVDBw4EK6ursjIyMBnn32G7du3Iz4+HgAwY8YMJCUlAagI3MXFxVaP88svv2D48OGIiIhAdnY2JkyYgDlz5qi+c/36dQQHB2Pz5s04cuQI4uLiMHbsWBw4cAAAsHTpUoSEhOCpp55S6vL29obZbIaXlxc+++wz/PTTT5g/fz7mzZuH5ORkq22pqzFjxsDLywsZGRk4ePAg5syZA4PBAKDiHyCDBg3Co48+ipycHHz66af47rvvlH4BKgL6L7/8gp07d+Lzzz/H8uXLq10PIiIiotvFbMtseyuYbYmIiOiPjNmW2fZWMNsS0S0RIqJ6FhsbK5GRkSIiYjabJTU1VUwmk8yYMUNOnjwpOp1OioqKVGVCQ0Nl7ty5IiKSlJQkACQ7O1vZn5ubKwAkNTXVap0LFy6U8PBw1bZffvlFAEhubq6IiPTp00ceeugh1Xe6dOkis2fPVj4DkA0bNtR6jg888IAsW7ZMRESOHj0qACQjI0PZn5+fLwAkMTFRRER2794tLi4ucv36ddVxWrduLStWrLBax8qVK8XV1VVKSkqUbZs3bxatViunT58WEZENGzZIbVP93LlzpX379qpts2fPFgBy4cIFm+WGDBki06dPVz736dNH/va3v9VYl4jI5MmT5dFHH7W5PykpSRo0aKDaVvU8nJ2dZdWqVVbLjx8/XuLi4lTbdu/eLVqtVq5du6aMlQMHDij7LdfIcj2IiIiI6orZltmW2ZaIiIj+LJhtmW2ZbYmoPunv+koIIiIrvvrqKzg5OeHGjRswm80YPXo0EhISkJ6ejvLycvj7+6u+X1paisaNGyufjUYjOnTooHzOzs6GTqdDnz59rNZ3+PBh7Ny5U1mpW1lBQYFSX+VjAoCHh0etKzZLSkqQkJCAzZs3o7i4GDdv3sS1a9eUlbm5ubnQ6/UICgpSyvj5+cHV1VXVvpKSEtU5AsC1a9eU95VVdfToUXTs2BGOjo7Ktp49e8JsNiM3Nxfu7u41trvycbp166baFhISovpcXl6ORYsWITk5GUVFRSgrK0NpaSkcHBxqPf4777yDDz74AKdOncK1a9dQVlaGv/zlL3Vqmy3PPfccJkyYgI8//hhhYWGIjo5G69atAVT0ZU5OjuqxYCICs9mMwsJC5OXlQa/XIzg4WNnftm3bao8tIyIiIqorZltm29+D2ZaIiIj+SJhtmW1/D2ZbIroVXKhARPdEv3798O6778JoNKJ58+bQ6yumo5KSEuh0Ohw8eBA6nU5VpnJYtbe3V737yt7evsb6SkpKEBERgSVLllTb5+Hhofy35TFUFhqNBmazucZjz5gxA6mpqXjttdfg5+cHe3t7PPbYY8oj0eqipKQEHh4eqne6WfwRgtirr76KpUuX4s0330RgYCAcHR0xbdq0Ws9x3bp1mDFjBl5//XWEhITA2dkZr776Kvbv32+zjFarhYiott24cUP1OSEhAaNHj8bmzZvx9ddfY8GCBVi3bh2GDRuGkpISTJw4EVOnTq12bB8fH+Tl5d3CmRMRERHVjtm2evuYbSsw2xIREdH9htm2evuYbSsw2xLRncaFCkR0Tzg6OsLPz6/a9k6dOqG8vBxnz55Fr1696ny8wMBAmM1m7Nq1C2FhYdX2BwUF4YsvvkDLli2VcH07DAYDysvLVdv27NmDJ554AsOGDQNQEV5PnDih7A8ICMDNmzeRlZWlrAY9duwYLly4oGrf6dOnodfr0bJlyzq1pV27dli1ahWuXLmirM7ds2cPtFotAgIC6nxO7dq1w6ZNm1Tb9u3bV+0cIyMj8de//hUAYDabkZeXh/bt2yvfMRqNVvumR48emDRpkrLN1kpji6ZNm+Ly5cuq88rOzq72PX9/f/j7++PZZ5/FqFGjkJSUhGHDhiEoKAg//fST1fEFVKzCvXnzJg4ePIguXboAqFg9ffHixRrbRURERGQLsy2zrS3MtkRERHS/YbZltrWF2ZaI7jTtvW4AEVFl/v7+GDNmDGJiYrB+/XoUFhbiwIEDWLx4MTZv3myzXMuWLREbG4tx48YhJSUFhYWFSE9PR3JyMgBg8uTJOH/+PEaNGoWMjAwUFBRg27ZtePLJJ6uFtJq0bNkSaWlpOH36tBJY27Rpg/Xr1yM7OxuHDx/G6NGjVat527Zti7CwMMTFxeHAgQPIyspCXFycanVxWFgYQkJCEBUVhW+++QYnTpzA3r178fzzzyMzM9NqW8aMGQM7OzvExsbiyJEj2LlzJ6ZMmYKxY8fW+fFhAPD0008jPz8fM2fORG5uLj755BOsWrVK9Z02bdogNTUVe/fuxdGjRzFx4kScOXOmWt/s378fJ06cwG+//Qaz2Yw2bdogMzMT27ZtQ15eHv7+978jIyOjxvZ069YNDg4OmDdvHgoKCqq159q1a4iPj0d6ejpOnjyJPXv2ICMjA+3atQMAzJ49G3v37kV8fDyys7ORn5+PjRs3Ij4+HkDFP0AGDRqEiRMnYv/+/Th48CAmTJhQ6+puIiIiolvFbMtsy2xLREREfxbMtsy2zLZEdKdxoQIR/eEkJSUhJiYG06dPR0BAAKKiopCRkQEfH58ay7377rt47LHHMGnSJLRt2xZPPfUUrly5AgBo3rw59uzZg/LycoSHhyMwMBDTpk1Dw4YNodXWfSp8/fXXkZqaCm9vb3Tq1AkA8MYbb8DV1RU9evRAREQEBg4cqHqvGQB89NFHcHd3R+/evTFs2DA89dRTcHZ2hp2dHYCKR5Vt2bIFvXv3xpNPPgl/f388/vjjOHnypM3w6uDggG3btuH8+fPo0qULHnvsMYSGhuLtt9+u8/kAFY/V+uKLL5CSkoKOHTvivffew6JFi1TfeeGFFxAUFISBAweib9++aNasGaKiolTfmTFjBnQ6Hdq3b4+mTZvi1KlTmDhxIoYPH46RI0eiW7duOHfunGqVrjWNGjXC6tWrsWXLFgQGBmLt2rVISEhQ9ut0Opw7dw4xMTHw9/fHiBEjMHjwYLz44osAKt5Xt2vXLuTl5aFXr17o1KkT5s+fj+bNmyvHSEpKQvPmzdGnTx8MHz4ccXFxcHNzu6V+IyIiIqoLZltmW2ZbIiIi+rNgtmW2ZbYlojtJI1VfKENERHfdf/7zH3h7e2P79u0IDQ29180hIiIiIrptzLZERERE9GfBbEtEVH+4UIGIqB7s2LEDJSUlCAwMRHFxMWbNmoWioiLk5eXBYDDc6+YREREREdUZsy0RERER/Vkw2xIR3Tv6e90AIqL/BTdu3MC8efNw/PhxODs7o0ePHlizZg3DLhERERHdd5htiYiIiOjPgtmWiOje4RMViIiIiIiIiIiIiIiIiIiIqN5o73UDiIiIiIiIiIiIiIiIiIiI6H8HFyoQERERERERERERERERERFRveFCBSIiIiIiIiIiIiIiIiIiIqo3XKhARERERERERERERERERERE9YYLFYiIiIiIiIiIiIiIiIiIiKjecKECERERERERERERERERERER1RsuVCAiIiIiIiIiIiIiIiIiIqJ6w4UKREREREREREREREREREREVG+4UIGIiIiIiIiIiIiIiIiIiIjqzf8DH5RjArHZmbAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bc33c0",
   "metadata": {
    "papermill": {
     "duration": 0.306566,
     "end_time": "2025-01-08T10:15:33.903222",
     "exception": false,
     "start_time": "2025-01-08T10:15:33.596656",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abfde5c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-08T10:15:34.501514Z",
     "iopub.status.busy": "2025-01-08T10:15:34.501190Z",
     "iopub.status.idle": "2025-01-08T10:41:32.393727Z",
     "shell.execute_reply": "2025-01-08T10:41:32.392761Z"
    },
    "papermill": {
     "duration": 1558.194989,
     "end_time": "2025-01-08T10:41:32.395496",
     "exception": false,
     "start_time": "2025-01-08T10:15:34.200507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 5\n",
      "Random seed: 94\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7246, Accuracy: 0.8529, F1 Micro: 0.8964, F1 Macro: 0.6595\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5992, Accuracy: 0.9492, F1 Micro: 0.962, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5025, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4281, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3712, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3311, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3032, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2839, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.259, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2665, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 25: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 37.99563503265381 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.0002849092765245587\n",
      "Samples above threshold: 38\n",
      "Acquired samples: 38\n",
      "Sampling duration: 10.142042636871338 seconds\n",
      "New train size: 63\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7266, Accuracy: 0.8633, F1 Micro: 0.9025, F1 Macro: 0.6554\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6056, Accuracy: 0.9596, F1 Micro: 0.9695, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4986, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4194, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3656, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3325, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.286, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2773, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2591, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2554, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 63: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 36.982747316360474 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.00025328324991278364\n",
      "Samples above threshold: 34\n",
      "Acquired samples: 34\n",
      "Sampling duration: 9.183547019958496 seconds\n",
      "New train size: 97\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6583, Accuracy: 0.957, F1 Micro: 0.9675, F1 Macro: 0.652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.459, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3594, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3018, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2744, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2437, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2356, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2035, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1886, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.208, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 97: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 42.586870193481445 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.00011673168191919104\n",
      "Samples above threshold: 31\n",
      "Acquired samples: 31\n",
      "Sampling duration: 8.573060750961304 seconds\n",
      "New train size: 128\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6595, Accuracy: 0.9583, F1 Micro: 0.9684, F1 Macro: 0.652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4666, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3383, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2751, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2452, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2367, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2334, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2308, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1864, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1798, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 128: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 42.500325441360474 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 0.00012239873030921446\n",
      "Samples above threshold: 28\n",
      "Acquired samples: 28\n",
      "Sampling duration: 7.991379261016846 seconds\n",
      "New train size: 156\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6059, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3731, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2692, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2419, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2081, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1768, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1801, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1757, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1754, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1705, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 156: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 48.59472465515137 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 9.380435512866825e-05\n",
      "Samples above threshold: 25\n",
      "Acquired samples: 25\n",
      "Sampling duration: 7.22947883605957 seconds\n",
      "New train size: 181\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6093, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3688, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2881, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2434, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1936, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1994, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1843, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1824, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1777, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1687, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 181: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 49.2790105342865 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 8.103032741928484e-05\n",
      "Samples above threshold: 22\n",
      "Acquired samples: 22\n",
      "Sampling duration: 6.7071754932403564 seconds\n",
      "New train size: 203\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5605, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3176, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.222, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.197, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1829, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.163, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.196, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1702, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1797, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1661, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 203: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 54.143383264541626 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 8.703838539076969e-05\n",
      "Samples above threshold: 20\n",
      "Acquired samples: 20\n",
      "Sampling duration: 5.970274925231934 seconds\n",
      "New train size: 223\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5624, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3168, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2203, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.187, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1834, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1633, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.165, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1677, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1576, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1492, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 223: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 54.038745641708374 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 7.507522095693276e-05\n",
      "Samples above threshold: 18\n",
      "Acquired samples: 18\n",
      "Sampling duration: 5.414109706878662 seconds\n",
      "New train size: 241\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.567, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.32, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2431, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1952, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1949, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1747, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1747, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1698, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1588, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1529, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 241: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 56.28496694564819 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 250\n",
      "Threshold: 7.438476313836873e-05\n",
      "Samples above threshold: 16\n",
      "Acquired samples: 9\n",
      "Sampling duration: 5.084963321685791 seconds\n",
      "New train size: 250\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5569, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3323, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.233, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2038, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1718, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1721, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1726, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.151, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1527, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1597, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 250: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 54.34868550300598 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 7.526435510953888e-05\n",
      "Samples above threshold: 15\n",
      "Acquired samples: 15\n",
      "Sampling duration: 4.889181852340698 seconds\n",
      "New train size: 265\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5188, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.277, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.21, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1824, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1653, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1806, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1831, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1675, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1519, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1587, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 265: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 60.54866576194763 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 6.667749112239109e-05\n",
      "Samples above threshold: 14\n",
      "Acquired samples: 14\n",
      "Sampling duration: 4.440120697021484 seconds\n",
      "New train size: 279\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5186, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2781, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2283, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1798, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.172, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1725, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1747, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1576, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1563, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1735, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 279: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.80878806114197 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 9.397041867487133e-05\n",
      "Samples above threshold: 13\n",
      "Acquired samples: 13\n",
      "Sampling duration: 3.9815244674682617 seconds\n",
      "New train size: 292\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5228, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2752, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2211, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1951, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.181, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.18, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.151, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.159, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1569, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1758, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 292: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 60.619908809661865 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 300\n",
      "Threshold: 8.088515896815806e-05\n",
      "Samples above threshold: 11\n",
      "Acquired samples: 8\n",
      "Sampling duration: 3.8117642402648926 seconds\n",
      "New train size: 300\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5257, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2806, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2151, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1902, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1792, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1484, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1628, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1661, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1698, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1665, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 300: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.82522249221802 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 7.568056826130487e-05\n",
      "Samples above threshold: 10\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.8863484859466553 seconds\n",
      "New train size: 310\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5268, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2876, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2215, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.178, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1867, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1869, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1697, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1601, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1618, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1446, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 310: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 60.25228691101074 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 7.157356521929615e-05\n",
      "Samples above threshold: 9\n",
      "Acquired samples: 10\n",
      "Sampling duration: 3.1285605430603027 seconds\n",
      "New train size: 320\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5245, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2747, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2191, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1999, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1843, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1699, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1739, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1675, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1515, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1571, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 320: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 59.640894651412964 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 7.284042148967274e-05\n",
      "Samples above threshold: 8\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.9424362182617188 seconds\n",
      "New train size: 330\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4843, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2521, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.212, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1839, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1772, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.158, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1522, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1553, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1376, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1445, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 330: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.9268536567688 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 8.245695353252813e-05\n",
      "Samples above threshold: 7\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.7673702239990234 seconds\n",
      "New train size: 340\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4912, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.252, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2078, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1734, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1586, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.16, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.174, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1507, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1692, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1482, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 340: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.956393241882324 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 350\n",
      "Threshold: 9.846695320447908e-05\n",
      "Samples above threshold: 6\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.5903778076171875 seconds\n",
      "New train size: 350\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4893, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2535, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2139, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.186, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1711, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1712, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1617, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1705, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1565, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.149, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 350: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 64.67088484764099 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 8.444097984465772e-05\n",
      "Samples above threshold: 5\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.2800395488739014 seconds\n",
      "New train size: 360\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4923, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2501, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2034, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1859, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1729, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1567, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1453, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.144, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1536, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1444, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 360: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.504411935806274 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 7.406280856230298e-05\n",
      "Samples above threshold: 4\n",
      "Acquired samples: 10\n",
      "Sampling duration: 2.131425380706787 seconds\n",
      "New train size: 370\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4884, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2504, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1944, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.179, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1705, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1536, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1526, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1487, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1541, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1639, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 370: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 63.872140407562256 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 9.351277112727985e-05\n",
      "Samples above threshold: 3\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.775507926940918 seconds\n",
      "New train size: 380\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4835, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.248, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1915, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1654, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1629, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1567, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1792, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1643, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1632, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1566, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 380: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 64.32207989692688 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 0.00011722221679519869\n",
      "Samples above threshold: 2\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.499190330505371 seconds\n",
      "New train size: 390\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4542, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2264, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1826, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1766, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1825, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1647, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1696, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1535, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1505, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1488, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 390: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 69.47248792648315 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 400\n",
      "Threshold: 8.057269806158728e-05\n",
      "Samples above threshold: 1\n",
      "Acquired samples: 10\n",
      "Sampling duration: 1.2938523292541504 seconds\n",
      "New train size: 400\n",
      "Launching training on 2 GPUs.\n",
      "DistributedType.MULTI_GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4605, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2259, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1791, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1749, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1843, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1524, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1557, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1576, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.148, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1459, Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "Iteration 400: Accuracy: 0.9661, F1 Micro: 0.9743, F1 Macro: 0.6535\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        1-FR       1.00      1.00      1.00       128\n",
      "        2-GI       0.00      0.00      0.00         4\n",
      "        3-PI       1.00      1.00      1.00       128\n",
      "        4-DM       0.87      1.00      0.93       111\n",
      "     5-EDTRB       0.98      1.00      0.99       126\n",
      "        6-RE       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.96      0.99      0.97       500\n",
      "   macro avg       0.64      0.67      0.65       500\n",
      "weighted avg       0.95      0.99      0.97       500\n",
      " samples avg       0.96      0.99      0.97       500\n",
      "\n",
      "Training completed in 70.25672960281372 s\n",
      "Total sampling time: 107.71 seconds\n",
      "Total runtime: 1557.0801379680634 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[4], 4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6175435,
     "sourceId": 10027613,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7784.391077,
   "end_time": "2025-01-08T10:41:35.937361",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-08T08:31:51.546284",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0193582f43ed4de1b873b90955d68f57": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "03a9e3ec1e4849dfa8b3f185c37c05a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9e7ba73dca6d411fad7b5f425f716bd3",
        "IPY_MODEL_e1ac85b1b8344356aa931754a7551519",
        "IPY_MODEL_dfd25ed4d3574dad9574a53b3eddf4e7"
       ],
       "layout": "IPY_MODEL_fcf11842f53e4b00a284e998c41ebe1e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "07b584bc31c443a890fcb794bcba53ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5e1efb4fa9e5432e970307324955d6cb",
        "IPY_MODEL_c0ee4eff56354fa69f88b6de2bd0fcb2",
        "IPY_MODEL_eba60e03622143df83e080c2efdec79d"
       ],
       "layout": "IPY_MODEL_f56951fd76b74d72b020fa7aef594997",
       "tabbable": null,
       "tooltip": null
      }
     },
     "0bfec68a75374e39a571d7c3e0380f73": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ebf982a3787e4cdc981c83e65c3d15dc",
        "IPY_MODEL_9bdb6076cd7a4d61a11c9d41b43aaf21",
        "IPY_MODEL_38ca088121a14e4ca980f477af6d8765"
       ],
       "layout": "IPY_MODEL_7d4a3bddfdef433faaf059cb488c7bd6",
       "tabbable": null,
       "tooltip": null
      }
     },
     "0efe1a8942f2472387e0af32439b2c71": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0f793ad1e8444111884c55881c25ebc0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "18640e9c73ae43998def4a0bcc8c6297": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "24ad5837955145e1b1eff9f1c71e44d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "25255f9e724f45eaa52617df2074d96d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "29f7a43516c542cba81571f39fd78b83": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2aefd27c50494d5082ba180de9823989": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "38ca088121a14e4ca980f477af6d8765": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7b63bea6bd294d5a9bea80e6951e4f12",
       "placeholder": "​",
       "style": "IPY_MODEL_d509b7f0927345fab5f8e3bebba572bd",
       "tabbable": null,
       "tooltip": null,
       "value": " 498M/498M [00:02&lt;00:00, 205MB/s]"
      }
     },
     "3cd098085a374d8ca5a3f53238a7cf50": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "45f8b5ae918a4cb3a61cfd788f554f90": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "48f9bb20a65d4ebf82e0c9ee8e41f622": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f70fed1c0a3c440a9f965ff08b95a93e",
       "max": 229167.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8710b3b59a9d49f6be18942c3b0272c3",
       "tabbable": null,
       "tooltip": null,
       "value": 229167.0
      }
     },
     "4a4b0cef3b554de3badb981f23589693": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "515a37a7b50d444283f9bf7195a4cdf5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7713e0ee9d854fe39fd754713c7e0bf1",
        "IPY_MODEL_7686aeb854f94ce898bd921edb9ef860",
        "IPY_MODEL_ee94d9c98afb47f9abac129fe4d5b86d"
       ],
       "layout": "IPY_MODEL_29f7a43516c542cba81571f39fd78b83",
       "tabbable": null,
       "tooltip": null
      }
     },
     "5cb73dad21304401b69c1edbb8da63bf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5e1efb4fa9e5432e970307324955d6cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5cb73dad21304401b69c1edbb8da63bf",
       "placeholder": "​",
       "style": "IPY_MODEL_18640e9c73ae43998def4a0bcc8c6297",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "5e5c7f400f2942a6a912ff35fe898da1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5f229e2c29bd4f3bb21bdc32f309eb1d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "61065ec701774823a7a35a7864468eb1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "744911148c674b2fa16ffe1de268a631": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7686aeb854f94ce898bd921edb9ef860": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_45f8b5ae918a4cb3a61cfd788f554f90",
       "max": 112.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a05e33429ea64c6994ae388f3870e861",
       "tabbable": null,
       "tooltip": null,
       "value": 112.0
      }
     },
     "7713e0ee9d854fe39fd754713c7e0bf1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_25255f9e724f45eaa52617df2074d96d",
       "placeholder": "​",
       "style": "IPY_MODEL_0efe1a8942f2472387e0af32439b2c71",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json: 100%"
      }
     },
     "7958c3ae350c4538afeb0bbdc8271c91": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7b63bea6bd294d5a9bea80e6951e4f12": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7d4a3bddfdef433faaf059cb488c7bd6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7e896287dd0840c69368bbea30b4ba7f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8710b3b59a9d49f6be18942c3b0272c3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "89a923bb929c47948e233006fe5a8131": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_aa1d7a3865414152a7999d6ba12a7aae",
        "IPY_MODEL_48f9bb20a65d4ebf82e0c9ee8e41f622",
        "IPY_MODEL_dcbaf3f23ab64492902a6f2b90aff7cc"
       ],
       "layout": "IPY_MODEL_0193582f43ed4de1b873b90955d68f57",
       "tabbable": null,
       "tooltip": null
      }
     },
     "91c96788820446978eef62a034f25985": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9bdb6076cd7a4d61a11c9d41b43aaf21": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5e5c7f400f2942a6a912ff35fe898da1",
       "max": 497810400.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b54e7fd74643431db76575bba11cc80d",
       "tabbable": null,
       "tooltip": null,
       "value": 497810400.0
      }
     },
     "9e7ba73dca6d411fad7b5f425f716bd3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_df7367c3d7b547a083c2bb6d168c2f4b",
       "placeholder": "​",
       "style": "IPY_MODEL_eb639c7f0c764f0c9589b10641f7c5ce",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "9f4d9d4daf6e4b9fb0d2ca152b75cd9a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a05e33429ea64c6994ae388f3870e861": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a34502fd353747fd8957f5a2d452f106": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aa1d7a3865414152a7999d6ba12a7aae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_91c96788820446978eef62a034f25985",
       "placeholder": "​",
       "style": "IPY_MODEL_61065ec701774823a7a35a7864468eb1",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: 100%"
      }
     },
     "b54e7fd74643431db76575bba11cc80d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c0ee4eff56354fa69f88b6de2bd0fcb2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a34502fd353747fd8957f5a2d452f106",
       "max": 1534.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_744911148c674b2fa16ffe1de268a631",
       "tabbable": null,
       "tooltip": null,
       "value": 1534.0
      }
     },
     "ca866104ce884b32b2b15e24e8f922ef": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d509b7f0927345fab5f8e3bebba572bd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d6b6b3e7e8564906a18ca4aaba371010": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "dc32d2cfa29242d9869e943749f1b5aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "dcbaf3f23ab64492902a6f2b90aff7cc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ca866104ce884b32b2b15e24e8f922ef",
       "placeholder": "​",
       "style": "IPY_MODEL_9f4d9d4daf6e4b9fb0d2ca152b75cd9a",
       "tabbable": null,
       "tooltip": null,
       "value": " 229k/229k [00:00&lt;00:00, 5.59MB/s]"
      }
     },
     "df7367c3d7b547a083c2bb6d168c2f4b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dfd25ed4d3574dad9574a53b3eddf4e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2aefd27c50494d5082ba180de9823989",
       "placeholder": "​",
       "style": "IPY_MODEL_24ad5837955145e1b1eff9f1c71e44d0",
       "tabbable": null,
       "tooltip": null,
       "value": " 2.00/2.00 [00:00&lt;00:00, 198B/s]"
      }
     },
     "e1ac85b1b8344356aa931754a7551519": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3cd098085a374d8ca5a3f53238a7cf50",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d6b6b3e7e8564906a18ca4aaba371010",
       "tabbable": null,
       "tooltip": null,
       "value": 2.0
      }
     },
     "eb639c7f0c764f0c9589b10641f7c5ce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "eba60e03622143df83e080c2efdec79d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0f793ad1e8444111884c55881c25ebc0",
       "placeholder": "​",
       "style": "IPY_MODEL_7958c3ae350c4538afeb0bbdc8271c91",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.53k/1.53k [00:00&lt;00:00, 168kB/s]"
      }
     },
     "ebf982a3787e4cdc981c83e65c3d15dc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5f229e2c29bd4f3bb21bdc32f309eb1d",
       "placeholder": "​",
       "style": "IPY_MODEL_dc32d2cfa29242d9869e943749f1b5aa",
       "tabbable": null,
       "tooltip": null,
       "value": "pytorch_model.bin: 100%"
      }
     },
     "ee94d9c98afb47f9abac129fe4d5b86d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4a4b0cef3b554de3badb981f23589693",
       "placeholder": "​",
       "style": "IPY_MODEL_7e896287dd0840c69368bbea30b4ba7f",
       "tabbable": null,
       "tooltip": null,
       "value": " 112/112 [00:00&lt;00:00, 11.0kB/s]"
      }
     },
     "f56951fd76b74d72b020fa7aef594997": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f70fed1c0a3c440a9f965ff08b95a93e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fcf11842f53e4b00a284e998c41ebe1e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
