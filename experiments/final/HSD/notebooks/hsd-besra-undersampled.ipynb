{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1264c102",
   "metadata": {
    "papermill": {
     "duration": 0.012361,
     "end_time": "2025-05-10T12:28:42.333041",
     "exception": false,
     "start_time": "2025-05-10T12:28:42.320680",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "339ba0f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T12:28:42.356268Z",
     "iopub.status.busy": "2025-05-10T12:28:42.355808Z",
     "iopub.status.idle": "2025-05-10T12:29:18.447884Z",
     "shell.execute_reply": "2025-05-10T12:29:18.447113Z"
    },
    "papermill": {
     "duration": 36.105627,
     "end_time": "2025-05-10T12:29:18.449712",
     "exception": false,
     "start_time": "2025-05-10T12:28:42.344085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from collections import defaultdict\n",
    "from scipy.stats import beta\n",
    "from scipy.special import betaln\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a12dbfb",
   "metadata": {
    "papermill": {
     "duration": 0.011012,
     "end_time": "2025-05-10T12:29:18.472489",
     "exception": false,
     "start_time": "2025-05-10T12:29:18.461477",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f37c4dd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T12:29:18.496449Z",
     "iopub.status.busy": "2025-05-10T12:29:18.495833Z",
     "iopub.status.idle": "2025-05-10T12:29:18.499900Z",
     "shell.execute_reply": "2025-05-10T12:29:18.499033Z"
    },
    "papermill": {
     "duration": 0.017622,
     "end_time": "2025-05-10T12:29:18.501228",
     "exception": false,
     "start_time": "2025-05-10T12:29:18.483606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "670fe8a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T12:29:18.524303Z",
     "iopub.status.busy": "2025-05-10T12:29:18.524043Z",
     "iopub.status.idle": "2025-05-10T12:29:18.528090Z",
     "shell.execute_reply": "2025-05-10T12:29:18.527325Z"
    },
    "papermill": {
     "duration": 0.017082,
     "end_time": "2025-05-10T12:29:18.529560",
     "exception": false,
     "start_time": "2025-05-10T12:29:18.512478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/working/results') == False:\n",
    "    os.mkdir('/kaggle/working/results')\n",
    "\n",
    "if os.path.exists('/kaggle/working/acquired_data') == False:\n",
    "    os.mkdir('/kaggle/working/acquired_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "478ed3f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T12:29:18.551793Z",
     "iopub.status.busy": "2025-05-10T12:29:18.551559Z",
     "iopub.status.idle": "2025-05-10T12:29:18.565265Z",
     "shell.execute_reply": "2025-05-10T12:29:18.564381Z"
    },
    "papermill": {
     "duration": 0.026715,
     "end_time": "2025-05-10T12:29:18.566834",
     "exception": false,
     "start_time": "2025-05-10T12:29:18.540119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f0b312",
   "metadata": {
    "papermill": {
     "duration": 0.011224,
     "end_time": "2025-05-10T12:29:18.588919",
     "exception": false,
     "start_time": "2025-05-10T12:29:18.577695",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "094553c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T12:29:18.611796Z",
     "iopub.status.busy": "2025-05-10T12:29:18.611515Z",
     "iopub.status.idle": "2025-05-10T12:29:18.671039Z",
     "shell.execute_reply": "2025-05-10T12:29:18.669357Z"
    },
    "papermill": {
     "duration": 0.073458,
     "end_time": "2025-05-10T12:29:18.673198",
     "exception": false,
     "start_time": "2025-05-10T12:29:18.599740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Shared resources\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "data_used = manager.list()\n",
    "sampling_dur = manager.list()\n",
    "new_samples = manager.list()\n",
    "\n",
    "# Non shared resources\n",
    "filename = 'hsd-besra'\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "sequence_length = 80"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6458f47c",
   "metadata": {
    "papermill": {
     "duration": 0.010442,
     "end_time": "2025-05-10T12:29:18.694647",
     "exception": false,
     "start_time": "2025-05-10T12:29:18.684205",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebddeb6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T12:29:18.717738Z",
     "iopub.status.busy": "2025-05-10T12:29:18.717439Z",
     "iopub.status.idle": "2025-05-10T12:29:18.827135Z",
     "shell.execute_reply": "2025-05-10T12:29:18.826215Z"
    },
    "papermill": {
     "duration": 0.123424,
     "end_time": "2025-05-10T12:29:18.828487",
     "exception": false,
     "start_time": "2025-05-10T12:29:18.705063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (3328, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>HS</th>\n",
       "      <th>Abusive</th>\n",
       "      <th>HS_Individual</th>\n",
       "      <th>HS_Group</th>\n",
       "      <th>HS_Religion</th>\n",
       "      <th>HS_Race</th>\n",
       "      <th>HS_Physical</th>\n",
       "      <th>HS_Gender</th>\n",
       "      <th>HS_Other</th>\n",
       "      <th>HS_Weak</th>\n",
       "      <th>HS_Moderate</th>\n",
       "      <th>HS_Strong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USER USER USER USER BANCI KALENG MALU GA BISA ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USER Bu guru enakan jadi jablay atau guru esde...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jadi cowo itu harus Gantle kalo ga Gantle itu ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USER Awaasss... Jgn sampe beritanya sampe ke a...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USER udah biasa kali. Gue kpoper tapi kalo ngo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  HS  Abusive  \\\n",
       "0  USER USER USER USER BANCI KALENG MALU GA BISA ...   1        1   \n",
       "1  USER Bu guru enakan jadi jablay atau guru esde...   1        1   \n",
       "2  Jadi cowo itu harus Gantle kalo ga Gantle itu ...   1        1   \n",
       "3  USER Awaasss... Jgn sampe beritanya sampe ke a...   1        1   \n",
       "4  USER udah biasa kali. Gue kpoper tapi kalo ngo...   1        1   \n",
       "\n",
       "   HS_Individual  HS_Group  HS_Religion  HS_Race  HS_Physical  HS_Gender  \\\n",
       "0              1         0            0        0            0          1   \n",
       "1              1         0            0        0            0          1   \n",
       "2              0         1            0        0            0          1   \n",
       "3              1         0            0        0            1          0   \n",
       "4              1         0            0        0            0          1   \n",
       "\n",
       "   HS_Other  HS_Weak  HS_Moderate  HS_Strong  \n",
       "0         0        1            0          0  \n",
       "1         0        1            0          0  \n",
       "2         0        0            1          0  \n",
       "3         0        1            0          0  \n",
       "4         0        1            0          0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/kaggle/input/multi-label-hate-speech/undersampled.csv', encoding='latin-1')\n",
    "\n",
    "alay_dict = pd.read_csv('/kaggle/input/multi-label-hate-speech/new_kamusalay.csv', encoding='latin-1', header=None)\n",
    "alay_dict = alay_dict.rename(columns={0: 'original', \n",
    "                                      1: 'replacement'})\n",
    "\n",
    "print(\"Shape: \", data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8aaab7fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T12:29:18.852653Z",
     "iopub.status.busy": "2025-05-10T12:29:18.852386Z",
     "iopub.status.idle": "2025-05-10T12:29:18.862776Z",
     "shell.execute_reply": "2025-05-10T12:29:18.861999Z"
    },
    "papermill": {
     "duration": 0.02362,
     "end_time": "2025-05-10T12:29:18.864071",
     "exception": false,
     "start_time": "2025-05-10T12:29:18.840451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>HS</th>\n",
       "      <th>Abusive</th>\n",
       "      <th>HS_Individual</th>\n",
       "      <th>HS_Group</th>\n",
       "      <th>HS_Religion</th>\n",
       "      <th>HS_Race</th>\n",
       "      <th>HS_Physical</th>\n",
       "      <th>HS_Gender</th>\n",
       "      <th>HS_Other</th>\n",
       "      <th>HS_Weak</th>\n",
       "      <th>HS_Moderate</th>\n",
       "      <th>HS_Strong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USER USER USER USER BANCI KALENG MALU GA BISA ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USER Bu guru enakan jadi jablay atau guru esde...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jadi cowo itu harus Gantle kalo ga Gantle itu ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USER Awaasss... Jgn sampe beritanya sampe ke a...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USER udah biasa kali. Gue kpoper tapi kalo ngo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  HS  Abusive  \\\n",
       "0  USER USER USER USER BANCI KALENG MALU GA BISA ...   1        1   \n",
       "1  USER Bu guru enakan jadi jablay atau guru esde...   1        1   \n",
       "2  Jadi cowo itu harus Gantle kalo ga Gantle itu ...   1        1   \n",
       "3  USER Awaasss... Jgn sampe beritanya sampe ke a...   1        1   \n",
       "4  USER udah biasa kali. Gue kpoper tapi kalo ngo...   1        1   \n",
       "\n",
       "   HS_Individual  HS_Group  HS_Religion  HS_Race  HS_Physical  HS_Gender  \\\n",
       "0              1         0            0        0            0          1   \n",
       "1              1         0            0        0            0          1   \n",
       "2              0         1            0        0            0          1   \n",
       "3              1         0            0        0            1          0   \n",
       "4              1         0            0        0            0          1   \n",
       "\n",
       "   HS_Other  HS_Weak  HS_Moderate  HS_Strong  \n",
       "0         0        1            0          0  \n",
       "1         0        1            0          0  \n",
       "2         0        0            1          0  \n",
       "3         0        1            0          0  \n",
       "4         0        1            0          0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d478d1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T12:29:18.888513Z",
     "iopub.status.busy": "2025-05-10T12:29:18.888227Z",
     "iopub.status.idle": "2025-05-10T12:29:18.903161Z",
     "shell.execute_reply": "2025-05-10T12:29:18.902444Z"
    },
    "papermill": {
     "duration": 0.028437,
     "end_time": "2025-05-10T12:29:18.904409",
     "exception": false,
     "start_time": "2025-05-10T12:29:18.875972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HS\n",
       "0    1882\n",
       "1    1446\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.HS.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a605397",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T12:29:18.929121Z",
     "iopub.status.busy": "2025-05-10T12:29:18.928870Z",
     "iopub.status.idle": "2025-05-10T12:29:18.934942Z",
     "shell.execute_reply": "2025-05-10T12:29:18.934166Z"
    },
    "papermill": {
     "duration": 0.020022,
     "end_time": "2025-05-10T12:29:18.936445",
     "exception": false,
     "start_time": "2025-05-10T12:29:18.916423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Abusive\n",
       "0    1882\n",
       "1    1446\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Abusive.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0738249b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T12:29:18.961718Z",
     "iopub.status.busy": "2025-05-10T12:29:18.961476Z",
     "iopub.status.idle": "2025-05-10T12:29:18.975825Z",
     "shell.execute_reply": "2025-05-10T12:29:18.974916Z"
    },
    "papermill": {
     "duration": 0.028556,
     "end_time": "2025-05-10T12:29:18.977367",
     "exception": false,
     "start_time": "2025-05-10T12:29:18.948811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxic shape:  (1888, 13)\n",
      "Non-toxic shape:  (1440, 13)\n"
     ]
    }
   ],
   "source": [
    "print(\"Toxic shape: \", data[(data['HS'] == 1) | (data['Abusive'] == 1)].shape)\n",
    "print(\"Non-toxic shape: \", data[(data['HS'] == 0) & (data['Abusive'] == 0)].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7049be55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T12:29:19.003062Z",
     "iopub.status.busy": "2025-05-10T12:29:19.002807Z",
     "iopub.status.idle": "2025-05-10T12:29:19.012046Z",
     "shell.execute_reply": "2025-05-10T12:29:19.011320Z"
    },
    "papermill": {
     "duration": 0.02272,
     "end_time": "2025-05-10T12:29:19.013515",
     "exception": false,
     "start_time": "2025-05-10T12:29:18.990795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (15167, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>replacement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anakjakartaasikasik</td>\n",
       "      <td>anak jakarta asyik asyik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pakcikdahtua</td>\n",
       "      <td>pak cik sudah tua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pakcikmudalagi</td>\n",
       "      <td>pak cik muda lagi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t3tapjokowi</td>\n",
       "      <td>tetap jokowi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3x</td>\n",
       "      <td>tiga kali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aamiin</td>\n",
       "      <td>amin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aamiinn</td>\n",
       "      <td>amin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aamin</td>\n",
       "      <td>amin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aammiin</td>\n",
       "      <td>amin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>abis</td>\n",
       "      <td>habis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>abisin</td>\n",
       "      <td>habiskan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>acau</td>\n",
       "      <td>kacau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>achok</td>\n",
       "      <td>ahok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ad</td>\n",
       "      <td>ada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>adek</td>\n",
       "      <td>adik</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               original               replacement\n",
       "0   anakjakartaasikasik  anak jakarta asyik asyik\n",
       "1          pakcikdahtua         pak cik sudah tua\n",
       "2        pakcikmudalagi         pak cik muda lagi\n",
       "3           t3tapjokowi              tetap jokowi\n",
       "4                    3x                 tiga kali\n",
       "5                aamiin                      amin\n",
       "6               aamiinn                      amin\n",
       "7                 aamin                      amin\n",
       "8               aammiin                      amin\n",
       "9                  abis                     habis\n",
       "10               abisin                  habiskan\n",
       "11                 acau                     kacau\n",
       "12                achok                      ahok\n",
       "13                   ad                       ada\n",
       "14                 adek                      adik"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape: \", alay_dict.shape)\n",
    "alay_dict.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f118390",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T12:29:19.038715Z",
     "iopub.status.busy": "2025-05-10T12:29:19.038507Z",
     "iopub.status.idle": "2025-05-10T12:29:19.051885Z",
     "shell.execute_reply": "2025-05-10T12:29:19.051045Z"
    },
    "papermill": {
     "duration": 0.026826,
     "end_time": "2025-05-10T12:29:19.053177",
     "exception": false,
     "start_time": "2025-05-10T12:29:19.026351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove_nonaplhanumeric:  Halooo duniaa \n",
      "lowercase:  halooo, duniaa!\n",
      "remove_unnecessary_char:  Hehe RT USER USER apa kabs hehe URL \n",
      "normalize_alay:  amin adik habis\n"
     ]
    }
   ],
   "source": [
    "def lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_unnecessary_char(text):\n",
    "    text = re.sub('\\n',' ',text) # Remove every '\\n'\n",
    "    text = re.sub('rt',' ',text) # Remove every retweet symbol\n",
    "    text = re.sub('user',' ',text) # Remove every username\n",
    "    text = re.sub('url', ' ', text) # Remove every URL\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+)|(http?://[^\\s]+))',' ',text) # Remove every URL\n",
    "    text = re.sub(r'\\b(?:x[a-fA-F0-9]{2}\\s*)+\\b', '', text) # Remove emoji bytecode\n",
    "    text = re.sub('  +', ' ', text) # Remove extra spaces\n",
    "    return text\n",
    "    \n",
    "def remove_nonaplhanumeric(text):\n",
    "    text = re.sub('[^0-9a-zA-Z]+', ' ', text) \n",
    "    return text\n",
    "\n",
    "alay_dict_map = dict(zip(alay_dict['original'], alay_dict['replacement']))\n",
    "def normalize_alay(text):\n",
    "    return ' '.join([alay_dict_map[word] if word in alay_dict_map else word for word in text.split(' ')])\n",
    "\n",
    "print(\"remove_nonaplhanumeric: \", remove_nonaplhanumeric(\"Halooo,,,,, duniaa \\x8f \\xd2\\1 !!\"))\n",
    "print(\"lowercase: \", lowercase(\"Halooo, duniaa!\"))\n",
    "print(\"remove_unnecessary_char: \", remove_unnecessary_char(\"Hehe\\n\\n RT USER USER apa kabs www.google.com\\n  hehe URL xf8 x2a x89\"))\n",
    "print(\"normalize_alay: \", normalize_alay(\"aamiin adek abis\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be5de582",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T12:29:19.077236Z",
     "iopub.status.busy": "2025-05-10T12:29:19.076968Z",
     "iopub.status.idle": "2025-05-10T12:29:19.080569Z",
     "shell.execute_reply": "2025-05-10T12:29:19.079856Z"
    },
    "papermill": {
     "duration": 0.01721,
     "end_time": "2025-05-10T12:29:19.081756",
     "exception": false,
     "start_time": "2025-05-10T12:29:19.064546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = lowercase(text)\n",
    "    text = remove_nonaplhanumeric(text)\n",
    "    text = remove_unnecessary_char(text)\n",
    "    text = normalize_alay(text) \n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f86edff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T12:29:19.106105Z",
     "iopub.status.busy": "2025-05-10T12:29:19.105870Z",
     "iopub.status.idle": "2025-05-10T12:29:19.215091Z",
     "shell.execute_reply": "2025-05-10T12:29:19.214268Z"
    },
    "papermill": {
     "duration": 0.122999,
     "end_time": "2025-05-10T12:29:19.216511",
     "exception": false,
     "start_time": "2025-05-10T12:29:19.093512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2662,) (2662, 12)\n",
      "(666,) (666, 12)\n"
     ]
    }
   ],
   "source": [
    "data['Tweet'] = data['Tweet'].apply(preprocess)\n",
    "\n",
    "# Define the labels columns for multi-label classification\n",
    "label_columns = data.columns[1:]  # Assuming label columns start from the third column\n",
    "\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['Tweet'].values\n",
    "y_train = train_data[label_columns].values\n",
    "X_val = val_data['Tweet'].values\n",
    "y_val = val_data[label_columns].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8dd0f0",
   "metadata": {
    "papermill": {
     "duration": 0.012135,
     "end_time": "2025-05-10T12:29:19.241424",
     "exception": false,
     "start_time": "2025-05-10T12:29:19.229289",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BUILD DATASET & DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26c01221",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T12:29:19.266652Z",
     "iopub.status.busy": "2025-05-10T12:29:19.266360Z",
     "iopub.status.idle": "2025-05-10T12:29:20.061948Z",
     "shell.execute_reply": "2025-05-10T12:29:20.060974Z"
    },
    "papermill": {
     "duration": 0.809936,
     "end_time": "2025-05-10T12:29:20.063538",
     "exception": false,
     "start_time": "2025-05-10T12:29:19.253602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5edf60a372c34cb88f049b8b9922283b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec834e2897c445d792d55e6c0b2a0e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6abecfa16604459b6d6d5cb8c814f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f34cc2cef372450c88da78f27b374848",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class HateSpeechDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=64, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        labels = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(labels, dtype=torch.float if self.use_float else torch.long)\n",
    "        return item\n",
    "\n",
    "    def get_per_class_probs(self):\n",
    "        \"\"\"\n",
    "        Calculate the spread of labels (0 and 1) for each class in the dataset.\n",
    "        Returns:\n",
    "            dict: A dictionary where keys are class indices and values are [count_0, count_1].\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize a dictionary to store counts for each class\n",
    "        label_counts = defaultdict(lambda: [0, 0])  # [count_0, count_1] for each class\n",
    "\n",
    "        for i in range(len(self)):\n",
    "            # Get the labels for the i-th sample\n",
    "            labels = self[i]['labels']\n",
    "\n",
    "            # Update counts for each class\n",
    "            for class_idx, label in enumerate(labels):\n",
    "                label_counts[class_idx][int(label)] += 1\n",
    "\n",
    "        for key in label_counts.keys():\n",
    "            total = sum(label_counts[key])\n",
    "            label_counts[key] = [x / total for x in label_counts[key]]\n",
    "\n",
    "        return label_counts\n",
    "\n",
    "    def get_global_probs(self):\n",
    "        \"\"\"\n",
    "        Calculate the global count of 0s and 1s across all classes in the dataset.\n",
    "        Returns:\n",
    "            dict: A dictionary with keys '0' and '1' representing their global counts.\n",
    "        \"\"\"\n",
    "        global_counts = {'0': 0, '1': 0}\n",
    "\n",
    "        for i in range(len(self)):\n",
    "            # Get the labels for the i-th sample\n",
    "            labels = self[i]['labels']\n",
    "\n",
    "            # Update global counts\n",
    "            for label in labels:\n",
    "                global_counts[str(int(label))] += 1\n",
    "\n",
    "        total = global_counts['0'] + global_counts['1']\n",
    "        for key in global_counts.keys():\n",
    "            global_counts[key] /= total\n",
    "\n",
    "        return global_counts\n",
    "\n",
    "\n",
    "# Initialize BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c07e142",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T12:29:20.090536Z",
     "iopub.status.busy": "2025-05-10T12:29:20.090235Z",
     "iopub.status.idle": "2025-05-10T12:29:20.094770Z",
     "shell.execute_reply": "2025-05-10T12:29:20.094102Z"
    },
    "papermill": {
     "duration": 0.019368,
     "end_time": "2025-05-10T12:29:20.096024",
     "exception": false,
     "start_time": "2025-05-10T12:29:20.076656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataloaders(X_train, y_train, X_val, y_val, sequence_length=64, num_workers=4):\n",
    "    train_dataset = HateSpeechDataset(X_train, y_train, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = HateSpeechDataset(X_val, y_val, tokenizer, max_length=sequence_length)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c9f3ec",
   "metadata": {
    "papermill": {
     "duration": 0.012023,
     "end_time": "2025-05-10T12:29:20.120947",
     "exception": false,
     "start_time": "2025-05-10T12:29:20.108924",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14dded73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T12:29:20.146466Z",
     "iopub.status.busy": "2025-05-10T12:29:20.146171Z",
     "iopub.status.idle": "2025-05-10T12:29:20.150304Z",
     "shell.execute_reply": "2025-05-10T12:29:20.149391Z"
    },
    "papermill": {
     "duration": 0.018532,
     "end_time": "2025-05-10T12:29:20.151581",
     "exception": false,
     "start_time": "2025-05-10T12:29:20.133049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47b9a12e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T12:29:20.177321Z",
     "iopub.status.busy": "2025-05-10T12:29:20.177067Z",
     "iopub.status.idle": "2025-05-10T12:29:20.182110Z",
     "shell.execute_reply": "2025-05-10T12:29:20.181363Z"
    },
    "papermill": {
     "duration": 0.019237,
     "end_time": "2025-05-10T12:29:20.183393",
     "exception": false,
     "start_time": "2025-05-10T12:29:20.164156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        target_names=['HS', 'Abusive', 'HS_Individual', 'HS_Group', 'HS_Religion', 'HS_Race', 'HS_Physical', 'HS_Gender', 'HS_Other', 'HS_Weak', 'HS_Moderate', 'HS_Strong'],\n",
    "        zero_division=0\n",
    "    )   \n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da744a93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T12:29:20.209075Z",
     "iopub.status.busy": "2025-05-10T12:29:20.208824Z",
     "iopub.status.idle": "2025-05-10T12:29:20.221616Z",
     "shell.execute_reply": "2025-05-10T12:29:20.220972Z"
    },
    "papermill": {
     "duration": 0.027081,
     "end_time": "2025-05-10T12:29:20.222814",
     "exception": false,
     "start_time": "2025-05-10T12:29:20.195733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, metrics, trials, i):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "\n",
    "    # Define DataLoaders\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    train_loader, val_loader = get_dataloaders(current_X_train, current_y_train, X_val, y_val)\n",
    "\n",
    "    with accelerator.main_process_first():\n",
    "        model = BertForSequenceClassification.from_pretrained(\n",
    "            'indobenchmark/indobert-base-p1',\n",
    "            num_labels=len(label_columns),\n",
    "            problem_type=\"multi_label_classification\"\n",
    "        )\n",
    "        \n",
    "    # Define optimizer and loss function\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Prepare everything with Accelerator\n",
    "    model, optimizer, train_loader, val_loader = accelerator.prepare(\n",
    "        model, optimizer, train_loader, val_loader\n",
    "    )\n",
    "\n",
    "    best_result = None\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key != 'labels'}\n",
    "            labels = batch['labels']\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key != 'labels'}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "        result = compute_metrics(type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}))\n",
    "\n",
    "        if best_result is None or result['f1_micro'] >= best_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "\n",
    "            nearest_cp = current_train_size\n",
    "            if nearest_cp not in checkpoints:\n",
    "                for cp in checkpoints:\n",
    "                    if cp > current_train_size:\n",
    "                        nearest_cp = cp\n",
    "                        break\n",
    "            percentage = math.ceil(nearest_cp / total_data * 100)\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'{filename}-{trials+1}-model-{i+1}-{percentage}',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "            best_result = result\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    accelerator.print(f\"Model {i+1} - Iteration {current_train_size}: Accuracy: {round(best_result['accuracy'], 4)}, F1 Micro: {round(best_result['f1_micro'], 4)}, F1 Macro: {round(best_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(best_result['report'])\n",
    "        \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    accelerator.print(f\"Training completed in {duration} s\")\n",
    "    \n",
    "    # Update the shared lists\n",
    "    if accelerator.is_local_main_process:\n",
    "        metrics[0].append(best_result['accuracy'])\n",
    "        metrics[1].append(best_result['f1_micro'])\n",
    "        metrics[2].append(best_result['f1_macro'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df70be0",
   "metadata": {
    "papermill": {
     "duration": 0.011973,
     "end_time": "2025-05-10T12:29:20.247203",
     "exception": false,
     "start_time": "2025-05-10T12:29:20.235230",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PLOT RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc93a757",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T12:29:20.272192Z",
     "iopub.status.busy": "2025-05-10T12:29:20.271951Z",
     "iopub.status.idle": "2025-05-10T12:29:20.277082Z",
     "shell.execute_reply": "2025-05-10T12:29:20.276514Z"
    },
    "papermill": {
     "duration": 0.01881,
     "end_time": "2025-05-10T12:29:20.278510",
     "exception": false,
     "start_time": "2025-05-10T12:29:20.259700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9e5d7f",
   "metadata": {
    "papermill": {
     "duration": 0.011512,
     "end_time": "2025-05-10T12:29:20.302034",
     "exception": false,
     "start_time": "2025-05-10T12:29:20.290522",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QUERY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbfe2b31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T12:29:20.327904Z",
     "iopub.status.busy": "2025-05-10T12:29:20.327614Z",
     "iopub.status.idle": "2025-05-10T12:29:20.351264Z",
     "shell.execute_reply": "2025-05-10T12:29:20.350558Z"
    },
    "papermill": {
     "duration": 0.038393,
     "end_time": "2025-05-10T12:29:20.352518",
     "exception": false,
     "start_time": "2025-05-10T12:29:20.314125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def beta_score(p, y, alpha=0.1, beta=3):\n",
    "    \"\"\"Calculates Beta score for a given probability p and label y.\"\"\"\n",
    "    \n",
    "    if y == 1:\n",
    "        return -betaln(alpha, beta + 1) + betaln(alpha + p, beta + 1 - p)\n",
    "    elif y == 0:\n",
    "        return -betaln(alpha + 1, beta) + betaln(alpha + 1 - p, beta + p)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid label: y must be 0 or 1.\")\n",
    "\n",
    "def bayesian_update(prior, likelihood, evidence, alpha=0.1, beta_param=3):\n",
    "    \"\"\" \n",
    "    Bayes' Theorem: P(y'|x') = P(x'|y') * P(y') / P(x')\n",
    "    P(y'|x') or likelihood = model probs\n",
    "    p(y') or prior = class probabilities\n",
    "    p(x') or evidence = 1 / number of data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Using the Beta score to simulate the posterior\n",
    "    posterior = (likelihood * prior) / evidence\n",
    "    \n",
    "    # We calculate the posterior using the Beta distribution\n",
    "    return posterior\n",
    "\n",
    "def compute_expected_score_change(predicted_prob, class_probs, label_probs, class_idx):\n",
    "    scores_before = []\n",
    "    scores_after = []\n",
    "\n",
    "    # Before data addition: calculate Beta score for predicted prob\n",
    "    scores_before.append(beta_score(predicted_prob, int(1 if predicted_prob >= 0.5 else 0)))\n",
    "    scores_before.append(beta_score(1-predicted_prob, int(1 if predicted_prob >= 0.5 else 0)))\n",
    "    \n",
    "    # After data addition: use Bayesian update (posterior probability)\n",
    "    for k in range(2):\n",
    "        prior = predicted_prob\n",
    "        likelihood = class_probs[class_idx][k]  # Likelihood is the true label (0 or 1)\n",
    "        posterior = bayesian_update(prior, likelihood, 1)\n",
    "        scores_after.append(beta_score(posterior, int(1 if posterior >= 0.5 else 0)))\n",
    "\n",
    "    score_diff_0 = scores_after[0] - scores_before[0]\n",
    "    score_diff_1 = scores_after[1] - scores_before[1]\n",
    "    return label_probs['0'] * score_diff_0 + label_probs['1'] * score_diff_1\n",
    "\n",
    "# Function to compute Expected Score Change (∆Q)\n",
    "def besra_sampling(models, X_pool, train_indices, remaining_indices, tokenizer, sampling_dur, new_samples, trials, n_clusters=min_increment):\n",
    "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "    device = accelerator.device\n",
    "    \n",
    "    dataset = HateSpeechDataset(X_pool, np.zeros((len(X_pool), 12)), tokenizer, max_length=sequence_length)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    current_train_size = len(train_indices)\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    labeled_dataset = HateSpeechDataset(current_X_train, current_y_train, tokenizer, max_length=sequence_length)\n",
    "    label_probs = labeled_dataset.get_global_probs()\n",
    "    class_probs = labeled_dataset.get_per_class_probs()\n",
    "\n",
    "    for model in models:\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "    start_time = time.time()\n",
    "    score_changes = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids'].to(model.device)\n",
    "        attention_mask = batch['attention_mask'].to(model.device)\n",
    "        labels = batch['labels'].to(model.device)\n",
    "\n",
    "        model_probs = []\n",
    "\n",
    "        for model in models:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(input_ids, attention_mask=attention_mask)\n",
    "                logits = outputs.logits\n",
    "                probs = torch.sigmoid(logits)  # Multi-label classification uses sigmoid\n",
    "                model_probs.append(probs.unsqueeze(0))  # Add batch dimension for averaging\n",
    "        \n",
    "        # Stack all model predictions and compute the mean across models\n",
    "        model_probs = torch.cat(model_probs, dim=0)  # Concatenate predictions across models\n",
    "        probs = model_probs.mean(dim=0)  # Take the mean along the model axis\n",
    "\n",
    "        # Calculate Beta scores before and after data addition\n",
    "        for i in range(len(probs)):\n",
    "            score_diff = []\n",
    "            for class_idx in range(probs.shape[1]):\n",
    "                predicted_prob = probs[i, class_idx].item()\n",
    "                score_diff.append(compute_expected_score_change(predicted_prob, class_probs, label_probs, class_idx))\n",
    "            \n",
    "            score_changes.append(np.mean(score_diff))\n",
    "    \n",
    "    accelerator.wait_for_everyone()    \n",
    "    if accelerator.is_local_main_process:\n",
    "        score_changes = np.array(score_changes)\n",
    "        score_changes = score_changes.reshape(-1, 1)\n",
    "\n",
    "        target_samples = math.ceil(0.1 * len(X_pool))\n",
    "        collected_indices = set()\n",
    "        thresholds = []\n",
    "    \n",
    "        # Check nearest checkpoint\n",
    "        nearest_cp = 0\n",
    "        arrived_at_cp = False\n",
    "        for cp in checkpoints:\n",
    "            if cp > current_train_size:\n",
    "                nearest_cp = cp\n",
    "                break\n",
    "\n",
    "        # Determine number of maximum samples to be acquired\n",
    "        if target_samples <= n_clusters and n_clusters < nearest_cp - current_train_size:\n",
    "            target_samples = n_clusters\n",
    "        elif target_samples > n_clusters and target_samples < nearest_cp - current_train_size:\n",
    "            target_samples = target_samples\n",
    "        else:\n",
    "            arrived_at_cp = True\n",
    "            target_samples = nearest_cp - current_train_size\n",
    "\n",
    "        # No clustering needed when there's little data left\n",
    "        if current_train_size >= checkpoints[len(checkpoints)-1] - min_increment:\n",
    "            end_time = time.time()\n",
    "            duration = end_time - start_time\n",
    "            \n",
    "            temp = train_indices.copy()\n",
    "            temp.extend(remaining_indices)\n",
    "            \n",
    "            # Save acquired data up to checkpoint\n",
    "            acquired_data = pd.DataFrame({\n",
    "                'processed_text': [X_train[i] for i in temp],\n",
    "                'HS': [y_train[i][0] for i in temp],\n",
    "                'Abusive': [y_train[i][1] for i in temp],\n",
    "                'HS_Individual': [y_train[i][2] for i in temp],\n",
    "                'HS_Group': [y_train[i][3] for i in temp],\n",
    "                'HS_Religion': [y_train[i][4] for i in temp],\n",
    "                'HS_Race': [y_train[i][5] for i in temp],\n",
    "                'HS_Physical': [y_train[i][6] for i in temp],\n",
    "                'HS_Gender': [y_train[i][7] for i in temp],\n",
    "                'HS_Other': [y_train[i][8] for i in temp],\n",
    "                'HS_Weak': [y_train[i][9] for i in temp],\n",
    "                'HS_Moderate': [y_train[i][10] for i in temp],\n",
    "                'HS_Strong': [y_train[i][11] for i in temp],\n",
    "            })\n",
    "            acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "\n",
    "            print(\"Nearest checkpoint:\", nearest_cp)\n",
    "            print(\"Acquired samples:\", len(remaining_indices))\n",
    "            print(f\"Sampling duration: {duration} seconds\")\n",
    "            \n",
    "            sampling_dur.append(duration)\n",
    "            for i in remaining_indices:\n",
    "                new_samples.append(i)\n",
    "\n",
    "        else:\n",
    "            # Cluster the data based on its embeddings\n",
    "            kmeans=KMeans(n_clusters=n_clusters, n_init=1)\n",
    "            kmeans.fit(score_changes)\n",
    "            \n",
    "            for cluster_id in range(n_clusters):\n",
    "                # Cluster center and indices of samples in the current cluster\n",
    "                cluster_center = kmeans.cluster_centers_[cluster_id]\n",
    "                cluster_indices = np.where(kmeans.labels_ == cluster_id)[0]\n",
    "            \n",
    "                if cluster_indices.size == 0:\n",
    "                    # Skip clusters with no members\n",
    "                    print(f\"Cluster {cluster_id} has no members, skipping.\")\n",
    "                    continue\n",
    "            \n",
    "                # Calculate distances of each point in the cluster from the cluster center\n",
    "                cluster_distances = np.linalg.norm(score_changes[cluster_indices] - cluster_center, axis=1)\n",
    "            \n",
    "                # Determine the local threshold (10th percentile of closest distances to cluster center)\n",
    "                local_threshold = np.percentile(cluster_distances, 90)\n",
    "                thresholds.append(local_threshold)\n",
    "            \n",
    "                below_threshold_indices = cluster_indices[cluster_distances >= local_threshold]\n",
    "                collected_indices.update(below_threshold_indices)\n",
    "\n",
    "            # To handle multiple points with same distance\n",
    "            if len(collected_indices) > target_samples:\n",
    "                collected_indices = np.array(list(collected_indices))\n",
    "                np.random.shuffle(collected_indices)\n",
    "                collected_indices = collected_indices[:target_samples]\n",
    "                \n",
    "            end_time = time.time() \n",
    "            duration = end_time - start_time \n",
    "    \n",
    "            if arrived_at_cp:\n",
    "                temp = train_indices.copy()\n",
    "                temp.extend(collected_indices)\n",
    "                \n",
    "                # Save acquired data up to checkpoint\n",
    "                acquired_data = pd.DataFrame({\n",
    "                    'processed_text': [X_train[i] for i in temp],\n",
    "                    'HS': [y_train[i][0] for i in temp],\n",
    "                    'Abusive': [y_train[i][1] for i in temp],\n",
    "                    'HS_Individual': [y_train[i][2] for i in temp],\n",
    "                    'HS_Group': [y_train[i][3] for i in temp],\n",
    "                    'HS_Religion': [y_train[i][4] for i in temp],\n",
    "                    'HS_Race': [y_train[i][5] for i in temp],\n",
    "                    'HS_Physical': [y_train[i][6] for i in temp],\n",
    "                    'HS_Gender': [y_train[i][7] for i in temp],\n",
    "                    'HS_Other': [y_train[i][8] for i in temp],\n",
    "                    'HS_Weak': [y_train[i][9] for i in temp],\n",
    "                    'HS_Moderate': [y_train[i][10] for i in temp],\n",
    "                    'HS_Strong': [y_train[i][11] for i in temp],\n",
    "                })\n",
    "        \n",
    "                acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "            \n",
    "            print(\"Nearest checkpoint:\", nearest_cp)\n",
    "            # print(f\"Thresholds: {thresholds}\")\n",
    "            print(\"Acquired samples:\", len(collected_indices))\n",
    "            print(f\"Sampling duration: {duration} seconds\")\n",
    "        \n",
    "            sampling_dur.append(duration)\n",
    "            for i in collected_indices:\n",
    "                new_samples.append(remaining_indices[i])\n",
    "\n",
    "        threshold_data = pd.DataFrame({\n",
    "            'Threshold': thresholds\n",
    "        })\n",
    "        threshold_data.to_csv(f\"results/{filename}-thresholds-{trials+1}-{current_train_size}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3867ae",
   "metadata": {
    "papermill": {
     "duration": 0.012558,
     "end_time": "2025-05-10T12:29:20.377366",
     "exception": false,
     "start_time": "2025-05-10T12:29:20.364808",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d23b0d32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T12:29:20.403570Z",
     "iopub.status.busy": "2025-05-10T12:29:20.403298Z",
     "iopub.status.idle": "2025-05-10T12:29:20.414771Z",
     "shell.execute_reply": "2025-05-10T12:29:20.414113Z"
    },
    "papermill": {
     "duration": 0.02615,
     "end_time": "2025-05-10T12:29:20.416069",
     "exception": false,
     "start_time": "2025-05-10T12:29:20.389919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i):\n",
    "    accuracies = manager.list()\n",
    "    f1_micros = manager.list()\n",
    "    f1_macros = manager.list()\n",
    "    data_used = manager.list()\n",
    "    sampling_dur = manager.list()\n",
    "    new_samples = manager.list()\n",
    "    \n",
    "    print(\"TRIAL {}\".format(i+1))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "\n",
    "    start_time = time.time()\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        model_accuracies = manager.list()\n",
    "        model_f1_micros = manager.list()\n",
    "        model_f1_macros = manager.list()\n",
    "        \n",
    "        # Train the model\n",
    "        for j in range(3):\n",
    "            set_seed(seed[j])\n",
    "            args = (current_train_size, train_indices, (model_accuracies, model_f1_micros, model_f1_macros), i, j)\n",
    "            notebook_launcher(train_model, args, num_processes=2)\n",
    "\n",
    "        data_used.append(current_train_size)\n",
    "        accuracies.append(np.mean(model_accuracies))\n",
    "        f1_micros.append(np.mean(model_f1_micros))\n",
    "        f1_macros.append(np.mean(model_f1_macros))\n",
    "        print(f\"Averaged - Iteration {current_train_size}: Accuracy: {round(np.mean(model_accuracies), 4)}, F1 Micro: {round(np.mean(model_f1_micros), 4)}, F1 Macro: {round(np.mean(model_f1_macros), 4)}\")\n",
    "\n",
    "        nearest_cp = current_train_size\n",
    "        if nearest_cp not in checkpoints:\n",
    "            for cp in checkpoints:\n",
    "                if cp > current_train_size:\n",
    "                    nearest_cp = cp\n",
    "                    break\n",
    "        percentage = math.ceil(nearest_cp / total_data * 100)\n",
    "        \n",
    "        models = []\n",
    "        for j in range(3):\n",
    "            model = BertForSequenceClassification.from_pretrained(f'{filename}-{i+1}-model-{j+1}-{percentage}')\n",
    "            models.append(model)\n",
    "    \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples = manager.list()\n",
    "        sampling_args = (models, [X_train[i] for i in remaining_indices], train_indices, remaining_indices, tokenizer, sampling_dur, new_samples, i)\n",
    "        notebook_launcher(besra_sampling, sampling_args, num_processes=2)\n",
    "        new_samples = list(new_samples)\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    model_accuracies = manager.list()\n",
    "    model_f1_micros = manager.list()\n",
    "    model_f1_macros = manager.list()\n",
    "    \n",
    "    for j in range(3):\n",
    "        set_seed(seed[j])\n",
    "        args = (current_train_size, train_indices, (model_accuracies, model_f1_micros, model_f1_macros), i, j)\n",
    "        notebook_launcher(train_model, args, num_processes=2)\n",
    "        \n",
    "    data_used.append(current_train_size)\n",
    "    accuracies.append(np.mean(model_accuracies))\n",
    "    f1_micros.append(np.mean(model_f1_micros))\n",
    "    f1_macros.append(np.mean(model_f1_macros))\n",
    "    print(f\"Averaged - Iteration {current_train_size}: Accuracy: {round(np.mean(model_accuracies), 4)}, F1 Micro: {round(np.mean(model_f1_micros), 4)}, F1 Macro: {round(np.mean(model_f1_macros), 4)}\")\n",
    "        \n",
    "    data_used, accuracies, f1_micros, f1_macros, sampling_dur = list(data_used), list(accuracies), list(f1_micros), list(f1_macros), list(sampling_dur)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    \n",
    "    sampling_dur.insert(0, 0)\n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    results.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae79e64",
   "metadata": {
    "papermill": {
     "duration": 0.012337,
     "end_time": "2025-05-10T12:29:20.441254",
     "exception": false,
     "start_time": "2025-05-10T12:29:20.428917",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# RUN THE LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24e97697",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-10T12:29:20.468639Z",
     "iopub.status.busy": "2025-05-10T12:29:20.468335Z",
     "iopub.status.idle": "2025-05-10T13:49:11.109241Z",
     "shell.execute_reply": "2025-05-10T13:49:11.108124Z"
    },
    "papermill": {
     "duration": 4790.657007,
     "end_time": "2025-05-10T13:49:11.110916",
     "exception": false,
     "start_time": "2025-05-10T12:29:20.453909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIAL 1\n",
      "Random seed: [50, 67, 42]\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6807, Accuracy: 0.7103, F1 Micro: 0.2587, F1 Macro: 0.1588\n",
      "Epoch 2/10, Train Loss: 0.6025, Accuracy: 0.7939, F1 Micro: 0.2097, F1 Macro: 0.0907\n",
      "Epoch 3/10, Train Loss: 0.5498, Accuracy: 0.8095, F1 Micro: 0.187, F1 Macro: 0.0701\n",
      "Epoch 4/10, Train Loss: 0.4895, Accuracy: 0.8148, F1 Micro: 0.1836, F1 Macro: 0.0639\n",
      "Epoch 5/10, Train Loss: 0.4502, Accuracy: 0.8197, F1 Micro: 0.2086, F1 Macro: 0.0669\n",
      "Epoch 6/10, Train Loss: 0.4379, Accuracy: 0.8222, F1 Micro: 0.2338, F1 Macro: 0.0644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4299, Accuracy: 0.8225, F1 Micro: 0.2611, F1 Macro: 0.0641\n",
      "Epoch 8/10, Train Loss: 0.4177, Accuracy: 0.8232, F1 Micro: 0.2606, F1 Macro: 0.0639\n",
      "Epoch 9/10, Train Loss: 0.3804, Accuracy: 0.823, F1 Micro: 0.248, F1 Macro: 0.0628\n",
      "Epoch 10/10, Train Loss: 0.3757, Accuracy: 0.8228, F1 Micro: 0.2422, F1 Macro: 0.0621\n",
      "Model 1 - Iteration 166: Accuracy: 0.8225, F1 Micro: 0.2611, F1 Macro: 0.0641\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       1.00      0.01      0.01       360\n",
      "      Abusive       0.73      0.79      0.76       365\n",
      "HS_Individual       0.00      0.00      0.00       201\n",
      "     HS_Group       0.00      0.00      0.00       159\n",
      "  HS_Religion       0.00      0.00      0.00        68\n",
      "      HS_Race       0.00      0.00      0.00        65\n",
      "  HS_Physical       0.00      0.00      0.00        82\n",
      "    HS_Gender       0.00      0.00      0.00        83\n",
      "     HS_Other       0.00      0.00      0.00        77\n",
      "      HS_Weak       0.00      0.00      0.00       197\n",
      "  HS_Moderate       0.00      0.00      0.00       134\n",
      "    HS_Strong       0.00      0.00      0.00        29\n",
      "\n",
      "    micro avg       0.73      0.16      0.26      1820\n",
      "    macro avg       0.14      0.07      0.06      1820\n",
      " weighted avg       0.34      0.16      0.15      1820\n",
      "  samples avg       0.37      0.16      0.20      1820\n",
      "\n",
      "Training completed in 24.064088821411133 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.693, Accuracy: 0.6237, F1 Micro: 0.1759, F1 Macro: 0.1219\n",
      "Epoch 2/10, Train Loss: 0.6204, Accuracy: 0.789, F1 Micro: 0.1329, F1 Macro: 0.0552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5658, Accuracy: 0.8123, F1 Micro: 0.2235, F1 Macro: 0.0711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5018, Accuracy: 0.8238, F1 Micro: 0.3211, F1 Macro: 0.0986\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4557, Accuracy: 0.8303, F1 Micro: 0.3678, F1 Macro: 0.1101\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4464, Accuracy: 0.8313, F1 Micro: 0.3763, F1 Macro: 0.1107\n",
      "Epoch 7/10, Train Loss: 0.4332, Accuracy: 0.8293, F1 Micro: 0.354, F1 Macro: 0.1017\n",
      "Epoch 8/10, Train Loss: 0.4191, Accuracy: 0.8251, F1 Micro: 0.3052, F1 Macro: 0.0823\n",
      "Epoch 9/10, Train Loss: 0.3815, Accuracy: 0.8223, F1 Micro: 0.2561, F1 Macro: 0.0675\n",
      "Epoch 10/10, Train Loss: 0.3742, Accuracy: 0.8217, F1 Micro: 0.2383, F1 Macro: 0.0643\n",
      "Model 2 - Iteration 166: Accuracy: 0.8313, F1 Micro: 0.3763, F1 Macro: 0.1107\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.70      0.52      0.60       360\n",
      "      Abusive       0.69      0.77      0.73       365\n",
      "HS_Individual       0.00      0.00      0.00       201\n",
      "     HS_Group       0.00      0.00      0.00       159\n",
      "  HS_Religion       0.00      0.00      0.00        68\n",
      "      HS_Race       0.00      0.00      0.00        65\n",
      "  HS_Physical       0.00      0.00      0.00        82\n",
      "    HS_Gender       0.00      0.00      0.00        83\n",
      "     HS_Other       0.00      0.00      0.00        77\n",
      "      HS_Weak       0.00      0.00      0.00       197\n",
      "  HS_Moderate       0.00      0.00      0.00       134\n",
      "    HS_Strong       0.00      0.00      0.00        29\n",
      "\n",
      "    micro avg       0.70      0.26      0.38      1820\n",
      "    macro avg       0.12      0.11      0.11      1820\n",
      " weighted avg       0.28      0.26      0.26      1820\n",
      "  samples avg       0.42      0.21      0.25      1820\n",
      "\n",
      "Training completed in 29.194749355316162 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7205, Accuracy: 0.6487, F1 Micro: 0.358, F1 Macro: 0.1855\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6257, Accuracy: 0.7778, F1 Micro: 0.4057, F1 Macro: 0.1348\n",
      "Epoch 3/10, Train Loss: 0.5641, Accuracy: 0.8005, F1 Micro: 0.4008, F1 Macro: 0.1074\n",
      "Epoch 4/10, Train Loss: 0.5054, Accuracy: 0.8012, F1 Micro: 0.3382, F1 Macro: 0.0861\n",
      "Epoch 5/10, Train Loss: 0.4625, Accuracy: 0.8072, F1 Micro: 0.2962, F1 Macro: 0.0637\n",
      "Epoch 6/10, Train Loss: 0.4448, Accuracy: 0.8173, F1 Micro: 0.2741, F1 Macro: 0.0614\n",
      "Epoch 7/10, Train Loss: 0.4338, Accuracy: 0.8192, F1 Micro: 0.2543, F1 Macro: 0.0608\n",
      "Epoch 8/10, Train Loss: 0.4152, Accuracy: 0.8205, F1 Micro: 0.2556, F1 Macro: 0.0617\n",
      "Epoch 9/10, Train Loss: 0.3786, Accuracy: 0.8202, F1 Micro: 0.2361, F1 Macro: 0.0598\n",
      "Epoch 10/10, Train Loss: 0.372, Accuracy: 0.8199, F1 Micro: 0.2148, F1 Macro: 0.0574\n",
      "Model 3 - Iteration 166: Accuracy: 0.7778, F1 Micro: 0.4057, F1 Macro: 0.1348\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.52      0.83      0.64       360\n",
      "      Abusive       0.48      1.00      0.64       365\n",
      "HS_Individual       0.25      0.05      0.09       201\n",
      "     HS_Group       0.00      0.00      0.00       159\n",
      "  HS_Religion       0.00      0.00      0.00        68\n",
      "      HS_Race       0.00      0.00      0.00        65\n",
      "  HS_Physical       0.00      0.00      0.00        82\n",
      "    HS_Gender       0.10      0.23      0.13        83\n",
      "     HS_Other       0.24      0.05      0.09        77\n",
      "      HS_Weak       0.00      0.00      0.00       197\n",
      "  HS_Moderate       0.10      0.01      0.03       134\n",
      "    HS_Strong       0.00      0.00      0.00        29\n",
      "\n",
      "    micro avg       0.43      0.38      0.41      1820\n",
      "    macro avg       0.14      0.18      0.13      1820\n",
      " weighted avg       0.25      0.38      0.28      1820\n",
      "  samples avg       0.44      0.29      0.31      1820\n",
      "\n",
      "Training completed in 23.102893114089966 s\n",
      "Averaged - Iteration 166: Accuracy: 0.8105, F1 Micro: 0.3477, F1 Macro: 0.1032\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1664\n",
      "Acquired samples: 250\n",
      "Sampling duration: 30.117685794830322 seconds\n",
      "New train size: 416\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6397, Accuracy: 0.7937, F1 Micro: 0.1659, F1 Macro: 0.0712\n",
      "Epoch 2/10, Train Loss: 0.522, Accuracy: 0.8065, F1 Micro: 0.0699, F1 Macro: 0.0262\n",
      "Epoch 3/10, Train Loss: 0.4527, Accuracy: 0.8083, F1 Micro: 0.0606, F1 Macro: 0.0225\n",
      "Epoch 4/10, Train Loss: 0.4308, Accuracy: 0.8168, F1 Micro: 0.1619, F1 Macro: 0.0486\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3994, Accuracy: 0.8203, F1 Micro: 0.2, F1 Macro: 0.0561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3978, Accuracy: 0.8216, F1 Micro: 0.2111, F1 Macro: 0.0597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3604, Accuracy: 0.8292, F1 Micro: 0.2871, F1 Macro: 0.0867\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3661, Accuracy: 0.8337, F1 Micro: 0.349, F1 Macro: 0.1059\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3582, Accuracy: 0.8377, F1 Micro: 0.3798, F1 Macro: 0.1226\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3227, Accuracy: 0.8464, F1 Micro: 0.4477, F1 Macro: 0.1876\n",
      "Model 1 - Iteration 416: Accuracy: 0.8464, F1 Micro: 0.4477, F1 Macro: 0.1876\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.74      0.53      0.62       360\n",
      "      Abusive       0.83      0.79      0.81       365\n",
      "HS_Individual       0.72      0.19      0.30       201\n",
      "     HS_Group       0.60      0.11      0.19       159\n",
      "  HS_Religion       0.00      0.00      0.00        68\n",
      "      HS_Race       0.00      0.00      0.00        65\n",
      "  HS_Physical       1.00      0.01      0.02        82\n",
      "    HS_Gender       0.00      0.00      0.00        83\n",
      "     HS_Other       0.00      0.00      0.00        77\n",
      "      HS_Weak       0.68      0.20      0.31       197\n",
      "  HS_Moderate       0.00      0.00      0.00       134\n",
      "    HS_Strong       0.00      0.00      0.00        29\n",
      "\n",
      "    micro avg       0.77      0.32      0.45      1820\n",
      "    macro avg       0.38      0.15      0.19      1820\n",
      " weighted avg       0.56      0.32      0.37      1820\n",
      "  samples avg       0.38      0.24      0.26      1820\n",
      "\n",
      "Training completed in 36.97254228591919 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6543, Accuracy: 0.787, F1 Micro: 0.1454, F1 Macro: 0.0592\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5373, Accuracy: 0.8178, F1 Micro: 0.2568, F1 Macro: 0.0782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4612, Accuracy: 0.8306, F1 Micro: 0.3579, F1 Macro: 0.1086\n",
      "Epoch 4/10, Train Loss: 0.4333, Accuracy: 0.8244, F1 Micro: 0.2796, F1 Macro: 0.0848\n",
      "Epoch 5/10, Train Loss: 0.4014, Accuracy: 0.8231, F1 Micro: 0.2404, F1 Macro: 0.0685\n",
      "Epoch 6/10, Train Loss: 0.3935, Accuracy: 0.827, F1 Micro: 0.2701, F1 Macro: 0.083\n",
      "Epoch 7/10, Train Loss: 0.3557, Accuracy: 0.8336, F1 Micro: 0.3399, F1 Macro: 0.1053\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3606, Accuracy: 0.8381, F1 Micro: 0.3955, F1 Macro: 0.121\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3515, Accuracy: 0.8432, F1 Micro: 0.4232, F1 Macro: 0.1389\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3203, Accuracy: 0.849, F1 Micro: 0.4675, F1 Macro: 0.1684\n",
      "Model 2 - Iteration 416: Accuracy: 0.849, F1 Micro: 0.4675, F1 Macro: 0.1684\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.75      0.73      0.74       360\n",
      "      Abusive       0.81      0.79      0.80       365\n",
      "HS_Individual       0.72      0.24      0.36       201\n",
      "     HS_Group       0.45      0.03      0.06       159\n",
      "  HS_Religion       0.00      0.00      0.00        68\n",
      "      HS_Race       0.00      0.00      0.00        65\n",
      "  HS_Physical       0.00      0.00      0.00        82\n",
      "    HS_Gender       0.00      0.00      0.00        83\n",
      "     HS_Other       0.00      0.00      0.00        77\n",
      "      HS_Weak       0.67      0.03      0.06       197\n",
      "  HS_Moderate       0.00      0.00      0.00       134\n",
      "    HS_Strong       0.00      0.00      0.00        29\n",
      "\n",
      "    micro avg       0.77      0.34      0.47      1820\n",
      "    macro avg       0.28      0.15      0.17      1820\n",
      " weighted avg       0.50      0.34      0.36      1820\n",
      "  samples avg       0.44      0.25      0.28      1820\n",
      "\n",
      "Training completed in 34.77583932876587 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6781, Accuracy: 0.7762, F1 Micro: 0.4138, F1 Macro: 0.145\n",
      "Epoch 2/10, Train Loss: 0.5483, Accuracy: 0.8028, F1 Micro: 0.3649, F1 Macro: 0.0978\n",
      "Epoch 3/10, Train Loss: 0.4625, Accuracy: 0.8183, F1 Micro: 0.2465, F1 Macro: 0.0595\n",
      "Epoch 4/10, Train Loss: 0.4354, Accuracy: 0.8143, F1 Micro: 0.1432, F1 Macro: 0.044\n",
      "Epoch 5/10, Train Loss: 0.3994, Accuracy: 0.8172, F1 Micro: 0.1784, F1 Macro: 0.0512\n",
      "Epoch 6/10, Train Loss: 0.3975, Accuracy: 0.8162, F1 Micro: 0.1622, F1 Macro: 0.0485\n",
      "Epoch 7/10, Train Loss: 0.361, Accuracy: 0.8243, F1 Micro: 0.236, F1 Macro: 0.0709\n",
      "Epoch 8/10, Train Loss: 0.3622, Accuracy: 0.8338, F1 Micro: 0.3339, F1 Macro: 0.1023\n",
      "Epoch 9/10, Train Loss: 0.3595, Accuracy: 0.8334, F1 Micro: 0.3253, F1 Macro: 0.1027\n",
      "Epoch 10/10, Train Loss: 0.3265, Accuracy: 0.8423, F1 Micro: 0.3928, F1 Macro: 0.1323\n",
      "Model 3 - Iteration 416: Accuracy: 0.7762, F1 Micro: 0.4138, F1 Macro: 0.145\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.52      0.87      0.65       360\n",
      "      Abusive       0.48      1.00      0.64       365\n",
      "HS_Individual       0.29      0.11      0.16       201\n",
      "     HS_Group       0.00      0.00      0.00       159\n",
      "  HS_Religion       0.00      0.00      0.00        68\n",
      "      HS_Race       0.00      0.00      0.00        65\n",
      "  HS_Physical       0.13      0.04      0.06        82\n",
      "    HS_Gender       0.09      0.23      0.13        83\n",
      "     HS_Other       0.33      0.05      0.09        77\n",
      "      HS_Weak       0.00      0.00      0.00       197\n",
      "  HS_Moderate       0.00      0.00      0.00       134\n",
      "    HS_Strong       0.00      0.00      0.00        29\n",
      "\n",
      "    micro avg       0.43      0.40      0.41      1820\n",
      "    macro avg       0.15      0.19      0.14      1820\n",
      " weighted avg       0.26      0.40      0.29      1820\n",
      "  samples avg       0.44      0.30      0.31      1820\n",
      "\n",
      "Training completed in 26.040321111679077 s\n",
      "Averaged - Iteration 416: Accuracy: 0.8238, F1 Micro: 0.443, F1 Macro: 0.167\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1664\n",
      "Acquired samples: 225\n",
      "Sampling duration: 30.71800446510315 seconds\n",
      "New train size: 641\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6103, Accuracy: 0.8082, F1 Micro: 0.1868, F1 Macro: 0.0605\n",
      "Epoch 2/10, Train Loss: 0.4745, Accuracy: 0.8165, F1 Micro: 0.1755, F1 Macro: 0.062\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4364, Accuracy: 0.8204, F1 Micro: 0.1985, F1 Macro: 0.0582\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4033, Accuracy: 0.8287, F1 Micro: 0.2813, F1 Macro: 0.085\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3858, Accuracy: 0.8349, F1 Micro: 0.3658, F1 Macro: 0.1107\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3771, Accuracy: 0.8427, F1 Micro: 0.4332, F1 Macro: 0.1628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3436, Accuracy: 0.8516, F1 Micro: 0.4755, F1 Macro: 0.2175\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3227, Accuracy: 0.8575, F1 Micro: 0.5339, F1 Macro: 0.2634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2826, Accuracy: 0.8584, F1 Micro: 0.5554, F1 Macro: 0.3156\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2755, Accuracy: 0.8613, F1 Micro: 0.5711, F1 Macro: 0.3789\n",
      "Model 1 - Iteration 641: Accuracy: 0.8613, F1 Micro: 0.5711, F1 Macro: 0.3789\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.71      0.76       360\n",
      "      Abusive       0.87      0.78      0.82       365\n",
      "HS_Individual       0.65      0.43      0.52       201\n",
      "     HS_Group       0.56      0.38      0.46       159\n",
      "  HS_Religion       1.00      0.01      0.03        68\n",
      "      HS_Race       0.96      0.38      0.55        65\n",
      "  HS_Physical       0.58      0.23      0.33        82\n",
      "    HS_Gender       0.67      0.05      0.09        83\n",
      "     HS_Other       0.00      0.00      0.00        77\n",
      "      HS_Weak       0.64      0.45      0.53       197\n",
      "  HS_Moderate       0.32      0.17      0.22       134\n",
      "    HS_Strong       1.00      0.14      0.24        29\n",
      "\n",
      "    micro avg       0.73      0.47      0.57      1820\n",
      "    macro avg       0.67      0.31      0.38      1820\n",
      " weighted avg       0.69      0.47      0.53      1820\n",
      "  samples avg       0.39      0.30      0.31      1820\n",
      "\n",
      "Training completed in 47.33509349822998 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6251, Accuracy: 0.8091, F1 Micro: 0.2309, F1 Macro: 0.0647\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4832, Accuracy: 0.8316, F1 Micro: 0.4012, F1 Macro: 0.116\n",
      "Epoch 3/10, Train Loss: 0.4396, Accuracy: 0.8256, F1 Micro: 0.2829, F1 Macro: 0.086\n",
      "Epoch 4/10, Train Loss: 0.4038, Accuracy: 0.8314, F1 Micro: 0.3325, F1 Macro: 0.1023\n",
      "Epoch 5/10, Train Loss: 0.3844, Accuracy: 0.8381, F1 Micro: 0.3915, F1 Macro: 0.119\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3742, Accuracy: 0.8442, F1 Micro: 0.4421, F1 Macro: 0.1444\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3425, Accuracy: 0.8523, F1 Micro: 0.4779, F1 Macro: 0.2017\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3231, Accuracy: 0.8566, F1 Micro: 0.5332, F1 Macro: 0.2661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2803, Accuracy: 0.8608, F1 Micro: 0.5544, F1 Macro: 0.3212\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.277, Accuracy: 0.8658, F1 Micro: 0.5875, F1 Macro: 0.3956\n",
      "Model 2 - Iteration 641: Accuracy: 0.8658, F1 Micro: 0.5875, F1 Macro: 0.3956\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.73      0.78       360\n",
      "      Abusive       0.85      0.79      0.82       365\n",
      "HS_Individual       0.67      0.42      0.52       201\n",
      "     HS_Group       0.59      0.43      0.50       159\n",
      "  HS_Religion       0.00      0.00      0.00        68\n",
      "      HS_Race       0.88      0.54      0.67        65\n",
      "  HS_Physical       0.61      0.21      0.31        82\n",
      "    HS_Gender       0.00      0.00      0.00        83\n",
      "     HS_Other       0.50      0.05      0.09        77\n",
      "      HS_Weak       0.70      0.42      0.52       197\n",
      "  HS_Moderate       0.40      0.24      0.30       134\n",
      "    HS_Strong       1.00      0.14      0.24        29\n",
      "\n",
      "    micro avg       0.75      0.48      0.59      1820\n",
      "    macro avg       0.59      0.33      0.40      1820\n",
      " weighted avg       0.66      0.48      0.54      1820\n",
      "  samples avg       0.42      0.32      0.33      1820\n",
      "\n",
      "Training completed in 41.75987195968628 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6401, Accuracy: 0.7971, F1 Micro: 0.4243, F1 Macro: 0.118\n",
      "Epoch 2/10, Train Loss: 0.4869, Accuracy: 0.8181, F1 Micro: 0.2584, F1 Macro: 0.0637\n",
      "Epoch 3/10, Train Loss: 0.4413, Accuracy: 0.8188, F1 Micro: 0.1956, F1 Macro: 0.0583\n",
      "Epoch 4/10, Train Loss: 0.4042, Accuracy: 0.822, F1 Micro: 0.219, F1 Macro: 0.0667\n",
      "Epoch 5/10, Train Loss: 0.3908, Accuracy: 0.8322, F1 Micro: 0.3255, F1 Macro: 0.1001\n",
      "Epoch 6/10, Train Loss: 0.3857, Accuracy: 0.8371, F1 Micro: 0.3626, F1 Macro: 0.1164\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3526, Accuracy: 0.8462, F1 Micro: 0.4284, F1 Macro: 0.1598\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3331, Accuracy: 0.8538, F1 Micro: 0.4896, F1 Macro: 0.2287\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2996, Accuracy: 0.8608, F1 Micro: 0.5484, F1 Macro: 0.3155\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2954, Accuracy: 0.8594, F1 Micro: 0.5546, F1 Macro: 0.3585\n",
      "Model 3 - Iteration 641: Accuracy: 0.8594, F1 Micro: 0.5546, F1 Macro: 0.3585\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.69      0.75       360\n",
      "      Abusive       0.85      0.73      0.79       365\n",
      "HS_Individual       0.71      0.38      0.50       201\n",
      "     HS_Group       0.56      0.43      0.49       159\n",
      "  HS_Religion       0.33      0.01      0.03        68\n",
      "      HS_Race       0.94      0.52      0.67        65\n",
      "  HS_Physical       0.00      0.00      0.00        82\n",
      "    HS_Gender       1.00      0.05      0.09        83\n",
      "     HS_Other       0.00      0.00      0.00        77\n",
      "      HS_Weak       0.69      0.34      0.46       197\n",
      "  HS_Moderate       0.36      0.25      0.30       134\n",
      "    HS_Strong       0.67      0.14      0.23        29\n",
      "\n",
      "    micro avg       0.74      0.44      0.55      1820\n",
      "    macro avg       0.58      0.30      0.36      1820\n",
      " weighted avg       0.66      0.44      0.51      1820\n",
      "  samples avg       0.39      0.29      0.31      1820\n",
      "\n",
      "Training completed in 39.099639892578125 s\n",
      "Averaged - Iteration 641: Accuracy: 0.8622, F1 Micro: 0.5711, F1 Macro: 0.3777\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1664\n",
      "Acquired samples: 203\n",
      "Sampling duration: 27.65644335746765 seconds\n",
      "New train size: 844\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6031, Accuracy: 0.8102, F1 Micro: 0.2605, F1 Macro: 0.0723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4625, Accuracy: 0.8327, F1 Micro: 0.3365, F1 Macro: 0.1048\n",
      "Epoch 3/10, Train Loss: 0.4225, Accuracy: 0.8299, F1 Micro: 0.3025, F1 Macro: 0.0909\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3962, Accuracy: 0.8368, F1 Micro: 0.397, F1 Macro: 0.1176\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3887, Accuracy: 0.8438, F1 Micro: 0.4453, F1 Macro: 0.1669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3697, Accuracy: 0.8524, F1 Micro: 0.4899, F1 Macro: 0.2221\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3223, Accuracy: 0.8597, F1 Micro: 0.5589, F1 Macro: 0.2944\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.296, Accuracy: 0.8631, F1 Micro: 0.5832, F1 Macro: 0.3558\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2703, Accuracy: 0.8702, F1 Micro: 0.6184, F1 Macro: 0.4286\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2596, Accuracy: 0.8704, F1 Micro: 0.6371, F1 Macro: 0.4421\n",
      "Model 1 - Iteration 844: Accuracy: 0.8704, F1 Micro: 0.6371, F1 Macro: 0.4421\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.81      0.82       360\n",
      "      Abusive       0.82      0.84      0.83       365\n",
      "HS_Individual       0.65      0.59      0.62       201\n",
      "     HS_Group       0.63      0.55      0.58       159\n",
      "  HS_Religion       0.00      0.00      0.00        68\n",
      "      HS_Race       0.97      0.58      0.73        65\n",
      "  HS_Physical       0.47      0.34      0.39        82\n",
      "    HS_Gender       0.52      0.17      0.25        83\n",
      "     HS_Other       0.50      0.01      0.03        77\n",
      "      HS_Weak       0.65      0.59      0.62       197\n",
      "  HS_Moderate       0.41      0.33      0.37       134\n",
      "    HS_Strong       1.00      0.03      0.07        29\n",
      "\n",
      "    micro avg       0.71      0.58      0.64      1820\n",
      "    macro avg       0.62      0.40      0.44      1820\n",
      " weighted avg       0.67      0.58      0.60      1820\n",
      "  samples avg       0.42      0.36      0.36      1820\n",
      "\n",
      "Training completed in 49.88951635360718 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6178, Accuracy: 0.8124, F1 Micro: 0.2917, F1 Macro: 0.0811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4726, Accuracy: 0.8316, F1 Micro: 0.4336, F1 Macro: 0.1206\n",
      "Epoch 3/10, Train Loss: 0.4248, Accuracy: 0.8292, F1 Micro: 0.3151, F1 Macro: 0.0969\n",
      "Epoch 4/10, Train Loss: 0.3956, Accuracy: 0.8369, F1 Micro: 0.3952, F1 Macro: 0.1177\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3887, Accuracy: 0.8442, F1 Micro: 0.4473, F1 Macro: 0.1473\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3709, Accuracy: 0.8557, F1 Micro: 0.5121, F1 Macro: 0.2174\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3226, Accuracy: 0.8587, F1 Micro: 0.5568, F1 Macro: 0.2948\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2984, Accuracy: 0.865, F1 Micro: 0.5945, F1 Macro: 0.3795\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2751, Accuracy: 0.8676, F1 Micro: 0.6139, F1 Macro: 0.4076\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2657, Accuracy: 0.8695, F1 Micro: 0.6281, F1 Macro: 0.4285\n",
      "Model 2 - Iteration 844: Accuracy: 0.8695, F1 Micro: 0.6281, F1 Macro: 0.4285\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.81      0.80      0.81       360\n",
      "      Abusive       0.83      0.84      0.83       365\n",
      "HS_Individual       0.62      0.53      0.57       201\n",
      "     HS_Group       0.63      0.55      0.59       159\n",
      "  HS_Religion       0.00      0.00      0.00        68\n",
      "      HS_Race       0.94      0.69      0.80        65\n",
      "  HS_Physical       0.55      0.29      0.38        82\n",
      "    HS_Gender       0.56      0.06      0.11        83\n",
      "     HS_Other       0.50      0.05      0.09        77\n",
      "      HS_Weak       0.63      0.53      0.57       197\n",
      "  HS_Moderate       0.42      0.35      0.38       134\n",
      "    HS_Strong       0.00      0.00      0.00        29\n",
      "\n",
      "    micro avg       0.72      0.56      0.63      1820\n",
      "    macro avg       0.54      0.39      0.43      1820\n",
      " weighted avg       0.66      0.56      0.59      1820\n",
      "  samples avg       0.42      0.36      0.36      1820\n",
      "\n",
      "Training completed in 45.62919211387634 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6258, Accuracy: 0.7974, F1 Micro: 0.4415, F1 Macro: 0.1236\n",
      "Epoch 2/10, Train Loss: 0.4756, Accuracy: 0.8189, F1 Micro: 0.2319, F1 Macro: 0.0639\n",
      "Epoch 3/10, Train Loss: 0.4247, Accuracy: 0.827, F1 Micro: 0.2858, F1 Macro: 0.0893\n",
      "Epoch 4/10, Train Loss: 0.3972, Accuracy: 0.834, F1 Micro: 0.3462, F1 Macro: 0.1067\n",
      "Epoch 5/10, Train Loss: 0.3959, Accuracy: 0.8404, F1 Micro: 0.4109, F1 Macro: 0.1251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3782, Accuracy: 0.851, F1 Micro: 0.4817, F1 Macro: 0.1919\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3345, Accuracy: 0.8602, F1 Micro: 0.5478, F1 Macro: 0.2766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3096, Accuracy: 0.8636, F1 Micro: 0.5839, F1 Macro: 0.3521\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2828, Accuracy: 0.8672, F1 Micro: 0.6136, F1 Macro: 0.4218\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2776, Accuracy: 0.8697, F1 Micro: 0.6257, F1 Macro: 0.4191\n",
      "Model 3 - Iteration 844: Accuracy: 0.8697, F1 Micro: 0.6257, F1 Macro: 0.4191\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.81      0.78      0.79       360\n",
      "      Abusive       0.83      0.85      0.84       365\n",
      "HS_Individual       0.63      0.54      0.58       201\n",
      "     HS_Group       0.62      0.52      0.57       159\n",
      "  HS_Religion       1.00      0.01      0.03        68\n",
      "      HS_Race       0.98      0.65      0.78        65\n",
      "  HS_Physical       0.67      0.17      0.27        82\n",
      "    HS_Gender       0.53      0.10      0.16        83\n",
      "     HS_Other       1.00      0.01      0.03        77\n",
      "      HS_Weak       0.64      0.53      0.58       197\n",
      "  HS_Moderate       0.43      0.37      0.40       134\n",
      "    HS_Strong       0.00      0.00      0.00        29\n",
      "\n",
      "    micro avg       0.72      0.55      0.63      1820\n",
      "    macro avg       0.68      0.38      0.42      1820\n",
      " weighted avg       0.72      0.55      0.58      1820\n",
      "  samples avg       0.42      0.35      0.36      1820\n",
      "\n",
      "Training completed in 41.743727922439575 s\n",
      "Averaged - Iteration 844: Accuracy: 0.8699, F1 Micro: 0.6303, F1 Macro: 0.4299\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1664\n",
      "Acquired samples: 182\n",
      "Sampling duration: 25.133851528167725 seconds\n",
      "New train size: 1026\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.578, Accuracy: 0.814, F1 Micro: 0.29, F1 Macro: 0.082\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4503, Accuracy: 0.8332, F1 Micro: 0.355, F1 Macro: 0.1056\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.417, Accuracy: 0.8385, F1 Micro: 0.3936, F1 Macro: 0.1183\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3907, Accuracy: 0.8457, F1 Micro: 0.4514, F1 Macro: 0.1837\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3487, Accuracy: 0.8551, F1 Micro: 0.4983, F1 Macro: 0.2305\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3316, Accuracy: 0.8599, F1 Micro: 0.5351, F1 Macro: 0.2841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3085, Accuracy: 0.8646, F1 Micro: 0.567, F1 Macro: 0.3508\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2772, Accuracy: 0.8715, F1 Micro: 0.6113, F1 Macro: 0.4096\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.259, Accuracy: 0.8736, F1 Micro: 0.6317, F1 Macro: 0.4405\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2261, Accuracy: 0.8757, F1 Micro: 0.6478, F1 Macro: 0.48\n",
      "Model 1 - Iteration 1026: Accuracy: 0.8757, F1 Micro: 0.6478, F1 Macro: 0.48\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.79      0.81       360\n",
      "      Abusive       0.85      0.81      0.83       365\n",
      "HS_Individual       0.68      0.57      0.62       201\n",
      "     HS_Group       0.64      0.61      0.63       159\n",
      "  HS_Religion       0.70      0.10      0.18        68\n",
      "      HS_Race       0.96      0.72      0.82        65\n",
      "  HS_Physical       0.48      0.26      0.33        82\n",
      "    HS_Gender       0.56      0.17      0.26        83\n",
      "     HS_Other       0.67      0.05      0.10        77\n",
      "      HS_Weak       0.69      0.57      0.63       197\n",
      "  HS_Moderate       0.44      0.42      0.43       134\n",
      "    HS_Strong       1.00      0.07      0.13        29\n",
      "\n",
      "    micro avg       0.74      0.58      0.65      1820\n",
      "    macro avg       0.71      0.43      0.48      1820\n",
      " weighted avg       0.72      0.58      0.62      1820\n",
      "  samples avg       0.41      0.36      0.36      1820\n",
      "\n",
      "Training completed in 51.686761140823364 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5908, Accuracy: 0.8224, F1 Micro: 0.3711, F1 Macro: 0.1057\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.458, Accuracy: 0.832, F1 Micro: 0.3813, F1 Macro: 0.1118\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4168, Accuracy: 0.8364, F1 Micro: 0.3978, F1 Macro: 0.118\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3913, Accuracy: 0.8461, F1 Micro: 0.455, F1 Macro: 0.1602\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3532, Accuracy: 0.8567, F1 Micro: 0.5257, F1 Macro: 0.2459\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3313, Accuracy: 0.8615, F1 Micro: 0.5884, F1 Macro: 0.338\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.314, Accuracy: 0.8688, F1 Micro: 0.6089, F1 Macro: 0.3852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2816, Accuracy: 0.8723, F1 Micro: 0.614, F1 Macro: 0.4162\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2626, Accuracy: 0.8735, F1 Micro: 0.6275, F1 Macro: 0.4363\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2302, Accuracy: 0.8743, F1 Micro: 0.6448, F1 Macro: 0.4716\n",
      "Model 2 - Iteration 1026: Accuracy: 0.8743, F1 Micro: 0.6448, F1 Macro: 0.4716\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.80      0.82       360\n",
      "      Abusive       0.86      0.81      0.83       365\n",
      "HS_Individual       0.65      0.53      0.58       201\n",
      "     HS_Group       0.64      0.60      0.62       159\n",
      "  HS_Religion       1.00      0.04      0.08        68\n",
      "      HS_Race       0.88      0.77      0.82        65\n",
      "  HS_Physical       0.52      0.28      0.37        82\n",
      "    HS_Gender       0.53      0.19      0.28        83\n",
      "     HS_Other       0.50      0.08      0.13        77\n",
      "      HS_Weak       0.66      0.54      0.60       197\n",
      "  HS_Moderate       0.47      0.45      0.46       134\n",
      "    HS_Strong       1.00      0.03      0.07        29\n",
      "\n",
      "    micro avg       0.73      0.58      0.64      1820\n",
      "    macro avg       0.71      0.43      0.47      1820\n",
      " weighted avg       0.72      0.58      0.61      1820\n",
      "  samples avg       0.42      0.36      0.36      1820\n",
      "\n",
      "Training completed in 52.06587743759155 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6022, Accuracy: 0.8015, F1 Micro: 0.435, F1 Macro: 0.1142\n",
      "Epoch 2/10, Train Loss: 0.4572, Accuracy: 0.8251, F1 Micro: 0.281, F1 Macro: 0.0848\n",
      "Epoch 3/10, Train Loss: 0.4181, Accuracy: 0.8292, F1 Micro: 0.2865, F1 Macro: 0.0905\n",
      "Epoch 4/10, Train Loss: 0.3982, Accuracy: 0.8432, F1 Micro: 0.4143, F1 Macro: 0.1355\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3611, Accuracy: 0.8522, F1 Micro: 0.4745, F1 Macro: 0.2123\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.338, Accuracy: 0.8628, F1 Micro: 0.573, F1 Macro: 0.3363\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3192, Accuracy: 0.8663, F1 Micro: 0.5866, F1 Macro: 0.3566\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2908, Accuracy: 0.8698, F1 Micro: 0.6159, F1 Macro: 0.4162\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2673, Accuracy: 0.8742, F1 Micro: 0.6267, F1 Macro: 0.4475\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.233, Accuracy: 0.8766, F1 Micro: 0.6505, F1 Macro: 0.5004\n",
      "Model 3 - Iteration 1026: Accuracy: 0.8766, F1 Micro: 0.6505, F1 Macro: 0.5004\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.79      0.82       360\n",
      "      Abusive       0.84      0.80      0.82       365\n",
      "HS_Individual       0.66      0.53      0.59       201\n",
      "     HS_Group       0.64      0.63      0.63       159\n",
      "  HS_Religion       0.60      0.13      0.22        68\n",
      "      HS_Race       0.87      0.82      0.84        65\n",
      "  HS_Physical       0.62      0.22      0.32        82\n",
      "    HS_Gender       0.61      0.20      0.31        83\n",
      "     HS_Other       0.86      0.08      0.14        77\n",
      "      HS_Weak       0.67      0.53      0.59       197\n",
      "  HS_Moderate       0.48      0.48      0.48       134\n",
      "    HS_Strong       1.00      0.14      0.24        29\n",
      "\n",
      "    micro avg       0.74      0.58      0.65      1820\n",
      "    macro avg       0.72      0.45      0.50      1820\n",
      " weighted avg       0.73      0.58      0.62      1820\n",
      "  samples avg       0.42      0.36      0.36      1820\n",
      "\n",
      "Training completed in 48.18657183647156 s\n",
      "Averaged - Iteration 1026: Accuracy: 0.8755, F1 Micro: 0.6477, F1 Macro: 0.484\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1664\n",
      "Acquired samples: 164\n",
      "Sampling duration: 23.403295040130615 seconds\n",
      "New train size: 1190\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5675, Accuracy: 0.8164, F1 Micro: 0.3497, F1 Macro: 0.0968\n",
      "Epoch 2/10, Train Loss: 0.4467, Accuracy: 0.83, F1 Micro: 0.3166, F1 Macro: 0.0936\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4147, Accuracy: 0.8381, F1 Micro: 0.4314, F1 Macro: 0.1235\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3807, Accuracy: 0.8493, F1 Micro: 0.5232, F1 Macro: 0.2384\n",
      "Epoch 5/10, Train Loss: 0.355, Accuracy: 0.8561, F1 Micro: 0.5175, F1 Macro: 0.2478\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3203, Accuracy: 0.8661, F1 Micro: 0.5831, F1 Macro: 0.3631\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2905, Accuracy: 0.8755, F1 Micro: 0.6421, F1 Macro: 0.4372\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2578, Accuracy: 0.8763, F1 Micro: 0.6426, F1 Macro: 0.4559\n",
      "Epoch 9/10, Train Loss: 0.2323, Accuracy: 0.8778, F1 Micro: 0.6419, F1 Macro: 0.4607\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2057, Accuracy: 0.8748, F1 Micro: 0.6686, F1 Macro: 0.5266\n",
      "Model 1 - Iteration 1190: Accuracy: 0.8748, F1 Micro: 0.6686, F1 Macro: 0.5266\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.81      0.83      0.82       360\n",
      "      Abusive       0.83      0.85      0.84       365\n",
      "HS_Individual       0.62      0.64      0.63       201\n",
      "     HS_Group       0.64      0.58      0.61       159\n",
      "  HS_Religion       0.76      0.32      0.45        68\n",
      "      HS_Race       0.92      0.74      0.82        65\n",
      "  HS_Physical       0.48      0.46      0.47        82\n",
      "    HS_Gender       0.49      0.34      0.40        83\n",
      "     HS_Other       0.73      0.10      0.18        77\n",
      "      HS_Weak       0.62      0.65      0.64       197\n",
      "  HS_Moderate       0.47      0.45      0.46       134\n",
      "    HS_Strong       0.00      0.00      0.00        29\n",
      "\n",
      "    micro avg       0.70      0.64      0.67      1820\n",
      "    macro avg       0.61      0.50      0.53      1820\n",
      " weighted avg       0.69      0.64      0.65      1820\n",
      "  samples avg       0.41      0.40      0.38      1820\n",
      "\n",
      "Training completed in 51.079723596572876 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5814, Accuracy: 0.8231, F1 Micro: 0.3976, F1 Macro: 0.1113\n",
      "Epoch 2/10, Train Loss: 0.4516, Accuracy: 0.8312, F1 Micro: 0.3384, F1 Macro: 0.1035\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4153, Accuracy: 0.839, F1 Micro: 0.4069, F1 Macro: 0.1218\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3831, Accuracy: 0.851, F1 Micro: 0.5045, F1 Macro: 0.1973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3559, Accuracy: 0.8583, F1 Micro: 0.5195, F1 Macro: 0.2475\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3238, Accuracy: 0.8674, F1 Micro: 0.5983, F1 Macro: 0.3776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2907, Accuracy: 0.8722, F1 Micro: 0.6222, F1 Macro: 0.4098\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2619, Accuracy: 0.8745, F1 Micro: 0.6412, F1 Macro: 0.4438\n",
      "Epoch 9/10, Train Loss: 0.2352, Accuracy: 0.8741, F1 Micro: 0.6172, F1 Macro: 0.4358\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2105, Accuracy: 0.8779, F1 Micro: 0.6637, F1 Macro: 0.5245\n",
      "Model 2 - Iteration 1190: Accuracy: 0.8779, F1 Micro: 0.6637, F1 Macro: 0.5245\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.82      0.83       360\n",
      "      Abusive       0.84      0.81      0.83       365\n",
      "HS_Individual       0.64      0.58      0.61       201\n",
      "     HS_Group       0.65      0.60      0.63       159\n",
      "  HS_Religion       0.89      0.25      0.39        68\n",
      "      HS_Race       0.84      0.78      0.81        65\n",
      "  HS_Physical       0.52      0.35      0.42        82\n",
      "    HS_Gender       0.58      0.27      0.36        83\n",
      "     HS_Other       0.78      0.09      0.16        77\n",
      "      HS_Weak       0.65      0.60      0.62       197\n",
      "  HS_Moderate       0.47      0.42      0.44       134\n",
      "    HS_Strong       1.00      0.10      0.19        29\n",
      "\n",
      "    micro avg       0.73      0.61      0.66      1820\n",
      "    macro avg       0.72      0.47      0.52      1820\n",
      " weighted avg       0.73      0.61      0.64      1820\n",
      "  samples avg       0.42      0.38      0.37      1820\n",
      "\n",
      "Training completed in 52.0097017288208 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5918, Accuracy: 0.8061, F1 Micro: 0.4357, F1 Macro: 0.1126\n",
      "Epoch 2/10, Train Loss: 0.4501, Accuracy: 0.8314, F1 Micro: 0.3382, F1 Macro: 0.1034\n",
      "Epoch 3/10, Train Loss: 0.4151, Accuracy: 0.8373, F1 Micro: 0.3808, F1 Macro: 0.1154\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3878, Accuracy: 0.8466, F1 Micro: 0.4624, F1 Macro: 0.1705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3654, Accuracy: 0.8548, F1 Micro: 0.4842, F1 Macro: 0.2307\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3336, Accuracy: 0.8682, F1 Micro: 0.602, F1 Macro: 0.3683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3018, Accuracy: 0.8713, F1 Micro: 0.6096, F1 Macro: 0.3956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2701, Accuracy: 0.8763, F1 Micro: 0.6462, F1 Macro: 0.475\n",
      "Epoch 9/10, Train Loss: 0.245, Accuracy: 0.8754, F1 Micro: 0.627, F1 Macro: 0.4652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2194, Accuracy: 0.8789, F1 Micro: 0.6551, F1 Macro: 0.5228\n",
      "Model 3 - Iteration 1190: Accuracy: 0.8789, F1 Micro: 0.6551, F1 Macro: 0.5228\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.87      0.77      0.82       360\n",
      "      Abusive       0.85      0.78      0.81       365\n",
      "HS_Individual       0.69      0.55      0.61       201\n",
      "     HS_Group       0.66      0.60      0.63       159\n",
      "  HS_Religion       0.66      0.28      0.39        68\n",
      "      HS_Race       0.93      0.82      0.87        65\n",
      "  HS_Physical       0.59      0.23      0.33        82\n",
      "    HS_Gender       0.44      0.24      0.31        83\n",
      "     HS_Other       0.78      0.09      0.16        77\n",
      "      HS_Weak       0.69      0.55      0.61       197\n",
      "  HS_Moderate       0.49      0.46      0.48       134\n",
      "    HS_Strong       1.00      0.14      0.24        29\n",
      "\n",
      "    micro avg       0.75      0.58      0.66      1820\n",
      "    macro avg       0.72      0.46      0.52      1820\n",
      " weighted avg       0.74      0.58      0.63      1820\n",
      "  samples avg       0.41      0.36      0.36      1820\n",
      "\n",
      "Training completed in 51.15617895126343 s\n",
      "Averaged - Iteration 1190: Accuracy: 0.8772, F1 Micro: 0.6625, F1 Macro: 0.5246\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1664\n",
      "Acquired samples: 148\n",
      "Sampling duration: 21.02265238761902 seconds\n",
      "New train size: 1338\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5585, Accuracy: 0.8222, F1 Micro: 0.3351, F1 Macro: 0.0985\n",
      "Epoch 2/10, Train Loss: 0.4425, Accuracy: 0.8318, F1 Micro: 0.3249, F1 Macro: 0.099\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3998, Accuracy: 0.8396, F1 Micro: 0.4253, F1 Macro: 0.1366\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.364, Accuracy: 0.8543, F1 Micro: 0.5009, F1 Macro: 0.229\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3289, Accuracy: 0.8649, F1 Micro: 0.5871, F1 Macro: 0.345\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3057, Accuracy: 0.8701, F1 Micro: 0.596, F1 Macro: 0.3976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2734, Accuracy: 0.8759, F1 Micro: 0.6237, F1 Macro: 0.4374\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2422, Accuracy: 0.879, F1 Micro: 0.6616, F1 Macro: 0.5164\n",
      "Epoch 9/10, Train Loss: 0.2205, Accuracy: 0.881, F1 Micro: 0.6556, F1 Macro: 0.5203\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1977, Accuracy: 0.8832, F1 Micro: 0.6792, F1 Macro: 0.5591\n",
      "Model 1 - Iteration 1338: Accuracy: 0.8832, F1 Micro: 0.6792, F1 Macro: 0.5591\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.80      0.82       360\n",
      "      Abusive       0.83      0.85      0.84       365\n",
      "HS_Individual       0.66      0.62      0.64       201\n",
      "     HS_Group       0.70      0.55      0.61       159\n",
      "  HS_Religion       0.83      0.43      0.56        68\n",
      "      HS_Race       0.92      0.75      0.83        65\n",
      "  HS_Physical       0.50      0.46      0.48        82\n",
      "    HS_Gender       0.66      0.28      0.39        83\n",
      "     HS_Other       0.80      0.16      0.26        77\n",
      "      HS_Weak       0.65      0.62      0.64       197\n",
      "  HS_Moderate       0.51      0.39      0.44       134\n",
      "    HS_Strong       1.00      0.10      0.19        29\n",
      "\n",
      "    micro avg       0.74      0.63      0.68      1820\n",
      "    macro avg       0.74      0.50      0.56      1820\n",
      " weighted avg       0.74      0.63      0.66      1820\n",
      "  samples avg       0.43      0.39      0.38      1820\n",
      "\n",
      "Training completed in 55.062071561813354 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5726, Accuracy: 0.8274, F1 Micro: 0.407, F1 Macro: 0.1147\n",
      "Epoch 2/10, Train Loss: 0.4441, Accuracy: 0.8338, F1 Micro: 0.3606, F1 Macro: 0.1092\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4011, Accuracy: 0.8427, F1 Micro: 0.444, F1 Macro: 0.1412\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3688, Accuracy: 0.8559, F1 Micro: 0.5136, F1 Macro: 0.2259\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3317, Accuracy: 0.865, F1 Micro: 0.6038, F1 Macro: 0.3761\n",
      "Epoch 6/10, Train Loss: 0.313, Accuracy: 0.8686, F1 Micro: 0.5779, F1 Macro: 0.3694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2757, Accuracy: 0.8736, F1 Micro: 0.625, F1 Macro: 0.4424\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2479, Accuracy: 0.8748, F1 Micro: 0.6495, F1 Macro: 0.4904\n",
      "Epoch 9/10, Train Loss: 0.227, Accuracy: 0.8753, F1 Micro: 0.6212, F1 Macro: 0.4754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2022, Accuracy: 0.8804, F1 Micro: 0.6634, F1 Macro: 0.5328\n",
      "Model 2 - Iteration 1338: Accuracy: 0.8804, F1 Micro: 0.6634, F1 Macro: 0.5328\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.80      0.81       360\n",
      "      Abusive       0.84      0.82      0.83       365\n",
      "HS_Individual       0.69      0.56      0.62       201\n",
      "     HS_Group       0.66      0.58      0.62       159\n",
      "  HS_Religion       0.86      0.28      0.42        68\n",
      "      HS_Race       0.89      0.77      0.83        65\n",
      "  HS_Physical       0.61      0.38      0.47        82\n",
      "    HS_Gender       0.70      0.19      0.30        83\n",
      "     HS_Other       0.71      0.16      0.26        77\n",
      "      HS_Weak       0.69      0.55      0.61       197\n",
      "  HS_Moderate       0.48      0.43      0.45       134\n",
      "    HS_Strong       1.00      0.10      0.19        29\n",
      "\n",
      "    micro avg       0.75      0.60      0.66      1820\n",
      "    macro avg       0.75      0.47      0.53      1820\n",
      " weighted avg       0.74      0.60      0.64      1820\n",
      "  samples avg       0.43      0.37      0.37      1820\n",
      "\n",
      "Training completed in 52.57735228538513 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5837, Accuracy: 0.8145, F1 Micro: 0.4067, F1 Macro: 0.1081\n",
      "Epoch 2/10, Train Loss: 0.4462, Accuracy: 0.8291, F1 Micro: 0.3083, F1 Macro: 0.0938\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4039, Accuracy: 0.8422, F1 Micro: 0.4334, F1 Macro: 0.1278\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3748, Accuracy: 0.8515, F1 Micro: 0.4867, F1 Macro: 0.2037\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3417, Accuracy: 0.864, F1 Micro: 0.5923, F1 Macro: 0.3567\n",
      "Epoch 6/10, Train Loss: 0.3203, Accuracy: 0.8685, F1 Micro: 0.5821, F1 Macro: 0.3885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2891, Accuracy: 0.8754, F1 Micro: 0.6251, F1 Macro: 0.4374\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2542, Accuracy: 0.8781, F1 Micro: 0.6575, F1 Macro: 0.4945\n",
      "Epoch 9/10, Train Loss: 0.2355, Accuracy: 0.8781, F1 Micro: 0.6278, F1 Macro: 0.4734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2108, Accuracy: 0.8827, F1 Micro: 0.6818, F1 Macro: 0.56\n",
      "Model 3 - Iteration 1338: Accuracy: 0.8827, F1 Micro: 0.6818, F1 Macro: 0.56\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.81      0.82       360\n",
      "      Abusive       0.84      0.83      0.83       365\n",
      "HS_Individual       0.68      0.61      0.64       201\n",
      "     HS_Group       0.67      0.62      0.64       159\n",
      "  HS_Religion       0.70      0.49      0.57        68\n",
      "      HS_Race       0.86      0.83      0.84        65\n",
      "  HS_Physical       0.63      0.39      0.48        82\n",
      "    HS_Gender       0.50      0.33      0.39        83\n",
      "     HS_Other       0.77      0.13      0.22        77\n",
      "      HS_Weak       0.68      0.61      0.65       197\n",
      "  HS_Moderate       0.48      0.49      0.49       134\n",
      "    HS_Strong       1.00      0.07      0.13        29\n",
      "\n",
      "    micro avg       0.73      0.64      0.68      1820\n",
      "    macro avg       0.72      0.52      0.56      1820\n",
      " weighted avg       0.73      0.64      0.67      1820\n",
      "  samples avg       0.43      0.39      0.38      1820\n",
      "\n",
      "Training completed in 52.371875524520874 s\n",
      "Averaged - Iteration 1338: Accuracy: 0.8821, F1 Micro: 0.6748, F1 Macro: 0.5506\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1664\n",
      "Acquired samples: 133\n",
      "Sampling duration: 19.201745748519897 seconds\n",
      "New train size: 1471\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5506, Accuracy: 0.8256, F1 Micro: 0.4006, F1 Macro: 0.1132\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4306, Accuracy: 0.8391, F1 Micro: 0.4168, F1 Macro: 0.1217\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4019, Accuracy: 0.8461, F1 Micro: 0.4713, F1 Macro: 0.1905\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3664, Accuracy: 0.8587, F1 Micro: 0.5206, F1 Macro: 0.2487\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3292, Accuracy: 0.8661, F1 Micro: 0.5845, F1 Macro: 0.3389\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.287, Accuracy: 0.8741, F1 Micro: 0.6284, F1 Macro: 0.4374\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2607, Accuracy: 0.8761, F1 Micro: 0.6562, F1 Macro: 0.484\n",
      "Epoch 8/10, Train Loss: 0.2356, Accuracy: 0.8787, F1 Micro: 0.6489, F1 Macro: 0.5133\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2258, Accuracy: 0.8829, F1 Micro: 0.6812, F1 Macro: 0.5714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1949, Accuracy: 0.8856, F1 Micro: 0.6829, F1 Macro: 0.5777\n",
      "Model 1 - Iteration 1471: Accuracy: 0.8856, F1 Micro: 0.6829, F1 Macro: 0.5777\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.79      0.81       360\n",
      "      Abusive       0.85      0.80      0.83       365\n",
      "HS_Individual       0.72      0.59      0.64       201\n",
      "     HS_Group       0.66      0.64      0.65       159\n",
      "  HS_Religion       0.72      0.60      0.66        68\n",
      "      HS_Race       0.86      0.77      0.81        65\n",
      "  HS_Physical       0.68      0.41      0.52        82\n",
      "    HS_Gender       0.86      0.14      0.25        83\n",
      "     HS_Other       0.71      0.19      0.31        77\n",
      "      HS_Weak       0.71      0.59      0.64       197\n",
      "  HS_Moderate       0.48      0.46      0.47       134\n",
      "    HS_Strong       1.00      0.21      0.34        29\n",
      "\n",
      "    micro avg       0.75      0.62      0.68      1820\n",
      "    macro avg       0.76      0.52      0.58      1820\n",
      " weighted avg       0.76      0.62      0.67      1820\n",
      "  samples avg       0.43      0.38      0.38      1820\n",
      "\n",
      "Training completed in 58.40063762664795 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5645, Accuracy: 0.8275, F1 Micro: 0.4342, F1 Macro: 0.1191\n",
      "Epoch 2/10, Train Loss: 0.433, Accuracy: 0.8366, F1 Micro: 0.4212, F1 Macro: 0.1213\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4031, Accuracy: 0.8442, F1 Micro: 0.4701, F1 Macro: 0.1582\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3701, Accuracy: 0.8561, F1 Micro: 0.5004, F1 Macro: 0.2275\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3313, Accuracy: 0.8639, F1 Micro: 0.5792, F1 Macro: 0.3435\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.291, Accuracy: 0.8711, F1 Micro: 0.6281, F1 Macro: 0.4211\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2632, Accuracy: 0.8745, F1 Micro: 0.6445, F1 Macro: 0.4651\n",
      "Epoch 8/10, Train Loss: 0.2432, Accuracy: 0.878, F1 Micro: 0.636, F1 Macro: 0.4853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.231, Accuracy: 0.8805, F1 Micro: 0.6868, F1 Macro: 0.5755\n",
      "Epoch 10/10, Train Loss: 0.2018, Accuracy: 0.8822, F1 Micro: 0.6613, F1 Macro: 0.5387\n",
      "Model 2 - Iteration 1471: Accuracy: 0.8805, F1 Micro: 0.6868, F1 Macro: 0.5755\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.84      0.82       360\n",
      "      Abusive       0.80      0.86      0.83       365\n",
      "HS_Individual       0.64      0.64      0.64       201\n",
      "     HS_Group       0.66      0.65      0.66       159\n",
      "  HS_Religion       0.78      0.43      0.55        68\n",
      "      HS_Race       0.82      0.82      0.82        65\n",
      "  HS_Physical       0.54      0.45      0.49        82\n",
      "    HS_Gender       0.64      0.34      0.44        83\n",
      "     HS_Other       0.72      0.17      0.27        77\n",
      "      HS_Weak       0.64      0.63      0.64       197\n",
      "  HS_Moderate       0.50      0.51      0.51       134\n",
      "    HS_Strong       0.80      0.14      0.24        29\n",
      "\n",
      "    micro avg       0.71      0.66      0.69      1820\n",
      "    macro avg       0.70      0.54      0.58      1820\n",
      " weighted avg       0.71      0.66      0.67      1820\n",
      "  samples avg       0.43      0.41      0.39      1820\n",
      "\n",
      "Training completed in 55.107964277267456 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5716, Accuracy: 0.8183, F1 Micro: 0.35, F1 Macro: 0.0947\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4327, Accuracy: 0.8384, F1 Micro: 0.4271, F1 Macro: 0.123\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4052, Accuracy: 0.8429, F1 Micro: 0.4688, F1 Macro: 0.1614\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3751, Accuracy: 0.8589, F1 Micro: 0.5124, F1 Macro: 0.2427\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3397, Accuracy: 0.8661, F1 Micro: 0.5724, F1 Macro: 0.3146\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2968, Accuracy: 0.871, F1 Micro: 0.6215, F1 Macro: 0.4321\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2696, Accuracy: 0.8741, F1 Micro: 0.6535, F1 Macro: 0.4823\n",
      "Epoch 8/10, Train Loss: 0.2463, Accuracy: 0.8789, F1 Micro: 0.6462, F1 Macro: 0.503\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2351, Accuracy: 0.8847, F1 Micro: 0.6843, F1 Macro: 0.5679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2069, Accuracy: 0.8882, F1 Micro: 0.6967, F1 Macro: 0.5954\n",
      "Model 3 - Iteration 1471: Accuracy: 0.8882, F1 Micro: 0.6967, F1 Macro: 0.5954\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.82      0.83       360\n",
      "      Abusive       0.84      0.83      0.83       365\n",
      "HS_Individual       0.70      0.60      0.65       201\n",
      "     HS_Group       0.67      0.64      0.65       159\n",
      "  HS_Religion       0.68      0.60      0.64        68\n",
      "      HS_Race       0.85      0.82      0.83        65\n",
      "  HS_Physical       0.72      0.40      0.52        82\n",
      "    HS_Gender       0.61      0.30      0.40        83\n",
      "     HS_Other       0.79      0.19      0.31        77\n",
      "      HS_Weak       0.71      0.60      0.65       197\n",
      "  HS_Moderate       0.52      0.54      0.53       134\n",
      "    HS_Strong       1.00      0.17      0.29        29\n",
      "\n",
      "    micro avg       0.75      0.65      0.70      1820\n",
      "    macro avg       0.74      0.54      0.60      1820\n",
      " weighted avg       0.75      0.65      0.68      1820\n",
      "  samples avg       0.44      0.40      0.39      1820\n",
      "\n",
      "Training completed in 58.90374541282654 s\n",
      "Averaged - Iteration 1471: Accuracy: 0.8848, F1 Micro: 0.6888, F1 Macro: 0.5829\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1664\n",
      "Acquired samples: 120\n",
      "Sampling duration: 17.60651206970215 seconds\n",
      "New train size: 1591\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.543, Accuracy: 0.8306, F1 Micro: 0.3718, F1 Macro: 0.1103\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.433, Accuracy: 0.8371, F1 Micro: 0.456, F1 Macro: 0.126\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3986, Accuracy: 0.8516, F1 Micro: 0.5142, F1 Macro: 0.2242\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3454, Accuracy: 0.8641, F1 Micro: 0.5787, F1 Macro: 0.3166\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3123, Accuracy: 0.8685, F1 Micro: 0.6203, F1 Macro: 0.4109\n",
      "Epoch 6/10, Train Loss: 0.2741, Accuracy: 0.8712, F1 Micro: 0.6026, F1 Macro: 0.4041\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2504, Accuracy: 0.8765, F1 Micro: 0.6259, F1 Macro: 0.4485\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2256, Accuracy: 0.8821, F1 Micro: 0.6615, F1 Macro: 0.5381\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1958, Accuracy: 0.8835, F1 Micro: 0.6699, F1 Macro: 0.5734\n",
      "Epoch 10/10, Train Loss: 0.1807, Accuracy: 0.8863, F1 Micro: 0.6606, F1 Macro: 0.5435\n",
      "Model 1 - Iteration 1591: Accuracy: 0.8835, F1 Micro: 0.6699, F1 Macro: 0.5734\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.78      0.81       360\n",
      "      Abusive       0.89      0.73      0.80       365\n",
      "HS_Individual       0.73      0.56      0.63       201\n",
      "     HS_Group       0.65      0.64      0.64       159\n",
      "  HS_Religion       0.75      0.65      0.69        68\n",
      "      HS_Race       0.83      0.88      0.85        65\n",
      "  HS_Physical       0.61      0.37      0.46        82\n",
      "    HS_Gender       0.87      0.16      0.27        83\n",
      "     HS_Other       0.68      0.17      0.27        77\n",
      "      HS_Weak       0.73      0.57      0.64       197\n",
      "  HS_Moderate       0.45      0.41      0.43       134\n",
      "    HS_Strong       1.00      0.24      0.39        29\n",
      "\n",
      "    micro avg       0.76      0.60      0.67      1820\n",
      "    macro avg       0.75      0.51      0.57      1820\n",
      " weighted avg       0.76      0.60      0.65      1820\n",
      "  samples avg       0.41      0.36      0.36      1820\n",
      "\n",
      "Training completed in 58.90223050117493 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5561, Accuracy: 0.8258, F1 Micro: 0.4359, F1 Macro: 0.1187\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4363, Accuracy: 0.8364, F1 Micro: 0.446, F1 Macro: 0.1259\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3999, Accuracy: 0.8494, F1 Micro: 0.4874, F1 Macro: 0.1866\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3497, Accuracy: 0.8612, F1 Micro: 0.5639, F1 Macro: 0.2965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3185, Accuracy: 0.8672, F1 Micro: 0.6189, F1 Macro: 0.3959\n",
      "Epoch 6/10, Train Loss: 0.2764, Accuracy: 0.8704, F1 Micro: 0.5969, F1 Macro: 0.3873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.253, Accuracy: 0.8761, F1 Micro: 0.6258, F1 Macro: 0.4415\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2325, Accuracy: 0.8781, F1 Micro: 0.6322, F1 Macro: 0.4857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1983, Accuracy: 0.8811, F1 Micro: 0.656, F1 Macro: 0.5547\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1838, Accuracy: 0.883, F1 Micro: 0.6619, F1 Macro: 0.5279\n",
      "Model 2 - Iteration 1591: Accuracy: 0.883, F1 Micro: 0.6619, F1 Macro: 0.5279\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.75      0.80       360\n",
      "      Abusive       0.86      0.81      0.83       365\n",
      "HS_Individual       0.67      0.59      0.62       201\n",
      "     HS_Group       0.73      0.50      0.59       159\n",
      "  HS_Religion       0.96      0.35      0.52        68\n",
      "      HS_Race       0.87      0.69      0.77        65\n",
      "  HS_Physical       0.60      0.39      0.47        82\n",
      "    HS_Gender       0.86      0.22      0.35        83\n",
      "     HS_Other       0.76      0.17      0.28        77\n",
      "      HS_Weak       0.67      0.59      0.63       197\n",
      "  HS_Moderate       0.52      0.34      0.41       134\n",
      "    HS_Strong       1.00      0.03      0.07        29\n",
      "\n",
      "    micro avg       0.77      0.58      0.66      1820\n",
      "    macro avg       0.78      0.45      0.53      1820\n",
      " weighted avg       0.77      0.58      0.64      1820\n",
      "  samples avg       0.43      0.36      0.36      1820\n",
      "\n",
      "Training completed in 61.493425607681274 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5625, Accuracy: 0.82, F1 Micro: 0.2889, F1 Macro: 0.0819\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4356, Accuracy: 0.8365, F1 Micro: 0.3775, F1 Macro: 0.1141\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4043, Accuracy: 0.8448, F1 Micro: 0.4211, F1 Macro: 0.1485\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3555, Accuracy: 0.8624, F1 Micro: 0.5678, F1 Macro: 0.297\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3228, Accuracy: 0.8676, F1 Micro: 0.6221, F1 Macro: 0.3967\n",
      "Epoch 6/10, Train Loss: 0.283, Accuracy: 0.8694, F1 Micro: 0.5943, F1 Macro: 0.3907\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.261, Accuracy: 0.8755, F1 Micro: 0.6238, F1 Macro: 0.4455\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2344, Accuracy: 0.8804, F1 Micro: 0.6468, F1 Macro: 0.5197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2061, Accuracy: 0.8865, F1 Micro: 0.6857, F1 Macro: 0.5979\n",
      "Epoch 10/10, Train Loss: 0.1863, Accuracy: 0.887, F1 Micro: 0.6756, F1 Macro: 0.5536\n",
      "Model 3 - Iteration 1591: Accuracy: 0.8865, F1 Micro: 0.6857, F1 Macro: 0.5979\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.82      0.83       360\n",
      "      Abusive       0.87      0.77      0.81       365\n",
      "HS_Individual       0.72      0.57      0.64       201\n",
      "     HS_Group       0.64      0.66      0.65       159\n",
      "  HS_Religion       0.73      0.60      0.66        68\n",
      "      HS_Race       0.84      0.88      0.86        65\n",
      "  HS_Physical       0.68      0.34      0.46        82\n",
      "    HS_Gender       0.64      0.22      0.32        83\n",
      "     HS_Other       0.71      0.16      0.26        77\n",
      "      HS_Weak       0.74      0.56      0.64       197\n",
      "  HS_Moderate       0.48      0.52      0.50       134\n",
      "    HS_Strong       1.00      0.38      0.55        29\n",
      "\n",
      "    micro avg       0.76      0.63      0.69      1820\n",
      "    macro avg       0.74      0.54      0.60      1820\n",
      " weighted avg       0.76      0.63      0.67      1820\n",
      "  samples avg       0.43      0.38      0.38      1820\n",
      "\n",
      "Training completed in 60.63746929168701 s\n",
      "Averaged - Iteration 1591: Accuracy: 0.8843, F1 Micro: 0.6725, F1 Macro: 0.5664\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1664\n",
      "Acquired samples: 73\n",
      "Sampling duration: 15.624293565750122 seconds\n",
      "New train size: 1664\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5429, Accuracy: 0.83, F1 Micro: 0.3719, F1 Macro: 0.1102\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4301, Accuracy: 0.8378, F1 Micro: 0.4098, F1 Macro: 0.12\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3951, Accuracy: 0.8492, F1 Micro: 0.5018, F1 Macro: 0.2128\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3497, Accuracy: 0.8625, F1 Micro: 0.5617, F1 Macro: 0.294\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3137, Accuracy: 0.8697, F1 Micro: 0.613, F1 Macro: 0.3987\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2801, Accuracy: 0.8773, F1 Micro: 0.6506, F1 Macro: 0.4687\n",
      "Epoch 7/10, Train Loss: 0.2548, Accuracy: 0.8764, F1 Micro: 0.6473, F1 Macro: 0.483\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2252, Accuracy: 0.8814, F1 Micro: 0.6644, F1 Macro: 0.5481\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2047, Accuracy: 0.8853, F1 Micro: 0.6872, F1 Macro: 0.6055\n",
      "Epoch 10/10, Train Loss: 0.1834, Accuracy: 0.8879, F1 Micro: 0.6765, F1 Macro: 0.5608\n",
      "Model 1 - Iteration 1664: Accuracy: 0.8853, F1 Micro: 0.6872, F1 Macro: 0.6055\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.82      0.83       360\n",
      "      Abusive       0.86      0.77      0.81       365\n",
      "HS_Individual       0.70      0.57      0.63       201\n",
      "     HS_Group       0.65      0.69      0.67       159\n",
      "  HS_Religion       0.76      0.65      0.70        68\n",
      "      HS_Race       0.85      0.86      0.85        65\n",
      "  HS_Physical       0.55      0.35      0.43        82\n",
      "    HS_Gender       0.70      0.19      0.30        83\n",
      "     HS_Other       0.68      0.25      0.36        77\n",
      "      HS_Weak       0.71      0.59      0.64       197\n",
      "  HS_Moderate       0.48      0.52      0.50       134\n",
      "    HS_Strong       0.92      0.38      0.54        29\n",
      "\n",
      "    micro avg       0.74      0.64      0.69      1820\n",
      "    macro avg       0.72      0.55      0.61      1820\n",
      " weighted avg       0.74      0.64      0.68      1820\n",
      "  samples avg       0.41      0.38      0.37      1820\n",
      "\n",
      "Training completed in 58.80759239196777 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5571, Accuracy: 0.8292, F1 Micro: 0.4276, F1 Macro: 0.1188\n",
      "Epoch 2/10, Train Loss: 0.4309, Accuracy: 0.8357, F1 Micro: 0.3764, F1 Macro: 0.1136\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3978, Accuracy: 0.849, F1 Micro: 0.492, F1 Macro: 0.1876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3499, Accuracy: 0.861, F1 Micro: 0.5554, F1 Macro: 0.2909\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3153, Accuracy: 0.8699, F1 Micro: 0.624, F1 Macro: 0.4081\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2845, Accuracy: 0.8764, F1 Micro: 0.6435, F1 Macro: 0.4512\n",
      "Epoch 7/10, Train Loss: 0.2591, Accuracy: 0.8763, F1 Micro: 0.6422, F1 Macro: 0.4734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2291, Accuracy: 0.8816, F1 Micro: 0.6564, F1 Macro: 0.5106\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2089, Accuracy: 0.883, F1 Micro: 0.6755, F1 Macro: 0.5769\n",
      "Epoch 10/10, Train Loss: 0.1862, Accuracy: 0.8837, F1 Micro: 0.6633, F1 Macro: 0.5558\n",
      "Model 2 - Iteration 1664: Accuracy: 0.883, F1 Micro: 0.6755, F1 Macro: 0.5769\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.79      0.81       360\n",
      "      Abusive       0.85      0.78      0.82       365\n",
      "HS_Individual       0.67      0.58      0.62       201\n",
      "     HS_Group       0.68      0.63      0.65       159\n",
      "  HS_Religion       0.90      0.40      0.55        68\n",
      "      HS_Race       0.81      0.85      0.83        65\n",
      "  HS_Physical       0.60      0.44      0.51        82\n",
      "    HS_Gender       0.67      0.27      0.38        83\n",
      "     HS_Other       0.74      0.18      0.29        77\n",
      "      HS_Weak       0.68      0.58      0.63       197\n",
      "  HS_Moderate       0.51      0.45      0.48       134\n",
      "    HS_Strong       0.70      0.24      0.36        29\n",
      "\n",
      "    micro avg       0.75      0.62      0.68      1820\n",
      "    macro avg       0.72      0.52      0.58      1820\n",
      " weighted avg       0.74      0.62      0.66      1820\n",
      "  samples avg       0.42      0.38      0.37      1820\n",
      "\n",
      "Training completed in 57.08041191101074 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.561, Accuracy: 0.8183, F1 Micro: 0.2526, F1 Macro: 0.0723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4322, Accuracy: 0.832, F1 Micro: 0.3373, F1 Macro: 0.1031\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4023, Accuracy: 0.8458, F1 Micro: 0.452, F1 Macro: 0.1588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3599, Accuracy: 0.8604, F1 Micro: 0.5349, F1 Macro: 0.2696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3231, Accuracy: 0.8692, F1 Micro: 0.6094, F1 Macro: 0.3858\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2897, Accuracy: 0.8761, F1 Micro: 0.6438, F1 Macro: 0.4488\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2641, Accuracy: 0.8752, F1 Micro: 0.6466, F1 Macro: 0.4813\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2349, Accuracy: 0.8811, F1 Micro: 0.6505, F1 Macro: 0.5132\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2123, Accuracy: 0.8852, F1 Micro: 0.6817, F1 Macro: 0.605\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1913, Accuracy: 0.8893, F1 Micro: 0.6905, F1 Macro: 0.5745\n",
      "Model 3 - Iteration 1664: Accuracy: 0.8893, F1 Micro: 0.6905, F1 Macro: 0.5745\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.79      0.82       360\n",
      "      Abusive       0.85      0.81      0.83       365\n",
      "HS_Individual       0.69      0.64      0.66       201\n",
      "     HS_Group       0.75      0.57      0.65       159\n",
      "  HS_Religion       0.82      0.49      0.61        68\n",
      "      HS_Race       0.91      0.82      0.86        65\n",
      "  HS_Physical       0.69      0.41      0.52        82\n",
      "    HS_Gender       0.61      0.34      0.43        83\n",
      "     HS_Other       0.80      0.16      0.26        77\n",
      "      HS_Weak       0.69      0.63      0.66       197\n",
      "  HS_Moderate       0.54      0.40      0.46       134\n",
      "    HS_Strong       1.00      0.07      0.13        29\n",
      "\n",
      "    micro avg       0.77      0.63      0.69      1820\n",
      "    macro avg       0.77      0.51      0.57      1820\n",
      " weighted avg       0.77      0.63      0.67      1820\n",
      "  samples avg       0.43      0.38      0.38      1820\n",
      "\n",
      "Training completed in 62.81116604804993 s\n",
      "Averaged - Iteration 1664: Accuracy: 0.8859, F1 Micro: 0.6844, F1 Macro: 0.5857\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1996\n",
      "Acquired samples: 100\n",
      "Sampling duration: 15.133268594741821 seconds\n",
      "New train size: 1764\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5416, Accuracy: 0.8337, F1 Micro: 0.4079, F1 Macro: 0.118\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4348, Accuracy: 0.8385, F1 Micro: 0.4316, F1 Macro: 0.1238\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3882, Accuracy: 0.8555, F1 Micro: 0.5303, F1 Macro: 0.2504\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3377, Accuracy: 0.8637, F1 Micro: 0.5449, F1 Macro: 0.3054\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3125, Accuracy: 0.8727, F1 Micro: 0.6203, F1 Macro: 0.4191\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2713, Accuracy: 0.8765, F1 Micro: 0.6503, F1 Macro: 0.468\n",
      "Epoch 7/10, Train Loss: 0.249, Accuracy: 0.8775, F1 Micro: 0.6345, F1 Macro: 0.4899\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2174, Accuracy: 0.8841, F1 Micro: 0.665, F1 Macro: 0.5559\n",
      "Epoch 9/10, Train Loss: 0.1884, Accuracy: 0.8816, F1 Micro: 0.6454, F1 Macro: 0.4997\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1724, Accuracy: 0.8882, F1 Micro: 0.6862, F1 Macro: 0.5696\n",
      "Model 1 - Iteration 1764: Accuracy: 0.8882, F1 Micro: 0.6862, F1 Macro: 0.5696\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.79      0.82       360\n",
      "      Abusive       0.86      0.81      0.84       365\n",
      "HS_Individual       0.68      0.63      0.65       201\n",
      "     HS_Group       0.72      0.52      0.60       159\n",
      "  HS_Religion       0.84      0.54      0.66        68\n",
      "      HS_Race       0.91      0.80      0.85        65\n",
      "  HS_Physical       0.61      0.46      0.53        82\n",
      "    HS_Gender       1.00      0.20      0.34        83\n",
      "     HS_Other       0.70      0.21      0.32        77\n",
      "      HS_Weak       0.69      0.62      0.65       197\n",
      "  HS_Moderate       0.52      0.38      0.44       134\n",
      "    HS_Strong       1.00      0.07      0.13        29\n",
      "\n",
      "    micro avg       0.77      0.62      0.69      1820\n",
      "    macro avg       0.78      0.50      0.57      1820\n",
      " weighted avg       0.77      0.62      0.67      1820\n",
      "  samples avg       0.43      0.38      0.38      1820\n",
      "\n",
      "Training completed in 61.02964377403259 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5521, Accuracy: 0.8301, F1 Micro: 0.4482, F1 Macro: 0.122\n",
      "Epoch 2/10, Train Loss: 0.4354, Accuracy: 0.8378, F1 Micro: 0.4243, F1 Macro: 0.1238\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3897, Accuracy: 0.8537, F1 Micro: 0.5095, F1 Macro: 0.2067\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3416, Accuracy: 0.8623, F1 Micro: 0.5505, F1 Macro: 0.3107\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3153, Accuracy: 0.8736, F1 Micro: 0.6177, F1 Macro: 0.4021\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2724, Accuracy: 0.8765, F1 Micro: 0.6496, F1 Macro: 0.454\n",
      "Epoch 7/10, Train Loss: 0.2546, Accuracy: 0.8786, F1 Micro: 0.6361, F1 Macro: 0.4748\n",
      "Epoch 8/10, Train Loss: 0.2209, Accuracy: 0.8793, F1 Micro: 0.6347, F1 Macro: 0.4856\n",
      "Epoch 9/10, Train Loss: 0.1916, Accuracy: 0.8792, F1 Micro: 0.6397, F1 Macro: 0.4985\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1735, Accuracy: 0.8892, F1 Micro: 0.6905, F1 Macro: 0.5891\n",
      "Model 2 - Iteration 1764: Accuracy: 0.8892, F1 Micro: 0.6905, F1 Macro: 0.5891\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.78      0.82       360\n",
      "      Abusive       0.87      0.81      0.84       365\n",
      "HS_Individual       0.70      0.58      0.64       201\n",
      "     HS_Group       0.71      0.64      0.67       159\n",
      "  HS_Religion       0.81      0.56      0.66        68\n",
      "      HS_Race       0.86      0.83      0.84        65\n",
      "  HS_Physical       0.64      0.39      0.48        82\n",
      "    HS_Gender       0.76      0.23      0.35        83\n",
      "     HS_Other       0.68      0.27      0.39        77\n",
      "      HS_Weak       0.71      0.56      0.63       197\n",
      "  HS_Moderate       0.52      0.49      0.51       134\n",
      "    HS_Strong       1.00      0.14      0.24        29\n",
      "\n",
      "    micro avg       0.77      0.63      0.69      1820\n",
      "    macro avg       0.76      0.52      0.59      1820\n",
      " weighted avg       0.77      0.63      0.68      1820\n",
      "  samples avg       0.43      0.38      0.38      1820\n",
      "\n",
      "Training completed in 57.94980573654175 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5612, Accuracy: 0.8191, F1 Micro: 0.2685, F1 Macro: 0.072\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4374, Accuracy: 0.8371, F1 Micro: 0.3926, F1 Macro: 0.1175\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3952, Accuracy: 0.8477, F1 Micro: 0.4415, F1 Macro: 0.1569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3504, Accuracy: 0.8593, F1 Micro: 0.5184, F1 Macro: 0.288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3241, Accuracy: 0.8712, F1 Micro: 0.6152, F1 Macro: 0.4071\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2784, Accuracy: 0.8758, F1 Micro: 0.6502, F1 Macro: 0.4715\n",
      "Epoch 7/10, Train Loss: 0.2616, Accuracy: 0.877, F1 Micro: 0.6328, F1 Macro: 0.4873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2274, Accuracy: 0.8835, F1 Micro: 0.6635, F1 Macro: 0.5716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1976, Accuracy: 0.8838, F1 Micro: 0.6639, F1 Macro: 0.551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1788, Accuracy: 0.8916, F1 Micro: 0.7076, F1 Macro: 0.6212\n",
      "Model 3 - Iteration 1764: Accuracy: 0.8916, F1 Micro: 0.7076, F1 Macro: 0.6212\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.80      0.83       360\n",
      "      Abusive       0.85      0.84      0.84       365\n",
      "HS_Individual       0.69      0.67      0.68       201\n",
      "     HS_Group       0.69      0.61      0.65       159\n",
      "  HS_Religion       0.78      0.62      0.69        68\n",
      "      HS_Race       0.90      0.85      0.87        65\n",
      "  HS_Physical       0.67      0.40      0.50        82\n",
      "    HS_Gender       0.62      0.43      0.51        83\n",
      "     HS_Other       0.75      0.19      0.31        77\n",
      "      HS_Weak       0.68      0.63      0.66       197\n",
      "  HS_Moderate       0.53      0.51      0.52       134\n",
      "    HS_Strong       1.00      0.24      0.39        29\n",
      "\n",
      "    micro avg       0.76      0.66      0.71      1820\n",
      "    macro avg       0.75      0.57      0.62      1820\n",
      " weighted avg       0.76      0.66      0.70      1820\n",
      "  samples avg       0.44      0.41      0.40      1820\n",
      "\n",
      "Training completed in 60.64521026611328 s\n",
      "Averaged - Iteration 1764: Accuracy: 0.8897, F1 Micro: 0.6948, F1 Macro: 0.5933\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1996\n",
      "Acquired samples: 100\n",
      "Sampling duration: 12.17301893234253 seconds\n",
      "New train size: 1864\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.533, Accuracy: 0.837, F1 Micro: 0.4119, F1 Macro: 0.1201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4235, Accuracy: 0.8375, F1 Micro: 0.413, F1 Macro: 0.1206\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.378, Accuracy: 0.8523, F1 Micro: 0.458, F1 Macro: 0.2059\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3389, Accuracy: 0.8646, F1 Micro: 0.6018, F1 Macro: 0.3688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2924, Accuracy: 0.8732, F1 Micro: 0.6233, F1 Macro: 0.423\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2639, Accuracy: 0.8778, F1 Micro: 0.6571, F1 Macro: 0.4645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2383, Accuracy: 0.8814, F1 Micro: 0.679, F1 Macro: 0.5661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2166, Accuracy: 0.8848, F1 Micro: 0.6898, F1 Macro: 0.6144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1889, Accuracy: 0.8894, F1 Micro: 0.6902, F1 Macro: 0.6047\n",
      "Epoch 10/10, Train Loss: 0.1654, Accuracy: 0.8886, F1 Micro: 0.6866, F1 Macro: 0.5701\n",
      "Model 1 - Iteration 1864: Accuracy: 0.8894, F1 Micro: 0.6902, F1 Macro: 0.6047\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.78      0.82       360\n",
      "      Abusive       0.89      0.78      0.83       365\n",
      "HS_Individual       0.70      0.61      0.65       201\n",
      "     HS_Group       0.70      0.60      0.65       159\n",
      "  HS_Religion       0.85      0.59      0.70        68\n",
      "      HS_Race       0.86      0.86      0.86        65\n",
      "  HS_Physical       0.67      0.45      0.54        82\n",
      "    HS_Gender       0.89      0.19      0.32        83\n",
      "     HS_Other       0.76      0.25      0.37        77\n",
      "      HS_Weak       0.68      0.61      0.64       197\n",
      "  HS_Moderate       0.50      0.42      0.45       134\n",
      "    HS_Strong       1.00      0.28      0.43        29\n",
      "\n",
      "    micro avg       0.77      0.62      0.69      1820\n",
      "    macro avg       0.78      0.53      0.60      1820\n",
      " weighted avg       0.78      0.62      0.68      1820\n",
      "  samples avg       0.43      0.38      0.38      1820\n",
      "\n",
      "Training completed in 63.63036036491394 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5424, Accuracy: 0.8316, F1 Micro: 0.4461, F1 Macro: 0.1223\n",
      "Epoch 2/10, Train Loss: 0.4236, Accuracy: 0.8397, F1 Micro: 0.4326, F1 Macro: 0.1279\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3769, Accuracy: 0.8542, F1 Micro: 0.4843, F1 Macro: 0.2004\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3395, Accuracy: 0.8658, F1 Micro: 0.5924, F1 Macro: 0.3615\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2954, Accuracy: 0.8689, F1 Micro: 0.5992, F1 Macro: 0.3851\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2659, Accuracy: 0.8773, F1 Micro: 0.6502, F1 Macro: 0.4503\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2395, Accuracy: 0.881, F1 Micro: 0.6715, F1 Macro: 0.541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2195, Accuracy: 0.8835, F1 Micro: 0.6824, F1 Macro: 0.5831\n",
      "Epoch 9/10, Train Loss: 0.1923, Accuracy: 0.8868, F1 Micro: 0.6817, F1 Macro: 0.5853\n",
      "Epoch 10/10, Train Loss: 0.1708, Accuracy: 0.8861, F1 Micro: 0.6729, F1 Macro: 0.5506\n",
      "Model 2 - Iteration 1864: Accuracy: 0.8835, F1 Micro: 0.6824, F1 Macro: 0.5831\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.83      0.83       360\n",
      "      Abusive       0.87      0.77      0.82       365\n",
      "HS_Individual       0.68      0.55      0.61       201\n",
      "     HS_Group       0.64      0.70      0.67       159\n",
      "  HS_Religion       0.76      0.54      0.63        68\n",
      "      HS_Race       0.81      0.86      0.84        65\n",
      "  HS_Physical       0.62      0.40      0.49        82\n",
      "    HS_Gender       0.71      0.24      0.36        83\n",
      "     HS_Other       0.65      0.22      0.33        77\n",
      "      HS_Weak       0.69      0.54      0.61       197\n",
      "  HS_Moderate       0.51      0.57      0.54       134\n",
      "    HS_Strong       0.83      0.17      0.29        29\n",
      "\n",
      "    micro avg       0.74      0.63      0.68      1820\n",
      "    macro avg       0.72      0.53      0.58      1820\n",
      " weighted avg       0.74      0.63      0.67      1820\n",
      "  samples avg       0.41      0.38      0.38      1820\n",
      "\n",
      "Training completed in 60.89726901054382 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5522, Accuracy: 0.8198, F1 Micro: 0.2335, F1 Macro: 0.0704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4245, Accuracy: 0.8395, F1 Micro: 0.427, F1 Macro: 0.1236\n",
      "Epoch 3/10, Train Loss: 0.3831, Accuracy: 0.8397, F1 Micro: 0.368, F1 Macro: 0.1356\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3493, Accuracy: 0.8673, F1 Micro: 0.6081, F1 Macro: 0.3653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3034, Accuracy: 0.8723, F1 Micro: 0.6096, F1 Macro: 0.4011\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2721, Accuracy: 0.8777, F1 Micro: 0.6523, F1 Macro: 0.467\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2451, Accuracy: 0.8822, F1 Micro: 0.664, F1 Macro: 0.5204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2209, Accuracy: 0.8872, F1 Micro: 0.6956, F1 Macro: 0.6157\n",
      "Epoch 9/10, Train Loss: 0.1958, Accuracy: 0.888, F1 Micro: 0.6838, F1 Macro: 0.5892\n",
      "Epoch 10/10, Train Loss: 0.173, Accuracy: 0.886, F1 Micro: 0.6604, F1 Macro: 0.546\n",
      "Model 3 - Iteration 1864: Accuracy: 0.8872, F1 Micro: 0.6956, F1 Macro: 0.6157\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.83      0.84       360\n",
      "      Abusive       0.87      0.79      0.83       365\n",
      "HS_Individual       0.71      0.60      0.65       201\n",
      "     HS_Group       0.65      0.68      0.66       159\n",
      "  HS_Religion       0.69      0.65      0.67        68\n",
      "      HS_Race       0.85      0.86      0.85        65\n",
      "  HS_Physical       0.62      0.34      0.44        82\n",
      "    HS_Gender       0.58      0.30      0.40        83\n",
      "     HS_Other       0.60      0.23      0.34        77\n",
      "      HS_Weak       0.72      0.59      0.65       197\n",
      "  HS_Moderate       0.48      0.55      0.51       134\n",
      "    HS_Strong       1.00      0.38      0.55        29\n",
      "\n",
      "    micro avg       0.74      0.65      0.70      1820\n",
      "    macro avg       0.72      0.57      0.62      1820\n",
      " weighted avg       0.74      0.65      0.69      1820\n",
      "  samples avg       0.42      0.40      0.39      1820\n",
      "\n",
      "Training completed in 60.40172052383423 s\n",
      "Averaged - Iteration 1864: Accuracy: 0.8867, F1 Micro: 0.6894, F1 Macro: 0.6011\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1996\n",
      "Acquired samples: 100\n",
      "Sampling duration: 11.849092483520508 seconds\n",
      "New train size: 1964\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5273, Accuracy: 0.835, F1 Micro: 0.3681, F1 Macro: 0.1125\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4201, Accuracy: 0.8383, F1 Micro: 0.3863, F1 Macro: 0.1189\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3698, Accuracy: 0.8582, F1 Micro: 0.5263, F1 Macro: 0.2504\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.322, Accuracy: 0.8679, F1 Micro: 0.598, F1 Macro: 0.379\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2845, Accuracy: 0.8742, F1 Micro: 0.6431, F1 Macro: 0.4764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2597, Accuracy: 0.8791, F1 Micro: 0.6587, F1 Macro: 0.4948\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2247, Accuracy: 0.8824, F1 Micro: 0.6665, F1 Macro: 0.5553\n",
      "Epoch 8/10, Train Loss: 0.2025, Accuracy: 0.8813, F1 Micro: 0.6411, F1 Macro: 0.5197\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1761, Accuracy: 0.8893, F1 Micro: 0.6826, F1 Macro: 0.5727\n",
      "Epoch 10/10, Train Loss: 0.1539, Accuracy: 0.8888, F1 Micro: 0.681, F1 Macro: 0.5593\n",
      "Model 1 - Iteration 1964: Accuracy: 0.8893, F1 Micro: 0.6826, F1 Macro: 0.5727\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.78      0.81       360\n",
      "      Abusive       0.89      0.78      0.83       365\n",
      "HS_Individual       0.76      0.58      0.66       201\n",
      "     HS_Group       0.68      0.58      0.62       159\n",
      "  HS_Religion       0.82      0.54      0.65        68\n",
      "      HS_Race       0.89      0.83      0.86        65\n",
      "  HS_Physical       0.69      0.40      0.51        82\n",
      "    HS_Gender       1.00      0.12      0.22        83\n",
      "     HS_Other       0.67      0.26      0.37        77\n",
      "      HS_Weak       0.75      0.58      0.65       197\n",
      "  HS_Moderate       0.49      0.40      0.44       134\n",
      "    HS_Strong       1.00      0.14      0.24        29\n",
      "\n",
      "    micro avg       0.79      0.60      0.68      1820\n",
      "    macro avg       0.79      0.50      0.57      1820\n",
      " weighted avg       0.79      0.60      0.67      1820\n",
      "  samples avg       0.43      0.37      0.38      1820\n",
      "\n",
      "Training completed in 67.24328970909119 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5371, Accuracy: 0.8334, F1 Micro: 0.4098, F1 Macro: 0.1181\n",
      "Epoch 2/10, Train Loss: 0.4203, Accuracy: 0.8357, F1 Micro: 0.3485, F1 Macro: 0.1108\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3722, Accuracy: 0.856, F1 Micro: 0.5152, F1 Macro: 0.2382\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3251, Accuracy: 0.8684, F1 Micro: 0.6053, F1 Macro: 0.3814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2864, Accuracy: 0.8737, F1 Micro: 0.6449, F1 Macro: 0.4648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2639, Accuracy: 0.8774, F1 Micro: 0.6506, F1 Macro: 0.4913\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2306, Accuracy: 0.8823, F1 Micro: 0.6671, F1 Macro: 0.5473\n",
      "Epoch 8/10, Train Loss: 0.2096, Accuracy: 0.8808, F1 Micro: 0.6426, F1 Macro: 0.5191\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1832, Accuracy: 0.8883, F1 Micro: 0.6924, F1 Macro: 0.5835\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1564, Accuracy: 0.892, F1 Micro: 0.7006, F1 Macro: 0.6228\n",
      "Model 2 - Iteration 1964: Accuracy: 0.892, F1 Micro: 0.7006, F1 Macro: 0.6228\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.79      0.82       360\n",
      "      Abusive       0.88      0.79      0.83       365\n",
      "HS_Individual       0.67      0.57      0.61       201\n",
      "     HS_Group       0.69      0.66      0.67       159\n",
      "  HS_Religion       0.82      0.60      0.69        68\n",
      "      HS_Race       0.90      0.85      0.87        65\n",
      "  HS_Physical       0.76      0.46      0.58        82\n",
      "    HS_Gender       0.87      0.31      0.46        83\n",
      "     HS_Other       0.65      0.26      0.37        77\n",
      "      HS_Weak       0.70      0.57      0.63       197\n",
      "  HS_Moderate       0.55      0.52      0.54       134\n",
      "    HS_Strong       1.00      0.24      0.39        29\n",
      "\n",
      "    micro avg       0.77      0.64      0.70      1820\n",
      "    macro avg       0.78      0.55      0.62      1820\n",
      " weighted avg       0.78      0.64      0.69      1820\n",
      "  samples avg       0.43      0.39      0.39      1820\n",
      "\n",
      "Training completed in 66.4127037525177 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5422, Accuracy: 0.8184, F1 Micro: 0.2133, F1 Macro: 0.0668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4199, Accuracy: 0.8344, F1 Micro: 0.3456, F1 Macro: 0.1075\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.375, Accuracy: 0.8569, F1 Micro: 0.5043, F1 Macro: 0.2246\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3276, Accuracy: 0.8665, F1 Micro: 0.5678, F1 Macro: 0.3491\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2886, Accuracy: 0.8734, F1 Micro: 0.6366, F1 Macro: 0.4495\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2657, Accuracy: 0.8773, F1 Micro: 0.6551, F1 Macro: 0.4878\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.235, Accuracy: 0.8838, F1 Micro: 0.6775, F1 Macro: 0.5755\n",
      "Epoch 8/10, Train Loss: 0.2105, Accuracy: 0.8823, F1 Micro: 0.6528, F1 Macro: 0.546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1843, Accuracy: 0.8913, F1 Micro: 0.6996, F1 Macro: 0.6092\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.161, Accuracy: 0.8916, F1 Micro: 0.7017, F1 Macro: 0.6177\n",
      "Model 3 - Iteration 1964: Accuracy: 0.8916, F1 Micro: 0.7017, F1 Macro: 0.6177\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.78      0.81       360\n",
      "      Abusive       0.86      0.82      0.84       365\n",
      "HS_Individual       0.70      0.63      0.66       201\n",
      "     HS_Group       0.69      0.60      0.64       159\n",
      "  HS_Religion       0.74      0.66      0.70        68\n",
      "      HS_Race       0.90      0.85      0.87        65\n",
      "  HS_Physical       0.72      0.38      0.50        82\n",
      "    HS_Gender       0.75      0.36      0.49        83\n",
      "     HS_Other       0.72      0.27      0.40        77\n",
      "      HS_Weak       0.70      0.61      0.65       197\n",
      "  HS_Moderate       0.53      0.48      0.50       134\n",
      "    HS_Strong       1.00      0.21      0.34        29\n",
      "\n",
      "    micro avg       0.77      0.65      0.70      1820\n",
      "    macro avg       0.76      0.55      0.62      1820\n",
      " weighted avg       0.77      0.65      0.69      1820\n",
      "  samples avg       0.44      0.40      0.39      1820\n",
      "\n",
      "Training completed in 71.55590605735779 s\n",
      "Averaged - Iteration 1964: Accuracy: 0.891, F1 Micro: 0.695, F1 Macro: 0.6044\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1996\n",
      "Acquired samples: 32\n",
      "Sampling duration: 10.825990915298462 seconds\n",
      "New train size: 1996\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5324, Accuracy: 0.8352, F1 Micro: 0.4466, F1 Macro: 0.1238\n",
      "Epoch 2/10, Train Loss: 0.4205, Accuracy: 0.838, F1 Micro: 0.4255, F1 Macro: 0.1275\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3714, Accuracy: 0.8602, F1 Micro: 0.5746, F1 Macro: 0.2878\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3284, Accuracy: 0.8678, F1 Micro: 0.5794, F1 Macro: 0.376\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.287, Accuracy: 0.8746, F1 Micro: 0.6144, F1 Macro: 0.4027\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2576, Accuracy: 0.8789, F1 Micro: 0.6282, F1 Macro: 0.4684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2234, Accuracy: 0.8841, F1 Micro: 0.6777, F1 Macro: 0.5406\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2013, Accuracy: 0.8886, F1 Micro: 0.7051, F1 Macro: 0.6025\n",
      "Epoch 9/10, Train Loss: 0.1801, Accuracy: 0.8886, F1 Micro: 0.6921, F1 Macro: 0.5785\n",
      "Epoch 10/10, Train Loss: 0.1668, Accuracy: 0.887, F1 Micro: 0.6656, F1 Macro: 0.5431\n",
      "Model 1 - Iteration 1996: Accuracy: 0.8886, F1 Micro: 0.7051, F1 Macro: 0.6025\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.86      0.84       360\n",
      "      Abusive       0.85      0.82      0.84       365\n",
      "HS_Individual       0.69      0.66      0.67       201\n",
      "     HS_Group       0.65      0.65      0.65       159\n",
      "  HS_Religion       0.77      0.63      0.69        68\n",
      "      HS_Race       0.86      0.85      0.85        65\n",
      "  HS_Physical       0.59      0.50      0.54        82\n",
      "    HS_Gender       0.72      0.25      0.38        83\n",
      "     HS_Other       0.72      0.23      0.35        77\n",
      "      HS_Weak       0.69      0.68      0.68       197\n",
      "  HS_Moderate       0.48      0.50      0.49       134\n",
      "    HS_Strong       1.00      0.14      0.24        29\n",
      "\n",
      "    micro avg       0.74      0.67      0.71      1820\n",
      "    macro avg       0.74      0.56      0.60      1820\n",
      " weighted avg       0.74      0.67      0.69      1820\n",
      "  samples avg       0.43      0.41      0.40      1820\n",
      "\n",
      "Training completed in 63.845465421676636 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5424, Accuracy: 0.833, F1 Micro: 0.4478, F1 Macro: 0.123\n",
      "Epoch 2/10, Train Loss: 0.42, Accuracy: 0.842, F1 Micro: 0.4227, F1 Macro: 0.1356\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3714, Accuracy: 0.8588, F1 Micro: 0.5411, F1 Macro: 0.2505\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3309, Accuracy: 0.8676, F1 Micro: 0.5683, F1 Macro: 0.3613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2917, Accuracy: 0.8727, F1 Micro: 0.623, F1 Macro: 0.4143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2631, Accuracy: 0.8803, F1 Micro: 0.6559, F1 Macro: 0.4902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.231, Accuracy: 0.8827, F1 Micro: 0.6665, F1 Macro: 0.5297\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.209, Accuracy: 0.8866, F1 Micro: 0.6851, F1 Macro: 0.5613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.184, Accuracy: 0.8878, F1 Micro: 0.6855, F1 Macro: 0.5727\n",
      "Epoch 10/10, Train Loss: 0.1698, Accuracy: 0.8863, F1 Micro: 0.6773, F1 Macro: 0.5667\n",
      "Model 2 - Iteration 1996: Accuracy: 0.8878, F1 Micro: 0.6855, F1 Macro: 0.5727\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.78      0.81       360\n",
      "      Abusive       0.85      0.80      0.83       365\n",
      "HS_Individual       0.71      0.58      0.64       201\n",
      "     HS_Group       0.66      0.58      0.62       159\n",
      "  HS_Religion       0.87      0.50      0.64        68\n",
      "      HS_Race       0.89      0.78      0.84        65\n",
      "  HS_Physical       0.72      0.41      0.53        82\n",
      "    HS_Gender       0.75      0.33      0.45        83\n",
      "     HS_Other       0.68      0.27      0.39        77\n",
      "      HS_Weak       0.71      0.58      0.64       197\n",
      "  HS_Moderate       0.52      0.46      0.49       134\n",
      "    HS_Strong       0.00      0.00      0.00        29\n",
      "\n",
      "    micro avg       0.77      0.62      0.69      1820\n",
      "    macro avg       0.69      0.51      0.57      1820\n",
      " weighted avg       0.75      0.62      0.67      1820\n",
      "  samples avg       0.43      0.38      0.38      1820\n",
      "\n",
      "Training completed in 65.92924690246582 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.548, Accuracy: 0.8222, F1 Micro: 0.2693, F1 Macro: 0.0807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.419, Accuracy: 0.84, F1 Micro: 0.3972, F1 Macro: 0.1207\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.377, Accuracy: 0.8574, F1 Micro: 0.5239, F1 Macro: 0.2275\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3367, Accuracy: 0.8625, F1 Micro: 0.5431, F1 Macro: 0.3356\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2984, Accuracy: 0.8707, F1 Micro: 0.5881, F1 Macro: 0.3754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2675, Accuracy: 0.8793, F1 Micro: 0.644, F1 Macro: 0.504\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2336, Accuracy: 0.8834, F1 Micro: 0.6773, F1 Macro: 0.5401\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2146, Accuracy: 0.886, F1 Micro: 0.6884, F1 Macro: 0.5613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1878, Accuracy: 0.8878, F1 Micro: 0.6928, F1 Macro: 0.5984\n",
      "Epoch 10/10, Train Loss: 0.1736, Accuracy: 0.8879, F1 Micro: 0.6711, F1 Macro: 0.5663\n",
      "Model 3 - Iteration 1996: Accuracy: 0.8878, F1 Micro: 0.6928, F1 Macro: 0.5984\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.80      0.82       360\n",
      "      Abusive       0.85      0.82      0.84       365\n",
      "HS_Individual       0.72      0.59      0.65       201\n",
      "     HS_Group       0.65      0.63      0.64       159\n",
      "  HS_Religion       0.70      0.65      0.67        68\n",
      "      HS_Race       0.90      0.82      0.85        65\n",
      "  HS_Physical       0.75      0.33      0.46        82\n",
      "    HS_Gender       0.60      0.40      0.48        83\n",
      "     HS_Other       0.64      0.23      0.34        77\n",
      "      HS_Weak       0.72      0.58      0.65       197\n",
      "  HS_Moderate       0.50      0.48      0.49       134\n",
      "    HS_Strong       1.00      0.17      0.29        29\n",
      "\n",
      "    micro avg       0.75      0.64      0.69      1820\n",
      "    macro avg       0.74      0.54      0.60      1820\n",
      " weighted avg       0.75      0.64      0.68      1820\n",
      "  samples avg       0.43      0.40      0.39      1820\n",
      "\n",
      "Training completed in 67.31493186950684 s\n",
      "Averaged - Iteration 1996: Accuracy: 0.8881, F1 Micro: 0.6945, F1 Macro: 0.5912\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2329\n",
      "Acquired samples: 100\n",
      "Sampling duration: 10.009848594665527 seconds\n",
      "New train size: 2096\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5223, Accuracy: 0.8363, F1 Micro: 0.4229, F1 Macro: 0.121\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.414, Accuracy: 0.8415, F1 Micro: 0.4505, F1 Macro: 0.1492\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3682, Accuracy: 0.8598, F1 Micro: 0.5402, F1 Macro: 0.2622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.311, Accuracy: 0.8738, F1 Micro: 0.6237, F1 Macro: 0.42\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2801, Accuracy: 0.8813, F1 Micro: 0.6713, F1 Macro: 0.5163\n",
      "Epoch 6/10, Train Loss: 0.2494, Accuracy: 0.8803, F1 Micro: 0.6464, F1 Macro: 0.4986\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2162, Accuracy: 0.8848, F1 Micro: 0.6828, F1 Macro: 0.5755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1908, Accuracy: 0.8886, F1 Micro: 0.6935, F1 Macro: 0.5729\n",
      "Epoch 9/10, Train Loss: 0.1703, Accuracy: 0.8896, F1 Micro: 0.6883, F1 Macro: 0.5654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1504, Accuracy: 0.8938, F1 Micro: 0.6957, F1 Macro: 0.6041\n",
      "Model 1 - Iteration 2096: Accuracy: 0.8938, F1 Micro: 0.6957, F1 Macro: 0.6041\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.88      0.77      0.82       360\n",
      "      Abusive       0.89      0.78      0.83       365\n",
      "HS_Individual       0.73      0.60      0.66       201\n",
      "     HS_Group       0.73      0.59      0.65       159\n",
      "  HS_Religion       0.78      0.62      0.69        68\n",
      "      HS_Race       0.91      0.82      0.86        65\n",
      "  HS_Physical       0.72      0.35      0.48        82\n",
      "    HS_Gender       1.00      0.25      0.40        83\n",
      "     HS_Other       0.65      0.22      0.33        77\n",
      "      HS_Weak       0.73      0.59      0.65       197\n",
      "  HS_Moderate       0.56      0.43      0.49       134\n",
      "    HS_Strong       1.00      0.24      0.39        29\n",
      "\n",
      "    micro avg       0.80      0.61      0.70      1820\n",
      "    macro avg       0.80      0.52      0.60      1820\n",
      " weighted avg       0.80      0.61      0.68      1820\n",
      "  samples avg       0.44      0.38      0.39      1820\n",
      "\n",
      "Training completed in 67.18215680122375 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5334, Accuracy: 0.833, F1 Micro: 0.4373, F1 Macro: 0.1217\n",
      "Epoch 2/10, Train Loss: 0.4138, Accuracy: 0.8409, F1 Micro: 0.4219, F1 Macro: 0.134\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3712, Accuracy: 0.8586, F1 Micro: 0.5388, F1 Macro: 0.2636\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3149, Accuracy: 0.8707, F1 Micro: 0.6235, F1 Macro: 0.407\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2841, Accuracy: 0.8799, F1 Micro: 0.662, F1 Macro: 0.4964\n",
      "Epoch 6/10, Train Loss: 0.2502, Accuracy: 0.8802, F1 Micro: 0.6373, F1 Macro: 0.4777\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2183, Accuracy: 0.8835, F1 Micro: 0.6714, F1 Macro: 0.5556\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1913, Accuracy: 0.8867, F1 Micro: 0.6803, F1 Macro: 0.5529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1726, Accuracy: 0.8912, F1 Micro: 0.689, F1 Macro: 0.5944\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1521, Accuracy: 0.8955, F1 Micro: 0.7047, F1 Macro: 0.637\n",
      "Model 2 - Iteration 2096: Accuracy: 0.8955, F1 Micro: 0.7047, F1 Macro: 0.637\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.88      0.76      0.81       360\n",
      "      Abusive       0.90      0.79      0.84       365\n",
      "HS_Individual       0.73      0.58      0.65       201\n",
      "     HS_Group       0.68      0.63      0.66       159\n",
      "  HS_Religion       0.77      0.63      0.69        68\n",
      "      HS_Race       0.92      0.85      0.88        65\n",
      "  HS_Physical       0.76      0.38      0.50        82\n",
      "    HS_Gender       0.87      0.40      0.55        83\n",
      "     HS_Other       0.68      0.22      0.33        77\n",
      "      HS_Weak       0.76      0.57      0.65       197\n",
      "  HS_Moderate       0.54      0.51      0.53       134\n",
      "    HS_Strong       1.00      0.38      0.55        29\n",
      "\n",
      "    micro avg       0.80      0.63      0.70      1820\n",
      "    macro avg       0.79      0.56      0.64      1820\n",
      " weighted avg       0.80      0.63      0.70      1820\n",
      "  samples avg       0.44      0.38      0.39      1820\n",
      "\n",
      "Training completed in 67.47806644439697 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5382, Accuracy: 0.8244, F1 Micro: 0.2847, F1 Macro: 0.0886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4148, Accuracy: 0.8415, F1 Micro: 0.43, F1 Macro: 0.1408\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.376, Accuracy: 0.8602, F1 Micro: 0.5465, F1 Macro: 0.2789\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.322, Accuracy: 0.8719, F1 Micro: 0.6139, F1 Macro: 0.4125\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2916, Accuracy: 0.8772, F1 Micro: 0.6553, F1 Macro: 0.4966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2575, Accuracy: 0.8797, F1 Micro: 0.6572, F1 Macro: 0.4976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.226, Accuracy: 0.8864, F1 Micro: 0.6948, F1 Macro: 0.5866\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1985, Accuracy: 0.8896, F1 Micro: 0.7008, F1 Macro: 0.6162\n",
      "Epoch 9/10, Train Loss: 0.1814, Accuracy: 0.8895, F1 Micro: 0.6819, F1 Macro: 0.5869\n",
      "Epoch 10/10, Train Loss: 0.1603, Accuracy: 0.8889, F1 Micro: 0.6695, F1 Macro: 0.5811\n",
      "Model 3 - Iteration 2096: Accuracy: 0.8896, F1 Micro: 0.7008, F1 Macro: 0.6162\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.80      0.83       360\n",
      "      Abusive       0.85      0.82      0.84       365\n",
      "HS_Individual       0.68      0.66      0.67       201\n",
      "     HS_Group       0.69      0.60      0.64       159\n",
      "  HS_Religion       0.78      0.62      0.69        68\n",
      "      HS_Race       0.90      0.82      0.85        65\n",
      "  HS_Physical       0.65      0.43      0.51        82\n",
      "    HS_Gender       0.60      0.35      0.44        83\n",
      "     HS_Other       0.73      0.21      0.32        77\n",
      "      HS_Weak       0.69      0.64      0.66       197\n",
      "  HS_Moderate       0.51      0.49      0.50       134\n",
      "    HS_Strong       1.00      0.28      0.43        29\n",
      "\n",
      "    micro avg       0.75      0.65      0.70      1820\n",
      "    macro avg       0.74      0.56      0.62      1820\n",
      " weighted avg       0.75      0.65      0.69      1820\n",
      "  samples avg       0.43      0.40      0.39      1820\n",
      "\n",
      "Training completed in 67.90034437179565 s\n",
      "Averaged - Iteration 2096: Accuracy: 0.893, F1 Micro: 0.7004, F1 Macro: 0.6191\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2329\n",
      "Acquired samples: 100\n",
      "Sampling duration: 8.791496753692627 seconds\n",
      "New train size: 2196\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5177, Accuracy: 0.8358, F1 Micro: 0.3877, F1 Macro: 0.1153\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4179, Accuracy: 0.8438, F1 Micro: 0.4675, F1 Macro: 0.1775\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3638, Accuracy: 0.8651, F1 Micro: 0.5796, F1 Macro: 0.3203\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3131, Accuracy: 0.8736, F1 Micro: 0.6118, F1 Macro: 0.4205\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2825, Accuracy: 0.8806, F1 Micro: 0.6667, F1 Macro: 0.5123\n",
      "Epoch 6/10, Train Loss: 0.2433, Accuracy: 0.8814, F1 Micro: 0.6594, F1 Macro: 0.5451\n",
      "Epoch 7/10, Train Loss: 0.205, Accuracy: 0.8829, F1 Micro: 0.6498, F1 Macro: 0.5281\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.182, Accuracy: 0.8882, F1 Micro: 0.6789, F1 Macro: 0.5737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1628, Accuracy: 0.8925, F1 Micro: 0.6944, F1 Macro: 0.601\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1481, Accuracy: 0.8956, F1 Micro: 0.7109, F1 Macro: 0.6351\n",
      "Model 1 - Iteration 2196: Accuracy: 0.8956, F1 Micro: 0.7109, F1 Macro: 0.6351\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.87      0.79      0.83       360\n",
      "      Abusive       0.89      0.82      0.85       365\n",
      "HS_Individual       0.72      0.60      0.66       201\n",
      "     HS_Group       0.70      0.65      0.68       159\n",
      "  HS_Religion       0.77      0.60      0.68        68\n",
      "      HS_Race       0.92      0.85      0.88        65\n",
      "  HS_Physical       0.76      0.50      0.60        82\n",
      "    HS_Gender       0.89      0.40      0.55        83\n",
      "     HS_Other       0.60      0.27      0.37        77\n",
      "      HS_Weak       0.71      0.59      0.64       197\n",
      "  HS_Moderate       0.52      0.47      0.49       134\n",
      "    HS_Strong       1.00      0.24      0.39        29\n",
      "\n",
      "    micro avg       0.78      0.65      0.71      1820\n",
      "    macro avg       0.78      0.56      0.64      1820\n",
      " weighted avg       0.78      0.65      0.70      1820\n",
      "  samples avg       0.44      0.40      0.40      1820\n",
      "\n",
      "Training completed in 69.28027486801147 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5264, Accuracy: 0.8349, F1 Micro: 0.3803, F1 Macro: 0.1139\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4166, Accuracy: 0.8434, F1 Micro: 0.4646, F1 Macro: 0.1596\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3665, Accuracy: 0.8655, F1 Micro: 0.5836, F1 Macro: 0.3244\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3112, Accuracy: 0.8745, F1 Micro: 0.6237, F1 Macro: 0.4171\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.284, Accuracy: 0.8803, F1 Micro: 0.6632, F1 Macro: 0.4957\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2433, Accuracy: 0.8837, F1 Micro: 0.6767, F1 Macro: 0.5531\n",
      "Epoch 7/10, Train Loss: 0.2086, Accuracy: 0.8822, F1 Micro: 0.6334, F1 Macro: 0.5182\n",
      "Epoch 8/10, Train Loss: 0.1821, Accuracy: 0.8874, F1 Micro: 0.6707, F1 Macro: 0.5787\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1654, Accuracy: 0.8915, F1 Micro: 0.6912, F1 Macro: 0.5929\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1463, Accuracy: 0.8927, F1 Micro: 0.698, F1 Macro: 0.631\n",
      "Model 2 - Iteration 2196: Accuracy: 0.8927, F1 Micro: 0.698, F1 Macro: 0.631\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.76      0.81       360\n",
      "      Abusive       0.89      0.83      0.86       365\n",
      "HS_Individual       0.72      0.54      0.61       201\n",
      "     HS_Group       0.67      0.64      0.65       159\n",
      "  HS_Religion       0.82      0.59      0.68        68\n",
      "      HS_Race       0.90      0.85      0.87        65\n",
      "  HS_Physical       0.79      0.40      0.53        82\n",
      "    HS_Gender       0.88      0.35      0.50        83\n",
      "     HS_Other       0.60      0.23      0.34        77\n",
      "      HS_Weak       0.72      0.52      0.60       197\n",
      "  HS_Moderate       0.55      0.51      0.53       134\n",
      "    HS_Strong       1.00      0.41      0.59        29\n",
      "\n",
      "    micro avg       0.79      0.63      0.70      1820\n",
      "    macro avg       0.78      0.55      0.63      1820\n",
      " weighted avg       0.78      0.63      0.69      1820\n",
      "  samples avg       0.45      0.39      0.39      1820\n",
      "\n",
      "Training completed in 69.50466394424438 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5313, Accuracy: 0.8224, F1 Micro: 0.2556, F1 Macro: 0.0805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4165, Accuracy: 0.8423, F1 Micro: 0.4232, F1 Macro: 0.1347\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3695, Accuracy: 0.8634, F1 Micro: 0.5821, F1 Macro: 0.3175\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3174, Accuracy: 0.8748, F1 Micro: 0.6231, F1 Macro: 0.4386\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.289, Accuracy: 0.879, F1 Micro: 0.6583, F1 Macro: 0.4938\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2497, Accuracy: 0.8837, F1 Micro: 0.6646, F1 Macro: 0.5404\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2148, Accuracy: 0.8885, F1 Micro: 0.6781, F1 Macro: 0.5847\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.188, Accuracy: 0.8926, F1 Micro: 0.6969, F1 Macro: 0.6218\n",
      "Epoch 9/10, Train Loss: 0.1669, Accuracy: 0.8933, F1 Micro: 0.6956, F1 Macro: 0.6291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.148, Accuracy: 0.8936, F1 Micro: 0.7074, F1 Macro: 0.638\n",
      "Model 3 - Iteration 2196: Accuracy: 0.8936, F1 Micro: 0.7074, F1 Macro: 0.638\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.77      0.81       360\n",
      "      Abusive       0.86      0.84      0.85       365\n",
      "HS_Individual       0.75      0.57      0.65       201\n",
      "     HS_Group       0.67      0.68      0.67       159\n",
      "  HS_Religion       0.75      0.62      0.68        68\n",
      "      HS_Race       0.88      0.86      0.87        65\n",
      "  HS_Physical       0.83      0.37      0.51        82\n",
      "    HS_Gender       0.82      0.40      0.54        83\n",
      "     HS_Other       0.67      0.31      0.42        77\n",
      "      HS_Weak       0.74      0.55      0.63       197\n",
      "  HS_Moderate       0.52      0.57      0.54       134\n",
      "    HS_Strong       0.83      0.34      0.49        29\n",
      "\n",
      "    micro avg       0.77      0.65      0.71      1820\n",
      "    macro avg       0.76      0.57      0.64      1820\n",
      " weighted avg       0.78      0.65      0.70      1820\n",
      "  samples avg       0.45      0.41      0.41      1820\n",
      "\n",
      "Training completed in 71.32080936431885 s\n",
      "Averaged - Iteration 2196: Accuracy: 0.894, F1 Micro: 0.7055, F1 Macro: 0.6347\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2329\n",
      "Acquired samples: 100\n",
      "Sampling duration: 7.573153734207153 seconds\n",
      "New train size: 2296\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5127, Accuracy: 0.837, F1 Micro: 0.4345, F1 Macro: 0.1231\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.415, Accuracy: 0.8461, F1 Micro: 0.4851, F1 Macro: 0.19\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3603, Accuracy: 0.864, F1 Micro: 0.5936, F1 Macro: 0.3357\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3091, Accuracy: 0.8745, F1 Micro: 0.6454, F1 Macro: 0.4322\n",
      "Epoch 5/10, Train Loss: 0.2722, Accuracy: 0.8778, F1 Micro: 0.64, F1 Macro: 0.4904\n",
      "Epoch 6/10, Train Loss: 0.2436, Accuracy: 0.878, F1 Micro: 0.62, F1 Macro: 0.5082\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2184, Accuracy: 0.8859, F1 Micro: 0.69, F1 Macro: 0.6062\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1894, Accuracy: 0.8936, F1 Micro: 0.7057, F1 Macro: 0.6127\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1657, Accuracy: 0.8944, F1 Micro: 0.7162, F1 Macro: 0.6293\n",
      "Epoch 10/10, Train Loss: 0.1486, Accuracy: 0.8945, F1 Micro: 0.6983, F1 Macro: 0.6077\n",
      "Model 1 - Iteration 2296: Accuracy: 0.8944, F1 Micro: 0.7162, F1 Macro: 0.6293\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.84      0.84       360\n",
      "      Abusive       0.89      0.82      0.85       365\n",
      "HS_Individual       0.68      0.66      0.67       201\n",
      "     HS_Group       0.70      0.62      0.66       159\n",
      "  HS_Religion       0.79      0.74      0.76        68\n",
      "      HS_Race       0.92      0.83      0.87        65\n",
      "  HS_Physical       0.57      0.56      0.57        82\n",
      "    HS_Gender       0.94      0.36      0.52        83\n",
      "     HS_Other       0.68      0.25      0.36        77\n",
      "      HS_Weak       0.67      0.67      0.67       197\n",
      "  HS_Moderate       0.54      0.44      0.48       134\n",
      "    HS_Strong       1.00      0.17      0.29        29\n",
      "\n",
      "    micro avg       0.76      0.67      0.72      1820\n",
      "    macro avg       0.77      0.58      0.63      1820\n",
      " weighted avg       0.77      0.67      0.71      1820\n",
      "  samples avg       0.44      0.41      0.41      1820\n",
      "\n",
      "Training completed in 66.7239146232605 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5214, Accuracy: 0.8343, F1 Micro: 0.412, F1 Macro: 0.1185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4161, Accuracy: 0.8451, F1 Micro: 0.4623, F1 Macro: 0.1551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3629, Accuracy: 0.8638, F1 Micro: 0.5826, F1 Macro: 0.3305\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3134, Accuracy: 0.8724, F1 Micro: 0.6311, F1 Macro: 0.408\n",
      "Epoch 5/10, Train Loss: 0.2781, Accuracy: 0.8771, F1 Micro: 0.6279, F1 Macro: 0.4465\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2496, Accuracy: 0.8838, F1 Micro: 0.6633, F1 Macro: 0.5486\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2213, Accuracy: 0.8874, F1 Micro: 0.6808, F1 Macro: 0.5857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.195, Accuracy: 0.8911, F1 Micro: 0.6946, F1 Macro: 0.5982\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1713, Accuracy: 0.8944, F1 Micro: 0.7025, F1 Macro: 0.6265\n",
      "Epoch 10/10, Train Loss: 0.1507, Accuracy: 0.8929, F1 Micro: 0.6922, F1 Macro: 0.623\n",
      "Model 2 - Iteration 2296: Accuracy: 0.8944, F1 Micro: 0.7025, F1 Macro: 0.6265\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.87      0.78      0.82       360\n",
      "      Abusive       0.88      0.81      0.84       365\n",
      "HS_Individual       0.73      0.55      0.63       201\n",
      "     HS_Group       0.71      0.64      0.67       159\n",
      "  HS_Religion       0.87      0.59      0.70        68\n",
      "      HS_Race       0.92      0.85      0.88        65\n",
      "  HS_Physical       0.75      0.46      0.57        82\n",
      "    HS_Gender       0.84      0.33      0.47        83\n",
      "     HS_Other       0.65      0.26      0.37        77\n",
      "      HS_Weak       0.72      0.55      0.62       197\n",
      "  HS_Moderate       0.55      0.47      0.51       134\n",
      "    HS_Strong       1.00      0.28      0.43        29\n",
      "\n",
      "    micro avg       0.79      0.63      0.70      1820\n",
      "    macro avg       0.79      0.55      0.63      1820\n",
      " weighted avg       0.79      0.63      0.69      1820\n",
      "  samples avg       0.45      0.39      0.40      1820\n",
      "\n",
      "Training completed in 69.60216760635376 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5277, Accuracy: 0.83, F1 Micro: 0.3374, F1 Macro: 0.1029\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4151, Accuracy: 0.8422, F1 Micro: 0.4142, F1 Macro: 0.1359\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3682, Accuracy: 0.8634, F1 Micro: 0.5663, F1 Macro: 0.319\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.321, Accuracy: 0.8746, F1 Micro: 0.6362, F1 Macro: 0.4221\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.279, Accuracy: 0.8789, F1 Micro: 0.6409, F1 Macro: 0.4665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2509, Accuracy: 0.8823, F1 Micro: 0.6465, F1 Macro: 0.5297\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.228, Accuracy: 0.8912, F1 Micro: 0.7099, F1 Macro: 0.6213\n",
      "Epoch 8/10, Train Loss: 0.197, Accuracy: 0.8934, F1 Micro: 0.7079, F1 Macro: 0.5985\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1741, Accuracy: 0.8965, F1 Micro: 0.7104, F1 Macro: 0.6342\n",
      "Epoch 10/10, Train Loss: 0.1505, Accuracy: 0.8941, F1 Micro: 0.7013, F1 Macro: 0.6353\n",
      "Model 3 - Iteration 2296: Accuracy: 0.8965, F1 Micro: 0.7104, F1 Macro: 0.6342\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.88      0.79      0.83       360\n",
      "      Abusive       0.89      0.79      0.84       365\n",
      "HS_Individual       0.76      0.59      0.66       201\n",
      "     HS_Group       0.70      0.65      0.67       159\n",
      "  HS_Religion       0.76      0.66      0.71        68\n",
      "      HS_Race       0.90      0.85      0.87        65\n",
      "  HS_Physical       0.78      0.44      0.56        82\n",
      "    HS_Gender       0.82      0.33      0.47        83\n",
      "     HS_Other       0.64      0.23      0.34        77\n",
      "      HS_Weak       0.76      0.58      0.66       197\n",
      "  HS_Moderate       0.52      0.51      0.52       134\n",
      "    HS_Strong       1.00      0.31      0.47        29\n",
      "\n",
      "    micro avg       0.79      0.64      0.71      1820\n",
      "    macro avg       0.78      0.56      0.63      1820\n",
      " weighted avg       0.79      0.64      0.70      1820\n",
      "  samples avg       0.44      0.39      0.40      1820\n",
      "\n",
      "Training completed in 68.9892680644989 s\n",
      "Averaged - Iteration 2296: Accuracy: 0.8951, F1 Micro: 0.7097, F1 Macro: 0.63\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2329\n",
      "Acquired samples: 33\n",
      "Sampling duration: 6.203242063522339 seconds\n",
      "New train size: 2329\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5143, Accuracy: 0.8367, F1 Micro: 0.4021, F1 Macro: 0.1184\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.401, Accuracy: 0.8494, F1 Micro: 0.4945, F1 Macro: 0.2127\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3536, Accuracy: 0.8658, F1 Micro: 0.587, F1 Macro: 0.348\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3032, Accuracy: 0.8735, F1 Micro: 0.6031, F1 Macro: 0.3993\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2619, Accuracy: 0.8767, F1 Micro: 0.6196, F1 Macro: 0.4413\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2329, Accuracy: 0.8839, F1 Micro: 0.6499, F1 Macro: 0.5038\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2108, Accuracy: 0.8902, F1 Micro: 0.6975, F1 Macro: 0.58\n",
      "Epoch 8/10, Train Loss: 0.1758, Accuracy: 0.8898, F1 Micro: 0.688, F1 Macro: 0.5821\n",
      "Epoch 9/10, Train Loss: 0.1527, Accuracy: 0.8919, F1 Micro: 0.6822, F1 Macro: 0.5876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1364, Accuracy: 0.8963, F1 Micro: 0.7067, F1 Macro: 0.5994\n",
      "Model 1 - Iteration 2329: Accuracy: 0.8963, F1 Micro: 0.7067, F1 Macro: 0.5994\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.88      0.78      0.82       360\n",
      "      Abusive       0.89      0.81      0.85       365\n",
      "HS_Individual       0.71      0.66      0.69       201\n",
      "     HS_Group       0.75      0.53      0.62       159\n",
      "  HS_Religion       0.87      0.59      0.70        68\n",
      "      HS_Race       0.91      0.80      0.85        65\n",
      "  HS_Physical       0.72      0.52      0.61        82\n",
      "    HS_Gender       0.97      0.34      0.50        83\n",
      "     HS_Other       0.65      0.19      0.30        77\n",
      "      HS_Weak       0.71      0.67      0.69       197\n",
      "  HS_Moderate       0.55      0.36      0.43       134\n",
      "    HS_Strong       1.00      0.07      0.13        29\n",
      "\n",
      "    micro avg       0.80      0.63      0.71      1820\n",
      "    macro avg       0.80      0.53      0.60      1820\n",
      " weighted avg       0.80      0.63      0.69      1820\n",
      "  samples avg       0.45      0.39      0.39      1820\n",
      "\n",
      "Training completed in 69.82993292808533 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5246, Accuracy: 0.8324, F1 Micro: 0.366, F1 Macro: 0.1095\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4021, Accuracy: 0.8478, F1 Micro: 0.4763, F1 Macro: 0.1783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.355, Accuracy: 0.8641, F1 Micro: 0.5849, F1 Macro: 0.352\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3069, Accuracy: 0.8738, F1 Micro: 0.6176, F1 Macro: 0.3993\n",
      "Epoch 5/10, Train Loss: 0.2677, Accuracy: 0.875, F1 Micro: 0.6039, F1 Macro: 0.4025\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2399, Accuracy: 0.8826, F1 Micro: 0.6455, F1 Macro: 0.4994\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2152, Accuracy: 0.889, F1 Micro: 0.6828, F1 Macro: 0.5846\n",
      "Epoch 8/10, Train Loss: 0.1806, Accuracy: 0.887, F1 Micro: 0.6688, F1 Macro: 0.5842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1572, Accuracy: 0.894, F1 Micro: 0.6972, F1 Macro: 0.6109\n",
      "Epoch 10/10, Train Loss: 0.14, Accuracy: 0.8928, F1 Micro: 0.6939, F1 Macro: 0.5904\n",
      "Model 2 - Iteration 2329: Accuracy: 0.894, F1 Micro: 0.6972, F1 Macro: 0.6109\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.89      0.75      0.81       360\n",
      "      Abusive       0.88      0.81      0.85       365\n",
      "HS_Individual       0.76      0.53      0.62       201\n",
      "     HS_Group       0.70      0.65      0.67       159\n",
      "  HS_Religion       0.84      0.56      0.67        68\n",
      "      HS_Race       0.93      0.85      0.89        65\n",
      "  HS_Physical       0.80      0.34      0.48        82\n",
      "    HS_Gender       0.83      0.35      0.49        83\n",
      "     HS_Other       0.63      0.25      0.36        77\n",
      "      HS_Weak       0.76      0.52      0.61       197\n",
      "  HS_Moderate       0.54      0.53      0.53       134\n",
      "    HS_Strong       1.00      0.21      0.34        29\n",
      "\n",
      "    micro avg       0.80      0.62      0.70      1820\n",
      "    macro avg       0.80      0.53      0.61      1820\n",
      " weighted avg       0.80      0.62      0.69      1820\n",
      "  samples avg       0.45      0.38      0.39      1820\n",
      "\n",
      "Training completed in 69.7622766494751 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5294, Accuracy: 0.8327, F1 Micro: 0.3721, F1 Macro: 0.1118\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4032, Accuracy: 0.8446, F1 Micro: 0.429, F1 Macro: 0.1533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3625, Accuracy: 0.8641, F1 Micro: 0.5677, F1 Macro: 0.3314\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.312, Accuracy: 0.8738, F1 Micro: 0.614, F1 Macro: 0.404\n",
      "Epoch 5/10, Train Loss: 0.2746, Accuracy: 0.8752, F1 Micro: 0.6099, F1 Macro: 0.4369\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2425, Accuracy: 0.8857, F1 Micro: 0.6607, F1 Macro: 0.5285\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2193, Accuracy: 0.8919, F1 Micro: 0.695, F1 Macro: 0.596\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1847, Accuracy: 0.8932, F1 Micro: 0.7043, F1 Macro: 0.634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1601, Accuracy: 0.8946, F1 Micro: 0.7044, F1 Macro: 0.6379\n",
      "Epoch 10/10, Train Loss: 0.1422, Accuracy: 0.8944, F1 Micro: 0.697, F1 Macro: 0.6143\n",
      "Model 3 - Iteration 2329: Accuracy: 0.8946, F1 Micro: 0.7044, F1 Macro: 0.6379\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.89      0.76      0.82       360\n",
      "      Abusive       0.87      0.82      0.85       365\n",
      "HS_Individual       0.78      0.54      0.64       201\n",
      "     HS_Group       0.66      0.67      0.66       159\n",
      "  HS_Religion       0.75      0.68      0.71        68\n",
      "      HS_Race       0.93      0.86      0.90        65\n",
      "  HS_Physical       0.90      0.32      0.47        82\n",
      "    HS_Gender       0.80      0.34      0.47        83\n",
      "     HS_Other       0.62      0.26      0.37        77\n",
      "      HS_Weak       0.78      0.53      0.63       197\n",
      "  HS_Moderate       0.51      0.56      0.54       134\n",
      "    HS_Strong       0.93      0.45      0.60        29\n",
      "\n",
      "    micro avg       0.79      0.64      0.70      1820\n",
      "    macro avg       0.79      0.57      0.64      1820\n",
      " weighted avg       0.80      0.64      0.69      1820\n",
      "  samples avg       0.45      0.40      0.40      1820\n",
      "\n",
      "Training completed in 71.71870422363281 s\n",
      "Averaged - Iteration 2329: Accuracy: 0.895, F1 Micro: 0.7028, F1 Macro: 0.6161\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2662\n",
      "Acquired samples: 100\n",
      "Sampling duration: 5.847086429595947 seconds\n",
      "New train size: 2429\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5051, Accuracy: 0.8286, F1 Micro: 0.287, F1 Macro: 0.0877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4046, Accuracy: 0.8468, F1 Micro: 0.454, F1 Macro: 0.1835\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3519, Accuracy: 0.8641, F1 Micro: 0.602, F1 Macro: 0.3633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3023, Accuracy: 0.8735, F1 Micro: 0.619, F1 Macro: 0.4232\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2719, Accuracy: 0.8787, F1 Micro: 0.6579, F1 Macro: 0.4933\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2396, Accuracy: 0.8845, F1 Micro: 0.6679, F1 Macro: 0.5361\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2032, Accuracy: 0.8877, F1 Micro: 0.6789, F1 Macro: 0.5659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1827, Accuracy: 0.8934, F1 Micro: 0.7122, F1 Macro: 0.6362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.16, Accuracy: 0.8952, F1 Micro: 0.716, F1 Macro: 0.6407\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1393, Accuracy: 0.8991, F1 Micro: 0.7261, F1 Macro: 0.6536\n",
      "Model 1 - Iteration 2429: Accuracy: 0.8991, F1 Micro: 0.7261, F1 Macro: 0.6536\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.81      0.83       360\n",
      "      Abusive       0.87      0.84      0.86       365\n",
      "HS_Individual       0.69      0.68      0.69       201\n",
      "     HS_Group       0.74      0.58      0.65       159\n",
      "  HS_Religion       0.81      0.68      0.74        68\n",
      "      HS_Race       0.93      0.82      0.87        65\n",
      "  HS_Physical       0.70      0.56      0.62        82\n",
      "    HS_Gender       0.89      0.49      0.64        83\n",
      "     HS_Other       0.69      0.29      0.40        77\n",
      "      HS_Weak       0.68      0.68      0.68       197\n",
      "  HS_Moderate       0.58      0.42      0.49       134\n",
      "    HS_Strong       1.00      0.24      0.39        29\n",
      "\n",
      "    micro avg       0.78      0.68      0.73      1820\n",
      "    macro avg       0.79      0.59      0.65      1820\n",
      " weighted avg       0.78      0.68      0.72      1820\n",
      "  samples avg       0.46      0.42      0.41      1820\n",
      "\n",
      "Training completed in 75.24432754516602 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5161, Accuracy: 0.8318, F1 Micro: 0.3547, F1 Macro: 0.107\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4048, Accuracy: 0.8457, F1 Micro: 0.4614, F1 Macro: 0.1581\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3536, Accuracy: 0.8656, F1 Micro: 0.5901, F1 Macro: 0.3535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3041, Accuracy: 0.8747, F1 Micro: 0.6297, F1 Macro: 0.4201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2764, Accuracy: 0.8778, F1 Micro: 0.6586, F1 Macro: 0.4929\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2434, Accuracy: 0.8851, F1 Micro: 0.679, F1 Macro: 0.5573\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2099, Accuracy: 0.8908, F1 Micro: 0.6914, F1 Macro: 0.5792\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1872, Accuracy: 0.893, F1 Micro: 0.709, F1 Macro: 0.6332\n",
      "Epoch 9/10, Train Loss: 0.1635, Accuracy: 0.8933, F1 Micro: 0.7026, F1 Macro: 0.635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1445, Accuracy: 0.8978, F1 Micro: 0.7185, F1 Macro: 0.6549\n",
      "Model 2 - Iteration 2429: Accuracy: 0.8978, F1 Micro: 0.7185, F1 Macro: 0.6549\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.79      0.83       360\n",
      "      Abusive       0.88      0.83      0.85       365\n",
      "HS_Individual       0.68      0.66      0.67       201\n",
      "     HS_Group       0.77      0.56      0.65       159\n",
      "  HS_Religion       0.82      0.62      0.71        68\n",
      "      HS_Race       0.93      0.82      0.87        65\n",
      "  HS_Physical       0.68      0.50      0.58        82\n",
      "    HS_Gender       0.85      0.49      0.63        83\n",
      "     HS_Other       0.70      0.25      0.37        77\n",
      "      HS_Weak       0.67      0.64      0.65       197\n",
      "  HS_Moderate       0.63      0.43      0.51       134\n",
      "    HS_Strong       0.86      0.41      0.56        29\n",
      "\n",
      "    micro avg       0.79      0.66      0.72      1820\n",
      "    macro avg       0.78      0.58      0.65      1820\n",
      " weighted avg       0.78      0.66      0.71      1820\n",
      "  samples avg       0.46      0.41      0.41      1820\n",
      "\n",
      "Training completed in 73.32585835456848 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5194, Accuracy: 0.8299, F1 Micro: 0.323, F1 Macro: 0.1004\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4067, Accuracy: 0.8416, F1 Micro: 0.4041, F1 Macro: 0.1495\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3608, Accuracy: 0.8658, F1 Micro: 0.573, F1 Macro: 0.3238\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3098, Accuracy: 0.8742, F1 Micro: 0.6305, F1 Macro: 0.4447\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2824, Accuracy: 0.8772, F1 Micro: 0.6305, F1 Macro: 0.4603\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.247, Accuracy: 0.8845, F1 Micro: 0.6724, F1 Macro: 0.5442\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2154, Accuracy: 0.8888, F1 Micro: 0.6808, F1 Macro: 0.5866\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1902, Accuracy: 0.8919, F1 Micro: 0.6996, F1 Macro: 0.6225\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1625, Accuracy: 0.8915, F1 Micro: 0.7027, F1 Macro: 0.6407\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1459, Accuracy: 0.8979, F1 Micro: 0.7215, F1 Macro: 0.6559\n",
      "Model 3 - Iteration 2429: Accuracy: 0.8979, F1 Micro: 0.7215, F1 Macro: 0.6559\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.80      0.83       360\n",
      "      Abusive       0.87      0.84      0.85       365\n",
      "HS_Individual       0.72      0.64      0.67       201\n",
      "     HS_Group       0.71      0.63      0.67       159\n",
      "  HS_Religion       0.82      0.68      0.74        68\n",
      "      HS_Race       0.90      0.86      0.88        65\n",
      "  HS_Physical       0.74      0.43      0.54        82\n",
      "    HS_Gender       0.85      0.47      0.60        83\n",
      "     HS_Other       0.64      0.32      0.43        77\n",
      "      HS_Weak       0.71      0.63      0.67       197\n",
      "  HS_Moderate       0.53      0.45      0.49       134\n",
      "    HS_Strong       0.83      0.34      0.49        29\n",
      "\n",
      "    micro avg       0.78      0.67      0.72      1820\n",
      "    macro avg       0.77      0.59      0.66      1820\n",
      " weighted avg       0.78      0.67      0.71      1820\n",
      "  samples avg       0.46      0.42      0.42      1820\n",
      "\n",
      "Training completed in 75.20770382881165 s\n",
      "Averaged - Iteration 2429: Accuracy: 0.8983, F1 Micro: 0.722, F1 Macro: 0.6548\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2662\n",
      "Acquired samples: 100\n",
      "Sampling duration: 4.436571359634399 seconds\n",
      "New train size: 2529\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5011, Accuracy: 0.8236, F1 Micro: 0.2395, F1 Macro: 0.0694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3978, Accuracy: 0.8486, F1 Micro: 0.4637, F1 Macro: 0.193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3477, Accuracy: 0.8638, F1 Micro: 0.575, F1 Macro: 0.3375\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2891, Accuracy: 0.8746, F1 Micro: 0.6439, F1 Macro: 0.4413\n",
      "Epoch 5/10, Train Loss: 0.2569, Accuracy: 0.8776, F1 Micro: 0.6304, F1 Macro: 0.4666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2308, Accuracy: 0.8841, F1 Micro: 0.6734, F1 Macro: 0.5634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2006, Accuracy: 0.8918, F1 Micro: 0.7072, F1 Macro: 0.614\n",
      "Epoch 8/10, Train Loss: 0.1837, Accuracy: 0.8893, F1 Micro: 0.6699, F1 Macro: 0.5577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1554, Accuracy: 0.8941, F1 Micro: 0.7169, F1 Macro: 0.6348\n",
      "Epoch 10/10, Train Loss: 0.1387, Accuracy: 0.894, F1 Micro: 0.6925, F1 Macro: 0.6168\n",
      "Model 1 - Iteration 2529: Accuracy: 0.8941, F1 Micro: 0.7169, F1 Macro: 0.6348\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.83      0.84       360\n",
      "      Abusive       0.89      0.82      0.85       365\n",
      "HS_Individual       0.72      0.59      0.64       201\n",
      "     HS_Group       0.64      0.74      0.69       159\n",
      "  HS_Religion       0.68      0.78      0.73        68\n",
      "      HS_Race       0.87      0.83      0.85        65\n",
      "  HS_Physical       0.72      0.40      0.52        82\n",
      "    HS_Gender       0.97      0.36      0.53        83\n",
      "     HS_Other       0.62      0.26      0.37        77\n",
      "      HS_Weak       0.71      0.59      0.65       197\n",
      "  HS_Moderate       0.52      0.63      0.57       134\n",
      "    HS_Strong       1.00      0.24      0.39        29\n",
      "\n",
      "    micro avg       0.76      0.68      0.72      1820\n",
      "    macro avg       0.76      0.59      0.63      1820\n",
      " weighted avg       0.77      0.68      0.71      1820\n",
      "  samples avg       0.44      0.42      0.41      1820\n",
      "\n",
      "Training completed in 70.66629528999329 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.51, Accuracy: 0.8279, F1 Micro: 0.3211, F1 Macro: 0.0962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.398, Accuracy: 0.8453, F1 Micro: 0.4328, F1 Macro: 0.1485\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3484, Accuracy: 0.8643, F1 Micro: 0.5711, F1 Macro: 0.3356\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2913, Accuracy: 0.874, F1 Micro: 0.629, F1 Macro: 0.4132\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2601, Accuracy: 0.8778, F1 Micro: 0.6306, F1 Macro: 0.453\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2332, Accuracy: 0.885, F1 Micro: 0.6714, F1 Macro: 0.5515\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2027, Accuracy: 0.8914, F1 Micro: 0.6999, F1 Macro: 0.6084\n",
      "Epoch 8/10, Train Loss: 0.184, Accuracy: 0.8898, F1 Micro: 0.6777, F1 Macro: 0.5918\n",
      "Epoch 9/10, Train Loss: 0.1588, Accuracy: 0.8889, F1 Micro: 0.6908, F1 Macro: 0.6223\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1412, Accuracy: 0.8958, F1 Micro: 0.711, F1 Macro: 0.6511\n",
      "Model 2 - Iteration 2529: Accuracy: 0.8958, F1 Micro: 0.711, F1 Macro: 0.6511\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.88      0.78      0.83       360\n",
      "      Abusive       0.89      0.81      0.85       365\n",
      "HS_Individual       0.74      0.56      0.63       201\n",
      "     HS_Group       0.67      0.64      0.66       159\n",
      "  HS_Religion       0.76      0.69      0.72        68\n",
      "      HS_Race       0.93      0.83      0.88        65\n",
      "  HS_Physical       0.73      0.45      0.56        82\n",
      "    HS_Gender       0.84      0.46      0.59        83\n",
      "     HS_Other       0.63      0.22      0.33        77\n",
      "      HS_Weak       0.73      0.56      0.63       197\n",
      "  HS_Moderate       0.54      0.57      0.55       134\n",
      "    HS_Strong       1.00      0.41      0.59        29\n",
      "\n",
      "    micro avg       0.79      0.65      0.71      1820\n",
      "    macro avg       0.78      0.58      0.65      1820\n",
      " weighted avg       0.79      0.65      0.70      1820\n",
      "  samples avg       0.45      0.40      0.40      1820\n",
      "\n",
      "Training completed in 73.57445812225342 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5142, Accuracy: 0.8294, F1 Micro: 0.3123, F1 Macro: 0.0979\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3999, Accuracy: 0.8423, F1 Micro: 0.4086, F1 Macro: 0.1519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3593, Accuracy: 0.8617, F1 Micro: 0.5584, F1 Macro: 0.2967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2984, Accuracy: 0.8716, F1 Micro: 0.6175, F1 Macro: 0.4247\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2658, Accuracy: 0.8799, F1 Micro: 0.6451, F1 Macro: 0.4919\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2395, Accuracy: 0.8885, F1 Micro: 0.6858, F1 Macro: 0.5752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2082, Accuracy: 0.8925, F1 Micro: 0.706, F1 Macro: 0.6162\n",
      "Epoch 8/10, Train Loss: 0.1912, Accuracy: 0.8902, F1 Micro: 0.6822, F1 Macro: 0.5965\n",
      "Epoch 9/10, Train Loss: 0.1621, Accuracy: 0.8914, F1 Micro: 0.7011, F1 Macro: 0.6271\n",
      "Epoch 10/10, Train Loss: 0.1418, Accuracy: 0.8933, F1 Micro: 0.6982, F1 Macro: 0.6421\n",
      "Model 3 - Iteration 2529: Accuracy: 0.8925, F1 Micro: 0.706, F1 Macro: 0.6162\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.87      0.82      0.84       360\n",
      "      Abusive       0.86      0.81      0.84       365\n",
      "HS_Individual       0.74      0.62      0.68       201\n",
      "     HS_Group       0.66      0.64      0.65       159\n",
      "  HS_Religion       0.72      0.71      0.71        68\n",
      "      HS_Race       0.90      0.85      0.87        65\n",
      "  HS_Physical       0.73      0.37      0.49        82\n",
      "    HS_Gender       0.63      0.33      0.43        83\n",
      "     HS_Other       0.70      0.18      0.29        77\n",
      "      HS_Weak       0.75      0.61      0.67       197\n",
      "  HS_Moderate       0.49      0.50      0.49       134\n",
      "    HS_Strong       1.00      0.28      0.43        29\n",
      "\n",
      "    micro avg       0.77      0.65      0.71      1820\n",
      "    macro avg       0.75      0.56      0.62      1820\n",
      " weighted avg       0.77      0.65      0.69      1820\n",
      "  samples avg       0.45      0.40      0.40      1820\n",
      "\n",
      "Training completed in 72.24478816986084 s\n",
      "Averaged - Iteration 2529: Accuracy: 0.8941, F1 Micro: 0.7113, F1 Macro: 0.634\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2662\n",
      "Acquired samples: 100\n",
      "Sampling duration: 3.0040934085845947 seconds\n",
      "New train size: 2629\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.497, Accuracy: 0.8177, F1 Micro: 0.165, F1 Macro: 0.0533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3892, Accuracy: 0.8526, F1 Micro: 0.5164, F1 Macro: 0.2297\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3248, Accuracy: 0.8645, F1 Micro: 0.5698, F1 Macro: 0.3536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2816, Accuracy: 0.8747, F1 Micro: 0.6309, F1 Macro: 0.4325\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2425, Accuracy: 0.8827, F1 Micro: 0.6619, F1 Macro: 0.502\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2173, Accuracy: 0.887, F1 Micro: 0.6784, F1 Macro: 0.5735\n",
      "Epoch 7/10, Train Loss: 0.1848, Accuracy: 0.8868, F1 Micro: 0.6647, F1 Macro: 0.5587\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1617, Accuracy: 0.8943, F1 Micro: 0.7134, F1 Macro: 0.6302\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1457, Accuracy: 0.8946, F1 Micro: 0.7153, F1 Macro: 0.6383\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1248, Accuracy: 0.8968, F1 Micro: 0.7199, F1 Macro: 0.649\n",
      "Model 1 - Iteration 2629: Accuracy: 0.8968, F1 Micro: 0.7199, F1 Macro: 0.649\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.81      0.83       360\n",
      "      Abusive       0.89      0.83      0.86       365\n",
      "HS_Individual       0.73      0.63      0.68       201\n",
      "     HS_Group       0.66      0.64      0.65       159\n",
      "  HS_Religion       0.74      0.63      0.68        68\n",
      "      HS_Race       0.88      0.82      0.85        65\n",
      "  HS_Physical       0.79      0.50      0.61        82\n",
      "    HS_Gender       0.93      0.48      0.63        83\n",
      "     HS_Other       0.61      0.35      0.45        77\n",
      "      HS_Weak       0.72      0.62      0.66       197\n",
      "  HS_Moderate       0.52      0.48      0.50       134\n",
      "    HS_Strong       1.00      0.24      0.39        29\n",
      "\n",
      "    micro avg       0.78      0.67      0.72      1820\n",
      "    macro avg       0.78      0.59      0.65      1820\n",
      " weighted avg       0.78      0.67      0.71      1820\n",
      "  samples avg       0.45      0.42      0.41      1820\n",
      "\n",
      "Training completed in 78.26960468292236 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5054, Accuracy: 0.8173, F1 Micro: 0.1704, F1 Macro: 0.055\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3893, Accuracy: 0.8502, F1 Micro: 0.4691, F1 Macro: 0.1715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3284, Accuracy: 0.8645, F1 Micro: 0.5793, F1 Macro: 0.3596\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.284, Accuracy: 0.8745, F1 Micro: 0.6264, F1 Macro: 0.4127\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2445, Accuracy: 0.8812, F1 Micro: 0.6496, F1 Macro: 0.481\n",
      "Epoch 6/10, Train Loss: 0.2217, Accuracy: 0.8827, F1 Micro: 0.6438, F1 Macro: 0.5115\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.189, Accuracy: 0.8888, F1 Micro: 0.6716, F1 Macro: 0.5658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1664, Accuracy: 0.8942, F1 Micro: 0.7191, F1 Macro: 0.6498\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1481, Accuracy: 0.9009, F1 Micro: 0.7336, F1 Macro: 0.6666\n",
      "Epoch 10/10, Train Loss: 0.1257, Accuracy: 0.8972, F1 Micro: 0.7135, F1 Macro: 0.6525\n",
      "Model 2 - Iteration 2629: Accuracy: 0.9009, F1 Micro: 0.7336, F1 Macro: 0.6666\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.83      0.84       360\n",
      "      Abusive       0.87      0.85      0.86       365\n",
      "HS_Individual       0.69      0.61      0.65       201\n",
      "     HS_Group       0.71      0.69      0.70       159\n",
      "  HS_Religion       0.80      0.60      0.69        68\n",
      "      HS_Race       0.93      0.86      0.90        65\n",
      "  HS_Physical       0.76      0.62      0.68        82\n",
      "    HS_Gender       0.85      0.48      0.62        83\n",
      "     HS_Other       0.61      0.29      0.39        77\n",
      "      HS_Weak       0.70      0.62      0.66       197\n",
      "  HS_Moderate       0.61      0.56      0.59       134\n",
      "    HS_Strong       1.00      0.28      0.43        29\n",
      "\n",
      "    micro avg       0.78      0.69      0.73      1820\n",
      "    macro avg       0.78      0.61      0.67      1820\n",
      " weighted avg       0.78      0.69      0.73      1820\n",
      "  samples avg       0.46      0.42      0.42      1820\n",
      "\n",
      "Training completed in 75.84814286231995 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.511, Accuracy: 0.8163, F1 Micro: 0.1648, F1 Macro: 0.0552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3916, Accuracy: 0.8461, F1 Micro: 0.4291, F1 Macro: 0.15\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3331, Accuracy: 0.8661, F1 Micro: 0.5786, F1 Macro: 0.3585\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2884, Accuracy: 0.8764, F1 Micro: 0.6369, F1 Macro: 0.4485\n",
      "Epoch 5/10, Train Loss: 0.2502, Accuracy: 0.8798, F1 Micro: 0.6346, F1 Macro: 0.4695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2278, Accuracy: 0.8864, F1 Micro: 0.6704, F1 Macro: 0.5667\n",
      "Epoch 7/10, Train Loss: 0.1967, Accuracy: 0.8891, F1 Micro: 0.6673, F1 Macro: 0.555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1697, Accuracy: 0.8934, F1 Micro: 0.7274, F1 Macro: 0.6506\n",
      "Epoch 9/10, Train Loss: 0.1523, Accuracy: 0.8971, F1 Micro: 0.7119, F1 Macro: 0.6328\n",
      "Epoch 10/10, Train Loss: 0.1326, Accuracy: 0.898, F1 Micro: 0.7197, F1 Macro: 0.6575\n",
      "Model 3 - Iteration 2629: Accuracy: 0.8934, F1 Micro: 0.7274, F1 Macro: 0.6506\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.86      0.83       360\n",
      "      Abusive       0.85      0.87      0.86       365\n",
      "HS_Individual       0.64      0.71      0.68       201\n",
      "     HS_Group       0.71      0.65      0.68       159\n",
      "  HS_Religion       0.76      0.65      0.70        68\n",
      "      HS_Race       0.89      0.86      0.88        65\n",
      "  HS_Physical       0.58      0.61      0.60        82\n",
      "    HS_Gender       0.79      0.53      0.63        83\n",
      "     HS_Other       0.72      0.27      0.40        77\n",
      "      HS_Weak       0.66      0.72      0.68       197\n",
      "  HS_Moderate       0.53      0.54      0.54       134\n",
      "    HS_Strong       1.00      0.21      0.34        29\n",
      "\n",
      "    micro avg       0.74      0.72      0.73      1820\n",
      "    macro avg       0.74      0.62      0.65      1820\n",
      " weighted avg       0.74      0.72      0.72      1820\n",
      "  samples avg       0.44      0.44      0.42      1820\n",
      "\n",
      "Training completed in 71.60056257247925 s\n",
      "Averaged - Iteration 2629: Accuracy: 0.8971, F1 Micro: 0.7269, F1 Macro: 0.6554\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2662\n",
      "Acquired samples: 33\n",
      "Sampling duration: 1.5757200717926025 seconds\n",
      "New train size: 2662\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.498, Accuracy: 0.8293, F1 Micro: 0.293, F1 Macro: 0.0947\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3878, Accuracy: 0.8523, F1 Micro: 0.5063, F1 Macro: 0.2147\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3223, Accuracy: 0.8692, F1 Micro: 0.6142, F1 Macro: 0.3907\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2823, Accuracy: 0.8749, F1 Micro: 0.6265, F1 Macro: 0.417\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2474, Accuracy: 0.8811, F1 Micro: 0.6469, F1 Macro: 0.4713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2176, Accuracy: 0.8842, F1 Micro: 0.6928, F1 Macro: 0.5757\n",
      "Epoch 7/10, Train Loss: 0.196, Accuracy: 0.8887, F1 Micro: 0.6904, F1 Macro: 0.5825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1749, Accuracy: 0.8925, F1 Micro: 0.698, F1 Macro: 0.6108\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1465, Accuracy: 0.8952, F1 Micro: 0.7044, F1 Macro: 0.6161\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1299, Accuracy: 0.8968, F1 Micro: 0.7048, F1 Macro: 0.6175\n",
      "Model 1 - Iteration 2662: Accuracy: 0.8968, F1 Micro: 0.7048, F1 Macro: 0.6175\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.88      0.78      0.83       360\n",
      "      Abusive       0.91      0.82      0.86       365\n",
      "HS_Individual       0.76      0.58      0.66       201\n",
      "     HS_Group       0.69      0.57      0.63       159\n",
      "  HS_Religion       0.77      0.63      0.69        68\n",
      "      HS_Race       0.93      0.78      0.85        65\n",
      "  HS_Physical       0.81      0.43      0.56        82\n",
      "    HS_Gender       0.97      0.34      0.50        83\n",
      "     HS_Other       0.65      0.22      0.33        77\n",
      "      HS_Weak       0.75      0.58      0.65       197\n",
      "  HS_Moderate       0.53      0.41      0.46       134\n",
      "    HS_Strong       1.00      0.24      0.39        29\n",
      "\n",
      "    micro avg       0.81      0.62      0.70      1820\n",
      "    macro avg       0.80      0.53      0.62      1820\n",
      " weighted avg       0.81      0.62      0.69      1820\n",
      "  samples avg       0.46      0.39      0.40      1820\n",
      "\n",
      "Training completed in 78.05564713478088 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5064, Accuracy: 0.8256, F1 Micro: 0.2797, F1 Macro: 0.0889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3859, Accuracy: 0.8495, F1 Micro: 0.4823, F1 Macro: 0.176\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3227, Accuracy: 0.8682, F1 Micro: 0.5975, F1 Macro: 0.3663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2825, Accuracy: 0.8734, F1 Micro: 0.6104, F1 Macro: 0.4034\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2477, Accuracy: 0.8781, F1 Micro: 0.6592, F1 Macro: 0.4953\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2211, Accuracy: 0.8835, F1 Micro: 0.6883, F1 Macro: 0.5648\n",
      "Epoch 7/10, Train Loss: 0.1965, Accuracy: 0.8898, F1 Micro: 0.6837, F1 Macro: 0.5687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1732, Accuracy: 0.8932, F1 Micro: 0.7005, F1 Macro: 0.6154\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1464, Accuracy: 0.8923, F1 Micro: 0.7114, F1 Macro: 0.6452\n",
      "Epoch 10/10, Train Loss: 0.1311, Accuracy: 0.8964, F1 Micro: 0.7057, F1 Macro: 0.6463\n",
      "Model 2 - Iteration 2662: Accuracy: 0.8923, F1 Micro: 0.7114, F1 Macro: 0.6452\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.83      0.84       360\n",
      "      Abusive       0.87      0.82      0.85       365\n",
      "HS_Individual       0.73      0.57      0.64       201\n",
      "     HS_Group       0.62      0.72      0.67       159\n",
      "  HS_Religion       0.76      0.66      0.71        68\n",
      "      HS_Race       0.81      0.86      0.84        65\n",
      "  HS_Physical       0.76      0.39      0.52        82\n",
      "    HS_Gender       0.83      0.35      0.49        83\n",
      "     HS_Other       0.58      0.38      0.46        77\n",
      "      HS_Weak       0.72      0.55      0.62       197\n",
      "  HS_Moderate       0.53      0.63      0.58       134\n",
      "    HS_Strong       0.80      0.41      0.55        29\n",
      "\n",
      "    micro avg       0.76      0.67      0.71      1820\n",
      "    macro avg       0.74      0.60      0.65      1820\n",
      " weighted avg       0.76      0.67      0.70      1820\n",
      "  samples avg       0.45      0.41      0.41      1820\n",
      "\n",
      "Training completed in 74.9145245552063 s\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5116, Accuracy: 0.8313, F1 Micro: 0.3386, F1 Macro: 0.1056\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3898, Accuracy: 0.8477, F1 Micro: 0.4424, F1 Macro: 0.1608\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3285, Accuracy: 0.87, F1 Micro: 0.5993, F1 Macro: 0.3848\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2871, Accuracy: 0.8761, F1 Micro: 0.6226, F1 Macro: 0.4178\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2544, Accuracy: 0.8816, F1 Micro: 0.6415, F1 Macro: 0.4674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2231, Accuracy: 0.8875, F1 Micro: 0.6974, F1 Macro: 0.5859\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2044, Accuracy: 0.8928, F1 Micro: 0.7073, F1 Macro: 0.6295\n",
      "Epoch 8/10, Train Loss: 0.1787, Accuracy: 0.8945, F1 Micro: 0.6978, F1 Macro: 0.6018\n",
      "Epoch 9/10, Train Loss: 0.1513, Accuracy: 0.8931, F1 Micro: 0.6923, F1 Macro: 0.6298\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1329, Accuracy: 0.8969, F1 Micro: 0.7161, F1 Macro: 0.6482\n",
      "Model 3 - Iteration 2662: Accuracy: 0.8969, F1 Micro: 0.7161, F1 Macro: 0.6482\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.88      0.81      0.84       360\n",
      "      Abusive       0.88      0.83      0.85       365\n",
      "HS_Individual       0.76      0.58      0.66       201\n",
      "     HS_Group       0.63      0.67      0.65       159\n",
      "  HS_Religion       0.79      0.68      0.73        68\n",
      "      HS_Race       0.92      0.83      0.87        65\n",
      "  HS_Physical       0.89      0.39      0.54        82\n",
      "    HS_Gender       0.87      0.41      0.56        83\n",
      "     HS_Other       0.67      0.26      0.37        77\n",
      "      HS_Weak       0.76      0.55      0.64       197\n",
      "  HS_Moderate       0.50      0.59      0.54       134\n",
      "    HS_Strong       0.85      0.38      0.52        29\n",
      "\n",
      "    micro avg       0.79      0.66      0.72      1820\n",
      "    macro avg       0.78      0.58      0.65      1820\n",
      " weighted avg       0.79      0.66      0.71      1820\n",
      "  samples avg       0.45      0.41      0.41      1820\n",
      "\n",
      "Training completed in 75.84061932563782 s\n",
      "Averaged - Iteration 2662: Accuracy: 0.8953, F1 Micro: 0.7108, F1 Macro: 0.637\n",
      "Total sampling time: 307.91 seconds\n",
      "Total runtime: 4789.280836582184 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning([50, 67, 42], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1fc26b",
   "metadata": {
    "papermill": {
     "duration": 0.15847,
     "end_time": "2025-05-10T13:49:11.432236",
     "exception": false,
     "start_time": "2025-05-10T13:49:11.273766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6647971,
     "sourceId": 11748149,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4836.337565,
   "end_time": "2025-05-10T13:49:14.803725",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-10T12:28:38.466160",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0281d060972a45ccb50e7583f064f042": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "02e138cf49b2460595f759587bf0e5d7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "06b231b0f54b47b19c771f396ede54d3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "07a8ac98687549439511082e06b98cdd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5a38c532331c49d4b9b1cd86b0d2e006",
       "max": 229167.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0281d060972a45ccb50e7583f064f042",
       "tabbable": null,
       "tooltip": null,
       "value": 229167.0
      }
     },
     "0f53e4ce56c145beb4e8eef5ba714b93": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "18ced57369474dfe998d3e93e5e178b8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "27c93d6657114cdca4a7790b32c811ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "311820c4d7614ba19daf53f9b14a5b04": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5d6485920a7a4143b4c0c880914eac1d",
       "max": 112.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_457effa4b27e4e9ca62ec512da051720",
       "tabbable": null,
       "tooltip": null,
       "value": 112.0
      }
     },
     "326d715fad544b7fb25b5f23a5aafa58": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "331c51c6db3a475bac1769a27a263eec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_06b231b0f54b47b19c771f396ede54d3",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_cf8d2dfae408429a9672e028f4889cec",
       "tabbable": null,
       "tooltip": null,
       "value": 2.0
      }
     },
     "33a5d3a11a3e4ab3b81c9aa151dc4391": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "347f4946007848b6b0800fd6deba8e8f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "36dd15de103349c9b931ba31ee03445b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "412be042c8e842969f927e23ac68f0e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_75e91331fa14497098ada1783b6a6d16",
       "placeholder": "​",
       "style": "IPY_MODEL_7572baa913fe48f1bd5e2c86388e6529",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "428185ae6bb54cd7af129129517a47ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "43f3068e55cd4e8fa09fa1ae9a418d37": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "457effa4b27e4e9ca62ec512da051720": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4d45df9bd0744cc08f2d4b9ede27a782": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_02e138cf49b2460595f759587bf0e5d7",
       "max": 1534.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_428185ae6bb54cd7af129129517a47ee",
       "tabbable": null,
       "tooltip": null,
       "value": 1534.0
      }
     },
     "5a38c532331c49d4b9b1cd86b0d2e006": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5ab48dd192d74f77909ad95cebbfcdc6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_18ced57369474dfe998d3e93e5e178b8",
       "placeholder": "​",
       "style": "IPY_MODEL_27c93d6657114cdca4a7790b32c811ff",
       "tabbable": null,
       "tooltip": null,
       "value": " 112/112 [00:00&lt;00:00, 11.9kB/s]"
      }
     },
     "5d1968f9adeb4037a066315ef9cd946c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f4f0df5e51c840f69e89fd7d30a8009d",
       "placeholder": "​",
       "style": "IPY_MODEL_36dd15de103349c9b931ba31ee03445b",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: 100%"
      }
     },
     "5d6485920a7a4143b4c0c880914eac1d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5edf60a372c34cb88f049b8b9922283b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_412be042c8e842969f927e23ac68f0e6",
        "IPY_MODEL_331c51c6db3a475bac1769a27a263eec",
        "IPY_MODEL_ab2f9caea5324906a01cce6eb7d7aeb8"
       ],
       "layout": "IPY_MODEL_33a5d3a11a3e4ab3b81c9aa151dc4391",
       "tabbable": null,
       "tooltip": null
      }
     },
     "621967918f54400b8a377458b6390c2c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6b6c52f9f31d434f8498526618537177": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7572baa913fe48f1bd5e2c86388e6529": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "75e91331fa14497098ada1783b6a6d16": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9c4bbcc3cdf644d994830f74d167f5ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bc816dd4e76a436cac5d82a64b60530c",
       "placeholder": "​",
       "style": "IPY_MODEL_a370779d1ef3455ca95f41f63b6cb881",
       "tabbable": null,
       "tooltip": null,
       "value": " 229k/229k [00:00&lt;00:00, 6.21MB/s]"
      }
     },
     "a370779d1ef3455ca95f41f63b6cb881": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ab2f9caea5324906a01cce6eb7d7aeb8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bcc36714a39a42d9aeb2cd634fb06973",
       "placeholder": "​",
       "style": "IPY_MODEL_b1ac285c7aeb4451979bfa079b8c9ca9",
       "tabbable": null,
       "tooltip": null,
       "value": " 2.00/2.00 [00:00&lt;00:00, 157B/s]"
      }
     },
     "b1ac285c7aeb4451979bfa079b8c9ca9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "bc816dd4e76a436cac5d82a64b60530c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bcc36714a39a42d9aeb2cd634fb06973": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c16c98b852ec42c09fca12b397f0069a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_621967918f54400b8a377458b6390c2c",
       "placeholder": "​",
       "style": "IPY_MODEL_fc1346dce24a4695a9e33cff3353154f",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json: 100%"
      }
     },
     "cf8d2dfae408429a9672e028f4889cec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d6abecfa16604459b6d6d5cb8c814f6a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c16c98b852ec42c09fca12b397f0069a",
        "IPY_MODEL_311820c4d7614ba19daf53f9b14a5b04",
        "IPY_MODEL_5ab48dd192d74f77909ad95cebbfcdc6"
       ],
       "layout": "IPY_MODEL_e20ca632afd3435a879248fae127a632",
       "tabbable": null,
       "tooltip": null
      }
     },
     "d968ed8093534142b2071f80c3c1649a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0f53e4ce56c145beb4e8eef5ba714b93",
       "placeholder": "​",
       "style": "IPY_MODEL_43f3068e55cd4e8fa09fa1ae9a418d37",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "e20ca632afd3435a879248fae127a632": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ec834e2897c445d792d55e6c0b2a0e61": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5d1968f9adeb4037a066315ef9cd946c",
        "IPY_MODEL_07a8ac98687549439511082e06b98cdd",
        "IPY_MODEL_9c4bbcc3cdf644d994830f74d167f5ff"
       ],
       "layout": "IPY_MODEL_6b6c52f9f31d434f8498526618537177",
       "tabbable": null,
       "tooltip": null
      }
     },
     "f34cc2cef372450c88da78f27b374848": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d968ed8093534142b2071f80c3c1649a",
        "IPY_MODEL_4d45df9bd0744cc08f2d4b9ede27a782",
        "IPY_MODEL_fe3dc10dbef14ec49444cec0c0e7adcb"
       ],
       "layout": "IPY_MODEL_347f4946007848b6b0800fd6deba8e8f",
       "tabbable": null,
       "tooltip": null
      }
     },
     "f4f0df5e51c840f69e89fd7d30a8009d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fc1346dce24a4695a9e33cff3353154f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fcbfbf11465d4f65b4c5a5a92893570a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fe3dc10dbef14ec49444cec0c0e7adcb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fcbfbf11465d4f65b4c5a5a92893570a",
       "placeholder": "​",
       "style": "IPY_MODEL_326d715fad544b7fb25b5f23a5aafa58",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.53k/1.53k [00:00&lt;00:00, 143kB/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
