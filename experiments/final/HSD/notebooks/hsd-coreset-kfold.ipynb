{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8b67737",
   "metadata": {
    "papermill": {
     "duration": 0.01108,
     "end_time": "2025-06-29T02:16:23.587599",
     "exception": false,
     "start_time": "2025-06-29T02:16:23.576519",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "245bf682",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:16:23.609633Z",
     "iopub.status.busy": "2025-06-29T02:16:23.609285Z",
     "iopub.status.idle": "2025-06-29T02:16:47.247110Z",
     "shell.execute_reply": "2025-06-29T02:16:47.246437Z"
    },
    "papermill": {
     "duration": 23.650808,
     "end_time": "2025-06-29T02:16:47.248775",
     "exception": false,
     "start_time": "2025-06-29T02:16:23.597967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4717cfe8",
   "metadata": {
    "papermill": {
     "duration": 0.009957,
     "end_time": "2025-06-29T02:16:47.269751",
     "exception": false,
     "start_time": "2025-06-29T02:16:47.259794",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ed55256",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:16:47.291042Z",
     "iopub.status.busy": "2025-06-29T02:16:47.290574Z",
     "iopub.status.idle": "2025-06-29T02:16:47.294228Z",
     "shell.execute_reply": "2025-06-29T02:16:47.293650Z"
    },
    "papermill": {
     "duration": 0.015607,
     "end_time": "2025-06-29T02:16:47.295475",
     "exception": false,
     "start_time": "2025-06-29T02:16:47.279868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9e26339",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:16:47.318692Z",
     "iopub.status.busy": "2025-06-29T02:16:47.318455Z",
     "iopub.status.idle": "2025-06-29T02:16:47.322210Z",
     "shell.execute_reply": "2025-06-29T02:16:47.321432Z"
    },
    "papermill": {
     "duration": 0.016289,
     "end_time": "2025-06-29T02:16:47.323626",
     "exception": false,
     "start_time": "2025-06-29T02:16:47.307337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/working/results') == False:\n",
    "    os.mkdir('/kaggle/working/results')\n",
    "\n",
    "if os.path.exists('/kaggle/working/acquired_data') == False:\n",
    "    os.mkdir('/kaggle/working/acquired_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48cc4f42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:16:47.345433Z",
     "iopub.status.busy": "2025-06-29T02:16:47.345165Z",
     "iopub.status.idle": "2025-06-29T02:16:47.355222Z",
     "shell.execute_reply": "2025-06-29T02:16:47.354436Z"
    },
    "papermill": {
     "duration": 0.022858,
     "end_time": "2025-06-29T02:16:47.356619",
     "exception": false,
     "start_time": "2025-06-29T02:16:47.333761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ec12dd",
   "metadata": {
    "papermill": {
     "duration": 0.011847,
     "end_time": "2025-06-29T02:16:47.378865",
     "exception": false,
     "start_time": "2025-06-29T02:16:47.367018",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42d5355a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:16:47.400408Z",
     "iopub.status.busy": "2025-06-29T02:16:47.400187Z",
     "iopub.status.idle": "2025-06-29T02:16:47.456850Z",
     "shell.execute_reply": "2025-06-29T02:16:47.455451Z"
    },
    "papermill": {
     "duration": 0.06923,
     "end_time": "2025-06-29T02:16:47.458653",
     "exception": false,
     "start_time": "2025-06-29T02:16:47.389423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Shared resources\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "data_used = manager.list()\n",
    "sampling_dur = manager.list()\n",
    "new_samples = manager.list()\n",
    "farthest_point = manager.dict()\n",
    "\n",
    "# Non shared resources\n",
    "filename = 'hsd-coreset-kfold'\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "sequence_length = 80\n",
    "min_increment = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9919816",
   "metadata": {
    "papermill": {
     "duration": 0.01017,
     "end_time": "2025-06-29T02:16:47.479255",
     "exception": false,
     "start_time": "2025-06-29T02:16:47.469085",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43c58494",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:16:47.500951Z",
     "iopub.status.busy": "2025-06-29T02:16:47.500709Z",
     "iopub.status.idle": "2025-06-29T02:16:47.656871Z",
     "shell.execute_reply": "2025-06-29T02:16:47.655896Z"
    },
    "papermill": {
     "duration": 0.168618,
     "end_time": "2025-06-29T02:16:47.658175",
     "exception": false,
     "start_time": "2025-06-29T02:16:47.489557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (13169, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>HS</th>\n",
       "      <th>Abusive</th>\n",
       "      <th>HS_Individual</th>\n",
       "      <th>HS_Group</th>\n",
       "      <th>HS_Religion</th>\n",
       "      <th>HS_Race</th>\n",
       "      <th>HS_Physical</th>\n",
       "      <th>HS_Gender</th>\n",
       "      <th>HS_Other</th>\n",
       "      <th>HS_Weak</th>\n",
       "      <th>HS_Moderate</th>\n",
       "      <th>HS_Strong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- disaat semua cowok berusaha melacak perhatia...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT USER: USER siapa yang telat ngasih tau elu?...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41. Kadang aku berfikir, kenapa aku tetap perc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USER USER AKU ITU AKU\\n\\nKU TAU MATAMU SIPIT T...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USER USER Kaum cebong kapir udah keliatan dong...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  HS  Abusive  \\\n",
       "0  - disaat semua cowok berusaha melacak perhatia...   1        1   \n",
       "1  RT USER: USER siapa yang telat ngasih tau elu?...   0        1   \n",
       "2  41. Kadang aku berfikir, kenapa aku tetap perc...   0        0   \n",
       "3  USER USER AKU ITU AKU\\n\\nKU TAU MATAMU SIPIT T...   0        0   \n",
       "4  USER USER Kaum cebong kapir udah keliatan dong...   1        1   \n",
       "\n",
       "   HS_Individual  HS_Group  HS_Religion  HS_Race  HS_Physical  HS_Gender  \\\n",
       "0              1         0            0        0            0          0   \n",
       "1              0         0            0        0            0          0   \n",
       "2              0         0            0        0            0          0   \n",
       "3              0         0            0        0            0          0   \n",
       "4              0         1            1        0            0          0   \n",
       "\n",
       "   HS_Other  HS_Weak  HS_Moderate  HS_Strong  \n",
       "0         1        1            0          0  \n",
       "1         0        0            0          0  \n",
       "2         0        0            0          0  \n",
       "3         0        0            0          0  \n",
       "4         0        0            1          0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/kaggle/input/multi-label-hate-speech-2/re_dataset.csv', encoding='latin-1')\n",
    "\n",
    "alay_dict = pd.read_csv('/kaggle/input/multi-label-hate-speech-2/new_kamusalay.csv', encoding='latin-1', header=None)\n",
    "alay_dict = alay_dict.rename(columns={0: 'original', \n",
    "                                      1: 'replacement'})\n",
    "\n",
    "print(\"Shape: \", data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "643a62f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:16:47.684460Z",
     "iopub.status.busy": "2025-06-29T02:16:47.684173Z",
     "iopub.status.idle": "2025-06-29T02:16:47.698064Z",
     "shell.execute_reply": "2025-06-29T02:16:47.697219Z"
    },
    "papermill": {
     "duration": 0.028434,
     "end_time": "2025-06-29T02:16:47.699257",
     "exception": false,
     "start_time": "2025-06-29T02:16:47.670823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HS\n",
       "0    7608\n",
       "1    5561\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.HS.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5961bf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:16:47.721622Z",
     "iopub.status.busy": "2025-06-29T02:16:47.721343Z",
     "iopub.status.idle": "2025-06-29T02:16:47.726895Z",
     "shell.execute_reply": "2025-06-29T02:16:47.726086Z"
    },
    "papermill": {
     "duration": 0.018225,
     "end_time": "2025-06-29T02:16:47.728141",
     "exception": false,
     "start_time": "2025-06-29T02:16:47.709916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Abusive\n",
       "0    8126\n",
       "1    5043\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Abusive.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "752b5a94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:16:47.750673Z",
     "iopub.status.busy": "2025-06-29T02:16:47.750430Z",
     "iopub.status.idle": "2025-06-29T02:16:47.758324Z",
     "shell.execute_reply": "2025-06-29T02:16:47.757663Z"
    },
    "papermill": {
     "duration": 0.020575,
     "end_time": "2025-06-29T02:16:47.759740",
     "exception": false,
     "start_time": "2025-06-29T02:16:47.739165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (15167, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>replacement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anakjakartaasikasik</td>\n",
       "      <td>anak jakarta asyik asyik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pakcikdahtua</td>\n",
       "      <td>pak cik sudah tua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pakcikmudalagi</td>\n",
       "      <td>pak cik muda lagi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t3tapjokowi</td>\n",
       "      <td>tetap jokowi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3x</td>\n",
       "      <td>tiga kali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aamiin</td>\n",
       "      <td>amin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aamiinn</td>\n",
       "      <td>amin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aamin</td>\n",
       "      <td>amin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aammiin</td>\n",
       "      <td>amin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>abis</td>\n",
       "      <td>habis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>abisin</td>\n",
       "      <td>habiskan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>acau</td>\n",
       "      <td>kacau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>achok</td>\n",
       "      <td>ahok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ad</td>\n",
       "      <td>ada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>adek</td>\n",
       "      <td>adik</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               original               replacement\n",
       "0   anakjakartaasikasik  anak jakarta asyik asyik\n",
       "1          pakcikdahtua         pak cik sudah tua\n",
       "2        pakcikmudalagi         pak cik muda lagi\n",
       "3           t3tapjokowi              tetap jokowi\n",
       "4                    3x                 tiga kali\n",
       "5                aamiin                      amin\n",
       "6               aamiinn                      amin\n",
       "7                 aamin                      amin\n",
       "8               aammiin                      amin\n",
       "9                  abis                     habis\n",
       "10               abisin                  habiskan\n",
       "11                 acau                     kacau\n",
       "12                achok                      ahok\n",
       "13                   ad                       ada\n",
       "14                 adek                      adik"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape: \", alay_dict.shape)\n",
    "alay_dict.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcbc8f53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:16:47.783341Z",
     "iopub.status.busy": "2025-06-29T02:16:47.783136Z",
     "iopub.status.idle": "2025-06-29T02:16:47.795322Z",
     "shell.execute_reply": "2025-06-29T02:16:47.794689Z"
    },
    "papermill": {
     "duration": 0.025314,
     "end_time": "2025-06-29T02:16:47.796691",
     "exception": false,
     "start_time": "2025-06-29T02:16:47.771377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove_nonaplhanumeric:  Halooo duniaa \n",
      "lowercase:  halooo, duniaa!\n",
      "remove_unnecessary_char:  Hehe RT USER USER apa kabs hehe URL \n",
      "normalize_alay:  amin adik habis\n"
     ]
    }
   ],
   "source": [
    "def lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_unnecessary_char(text):\n",
    "    text = re.sub('\\n',' ',text) # Remove every '\\n'\n",
    "    text = re.sub('rt',' ',text) # Remove every retweet symbol\n",
    "    text = re.sub('user',' ',text) # Remove every username\n",
    "    text = re.sub('url', ' ', text) # Remove every URL\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+)|(http?://[^\\s]+))',' ',text) # Remove every URL\n",
    "    text = re.sub(r'\\b(?:x[a-fA-F0-9]{2}\\s*)+\\b', '', text) # Remove emoji bytecode\n",
    "    text = re.sub('  +', ' ', text) # Remove extra spaces\n",
    "    return text\n",
    "    \n",
    "def remove_nonaplhanumeric(text):\n",
    "    text = re.sub('[^0-9a-zA-Z]+', ' ', text) \n",
    "    return text\n",
    "\n",
    "alay_dict_map = dict(zip(alay_dict['original'], alay_dict['replacement']))\n",
    "def normalize_alay(text):\n",
    "    return ' '.join([alay_dict_map[word] if word in alay_dict_map else word for word in text.split(' ')])\n",
    "\n",
    "print(\"remove_nonaplhanumeric: \", remove_nonaplhanumeric(\"Halooo,,,,, duniaa \\x8f \\xd2\\1 !!\"))\n",
    "print(\"lowercase: \", lowercase(\"Halooo, duniaa!\"))\n",
    "print(\"remove_unnecessary_char: \", remove_unnecessary_char(\"Hehe\\n\\n RT USER USER apa kabs www.google.com\\n  hehe URL xf8 x2a x89\"))\n",
    "print(\"normalize_alay: \", normalize_alay(\"aamiin adek abis\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad8966c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:16:47.819701Z",
     "iopub.status.busy": "2025-06-29T02:16:47.819498Z",
     "iopub.status.idle": "2025-06-29T02:16:47.822577Z",
     "shell.execute_reply": "2025-06-29T02:16:47.821990Z"
    },
    "papermill": {
     "duration": 0.015982,
     "end_time": "2025-06-29T02:16:47.823858",
     "exception": false,
     "start_time": "2025-06-29T02:16:47.807876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = lowercase(text)\n",
    "    text = remove_nonaplhanumeric(text)\n",
    "    text = remove_unnecessary_char(text)\n",
    "    text = normalize_alay(text) \n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1a6cefb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:16:47.846820Z",
     "iopub.status.busy": "2025-06-29T02:16:47.846581Z",
     "iopub.status.idle": "2025-06-29T02:16:48.204249Z",
     "shell.execute_reply": "2025-06-29T02:16:48.203354Z"
    },
    "papermill": {
     "duration": 0.370614,
     "end_time": "2025-06-29T02:16:48.205671",
     "exception": false,
     "start_time": "2025-06-29T02:16:47.835057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['Tweet'] = data['Tweet'].apply(preprocess)\n",
    "label_columns = data.columns[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3bb2b2",
   "metadata": {
    "papermill": {
     "duration": 0.010917,
     "end_time": "2025-06-29T02:16:48.228528",
     "exception": false,
     "start_time": "2025-06-29T02:16:48.217611",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BUILD DATASET & DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "081ef4f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:16:48.251466Z",
     "iopub.status.busy": "2025-06-29T02:16:48.251193Z",
     "iopub.status.idle": "2025-06-29T02:16:48.959636Z",
     "shell.execute_reply": "2025-06-29T02:16:48.958736Z"
    },
    "papermill": {
     "duration": 0.721535,
     "end_time": "2025-06-29T02:16:48.961064",
     "exception": false,
     "start_time": "2025-06-29T02:16:48.239529",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c234ee16574257b1353ac989a8abd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0b30660daf84e0c80faa3e2fa961f79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e8759ba1434e49a951162e51c39e2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929e89e44942450283fc5dd973ece05f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class HateSpeechDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        labels = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(labels, dtype=torch.float if self.use_float else torch.long)\n",
    "        return item\n",
    "\n",
    "# Initialize BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71f92adb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:16:48.985995Z",
     "iopub.status.busy": "2025-06-29T02:16:48.985731Z",
     "iopub.status.idle": "2025-06-29T02:16:48.990124Z",
     "shell.execute_reply": "2025-06-29T02:16:48.989292Z"
    },
    "papermill": {
     "duration": 0.018025,
     "end_time": "2025-06-29T02:16:48.991242",
     "exception": false,
     "start_time": "2025-06-29T02:16:48.973217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataloaders(X_train, y_train, X_val, y_val, sequence_length=sequence_length, num_workers=4):\n",
    "    train_dataset = HateSpeechDataset(X_train, y_train, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = HateSpeechDataset(X_val, y_val, tokenizer, max_length=sequence_length)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43146c95",
   "metadata": {
    "papermill": {
     "duration": 0.011309,
     "end_time": "2025-06-29T02:16:49.014146",
     "exception": false,
     "start_time": "2025-06-29T02:16:49.002837",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c56647c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:16:49.038347Z",
     "iopub.status.busy": "2025-06-29T02:16:49.038118Z",
     "iopub.status.idle": "2025-06-29T02:16:49.042889Z",
     "shell.execute_reply": "2025-06-29T02:16:49.042077Z"
    },
    "papermill": {
     "duration": 0.01833,
     "end_time": "2025-06-29T02:16:49.044206",
     "exception": false,
     "start_time": "2025-06-29T02:16:49.025876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        target_names=['HS', 'Abusive', 'HS_Individual', 'HS_Group', 'HS_Religion', 'HS_Race', 'HS_Physical', 'HS_Gender', 'HS_Other', 'HS_Weak', 'HS_Moderate', 'HS_Strong'],\n",
    "        zero_division=0\n",
    "    )   \n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58aafb04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:16:49.067992Z",
     "iopub.status.busy": "2025-06-29T02:16:49.067797Z",
     "iopub.status.idle": "2025-06-29T02:16:49.080008Z",
     "shell.execute_reply": "2025-06-29T02:16:49.079190Z"
    },
    "papermill": {
     "duration": 0.025354,
     "end_time": "2025-06-29T02:16:49.081137",
     "exception": false,
     "start_time": "2025-06-29T02:16:49.055783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, metrics, trials, seed, X_train_fold, y_train_fold, X_val_fold, y_val_fold, label_columns):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "\n",
    "    accelerator.print(f\"Fold {trials + 1} - Training with {current_train_size} samples\")\n",
    "\n",
    "    with accelerator.main_process_first():\n",
    "        model = BertForSequenceClassification.from_pretrained(\n",
    "            'indobenchmark/indobert-base-p1',\n",
    "            num_labels=len(label_columns),\n",
    "            problem_type=\"multi_label_classification\"\n",
    "        )\n",
    "\n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Define DataLoaders using the fold's data\n",
    "    current_X_train = [X_train_fold[i] for i in train_indices]\n",
    "    current_y_train = [y_train_fold[i] for i in train_indices]\n",
    "    train_loader, val_loader = get_dataloaders(current_X_train, current_y_train, X_val_fold, y_val_fold)\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Prepare everything with Accelerator\n",
    "    model, optimizer, train_loader, val_loader = accelerator.prepare(\n",
    "        model, optimizer, train_loader, val_loader\n",
    "    )\n",
    "\n",
    "    best_result = None\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key != 'labels'}\n",
    "            labels = batch['labels']\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key != 'labels'}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "        result = compute_metrics(type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}))\n",
    "\n",
    "        if best_result is None or result['f1_micro'] >= best_result['f1_micro']:\n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'{filename}-fold-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "            best_result = result\n",
    "        \n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    accelerator.print(f\"Best result for {current_train_size} samples: F1 Micro: {round(best_result['f1_micro'], 4)}\")\n",
    "    accelerator.print(best_result['report'])\n",
    "    \n",
    "    # Update the shared lists\n",
    "    if accelerator.is_local_main_process:\n",
    "        metrics[0].append(current_train_size)\n",
    "        metrics[1].append(best_result['accuracy'])\n",
    "        metrics[2].append(best_result['f1_micro'])\n",
    "        metrics[3].append(best_result['f1_macro'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793fc4c0",
   "metadata": {
    "papermill": {
     "duration": 0.011462,
     "end_time": "2025-06-29T02:16:49.104236",
     "exception": false,
     "start_time": "2025-06-29T02:16:49.092774",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PLOT THE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c88caeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:16:49.128483Z",
     "iopub.status.busy": "2025-06-29T02:16:49.128232Z",
     "iopub.status.idle": "2025-06-29T02:16:49.133884Z",
     "shell.execute_reply": "2025-06-29T02:16:49.133069Z"
    },
    "papermill": {
     "duration": 0.019168,
     "end_time": "2025-06-29T02:16:49.135130",
     "exception": false,
     "start_time": "2025-06-29T02:16:49.115962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30db4ad5",
   "metadata": {
    "papermill": {
     "duration": 0.01204,
     "end_time": "2025-06-29T02:16:49.159093",
     "exception": false,
     "start_time": "2025-06-29T02:16:49.147053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QUERY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d607e58c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:16:49.183735Z",
     "iopub.status.busy": "2025-06-29T02:16:49.183506Z",
     "iopub.status.idle": "2025-06-29T02:16:49.195874Z",
     "shell.execute_reply": "2025-06-29T02:16:49.195034Z"
    },
    "papermill": {
     "duration": 0.026331,
     "end_time": "2025-06-29T02:16:49.197077",
     "exception": false,
     "start_time": "2025-06-29T02:16:49.170746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def coreset_sampling(model, farthest_point, X_pool, train_indices, remaining_indices, sampling_dur, new_samples, trials, X_train_fold, y_train_fold, n_samples=min_increment):\n",
    "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "    device = accelerator.device\n",
    "    model.to(device)\n",
    "\n",
    "    current_train_size = len(train_indices)\n",
    "    dataset = HateSpeechDataset(X_pool, np.zeros((len(X_pool), 4)), tokenizer, max_length=sequence_length)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    farthest_data = dict(farthest_point)\n",
    "    \n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    embeddings = []\n",
    "    \n",
    "    for data in dataloader:\n",
    "        input_ids = data['input_ids'].to(device, non_blocking=True)\n",
    "        attention_mask = data['attention_mask'].to(device, non_blocking=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = model.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        hidden_states = outputs.last_hidden_state.mean(dim=1)  # Mean of hidden states for vector representation\n",
    "        embeddings.append(hidden_states.cpu().numpy())\n",
    "\n",
    "    if 'input_ids' in farthest_data:\n",
    "        with torch.no_grad():\n",
    "            outputs = model.base_model(\n",
    "                input_ids=farthest_data['input_ids'].unsqueeze(0).to(device, non_blocking=True), \n",
    "                attention_mask=farthest_data['attention_mask'].unsqueeze(0).to(device, non_blocking=True)\n",
    "            )\n",
    "            hidden_states = outputs.last_hidden_state.mean(dim=1)  # Mean of hidden states for vector representation\n",
    "            embeddings.append(hidden_states.cpu().numpy())\n",
    "    \n",
    "    embeddings = np.vstack(embeddings)\n",
    "    embeddings = np.array(embeddings)\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "\n",
    "    if accelerator.is_local_main_process:\n",
    "        # Use pairwise distances to compute a distance matrix for Coreset selection\n",
    "        distance_matrix = pairwise_distances(embeddings)    \n",
    "        selected_indices = distance_matrix.shape[0] - 1 if 'input_ids' in farthest_data else 0\n",
    "        \n",
    "        # Calculate the minimum distance from selected points to all other points\n",
    "        min_distances = distance_matrix[selected_indices]\n",
    "\n",
    "        sorted_dist = np.argsort(min_distances)\n",
    "        sorted_dist = sorted_dist[::-1]\n",
    "        farthest_point['input_ids'] = dataset[sorted_dist[0]]['input_ids']\n",
    "        farthest_point['attention_mask'] = dataset[sorted_dist[0]]['attention_mask']\n",
    "                \n",
    "        threshold = np.percentile(min_distances, 90)\n",
    "        candidates = np.where(min_distances >= threshold)[0]  # Select the point farthest from the current set\n",
    "        num_of_candidates = len(candidates)\n",
    "    \n",
    "        # Check nearest checkpoint\n",
    "        nearest_cp = 0\n",
    "        for cp in checkpoints:\n",
    "            if cp > current_train_size:\n",
    "                nearest_cp = cp\n",
    "                break\n",
    "        \n",
    "        if num_of_candidates <= n_samples and n_samples < nearest_cp - current_train_size:\n",
    "            selected_indices = sorted_dist[:n_samples]\n",
    "        elif num_of_candidates > n_samples and num_of_candidates < nearest_cp - current_train_size:\n",
    "             selected_indices = sorted_dist[:max(n_samples, min(math.ceil(0.1*len(sorted_dist)), num_of_candidates))]\n",
    "        else:\n",
    "            selected_indices = sorted_dist[:nearest_cp - current_train_size]\n",
    "    \n",
    "            temp = train_indices.copy()\n",
    "            temp.extend([remaining_indices[i] for i in selected_indices])\n",
    "            \n",
    "            # Save acquired data up to checkpoint\n",
    "            acquired_data = pd.DataFrame({\n",
    "                'processed_text': [X_train_fold[i] for i in temp],\n",
    "                'HS': [y_train_fold[i][0] for i in temp],\n",
    "                'Abusive': [y_train_fold[i][1] for i in temp],\n",
    "                'HS_Individual': [y_train_fold[i][2] for i in temp],\n",
    "                'HS_Group': [y_train_fold[i][3] for i in temp],\n",
    "                'HS_Religion': [y_train_fold[i][4] for i in temp],\n",
    "                'HS_Race': [y_train_fold[i][5] for i in temp],\n",
    "                'HS_Physical': [y_train_fold[i][6] for i in temp],\n",
    "                'HS_Gender': [y_train_fold[i][7] for i in temp],\n",
    "                'HS_Other': [y_train_fold[i][8] for i in temp],\n",
    "                'HS_Weak': [y_train_fold[i][9] for i in temp],\n",
    "                'HS_Moderate': [y_train_fold[i][10] for i in temp],\n",
    "                'HS_Strong': [y_train_fold[i][11] for i in temp],\n",
    "            })\n",
    "    \n",
    "            acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "    \n",
    "        end_time = time.time() \n",
    "        duration = end_time - start_time\n",
    "    \n",
    "        sampling_dur.append(duration)\n",
    "        for i in selected_indices:\n",
    "            new_samples.append(remaining_indices[i])\n",
    "            \n",
    "        print(\"Nearest checkpoint:\", nearest_cp)\n",
    "        print(\"Threshold:\", threshold)\n",
    "        print(\"Samples above threshold:\", num_of_candidates)\n",
    "        print(\"Acquired samples:\", len(selected_indices))\n",
    "        print(f\"Sampling duration: {duration} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e064e145",
   "metadata": {
    "papermill": {
     "duration": 0.011817,
     "end_time": "2025-06-29T02:16:49.220853",
     "exception": false,
     "start_time": "2025-06-29T02:16:49.209036",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b9d4815",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:16:49.245891Z",
     "iopub.status.busy": "2025-06-29T02:16:49.245663Z",
     "iopub.status.idle": "2025-06-29T10:15:46.122155Z",
     "shell.execute_reply": "2025-06-29T10:15:46.120955Z"
    },
    "papermill": {
     "duration": 28736.891042,
     "end_time": "2025-06-29T10:15:46.123899",
     "exception": false,
     "start_time": "2025-06-29T02:16:49.232857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "STARTING FOLD 1/5\n",
      "===============================================\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 658 samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "851c0a6385df4b8d8391a37e0319a781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.6398, Accuracy: 0.7977, F1 Micro: 0.3894, F1 Macro: 0.1173\n",
      "Epoch 2/10, Train Loss: 0.4791, Accuracy: 0.8349, F1 Micro: 0.1631, F1 Macro: 0.0493\n",
      "Epoch 3/10, Train Loss: 0.4083, Accuracy: 0.8329, F1 Micro: 0.1055, F1 Macro: 0.0371\n",
      "Epoch 4/10, Train Loss: 0.3819, Accuracy: 0.8329, F1 Micro: 0.0977, F1 Macro: 0.0354\n",
      "Epoch 5/10, Train Loss: 0.3775, Accuracy: 0.8368, F1 Micro: 0.1577, F1 Macro: 0.0517\n",
      "Epoch 6/10, Train Loss: 0.3646, Accuracy: 0.8432, F1 Micro: 0.2313, F1 Macro: 0.0778\n",
      "Epoch 7/10, Train Loss: 0.3564, Accuracy: 0.8514, F1 Micro: 0.3095, F1 Macro: 0.1032\n",
      "Epoch 8/10, Train Loss: 0.3305, Accuracy: 0.861, F1 Micro: 0.3998, F1 Macro: 0.1449\n",
      "Epoch 9/10, Train Loss: 0.3159, Accuracy: 0.8714, F1 Micro: 0.4936, F1 Macro: 0.2158\n",
      "Epoch 10/10, Train Loss: 0.2956, Accuracy: 0.8752, F1 Micro: 0.5329, F1 Macro: 0.2447\n",
      "Best result for 658 samples: F1 Micro: 0.5329\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.62      0.71      1141\n",
      "      Abusive       0.80      0.75      0.77      1012\n",
      "HS_Individual       0.67      0.40      0.50       737\n",
      "     HS_Group       0.00      0.00      0.00       404\n",
      "  HS_Religion       0.00      0.00      0.00       164\n",
      "      HS_Race       0.00      0.00      0.00       119\n",
      "  HS_Physical       0.00      0.00      0.00        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.72      0.36      0.48       779\n",
      "      HS_Weak       0.66      0.36      0.46       686\n",
      "  HS_Moderate       0.00      0.00      0.00       356\n",
      "    HS_Strong       0.00      0.00      0.00        99\n",
      "\n",
      "    micro avg       0.76      0.41      0.53      5608\n",
      "    macro avg       0.31      0.21      0.24      5608\n",
      " weighted avg       0.58      0.41      0.47      5608\n",
      "  samples avg       0.37      0.26      0.28      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 27.42330207824707\n",
      "Samples above threshold: 988\n",
      "Acquired samples: 988\n",
      "Sampling duration: 43.74325704574585 seconds\n",
      "\n",
      "Fold 1 - New train size: 1646\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 1646 samples\n",
      "Epoch 1/10, Train Loss: 0.5325, Accuracy: 0.8261, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.3542, Accuracy: 0.8261, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.3251, Accuracy: 0.8311, F1 Micro: 0.0613, F1 Macro: 0.0252\n",
      "Epoch 4/10, Train Loss: 0.3037, Accuracy: 0.8575, F1 Micro: 0.3635, F1 Macro: 0.1223\n",
      "Epoch 5/10, Train Loss: 0.2596, Accuracy: 0.8701, F1 Micro: 0.4914, F1 Macro: 0.2702\n",
      "Epoch 6/10, Train Loss: 0.2256, Accuracy: 0.8792, F1 Micro: 0.5449, F1 Macro: 0.3144\n",
      "Epoch 7/10, Train Loss: 0.2103, Accuracy: 0.8865, F1 Micro: 0.5999, F1 Macro: 0.3935\n",
      "Epoch 8/10, Train Loss: 0.1744, Accuracy: 0.8893, F1 Micro: 0.6078, F1 Macro: 0.4123\n",
      "Epoch 9/10, Train Loss: 0.1656, Accuracy: 0.8959, F1 Micro: 0.6744, F1 Macro: 0.4909\n",
      "Epoch 10/10, Train Loss: 0.1537, Accuracy: 0.8964, F1 Micro: 0.6696, F1 Macro: 0.5018\n",
      "Best result for 1646 samples: F1 Micro: 0.6744\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.81      0.81      1141\n",
      "      Abusive       0.83      0.75      0.78      1012\n",
      "HS_Individual       0.68      0.65      0.66       737\n",
      "     HS_Group       0.64      0.43      0.52       404\n",
      "  HS_Religion       0.82      0.19      0.31       164\n",
      "      HS_Race       0.74      0.43      0.54       119\n",
      "  HS_Physical       0.00      0.00      0.00        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.74      0.65      0.69       779\n",
      "      HS_Weak       0.64      0.59      0.62       686\n",
      "  HS_Moderate       0.58      0.25      0.35       356\n",
      "    HS_Strong       0.68      0.56      0.61        99\n",
      "\n",
      "    micro avg       0.74      0.62      0.67      5608\n",
      "    macro avg       0.60      0.44      0.49      5608\n",
      " weighted avg       0.72      0.62      0.66      5608\n",
      "  samples avg       0.39      0.35      0.34      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 39.01836624145508\n",
      "Samples above threshold: 889\n",
      "Acquired samples: 889\n",
      "Sampling duration: 44.619723081588745 seconds\n",
      "\n",
      "Fold 1 - New train size: 2535\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 2535 samples\n",
      "Epoch 1/10, Train Loss: 0.516, Accuracy: 0.8402, F1 Micro: 0.4189, F1 Macro: 0.1343\n",
      "Epoch 2/10, Train Loss: 0.3708, Accuracy: 0.8545, F1 Micro: 0.5595, F1 Macro: 0.2551\n",
      "Epoch 3/10, Train Loss: 0.3198, Accuracy: 0.8813, F1 Micro: 0.5899, F1 Macro: 0.3243\n",
      "Epoch 4/10, Train Loss: 0.2741, Accuracy: 0.8926, F1 Micro: 0.6478, F1 Macro: 0.4205\n",
      "Epoch 5/10, Train Loss: 0.2439, Accuracy: 0.8972, F1 Micro: 0.6514, F1 Macro: 0.4614\n",
      "Epoch 6/10, Train Loss: 0.2256, Accuracy: 0.9021, F1 Micro: 0.7042, F1 Macro: 0.5468\n",
      "Epoch 7/10, Train Loss: 0.1899, Accuracy: 0.9007, F1 Micro: 0.6505, F1 Macro: 0.5047\n",
      "Epoch 8/10, Train Loss: 0.1683, Accuracy: 0.906, F1 Micro: 0.696, F1 Macro: 0.5615\n",
      "Epoch 9/10, Train Loss: 0.1506, Accuracy: 0.9049, F1 Micro: 0.712, F1 Macro: 0.5724\n",
      "Epoch 10/10, Train Loss: 0.1336, Accuracy: 0.9066, F1 Micro: 0.7184, F1 Macro: 0.5814\n",
      "Best result for 2535 samples: F1 Micro: 0.7184\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.81      0.82      0.82      1141\n",
      "      Abusive       0.83      0.80      0.81      1012\n",
      "HS_Individual       0.74      0.62      0.67       737\n",
      "     HS_Group       0.64      0.65      0.64       404\n",
      "  HS_Religion       0.75      0.52      0.61       164\n",
      "      HS_Race       0.77      0.69      0.73       119\n",
      "  HS_Physical       0.00      0.00      0.00        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.76      0.73      0.74       779\n",
      "      HS_Weak       0.71      0.56      0.62       686\n",
      "  HS_Moderate       0.56      0.53      0.54       356\n",
      "    HS_Strong       0.80      0.75      0.77        99\n",
      "\n",
      "    micro avg       0.75      0.69      0.72      5608\n",
      "    macro avg       0.61      0.55      0.58      5608\n",
      " weighted avg       0.74      0.69      0.71      5608\n",
      "  samples avg       0.40      0.38      0.37      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 38.11597442626953\n",
      "Samples above threshold: 801\n",
      "Acquired samples: 801\n",
      "Sampling duration: 40.824090242385864 seconds\n",
      "\n",
      "Fold 1 - New train size: 3336\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 3336 samples\n",
      "Epoch 1/10, Train Loss: 0.4835, Accuracy: 0.8483, F1 Micro: 0.3808, F1 Macro: 0.1208\n",
      "Epoch 2/10, Train Loss: 0.3337, Accuracy: 0.8768, F1 Micro: 0.5466, F1 Macro: 0.2803\n",
      "Epoch 3/10, Train Loss: 0.2737, Accuracy: 0.8921, F1 Micro: 0.6235, F1 Macro: 0.3758\n",
      "Epoch 4/10, Train Loss: 0.2356, Accuracy: 0.8994, F1 Micro: 0.6582, F1 Macro: 0.4603\n",
      "Epoch 5/10, Train Loss: 0.2031, Accuracy: 0.906, F1 Micro: 0.6955, F1 Macro: 0.5318\n",
      "Epoch 6/10, Train Loss: 0.1829, Accuracy: 0.9067, F1 Micro: 0.6913, F1 Macro: 0.5579\n",
      "Epoch 7/10, Train Loss: 0.1578, Accuracy: 0.9069, F1 Micro: 0.7291, F1 Macro: 0.5909\n",
      "Epoch 8/10, Train Loss: 0.1359, Accuracy: 0.9079, F1 Micro: 0.6954, F1 Macro: 0.5714\n",
      "Epoch 9/10, Train Loss: 0.1214, Accuracy: 0.909, F1 Micro: 0.7175, F1 Macro: 0.5788\n",
      "Epoch 10/10, Train Loss: 0.1052, Accuracy: 0.908, F1 Micro: 0.7043, F1 Macro: 0.5767\n",
      "Best result for 3336 samples: F1 Micro: 0.7291\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.78      0.88      0.83      1141\n",
      "      Abusive       0.78      0.86      0.82      1012\n",
      "HS_Individual       0.72      0.65      0.68       737\n",
      "     HS_Group       0.64      0.66      0.65       404\n",
      "  HS_Religion       0.66      0.64      0.65       164\n",
      "      HS_Race       0.79      0.71      0.75       119\n",
      "  HS_Physical       0.00      0.00      0.00        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.77      0.73      0.75       779\n",
      "      HS_Weak       0.69      0.57      0.62       686\n",
      "  HS_Moderate       0.60      0.54      0.57       356\n",
      "    HS_Strong       0.78      0.75      0.76        99\n",
      "\n",
      "    micro avg       0.74      0.72      0.73      5608\n",
      "    macro avg       0.60      0.58      0.59      5608\n",
      " weighted avg       0.72      0.72      0.72      5608\n",
      "  samples avg       0.41      0.40      0.39      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 36.980659103393556\n",
      "Samples above threshold: 720\n",
      "Acquired samples: 720\n",
      "Sampling duration: 36.71747708320618 seconds\n",
      "\n",
      "Fold 1 - New train size: 4056\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 4056 samples\n",
      "Epoch 1/10, Train Loss: 0.4675, Accuracy: 0.8531, F1 Micro: 0.4696, F1 Macro: 0.1899\n",
      "Epoch 2/10, Train Loss: 0.3195, Accuracy: 0.8854, F1 Micro: 0.5996, F1 Macro: 0.323\n",
      "Epoch 3/10, Train Loss: 0.267, Accuracy: 0.9, F1 Micro: 0.6744, F1 Macro: 0.465\n",
      "Epoch 4/10, Train Loss: 0.2347, Accuracy: 0.9031, F1 Micro: 0.7092, F1 Macro: 0.5369\n",
      "Epoch 5/10, Train Loss: 0.1928, Accuracy: 0.909, F1 Micro: 0.7225, F1 Macro: 0.5415\n",
      "Epoch 6/10, Train Loss: 0.1726, Accuracy: 0.9125, F1 Micro: 0.7165, F1 Macro: 0.5681\n",
      "Epoch 7/10, Train Loss: 0.1505, Accuracy: 0.914, F1 Micro: 0.7298, F1 Macro: 0.5927\n",
      "Epoch 8/10, Train Loss: 0.125, Accuracy: 0.915, F1 Micro: 0.7423, F1 Macro: 0.6183\n",
      "Epoch 9/10, Train Loss: 0.1106, Accuracy: 0.9146, F1 Micro: 0.7373, F1 Macro: 0.6232\n",
      "Epoch 10/10, Train Loss: 0.1022, Accuracy: 0.9164, F1 Micro: 0.7481, F1 Macro: 0.6396\n",
      "Best result for 4056 samples: F1 Micro: 0.7481\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.82      0.83      1141\n",
      "      Abusive       0.85      0.87      0.86      1012\n",
      "HS_Individual       0.74      0.68      0.71       737\n",
      "     HS_Group       0.70      0.59      0.64       404\n",
      "  HS_Religion       0.73      0.62      0.67       164\n",
      "      HS_Race       0.77      0.77      0.77       119\n",
      "  HS_Physical       0.73      0.15      0.25        53\n",
      "    HS_Gender       0.83      0.09      0.16        58\n",
      "     HS_Other       0.82      0.69      0.75       779\n",
      "      HS_Weak       0.71      0.65      0.68       686\n",
      "  HS_Moderate       0.66      0.50      0.57       356\n",
      "    HS_Strong       0.78      0.81      0.79        99\n",
      "\n",
      "    micro avg       0.79      0.71      0.75      5608\n",
      "    macro avg       0.76      0.60      0.64      5608\n",
      " weighted avg       0.78      0.71      0.74      5608\n",
      "  samples avg       0.43      0.41      0.40      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 38.253919219970705\n",
      "Samples above threshold: 648\n",
      "Acquired samples: 648\n",
      "Sampling duration: 33.038206815719604 seconds\n",
      "\n",
      "Fold 1 - New train size: 4704\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 4704 samples\n",
      "Epoch 1/10, Train Loss: 0.4516, Accuracy: 0.8612, F1 Micro: 0.4203, F1 Macro: 0.1501\n",
      "Epoch 2/10, Train Loss: 0.2989, Accuracy: 0.891, F1 Micro: 0.6707, F1 Macro: 0.406\n",
      "Epoch 3/10, Train Loss: 0.2454, Accuracy: 0.9032, F1 Micro: 0.6865, F1 Macro: 0.4876\n",
      "Epoch 4/10, Train Loss: 0.2023, Accuracy: 0.9116, F1 Micro: 0.7263, F1 Macro: 0.5556\n",
      "Epoch 5/10, Train Loss: 0.1801, Accuracy: 0.9135, F1 Micro: 0.7439, F1 Macro: 0.5885\n",
      "Epoch 6/10, Train Loss: 0.1527, Accuracy: 0.9159, F1 Micro: 0.7461, F1 Macro: 0.5998\n",
      "Epoch 7/10, Train Loss: 0.1298, Accuracy: 0.9167, F1 Micro: 0.7531, F1 Macro: 0.6154\n",
      "Epoch 8/10, Train Loss: 0.1125, Accuracy: 0.9156, F1 Micro: 0.7615, F1 Macro: 0.6433\n",
      "Epoch 9/10, Train Loss: 0.0969, Accuracy: 0.9178, F1 Micro: 0.7444, F1 Macro: 0.6186\n",
      "Epoch 10/10, Train Loss: 0.0848, Accuracy: 0.9153, F1 Micro: 0.7611, F1 Macro: 0.6435\n",
      "Best result for 4704 samples: F1 Micro: 0.7615\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.88      0.84      1141\n",
      "      Abusive       0.82      0.93      0.87      1012\n",
      "HS_Individual       0.70      0.73      0.72       737\n",
      "     HS_Group       0.69      0.66      0.67       404\n",
      "  HS_Religion       0.80      0.55      0.65       164\n",
      "      HS_Race       0.82      0.71      0.76       119\n",
      "  HS_Physical       0.75      0.17      0.28        53\n",
      "    HS_Gender       1.00      0.03      0.07        58\n",
      "     HS_Other       0.73      0.82      0.78       779\n",
      "      HS_Weak       0.67      0.71      0.69       686\n",
      "  HS_Moderate       0.65      0.56      0.60       356\n",
      "    HS_Strong       0.80      0.80      0.80        99\n",
      "\n",
      "    micro avg       0.75      0.77      0.76      5608\n",
      "    macro avg       0.77      0.63      0.64      5608\n",
      " weighted avg       0.75      0.77      0.75      5608\n",
      "  samples avg       0.44      0.44      0.42      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 33.54686393737793\n",
      "Samples above threshold: 584\n",
      "Acquired samples: 584\n",
      "Sampling duration: 29.729512214660645 seconds\n",
      "\n",
      "Fold 1 - New train size: 5288\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 5288 samples\n",
      "Epoch 1/10, Train Loss: 0.4311, Accuracy: 0.8679, F1 Micro: 0.4728, F1 Macro: 0.1894\n",
      "Epoch 2/10, Train Loss: 0.2829, Accuracy: 0.8972, F1 Micro: 0.6652, F1 Macro: 0.4528\n",
      "Epoch 3/10, Train Loss: 0.2214, Accuracy: 0.9033, F1 Micro: 0.7174, F1 Macro: 0.5296\n",
      "Epoch 4/10, Train Loss: 0.1863, Accuracy: 0.9083, F1 Micro: 0.7301, F1 Macro: 0.5775\n",
      "Epoch 5/10, Train Loss: 0.165, Accuracy: 0.9107, F1 Micro: 0.7346, F1 Macro: 0.5867\n",
      "Epoch 6/10, Train Loss: 0.1401, Accuracy: 0.9174, F1 Micro: 0.7552, F1 Macro: 0.6008\n",
      "Epoch 7/10, Train Loss: 0.1185, Accuracy: 0.917, F1 Micro: 0.7546, F1 Macro: 0.6064\n",
      "Epoch 8/10, Train Loss: 0.1003, Accuracy: 0.9178, F1 Micro: 0.7464, F1 Macro: 0.6292\n",
      "Epoch 9/10, Train Loss: 0.0931, Accuracy: 0.9062, F1 Micro: 0.7479, F1 Macro: 0.6346\n",
      "Epoch 10/10, Train Loss: 0.0791, Accuracy: 0.9193, F1 Micro: 0.7524, F1 Macro: 0.65\n",
      "Best result for 5288 samples: F1 Micro: 0.7552\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.86      0.84      1141\n",
      "      Abusive       0.85      0.89      0.87      1012\n",
      "HS_Individual       0.71      0.73      0.72       737\n",
      "     HS_Group       0.76      0.55      0.64       404\n",
      "  HS_Religion       0.76      0.48      0.59       164\n",
      "      HS_Race       0.78      0.71      0.75       119\n",
      "  HS_Physical       1.00      0.02      0.04        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.78      0.76      0.77       779\n",
      "      HS_Weak       0.69      0.70      0.69       686\n",
      "  HS_Moderate       0.69      0.44      0.54       356\n",
      "    HS_Strong       0.80      0.73      0.76        99\n",
      "\n",
      "    micro avg       0.78      0.73      0.76      5608\n",
      "    macro avg       0.72      0.57      0.60      5608\n",
      " weighted avg       0.77      0.73      0.74      5608\n",
      "  samples avg       0.44      0.42      0.41      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 34.82076225280762\n",
      "Samples above threshold: 525\n",
      "Acquired samples: 525\n",
      "Sampling duration: 27.1153085231781 seconds\n",
      "\n",
      "Fold 1 - New train size: 5813\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 5813 samples\n",
      "Epoch 1/10, Train Loss: 0.4303, Accuracy: 0.8732, F1 Micro: 0.5312, F1 Macro: 0.2367\n",
      "Epoch 2/10, Train Loss: 0.286, Accuracy: 0.9004, F1 Micro: 0.6801, F1 Macro: 0.4896\n",
      "Epoch 3/10, Train Loss: 0.2289, Accuracy: 0.9085, F1 Micro: 0.7127, F1 Macro: 0.5085\n",
      "Epoch 4/10, Train Loss: 0.1901, Accuracy: 0.9134, F1 Micro: 0.746, F1 Macro: 0.5788\n",
      "Epoch 5/10, Train Loss: 0.1645, Accuracy: 0.9118, F1 Micro: 0.7537, F1 Macro: 0.6026\n",
      "Epoch 6/10, Train Loss: 0.1434, Accuracy: 0.9197, F1 Micro: 0.7508, F1 Macro: 0.6289\n",
      "Epoch 7/10, Train Loss: 0.12, Accuracy: 0.9214, F1 Micro: 0.7562, F1 Macro: 0.6224\n",
      "Epoch 8/10, Train Loss: 0.1063, Accuracy: 0.9192, F1 Micro: 0.7589, F1 Macro: 0.6455\n",
      "Epoch 9/10, Train Loss: 0.0886, Accuracy: 0.9133, F1 Micro: 0.7568, F1 Macro: 0.6665\n",
      "Epoch 10/10, Train Loss: 0.0817, Accuracy: 0.9197, F1 Micro: 0.7575, F1 Macro: 0.6759\n",
      "Best result for 5813 samples: F1 Micro: 0.7589\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.84      0.84      1141\n",
      "      Abusive       0.86      0.87      0.87      1012\n",
      "HS_Individual       0.72      0.71      0.71       737\n",
      "     HS_Group       0.74      0.57      0.64       404\n",
      "  HS_Religion       0.75      0.56      0.64       164\n",
      "      HS_Race       0.77      0.71      0.74       119\n",
      "  HS_Physical       0.71      0.09      0.17        53\n",
      "    HS_Gender       0.77      0.17      0.28        58\n",
      "     HS_Other       0.82      0.76      0.79       779\n",
      "      HS_Weak       0.69      0.68      0.68       686\n",
      "  HS_Moderate       0.69      0.49      0.57       356\n",
      "    HS_Strong       0.80      0.79      0.80        99\n",
      "\n",
      "    micro avg       0.79      0.73      0.76      5608\n",
      "    macro avg       0.77      0.60      0.65      5608\n",
      " weighted avg       0.79      0.73      0.75      5608\n",
      "  samples avg       0.44      0.42      0.41      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 36.358280181884766\n",
      "Samples above threshold: 473\n",
      "Acquired samples: 473\n",
      "Sampling duration: 24.552650928497314 seconds\n",
      "\n",
      "Fold 1 - New train size: 6286\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 6286 samples\n",
      "Epoch 1/10, Train Loss: 0.4152, Accuracy: 0.8734, F1 Micro: 0.5098, F1 Macro: 0.2281\n",
      "Epoch 2/10, Train Loss: 0.2713, Accuracy: 0.9004, F1 Micro: 0.7053, F1 Macro: 0.5126\n",
      "Epoch 3/10, Train Loss: 0.2132, Accuracy: 0.9092, F1 Micro: 0.7218, F1 Macro: 0.5185\n",
      "Epoch 4/10, Train Loss: 0.1831, Accuracy: 0.9151, F1 Micro: 0.7483, F1 Macro: 0.585\n",
      "Epoch 5/10, Train Loss: 0.1551, Accuracy: 0.9167, F1 Micro: 0.7448, F1 Macro: 0.5675\n",
      "Epoch 6/10, Train Loss: 0.1335, Accuracy: 0.9216, F1 Micro: 0.765, F1 Macro: 0.6367\n",
      "Epoch 7/10, Train Loss: 0.1105, Accuracy: 0.9188, F1 Micro: 0.7518, F1 Macro: 0.6308\n",
      "Epoch 8/10, Train Loss: 0.0933, Accuracy: 0.922, F1 Micro: 0.77, F1 Macro: 0.6875\n",
      "Epoch 9/10, Train Loss: 0.0828, Accuracy: 0.9205, F1 Micro: 0.7679, F1 Macro: 0.6813\n",
      "Epoch 10/10, Train Loss: 0.0726, Accuracy: 0.9185, F1 Micro: 0.7647, F1 Macro: 0.6848\n",
      "Best result for 6286 samples: F1 Micro: 0.77\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.85      0.85      1141\n",
      "      Abusive       0.87      0.88      0.87      1012\n",
      "HS_Individual       0.73      0.73      0.73       737\n",
      "     HS_Group       0.75      0.61      0.67       404\n",
      "  HS_Religion       0.76      0.58      0.66       164\n",
      "      HS_Race       0.77      0.74      0.75       119\n",
      "  HS_Physical       0.64      0.26      0.37        53\n",
      "    HS_Gender       0.66      0.33      0.44        58\n",
      "     HS_Other       0.81      0.76      0.78       779\n",
      "      HS_Weak       0.70      0.71      0.70       686\n",
      "  HS_Moderate       0.70      0.53      0.61       356\n",
      "    HS_Strong       0.82      0.81      0.81        99\n",
      "\n",
      "    micro avg       0.79      0.75      0.77      5608\n",
      "    macro avg       0.75      0.65      0.69      5608\n",
      " weighted avg       0.79      0.75      0.77      5608\n",
      "  samples avg       0.44      0.43      0.42      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 33.183524703979494\n",
      "Samples above threshold: 425\n",
      "Acquired samples: 298\n",
      "Sampling duration: 22.389583349227905 seconds\n",
      "\n",
      "Fold 1 - New train size: 6584\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 6584 samples\n",
      "Epoch 1/10, Train Loss: 0.4139, Accuracy: 0.8795, F1 Micro: 0.5978, F1 Macro: 0.2776\n",
      "Epoch 2/10, Train Loss: 0.2704, Accuracy: 0.9023, F1 Micro: 0.6766, F1 Macro: 0.4343\n",
      "Epoch 3/10, Train Loss: 0.2141, Accuracy: 0.9119, F1 Micro: 0.7258, F1 Macro: 0.5242\n",
      "Epoch 4/10, Train Loss: 0.1808, Accuracy: 0.9143, F1 Micro: 0.7492, F1 Macro: 0.5828\n",
      "Epoch 5/10, Train Loss: 0.1551, Accuracy: 0.9183, F1 Micro: 0.7596, F1 Macro: 0.6211\n",
      "Epoch 6/10, Train Loss: 0.1312, Accuracy: 0.9191, F1 Micro: 0.7653, F1 Macro: 0.6298\n",
      "Epoch 7/10, Train Loss: 0.1117, Accuracy: 0.9175, F1 Micro: 0.7665, F1 Macro: 0.667\n",
      "Epoch 8/10, Train Loss: 0.0961, Accuracy: 0.9212, F1 Micro: 0.759, F1 Macro: 0.6265\n",
      "Epoch 9/10, Train Loss: 0.083, Accuracy: 0.9221, F1 Micro: 0.7694, F1 Macro: 0.6653\n",
      "Epoch 10/10, Train Loss: 0.0711, Accuracy: 0.9217, F1 Micro: 0.7595, F1 Macro: 0.6811\n",
      "Best result for 6584 samples: F1 Micro: 0.7694\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.84      0.85      1141\n",
      "      Abusive       0.87      0.89      0.88      1012\n",
      "HS_Individual       0.71      0.77      0.74       737\n",
      "     HS_Group       0.78      0.53      0.63       404\n",
      "  HS_Religion       0.80      0.54      0.64       164\n",
      "      HS_Race       0.79      0.71      0.74       119\n",
      "  HS_Physical       0.83      0.19      0.31        53\n",
      "    HS_Gender       0.73      0.19      0.30        58\n",
      "     HS_Other       0.82      0.78      0.80       779\n",
      "      HS_Weak       0.68      0.74      0.71       686\n",
      "  HS_Moderate       0.71      0.47      0.56       356\n",
      "    HS_Strong       0.84      0.80      0.82        99\n",
      "\n",
      "    micro avg       0.79      0.75      0.77      5608\n",
      "    macro avg       0.78      0.62      0.67      5608\n",
      " weighted avg       0.79      0.75      0.76      5608\n",
      "  samples avg       0.44      0.43      0.42      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 36.393367004394534\n",
      "Samples above threshold: 396\n",
      "Acquired samples: 396\n",
      "Sampling duration: 20.60116958618164 seconds\n",
      "\n",
      "Fold 1 - New train size: 6980\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 6980 samples\n",
      "Epoch 1/10, Train Loss: 0.4091, Accuracy: 0.8797, F1 Micro: 0.5706, F1 Macro: 0.2735\n",
      "Epoch 2/10, Train Loss: 0.2753, Accuracy: 0.9023, F1 Micro: 0.7123, F1 Macro: 0.497\n",
      "Epoch 3/10, Train Loss: 0.2216, Accuracy: 0.9129, F1 Micro: 0.7211, F1 Macro: 0.5357\n",
      "Epoch 4/10, Train Loss: 0.1788, Accuracy: 0.9179, F1 Micro: 0.7407, F1 Macro: 0.5794\n",
      "Epoch 5/10, Train Loss: 0.1541, Accuracy: 0.9208, F1 Micro: 0.7566, F1 Macro: 0.6173\n",
      "Epoch 6/10, Train Loss: 0.1341, Accuracy: 0.9224, F1 Micro: 0.7612, F1 Macro: 0.6246\n",
      "Epoch 7/10, Train Loss: 0.1153, Accuracy: 0.9194, F1 Micro: 0.7733, F1 Macro: 0.6639\n",
      "Epoch 8/10, Train Loss: 0.0951, Accuracy: 0.9234, F1 Micro: 0.7664, F1 Macro: 0.6708\n",
      "Epoch 9/10, Train Loss: 0.0779, Accuracy: 0.9188, F1 Micro: 0.7721, F1 Macro: 0.6883\n",
      "Epoch 10/10, Train Loss: 0.072, Accuracy: 0.9216, F1 Micro: 0.7646, F1 Macro: 0.6876\n",
      "Best result for 6980 samples: F1 Micro: 0.7733\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.81      0.89      0.85      1141\n",
      "      Abusive       0.86      0.89      0.88      1012\n",
      "HS_Individual       0.70      0.77      0.73       737\n",
      "     HS_Group       0.69      0.68      0.69       404\n",
      "  HS_Religion       0.72      0.67      0.69       164\n",
      "      HS_Race       0.74      0.76      0.75       119\n",
      "  HS_Physical       0.88      0.13      0.23        53\n",
      "    HS_Gender       0.89      0.14      0.24        58\n",
      "     HS_Other       0.75      0.84      0.79       779\n",
      "      HS_Weak       0.67      0.74      0.71       686\n",
      "  HS_Moderate       0.64      0.61      0.62       356\n",
      "    HS_Strong       0.77      0.80      0.79        99\n",
      "\n",
      "    micro avg       0.76      0.79      0.77      5608\n",
      "    macro avg       0.76      0.66      0.66      5608\n",
      " weighted avg       0.76      0.79      0.77      5608\n",
      "  samples avg       0.44      0.45      0.43      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 37.38975715637207\n",
      "Samples above threshold: 356\n",
      "Acquired samples: 356\n",
      "Sampling duration: 18.792405366897583 seconds\n",
      "\n",
      "Fold 1 - New train size: 7336\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 7336 samples\n",
      "Epoch 1/10, Train Loss: 0.411, Accuracy: 0.8764, F1 Micro: 0.5365, F1 Macro: 0.2667\n",
      "Epoch 2/10, Train Loss: 0.2736, Accuracy: 0.9028, F1 Micro: 0.7062, F1 Macro: 0.4735\n",
      "Epoch 3/10, Train Loss: 0.2193, Accuracy: 0.9131, F1 Micro: 0.7456, F1 Macro: 0.5416\n",
      "Epoch 4/10, Train Loss: 0.185, Accuracy: 0.9182, F1 Micro: 0.7552, F1 Macro: 0.5885\n",
      "Epoch 5/10, Train Loss: 0.152, Accuracy: 0.9164, F1 Micro: 0.77, F1 Macro: 0.6322\n",
      "Epoch 6/10, Train Loss: 0.1333, Accuracy: 0.9229, F1 Micro: 0.7745, F1 Macro: 0.6443\n",
      "Epoch 7/10, Train Loss: 0.1063, Accuracy: 0.9186, F1 Micro: 0.769, F1 Macro: 0.6546\n",
      "Epoch 8/10, Train Loss: 0.0998, Accuracy: 0.9252, F1 Micro: 0.7684, F1 Macro: 0.6719\n",
      "Epoch 9/10, Train Loss: 0.0803, Accuracy: 0.9243, F1 Micro: 0.7771, F1 Macro: 0.6907\n",
      "Epoch 10/10, Train Loss: 0.0719, Accuracy: 0.9238, F1 Micro: 0.776, F1 Macro: 0.7004\n",
      "Best result for 7336 samples: F1 Micro: 0.7771\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.86      0.86      1141\n",
      "      Abusive       0.87      0.90      0.88      1012\n",
      "HS_Individual       0.75      0.72      0.73       737\n",
      "     HS_Group       0.70      0.62      0.66       404\n",
      "  HS_Religion       0.74      0.65      0.69       164\n",
      "      HS_Race       0.74      0.70      0.72       119\n",
      "  HS_Physical       0.76      0.25      0.37        53\n",
      "    HS_Gender       0.82      0.31      0.45        58\n",
      "     HS_Other       0.83      0.77      0.80       779\n",
      "      HS_Weak       0.72      0.70      0.71       686\n",
      "  HS_Moderate       0.65      0.58      0.61       356\n",
      "    HS_Strong       0.81      0.79      0.80        99\n",
      "\n",
      "    micro avg       0.80      0.76      0.78      5608\n",
      "    macro avg       0.77      0.65      0.69      5608\n",
      " weighted avg       0.79      0.76      0.77      5608\n",
      "  samples avg       0.45      0.43      0.43      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 33.67606163024902\n",
      "Samples above threshold: 320\n",
      "Acquired samples: 320\n",
      "Sampling duration: 16.80160403251648 seconds\n",
      "\n",
      "Fold 1 - New train size: 7656\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 7656 samples\n",
      "Epoch 1/10, Train Loss: 0.4097, Accuracy: 0.8782, F1 Micro: 0.5481, F1 Macro: 0.2595\n",
      "Epoch 2/10, Train Loss: 0.2699, Accuracy: 0.9036, F1 Micro: 0.7105, F1 Macro: 0.5144\n",
      "Epoch 3/10, Train Loss: 0.2159, Accuracy: 0.9139, F1 Micro: 0.7462, F1 Macro: 0.5647\n",
      "Epoch 4/10, Train Loss: 0.1793, Accuracy: 0.9209, F1 Micro: 0.7624, F1 Macro: 0.6121\n",
      "Epoch 5/10, Train Loss: 0.1523, Accuracy: 0.9216, F1 Micro: 0.7689, F1 Macro: 0.6275\n",
      "Epoch 6/10, Train Loss: 0.1325, Accuracy: 0.9218, F1 Micro: 0.762, F1 Macro: 0.6408\n",
      "Epoch 7/10, Train Loss: 0.1116, Accuracy: 0.9263, F1 Micro: 0.7782, F1 Macro: 0.6754\n",
      "Epoch 8/10, Train Loss: 0.094, Accuracy: 0.9204, F1 Micro: 0.7762, F1 Macro: 0.6824\n",
      "Epoch 9/10, Train Loss: 0.0807, Accuracy: 0.9213, F1 Micro: 0.7778, F1 Macro: 0.6934\n",
      "Epoch 10/10, Train Loss: 0.072, Accuracy: 0.9208, F1 Micro: 0.7781, F1 Macro: 0.7076\n",
      "Best result for 7656 samples: F1 Micro: 0.7782\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.87      0.84      0.86      1141\n",
      "      Abusive       0.90      0.87      0.88      1012\n",
      "HS_Individual       0.75      0.74      0.74       737\n",
      "     HS_Group       0.77      0.58      0.66       404\n",
      "  HS_Religion       0.78      0.61      0.68       164\n",
      "      HS_Race       0.80      0.71      0.75       119\n",
      "  HS_Physical       0.80      0.15      0.25        53\n",
      "    HS_Gender       0.78      0.24      0.37        58\n",
      "     HS_Other       0.83      0.78      0.81       779\n",
      "      HS_Weak       0.73      0.71      0.72       686\n",
      "  HS_Moderate       0.70      0.51      0.59       356\n",
      "    HS_Strong       0.82      0.76      0.79        99\n",
      "\n",
      "    micro avg       0.82      0.74      0.78      5608\n",
      "    macro avg       0.79      0.62      0.68      5608\n",
      " weighted avg       0.81      0.74      0.77      5608\n",
      "  samples avg       0.44      0.42      0.41      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 35.602692413330075\n",
      "Samples above threshold: 288\n",
      "Acquired samples: 245\n",
      "Sampling duration: 15.648024559020996 seconds\n",
      "\n",
      "Fold 1 - New train size: 7901\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 7901 samples\n",
      "Epoch 1/10, Train Loss: 0.4042, Accuracy: 0.8815, F1 Micro: 0.5832, F1 Macro: 0.2877\n",
      "Epoch 2/10, Train Loss: 0.2636, Accuracy: 0.9044, F1 Micro: 0.7202, F1 Macro: 0.5401\n",
      "Epoch 3/10, Train Loss: 0.2129, Accuracy: 0.9141, F1 Micro: 0.7473, F1 Macro: 0.5709\n",
      "Epoch 4/10, Train Loss: 0.1782, Accuracy: 0.9204, F1 Micro: 0.7552, F1 Macro: 0.5981\n",
      "Epoch 5/10, Train Loss: 0.1478, Accuracy: 0.9232, F1 Micro: 0.7655, F1 Macro: 0.627\n",
      "Epoch 6/10, Train Loss: 0.1258, Accuracy: 0.9253, F1 Micro: 0.7669, F1 Macro: 0.6454\n",
      "Epoch 7/10, Train Loss: 0.1066, Accuracy: 0.9252, F1 Micro: 0.7726, F1 Macro: 0.6638\n",
      "Epoch 8/10, Train Loss: 0.0917, Accuracy: 0.9237, F1 Micro: 0.772, F1 Macro: 0.6799\n",
      "Epoch 9/10, Train Loss: 0.0794, Accuracy: 0.9255, F1 Micro: 0.7767, F1 Macro: 0.6985\n",
      "Epoch 10/10, Train Loss: 0.0658, Accuracy: 0.9266, F1 Micro: 0.78, F1 Macro: 0.7023\n",
      "Best result for 7901 samples: F1 Micro: 0.78\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.87      0.83      0.85      1141\n",
      "      Abusive       0.91      0.87      0.89      1012\n",
      "HS_Individual       0.76      0.73      0.75       737\n",
      "     HS_Group       0.74      0.59      0.66       404\n",
      "  HS_Religion       0.77      0.66      0.71       164\n",
      "      HS_Race       0.70      0.79      0.74       119\n",
      "  HS_Physical       0.79      0.28      0.42        53\n",
      "    HS_Gender       0.83      0.34      0.49        58\n",
      "     HS_Other       0.84      0.78      0.81       779\n",
      "      HS_Weak       0.73      0.71      0.72       686\n",
      "  HS_Moderate       0.70      0.51      0.59       356\n",
      "    HS_Strong       0.78      0.84      0.81        99\n",
      "\n",
      "    micro avg       0.81      0.75      0.78      5608\n",
      "    macro avg       0.79      0.66      0.70      5608\n",
      " weighted avg       0.81      0.75      0.78      5608\n",
      "  samples avg       0.45      0.43      0.42      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 34.63042984008789\n",
      "Samples above threshold: 264\n",
      "Acquired samples: 264\n",
      "Sampling duration: 14.028999328613281 seconds\n",
      "\n",
      "Fold 1 - New train size: 8165\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 8165 samples\n",
      "Epoch 1/10, Train Loss: 0.4018, Accuracy: 0.8843, F1 Micro: 0.6037, F1 Macro: 0.283\n",
      "Epoch 2/10, Train Loss: 0.2624, Accuracy: 0.9073, F1 Micro: 0.7032, F1 Macro: 0.4627\n",
      "Epoch 3/10, Train Loss: 0.205, Accuracy: 0.9128, F1 Micro: 0.7114, F1 Macro: 0.5185\n",
      "Epoch 4/10, Train Loss: 0.1767, Accuracy: 0.9199, F1 Micro: 0.7525, F1 Macro: 0.6036\n",
      "Epoch 5/10, Train Loss: 0.1508, Accuracy: 0.923, F1 Micro: 0.754, F1 Macro: 0.6041\n",
      "Epoch 6/10, Train Loss: 0.1271, Accuracy: 0.922, F1 Micro: 0.7653, F1 Macro: 0.6395\n",
      "Epoch 7/10, Train Loss: 0.106, Accuracy: 0.9252, F1 Micro: 0.7751, F1 Macro: 0.6432\n",
      "Epoch 8/10, Train Loss: 0.0943, Accuracy: 0.9248, F1 Micro: 0.7818, F1 Macro: 0.6776\n",
      "Epoch 9/10, Train Loss: 0.0793, Accuracy: 0.9255, F1 Micro: 0.7791, F1 Macro: 0.6939\n",
      "Epoch 10/10, Train Loss: 0.0689, Accuracy: 0.9238, F1 Micro: 0.776, F1 Macro: 0.6914\n",
      "Best result for 8165 samples: F1 Micro: 0.7818\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.88      0.86      1141\n",
      "      Abusive       0.88      0.91      0.89      1012\n",
      "HS_Individual       0.75      0.72      0.73       737\n",
      "     HS_Group       0.68      0.69      0.68       404\n",
      "  HS_Religion       0.82      0.58      0.68       164\n",
      "      HS_Race       0.79      0.71      0.75       119\n",
      "  HS_Physical       0.67      0.08      0.14        53\n",
      "    HS_Gender       0.82      0.31      0.45        58\n",
      "     HS_Other       0.78      0.84      0.81       779\n",
      "      HS_Weak       0.73      0.68      0.70       686\n",
      "  HS_Moderate       0.64      0.62      0.63       356\n",
      "    HS_Strong       0.80      0.81      0.80        99\n",
      "\n",
      "    micro avg       0.79      0.77      0.78      5608\n",
      "    macro avg       0.77      0.65      0.68      5608\n",
      " weighted avg       0.79      0.77      0.78      5608\n",
      "  samples avg       0.45      0.44      0.43      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 29.64773941040039\n",
      "Samples above threshold: 238\n",
      "Acquired samples: 238\n",
      "Sampling duration: 12.939016103744507 seconds\n",
      "\n",
      "Fold 1 - New train size: 8403\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 8403 samples\n",
      "Epoch 1/10, Train Loss: 0.4002, Accuracy: 0.8851, F1 Micro: 0.6195, F1 Macro: 0.3058\n",
      "Epoch 2/10, Train Loss: 0.2562, Accuracy: 0.9076, F1 Micro: 0.7115, F1 Macro: 0.517\n",
      "Epoch 3/10, Train Loss: 0.2173, Accuracy: 0.9141, F1 Micro: 0.7495, F1 Macro: 0.5923\n",
      "Epoch 4/10, Train Loss: 0.1772, Accuracy: 0.9219, F1 Micro: 0.768, F1 Macro: 0.6157\n",
      "Epoch 5/10, Train Loss: 0.1481, Accuracy: 0.9204, F1 Micro: 0.7727, F1 Macro: 0.6363\n",
      "Epoch 6/10, Train Loss: 0.1268, Accuracy: 0.919, F1 Micro: 0.7746, F1 Macro: 0.6559\n",
      "Epoch 7/10, Train Loss: 0.1084, Accuracy: 0.9204, F1 Micro: 0.7784, F1 Macro: 0.6737\n",
      "Epoch 8/10, Train Loss: 0.0919, Accuracy: 0.9227, F1 Micro: 0.7753, F1 Macro: 0.6852\n",
      "Epoch 9/10, Train Loss: 0.0784, Accuracy: 0.925, F1 Micro: 0.7762, F1 Macro: 0.6971\n",
      "Epoch 10/10, Train Loss: 0.0672, Accuracy: 0.9206, F1 Micro: 0.776, F1 Macro: 0.6911\n",
      "Best result for 8403 samples: F1 Micro: 0.7784\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.90      0.85      1141\n",
      "      Abusive       0.85      0.93      0.89      1012\n",
      "HS_Individual       0.69      0.79      0.73       737\n",
      "     HS_Group       0.71      0.66      0.68       404\n",
      "  HS_Religion       0.74      0.64      0.69       164\n",
      "      HS_Race       0.73      0.78      0.76       119\n",
      "  HS_Physical       0.62      0.15      0.24        53\n",
      "    HS_Gender       0.80      0.21      0.33        58\n",
      "     HS_Other       0.76      0.83      0.80       779\n",
      "      HS_Weak       0.67      0.78      0.72       686\n",
      "  HS_Moderate       0.65      0.61      0.63       356\n",
      "    HS_Strong       0.82      0.73      0.77        99\n",
      "\n",
      "    micro avg       0.75      0.80      0.78      5608\n",
      "    macro avg       0.74      0.67      0.67      5608\n",
      " weighted avg       0.75      0.80      0.77      5608\n",
      "  samples avg       0.45      0.46      0.44      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 34.01486663818359\n",
      "Samples above threshold: 214\n",
      "Acquired samples: 214\n",
      "Sampling duration: 11.746013164520264 seconds\n",
      "\n",
      "Fold 1 - New train size: 8617\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 8617 samples\n",
      "Epoch 1/10, Train Loss: 0.4014, Accuracy: 0.8831, F1 Micro: 0.587, F1 Macro: 0.2836\n",
      "Epoch 2/10, Train Loss: 0.2661, Accuracy: 0.9082, F1 Micro: 0.7197, F1 Macro: 0.5383\n",
      "Epoch 3/10, Train Loss: 0.2112, Accuracy: 0.918, F1 Micro: 0.7564, F1 Macro: 0.5958\n",
      "Epoch 4/10, Train Loss: 0.1738, Accuracy: 0.921, F1 Micro: 0.7623, F1 Macro: 0.6152\n",
      "Epoch 5/10, Train Loss: 0.1492, Accuracy: 0.9258, F1 Micro: 0.7764, F1 Macro: 0.6354\n",
      "Epoch 6/10, Train Loss: 0.1265, Accuracy: 0.926, F1 Micro: 0.7831, F1 Macro: 0.6749\n",
      "Epoch 7/10, Train Loss: 0.1047, Accuracy: 0.9247, F1 Micro: 0.7717, F1 Macro: 0.6618\n",
      "Epoch 8/10, Train Loss: 0.0906, Accuracy: 0.9259, F1 Micro: 0.7811, F1 Macro: 0.6875\n",
      "Epoch 9/10, Train Loss: 0.0783, Accuracy: 0.9256, F1 Micro: 0.7806, F1 Macro: 0.698\n",
      "Epoch 10/10, Train Loss: 0.069, Accuracy: 0.9258, F1 Micro: 0.7774, F1 Macro: 0.6931\n",
      "Best result for 8617 samples: F1 Micro: 0.7831\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.87      0.86      1141\n",
      "      Abusive       0.88      0.89      0.88      1012\n",
      "HS_Individual       0.73      0.76      0.74       737\n",
      "     HS_Group       0.76      0.62      0.68       404\n",
      "  HS_Religion       0.71      0.66      0.68       164\n",
      "      HS_Race       0.76      0.76      0.76       119\n",
      "  HS_Physical       0.75      0.11      0.20        53\n",
      "    HS_Gender       0.74      0.24      0.36        58\n",
      "     HS_Other       0.83      0.78      0.80       779\n",
      "      HS_Weak       0.71      0.75      0.73       686\n",
      "  HS_Moderate       0.71      0.54      0.61       356\n",
      "    HS_Strong       0.80      0.76      0.78        99\n",
      "\n",
      "    micro avg       0.80      0.77      0.78      5608\n",
      "    macro avg       0.77      0.64      0.67      5608\n",
      " weighted avg       0.80      0.77      0.78      5608\n",
      "  samples avg       0.45      0.44      0.43      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 30.76548500061035\n",
      "Samples above threshold: 192\n",
      "Acquired samples: 200\n",
      "Sampling duration: 10.643192529678345 seconds\n",
      "\n",
      "Fold 1 - New train size: 8817\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 8817 samples\n",
      "Epoch 1/10, Train Loss: 0.3928, Accuracy: 0.8855, F1 Micro: 0.6038, F1 Macro: 0.3059\n",
      "Epoch 2/10, Train Loss: 0.2621, Accuracy: 0.9083, F1 Micro: 0.7063, F1 Macro: 0.4845\n",
      "Epoch 3/10, Train Loss: 0.2125, Accuracy: 0.9166, F1 Micro: 0.7527, F1 Macro: 0.5687\n",
      "Epoch 4/10, Train Loss: 0.1766, Accuracy: 0.9191, F1 Micro: 0.7639, F1 Macro: 0.6\n",
      "Epoch 5/10, Train Loss: 0.1456, Accuracy: 0.9246, F1 Micro: 0.7777, F1 Macro: 0.6317\n",
      "Epoch 6/10, Train Loss: 0.1249, Accuracy: 0.9274, F1 Micro: 0.7813, F1 Macro: 0.6741\n",
      "Epoch 7/10, Train Loss: 0.1048, Accuracy: 0.9253, F1 Micro: 0.7755, F1 Macro: 0.6762\n",
      "Epoch 8/10, Train Loss: 0.0877, Accuracy: 0.9266, F1 Micro: 0.7873, F1 Macro: 0.6787\n",
      "Epoch 9/10, Train Loss: 0.0764, Accuracy: 0.9253, F1 Micro: 0.7797, F1 Macro: 0.7031\n",
      "Epoch 10/10, Train Loss: 0.0692, Accuracy: 0.9274, F1 Micro: 0.7913, F1 Macro: 0.7119\n",
      "Best result for 8817 samples: F1 Micro: 0.7913\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.88      0.87      1141\n",
      "      Abusive       0.89      0.90      0.90      1012\n",
      "HS_Individual       0.75      0.75      0.75       737\n",
      "     HS_Group       0.69      0.69      0.69       404\n",
      "  HS_Religion       0.70      0.71      0.71       164\n",
      "      HS_Race       0.74      0.77      0.76       119\n",
      "  HS_Physical       0.78      0.26      0.39        53\n",
      "    HS_Gender       0.81      0.36      0.50        58\n",
      "     HS_Other       0.82      0.82      0.82       779\n",
      "      HS_Weak       0.73      0.73      0.73       686\n",
      "  HS_Moderate       0.63      0.63      0.63       356\n",
      "    HS_Strong       0.78      0.83      0.80        99\n",
      "\n",
      "    micro avg       0.79      0.79      0.79      5608\n",
      "    macro avg       0.76      0.70      0.71      5608\n",
      " weighted avg       0.79      0.79      0.79      5608\n",
      "  samples avg       0.45      0.45      0.44      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 32.57812957763672\n",
      "Samples above threshold: 172\n",
      "Acquired samples: 200\n",
      "Sampling duration: 9.647423267364502 seconds\n",
      "\n",
      "Fold 1 - New train size: 9017\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 9017 samples\n",
      "Epoch 1/10, Train Loss: 0.3956, Accuracy: 0.8779, F1 Micro: 0.5133, F1 Macro: 0.245\n",
      "Epoch 2/10, Train Loss: 0.2615, Accuracy: 0.9095, F1 Micro: 0.7103, F1 Macro: 0.5159\n",
      "Epoch 3/10, Train Loss: 0.2111, Accuracy: 0.9161, F1 Micro: 0.7514, F1 Macro: 0.5677\n",
      "Epoch 4/10, Train Loss: 0.1751, Accuracy: 0.9233, F1 Micro: 0.7697, F1 Macro: 0.608\n",
      "Epoch 5/10, Train Loss: 0.1492, Accuracy: 0.9247, F1 Micro: 0.7717, F1 Macro: 0.627\n",
      "Epoch 6/10, Train Loss: 0.1224, Accuracy: 0.9241, F1 Micro: 0.783, F1 Macro: 0.6643\n",
      "Epoch 7/10, Train Loss: 0.1053, Accuracy: 0.9264, F1 Micro: 0.7815, F1 Macro: 0.6702\n",
      "Epoch 8/10, Train Loss: 0.0927, Accuracy: 0.9273, F1 Micro: 0.7901, F1 Macro: 0.698\n",
      "Epoch 9/10, Train Loss: 0.0812, Accuracy: 0.9264, F1 Micro: 0.7779, F1 Macro: 0.6914\n",
      "Epoch 10/10, Train Loss: 0.0705, Accuracy: 0.923, F1 Micro: 0.7795, F1 Macro: 0.6859\n",
      "Best result for 9017 samples: F1 Micro: 0.7901\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.88      0.86      1141\n",
      "      Abusive       0.88      0.90      0.89      1012\n",
      "HS_Individual       0.71      0.81      0.76       737\n",
      "     HS_Group       0.81      0.60      0.69       404\n",
      "  HS_Religion       0.72      0.67      0.69       164\n",
      "      HS_Race       0.74      0.78      0.76       119\n",
      "  HS_Physical       0.60      0.23      0.33        53\n",
      "    HS_Gender       0.73      0.33      0.45        58\n",
      "     HS_Other       0.83      0.79      0.81       779\n",
      "      HS_Weak       0.68      0.81      0.74       686\n",
      "  HS_Moderate       0.75      0.53      0.62       356\n",
      "    HS_Strong       0.83      0.73      0.77        99\n",
      "\n",
      "    micro avg       0.79      0.79      0.79      5608\n",
      "    macro avg       0.76      0.67      0.70      5608\n",
      " weighted avg       0.79      0.79      0.79      5608\n",
      "  samples avg       0.45      0.45      0.44      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 31.01293487548828\n",
      "Samples above threshold: 152\n",
      "Acquired samples: 200\n",
      "Sampling duration: 9.015270233154297 seconds\n",
      "\n",
      "Fold 1 - New train size: 9217\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 9217 samples\n",
      "Epoch 1/10, Train Loss: 0.3887, Accuracy: 0.8859, F1 Micro: 0.5945, F1 Macro: 0.3011\n",
      "Epoch 2/10, Train Loss: 0.2591, Accuracy: 0.9098, F1 Micro: 0.7037, F1 Macro: 0.5169\n",
      "Epoch 3/10, Train Loss: 0.209, Accuracy: 0.919, F1 Micro: 0.7532, F1 Macro: 0.5908\n",
      "Epoch 4/10, Train Loss: 0.1744, Accuracy: 0.9222, F1 Micro: 0.7688, F1 Macro: 0.6111\n",
      "Epoch 5/10, Train Loss: 0.1446, Accuracy: 0.9191, F1 Micro: 0.7744, F1 Macro: 0.6366\n",
      "Epoch 6/10, Train Loss: 0.125, Accuracy: 0.9256, F1 Micro: 0.7821, F1 Macro: 0.6413\n",
      "Epoch 7/10, Train Loss: 0.1011, Accuracy: 0.9249, F1 Micro: 0.7807, F1 Macro: 0.674\n",
      "Epoch 8/10, Train Loss: 0.0891, Accuracy: 0.9252, F1 Micro: 0.7754, F1 Macro: 0.6871\n",
      "Epoch 9/10, Train Loss: 0.0766, Accuracy: 0.924, F1 Micro: 0.7802, F1 Macro: 0.6901\n",
      "Epoch 10/10, Train Loss: 0.0676, Accuracy: 0.9226, F1 Micro: 0.7819, F1 Macro: 0.7061\n",
      "Best result for 9217 samples: F1 Micro: 0.7821\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.87      0.86      1141\n",
      "      Abusive       0.90      0.88      0.89      1012\n",
      "HS_Individual       0.74      0.78      0.76       737\n",
      "     HS_Group       0.75      0.60      0.66       404\n",
      "  HS_Religion       0.75      0.63      0.69       164\n",
      "      HS_Race       0.77      0.70      0.73       119\n",
      "  HS_Physical       0.67      0.08      0.14        53\n",
      "    HS_Gender       0.80      0.07      0.13        58\n",
      "     HS_Other       0.79      0.82      0.81       779\n",
      "      HS_Weak       0.70      0.77      0.73       686\n",
      "  HS_Moderate       0.70      0.51      0.59       356\n",
      "    HS_Strong       0.79      0.65      0.71        99\n",
      "\n",
      "    micro avg       0.80      0.77      0.78      5608\n",
      "    macro avg       0.77      0.61      0.64      5608\n",
      " weighted avg       0.79      0.77      0.77      5608\n",
      "  samples avg       0.44      0.44      0.43      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 29.054077911376954\n",
      "Samples above threshold: 132\n",
      "Acquired samples: 1\n",
      "Sampling duration: 8.008646726608276 seconds\n",
      "\n",
      "Fold 1 - New train size: 9218\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 9218 samples\n",
      "Epoch 1/10, Train Loss: 0.3902, Accuracy: 0.8848, F1 Micro: 0.6552, F1 Macro: 0.327\n",
      "Epoch 2/10, Train Loss: 0.2571, Accuracy: 0.9098, F1 Micro: 0.7194, F1 Macro: 0.5243\n",
      "Epoch 3/10, Train Loss: 0.207, Accuracy: 0.9173, F1 Micro: 0.7492, F1 Macro: 0.5834\n",
      "Epoch 4/10, Train Loss: 0.1748, Accuracy: 0.9244, F1 Micro: 0.7711, F1 Macro: 0.616\n",
      "Epoch 5/10, Train Loss: 0.1453, Accuracy: 0.9256, F1 Micro: 0.7732, F1 Macro: 0.6399\n",
      "Epoch 6/10, Train Loss: 0.1235, Accuracy: 0.9277, F1 Micro: 0.7821, F1 Macro: 0.6674\n",
      "Epoch 7/10, Train Loss: 0.1025, Accuracy: 0.9252, F1 Micro: 0.7762, F1 Macro: 0.6656\n",
      "Epoch 8/10, Train Loss: 0.0897, Accuracy: 0.9273, F1 Micro: 0.7864, F1 Macro: 0.7035\n",
      "Epoch 9/10, Train Loss: 0.0753, Accuracy: 0.9209, F1 Micro: 0.7786, F1 Macro: 0.699\n",
      "Epoch 10/10, Train Loss: 0.0663, Accuracy: 0.9281, F1 Micro: 0.79, F1 Macro: 0.71\n",
      "Best result for 9218 samples: F1 Micro: 0.79\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.87      0.85      0.86      1141\n",
      "      Abusive       0.89      0.91      0.90      1012\n",
      "HS_Individual       0.75      0.75      0.75       737\n",
      "     HS_Group       0.74      0.65      0.69       404\n",
      "  HS_Religion       0.73      0.66      0.69       164\n",
      "      HS_Race       0.79      0.74      0.77       119\n",
      "  HS_Physical       0.62      0.30      0.41        53\n",
      "    HS_Gender       0.69      0.41      0.52        58\n",
      "     HS_Other       0.83      0.80      0.82       779\n",
      "      HS_Weak       0.72      0.73      0.73       686\n",
      "  HS_Moderate       0.67      0.58      0.62       356\n",
      "    HS_Strong       0.75      0.78      0.77        99\n",
      "\n",
      "    micro avg       0.80      0.78      0.79      5608\n",
      "    macro avg       0.75      0.68      0.71      5608\n",
      " weighted avg       0.80      0.78      0.79      5608\n",
      "  samples avg       0.45      0.44      0.43      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 30.96750888824463\n",
      "Samples above threshold: 132\n",
      "Acquired samples: 200\n",
      "Sampling duration: 7.742291212081909 seconds\n",
      "\n",
      "Fold 1 - New train size: 9418\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 9418 samples\n",
      "Epoch 1/10, Train Loss: 0.3904, Accuracy: 0.8876, F1 Micro: 0.6146, F1 Macro: 0.2971\n",
      "Epoch 2/10, Train Loss: 0.2604, Accuracy: 0.9109, F1 Micro: 0.7274, F1 Macro: 0.5372\n",
      "Epoch 3/10, Train Loss: 0.2062, Accuracy: 0.9185, F1 Micro: 0.7587, F1 Macro: 0.5772\n",
      "Epoch 4/10, Train Loss: 0.1779, Accuracy: 0.924, F1 Micro: 0.7721, F1 Macro: 0.6203\n",
      "Epoch 5/10, Train Loss: 0.1473, Accuracy: 0.9259, F1 Micro: 0.7788, F1 Macro: 0.6311\n",
      "Epoch 6/10, Train Loss: 0.1236, Accuracy: 0.9238, F1 Micro: 0.7814, F1 Macro: 0.6505\n",
      "Epoch 7/10, Train Loss: 0.1031, Accuracy: 0.9258, F1 Micro: 0.7769, F1 Macro: 0.6637\n",
      "Epoch 8/10, Train Loss: 0.0884, Accuracy: 0.9237, F1 Micro: 0.7732, F1 Macro: 0.6917\n",
      "Epoch 9/10, Train Loss: 0.0734, Accuracy: 0.9267, F1 Micro: 0.7852, F1 Macro: 0.7101\n",
      "Epoch 10/10, Train Loss: 0.0654, Accuracy: 0.9231, F1 Micro: 0.7797, F1 Macro: 0.702\n",
      "Best result for 9418 samples: F1 Micro: 0.7852\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.86      0.86      1141\n",
      "      Abusive       0.89      0.91      0.90      1012\n",
      "HS_Individual       0.75      0.73      0.74       737\n",
      "     HS_Group       0.72      0.65      0.68       404\n",
      "  HS_Religion       0.78      0.63      0.70       164\n",
      "      HS_Race       0.78      0.75      0.76       119\n",
      "  HS_Physical       0.63      0.32      0.42        53\n",
      "    HS_Gender       0.72      0.40      0.51        58\n",
      "     HS_Other       0.84      0.78      0.80       779\n",
      "      HS_Weak       0.72      0.72      0.72       686\n",
      "  HS_Moderate       0.65      0.60      0.62       356\n",
      "    HS_Strong       0.82      0.78      0.80        99\n",
      "\n",
      "    micro avg       0.80      0.77      0.79      5608\n",
      "    macro avg       0.76      0.68      0.71      5608\n",
      " weighted avg       0.80      0.77      0.78      5608\n",
      "  samples avg       0.45      0.44      0.43      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 27.203808403015138\n",
      "Samples above threshold: 112\n",
      "Acquired samples: 200\n",
      "Sampling duration: 6.818356990814209 seconds\n",
      "\n",
      "Fold 1 - New train size: 9618\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 9618 samples\n",
      "Epoch 1/10, Train Loss: 0.3908, Accuracy: 0.889, F1 Micro: 0.633, F1 Macro: 0.3158\n",
      "Epoch 2/10, Train Loss: 0.2573, Accuracy: 0.9104, F1 Micro: 0.7156, F1 Macro: 0.5258\n",
      "Epoch 3/10, Train Loss: 0.2078, Accuracy: 0.9197, F1 Micro: 0.7544, F1 Macro: 0.5815\n",
      "Epoch 4/10, Train Loss: 0.1757, Accuracy: 0.9238, F1 Micro: 0.774, F1 Macro: 0.6013\n",
      "Epoch 5/10, Train Loss: 0.1446, Accuracy: 0.9265, F1 Micro: 0.7874, F1 Macro: 0.6623\n",
      "Epoch 6/10, Train Loss: 0.1236, Accuracy: 0.9234, F1 Micro: 0.7831, F1 Macro: 0.6535\n",
      "Epoch 7/10, Train Loss: 0.1049, Accuracy: 0.9221, F1 Micro: 0.7811, F1 Macro: 0.693\n",
      "Epoch 8/10, Train Loss: 0.0866, Accuracy: 0.9279, F1 Micro: 0.7783, F1 Macro: 0.6873\n",
      "Epoch 9/10, Train Loss: 0.0757, Accuracy: 0.9239, F1 Micro: 0.7822, F1 Macro: 0.7075\n",
      "Epoch 10/10, Train Loss: 0.0648, Accuracy: 0.9282, F1 Micro: 0.7854, F1 Macro: 0.6942\n",
      "Best result for 9618 samples: F1 Micro: 0.7874\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.89      0.86      1141\n",
      "      Abusive       0.87      0.90      0.89      1012\n",
      "HS_Individual       0.74      0.76      0.75       737\n",
      "     HS_Group       0.72      0.68      0.70       404\n",
      "  HS_Religion       0.74      0.62      0.67       164\n",
      "      HS_Race       0.79      0.73      0.76       119\n",
      "  HS_Physical       0.56      0.09      0.16        53\n",
      "    HS_Gender       0.78      0.12      0.21        58\n",
      "     HS_Other       0.81      0.82      0.82       779\n",
      "      HS_Weak       0.72      0.74      0.73       686\n",
      "  HS_Moderate       0.69      0.56      0.62       356\n",
      "    HS_Strong       0.77      0.78      0.77        99\n",
      "\n",
      "    micro avg       0.79      0.78      0.79      5608\n",
      "    macro avg       0.75      0.64      0.66      5608\n",
      " weighted avg       0.79      0.78      0.78      5608\n",
      "  samples avg       0.45      0.44      0.43      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 25.25724048614502\n",
      "Samples above threshold: 92\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.905766487121582 seconds\n",
      "\n",
      "Fold 1 - New train size: 9818\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 9818 samples\n",
      "Epoch 1/10, Train Loss: 0.3935, Accuracy: 0.8864, F1 Micro: 0.6087, F1 Macro: 0.298\n",
      "Epoch 2/10, Train Loss: 0.2553, Accuracy: 0.9109, F1 Micro: 0.7152, F1 Macro: 0.5267\n",
      "Epoch 3/10, Train Loss: 0.2111, Accuracy: 0.9171, F1 Micro: 0.7608, F1 Macro: 0.6037\n",
      "Epoch 4/10, Train Loss: 0.1694, Accuracy: 0.9214, F1 Micro: 0.7636, F1 Macro: 0.6021\n",
      "Epoch 5/10, Train Loss: 0.1433, Accuracy: 0.9229, F1 Micro: 0.773, F1 Macro: 0.6255\n",
      "Epoch 6/10, Train Loss: 0.1214, Accuracy: 0.9258, F1 Micro: 0.7793, F1 Macro: 0.6441\n",
      "Epoch 7/10, Train Loss: 0.104, Accuracy: 0.9237, F1 Micro: 0.783, F1 Macro: 0.6791\n",
      "Epoch 8/10, Train Loss: 0.0888, Accuracy: 0.9218, F1 Micro: 0.7815, F1 Macro: 0.686\n",
      "Epoch 9/10, Train Loss: 0.0764, Accuracy: 0.9266, F1 Micro: 0.7893, F1 Macro: 0.7057\n",
      "Epoch 10/10, Train Loss: 0.0639, Accuracy: 0.9267, F1 Micro: 0.7838, F1 Macro: 0.7095\n",
      "Best result for 9818 samples: F1 Micro: 0.7893\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.88      0.86      1141\n",
      "      Abusive       0.90      0.91      0.91      1012\n",
      "HS_Individual       0.74      0.76      0.75       737\n",
      "     HS_Group       0.70      0.67      0.68       404\n",
      "  HS_Religion       0.76      0.65      0.70       164\n",
      "      HS_Race       0.79      0.66      0.72       119\n",
      "  HS_Physical       0.75      0.23      0.35        53\n",
      "    HS_Gender       0.82      0.40      0.53        58\n",
      "     HS_Other       0.77      0.85      0.81       779\n",
      "      HS_Weak       0.72      0.74      0.73       686\n",
      "  HS_Moderate       0.65      0.62      0.63       356\n",
      "    HS_Strong       0.81      0.79      0.80        99\n",
      "\n",
      "    micro avg       0.79      0.79      0.79      5608\n",
      "    macro avg       0.77      0.68      0.71      5608\n",
      " weighted avg       0.79      0.79      0.79      5608\n",
      "  samples avg       0.45      0.45      0.44      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 28.966803932189944\n",
      "Samples above threshold: 72\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.96023416519165 seconds\n",
      "\n",
      "Fold 1 - New train size: 10018\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 10018 samples\n",
      "Epoch 1/10, Train Loss: 0.3847, Accuracy: 0.8879, F1 Micro: 0.6489, F1 Macro: 0.3352\n",
      "Epoch 2/10, Train Loss: 0.2574, Accuracy: 0.9121, F1 Micro: 0.7315, F1 Macro: 0.5294\n",
      "Epoch 3/10, Train Loss: 0.2071, Accuracy: 0.9161, F1 Micro: 0.7609, F1 Macro: 0.5821\n",
      "Epoch 4/10, Train Loss: 0.171, Accuracy: 0.9166, F1 Micro: 0.7703, F1 Macro: 0.6119\n",
      "Epoch 5/10, Train Loss: 0.1433, Accuracy: 0.9254, F1 Micro: 0.7802, F1 Macro: 0.6421\n",
      "Epoch 6/10, Train Loss: 0.1214, Accuracy: 0.9246, F1 Micro: 0.7829, F1 Macro: 0.6466\n",
      "Epoch 7/10, Train Loss: 0.1038, Accuracy: 0.9269, F1 Micro: 0.7787, F1 Macro: 0.6672\n",
      "Epoch 8/10, Train Loss: 0.0845, Accuracy: 0.9252, F1 Micro: 0.7783, F1 Macro: 0.6744\n",
      "Epoch 9/10, Train Loss: 0.0749, Accuracy: 0.926, F1 Micro: 0.7861, F1 Macro: 0.7011\n",
      "Epoch 10/10, Train Loss: 0.0653, Accuracy: 0.9255, F1 Micro: 0.7779, F1 Macro: 0.6908\n",
      "Best result for 10018 samples: F1 Micro: 0.7861\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.87      0.86      1141\n",
      "      Abusive       0.89      0.92      0.91      1012\n",
      "HS_Individual       0.72      0.77      0.75       737\n",
      "     HS_Group       0.73      0.61      0.67       404\n",
      "  HS_Religion       0.71      0.66      0.69       164\n",
      "      HS_Race       0.76      0.73      0.74       119\n",
      "  HS_Physical       0.64      0.26      0.37        53\n",
      "    HS_Gender       0.69      0.38      0.49        58\n",
      "     HS_Other       0.81      0.82      0.81       779\n",
      "      HS_Weak       0.70      0.75      0.72       686\n",
      "  HS_Moderate       0.66      0.55      0.60       356\n",
      "    HS_Strong       0.84      0.77      0.80        99\n",
      "\n",
      "    micro avg       0.79      0.78      0.79      5608\n",
      "    macro avg       0.75      0.67      0.70      5608\n",
      " weighted avg       0.79      0.78      0.78      5608\n",
      "  samples avg       0.45      0.45      0.43      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 26.144224166870117\n",
      "Samples above threshold: 52\n",
      "Acquired samples: 200\n",
      "Sampling duration: 3.818737745285034 seconds\n",
      "\n",
      "Fold 1 - New train size: 10218\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 10218 samples\n",
      "Epoch 1/10, Train Loss: 0.3822, Accuracy: 0.8862, F1 Micro: 0.5878, F1 Macro: 0.2928\n",
      "Epoch 2/10, Train Loss: 0.2546, Accuracy: 0.9113, F1 Micro: 0.7361, F1 Macro: 0.561\n",
      "Epoch 3/10, Train Loss: 0.2084, Accuracy: 0.9207, F1 Micro: 0.751, F1 Macro: 0.5846\n",
      "Epoch 4/10, Train Loss: 0.1756, Accuracy: 0.9247, F1 Micro: 0.7721, F1 Macro: 0.6032\n",
      "Epoch 5/10, Train Loss: 0.1477, Accuracy: 0.9209, F1 Micro: 0.7784, F1 Macro: 0.6426\n",
      "Epoch 6/10, Train Loss: 0.1223, Accuracy: 0.9261, F1 Micro: 0.7848, F1 Macro: 0.6419\n",
      "Epoch 7/10, Train Loss: 0.1018, Accuracy: 0.9218, F1 Micro: 0.7835, F1 Macro: 0.6789\n",
      "Epoch 8/10, Train Loss: 0.0893, Accuracy: 0.9273, F1 Micro: 0.7839, F1 Macro: 0.6722\n",
      "Epoch 9/10, Train Loss: 0.0734, Accuracy: 0.9269, F1 Micro: 0.784, F1 Macro: 0.69\n",
      "Epoch 10/10, Train Loss: 0.0656, Accuracy: 0.9265, F1 Micro: 0.7877, F1 Macro: 0.7082\n",
      "Best result for 10218 samples: F1 Micro: 0.7877\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.87      0.86      1141\n",
      "      Abusive       0.88      0.92      0.90      1012\n",
      "HS_Individual       0.73      0.76      0.75       737\n",
      "     HS_Group       0.72      0.64      0.68       404\n",
      "  HS_Religion       0.71      0.65      0.68       164\n",
      "      HS_Race       0.75      0.74      0.74       119\n",
      "  HS_Physical       0.62      0.30      0.41        53\n",
      "    HS_Gender       0.68      0.43      0.53        58\n",
      "     HS_Other       0.82      0.82      0.82       779\n",
      "      HS_Weak       0.71      0.75      0.73       686\n",
      "  HS_Moderate       0.67      0.56      0.61       356\n",
      "    HS_Strong       0.80      0.81      0.80        99\n",
      "\n",
      "    micro avg       0.79      0.78      0.79      5608\n",
      "    macro avg       0.74      0.69      0.71      5608\n",
      " weighted avg       0.79      0.78      0.78      5608\n",
      "  samples avg       0.45      0.45      0.44      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 30.633425903320312\n",
      "Samples above threshold: 32\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.6814470291137695 seconds\n",
      "\n",
      "Fold 1 - New train size: 10418\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 10418 samples\n",
      "Epoch 1/10, Train Loss: 0.3791, Accuracy: 0.8915, F1 Micro: 0.6436, F1 Macro: 0.3378\n",
      "Epoch 2/10, Train Loss: 0.2517, Accuracy: 0.9117, F1 Micro: 0.7307, F1 Macro: 0.5404\n",
      "Epoch 3/10, Train Loss: 0.202, Accuracy: 0.92, F1 Micro: 0.767, F1 Macro: 0.5895\n",
      "Epoch 4/10, Train Loss: 0.1689, Accuracy: 0.9237, F1 Micro: 0.7648, F1 Macro: 0.5812\n",
      "Epoch 5/10, Train Loss: 0.1426, Accuracy: 0.9267, F1 Micro: 0.7867, F1 Macro: 0.653\n",
      "Epoch 6/10, Train Loss: 0.1226, Accuracy: 0.9283, F1 Micro: 0.7747, F1 Macro: 0.6385\n",
      "Epoch 7/10, Train Loss: 0.1036, Accuracy: 0.9275, F1 Micro: 0.7861, F1 Macro: 0.6756\n",
      "Epoch 8/10, Train Loss: 0.0845, Accuracy: 0.9285, F1 Micro: 0.7932, F1 Macro: 0.6772\n",
      "Epoch 9/10, Train Loss: 0.0712, Accuracy: 0.9288, F1 Micro: 0.7872, F1 Macro: 0.6886\n",
      "Epoch 10/10, Train Loss: 0.0652, Accuracy: 0.9258, F1 Micro: 0.7854, F1 Macro: 0.7078\n",
      "Best result for 10418 samples: F1 Micro: 0.7932\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.87      0.86      1141\n",
      "      Abusive       0.91      0.90      0.90      1012\n",
      "HS_Individual       0.75      0.79      0.77       737\n",
      "     HS_Group       0.74      0.65      0.69       404\n",
      "  HS_Religion       0.76      0.61      0.68       164\n",
      "      HS_Race       0.82      0.73      0.77       119\n",
      "  HS_Physical       0.44      0.08      0.13        53\n",
      "    HS_Gender       0.87      0.22      0.36        58\n",
      "     HS_Other       0.78      0.86      0.82       779\n",
      "      HS_Weak       0.72      0.76      0.74       686\n",
      "  HS_Moderate       0.67      0.58      0.62       356\n",
      "    HS_Strong       0.84      0.74      0.78        99\n",
      "\n",
      "    micro avg       0.80      0.79      0.79      5608\n",
      "    macro avg       0.76      0.65      0.68      5608\n",
      " weighted avg       0.79      0.79      0.79      5608\n",
      "  samples avg       0.45      0.45      0.43      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 28.032498359680176\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 117\n",
      "Sampling duration: 2.0092244148254395 seconds\n",
      "\n",
      "Fold 1 - New train size: 10535\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 10535 samples\n",
      "Epoch 1/10, Train Loss: 0.3864, Accuracy: 0.8887, F1 Micro: 0.6154, F1 Macro: 0.3102\n",
      "Epoch 2/10, Train Loss: 0.2587, Accuracy: 0.9103, F1 Micro: 0.7279, F1 Macro: 0.4988\n",
      "Epoch 3/10, Train Loss: 0.2073, Accuracy: 0.9212, F1 Micro: 0.7683, F1 Macro: 0.6069\n",
      "Epoch 4/10, Train Loss: 0.1716, Accuracy: 0.9254, F1 Micro: 0.7733, F1 Macro: 0.6221\n",
      "Epoch 5/10, Train Loss: 0.1475, Accuracy: 0.9275, F1 Micro: 0.7821, F1 Macro: 0.6394\n",
      "Epoch 6/10, Train Loss: 0.1218, Accuracy: 0.9275, F1 Micro: 0.7881, F1 Macro: 0.6736\n",
      "Epoch 7/10, Train Loss: 0.1056, Accuracy: 0.9289, F1 Micro: 0.7905, F1 Macro: 0.6606\n",
      "Epoch 8/10, Train Loss: 0.0873, Accuracy: 0.9261, F1 Micro: 0.788, F1 Macro: 0.7017\n",
      "Epoch 9/10, Train Loss: 0.0745, Accuracy: 0.9253, F1 Micro: 0.7835, F1 Macro: 0.6985\n",
      "Epoch 10/10, Train Loss: 0.0646, Accuracy: 0.9285, F1 Micro: 0.7892, F1 Macro: 0.7071\n",
      "Best result for 10535 samples: F1 Micro: 0.7905\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.86      0.86      1141\n",
      "      Abusive       0.91      0.89      0.90      1012\n",
      "HS_Individual       0.76      0.77      0.77       737\n",
      "     HS_Group       0.74      0.64      0.69       404\n",
      "  HS_Religion       0.75      0.57      0.65       164\n",
      "      HS_Race       0.83      0.66      0.73       119\n",
      "  HS_Physical       0.50      0.08      0.13        53\n",
      "    HS_Gender       0.75      0.16      0.26        58\n",
      "     HS_Other       0.81      0.82      0.82       779\n",
      "      HS_Weak       0.73      0.75      0.74       686\n",
      "  HS_Moderate       0.69      0.56      0.62       356\n",
      "    HS_Strong       0.80      0.73      0.76        99\n",
      "\n",
      "    micro avg       0.81      0.77      0.79      5608\n",
      "    macro avg       0.76      0.62      0.66      5608\n",
      " weighted avg       0.81      0.77      0.78      5608\n",
      "  samples avg       0.45      0.44      0.43      5608\n",
      "\n",
      "\n",
      "FOLD 1 COMPLETED in 5682.06 seconds\n",
      "===============================================\n",
      "STARTING FOLD 2/5\n",
      "===============================================\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 658 samples\n",
      "Epoch 1/10, Train Loss: 0.6071, Accuracy: 0.8373, F1 Micro: 0.2811, F1 Macro: 0.0967\n",
      "Epoch 2/10, Train Loss: 0.4721, Accuracy: 0.8453, F1 Micro: 0.2409, F1 Macro: 0.0795\n",
      "Epoch 3/10, Train Loss: 0.4136, Accuracy: 0.8385, F1 Micro: 0.1122, F1 Macro: 0.0411\n",
      "Epoch 4/10, Train Loss: 0.3858, Accuracy: 0.8491, F1 Micro: 0.2595, F1 Macro: 0.0869\n",
      "Epoch 5/10, Train Loss: 0.3744, Accuracy: 0.8514, F1 Micro: 0.2787, F1 Macro: 0.092\n",
      "Epoch 6/10, Train Loss: 0.3634, Accuracy: 0.8587, F1 Micro: 0.3797, F1 Macro: 0.1286\n",
      "Epoch 7/10, Train Loss: 0.3489, Accuracy: 0.8708, F1 Micro: 0.5093, F1 Macro: 0.2237\n",
      "Epoch 8/10, Train Loss: 0.3042, Accuracy: 0.8762, F1 Micro: 0.5769, F1 Macro: 0.2684\n",
      "Epoch 9/10, Train Loss: 0.2947, Accuracy: 0.8795, F1 Micro: 0.581, F1 Macro: 0.2943\n",
      "Epoch 10/10, Train Loss: 0.2572, Accuracy: 0.8806, F1 Micro: 0.6047, F1 Macro: 0.3163\n",
      "Best result for 658 samples: F1 Micro: 0.6047\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.75      0.76      0.75      1094\n",
      "      Abusive       0.80      0.73      0.76      1072\n",
      "HS_Individual       0.60      0.57      0.59       689\n",
      "     HS_Group       0.65      0.28      0.40       405\n",
      "  HS_Religion       0.00      0.00      0.00       124\n",
      "      HS_Race       0.00      0.00      0.00       125\n",
      "  HS_Physical       0.00      0.00      0.00        61\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.64      0.59      0.62       754\n",
      "      HS_Weak       0.58      0.53      0.56       664\n",
      "  HS_Moderate       0.50      0.07      0.12       346\n",
      "    HS_Strong       0.00      0.00      0.00        84\n",
      "\n",
      "    micro avg       0.69      0.54      0.60      5476\n",
      "    macro avg       0.38      0.29      0.32      5476\n",
      " weighted avg       0.62      0.54      0.56      5476\n",
      "  samples avg       0.37      0.32      0.31      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 28.0652099609375\n",
      "Samples above threshold: 988\n",
      "Acquired samples: 988\n",
      "Sampling duration: 50.61183571815491 seconds\n",
      "\n",
      "Fold 2 - New train size: 1646\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 1646 samples\n",
      "Epoch 1/10, Train Loss: 0.499, Accuracy: 0.8302, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.3313, Accuracy: 0.8302, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.3032, Accuracy: 0.8438, F1 Micro: 0.1725, F1 Macro: 0.0627\n",
      "Epoch 4/10, Train Loss: 0.2738, Accuracy: 0.8602, F1 Micro: 0.3508, F1 Macro: 0.1307\n",
      "Epoch 5/10, Train Loss: 0.2299, Accuracy: 0.8754, F1 Micro: 0.5646, F1 Macro: 0.3018\n",
      "Epoch 6/10, Train Loss: 0.2058, Accuracy: 0.8788, F1 Micro: 0.6286, F1 Macro: 0.4124\n",
      "Epoch 7/10, Train Loss: 0.1798, Accuracy: 0.8824, F1 Micro: 0.5961, F1 Macro: 0.3759\n",
      "Epoch 8/10, Train Loss: 0.1633, Accuracy: 0.8844, F1 Micro: 0.6189, F1 Macro: 0.3921\n",
      "Epoch 9/10, Train Loss: 0.1398, Accuracy: 0.8848, F1 Micro: 0.6464, F1 Macro: 0.429\n",
      "Epoch 10/10, Train Loss: 0.1248, Accuracy: 0.8883, F1 Micro: 0.6247, F1 Macro: 0.4203\n",
      "Best result for 1646 samples: F1 Micro: 0.6464\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.73      0.82      0.77      1094\n",
      "      Abusive       0.82      0.79      0.80      1072\n",
      "HS_Individual       0.57      0.65      0.61       689\n",
      "     HS_Group       0.70      0.37      0.49       405\n",
      "  HS_Religion       0.84      0.13      0.22       124\n",
      "      HS_Race       0.85      0.35      0.50       125\n",
      "  HS_Physical       0.00      0.00      0.00        61\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.62      0.68      0.65       754\n",
      "      HS_Weak       0.55      0.62      0.58       664\n",
      "  HS_Moderate       0.49      0.15      0.23       346\n",
      "    HS_Strong       0.83      0.18      0.29        84\n",
      "\n",
      "    micro avg       0.67      0.62      0.65      5476\n",
      "    macro avg       0.58      0.40      0.43      5476\n",
      " weighted avg       0.66      0.62      0.62      5476\n",
      "  samples avg       0.40      0.37      0.35      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 37.89996795654297\n",
      "Samples above threshold: 889\n",
      "Acquired samples: 889\n",
      "Sampling duration: 44.51175045967102 seconds\n",
      "\n",
      "Fold 2 - New train size: 2535\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 2535 samples\n",
      "Epoch 1/10, Train Loss: 0.4836, Accuracy: 0.8447, F1 Micro: 0.4455, F1 Macro: 0.1568\n",
      "Epoch 2/10, Train Loss: 0.3394, Accuracy: 0.8602, F1 Micro: 0.4876, F1 Macro: 0.218\n",
      "Epoch 3/10, Train Loss: 0.2861, Accuracy: 0.8752, F1 Micro: 0.5609, F1 Macro: 0.2682\n",
      "Epoch 4/10, Train Loss: 0.2584, Accuracy: 0.8814, F1 Micro: 0.5955, F1 Macro: 0.331\n",
      "Epoch 5/10, Train Loss: 0.2262, Accuracy: 0.8846, F1 Micro: 0.6415, F1 Macro: 0.3856\n",
      "Epoch 6/10, Train Loss: 0.2075, Accuracy: 0.8937, F1 Micro: 0.6642, F1 Macro: 0.4456\n",
      "Epoch 7/10, Train Loss: 0.1891, Accuracy: 0.8955, F1 Micro: 0.6682, F1 Macro: 0.4551\n",
      "Epoch 8/10, Train Loss: 0.1603, Accuracy: 0.898, F1 Micro: 0.6705, F1 Macro: 0.4538\n",
      "Epoch 9/10, Train Loss: 0.1366, Accuracy: 0.9005, F1 Micro: 0.6816, F1 Macro: 0.5094\n",
      "Epoch 10/10, Train Loss: 0.1246, Accuracy: 0.8982, F1 Micro: 0.685, F1 Macro: 0.5286\n",
      "Best result for 2535 samples: F1 Micro: 0.685\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.77      0.78      0.77      1094\n",
      "      Abusive       0.84      0.81      0.82      1072\n",
      "HS_Individual       0.72      0.55      0.62       689\n",
      "     HS_Group       0.58      0.69      0.63       405\n",
      "  HS_Religion       0.77      0.35      0.49       124\n",
      "      HS_Race       0.88      0.39      0.54       125\n",
      "  HS_Physical       0.60      0.05      0.09        61\n",
      "    HS_Gender       0.75      0.05      0.10        58\n",
      "     HS_Other       0.69      0.70      0.69       754\n",
      "      HS_Weak       0.69      0.52      0.60       664\n",
      "  HS_Moderate       0.51      0.58      0.54       346\n",
      "    HS_Strong       0.89      0.30      0.45        84\n",
      "\n",
      "    micro avg       0.72      0.65      0.68      5476\n",
      "    macro avg       0.72      0.48      0.53      5476\n",
      " weighted avg       0.73      0.65      0.67      5476\n",
      "  samples avg       0.40      0.37      0.36      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 36.2357292175293\n",
      "Samples above threshold: 801\n",
      "Acquired samples: 801\n",
      "Sampling duration: 41.14045190811157 seconds\n",
      "\n",
      "Fold 2 - New train size: 3336\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 3336 samples\n",
      "Epoch 1/10, Train Loss: 0.4748, Accuracy: 0.8516, F1 Micro: 0.4564, F1 Macro: 0.1789\n",
      "Epoch 2/10, Train Loss: 0.3282, Accuracy: 0.8761, F1 Micro: 0.5752, F1 Macro: 0.3225\n",
      "Epoch 3/10, Train Loss: 0.273, Accuracy: 0.8813, F1 Micro: 0.627, F1 Macro: 0.4398\n",
      "Epoch 4/10, Train Loss: 0.2348, Accuracy: 0.8933, F1 Micro: 0.6351, F1 Macro: 0.4672\n",
      "Epoch 5/10, Train Loss: 0.2029, Accuracy: 0.9019, F1 Micro: 0.6697, F1 Macro: 0.5006\n",
      "Epoch 6/10, Train Loss: 0.179, Accuracy: 0.9035, F1 Micro: 0.7047, F1 Macro: 0.5536\n",
      "Epoch 7/10, Train Loss: 0.151, Accuracy: 0.9072, F1 Micro: 0.7057, F1 Macro: 0.55\n",
      "Epoch 8/10, Train Loss: 0.1296, Accuracy: 0.906, F1 Micro: 0.7104, F1 Macro: 0.5501\n",
      "Epoch 9/10, Train Loss: 0.1144, Accuracy: 0.9066, F1 Micro: 0.7157, F1 Macro: 0.5772\n",
      "Epoch 10/10, Train Loss: 0.0976, Accuracy: 0.908, F1 Micro: 0.722, F1 Macro: 0.5688\n",
      "Best result for 3336 samples: F1 Micro: 0.722\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.79      0.80      0.79      1094\n",
      "      Abusive       0.84      0.90      0.87      1072\n",
      "HS_Individual       0.67      0.68      0.67       689\n",
      "     HS_Group       0.71      0.56      0.63       405\n",
      "  HS_Religion       0.74      0.47      0.57       124\n",
      "      HS_Race       0.87      0.57      0.69       125\n",
      "  HS_Physical       0.33      0.02      0.03        61\n",
      "    HS_Gender       0.33      0.02      0.03        58\n",
      "     HS_Other       0.71      0.72      0.71       754\n",
      "      HS_Weak       0.64      0.66      0.65       664\n",
      "  HS_Moderate       0.63      0.47      0.54       346\n",
      "    HS_Strong       0.78      0.54      0.63        84\n",
      "\n",
      "    micro avg       0.74      0.70      0.72      5476\n",
      "    macro avg       0.67      0.53      0.57      5476\n",
      " weighted avg       0.73      0.70      0.71      5476\n",
      "  samples avg       0.43      0.41      0.40      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 37.47336616516113\n",
      "Samples above threshold: 720\n",
      "Acquired samples: 720\n",
      "Sampling duration: 37.25039005279541 seconds\n",
      "\n",
      "Fold 2 - New train size: 4056\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 4056 samples\n",
      "Epoch 1/10, Train Loss: 0.462, Accuracy: 0.8548, F1 Micro: 0.444, F1 Macro: 0.1886\n",
      "Epoch 2/10, Train Loss: 0.3194, Accuracy: 0.8856, F1 Micro: 0.6203, F1 Macro: 0.3494\n",
      "Epoch 3/10, Train Loss: 0.2581, Accuracy: 0.8948, F1 Micro: 0.6799, F1 Macro: 0.4581\n",
      "Epoch 4/10, Train Loss: 0.2223, Accuracy: 0.9001, F1 Micro: 0.7006, F1 Macro: 0.5137\n",
      "Epoch 5/10, Train Loss: 0.1917, Accuracy: 0.9063, F1 Micro: 0.7157, F1 Macro: 0.5668\n",
      "Epoch 6/10, Train Loss: 0.1676, Accuracy: 0.9093, F1 Micro: 0.722, F1 Macro: 0.5714\n",
      "Epoch 7/10, Train Loss: 0.1395, Accuracy: 0.9084, F1 Micro: 0.7048, F1 Macro: 0.5602\n",
      "Epoch 8/10, Train Loss: 0.1219, Accuracy: 0.9084, F1 Micro: 0.7325, F1 Macro: 0.5914\n",
      "Epoch 9/10, Train Loss: 0.105, Accuracy: 0.9114, F1 Micro: 0.7219, F1 Macro: 0.6021\n",
      "Epoch 10/10, Train Loss: 0.0936, Accuracy: 0.9093, F1 Micro: 0.7286, F1 Macro: 0.6203\n",
      "Best result for 4056 samples: F1 Micro: 0.7325\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.77      0.86      0.81      1094\n",
      "      Abusive       0.89      0.86      0.87      1072\n",
      "HS_Individual       0.63      0.76      0.69       689\n",
      "     HS_Group       0.71      0.55      0.62       405\n",
      "  HS_Religion       0.68      0.56      0.61       124\n",
      "      HS_Race       0.84      0.62      0.72       125\n",
      "  HS_Physical       0.67      0.03      0.06        61\n",
      "    HS_Gender       1.00      0.02      0.03        58\n",
      "     HS_Other       0.69      0.78      0.73       754\n",
      "      HS_Weak       0.62      0.74      0.67       664\n",
      "  HS_Moderate       0.62      0.42      0.51       346\n",
      "    HS_Strong       0.80      0.75      0.77        84\n",
      "\n",
      "    micro avg       0.73      0.74      0.73      5476\n",
      "    macro avg       0.74      0.58      0.59      5476\n",
      " weighted avg       0.73      0.74      0.72      5476\n",
      "  samples avg       0.42      0.42      0.40      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 32.93168907165528\n",
      "Samples above threshold: 648\n",
      "Acquired samples: 648\n",
      "Sampling duration: 33.15288019180298 seconds\n",
      "\n",
      "Fold 2 - New train size: 4704\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 4704 samples\n",
      "Epoch 1/10, Train Loss: 0.4581, Accuracy: 0.8562, F1 Micro: 0.525, F1 Macro: 0.2328\n",
      "Epoch 2/10, Train Loss: 0.3276, Accuracy: 0.8914, F1 Micro: 0.6569, F1 Macro: 0.4135\n",
      "Epoch 3/10, Train Loss: 0.2595, Accuracy: 0.9012, F1 Micro: 0.6802, F1 Macro: 0.4967\n",
      "Epoch 4/10, Train Loss: 0.2189, Accuracy: 0.9064, F1 Micro: 0.7086, F1 Macro: 0.5586\n",
      "Epoch 5/10, Train Loss: 0.1899, Accuracy: 0.9082, F1 Micro: 0.7245, F1 Macro: 0.5777\n",
      "Epoch 6/10, Train Loss: 0.1617, Accuracy: 0.912, F1 Micro: 0.7227, F1 Macro: 0.5833\n",
      "Epoch 7/10, Train Loss: 0.1411, Accuracy: 0.9131, F1 Micro: 0.7247, F1 Macro: 0.5952\n",
      "Epoch 8/10, Train Loss: 0.1192, Accuracy: 0.9097, F1 Micro: 0.7379, F1 Macro: 0.6187\n",
      "Epoch 9/10, Train Loss: 0.1026, Accuracy: 0.9131, F1 Micro: 0.7355, F1 Macro: 0.6294\n",
      "Epoch 10/10, Train Loss: 0.0895, Accuracy: 0.9128, F1 Micro: 0.7418, F1 Macro: 0.639\n",
      "Best result for 4704 samples: F1 Micro: 0.7418\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.79      0.84      0.82      1094\n",
      "      Abusive       0.86      0.89      0.88      1072\n",
      "HS_Individual       0.64      0.76      0.69       689\n",
      "     HS_Group       0.76      0.54      0.63       405\n",
      "  HS_Religion       0.74      0.56      0.64       124\n",
      "      HS_Race       0.80      0.66      0.72       125\n",
      "  HS_Physical       0.41      0.15      0.22        61\n",
      "    HS_Gender       0.59      0.22      0.32        58\n",
      "     HS_Other       0.75      0.71      0.73       754\n",
      "      HS_Weak       0.64      0.75      0.69       664\n",
      "  HS_Moderate       0.68      0.43      0.53       346\n",
      "    HS_Strong       0.81      0.79      0.80        84\n",
      "\n",
      "    micro avg       0.75      0.74      0.74      5476\n",
      "    macro avg       0.71      0.61      0.64      5476\n",
      " weighted avg       0.75      0.74      0.73      5476\n",
      "  samples avg       0.44      0.43      0.41      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 35.42935638427734\n",
      "Samples above threshold: 584\n",
      "Acquired samples: 584\n",
      "Sampling duration: 30.094581604003906 seconds\n",
      "\n",
      "Fold 2 - New train size: 5288\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 5288 samples\n",
      "Epoch 1/10, Train Loss: 0.437, Accuracy: 0.8699, F1 Micro: 0.5238, F1 Macro: 0.234\n",
      "Epoch 2/10, Train Loss: 0.2978, Accuracy: 0.8888, F1 Micro: 0.666, F1 Macro: 0.413\n",
      "Epoch 3/10, Train Loss: 0.2431, Accuracy: 0.8991, F1 Micro: 0.7072, F1 Macro: 0.5398\n",
      "Epoch 4/10, Train Loss: 0.1967, Accuracy: 0.9095, F1 Micro: 0.7178, F1 Macro: 0.5666\n",
      "Epoch 5/10, Train Loss: 0.1703, Accuracy: 0.9049, F1 Micro: 0.7337, F1 Macro: 0.6041\n",
      "Epoch 6/10, Train Loss: 0.1458, Accuracy: 0.9127, F1 Micro: 0.7352, F1 Macro: 0.6175\n",
      "Epoch 7/10, Train Loss: 0.1262, Accuracy: 0.913, F1 Micro: 0.7338, F1 Macro: 0.6268\n",
      "Epoch 8/10, Train Loss: 0.1044, Accuracy: 0.9109, F1 Micro: 0.743, F1 Macro: 0.6314\n",
      "Epoch 9/10, Train Loss: 0.0916, Accuracy: 0.9121, F1 Micro: 0.7423, F1 Macro: 0.6397\n",
      "Epoch 10/10, Train Loss: 0.0829, Accuracy: 0.9105, F1 Micro: 0.7425, F1 Macro: 0.6315\n",
      "Best result for 5288 samples: F1 Micro: 0.743\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.76      0.88      0.81      1094\n",
      "      Abusive       0.88      0.86      0.87      1072\n",
      "HS_Individual       0.65      0.76      0.70       689\n",
      "     HS_Group       0.69      0.62      0.66       405\n",
      "  HS_Religion       0.70      0.56      0.62       124\n",
      "      HS_Race       0.80      0.64      0.71       125\n",
      "  HS_Physical       0.50      0.13      0.21        61\n",
      "    HS_Gender       0.53      0.16      0.24        58\n",
      "     HS_Other       0.70      0.78      0.74       754\n",
      "      HS_Weak       0.63      0.73      0.68       664\n",
      "  HS_Moderate       0.65      0.53      0.59       346\n",
      "    HS_Strong       0.74      0.76      0.75        84\n",
      "\n",
      "    micro avg       0.73      0.76      0.74      5476\n",
      "    macro avg       0.69      0.62      0.63      5476\n",
      " weighted avg       0.73      0.76      0.74      5476\n",
      "  samples avg       0.43      0.43      0.41      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 36.40915565490723\n",
      "Samples above threshold: 525\n",
      "Acquired samples: 525\n",
      "Sampling duration: 26.98395013809204 seconds\n",
      "\n",
      "Fold 2 - New train size: 5813\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 5813 samples\n",
      "Epoch 1/10, Train Loss: 0.4262, Accuracy: 0.8715, F1 Micro: 0.5847, F1 Macro: 0.2719\n",
      "Epoch 2/10, Train Loss: 0.2945, Accuracy: 0.8961, F1 Micro: 0.6787, F1 Macro: 0.4694\n",
      "Epoch 3/10, Train Loss: 0.2337, Accuracy: 0.9073, F1 Micro: 0.7051, F1 Macro: 0.5101\n",
      "Epoch 4/10, Train Loss: 0.196, Accuracy: 0.911, F1 Micro: 0.7313, F1 Macro: 0.5758\n",
      "Epoch 5/10, Train Loss: 0.1621, Accuracy: 0.9144, F1 Micro: 0.7352, F1 Macro: 0.5963\n",
      "Epoch 6/10, Train Loss: 0.1391, Accuracy: 0.9123, F1 Micro: 0.7486, F1 Macro: 0.6225\n",
      "Epoch 7/10, Train Loss: 0.1232, Accuracy: 0.9164, F1 Micro: 0.7515, F1 Macro: 0.6279\n",
      "Epoch 8/10, Train Loss: 0.1021, Accuracy: 0.9148, F1 Micro: 0.7458, F1 Macro: 0.644\n",
      "Epoch 9/10, Train Loss: 0.0904, Accuracy: 0.9138, F1 Micro: 0.742, F1 Macro: 0.6303\n",
      "Epoch 10/10, Train Loss: 0.0778, Accuracy: 0.9142, F1 Micro: 0.7496, F1 Macro: 0.6527\n",
      "Best result for 5813 samples: F1 Micro: 0.7515\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.86      0.83      1094\n",
      "      Abusive       0.88      0.89      0.88      1072\n",
      "HS_Individual       0.68      0.74      0.71       689\n",
      "     HS_Group       0.72      0.59      0.65       405\n",
      "  HS_Religion       0.74      0.49      0.59       124\n",
      "      HS_Race       0.81      0.61      0.69       125\n",
      "  HS_Physical       0.80      0.13      0.23        61\n",
      "    HS_Gender       0.58      0.12      0.20        58\n",
      "     HS_Other       0.72      0.77      0.75       754\n",
      "      HS_Weak       0.68      0.71      0.70       664\n",
      "  HS_Moderate       0.65      0.48      0.56       346\n",
      "    HS_Strong       0.78      0.74      0.76        84\n",
      "\n",
      "    micro avg       0.76      0.74      0.75      5476\n",
      "    macro avg       0.74      0.59      0.63      5476\n",
      " weighted avg       0.76      0.74      0.74      5476\n",
      "  samples avg       0.44      0.43      0.42      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 33.94530029296875\n",
      "Samples above threshold: 473\n",
      "Acquired samples: 473\n",
      "Sampling duration: 24.296761751174927 seconds\n",
      "\n",
      "Fold 2 - New train size: 6286\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 6286 samples\n",
      "Epoch 1/10, Train Loss: 0.431, Accuracy: 0.8781, F1 Micro: 0.5531, F1 Macro: 0.2636\n",
      "Epoch 2/10, Train Loss: 0.2919, Accuracy: 0.9003, F1 Micro: 0.6693, F1 Macro: 0.4776\n",
      "Epoch 3/10, Train Loss: 0.2313, Accuracy: 0.9091, F1 Micro: 0.7233, F1 Macro: 0.5602\n",
      "Epoch 4/10, Train Loss: 0.1972, Accuracy: 0.9092, F1 Micro: 0.7437, F1 Macro: 0.611\n",
      "Epoch 5/10, Train Loss: 0.163, Accuracy: 0.9186, F1 Micro: 0.7487, F1 Macro: 0.6275\n",
      "Epoch 6/10, Train Loss: 0.1381, Accuracy: 0.9182, F1 Micro: 0.7617, F1 Macro: 0.6478\n",
      "Epoch 7/10, Train Loss: 0.116, Accuracy: 0.9169, F1 Micro: 0.7531, F1 Macro: 0.642\n",
      "Epoch 8/10, Train Loss: 0.0964, Accuracy: 0.9189, F1 Micro: 0.7592, F1 Macro: 0.6661\n",
      "Epoch 9/10, Train Loss: 0.0861, Accuracy: 0.9156, F1 Micro: 0.7597, F1 Macro: 0.6727\n",
      "Epoch 10/10, Train Loss: 0.0777, Accuracy: 0.9155, F1 Micro: 0.7474, F1 Macro: 0.6534\n",
      "Best result for 6286 samples: F1 Micro: 0.7617\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.79      0.88      0.83      1094\n",
      "      Abusive       0.86      0.90      0.88      1072\n",
      "HS_Individual       0.67      0.77      0.72       689\n",
      "     HS_Group       0.75      0.60      0.67       405\n",
      "  HS_Religion       0.70      0.65      0.67       124\n",
      "      HS_Race       0.85      0.72      0.78       125\n",
      "  HS_Physical       0.62      0.13      0.22        61\n",
      "    HS_Gender       0.50      0.12      0.19        58\n",
      "     HS_Other       0.74      0.78      0.76       754\n",
      "      HS_Weak       0.66      0.75      0.70       664\n",
      "  HS_Moderate       0.68      0.50      0.58       346\n",
      "    HS_Strong       0.77      0.77      0.77        84\n",
      "\n",
      "    micro avg       0.75      0.77      0.76      5476\n",
      "    macro avg       0.72      0.63      0.65      5476\n",
      " weighted avg       0.75      0.77      0.75      5476\n",
      "  samples avg       0.45      0.44      0.43      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 32.570542907714845\n",
      "Samples above threshold: 425\n",
      "Acquired samples: 298\n",
      "Sampling duration: 22.30807590484619 seconds\n",
      "\n",
      "Fold 2 - New train size: 6584\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 6584 samples\n",
      "Epoch 1/10, Train Loss: 0.4243, Accuracy: 0.8814, F1 Micro: 0.5846, F1 Macro: 0.2882\n",
      "Epoch 2/10, Train Loss: 0.2869, Accuracy: 0.9018, F1 Micro: 0.6812, F1 Macro: 0.4878\n",
      "Epoch 3/10, Train Loss: 0.2332, Accuracy: 0.9114, F1 Micro: 0.72, F1 Macro: 0.5392\n",
      "Epoch 4/10, Train Loss: 0.1946, Accuracy: 0.9163, F1 Micro: 0.7509, F1 Macro: 0.6051\n",
      "Epoch 5/10, Train Loss: 0.1597, Accuracy: 0.9181, F1 Micro: 0.7506, F1 Macro: 0.6076\n",
      "Epoch 6/10, Train Loss: 0.1377, Accuracy: 0.919, F1 Micro: 0.7485, F1 Macro: 0.6216\n",
      "Epoch 7/10, Train Loss: 0.1178, Accuracy: 0.9185, F1 Micro: 0.7609, F1 Macro: 0.6531\n",
      "Epoch 8/10, Train Loss: 0.1033, Accuracy: 0.9183, F1 Micro: 0.7495, F1 Macro: 0.6499\n",
      "Epoch 9/10, Train Loss: 0.0887, Accuracy: 0.9197, F1 Micro: 0.7582, F1 Macro: 0.6704\n",
      "Epoch 10/10, Train Loss: 0.0767, Accuracy: 0.92, F1 Micro: 0.7567, F1 Macro: 0.6686\n",
      "Best result for 6584 samples: F1 Micro: 0.7609\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.86      0.83      1094\n",
      "      Abusive       0.89      0.88      0.88      1072\n",
      "HS_Individual       0.66      0.78      0.72       689\n",
      "     HS_Group       0.77      0.60      0.67       405\n",
      "  HS_Religion       0.70      0.64      0.67       124\n",
      "      HS_Race       0.83      0.65      0.73       125\n",
      "  HS_Physical       0.40      0.13      0.20        61\n",
      "    HS_Gender       0.57      0.21      0.30        58\n",
      "     HS_Other       0.74      0.79      0.76       754\n",
      "      HS_Weak       0.66      0.76      0.71       664\n",
      "  HS_Moderate       0.71      0.51      0.59       346\n",
      "    HS_Strong       0.79      0.77      0.78        84\n",
      "\n",
      "    micro avg       0.76      0.76      0.76      5476\n",
      "    macro avg       0.71      0.63      0.65      5476\n",
      " weighted avg       0.76      0.76      0.76      5476\n",
      "  samples avg       0.44      0.43      0.42      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 34.13092384338379\n",
      "Samples above threshold: 396\n",
      "Acquired samples: 396\n",
      "Sampling duration: 20.991376876831055 seconds\n",
      "\n",
      "Fold 2 - New train size: 6980\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 6980 samples\n",
      "Epoch 1/10, Train Loss: 0.4182, Accuracy: 0.883, F1 Micro: 0.5959, F1 Macro: 0.2931\n",
      "Epoch 2/10, Train Loss: 0.2787, Accuracy: 0.903, F1 Micro: 0.6796, F1 Macro: 0.4965\n",
      "Epoch 3/10, Train Loss: 0.2258, Accuracy: 0.9067, F1 Micro: 0.7267, F1 Macro: 0.5257\n",
      "Epoch 4/10, Train Loss: 0.1894, Accuracy: 0.9153, F1 Micro: 0.7322, F1 Macro: 0.5834\n",
      "Epoch 5/10, Train Loss: 0.1612, Accuracy: 0.9192, F1 Micro: 0.7562, F1 Macro: 0.6389\n",
      "Epoch 6/10, Train Loss: 0.1322, Accuracy: 0.9179, F1 Micro: 0.736, F1 Macro: 0.6255\n",
      "Epoch 7/10, Train Loss: 0.1154, Accuracy: 0.919, F1 Micro: 0.7537, F1 Macro: 0.6526\n",
      "Epoch 8/10, Train Loss: 0.0948, Accuracy: 0.9193, F1 Micro: 0.7566, F1 Macro: 0.6583\n",
      "Epoch 9/10, Train Loss: 0.0835, Accuracy: 0.9189, F1 Micro: 0.7521, F1 Macro: 0.6615\n",
      "Epoch 10/10, Train Loss: 0.0753, Accuracy: 0.9176, F1 Micro: 0.7299, F1 Macro: 0.6561\n",
      "Best result for 6980 samples: F1 Micro: 0.7566\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.82      0.82      1094\n",
      "      Abusive       0.88      0.90      0.89      1072\n",
      "HS_Individual       0.68      0.74      0.71       689\n",
      "     HS_Group       0.78      0.56      0.65       405\n",
      "  HS_Religion       0.75      0.63      0.68       124\n",
      "      HS_Race       0.82      0.67      0.74       125\n",
      "  HS_Physical       0.57      0.13      0.21        61\n",
      "    HS_Gender       0.64      0.28      0.39        58\n",
      "     HS_Other       0.78      0.73      0.76       754\n",
      "      HS_Weak       0.67      0.73      0.70       664\n",
      "  HS_Moderate       0.70      0.48      0.57       346\n",
      "    HS_Strong       0.82      0.76      0.79        84\n",
      "\n",
      "    micro avg       0.78      0.74      0.76      5476\n",
      "    macro avg       0.74      0.62      0.66      5476\n",
      " weighted avg       0.77      0.74      0.75      5476\n",
      "  samples avg       0.44      0.43      0.41      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 35.72723579406738\n",
      "Samples above threshold: 356\n",
      "Acquired samples: 356\n",
      "Sampling duration: 18.811715602874756 seconds\n",
      "\n",
      "Fold 2 - New train size: 7336\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 7336 samples\n",
      "Epoch 1/10, Train Loss: 0.4129, Accuracy: 0.8838, F1 Micro: 0.5784, F1 Macro: 0.2859\n",
      "Epoch 2/10, Train Loss: 0.2758, Accuracy: 0.9007, F1 Micro: 0.7019, F1 Macro: 0.5185\n",
      "Epoch 3/10, Train Loss: 0.222, Accuracy: 0.9125, F1 Micro: 0.7299, F1 Macro: 0.5612\n",
      "Epoch 4/10, Train Loss: 0.1812, Accuracy: 0.9178, F1 Micro: 0.7409, F1 Macro: 0.6076\n",
      "Epoch 5/10, Train Loss: 0.1541, Accuracy: 0.9203, F1 Micro: 0.7515, F1 Macro: 0.63\n",
      "Epoch 6/10, Train Loss: 0.1298, Accuracy: 0.9188, F1 Micro: 0.7558, F1 Macro: 0.6316\n",
      "Epoch 7/10, Train Loss: 0.1148, Accuracy: 0.9185, F1 Micro: 0.7588, F1 Macro: 0.6542\n",
      "Epoch 8/10, Train Loss: 0.0964, Accuracy: 0.9203, F1 Micro: 0.7565, F1 Macro: 0.6582\n",
      "Epoch 9/10, Train Loss: 0.0819, Accuracy: 0.9212, F1 Micro: 0.7644, F1 Macro: 0.6663\n",
      "Epoch 10/10, Train Loss: 0.0721, Accuracy: 0.921, F1 Micro: 0.7614, F1 Macro: 0.6736\n",
      "Best result for 7336 samples: F1 Micro: 0.7644\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.81      0.84      0.83      1094\n",
      "      Abusive       0.91      0.88      0.89      1072\n",
      "HS_Individual       0.70      0.73      0.71       689\n",
      "     HS_Group       0.75      0.64      0.69       405\n",
      "  HS_Religion       0.70      0.69      0.70       124\n",
      "      HS_Race       0.81      0.72      0.76       125\n",
      "  HS_Physical       0.88      0.11      0.20        61\n",
      "    HS_Gender       0.64      0.24      0.35        58\n",
      "     HS_Other       0.77      0.77      0.77       754\n",
      "      HS_Weak       0.68      0.71      0.70       664\n",
      "  HS_Moderate       0.66      0.56      0.60       346\n",
      "    HS_Strong       0.80      0.79      0.80        84\n",
      "\n",
      "    micro avg       0.78      0.75      0.76      5476\n",
      "    macro avg       0.76      0.64      0.67      5476\n",
      " weighted avg       0.78      0.75      0.76      5476\n",
      "  samples avg       0.44      0.43      0.42      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 34.71104011535645\n",
      "Samples above threshold: 320\n",
      "Acquired samples: 320\n",
      "Sampling duration: 16.77767252922058 seconds\n",
      "\n",
      "Fold 2 - New train size: 7656\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 7656 samples\n",
      "Epoch 1/10, Train Loss: 0.4075, Accuracy: 0.8854, F1 Micro: 0.608, F1 Macro: 0.3183\n",
      "Epoch 2/10, Train Loss: 0.2712, Accuracy: 0.9032, F1 Micro: 0.694, F1 Macro: 0.4814\n",
      "Epoch 3/10, Train Loss: 0.2205, Accuracy: 0.9138, F1 Micro: 0.7325, F1 Macro: 0.5628\n",
      "Epoch 4/10, Train Loss: 0.1763, Accuracy: 0.9126, F1 Micro: 0.7561, F1 Macro: 0.622\n",
      "Epoch 5/10, Train Loss: 0.1491, Accuracy: 0.9206, F1 Micro: 0.7645, F1 Macro: 0.6461\n",
      "Epoch 6/10, Train Loss: 0.1259, Accuracy: 0.9187, F1 Micro: 0.7603, F1 Macro: 0.6395\n",
      "Epoch 7/10, Train Loss: 0.1061, Accuracy: 0.919, F1 Micro: 0.7607, F1 Macro: 0.6551\n",
      "Epoch 8/10, Train Loss: 0.0926, Accuracy: 0.9171, F1 Micro: 0.763, F1 Macro: 0.6611\n",
      "Epoch 9/10, Train Loss: 0.0803, Accuracy: 0.9213, F1 Micro: 0.7636, F1 Macro: 0.6742\n",
      "Epoch 10/10, Train Loss: 0.0704, Accuracy: 0.9193, F1 Micro: 0.7612, F1 Macro: 0.6738\n",
      "Best result for 7656 samples: F1 Micro: 0.7645\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.88      0.84      1094\n",
      "      Abusive       0.90      0.88      0.89      1072\n",
      "HS_Individual       0.70      0.76      0.73       689\n",
      "     HS_Group       0.72      0.60      0.66       405\n",
      "  HS_Religion       0.71      0.65      0.68       124\n",
      "      HS_Race       0.82      0.70      0.76       125\n",
      "  HS_Physical       0.47      0.11      0.18        61\n",
      "    HS_Gender       0.54      0.12      0.20        58\n",
      "     HS_Other       0.76      0.76      0.76       754\n",
      "      HS_Weak       0.68      0.75      0.71       664\n",
      "  HS_Moderate       0.67      0.50      0.57       346\n",
      "    HS_Strong       0.79      0.77      0.78        84\n",
      "\n",
      "    micro avg       0.77      0.76      0.76      5476\n",
      "    macro avg       0.71      0.62      0.65      5476\n",
      " weighted avg       0.77      0.76      0.76      5476\n",
      "  samples avg       0.44      0.43      0.42      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 30.637125396728514\n",
      "Samples above threshold: 288\n",
      "Acquired samples: 245\n",
      "Sampling duration: 15.696226358413696 seconds\n",
      "\n",
      "Fold 2 - New train size: 7901\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 7901 samples\n",
      "Epoch 1/10, Train Loss: 0.4071, Accuracy: 0.8869, F1 Micro: 0.6141, F1 Macro: 0.3054\n",
      "Epoch 2/10, Train Loss: 0.275, Accuracy: 0.9023, F1 Micro: 0.6912, F1 Macro: 0.4867\n",
      "Epoch 3/10, Train Loss: 0.2164, Accuracy: 0.9115, F1 Micro: 0.7074, F1 Macro: 0.5306\n",
      "Epoch 4/10, Train Loss: 0.1806, Accuracy: 0.9172, F1 Micro: 0.7404, F1 Macro: 0.5909\n",
      "Epoch 5/10, Train Loss: 0.1527, Accuracy: 0.9203, F1 Micro: 0.7663, F1 Macro: 0.6452\n",
      "Epoch 6/10, Train Loss: 0.1299, Accuracy: 0.921, F1 Micro: 0.7616, F1 Macro: 0.6543\n",
      "Epoch 7/10, Train Loss: 0.1104, Accuracy: 0.9209, F1 Micro: 0.7545, F1 Macro: 0.6487\n",
      "Epoch 8/10, Train Loss: 0.0931, Accuracy: 0.9209, F1 Micro: 0.7649, F1 Macro: 0.6665\n",
      "Epoch 9/10, Train Loss: 0.0783, Accuracy: 0.9224, F1 Micro: 0.768, F1 Macro: 0.688\n",
      "Epoch 10/10, Train Loss: 0.0679, Accuracy: 0.9191, F1 Micro: 0.7658, F1 Macro: 0.6933\n",
      "Best result for 7901 samples: F1 Micro: 0.768\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.84      0.83      1094\n",
      "      Abusive       0.88      0.90      0.89      1072\n",
      "HS_Individual       0.70      0.74      0.72       689\n",
      "     HS_Group       0.75      0.62      0.68       405\n",
      "  HS_Religion       0.73      0.68      0.70       124\n",
      "      HS_Race       0.85      0.73      0.78       125\n",
      "  HS_Physical       0.45      0.23      0.30        61\n",
      "    HS_Gender       0.63      0.41      0.50        58\n",
      "     HS_Other       0.78      0.74      0.76       754\n",
      "      HS_Weak       0.69      0.73      0.71       664\n",
      "  HS_Moderate       0.68      0.54      0.60       346\n",
      "    HS_Strong       0.79      0.75      0.77        84\n",
      "\n",
      "    micro avg       0.78      0.76      0.77      5476\n",
      "    macro avg       0.73      0.66      0.69      5476\n",
      " weighted avg       0.78      0.76      0.76      5476\n",
      "  samples avg       0.44      0.43      0.42      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 33.33939971923828\n",
      "Samples above threshold: 264\n",
      "Acquired samples: 264\n",
      "Sampling duration: 14.232302188873291 seconds\n",
      "\n",
      "Fold 2 - New train size: 8165\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 8165 samples\n",
      "Epoch 1/10, Train Loss: 0.3999, Accuracy: 0.8878, F1 Micro: 0.6143, F1 Macro: 0.3143\n",
      "Epoch 2/10, Train Loss: 0.2666, Accuracy: 0.9037, F1 Micro: 0.7055, F1 Macro: 0.5057\n",
      "Epoch 3/10, Train Loss: 0.2113, Accuracy: 0.9131, F1 Micro: 0.742, F1 Macro: 0.588\n",
      "Epoch 4/10, Train Loss: 0.178, Accuracy: 0.9196, F1 Micro: 0.7488, F1 Macro: 0.5943\n",
      "Epoch 5/10, Train Loss: 0.1473, Accuracy: 0.92, F1 Micro: 0.763, F1 Macro: 0.6387\n",
      "Epoch 6/10, Train Loss: 0.1236, Accuracy: 0.9211, F1 Micro: 0.7691, F1 Macro: 0.6637\n",
      "Epoch 7/10, Train Loss: 0.1045, Accuracy: 0.9219, F1 Micro: 0.7601, F1 Macro: 0.6593\n",
      "Epoch 8/10, Train Loss: 0.0868, Accuracy: 0.9214, F1 Micro: 0.764, F1 Macro: 0.6687\n",
      "Epoch 9/10, Train Loss: 0.0756, Accuracy: 0.9214, F1 Micro: 0.7552, F1 Macro: 0.6601\n",
      "Epoch 10/10, Train Loss: 0.0681, Accuracy: 0.9235, F1 Micro: 0.772, F1 Macro: 0.6896\n",
      "Best result for 8165 samples: F1 Micro: 0.772\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.86      0.84      1094\n",
      "      Abusive       0.90      0.89      0.90      1072\n",
      "HS_Individual       0.70      0.73      0.72       689\n",
      "     HS_Group       0.72      0.64      0.68       405\n",
      "  HS_Religion       0.75      0.71      0.73       124\n",
      "      HS_Race       0.86      0.70      0.78       125\n",
      "  HS_Physical       0.79      0.18      0.29        61\n",
      "    HS_Gender       0.72      0.36      0.48        58\n",
      "     HS_Other       0.77      0.78      0.78       754\n",
      "      HS_Weak       0.69      0.71      0.70       664\n",
      "  HS_Moderate       0.66      0.58      0.61       346\n",
      "    HS_Strong       0.81      0.75      0.78        84\n",
      "\n",
      "    micro avg       0.78      0.76      0.77      5476\n",
      "    macro avg       0.77      0.66      0.69      5476\n",
      " weighted avg       0.78      0.76      0.77      5476\n",
      "  samples avg       0.45      0.44      0.42      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 33.18465042114258\n",
      "Samples above threshold: 238\n",
      "Acquired samples: 238\n",
      "Sampling duration: 12.81825041770935 seconds\n",
      "\n",
      "Fold 2 - New train size: 8403\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 8403 samples\n",
      "Epoch 1/10, Train Loss: 0.3965, Accuracy: 0.8853, F1 Micro: 0.6133, F1 Macro: 0.3245\n",
      "Epoch 2/10, Train Loss: 0.2617, Accuracy: 0.9033, F1 Micro: 0.6749, F1 Macro: 0.4634\n",
      "Epoch 3/10, Train Loss: 0.2087, Accuracy: 0.9131, F1 Micro: 0.7134, F1 Macro: 0.5588\n",
      "Epoch 4/10, Train Loss: 0.1718, Accuracy: 0.9178, F1 Micro: 0.7321, F1 Macro: 0.5852\n",
      "Epoch 5/10, Train Loss: 0.145, Accuracy: 0.9208, F1 Micro: 0.7562, F1 Macro: 0.6358\n",
      "Epoch 6/10, Train Loss: 0.1231, Accuracy: 0.9211, F1 Micro: 0.7584, F1 Macro: 0.6455\n",
      "Epoch 7/10, Train Loss: 0.101, Accuracy: 0.9218, F1 Micro: 0.7686, F1 Macro: 0.6654\n",
      "Epoch 8/10, Train Loss: 0.0894, Accuracy: 0.9193, F1 Micro: 0.7524, F1 Macro: 0.6608\n",
      "Epoch 9/10, Train Loss: 0.076, Accuracy: 0.9214, F1 Micro: 0.7655, F1 Macro: 0.684\n",
      "Epoch 10/10, Train Loss: 0.0648, Accuracy: 0.9183, F1 Micro: 0.7527, F1 Macro: 0.6757\n",
      "Best result for 8403 samples: F1 Micro: 0.7686\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.81      0.86      0.84      1094\n",
      "      Abusive       0.89      0.90      0.90      1072\n",
      "HS_Individual       0.70      0.73      0.71       689\n",
      "     HS_Group       0.73      0.64      0.68       405\n",
      "  HS_Religion       0.70      0.73      0.71       124\n",
      "      HS_Race       0.82      0.74      0.78       125\n",
      "  HS_Physical       0.86      0.10      0.18        61\n",
      "    HS_Gender       0.67      0.21      0.32        58\n",
      "     HS_Other       0.77      0.77      0.77       754\n",
      "      HS_Weak       0.68      0.71      0.70       664\n",
      "  HS_Moderate       0.64      0.57      0.60       346\n",
      "    HS_Strong       0.82      0.80      0.81        84\n",
      "\n",
      "    micro avg       0.77      0.76      0.77      5476\n",
      "    macro avg       0.76      0.65      0.67      5476\n",
      " weighted avg       0.77      0.76      0.76      5476\n",
      "  samples avg       0.45      0.44      0.43      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 31.520883178710935\n",
      "Samples above threshold: 214\n",
      "Acquired samples: 214\n",
      "Sampling duration: 11.991617918014526 seconds\n",
      "\n",
      "Fold 2 - New train size: 8617\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 8617 samples\n",
      "Epoch 1/10, Train Loss: 0.3958, Accuracy: 0.8862, F1 Micro: 0.637, F1 Macro: 0.32\n",
      "Epoch 2/10, Train Loss: 0.2636, Accuracy: 0.9043, F1 Micro: 0.6943, F1 Macro: 0.4859\n",
      "Epoch 3/10, Train Loss: 0.2155, Accuracy: 0.9155, F1 Micro: 0.7471, F1 Macro: 0.5859\n",
      "Epoch 4/10, Train Loss: 0.1746, Accuracy: 0.9202, F1 Micro: 0.7539, F1 Macro: 0.5931\n",
      "Epoch 5/10, Train Loss: 0.1445, Accuracy: 0.9214, F1 Micro: 0.7637, F1 Macro: 0.6407\n",
      "Epoch 6/10, Train Loss: 0.1218, Accuracy: 0.9197, F1 Micro: 0.7664, F1 Macro: 0.665\n",
      "Epoch 7/10, Train Loss: 0.1013, Accuracy: 0.9196, F1 Micro: 0.7653, F1 Macro: 0.6542\n",
      "Epoch 8/10, Train Loss: 0.0872, Accuracy: 0.9187, F1 Micro: 0.768, F1 Macro: 0.673\n",
      "Epoch 9/10, Train Loss: 0.0728, Accuracy: 0.9183, F1 Micro: 0.7625, F1 Macro: 0.6526\n",
      "Epoch 10/10, Train Loss: 0.0669, Accuracy: 0.9204, F1 Micro: 0.7711, F1 Macro: 0.695\n",
      "Best result for 8617 samples: F1 Micro: 0.7711\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.88      0.84      1094\n",
      "      Abusive       0.88      0.91      0.90      1072\n",
      "HS_Individual       0.68      0.76      0.72       689\n",
      "     HS_Group       0.70      0.66      0.68       405\n",
      "  HS_Religion       0.74      0.73      0.73       124\n",
      "      HS_Race       0.81      0.78      0.79       125\n",
      "  HS_Physical       0.67      0.23      0.34        61\n",
      "    HS_Gender       0.69      0.34      0.46        58\n",
      "     HS_Other       0.73      0.80      0.76       754\n",
      "      HS_Weak       0.66      0.75      0.70       664\n",
      "  HS_Moderate       0.63      0.62      0.62       346\n",
      "    HS_Strong       0.80      0.79      0.80        84\n",
      "\n",
      "    micro avg       0.75      0.79      0.77      5476\n",
      "    macro avg       0.73      0.69      0.69      5476\n",
      " weighted avg       0.75      0.79      0.77      5476\n",
      "  samples avg       0.45      0.45      0.44      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 35.25010681152344\n",
      "Samples above threshold: 192\n",
      "Acquired samples: 200\n",
      "Sampling duration: 10.651474475860596 seconds\n",
      "\n",
      "Fold 2 - New train size: 8817\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 8817 samples\n",
      "Epoch 1/10, Train Loss: 0.3904, Accuracy: 0.8854, F1 Micro: 0.578, F1 Macro: 0.2849\n",
      "Epoch 2/10, Train Loss: 0.2548, Accuracy: 0.9033, F1 Micro: 0.7123, F1 Macro: 0.4763\n",
      "Epoch 3/10, Train Loss: 0.2065, Accuracy: 0.9112, F1 Micro: 0.6979, F1 Macro: 0.5456\n",
      "Epoch 4/10, Train Loss: 0.1758, Accuracy: 0.9182, F1 Micro: 0.7386, F1 Macro: 0.5975\n",
      "Epoch 5/10, Train Loss: 0.1461, Accuracy: 0.9206, F1 Micro: 0.7656, F1 Macro: 0.6578\n",
      "Epoch 6/10, Train Loss: 0.1202, Accuracy: 0.9209, F1 Micro: 0.7568, F1 Macro: 0.6429\n",
      "Epoch 7/10, Train Loss: 0.1023, Accuracy: 0.9201, F1 Micro: 0.7626, F1 Macro: 0.6579\n",
      "Epoch 8/10, Train Loss: 0.0862, Accuracy: 0.9201, F1 Micro: 0.7627, F1 Macro: 0.6592\n",
      "Epoch 9/10, Train Loss: 0.0732, Accuracy: 0.9213, F1 Micro: 0.7659, F1 Macro: 0.6762\n",
      "Epoch 10/10, Train Loss: 0.0636, Accuracy: 0.9219, F1 Micro: 0.7685, F1 Macro: 0.6929\n",
      "Best result for 8817 samples: F1 Micro: 0.7685\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.85      0.84      1094\n",
      "      Abusive       0.89      0.90      0.90      1072\n",
      "HS_Individual       0.70      0.74      0.72       689\n",
      "     HS_Group       0.72      0.64      0.68       405\n",
      "  HS_Religion       0.73      0.66      0.69       124\n",
      "      HS_Race       0.83      0.71      0.77       125\n",
      "  HS_Physical       0.53      0.31      0.39        61\n",
      "    HS_Gender       0.63      0.38      0.47        58\n",
      "     HS_Other       0.78      0.74      0.76       754\n",
      "      HS_Weak       0.68      0.73      0.70       664\n",
      "  HS_Moderate       0.65      0.57      0.61       346\n",
      "    HS_Strong       0.80      0.79      0.79        84\n",
      "\n",
      "    micro avg       0.77      0.76      0.77      5476\n",
      "    macro avg       0.73      0.67      0.69      5476\n",
      " weighted avg       0.77      0.76      0.77      5476\n",
      "  samples avg       0.45      0.44      0.43      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 28.7608943939209\n",
      "Samples above threshold: 172\n",
      "Acquired samples: 200\n",
      "Sampling duration: 9.73435091972351 seconds\n",
      "\n",
      "Fold 2 - New train size: 9017\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 9017 samples\n",
      "Epoch 1/10, Train Loss: 0.3897, Accuracy: 0.8894, F1 Micro: 0.6351, F1 Macro: 0.325\n",
      "Epoch 2/10, Train Loss: 0.2618, Accuracy: 0.9057, F1 Micro: 0.7122, F1 Macro: 0.5238\n",
      "Epoch 3/10, Train Loss: 0.2126, Accuracy: 0.9162, F1 Micro: 0.7435, F1 Macro: 0.5753\n",
      "Epoch 4/10, Train Loss: 0.1691, Accuracy: 0.916, F1 Micro: 0.7618, F1 Macro: 0.6262\n",
      "Epoch 5/10, Train Loss: 0.145, Accuracy: 0.9193, F1 Micro: 0.7607, F1 Macro: 0.6169\n",
      "Epoch 6/10, Train Loss: 0.1214, Accuracy: 0.9214, F1 Micro: 0.7553, F1 Macro: 0.6458\n",
      "Epoch 7/10, Train Loss: 0.1071, Accuracy: 0.9219, F1 Micro: 0.7671, F1 Macro: 0.6707\n",
      "Epoch 8/10, Train Loss: 0.0881, Accuracy: 0.9209, F1 Micro: 0.7635, F1 Macro: 0.6629\n",
      "Epoch 9/10, Train Loss: 0.0776, Accuracy: 0.9209, F1 Micro: 0.7588, F1 Macro: 0.663\n",
      "Epoch 10/10, Train Loss: 0.064, Accuracy: 0.9231, F1 Micro: 0.7632, F1 Macro: 0.6844\n",
      "Best result for 9017 samples: F1 Micro: 0.7671\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.84      0.83      1094\n",
      "      Abusive       0.89      0.90      0.90      1072\n",
      "HS_Individual       0.68      0.77      0.72       689\n",
      "     HS_Group       0.79      0.58      0.67       405\n",
      "  HS_Religion       0.77      0.60      0.68       124\n",
      "      HS_Race       0.86      0.69      0.76       125\n",
      "  HS_Physical       0.47      0.15      0.23        61\n",
      "    HS_Gender       0.77      0.29      0.42        58\n",
      "     HS_Other       0.77      0.76      0.76       754\n",
      "      HS_Weak       0.67      0.76      0.71       664\n",
      "  HS_Moderate       0.71      0.48      0.57       346\n",
      "    HS_Strong       0.80      0.79      0.80        84\n",
      "\n",
      "    micro avg       0.78      0.76      0.77      5476\n",
      "    macro avg       0.75      0.63      0.67      5476\n",
      " weighted avg       0.78      0.76      0.76      5476\n",
      "  samples avg       0.45      0.44      0.42      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 33.78218460083008\n",
      "Samples above threshold: 152\n",
      "Acquired samples: 200\n",
      "Sampling duration: 8.771353960037231 seconds\n",
      "\n",
      "Fold 2 - New train size: 9217\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 9217 samples\n",
      "Epoch 1/10, Train Loss: 0.3859, Accuracy: 0.8863, F1 Micro: 0.637, F1 Macro: 0.3175\n",
      "Epoch 2/10, Train Loss: 0.2541, Accuracy: 0.9076, F1 Micro: 0.7146, F1 Macro: 0.5084\n",
      "Epoch 3/10, Train Loss: 0.2053, Accuracy: 0.917, F1 Micro: 0.7535, F1 Macro: 0.5909\n",
      "Epoch 4/10, Train Loss: 0.1686, Accuracy: 0.9174, F1 Micro: 0.7562, F1 Macro: 0.6035\n",
      "Epoch 5/10, Train Loss: 0.1405, Accuracy: 0.9202, F1 Micro: 0.7629, F1 Macro: 0.6246\n",
      "Epoch 6/10, Train Loss: 0.1193, Accuracy: 0.921, F1 Micro: 0.75, F1 Macro: 0.6254\n",
      "Epoch 7/10, Train Loss: 0.0998, Accuracy: 0.9224, F1 Micro: 0.765, F1 Macro: 0.6705\n",
      "Epoch 8/10, Train Loss: 0.0864, Accuracy: 0.9216, F1 Micro: 0.7661, F1 Macro: 0.6748\n",
      "Epoch 9/10, Train Loss: 0.0696, Accuracy: 0.9216, F1 Micro: 0.7664, F1 Macro: 0.6885\n",
      "Epoch 10/10, Train Loss: 0.0653, Accuracy: 0.9215, F1 Micro: 0.7659, F1 Macro: 0.6884\n",
      "Best result for 9217 samples: F1 Micro: 0.7664\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.84      0.83      1094\n",
      "      Abusive       0.88      0.92      0.90      1072\n",
      "HS_Individual       0.71      0.70      0.71       689\n",
      "     HS_Group       0.68      0.65      0.66       405\n",
      "  HS_Religion       0.71      0.73      0.72       124\n",
      "      HS_Race       0.82      0.74      0.78       125\n",
      "  HS_Physical       0.76      0.21      0.33        61\n",
      "    HS_Gender       0.72      0.36      0.48        58\n",
      "     HS_Other       0.78      0.74      0.76       754\n",
      "      HS_Weak       0.70      0.69      0.70       664\n",
      "  HS_Moderate       0.63      0.58      0.60       346\n",
      "    HS_Strong       0.81      0.77      0.79        84\n",
      "\n",
      "    micro avg       0.78      0.76      0.77      5476\n",
      "    macro avg       0.75      0.66      0.69      5476\n",
      " weighted avg       0.77      0.76      0.76      5476\n",
      "  samples avg       0.45      0.44      0.43      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 24.8895320892334\n",
      "Samples above threshold: 132\n",
      "Acquired samples: 1\n",
      "Sampling duration: 8.086101055145264 seconds\n",
      "\n",
      "Fold 2 - New train size: 9218\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 9218 samples\n",
      "Epoch 1/10, Train Loss: 0.384, Accuracy: 0.8886, F1 Micro: 0.6125, F1 Macro: 0.3087\n",
      "Epoch 2/10, Train Loss: 0.2543, Accuracy: 0.9063, F1 Micro: 0.676, F1 Macro: 0.4783\n",
      "Epoch 3/10, Train Loss: 0.2055, Accuracy: 0.9157, F1 Micro: 0.7344, F1 Macro: 0.5808\n",
      "Epoch 4/10, Train Loss: 0.1689, Accuracy: 0.9182, F1 Micro: 0.7511, F1 Macro: 0.5841\n",
      "Epoch 5/10, Train Loss: 0.1411, Accuracy: 0.9209, F1 Micro: 0.7622, F1 Macro: 0.6525\n",
      "Epoch 6/10, Train Loss: 0.1196, Accuracy: 0.9212, F1 Micro: 0.7514, F1 Macro: 0.6546\n",
      "Epoch 7/10, Train Loss: 0.1007, Accuracy: 0.9214, F1 Micro: 0.7589, F1 Macro: 0.666\n",
      "Epoch 8/10, Train Loss: 0.0865, Accuracy: 0.9211, F1 Micro: 0.7645, F1 Macro: 0.6798\n",
      "Epoch 9/10, Train Loss: 0.0717, Accuracy: 0.9193, F1 Micro: 0.7648, F1 Macro: 0.6708\n",
      "Epoch 10/10, Train Loss: 0.0624, Accuracy: 0.9211, F1 Micro: 0.7606, F1 Macro: 0.6849\n",
      "Best result for 9218 samples: F1 Micro: 0.7648\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.81      0.86      0.84      1094\n",
      "      Abusive       0.89      0.90      0.90      1072\n",
      "HS_Individual       0.69      0.71      0.70       689\n",
      "     HS_Group       0.66      0.68      0.67       405\n",
      "  HS_Religion       0.73      0.68      0.70       124\n",
      "      HS_Race       0.78      0.78      0.78       125\n",
      "  HS_Physical       0.71      0.16      0.27        61\n",
      "    HS_Gender       0.68      0.22      0.34        58\n",
      "     HS_Other       0.73      0.81      0.77       754\n",
      "      HS_Weak       0.69      0.70      0.69       664\n",
      "  HS_Moderate       0.59      0.61      0.60       346\n",
      "    HS_Strong       0.80      0.80      0.80        84\n",
      "\n",
      "    micro avg       0.76      0.77      0.76      5476\n",
      "    macro avg       0.73      0.66      0.67      5476\n",
      " weighted avg       0.76      0.77      0.76      5476\n",
      "  samples avg       0.45      0.44      0.43      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 30.934645462036134\n",
      "Samples above threshold: 132\n",
      "Acquired samples: 200\n",
      "Sampling duration: 7.8264076709747314 seconds\n",
      "\n",
      "Fold 2 - New train size: 9418\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 9418 samples\n",
      "Epoch 1/10, Train Loss: 0.3865, Accuracy: 0.8889, F1 Micro: 0.6282, F1 Macro: 0.3251\n",
      "Epoch 2/10, Train Loss: 0.252, Accuracy: 0.9069, F1 Micro: 0.6911, F1 Macro: 0.4747\n",
      "Epoch 3/10, Train Loss: 0.2019, Accuracy: 0.9157, F1 Micro: 0.7453, F1 Macro: 0.5815\n",
      "Epoch 4/10, Train Loss: 0.1732, Accuracy: 0.9205, F1 Micro: 0.7625, F1 Macro: 0.6197\n",
      "Epoch 5/10, Train Loss: 0.1408, Accuracy: 0.9218, F1 Micro: 0.7627, F1 Macro: 0.6279\n",
      "Epoch 6/10, Train Loss: 0.1206, Accuracy: 0.9212, F1 Micro: 0.7617, F1 Macro: 0.6448\n",
      "Epoch 7/10, Train Loss: 0.1002, Accuracy: 0.9229, F1 Micro: 0.7719, F1 Macro: 0.67\n",
      "Epoch 8/10, Train Loss: 0.086, Accuracy: 0.9216, F1 Micro: 0.7704, F1 Macro: 0.6765\n",
      "Epoch 9/10, Train Loss: 0.0746, Accuracy: 0.9218, F1 Micro: 0.7716, F1 Macro: 0.6813\n",
      "Epoch 10/10, Train Loss: 0.0612, Accuracy: 0.9215, F1 Micro: 0.7628, F1 Macro: 0.6957\n",
      "Best result for 9418 samples: F1 Micro: 0.7719\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.86      0.84      1094\n",
      "      Abusive       0.91      0.89      0.90      1072\n",
      "HS_Individual       0.69      0.78      0.73       689\n",
      "     HS_Group       0.76      0.59      0.67       405\n",
      "  HS_Religion       0.69      0.69      0.69       124\n",
      "      HS_Race       0.82      0.70      0.75       125\n",
      "  HS_Physical       0.60      0.15      0.24        61\n",
      "    HS_Gender       0.59      0.28      0.38        58\n",
      "     HS_Other       0.76      0.78      0.77       754\n",
      "      HS_Weak       0.68      0.77      0.72       664\n",
      "  HS_Moderate       0.70      0.50      0.58       346\n",
      "    HS_Strong       0.76      0.80      0.78        84\n",
      "\n",
      "    micro avg       0.78      0.77      0.77      5476\n",
      "    macro avg       0.73      0.65      0.67      5476\n",
      " weighted avg       0.77      0.77      0.77      5476\n",
      "  samples avg       0.44      0.44      0.42      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 27.85209903717041\n",
      "Samples above threshold: 112\n",
      "Acquired samples: 200\n",
      "Sampling duration: 6.8143768310546875 seconds\n",
      "\n",
      "Fold 2 - New train size: 9618\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 9618 samples\n",
      "Epoch 1/10, Train Loss: 0.3827, Accuracy: 0.891, F1 Micro: 0.627, F1 Macro: 0.3127\n",
      "Epoch 2/10, Train Loss: 0.2564, Accuracy: 0.9075, F1 Micro: 0.7116, F1 Macro: 0.531\n",
      "Epoch 3/10, Train Loss: 0.2068, Accuracy: 0.9169, F1 Micro: 0.7366, F1 Macro: 0.5717\n",
      "Epoch 4/10, Train Loss: 0.1704, Accuracy: 0.9216, F1 Micro: 0.7613, F1 Macro: 0.613\n",
      "Epoch 5/10, Train Loss: 0.1415, Accuracy: 0.9202, F1 Micro: 0.7494, F1 Macro: 0.6416\n",
      "Epoch 6/10, Train Loss: 0.1155, Accuracy: 0.921, F1 Micro: 0.7719, F1 Macro: 0.6673\n",
      "Epoch 7/10, Train Loss: 0.1, Accuracy: 0.9212, F1 Micro: 0.771, F1 Macro: 0.6635\n",
      "Epoch 8/10, Train Loss: 0.0853, Accuracy: 0.923, F1 Micro: 0.7689, F1 Macro: 0.6782\n",
      "Epoch 9/10, Train Loss: 0.0734, Accuracy: 0.9208, F1 Micro: 0.7582, F1 Macro: 0.6749\n",
      "Epoch 10/10, Train Loss: 0.0641, Accuracy: 0.9226, F1 Micro: 0.7641, F1 Macro: 0.6896\n",
      "Best result for 9618 samples: F1 Micro: 0.7719\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.79      0.89      0.84      1094\n",
      "      Abusive       0.88      0.91      0.90      1072\n",
      "HS_Individual       0.70      0.76      0.73       689\n",
      "     HS_Group       0.68      0.67      0.67       405\n",
      "  HS_Religion       0.67      0.69      0.68       124\n",
      "      HS_Race       0.85      0.72      0.78       125\n",
      "  HS_Physical       0.62      0.13      0.22        61\n",
      "    HS_Gender       0.67      0.21      0.32        58\n",
      "     HS_Other       0.73      0.81      0.77       754\n",
      "      HS_Weak       0.69      0.74      0.71       664\n",
      "  HS_Moderate       0.61      0.58      0.60       346\n",
      "    HS_Strong       0.80      0.79      0.80        84\n",
      "\n",
      "    micro avg       0.76      0.79      0.77      5476\n",
      "    macro avg       0.73      0.66      0.67      5476\n",
      " weighted avg       0.75      0.79      0.77      5476\n",
      "  samples avg       0.45      0.45      0.44      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 29.340383911132815\n",
      "Samples above threshold: 92\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.822380542755127 seconds\n",
      "\n",
      "Fold 2 - New train size: 9818\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 9818 samples\n",
      "Epoch 1/10, Train Loss: 0.3817, Accuracy: 0.8904, F1 Micro: 0.6277, F1 Macro: 0.3339\n",
      "Epoch 2/10, Train Loss: 0.253, Accuracy: 0.9047, F1 Micro: 0.6719, F1 Macro: 0.4724\n",
      "Epoch 3/10, Train Loss: 0.2028, Accuracy: 0.9173, F1 Micro: 0.7357, F1 Macro: 0.5781\n",
      "Epoch 4/10, Train Loss: 0.1735, Accuracy: 0.9183, F1 Micro: 0.762, F1 Macro: 0.6227\n",
      "Epoch 5/10, Train Loss: 0.1382, Accuracy: 0.921, F1 Micro: 0.7589, F1 Macro: 0.6189\n",
      "Epoch 6/10, Train Loss: 0.1238, Accuracy: 0.9217, F1 Micro: 0.764, F1 Macro: 0.6489\n",
      "Epoch 7/10, Train Loss: 0.1005, Accuracy: 0.9217, F1 Micro: 0.7643, F1 Macro: 0.666\n",
      "Epoch 8/10, Train Loss: 0.0847, Accuracy: 0.9223, F1 Micro: 0.7707, F1 Macro: 0.6747\n",
      "Epoch 9/10, Train Loss: 0.0723, Accuracy: 0.9193, F1 Micro: 0.7554, F1 Macro: 0.6824\n",
      "Epoch 10/10, Train Loss: 0.0627, Accuracy: 0.9205, F1 Micro: 0.7619, F1 Macro: 0.6807\n",
      "Best result for 9818 samples: F1 Micro: 0.7707\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.87      0.84      1094\n",
      "      Abusive       0.90      0.90      0.90      1072\n",
      "HS_Individual       0.68      0.78      0.73       689\n",
      "     HS_Group       0.74      0.58      0.65       405\n",
      "  HS_Religion       0.71      0.63      0.67       124\n",
      "      HS_Race       0.84      0.73      0.78       125\n",
      "  HS_Physical       0.69      0.15      0.24        61\n",
      "    HS_Gender       0.66      0.33      0.44        58\n",
      "     HS_Other       0.78      0.76      0.77       754\n",
      "      HS_Weak       0.67      0.77      0.71       664\n",
      "  HS_Moderate       0.67      0.50      0.57       346\n",
      "    HS_Strong       0.77      0.81      0.79        84\n",
      "\n",
      "    micro avg       0.77      0.77      0.77      5476\n",
      "    macro avg       0.74      0.65      0.67      5476\n",
      " weighted avg       0.77      0.77      0.77      5476\n",
      "  samples avg       0.45      0.44      0.43      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 21.82514190673828\n",
      "Samples above threshold: 72\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.914680004119873 seconds\n",
      "\n",
      "Fold 2 - New train size: 10018\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 10018 samples\n",
      "Epoch 1/10, Train Loss: 0.3803, Accuracy: 0.8863, F1 Micro: 0.5874, F1 Macro: 0.3062\n",
      "Epoch 2/10, Train Loss: 0.2515, Accuracy: 0.9081, F1 Micro: 0.7199, F1 Macro: 0.5288\n",
      "Epoch 3/10, Train Loss: 0.2017, Accuracy: 0.9168, F1 Micro: 0.7342, F1 Macro: 0.5646\n",
      "Epoch 4/10, Train Loss: 0.1688, Accuracy: 0.9191, F1 Micro: 0.7543, F1 Macro: 0.599\n",
      "Epoch 5/10, Train Loss: 0.1387, Accuracy: 0.9237, F1 Micro: 0.7671, F1 Macro: 0.6367\n",
      "Epoch 6/10, Train Loss: 0.1195, Accuracy: 0.9223, F1 Micro: 0.768, F1 Macro: 0.6599\n",
      "Epoch 7/10, Train Loss: 0.0991, Accuracy: 0.923, F1 Micro: 0.7661, F1 Macro: 0.6749\n",
      "Epoch 8/10, Train Loss: 0.0844, Accuracy: 0.9216, F1 Micro: 0.7736, F1 Macro: 0.6915\n",
      "Epoch 9/10, Train Loss: 0.0672, Accuracy: 0.9237, F1 Micro: 0.7685, F1 Macro: 0.6913\n",
      "Epoch 10/10, Train Loss: 0.0617, Accuracy: 0.9219, F1 Micro: 0.7612, F1 Macro: 0.6985\n",
      "Best result for 10018 samples: F1 Micro: 0.7736\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.81      0.88      0.84      1094\n",
      "      Abusive       0.90      0.91      0.90      1072\n",
      "HS_Individual       0.69      0.75      0.72       689\n",
      "     HS_Group       0.68      0.68      0.68       405\n",
      "  HS_Religion       0.65      0.73      0.69       124\n",
      "      HS_Race       0.83      0.79      0.81       125\n",
      "  HS_Physical       0.65      0.18      0.28        61\n",
      "    HS_Gender       0.68      0.40      0.50        58\n",
      "     HS_Other       0.76      0.80      0.78       754\n",
      "      HS_Weak       0.68      0.73      0.70       664\n",
      "  HS_Moderate       0.61      0.61      0.61       346\n",
      "    HS_Strong       0.80      0.77      0.79        84\n",
      "\n",
      "    micro avg       0.76      0.79      0.77      5476\n",
      "    macro avg       0.73      0.69      0.69      5476\n",
      " weighted avg       0.76      0.79      0.77      5476\n",
      "  samples avg       0.45      0.45      0.43      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 22.817855834960938\n",
      "Samples above threshold: 52\n",
      "Acquired samples: 200\n",
      "Sampling duration: 3.8797717094421387 seconds\n",
      "\n",
      "Fold 2 - New train size: 10218\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 10218 samples\n",
      "Epoch 1/10, Train Loss: 0.3801, Accuracy: 0.8872, F1 Micro: 0.5812, F1 Macro: 0.2974\n",
      "Epoch 2/10, Train Loss: 0.2584, Accuracy: 0.9068, F1 Micro: 0.6962, F1 Macro: 0.4643\n",
      "Epoch 3/10, Train Loss: 0.211, Accuracy: 0.9089, F1 Micro: 0.7482, F1 Macro: 0.5816\n",
      "Epoch 4/10, Train Loss: 0.1793, Accuracy: 0.9222, F1 Micro: 0.7663, F1 Macro: 0.6072\n",
      "Epoch 5/10, Train Loss: 0.1429, Accuracy: 0.924, F1 Micro: 0.7699, F1 Macro: 0.6488\n",
      "Epoch 6/10, Train Loss: 0.1209, Accuracy: 0.9253, F1 Micro: 0.7703, F1 Macro: 0.6682\n",
      "Epoch 7/10, Train Loss: 0.0994, Accuracy: 0.9225, F1 Micro: 0.7598, F1 Macro: 0.6551\n",
      "Epoch 8/10, Train Loss: 0.0858, Accuracy: 0.9227, F1 Micro: 0.7764, F1 Macro: 0.6963\n",
      "Epoch 9/10, Train Loss: 0.0731, Accuracy: 0.9234, F1 Micro: 0.775, F1 Macro: 0.697\n",
      "Epoch 10/10, Train Loss: 0.0658, Accuracy: 0.9212, F1 Micro: 0.7696, F1 Macro: 0.6731\n",
      "Best result for 10218 samples: F1 Micro: 0.7764\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.89      0.85      1094\n",
      "      Abusive       0.90      0.89      0.89      1072\n",
      "HS_Individual       0.72      0.74      0.73       689\n",
      "     HS_Group       0.66      0.71      0.69       405\n",
      "  HS_Religion       0.70      0.70      0.70       124\n",
      "      HS_Race       0.79      0.78      0.78       125\n",
      "  HS_Physical       0.55      0.18      0.27        61\n",
      "    HS_Gender       0.68      0.43      0.53        58\n",
      "     HS_Other       0.76      0.80      0.78       754\n",
      "      HS_Weak       0.70      0.72      0.71       664\n",
      "  HS_Moderate       0.60      0.63      0.61       346\n",
      "    HS_Strong       0.77      0.86      0.81        84\n",
      "\n",
      "    micro avg       0.76      0.79      0.78      5476\n",
      "    macro avg       0.72      0.70      0.70      5476\n",
      " weighted avg       0.76      0.79      0.77      5476\n",
      "  samples avg       0.44      0.45      0.43      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 26.62881965637207\n",
      "Samples above threshold: 32\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.75093150138855 seconds\n",
      "\n",
      "Fold 2 - New train size: 10418\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 10418 samples\n",
      "Epoch 1/10, Train Loss: 0.3741, Accuracy: 0.8898, F1 Micro: 0.6264, F1 Macro: 0.33\n",
      "Epoch 2/10, Train Loss: 0.2477, Accuracy: 0.9048, F1 Micro: 0.7061, F1 Macro: 0.426\n",
      "Epoch 3/10, Train Loss: 0.1999, Accuracy: 0.9143, F1 Micro: 0.731, F1 Macro: 0.543\n",
      "Epoch 4/10, Train Loss: 0.1694, Accuracy: 0.9195, F1 Micro: 0.77, F1 Macro: 0.6429\n",
      "Epoch 5/10, Train Loss: 0.1371, Accuracy: 0.9234, F1 Micro: 0.7654, F1 Macro: 0.6525\n",
      "Epoch 6/10, Train Loss: 0.1164, Accuracy: 0.922, F1 Micro: 0.7576, F1 Macro: 0.6491\n",
      "Epoch 7/10, Train Loss: 0.0959, Accuracy: 0.9232, F1 Micro: 0.7704, F1 Macro: 0.6829\n",
      "Epoch 8/10, Train Loss: 0.0815, Accuracy: 0.922, F1 Micro: 0.7745, F1 Macro: 0.6786\n",
      "Epoch 9/10, Train Loss: 0.0694, Accuracy: 0.9217, F1 Micro: 0.77, F1 Macro: 0.6898\n",
      "Epoch 10/10, Train Loss: 0.0623, Accuracy: 0.9232, F1 Micro: 0.7665, F1 Macro: 0.6979\n",
      "Best result for 10418 samples: F1 Micro: 0.7745\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.81      0.89      0.85      1094\n",
      "      Abusive       0.90      0.90      0.90      1072\n",
      "HS_Individual       0.67      0.80      0.73       689\n",
      "     HS_Group       0.73      0.58      0.65       405\n",
      "  HS_Religion       0.79      0.60      0.68       124\n",
      "      HS_Race       0.84      0.69      0.76       125\n",
      "  HS_Physical       0.56      0.15      0.23        61\n",
      "    HS_Gender       0.65      0.34      0.45        58\n",
      "     HS_Other       0.73      0.84      0.78       754\n",
      "      HS_Weak       0.67      0.79      0.72       664\n",
      "  HS_Moderate       0.68      0.51      0.58       346\n",
      "    HS_Strong       0.80      0.83      0.81        84\n",
      "\n",
      "    micro avg       0.76      0.79      0.77      5476\n",
      "    macro avg       0.73      0.66      0.68      5476\n",
      " weighted avg       0.76      0.79      0.77      5476\n",
      "  samples avg       0.45      0.45      0.43      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 20.825799179077148\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 117\n",
      "Sampling duration: 1.813964605331421 seconds\n",
      "\n",
      "Fold 2 - New train size: 10535\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 10535 samples\n",
      "Epoch 1/10, Train Loss: 0.3746, Accuracy: 0.8902, F1 Micro: 0.6416, F1 Macro: 0.331\n",
      "Epoch 2/10, Train Loss: 0.2467, Accuracy: 0.9096, F1 Micro: 0.7116, F1 Macro: 0.5289\n",
      "Epoch 3/10, Train Loss: 0.1989, Accuracy: 0.9118, F1 Micro: 0.7077, F1 Macro: 0.5083\n",
      "Epoch 4/10, Train Loss: 0.1699, Accuracy: 0.9177, F1 Micro: 0.7459, F1 Macro: 0.5747\n",
      "Epoch 5/10, Train Loss: 0.1394, Accuracy: 0.9242, F1 Micro: 0.7705, F1 Macro: 0.6614\n",
      "Epoch 6/10, Train Loss: 0.1156, Accuracy: 0.921, F1 Micro: 0.7562, F1 Macro: 0.6522\n",
      "Epoch 7/10, Train Loss: 0.0944, Accuracy: 0.9237, F1 Micro: 0.7703, F1 Macro: 0.6736\n",
      "Epoch 8/10, Train Loss: 0.081, Accuracy: 0.9236, F1 Micro: 0.7714, F1 Macro: 0.6951\n",
      "Epoch 9/10, Train Loss: 0.0677, Accuracy: 0.9227, F1 Micro: 0.771, F1 Macro: 0.6875\n",
      "Epoch 10/10, Train Loss: 0.0627, Accuracy: 0.9234, F1 Micro: 0.773, F1 Macro: 0.6959\n",
      "Best result for 10535 samples: F1 Micro: 0.773\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.85      0.84      1094\n",
      "      Abusive       0.90      0.90      0.90      1072\n",
      "HS_Individual       0.69      0.78      0.73       689\n",
      "     HS_Group       0.75      0.59      0.66       405\n",
      "  HS_Religion       0.75      0.60      0.67       124\n",
      "      HS_Race       0.83      0.72      0.77       125\n",
      "  HS_Physical       0.67      0.30      0.41        61\n",
      "    HS_Gender       0.75      0.41      0.53        58\n",
      "     HS_Other       0.76      0.78      0.77       754\n",
      "      HS_Weak       0.68      0.77      0.72       664\n",
      "  HS_Moderate       0.67      0.51      0.58       346\n",
      "    HS_Strong       0.81      0.73      0.77        84\n",
      "\n",
      "    micro avg       0.78      0.77      0.77      5476\n",
      "    macro avg       0.76      0.66      0.70      5476\n",
      " weighted avg       0.78      0.77      0.77      5476\n",
      "  samples avg       0.45      0.44      0.43      5476\n",
      "\n",
      "\n",
      "FOLD 2 COMPLETED in 5687.38 seconds\n",
      "===============================================\n",
      "STARTING FOLD 3/5\n",
      "===============================================\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 658 samples\n",
      "Epoch 1/10, Train Loss: 0.5882, Accuracy: 0.8199, F1 Micro: 0.3218, F1 Macro: 0.1158\n",
      "Epoch 2/10, Train Loss: 0.4613, Accuracy: 0.8328, F1 Micro: 0.1359, F1 Macro: 0.0419\n",
      "Epoch 3/10, Train Loss: 0.4093, Accuracy: 0.8371, F1 Micro: 0.1625, F1 Macro: 0.0606\n",
      "Epoch 4/10, Train Loss: 0.3943, Accuracy: 0.8407, F1 Micro: 0.2002, F1 Macro: 0.0725\n",
      "Epoch 5/10, Train Loss: 0.3792, Accuracy: 0.851, F1 Micro: 0.3263, F1 Macro: 0.1049\n",
      "Epoch 6/10, Train Loss: 0.362, Accuracy: 0.8581, F1 Micro: 0.3855, F1 Macro: 0.1378\n",
      "Epoch 7/10, Train Loss: 0.3352, Accuracy: 0.8715, F1 Micro: 0.5616, F1 Macro: 0.2467\n",
      "Epoch 8/10, Train Loss: 0.31, Accuracy: 0.8726, F1 Micro: 0.5138, F1 Macro: 0.2394\n",
      "Epoch 9/10, Train Loss: 0.2875, Accuracy: 0.8785, F1 Micro: 0.6054, F1 Macro: 0.3035\n",
      "Epoch 10/10, Train Loss: 0.2688, Accuracy: 0.8795, F1 Micro: 0.6353, F1 Macro: 0.3581\n",
      "Best result for 658 samples: F1 Micro: 0.6353\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.75      0.82      0.78      1142\n",
      "      Abusive       0.78      0.81      0.79      1026\n",
      "HS_Individual       0.60      0.64      0.62       723\n",
      "     HS_Group       0.57      0.38      0.46       419\n",
      "  HS_Religion       0.00      0.00      0.00       177\n",
      "      HS_Race       1.00      0.02      0.03       119\n",
      "  HS_Physical       0.00      0.00      0.00        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.61      0.71      0.66       746\n",
      "      HS_Weak       0.59      0.57      0.58       685\n",
      "  HS_Moderate       0.58      0.20      0.30       352\n",
      "    HS_Strong       1.00      0.04      0.07       105\n",
      "\n",
      "    micro avg       0.67      0.60      0.64      5634\n",
      "    macro avg       0.54      0.35      0.36      5634\n",
      " weighted avg       0.64      0.60      0.59      5634\n",
      "  samples avg       0.38      0.34      0.33      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 29.997733306884765\n",
      "Samples above threshold: 988\n",
      "Acquired samples: 988\n",
      "Sampling duration: 50.625951051712036 seconds\n",
      "\n",
      "Fold 3 - New train size: 1646\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 1646 samples\n",
      "Epoch 1/10, Train Loss: 0.4854, Accuracy: 0.8253, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.3089, Accuracy: 0.8253, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.2828, Accuracy: 0.8256, F1 Micro: 0.0035, F1 Macro: 0.0016\n",
      "Epoch 4/10, Train Loss: 0.2485, Accuracy: 0.8574, F1 Micro: 0.378, F1 Macro: 0.1245\n",
      "Epoch 5/10, Train Loss: 0.2295, Accuracy: 0.8691, F1 Micro: 0.5658, F1 Macro: 0.257\n",
      "Epoch 6/10, Train Loss: 0.1973, Accuracy: 0.8738, F1 Micro: 0.576, F1 Macro: 0.2844\n",
      "Epoch 7/10, Train Loss: 0.1777, Accuracy: 0.8779, F1 Micro: 0.6124, F1 Macro: 0.3151\n",
      "Epoch 8/10, Train Loss: 0.1667, Accuracy: 0.8808, F1 Micro: 0.6372, F1 Macro: 0.3573\n",
      "Epoch 9/10, Train Loss: 0.1462, Accuracy: 0.8836, F1 Micro: 0.6572, F1 Macro: 0.3778\n",
      "Epoch 10/10, Train Loss: 0.1308, Accuracy: 0.8863, F1 Micro: 0.6624, F1 Macro: 0.4411\n",
      "Best result for 1646 samples: F1 Micro: 0.6624\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.78      0.85      0.81      1142\n",
      "      Abusive       0.82      0.83      0.82      1026\n",
      "HS_Individual       0.62      0.62      0.62       723\n",
      "     HS_Group       0.57      0.54      0.56       419\n",
      "  HS_Religion       0.63      0.07      0.12       177\n",
      "      HS_Race       0.75      0.33      0.46       119\n",
      "  HS_Physical       0.00      0.00      0.00        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.62      0.70      0.66       746\n",
      "      HS_Weak       0.60      0.56      0.58       685\n",
      "  HS_Moderate       0.52      0.38      0.44       352\n",
      "    HS_Strong       0.52      0.14      0.22       105\n",
      "\n",
      "    micro avg       0.69      0.64      0.66      5634\n",
      "    macro avg       0.54      0.42      0.44      5634\n",
      " weighted avg       0.66      0.64      0.64      5634\n",
      "  samples avg       0.40      0.37      0.35      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 39.676113510131835\n",
      "Samples above threshold: 889\n",
      "Acquired samples: 889\n",
      "Sampling duration: 44.886765003204346 seconds\n",
      "\n",
      "Fold 3 - New train size: 2535\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 2535 samples\n",
      "Epoch 1/10, Train Loss: 0.4869, Accuracy: 0.8499, F1 Micro: 0.4238, F1 Macro: 0.1216\n",
      "Epoch 2/10, Train Loss: 0.3471, Accuracy: 0.8685, F1 Micro: 0.5422, F1 Macro: 0.2522\n",
      "Epoch 3/10, Train Loss: 0.2888, Accuracy: 0.8747, F1 Micro: 0.5389, F1 Macro: 0.2766\n",
      "Epoch 4/10, Train Loss: 0.2479, Accuracy: 0.889, F1 Micro: 0.6265, F1 Macro: 0.3969\n",
      "Epoch 5/10, Train Loss: 0.2197, Accuracy: 0.8952, F1 Micro: 0.6766, F1 Macro: 0.4705\n",
      "Epoch 6/10, Train Loss: 0.2018, Accuracy: 0.8999, F1 Micro: 0.6968, F1 Macro: 0.5167\n",
      "Epoch 7/10, Train Loss: 0.1825, Accuracy: 0.8974, F1 Micro: 0.694, F1 Macro: 0.4995\n",
      "Epoch 8/10, Train Loss: 0.158, Accuracy: 0.9015, F1 Micro: 0.7047, F1 Macro: 0.5589\n",
      "Epoch 9/10, Train Loss: 0.1353, Accuracy: 0.9001, F1 Micro: 0.6992, F1 Macro: 0.5353\n",
      "Epoch 10/10, Train Loss: 0.1206, Accuracy: 0.902, F1 Micro: 0.7063, F1 Macro: 0.5493\n",
      "Best result for 2535 samples: F1 Micro: 0.7063\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.80      0.80      1142\n",
      "      Abusive       0.84      0.86      0.85      1026\n",
      "HS_Individual       0.64      0.72      0.68       723\n",
      "     HS_Group       0.75      0.46      0.57       419\n",
      "  HS_Religion       0.82      0.43      0.56       177\n",
      "      HS_Race       0.82      0.50      0.62       119\n",
      "  HS_Physical       0.00      0.00      0.00        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.71      0.69      0.70       746\n",
      "      HS_Weak       0.63      0.66      0.64       685\n",
      "  HS_Moderate       0.71      0.36      0.47       352\n",
      "    HS_Strong       0.79      0.61      0.69       105\n",
      "\n",
      "    micro avg       0.74      0.67      0.71      5634\n",
      "    macro avg       0.63      0.51      0.55      5634\n",
      " weighted avg       0.73      0.67      0.69      5634\n",
      "  samples avg       0.41      0.39      0.38      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 38.9695930480957\n",
      "Samples above threshold: 801\n",
      "Acquired samples: 801\n",
      "Sampling duration: 40.91572594642639 seconds\n",
      "\n",
      "Fold 3 - New train size: 3336\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 3336 samples\n",
      "Epoch 1/10, Train Loss: 0.4616, Accuracy: 0.8553, F1 Micro: 0.4558, F1 Macro: 0.1691\n",
      "Epoch 2/10, Train Loss: 0.3305, Accuracy: 0.8812, F1 Micro: 0.6174, F1 Macro: 0.3279\n",
      "Epoch 3/10, Train Loss: 0.2731, Accuracy: 0.8924, F1 Micro: 0.678, F1 Macro: 0.4362\n",
      "Epoch 4/10, Train Loss: 0.2349, Accuracy: 0.9014, F1 Micro: 0.6768, F1 Macro: 0.4737\n",
      "Epoch 5/10, Train Loss: 0.2046, Accuracy: 0.9049, F1 Micro: 0.6973, F1 Macro: 0.5146\n",
      "Epoch 6/10, Train Loss: 0.1854, Accuracy: 0.9061, F1 Micro: 0.7039, F1 Macro: 0.537\n",
      "Epoch 7/10, Train Loss: 0.1538, Accuracy: 0.9061, F1 Micro: 0.7216, F1 Macro: 0.5725\n",
      "Epoch 8/10, Train Loss: 0.132, Accuracy: 0.9041, F1 Micro: 0.7331, F1 Macro: 0.5948\n",
      "Epoch 9/10, Train Loss: 0.1152, Accuracy: 0.9054, F1 Micro: 0.7215, F1 Macro: 0.571\n",
      "Epoch 10/10, Train Loss: 0.1024, Accuracy: 0.9086, F1 Micro: 0.731, F1 Macro: 0.599\n",
      "Best result for 3336 samples: F1 Micro: 0.7331\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.76      0.88      0.82      1142\n",
      "      Abusive       0.81      0.91      0.86      1026\n",
      "HS_Individual       0.64      0.76      0.69       723\n",
      "     HS_Group       0.68      0.59      0.63       419\n",
      "  HS_Religion       0.76      0.50      0.61       177\n",
      "      HS_Race       0.80      0.55      0.66       119\n",
      "  HS_Physical       1.00      0.09      0.16        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.68      0.81      0.74       746\n",
      "      HS_Weak       0.63      0.73      0.68       685\n",
      "  HS_Moderate       0.61      0.51      0.55       352\n",
      "    HS_Strong       0.82      0.69      0.75       105\n",
      "\n",
      "    micro avg       0.71      0.75      0.73      5634\n",
      "    macro avg       0.68      0.58      0.59      5634\n",
      " weighted avg       0.71      0.75      0.72      5634\n",
      "  samples avg       0.43      0.43      0.41      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 37.5260196685791\n",
      "Samples above threshold: 720\n",
      "Acquired samples: 720\n",
      "Sampling duration: 36.97034454345703 seconds\n",
      "\n",
      "Fold 3 - New train size: 4056\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 4056 samples\n",
      "Epoch 1/10, Train Loss: 0.4443, Accuracy: 0.8612, F1 Micro: 0.4254, F1 Macro: 0.1424\n",
      "Epoch 2/10, Train Loss: 0.3076, Accuracy: 0.8866, F1 Micro: 0.6132, F1 Macro: 0.3095\n",
      "Epoch 3/10, Train Loss: 0.2495, Accuracy: 0.8992, F1 Micro: 0.6827, F1 Macro: 0.4619\n",
      "Epoch 4/10, Train Loss: 0.2231, Accuracy: 0.9055, F1 Micro: 0.709, F1 Macro: 0.5241\n",
      "Epoch 5/10, Train Loss: 0.186, Accuracy: 0.9072, F1 Micro: 0.725, F1 Macro: 0.5521\n",
      "Epoch 6/10, Train Loss: 0.1613, Accuracy: 0.9061, F1 Micro: 0.7234, F1 Macro: 0.5432\n",
      "Epoch 7/10, Train Loss: 0.1431, Accuracy: 0.9067, F1 Micro: 0.7371, F1 Macro: 0.5997\n",
      "Epoch 8/10, Train Loss: 0.1213, Accuracy: 0.9104, F1 Micro: 0.7255, F1 Macro: 0.5756\n",
      "Epoch 9/10, Train Loss: 0.1073, Accuracy: 0.9088, F1 Micro: 0.7371, F1 Macro: 0.6076\n",
      "Epoch 10/10, Train Loss: 0.0954, Accuracy: 0.9073, F1 Micro: 0.7294, F1 Macro: 0.6173\n",
      "Best result for 4056 samples: F1 Micro: 0.7371\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.77      0.88      0.82      1142\n",
      "      Abusive       0.82      0.91      0.87      1026\n",
      "HS_Individual       0.68      0.70      0.69       723\n",
      "     HS_Group       0.65      0.68      0.67       419\n",
      "  HS_Religion       0.80      0.42      0.55       177\n",
      "      HS_Race       0.79      0.63      0.70       119\n",
      "  HS_Physical       1.00      0.10      0.18        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.70      0.80      0.75       746\n",
      "      HS_Weak       0.67      0.65      0.66       685\n",
      "  HS_Moderate       0.57      0.60      0.59       352\n",
      "    HS_Strong       0.80      0.67      0.73       105\n",
      "\n",
      "    micro avg       0.73      0.75      0.74      5634\n",
      "    macro avg       0.69      0.59      0.60      5634\n",
      " weighted avg       0.72      0.75      0.73      5634\n",
      "  samples avg       0.44      0.43      0.42      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 35.74359245300293\n",
      "Samples above threshold: 648\n",
      "Acquired samples: 648\n",
      "Sampling duration: 32.99257516860962 seconds\n",
      "\n",
      "Fold 3 - New train size: 4704\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 4704 samples\n",
      "Epoch 1/10, Train Loss: 0.4413, Accuracy: 0.8703, F1 Micro: 0.5337, F1 Macro: 0.2343\n",
      "Epoch 2/10, Train Loss: 0.3078, Accuracy: 0.8941, F1 Micro: 0.6515, F1 Macro: 0.4077\n",
      "Epoch 3/10, Train Loss: 0.2505, Accuracy: 0.9032, F1 Micro: 0.7048, F1 Macro: 0.5062\n",
      "Epoch 4/10, Train Loss: 0.2085, Accuracy: 0.9026, F1 Micro: 0.7324, F1 Macro: 0.5737\n",
      "Epoch 5/10, Train Loss: 0.1828, Accuracy: 0.913, F1 Micro: 0.7305, F1 Macro: 0.573\n",
      "Epoch 6/10, Train Loss: 0.1579, Accuracy: 0.9089, F1 Micro: 0.7419, F1 Macro: 0.5743\n",
      "Epoch 7/10, Train Loss: 0.1335, Accuracy: 0.9133, F1 Micro: 0.7399, F1 Macro: 0.6006\n",
      "Epoch 8/10, Train Loss: 0.1186, Accuracy: 0.913, F1 Micro: 0.7471, F1 Macro: 0.6155\n",
      "Epoch 9/10, Train Loss: 0.0971, Accuracy: 0.913, F1 Micro: 0.742, F1 Macro: 0.6159\n",
      "Epoch 10/10, Train Loss: 0.0903, Accuracy: 0.9144, F1 Micro: 0.7485, F1 Macro: 0.6369\n",
      "Best result for 4704 samples: F1 Micro: 0.7485\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.84      0.83      1142\n",
      "      Abusive       0.89      0.85      0.87      1026\n",
      "HS_Individual       0.71      0.70      0.71       723\n",
      "     HS_Group       0.71      0.63      0.67       419\n",
      "  HS_Religion       0.75      0.58      0.65       177\n",
      "      HS_Race       0.81      0.66      0.73       119\n",
      "  HS_Physical       0.68      0.16      0.26        80\n",
      "    HS_Gender       0.67      0.07      0.12        60\n",
      "     HS_Other       0.73      0.77      0.75       746\n",
      "      HS_Weak       0.69      0.68      0.68       685\n",
      "  HS_Moderate       0.65      0.56      0.60       352\n",
      "    HS_Strong       0.87      0.70      0.77       105\n",
      "\n",
      "    micro avg       0.77      0.73      0.75      5634\n",
      "    macro avg       0.75      0.60      0.64      5634\n",
      " weighted avg       0.77      0.73      0.74      5634\n",
      "  samples avg       0.43      0.41      0.41      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 36.582075119018555\n",
      "Samples above threshold: 584\n",
      "Acquired samples: 584\n",
      "Sampling duration: 29.956748008728027 seconds\n",
      "\n",
      "Fold 3 - New train size: 5288\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 5288 samples\n",
      "Epoch 1/10, Train Loss: 0.434, Accuracy: 0.8722, F1 Micro: 0.5235, F1 Macro: 0.2312\n",
      "Epoch 2/10, Train Loss: 0.2988, Accuracy: 0.8985, F1 Micro: 0.6777, F1 Macro: 0.4436\n",
      "Epoch 3/10, Train Loss: 0.2406, Accuracy: 0.9055, F1 Micro: 0.7196, F1 Macro: 0.5388\n",
      "Epoch 4/10, Train Loss: 0.2075, Accuracy: 0.9128, F1 Micro: 0.7264, F1 Macro: 0.5623\n",
      "Epoch 5/10, Train Loss: 0.1768, Accuracy: 0.9133, F1 Micro: 0.7448, F1 Macro: 0.5784\n",
      "Epoch 6/10, Train Loss: 0.1454, Accuracy: 0.9046, F1 Micro: 0.7436, F1 Macro: 0.6043\n",
      "Epoch 7/10, Train Loss: 0.1262, Accuracy: 0.9145, F1 Micro: 0.7496, F1 Macro: 0.6188\n",
      "Epoch 8/10, Train Loss: 0.1083, Accuracy: 0.9153, F1 Micro: 0.7506, F1 Macro: 0.6333\n",
      "Epoch 9/10, Train Loss: 0.0935, Accuracy: 0.915, F1 Micro: 0.7558, F1 Macro: 0.6498\n",
      "Epoch 10/10, Train Loss: 0.0815, Accuracy: 0.9151, F1 Micro: 0.7532, F1 Macro: 0.6522\n",
      "Best result for 5288 samples: F1 Micro: 0.7558\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.81      0.86      0.84      1142\n",
      "      Abusive       0.88      0.89      0.88      1026\n",
      "HS_Individual       0.70      0.74      0.72       723\n",
      "     HS_Group       0.69      0.65      0.67       419\n",
      "  HS_Religion       0.74      0.59      0.66       177\n",
      "      HS_Race       0.83      0.62      0.71       119\n",
      "  HS_Physical       0.72      0.16      0.27        80\n",
      "    HS_Gender       0.69      0.18      0.29        60\n",
      "     HS_Other       0.74      0.77      0.76       746\n",
      "      HS_Weak       0.67      0.72      0.69       685\n",
      "  HS_Moderate       0.62      0.58      0.60       352\n",
      "    HS_Strong       0.84      0.63      0.72       105\n",
      "\n",
      "    micro avg       0.76      0.75      0.76      5634\n",
      "    macro avg       0.74      0.62      0.65      5634\n",
      " weighted avg       0.76      0.75      0.75      5634\n",
      "  samples avg       0.43      0.43      0.42      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 37.521148681640625\n",
      "Samples above threshold: 525\n",
      "Acquired samples: 525\n",
      "Sampling duration: 26.903078079223633 seconds\n",
      "\n",
      "Fold 3 - New train size: 5813\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 5813 samples\n",
      "Epoch 1/10, Train Loss: 0.4115, Accuracy: 0.8783, F1 Micro: 0.568, F1 Macro: 0.2701\n",
      "Epoch 2/10, Train Loss: 0.2794, Accuracy: 0.9011, F1 Micro: 0.6813, F1 Macro: 0.4603\n",
      "Epoch 3/10, Train Loss: 0.2304, Accuracy: 0.9067, F1 Micro: 0.7289, F1 Macro: 0.5504\n",
      "Epoch 4/10, Train Loss: 0.1951, Accuracy: 0.9124, F1 Micro: 0.7356, F1 Macro: 0.5707\n",
      "Epoch 5/10, Train Loss: 0.165, Accuracy: 0.9136, F1 Micro: 0.7515, F1 Macro: 0.5994\n",
      "Epoch 6/10, Train Loss: 0.1408, Accuracy: 0.9173, F1 Micro: 0.7521, F1 Macro: 0.6038\n",
      "Epoch 7/10, Train Loss: 0.1145, Accuracy: 0.9032, F1 Micro: 0.7419, F1 Macro: 0.6255\n",
      "Epoch 8/10, Train Loss: 0.1047, Accuracy: 0.9183, F1 Micro: 0.75, F1 Macro: 0.6244\n",
      "Epoch 9/10, Train Loss: 0.0885, Accuracy: 0.9174, F1 Micro: 0.7605, F1 Macro: 0.6543\n",
      "Epoch 10/10, Train Loss: 0.0775, Accuracy: 0.9165, F1 Micro: 0.7547, F1 Macro: 0.6538\n",
      "Best result for 5813 samples: F1 Micro: 0.7605\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.81      0.86      0.84      1142\n",
      "      Abusive       0.89      0.89      0.89      1026\n",
      "HS_Individual       0.68      0.75      0.72       723\n",
      "     HS_Group       0.77      0.61      0.68       419\n",
      "  HS_Religion       0.79      0.54      0.64       177\n",
      "      HS_Race       0.84      0.61      0.71       119\n",
      "  HS_Physical       0.80      0.15      0.25        80\n",
      "    HS_Gender       0.68      0.22      0.33        60\n",
      "     HS_Other       0.73      0.79      0.76       746\n",
      "      HS_Weak       0.67      0.73      0.70       685\n",
      "  HS_Moderate       0.72      0.53      0.61       352\n",
      "    HS_Strong       0.87      0.62      0.72       105\n",
      "\n",
      "    micro avg       0.77      0.75      0.76      5634\n",
      "    macro avg       0.77      0.61      0.65      5634\n",
      " weighted avg       0.77      0.75      0.75      5634\n",
      "  samples avg       0.44      0.43      0.42      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 33.03235549926758\n",
      "Samples above threshold: 473\n",
      "Acquired samples: 473\n",
      "Sampling duration: 24.330979585647583 seconds\n",
      "\n",
      "Fold 3 - New train size: 6286\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 6286 samples\n",
      "Epoch 1/10, Train Loss: 0.4187, Accuracy: 0.8796, F1 Micro: 0.5866, F1 Macro: 0.2804\n",
      "Epoch 2/10, Train Loss: 0.2836, Accuracy: 0.9025, F1 Micro: 0.699, F1 Macro: 0.4768\n",
      "Epoch 3/10, Train Loss: 0.2311, Accuracy: 0.9109, F1 Micro: 0.726, F1 Macro: 0.5364\n",
      "Epoch 4/10, Train Loss: 0.1925, Accuracy: 0.9147, F1 Micro: 0.7303, F1 Macro: 0.5726\n",
      "Epoch 5/10, Train Loss: 0.1634, Accuracy: 0.9157, F1 Micro: 0.7505, F1 Macro: 0.5869\n",
      "Epoch 6/10, Train Loss: 0.1355, Accuracy: 0.9196, F1 Micro: 0.7617, F1 Macro: 0.6379\n",
      "Epoch 7/10, Train Loss: 0.1128, Accuracy: 0.9188, F1 Micro: 0.7661, F1 Macro: 0.6514\n",
      "Epoch 8/10, Train Loss: 0.1015, Accuracy: 0.9163, F1 Micro: 0.7566, F1 Macro: 0.6605\n",
      "Epoch 9/10, Train Loss: 0.0843, Accuracy: 0.9188, F1 Micro: 0.7664, F1 Macro: 0.6786\n",
      "Epoch 10/10, Train Loss: 0.0736, Accuracy: 0.9131, F1 Micro: 0.7614, F1 Macro: 0.6777\n",
      "Best result for 6286 samples: F1 Micro: 0.7664\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.86      0.84      1142\n",
      "      Abusive       0.88      0.90      0.89      1026\n",
      "HS_Individual       0.72      0.69      0.71       723\n",
      "     HS_Group       0.68      0.73      0.70       419\n",
      "  HS_Religion       0.70      0.60      0.65       177\n",
      "      HS_Race       0.79      0.70      0.74       119\n",
      "  HS_Physical       0.84      0.20      0.32        80\n",
      "    HS_Gender       0.67      0.30      0.41        60\n",
      "     HS_Other       0.76      0.80      0.78       746\n",
      "      HS_Weak       0.71      0.67      0.69       685\n",
      "  HS_Moderate       0.63      0.66      0.65       352\n",
      "    HS_Strong       0.82      0.71      0.76       105\n",
      "\n",
      "    micro avg       0.77      0.76      0.77      5634\n",
      "    macro avg       0.75      0.65      0.68      5634\n",
      " weighted avg       0.77      0.76      0.76      5634\n",
      "  samples avg       0.44      0.44      0.42      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 37.602848052978516\n",
      "Samples above threshold: 425\n",
      "Acquired samples: 298\n",
      "Sampling duration: 22.211720943450928 seconds\n",
      "\n",
      "Fold 3 - New train size: 6584\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 6584 samples\n",
      "Epoch 1/10, Train Loss: 0.4119, Accuracy: 0.8789, F1 Micro: 0.5653, F1 Macro: 0.2724\n",
      "Epoch 2/10, Train Loss: 0.2857, Accuracy: 0.9016, F1 Micro: 0.6797, F1 Macro: 0.4564\n",
      "Epoch 3/10, Train Loss: 0.2267, Accuracy: 0.9088, F1 Micro: 0.7362, F1 Macro: 0.5448\n",
      "Epoch 4/10, Train Loss: 0.1918, Accuracy: 0.9152, F1 Micro: 0.7532, F1 Macro: 0.5862\n",
      "Epoch 5/10, Train Loss: 0.1602, Accuracy: 0.9182, F1 Micro: 0.7471, F1 Macro: 0.6012\n",
      "Epoch 6/10, Train Loss: 0.1359, Accuracy: 0.9177, F1 Micro: 0.7671, F1 Macro: 0.6436\n",
      "Epoch 7/10, Train Loss: 0.1136, Accuracy: 0.9135, F1 Micro: 0.7601, F1 Macro: 0.652\n",
      "Epoch 8/10, Train Loss: 0.0983, Accuracy: 0.9177, F1 Micro: 0.7672, F1 Macro: 0.6773\n",
      "Epoch 9/10, Train Loss: 0.0836, Accuracy: 0.9167, F1 Micro: 0.7498, F1 Macro: 0.6525\n",
      "Epoch 10/10, Train Loss: 0.0728, Accuracy: 0.916, F1 Micro: 0.7622, F1 Macro: 0.6746\n",
      "Best result for 6584 samples: F1 Micro: 0.7672\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.81      0.88      0.84      1142\n",
      "      Abusive       0.89      0.90      0.90      1026\n",
      "HS_Individual       0.70      0.74      0.72       723\n",
      "     HS_Group       0.68      0.69      0.69       419\n",
      "  HS_Religion       0.72      0.62      0.66       177\n",
      "      HS_Race       0.79      0.75      0.77       119\n",
      "  HS_Physical       0.68      0.19      0.29        80\n",
      "    HS_Gender       0.63      0.32      0.42        60\n",
      "     HS_Other       0.74      0.80      0.77       746\n",
      "      HS_Weak       0.68      0.72      0.70       685\n",
      "  HS_Moderate       0.63      0.62      0.63       352\n",
      "    HS_Strong       0.81      0.68      0.74       105\n",
      "\n",
      "    micro avg       0.76      0.78      0.77      5634\n",
      "    macro avg       0.73      0.66      0.68      5634\n",
      " weighted avg       0.76      0.78      0.76      5634\n",
      "  samples avg       0.44      0.44      0.43      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 31.44513740539551\n",
      "Samples above threshold: 396\n",
      "Acquired samples: 396\n",
      "Sampling duration: 20.518158435821533 seconds\n",
      "\n",
      "Fold 3 - New train size: 6980\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 6980 samples\n",
      "Epoch 1/10, Train Loss: 0.4123, Accuracy: 0.8813, F1 Micro: 0.5867, F1 Macro: 0.2873\n",
      "Epoch 2/10, Train Loss: 0.2819, Accuracy: 0.9041, F1 Micro: 0.717, F1 Macro: 0.5185\n",
      "Epoch 3/10, Train Loss: 0.2327, Accuracy: 0.915, F1 Micro: 0.7414, F1 Macro: 0.5629\n",
      "Epoch 4/10, Train Loss: 0.1949, Accuracy: 0.9171, F1 Micro: 0.7572, F1 Macro: 0.5851\n",
      "Epoch 5/10, Train Loss: 0.1641, Accuracy: 0.9195, F1 Micro: 0.7604, F1 Macro: 0.6039\n",
      "Epoch 6/10, Train Loss: 0.1349, Accuracy: 0.9188, F1 Micro: 0.7549, F1 Macro: 0.6113\n",
      "Epoch 7/10, Train Loss: 0.1179, Accuracy: 0.9202, F1 Micro: 0.7633, F1 Macro: 0.6626\n",
      "Epoch 8/10, Train Loss: 0.0964, Accuracy: 0.9182, F1 Micro: 0.7627, F1 Macro: 0.6519\n",
      "Epoch 9/10, Train Loss: 0.0878, Accuracy: 0.9204, F1 Micro: 0.7697, F1 Macro: 0.6737\n",
      "Epoch 10/10, Train Loss: 0.0719, Accuracy: 0.9221, F1 Micro: 0.7723, F1 Macro: 0.6958\n",
      "Best result for 6980 samples: F1 Micro: 0.7723\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.85      0.85      1142\n",
      "      Abusive       0.88      0.89      0.88      1026\n",
      "HS_Individual       0.71      0.74      0.72       723\n",
      "     HS_Group       0.75      0.62      0.68       419\n",
      "  HS_Religion       0.84      0.58      0.68       177\n",
      "      HS_Race       0.84      0.63      0.72       119\n",
      "  HS_Physical       0.84      0.34      0.48        80\n",
      "    HS_Gender       0.69      0.33      0.45        60\n",
      "     HS_Other       0.77      0.80      0.79       746\n",
      "      HS_Weak       0.70      0.72      0.71       685\n",
      "  HS_Moderate       0.69      0.57      0.62       352\n",
      "    HS_Strong       0.82      0.70      0.76       105\n",
      "\n",
      "    micro avg       0.79      0.76      0.77      5634\n",
      "    macro avg       0.78      0.65      0.70      5634\n",
      " weighted avg       0.79      0.76      0.77      5634\n",
      "  samples avg       0.43      0.43      0.41      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 31.547091484069824\n",
      "Samples above threshold: 356\n",
      "Acquired samples: 356\n",
      "Sampling duration: 18.439398288726807 seconds\n",
      "\n",
      "Fold 3 - New train size: 7336\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 7336 samples\n",
      "Epoch 1/10, Train Loss: 0.4102, Accuracy: 0.8837, F1 Micro: 0.6286, F1 Macro: 0.3086\n",
      "Epoch 2/10, Train Loss: 0.2836, Accuracy: 0.9081, F1 Micro: 0.7104, F1 Macro: 0.521\n",
      "Epoch 3/10, Train Loss: 0.2323, Accuracy: 0.914, F1 Micro: 0.7529, F1 Macro: 0.5874\n",
      "Epoch 4/10, Train Loss: 0.194, Accuracy: 0.9147, F1 Micro: 0.7621, F1 Macro: 0.6125\n",
      "Epoch 5/10, Train Loss: 0.1636, Accuracy: 0.9214, F1 Micro: 0.7687, F1 Macro: 0.6193\n",
      "Epoch 6/10, Train Loss: 0.1383, Accuracy: 0.9218, F1 Micro: 0.7676, F1 Macro: 0.638\n",
      "Epoch 7/10, Train Loss: 0.116, Accuracy: 0.9222, F1 Micro: 0.7616, F1 Macro: 0.6508\n",
      "Epoch 8/10, Train Loss: 0.0981, Accuracy: 0.9232, F1 Micro: 0.7665, F1 Macro: 0.6719\n",
      "Epoch 9/10, Train Loss: 0.0824, Accuracy: 0.9231, F1 Micro: 0.7757, F1 Macro: 0.6935\n",
      "Epoch 10/10, Train Loss: 0.0727, Accuracy: 0.9218, F1 Micro: 0.7666, F1 Macro: 0.6833\n",
      "Best result for 7336 samples: F1 Micro: 0.7757\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.86      0.85      1142\n",
      "      Abusive       0.91      0.90      0.90      1026\n",
      "HS_Individual       0.71      0.73      0.72       723\n",
      "     HS_Group       0.75      0.68      0.71       419\n",
      "  HS_Religion       0.75      0.66      0.70       177\n",
      "      HS_Race       0.84      0.73      0.78       119\n",
      "  HS_Physical       0.85      0.21      0.34        80\n",
      "    HS_Gender       0.67      0.33      0.44        60\n",
      "     HS_Other       0.79      0.76      0.77       746\n",
      "      HS_Weak       0.70      0.71      0.70       685\n",
      "  HS_Moderate       0.69      0.61      0.64       352\n",
      "    HS_Strong       0.83      0.70      0.76       105\n",
      "\n",
      "    micro avg       0.79      0.76      0.78      5634\n",
      "    macro avg       0.78      0.66      0.69      5634\n",
      " weighted avg       0.79      0.76      0.77      5634\n",
      "  samples avg       0.45      0.43      0.42      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 36.49999923706055\n",
      "Samples above threshold: 320\n",
      "Acquired samples: 320\n",
      "Sampling duration: 16.985151767730713 seconds\n",
      "\n",
      "Fold 3 - New train size: 7656\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 7656 samples\n",
      "Epoch 1/10, Train Loss: 0.4034, Accuracy: 0.8772, F1 Micro: 0.6497, F1 Macro: 0.3313\n",
      "Epoch 2/10, Train Loss: 0.279, Accuracy: 0.9069, F1 Micro: 0.7003, F1 Macro: 0.5034\n",
      "Epoch 3/10, Train Loss: 0.2282, Accuracy: 0.9141, F1 Micro: 0.7468, F1 Macro: 0.5872\n",
      "Epoch 4/10, Train Loss: 0.1863, Accuracy: 0.9197, F1 Micro: 0.7601, F1 Macro: 0.6031\n",
      "Epoch 5/10, Train Loss: 0.1604, Accuracy: 0.9209, F1 Micro: 0.7714, F1 Macro: 0.6211\n",
      "Epoch 6/10, Train Loss: 0.1344, Accuracy: 0.9196, F1 Micro: 0.7656, F1 Macro: 0.6504\n",
      "Epoch 7/10, Train Loss: 0.1146, Accuracy: 0.9205, F1 Micro: 0.756, F1 Macro: 0.635\n",
      "Epoch 8/10, Train Loss: 0.0976, Accuracy: 0.9233, F1 Micro: 0.7684, F1 Macro: 0.6729\n",
      "Epoch 9/10, Train Loss: 0.0848, Accuracy: 0.9195, F1 Micro: 0.7691, F1 Macro: 0.6808\n",
      "Epoch 10/10, Train Loss: 0.0727, Accuracy: 0.9173, F1 Micro: 0.7709, F1 Macro: 0.6797\n",
      "Best result for 7656 samples: F1 Micro: 0.7714\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.88      0.85      1142\n",
      "      Abusive       0.88      0.88      0.88      1026\n",
      "HS_Individual       0.73      0.76      0.75       723\n",
      "     HS_Group       0.74      0.69      0.72       419\n",
      "  HS_Religion       0.78      0.51      0.62       177\n",
      "      HS_Race       0.84      0.62      0.71       119\n",
      "  HS_Physical       1.00      0.03      0.05        80\n",
      "    HS_Gender       0.50      0.02      0.03        60\n",
      "     HS_Other       0.74      0.81      0.77       746\n",
      "      HS_Weak       0.71      0.74      0.72       685\n",
      "  HS_Moderate       0.68      0.60      0.64       352\n",
      "    HS_Strong       0.84      0.63      0.72       105\n",
      "\n",
      "    micro avg       0.78      0.76      0.77      5634\n",
      "    macro avg       0.77      0.60      0.62      5634\n",
      " weighted avg       0.78      0.76      0.76      5634\n",
      "  samples avg       0.44      0.43      0.42      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 30.266888999938963\n",
      "Samples above threshold: 288\n",
      "Acquired samples: 245\n",
      "Sampling duration: 16.110531091690063 seconds\n",
      "\n",
      "Fold 3 - New train size: 7901\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 7901 samples\n",
      "Epoch 1/10, Train Loss: 0.3987, Accuracy: 0.8861, F1 Micro: 0.6448, F1 Macro: 0.3557\n",
      "Epoch 2/10, Train Loss: 0.2761, Accuracy: 0.9069, F1 Micro: 0.6964, F1 Macro: 0.508\n",
      "Epoch 3/10, Train Loss: 0.2234, Accuracy: 0.9169, F1 Micro: 0.7566, F1 Macro: 0.5893\n",
      "Epoch 4/10, Train Loss: 0.1894, Accuracy: 0.9178, F1 Micro: 0.7629, F1 Macro: 0.609\n",
      "Epoch 5/10, Train Loss: 0.1564, Accuracy: 0.9171, F1 Micro: 0.7609, F1 Macro: 0.6105\n",
      "Epoch 6/10, Train Loss: 0.1343, Accuracy: 0.9192, F1 Micro: 0.7656, F1 Macro: 0.6443\n",
      "Epoch 7/10, Train Loss: 0.1094, Accuracy: 0.9175, F1 Micro: 0.7716, F1 Macro: 0.6568\n",
      "Epoch 8/10, Train Loss: 0.0947, Accuracy: 0.9212, F1 Micro: 0.769, F1 Macro: 0.6592\n",
      "Epoch 9/10, Train Loss: 0.0791, Accuracy: 0.9231, F1 Micro: 0.7734, F1 Macro: 0.6812\n",
      "Epoch 10/10, Train Loss: 0.0704, Accuracy: 0.919, F1 Micro: 0.7718, F1 Macro: 0.6774\n",
      "Best result for 7901 samples: F1 Micro: 0.7734\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.84      0.85      1142\n",
      "      Abusive       0.90      0.90      0.90      1026\n",
      "HS_Individual       0.74      0.71      0.72       723\n",
      "     HS_Group       0.73      0.68      0.70       419\n",
      "  HS_Religion       0.77      0.58      0.66       177\n",
      "      HS_Race       0.87      0.65      0.74       119\n",
      "  HS_Physical       0.82      0.17      0.29        80\n",
      "    HS_Gender       0.77      0.33      0.47        60\n",
      "     HS_Other       0.77      0.78      0.78       746\n",
      "      HS_Weak       0.71      0.68      0.70       685\n",
      "  HS_Moderate       0.67      0.62      0.64       352\n",
      "    HS_Strong       0.84      0.64      0.72       105\n",
      "\n",
      "    micro avg       0.80      0.75      0.77      5634\n",
      "    macro avg       0.79      0.63      0.68      5634\n",
      " weighted avg       0.80      0.75      0.77      5634\n",
      "  samples avg       0.45      0.43      0.42      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 30.18958511352539\n",
      "Samples above threshold: 264\n",
      "Acquired samples: 264\n",
      "Sampling duration: 14.529894590377808 seconds\n",
      "\n",
      "Fold 3 - New train size: 8165\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 8165 samples\n",
      "Epoch 1/10, Train Loss: 0.4011, Accuracy: 0.8871, F1 Micro: 0.6479, F1 Macro: 0.3451\n",
      "Epoch 2/10, Train Loss: 0.2732, Accuracy: 0.9059, F1 Micro: 0.7289, F1 Macro: 0.5324\n",
      "Epoch 3/10, Train Loss: 0.2276, Accuracy: 0.9167, F1 Micro: 0.7468, F1 Macro: 0.5691\n",
      "Epoch 4/10, Train Loss: 0.1898, Accuracy: 0.9204, F1 Micro: 0.7657, F1 Macro: 0.608\n",
      "Epoch 5/10, Train Loss: 0.156, Accuracy: 0.9196, F1 Micro: 0.7717, F1 Macro: 0.6242\n",
      "Epoch 6/10, Train Loss: 0.1328, Accuracy: 0.9221, F1 Micro: 0.7723, F1 Macro: 0.6579\n",
      "Epoch 7/10, Train Loss: 0.1107, Accuracy: 0.9221, F1 Micro: 0.7737, F1 Macro: 0.6687\n",
      "Epoch 8/10, Train Loss: 0.0979, Accuracy: 0.9212, F1 Micro: 0.77, F1 Macro: 0.6654\n",
      "Epoch 9/10, Train Loss: 0.0873, Accuracy: 0.9224, F1 Micro: 0.7685, F1 Macro: 0.6761\n",
      "Epoch 10/10, Train Loss: 0.0696, Accuracy: 0.9209, F1 Micro: 0.7718, F1 Macro: 0.6793\n",
      "Best result for 8165 samples: F1 Micro: 0.7737\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.86      0.85      1142\n",
      "      Abusive       0.91      0.88      0.89      1026\n",
      "HS_Individual       0.72      0.74      0.73       723\n",
      "     HS_Group       0.74      0.68      0.70       419\n",
      "  HS_Religion       0.73      0.68      0.71       177\n",
      "      HS_Race       0.80      0.73      0.76       119\n",
      "  HS_Physical       0.73      0.14      0.23        80\n",
      "    HS_Gender       0.73      0.18      0.29        60\n",
      "     HS_Other       0.77      0.78      0.77       746\n",
      "      HS_Weak       0.70      0.72      0.71       685\n",
      "  HS_Moderate       0.68      0.63      0.66       352\n",
      "    HS_Strong       0.80      0.65      0.72       105\n",
      "\n",
      "    micro avg       0.79      0.76      0.77      5634\n",
      "    macro avg       0.76      0.64      0.67      5634\n",
      " weighted avg       0.79      0.76      0.77      5634\n",
      "  samples avg       0.44      0.43      0.42      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 30.686016082763672\n",
      "Samples above threshold: 238\n",
      "Acquired samples: 238\n",
      "Sampling duration: 13.259880065917969 seconds\n",
      "\n",
      "Fold 3 - New train size: 8403\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 8403 samples\n",
      "Epoch 1/10, Train Loss: 0.3981, Accuracy: 0.8815, F1 Micro: 0.6628, F1 Macro: 0.3462\n",
      "Epoch 2/10, Train Loss: 0.2701, Accuracy: 0.9044, F1 Micro: 0.6832, F1 Macro: 0.4509\n",
      "Epoch 3/10, Train Loss: 0.2257, Accuracy: 0.918, F1 Micro: 0.7569, F1 Macro: 0.5978\n",
      "Epoch 4/10, Train Loss: 0.185, Accuracy: 0.9195, F1 Micro: 0.7672, F1 Macro: 0.5996\n",
      "Epoch 5/10, Train Loss: 0.1557, Accuracy: 0.9227, F1 Micro: 0.7639, F1 Macro: 0.6132\n",
      "Epoch 6/10, Train Loss: 0.1326, Accuracy: 0.9202, F1 Micro: 0.7768, F1 Macro: 0.6634\n",
      "Epoch 7/10, Train Loss: 0.1125, Accuracy: 0.921, F1 Micro: 0.7713, F1 Macro: 0.6707\n",
      "Epoch 8/10, Train Loss: 0.094, Accuracy: 0.9213, F1 Micro: 0.7711, F1 Macro: 0.6789\n",
      "Epoch 9/10, Train Loss: 0.0816, Accuracy: 0.9241, F1 Micro: 0.7791, F1 Macro: 0.694\n",
      "Epoch 10/10, Train Loss: 0.0698, Accuracy: 0.9249, F1 Micro: 0.777, F1 Macro: 0.7019\n",
      "Best result for 8403 samples: F1 Micro: 0.7791\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.86      0.85      1142\n",
      "      Abusive       0.91      0.91      0.91      1026\n",
      "HS_Individual       0.73      0.72      0.72       723\n",
      "     HS_Group       0.72      0.68      0.70       419\n",
      "  HS_Religion       0.77      0.63      0.69       177\n",
      "      HS_Race       0.83      0.69      0.75       119\n",
      "  HS_Physical       0.76      0.28      0.40        80\n",
      "    HS_Gender       0.74      0.28      0.41        60\n",
      "     HS_Other       0.77      0.79      0.78       746\n",
      "      HS_Weak       0.71      0.71      0.71       685\n",
      "  HS_Moderate       0.66      0.63      0.65       352\n",
      "    HS_Strong       0.83      0.68      0.74       105\n",
      "\n",
      "    micro avg       0.79      0.77      0.78      5634\n",
      "    macro avg       0.77      0.65      0.69      5634\n",
      " weighted avg       0.79      0.77      0.78      5634\n",
      "  samples avg       0.45      0.44      0.43      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 28.782275390625\n",
      "Samples above threshold: 214\n",
      "Acquired samples: 214\n",
      "Sampling duration: 12.104450464248657 seconds\n",
      "\n",
      "Fold 3 - New train size: 8617\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 8617 samples\n",
      "Epoch 1/10, Train Loss: 0.3901, Accuracy: 0.887, F1 Micro: 0.6238, F1 Macro: 0.3156\n",
      "Epoch 2/10, Train Loss: 0.267, Accuracy: 0.9102, F1 Micro: 0.7179, F1 Macro: 0.5181\n",
      "Epoch 3/10, Train Loss: 0.2201, Accuracy: 0.9173, F1 Micro: 0.7565, F1 Macro: 0.5987\n",
      "Epoch 4/10, Train Loss: 0.1866, Accuracy: 0.9223, F1 Micro: 0.7656, F1 Macro: 0.6079\n",
      "Epoch 5/10, Train Loss: 0.1541, Accuracy: 0.9172, F1 Micro: 0.7717, F1 Macro: 0.622\n",
      "Epoch 6/10, Train Loss: 0.1276, Accuracy: 0.9228, F1 Micro: 0.775, F1 Macro: 0.6536\n",
      "Epoch 7/10, Train Loss: 0.1077, Accuracy: 0.9208, F1 Micro: 0.7674, F1 Macro: 0.6385\n",
      "Epoch 8/10, Train Loss: 0.0912, Accuracy: 0.9239, F1 Micro: 0.783, F1 Macro: 0.6787\n",
      "Epoch 9/10, Train Loss: 0.0788, Accuracy: 0.9218, F1 Micro: 0.7741, F1 Macro: 0.6757\n",
      "Epoch 10/10, Train Loss: 0.0643, Accuracy: 0.9188, F1 Micro: 0.7736, F1 Macro: 0.6865\n",
      "Best result for 8617 samples: F1 Micro: 0.783\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.88      0.86      1142\n",
      "      Abusive       0.89      0.92      0.91      1026\n",
      "HS_Individual       0.71      0.77      0.74       723\n",
      "     HS_Group       0.75      0.68      0.72       419\n",
      "  HS_Religion       0.72      0.68      0.70       177\n",
      "      HS_Race       0.86      0.70      0.77       119\n",
      "  HS_Physical       0.79      0.14      0.23        80\n",
      "    HS_Gender       0.81      0.22      0.34        60\n",
      "     HS_Other       0.75      0.82      0.78       746\n",
      "      HS_Weak       0.70      0.74      0.72       685\n",
      "  HS_Moderate       0.68      0.60      0.64       352\n",
      "    HS_Strong       0.80      0.69      0.74       105\n",
      "\n",
      "    micro avg       0.78      0.79      0.78      5634\n",
      "    macro avg       0.77      0.65      0.68      5634\n",
      " weighted avg       0.78      0.79      0.78      5634\n",
      "  samples avg       0.46      0.45      0.44      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 26.19485092163086\n",
      "Samples above threshold: 192\n",
      "Acquired samples: 200\n",
      "Sampling duration: 10.847767114639282 seconds\n",
      "\n",
      "Fold 3 - New train size: 8817\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 8817 samples\n",
      "Epoch 1/10, Train Loss: 0.3873, Accuracy: 0.8844, F1 Micro: 0.5798, F1 Macro: 0.3049\n",
      "Epoch 2/10, Train Loss: 0.2709, Accuracy: 0.9092, F1 Micro: 0.7227, F1 Macro: 0.5076\n",
      "Epoch 3/10, Train Loss: 0.2227, Accuracy: 0.9165, F1 Micro: 0.75, F1 Macro: 0.5729\n",
      "Epoch 4/10, Train Loss: 0.184, Accuracy: 0.9199, F1 Micro: 0.7685, F1 Macro: 0.6094\n",
      "Epoch 5/10, Train Loss: 0.1549, Accuracy: 0.9215, F1 Micro: 0.7734, F1 Macro: 0.6415\n",
      "Epoch 6/10, Train Loss: 0.1285, Accuracy: 0.9236, F1 Micro: 0.7656, F1 Macro: 0.653\n",
      "Epoch 7/10, Train Loss: 0.1081, Accuracy: 0.9203, F1 Micro: 0.7706, F1 Macro: 0.6521\n",
      "Epoch 8/10, Train Loss: 0.0953, Accuracy: 0.9242, F1 Micro: 0.7784, F1 Macro: 0.6681\n",
      "Epoch 9/10, Train Loss: 0.0787, Accuracy: 0.9221, F1 Micro: 0.7651, F1 Macro: 0.6579\n",
      "Epoch 10/10, Train Loss: 0.0687, Accuracy: 0.9225, F1 Micro: 0.7772, F1 Macro: 0.6787\n",
      "Best result for 8817 samples: F1 Micro: 0.7784\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.86      0.86      1142\n",
      "      Abusive       0.91      0.91      0.91      1026\n",
      "HS_Individual       0.77      0.70      0.73       723\n",
      "     HS_Group       0.70      0.72      0.71       419\n",
      "  HS_Religion       0.79      0.62      0.69       177\n",
      "      HS_Race       0.86      0.57      0.69       119\n",
      "  HS_Physical       0.65      0.14      0.23        80\n",
      "    HS_Gender       0.71      0.20      0.31        60\n",
      "     HS_Other       0.76      0.81      0.78       746\n",
      "      HS_Weak       0.74      0.67      0.71       685\n",
      "  HS_Moderate       0.64      0.67      0.66       352\n",
      "    HS_Strong       0.82      0.70      0.75       105\n",
      "\n",
      "    micro avg       0.80      0.76      0.78      5634\n",
      "    macro avg       0.77      0.63      0.67      5634\n",
      " weighted avg       0.79      0.76      0.77      5634\n",
      "  samples avg       0.44      0.44      0.43      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 33.7052864074707\n",
      "Samples above threshold: 172\n",
      "Acquired samples: 200\n",
      "Sampling duration: 9.969449520111084 seconds\n",
      "\n",
      "Fold 3 - New train size: 9017\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 9017 samples\n",
      "Epoch 1/10, Train Loss: 0.3879, Accuracy: 0.8889, F1 Micro: 0.6514, F1 Macro: 0.3436\n",
      "Epoch 2/10, Train Loss: 0.2644, Accuracy: 0.9102, F1 Micro: 0.7346, F1 Macro: 0.5569\n",
      "Epoch 3/10, Train Loss: 0.2145, Accuracy: 0.9159, F1 Micro: 0.7539, F1 Macro: 0.5814\n",
      "Epoch 4/10, Train Loss: 0.1797, Accuracy: 0.917, F1 Micro: 0.76, F1 Macro: 0.6101\n",
      "Epoch 5/10, Train Loss: 0.151, Accuracy: 0.9229, F1 Micro: 0.7689, F1 Macro: 0.6262\n",
      "Epoch 6/10, Train Loss: 0.1238, Accuracy: 0.9213, F1 Micro: 0.7721, F1 Macro: 0.6451\n",
      "Epoch 7/10, Train Loss: 0.1028, Accuracy: 0.9221, F1 Micro: 0.7694, F1 Macro: 0.6624\n",
      "Epoch 8/10, Train Loss: 0.0882, Accuracy: 0.925, F1 Micro: 0.7736, F1 Macro: 0.6741\n",
      "Epoch 9/10, Train Loss: 0.0804, Accuracy: 0.9239, F1 Micro: 0.7771, F1 Macro: 0.6875\n",
      "Epoch 10/10, Train Loss: 0.0671, Accuracy: 0.9192, F1 Micro: 0.777, F1 Macro: 0.7086\n",
      "Best result for 9017 samples: F1 Micro: 0.7771\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.85      0.85      1142\n",
      "      Abusive       0.90      0.91      0.90      1026\n",
      "HS_Individual       0.76      0.68      0.72       723\n",
      "     HS_Group       0.71      0.73      0.72       419\n",
      "  HS_Religion       0.77      0.62      0.69       177\n",
      "      HS_Race       0.81      0.73      0.77       119\n",
      "  HS_Physical       0.88      0.17      0.29        80\n",
      "    HS_Gender       0.70      0.32      0.44        60\n",
      "     HS_Other       0.78      0.79      0.78       746\n",
      "      HS_Weak       0.72      0.66      0.69       685\n",
      "  HS_Moderate       0.66      0.69      0.67       352\n",
      "    HS_Strong       0.83      0.65      0.73       105\n",
      "\n",
      "    micro avg       0.80      0.76      0.78      5634\n",
      "    macro avg       0.78      0.65      0.69      5634\n",
      " weighted avg       0.79      0.76      0.77      5634\n",
      "  samples avg       0.45      0.44      0.43      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 22.665655517578124\n",
      "Samples above threshold: 152\n",
      "Acquired samples: 200\n",
      "Sampling duration: 9.026435375213623 seconds\n",
      "\n",
      "Fold 3 - New train size: 9217\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 9217 samples\n",
      "Epoch 1/10, Train Loss: 0.3856, Accuracy: 0.8878, F1 Micro: 0.6051, F1 Macro: 0.3209\n",
      "Epoch 2/10, Train Loss: 0.2653, Accuracy: 0.9094, F1 Micro: 0.7288, F1 Macro: 0.565\n",
      "Epoch 3/10, Train Loss: 0.2167, Accuracy: 0.9181, F1 Micro: 0.755, F1 Macro: 0.5962\n",
      "Epoch 4/10, Train Loss: 0.1815, Accuracy: 0.9211, F1 Micro: 0.77, F1 Macro: 0.615\n",
      "Epoch 5/10, Train Loss: 0.1487, Accuracy: 0.9213, F1 Micro: 0.7776, F1 Macro: 0.6442\n",
      "Epoch 6/10, Train Loss: 0.1227, Accuracy: 0.9215, F1 Micro: 0.7754, F1 Macro: 0.6575\n",
      "Epoch 7/10, Train Loss: 0.1061, Accuracy: 0.9199, F1 Micro: 0.7726, F1 Macro: 0.6569\n",
      "Epoch 8/10, Train Loss: 0.0909, Accuracy: 0.9241, F1 Micro: 0.7658, F1 Macro: 0.665\n",
      "Epoch 9/10, Train Loss: 0.0762, Accuracy: 0.9226, F1 Micro: 0.7754, F1 Macro: 0.6885\n",
      "Epoch 10/10, Train Loss: 0.0684, Accuracy: 0.9234, F1 Micro: 0.783, F1 Macro: 0.7067\n",
      "Best result for 9217 samples: F1 Micro: 0.783\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.88      0.86      1142\n",
      "      Abusive       0.88      0.93      0.91      1026\n",
      "HS_Individual       0.72      0.75      0.73       723\n",
      "     HS_Group       0.70      0.72      0.71       419\n",
      "  HS_Religion       0.75      0.63      0.68       177\n",
      "      HS_Race       0.80      0.73      0.76       119\n",
      "  HS_Physical       0.80      0.25      0.38        80\n",
      "    HS_Gender       0.77      0.45      0.57        60\n",
      "     HS_Other       0.76      0.81      0.78       746\n",
      "      HS_Weak       0.70      0.73      0.71       685\n",
      "  HS_Moderate       0.63      0.68      0.66       352\n",
      "    HS_Strong       0.84      0.64      0.72       105\n",
      "\n",
      "    micro avg       0.77      0.79      0.78      5634\n",
      "    macro avg       0.77      0.68      0.71      5634\n",
      " weighted avg       0.78      0.79      0.78      5634\n",
      "  samples avg       0.46      0.45      0.44      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 33.71543731689453\n",
      "Samples above threshold: 132\n",
      "Acquired samples: 1\n",
      "Sampling duration: 8.129253625869751 seconds\n",
      "\n",
      "Fold 3 - New train size: 9218\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 9218 samples\n",
      "Epoch 1/10, Train Loss: 0.3859, Accuracy: 0.886, F1 Micro: 0.6029, F1 Macro: 0.2983\n",
      "Epoch 2/10, Train Loss: 0.2634, Accuracy: 0.9095, F1 Micro: 0.7079, F1 Macro: 0.504\n",
      "Epoch 3/10, Train Loss: 0.2119, Accuracy: 0.9161, F1 Micro: 0.7384, F1 Macro: 0.5605\n",
      "Epoch 4/10, Train Loss: 0.1797, Accuracy: 0.9158, F1 Micro: 0.7638, F1 Macro: 0.6124\n",
      "Epoch 5/10, Train Loss: 0.1539, Accuracy: 0.9212, F1 Micro: 0.7733, F1 Macro: 0.6341\n",
      "Epoch 6/10, Train Loss: 0.1293, Accuracy: 0.9209, F1 Micro: 0.7756, F1 Macro: 0.6602\n",
      "Epoch 7/10, Train Loss: 0.1052, Accuracy: 0.9223, F1 Micro: 0.7766, F1 Macro: 0.6524\n",
      "Epoch 8/10, Train Loss: 0.0901, Accuracy: 0.922, F1 Micro: 0.7734, F1 Macro: 0.6811\n",
      "Epoch 9/10, Train Loss: 0.0805, Accuracy: 0.9209, F1 Micro: 0.7793, F1 Macro: 0.7101\n",
      "Epoch 10/10, Train Loss: 0.0689, Accuracy: 0.9276, F1 Micro: 0.7858, F1 Macro: 0.7085\n",
      "Best result for 9218 samples: F1 Micro: 0.7858\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.87      0.84      0.86      1142\n",
      "      Abusive       0.92      0.91      0.91      1026\n",
      "HS_Individual       0.75      0.73      0.74       723\n",
      "     HS_Group       0.75      0.67      0.71       419\n",
      "  HS_Religion       0.77      0.60      0.68       177\n",
      "      HS_Race       0.88      0.66      0.75       119\n",
      "  HS_Physical       0.77      0.30      0.43        80\n",
      "    HS_Gender       0.77      0.40      0.53        60\n",
      "     HS_Other       0.79      0.78      0.79       746\n",
      "      HS_Weak       0.73      0.70      0.72       685\n",
      "  HS_Moderate       0.70      0.59      0.64       352\n",
      "    HS_Strong       0.82      0.70      0.75       105\n",
      "\n",
      "    micro avg       0.81      0.76      0.79      5634\n",
      "    macro avg       0.79      0.66      0.71      5634\n",
      " weighted avg       0.81      0.76      0.78      5634\n",
      "  samples avg       0.45      0.43      0.43      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 20.34574337005615\n",
      "Samples above threshold: 132\n",
      "Acquired samples: 200\n",
      "Sampling duration: 7.860239505767822 seconds\n",
      "\n",
      "Fold 3 - New train size: 9418\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 9418 samples\n",
      "Epoch 1/10, Train Loss: 0.3846, Accuracy: 0.8877, F1 Micro: 0.6065, F1 Macro: 0.3155\n",
      "Epoch 2/10, Train Loss: 0.2613, Accuracy: 0.9022, F1 Micro: 0.7182, F1 Macro: 0.4531\n",
      "Epoch 3/10, Train Loss: 0.2153, Accuracy: 0.9166, F1 Micro: 0.7563, F1 Macro: 0.5922\n",
      "Epoch 4/10, Train Loss: 0.1779, Accuracy: 0.9217, F1 Micro: 0.7601, F1 Macro: 0.5963\n",
      "Epoch 5/10, Train Loss: 0.1492, Accuracy: 0.9217, F1 Micro: 0.7696, F1 Macro: 0.6366\n",
      "Epoch 6/10, Train Loss: 0.1307, Accuracy: 0.9243, F1 Micro: 0.7757, F1 Macro: 0.6482\n",
      "Epoch 7/10, Train Loss: 0.1053, Accuracy: 0.9208, F1 Micro: 0.7705, F1 Macro: 0.6641\n",
      "Epoch 8/10, Train Loss: 0.0894, Accuracy: 0.9231, F1 Micro: 0.7804, F1 Macro: 0.6959\n",
      "Epoch 9/10, Train Loss: 0.0779, Accuracy: 0.9221, F1 Micro: 0.7706, F1 Macro: 0.6656\n",
      "Epoch 10/10, Train Loss: 0.0692, Accuracy: 0.9187, F1 Micro: 0.774, F1 Macro: 0.6935\n",
      "Best result for 9418 samples: F1 Micro: 0.7804\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.87      0.85      1142\n",
      "      Abusive       0.89      0.92      0.90      1026\n",
      "HS_Individual       0.74      0.72      0.73       723\n",
      "     HS_Group       0.70      0.75      0.72       419\n",
      "  HS_Religion       0.73      0.65      0.69       177\n",
      "      HS_Race       0.79      0.75      0.77       119\n",
      "  HS_Physical       0.75      0.23      0.35        80\n",
      "    HS_Gender       0.70      0.35      0.47        60\n",
      "     HS_Other       0.76      0.80      0.78       746\n",
      "      HS_Weak       0.72      0.70      0.71       685\n",
      "  HS_Moderate       0.63      0.71      0.67       352\n",
      "    HS_Strong       0.82      0.64      0.72       105\n",
      "\n",
      "    micro avg       0.78      0.78      0.78      5634\n",
      "    macro avg       0.75      0.67      0.70      5634\n",
      " weighted avg       0.78      0.78      0.78      5634\n",
      "  samples avg       0.45      0.44      0.43      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 18.470418548583986\n",
      "Samples above threshold: 112\n",
      "Acquired samples: 200\n",
      "Sampling duration: 6.892551422119141 seconds\n",
      "\n",
      "Fold 3 - New train size: 9618\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 9618 samples\n",
      "Epoch 1/10, Train Loss: 0.3817, Accuracy: 0.8836, F1 Micro: 0.5626, F1 Macro: 0.2944\n",
      "Epoch 2/10, Train Loss: 0.2641, Accuracy: 0.9072, F1 Micro: 0.7206, F1 Macro: 0.498\n",
      "Epoch 3/10, Train Loss: 0.2174, Accuracy: 0.9169, F1 Micro: 0.7485, F1 Macro: 0.5821\n",
      "Epoch 4/10, Train Loss: 0.1782, Accuracy: 0.9164, F1 Micro: 0.761, F1 Macro: 0.6143\n",
      "Epoch 5/10, Train Loss: 0.1495, Accuracy: 0.9247, F1 Micro: 0.78, F1 Macro: 0.6407\n",
      "Epoch 6/10, Train Loss: 0.1232, Accuracy: 0.9204, F1 Micro: 0.7768, F1 Macro: 0.6493\n",
      "Epoch 7/10, Train Loss: 0.1085, Accuracy: 0.9241, F1 Micro: 0.7812, F1 Macro: 0.6744\n",
      "Epoch 8/10, Train Loss: 0.0871, Accuracy: 0.9228, F1 Micro: 0.7787, F1 Macro: 0.6758\n",
      "Epoch 9/10, Train Loss: 0.0776, Accuracy: 0.9226, F1 Micro: 0.7774, F1 Macro: 0.7004\n",
      "Epoch 10/10, Train Loss: 0.0675, Accuracy: 0.9255, F1 Micro: 0.7782, F1 Macro: 0.7042\n",
      "Best result for 9618 samples: F1 Micro: 0.7812\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.88      0.85      1142\n",
      "      Abusive       0.92      0.89      0.90      1026\n",
      "HS_Individual       0.74      0.73      0.74       723\n",
      "     HS_Group       0.73      0.72      0.73       419\n",
      "  HS_Religion       0.77      0.64      0.70       177\n",
      "      HS_Race       0.80      0.67      0.73       119\n",
      "  HS_Physical       0.62      0.12      0.21        80\n",
      "    HS_Gender       0.86      0.20      0.32        60\n",
      "     HS_Other       0.75      0.81      0.78       746\n",
      "      HS_Weak       0.72      0.72      0.72       685\n",
      "  HS_Moderate       0.67      0.67      0.67       352\n",
      "    HS_Strong       0.80      0.70      0.75       105\n",
      "\n",
      "    micro avg       0.79      0.78      0.78      5634\n",
      "    macro avg       0.77      0.65      0.67      5634\n",
      " weighted avg       0.79      0.78      0.78      5634\n",
      "  samples avg       0.44      0.44      0.42      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 23.60845355987549\n",
      "Samples above threshold: 92\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.801077604293823 seconds\n",
      "\n",
      "Fold 3 - New train size: 9818\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 9818 samples\n",
      "Epoch 1/10, Train Loss: 0.3792, Accuracy: 0.8911, F1 Micro: 0.6566, F1 Macro: 0.3805\n",
      "Epoch 2/10, Train Loss: 0.2602, Accuracy: 0.9101, F1 Micro: 0.7132, F1 Macro: 0.5548\n",
      "Epoch 3/10, Train Loss: 0.2138, Accuracy: 0.9063, F1 Micro: 0.752, F1 Macro: 0.5977\n",
      "Epoch 4/10, Train Loss: 0.1765, Accuracy: 0.9207, F1 Micro: 0.7668, F1 Macro: 0.6078\n",
      "Epoch 5/10, Train Loss: 0.1475, Accuracy: 0.9212, F1 Micro: 0.775, F1 Macro: 0.6249\n",
      "Epoch 6/10, Train Loss: 0.1234, Accuracy: 0.9227, F1 Micro: 0.7768, F1 Macro: 0.65\n",
      "Epoch 7/10, Train Loss: 0.1063, Accuracy: 0.9231, F1 Micro: 0.7739, F1 Macro: 0.6722\n",
      "Epoch 8/10, Train Loss: 0.0856, Accuracy: 0.9234, F1 Micro: 0.7803, F1 Macro: 0.6925\n",
      "Epoch 9/10, Train Loss: 0.0774, Accuracy: 0.9235, F1 Micro: 0.7824, F1 Macro: 0.7046\n",
      "Epoch 10/10, Train Loss: 0.067, Accuracy: 0.9251, F1 Micro: 0.7832, F1 Macro: 0.6942\n",
      "Best result for 9818 samples: F1 Micro: 0.7832\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.86      0.86      1142\n",
      "      Abusive       0.90      0.93      0.91      1026\n",
      "HS_Individual       0.71      0.78      0.74       723\n",
      "     HS_Group       0.76      0.59      0.67       419\n",
      "  HS_Religion       0.76      0.64      0.70       177\n",
      "      HS_Race       0.86      0.66      0.75       119\n",
      "  HS_Physical       0.76      0.28      0.40        80\n",
      "    HS_Gender       0.68      0.32      0.43        60\n",
      "     HS_Other       0.78      0.81      0.79       746\n",
      "      HS_Weak       0.69      0.76      0.72       685\n",
      "  HS_Moderate       0.71      0.54      0.61       352\n",
      "    HS_Strong       0.83      0.68      0.74       105\n",
      "\n",
      "    micro avg       0.79      0.77      0.78      5634\n",
      "    macro avg       0.77      0.65      0.69      5634\n",
      " weighted avg       0.79      0.77      0.78      5634\n",
      "  samples avg       0.45      0.44      0.43      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 17.751388931274416\n",
      "Samples above threshold: 72\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.902477264404297 seconds\n",
      "\n",
      "Fold 3 - New train size: 10018\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 10018 samples\n",
      "Epoch 1/10, Train Loss: 0.3768, Accuracy: 0.8903, F1 Micro: 0.6617, F1 Macro: 0.3633\n",
      "Epoch 2/10, Train Loss: 0.2557, Accuracy: 0.9095, F1 Micro: 0.7208, F1 Macro: 0.5232\n",
      "Epoch 3/10, Train Loss: 0.2047, Accuracy: 0.9171, F1 Micro: 0.7569, F1 Macro: 0.6056\n",
      "Epoch 4/10, Train Loss: 0.1763, Accuracy: 0.9161, F1 Micro: 0.7708, F1 Macro: 0.615\n",
      "Epoch 5/10, Train Loss: 0.1416, Accuracy: 0.9246, F1 Micro: 0.7736, F1 Macro: 0.6259\n",
      "Epoch 6/10, Train Loss: 0.1202, Accuracy: 0.9271, F1 Micro: 0.7866, F1 Macro: 0.6695\n",
      "Epoch 7/10, Train Loss: 0.1056, Accuracy: 0.9246, F1 Micro: 0.7791, F1 Macro: 0.6635\n",
      "Epoch 8/10, Train Loss: 0.0852, Accuracy: 0.9242, F1 Micro: 0.7774, F1 Macro: 0.67\n",
      "Epoch 9/10, Train Loss: 0.0716, Accuracy: 0.923, F1 Micro: 0.7802, F1 Macro: 0.6964\n",
      "Epoch 10/10, Train Loss: 0.0643, Accuracy: 0.9215, F1 Micro: 0.7787, F1 Macro: 0.6952\n",
      "Best result for 10018 samples: F1 Micro: 0.7866\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.87      0.86      1142\n",
      "      Abusive       0.90      0.91      0.90      1026\n",
      "HS_Individual       0.78      0.72      0.75       723\n",
      "     HS_Group       0.72      0.73      0.72       419\n",
      "  HS_Religion       0.79      0.59      0.67       177\n",
      "      HS_Race       0.75      0.80      0.77       119\n",
      "  HS_Physical       0.82      0.11      0.20        80\n",
      "    HS_Gender       0.82      0.15      0.25        60\n",
      "     HS_Other       0.78      0.78      0.78       746\n",
      "      HS_Weak       0.76      0.70      0.73       685\n",
      "  HS_Moderate       0.66      0.67      0.66       352\n",
      "    HS_Strong       0.82      0.65      0.72       105\n",
      "\n",
      "    micro avg       0.80      0.77      0.79      5634\n",
      "    macro avg       0.79      0.64      0.67      5634\n",
      " weighted avg       0.80      0.77      0.78      5634\n",
      "  samples avg       0.45      0.44      0.43      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 28.27075786590576\n",
      "Samples above threshold: 52\n",
      "Acquired samples: 200\n",
      "Sampling duration: 3.8703293800354004 seconds\n",
      "\n",
      "Fold 3 - New train size: 10218\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 10218 samples\n",
      "Epoch 1/10, Train Loss: 0.3748, Accuracy: 0.8884, F1 Micro: 0.6174, F1 Macro: 0.3213\n",
      "Epoch 2/10, Train Loss: 0.2514, Accuracy: 0.9096, F1 Micro: 0.7344, F1 Macro: 0.5423\n",
      "Epoch 3/10, Train Loss: 0.2062, Accuracy: 0.9191, F1 Micro: 0.7588, F1 Macro: 0.5824\n",
      "Epoch 4/10, Train Loss: 0.1766, Accuracy: 0.9243, F1 Micro: 0.773, F1 Macro: 0.6081\n",
      "Epoch 5/10, Train Loss: 0.1449, Accuracy: 0.9243, F1 Micro: 0.7756, F1 Macro: 0.6514\n",
      "Epoch 6/10, Train Loss: 0.1229, Accuracy: 0.9218, F1 Micro: 0.7733, F1 Macro: 0.6426\n",
      "Epoch 7/10, Train Loss: 0.0994, Accuracy: 0.9239, F1 Micro: 0.7746, F1 Macro: 0.6572\n",
      "Epoch 8/10, Train Loss: 0.0823, Accuracy: 0.9233, F1 Micro: 0.7796, F1 Macro: 0.6925\n",
      "Epoch 9/10, Train Loss: 0.0729, Accuracy: 0.9233, F1 Micro: 0.7815, F1 Macro: 0.6872\n",
      "Epoch 10/10, Train Loss: 0.0639, Accuracy: 0.9245, F1 Micro: 0.7779, F1 Macro: 0.6964\n",
      "Best result for 10218 samples: F1 Micro: 0.7815\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.87      0.86      1142\n",
      "      Abusive       0.88      0.94      0.91      1026\n",
      "HS_Individual       0.71      0.77      0.74       723\n",
      "     HS_Group       0.74      0.67      0.70       419\n",
      "  HS_Religion       0.73      0.63      0.67       177\n",
      "      HS_Race       0.82      0.67      0.74       119\n",
      "  HS_Physical       0.72      0.23      0.34        80\n",
      "    HS_Gender       0.75      0.30      0.43        60\n",
      "     HS_Other       0.76      0.81      0.78       746\n",
      "      HS_Weak       0.68      0.74      0.71       685\n",
      "  HS_Moderate       0.68      0.62      0.65       352\n",
      "    HS_Strong       0.85      0.61      0.71       105\n",
      "\n",
      "    micro avg       0.78      0.78      0.78      5634\n",
      "    macro avg       0.76      0.65      0.69      5634\n",
      " weighted avg       0.78      0.78      0.78      5634\n",
      "  samples avg       0.45      0.45      0.44      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 17.24179744720459\n",
      "Samples above threshold: 32\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.671592950820923 seconds\n",
      "\n",
      "Fold 3 - New train size: 10418\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 10418 samples\n",
      "Epoch 1/10, Train Loss: 0.3681, Accuracy: 0.8894, F1 Micro: 0.6137, F1 Macro: 0.3482\n",
      "Epoch 2/10, Train Loss: 0.2499, Accuracy: 0.9107, F1 Micro: 0.7227, F1 Macro: 0.5099\n",
      "Epoch 3/10, Train Loss: 0.2034, Accuracy: 0.9165, F1 Micro: 0.7599, F1 Macro: 0.6042\n",
      "Epoch 4/10, Train Loss: 0.1676, Accuracy: 0.9218, F1 Micro: 0.7742, F1 Macro: 0.6213\n",
      "Epoch 5/10, Train Loss: 0.1412, Accuracy: 0.9253, F1 Micro: 0.769, F1 Macro: 0.6218\n",
      "Epoch 6/10, Train Loss: 0.1223, Accuracy: 0.9209, F1 Micro: 0.7709, F1 Macro: 0.6526\n",
      "Epoch 7/10, Train Loss: 0.0996, Accuracy: 0.9203, F1 Micro: 0.7768, F1 Macro: 0.6643\n",
      "Epoch 8/10, Train Loss: 0.0838, Accuracy: 0.9236, F1 Micro: 0.7811, F1 Macro: 0.6679\n",
      "Epoch 9/10, Train Loss: 0.0675, Accuracy: 0.9243, F1 Micro: 0.7798, F1 Macro: 0.6943\n",
      "Epoch 10/10, Train Loss: 0.06, Accuracy: 0.9236, F1 Micro: 0.7792, F1 Macro: 0.6977\n",
      "Best result for 10418 samples: F1 Micro: 0.7811\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.88      0.86      1142\n",
      "      Abusive       0.89      0.92      0.91      1026\n",
      "HS_Individual       0.72      0.76      0.74       723\n",
      "     HS_Group       0.72      0.69      0.71       419\n",
      "  HS_Religion       0.76      0.56      0.64       177\n",
      "      HS_Race       0.86      0.60      0.70       119\n",
      "  HS_Physical       0.79      0.14      0.23        80\n",
      "    HS_Gender       0.68      0.22      0.33        60\n",
      "     HS_Other       0.75      0.83      0.79       746\n",
      "      HS_Weak       0.70      0.74      0.72       685\n",
      "  HS_Moderate       0.66      0.62      0.64       352\n",
      "    HS_Strong       0.82      0.68      0.74       105\n",
      "\n",
      "    micro avg       0.78      0.78      0.78      5634\n",
      "    macro avg       0.77      0.64      0.67      5634\n",
      " weighted avg       0.78      0.78      0.77      5634\n",
      "  samples avg       0.46      0.45      0.44      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 17.62193489074707\n",
      "Samples above threshold: 13\n",
      "Acquired samples: 117\n",
      "Sampling duration: 1.8013908863067627 seconds\n",
      "\n",
      "Fold 3 - New train size: 10535\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 10535 samples\n",
      "Epoch 1/10, Train Loss: 0.3648, Accuracy: 0.8907, F1 Micro: 0.6458, F1 Macro: 0.3788\n",
      "Epoch 2/10, Train Loss: 0.2454, Accuracy: 0.9111, F1 Micro: 0.7344, F1 Macro: 0.5373\n",
      "Epoch 3/10, Train Loss: 0.201, Accuracy: 0.9182, F1 Micro: 0.7603, F1 Macro: 0.5952\n",
      "Epoch 4/10, Train Loss: 0.1681, Accuracy: 0.924, F1 Micro: 0.7731, F1 Macro: 0.6153\n",
      "Epoch 5/10, Train Loss: 0.1407, Accuracy: 0.9218, F1 Micro: 0.7763, F1 Macro: 0.6365\n",
      "Epoch 6/10, Train Loss: 0.1189, Accuracy: 0.9231, F1 Micro: 0.7803, F1 Macro: 0.6657\n",
      "Epoch 7/10, Train Loss: 0.0954, Accuracy: 0.9235, F1 Micro: 0.7796, F1 Macro: 0.6736\n",
      "Epoch 8/10, Train Loss: 0.0805, Accuracy: 0.9225, F1 Micro: 0.7791, F1 Macro: 0.697\n",
      "Epoch 9/10, Train Loss: 0.0713, Accuracy: 0.9231, F1 Micro: 0.7805, F1 Macro: 0.6953\n",
      "Epoch 10/10, Train Loss: 0.0618, Accuracy: 0.9203, F1 Micro: 0.7749, F1 Macro: 0.6971\n",
      "Best result for 10535 samples: F1 Micro: 0.7805\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.88      0.85      1142\n",
      "      Abusive       0.90      0.93      0.91      1026\n",
      "HS_Individual       0.70      0.76      0.73       723\n",
      "     HS_Group       0.72      0.66      0.69       419\n",
      "  HS_Religion       0.77      0.60      0.67       177\n",
      "      HS_Race       0.85      0.69      0.76       119\n",
      "  HS_Physical       0.83      0.24      0.37        80\n",
      "    HS_Gender       0.72      0.35      0.47        60\n",
      "     HS_Other       0.75      0.82      0.79       746\n",
      "      HS_Weak       0.69      0.74      0.71       685\n",
      "  HS_Moderate       0.66      0.59      0.63       352\n",
      "    HS_Strong       0.83      0.69      0.75       105\n",
      "\n",
      "    micro avg       0.78      0.78      0.78      5634\n",
      "    macro avg       0.77      0.66      0.70      5634\n",
      " weighted avg       0.78      0.78      0.78      5634\n",
      "  samples avg       0.46      0.45      0.44      5634\n",
      "\n",
      "\n",
      "FOLD 3 COMPLETED in 5736.01 seconds\n",
      "===============================================\n",
      "STARTING FOLD 4/5\n",
      "===============================================\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 658 samples\n",
      "Epoch 1/10, Train Loss: 0.5939, Accuracy: 0.8336, F1 Micro: 0.1027, F1 Macro: 0.041\n",
      "Epoch 2/10, Train Loss: 0.4543, Accuracy: 0.8308, F1 Micro: 0.0278, F1 Macro: 0.0116\n",
      "Epoch 3/10, Train Loss: 0.3982, Accuracy: 0.8346, F1 Micro: 0.0749, F1 Macro: 0.028\n",
      "Epoch 4/10, Train Loss: 0.3658, Accuracy: 0.8368, F1 Micro: 0.1066, F1 Macro: 0.0373\n",
      "Epoch 5/10, Train Loss: 0.354, Accuracy: 0.8477, F1 Micro: 0.2387, F1 Macro: 0.0822\n",
      "Epoch 6/10, Train Loss: 0.3471, Accuracy: 0.858, F1 Micro: 0.3466, F1 Macro: 0.1245\n",
      "Epoch 7/10, Train Loss: 0.3256, Accuracy: 0.8668, F1 Micro: 0.4318, F1 Macro: 0.1709\n",
      "Epoch 8/10, Train Loss: 0.3059, Accuracy: 0.8763, F1 Micro: 0.5264, F1 Macro: 0.231\n",
      "Epoch 9/10, Train Loss: 0.2677, Accuracy: 0.8784, F1 Micro: 0.5723, F1 Macro: 0.2659\n",
      "Epoch 10/10, Train Loss: 0.262, Accuracy: 0.881, F1 Micro: 0.5895, F1 Macro: 0.2937\n",
      "Best result for 658 samples: F1 Micro: 0.5895\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.79      0.76      0.78      1107\n",
      "      Abusive       0.82      0.73      0.78      1030\n",
      "HS_Individual       0.62      0.49      0.55       729\n",
      "     HS_Group       0.61      0.13      0.21       378\n",
      "  HS_Religion       0.00      0.00      0.00       167\n",
      "      HS_Race       0.00      0.00      0.00        88\n",
      "  HS_Physical       0.00      0.00      0.00        74\n",
      "    HS_Gender       0.00      0.00      0.00        75\n",
      "     HS_Other       0.65      0.60      0.62       744\n",
      "      HS_Weak       0.59      0.42      0.49       690\n",
      "  HS_Moderate       0.51      0.06      0.10       338\n",
      "    HS_Strong       0.00      0.00      0.00        79\n",
      "\n",
      "    micro avg       0.72      0.50      0.59      5499\n",
      "    macro avg       0.38      0.27      0.29      5499\n",
      " weighted avg       0.63      0.50      0.54      5499\n",
      "  samples avg       0.38      0.29      0.30      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 29.570524597167967\n",
      "Samples above threshold: 988\n",
      "Acquired samples: 988\n",
      "Sampling duration: 52.76541328430176 seconds\n",
      "\n",
      "Fold 4 - New train size: 1646\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 1646 samples\n",
      "Epoch 1/10, Train Loss: 0.4835, Accuracy: 0.8295, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.3194, Accuracy: 0.8295, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.299, Accuracy: 0.833, F1 Micro: 0.0423, F1 Macro: 0.0173\n",
      "Epoch 4/10, Train Loss: 0.2591, Accuracy: 0.8658, F1 Micro: 0.4274, F1 Macro: 0.1579\n",
      "Epoch 5/10, Train Loss: 0.2239, Accuracy: 0.873, F1 Micro: 0.4888, F1 Macro: 0.2345\n",
      "Epoch 6/10, Train Loss: 0.2034, Accuracy: 0.8799, F1 Micro: 0.5815, F1 Macro: 0.3593\n",
      "Epoch 7/10, Train Loss: 0.177, Accuracy: 0.8792, F1 Micro: 0.5407, F1 Macro: 0.3132\n",
      "Epoch 8/10, Train Loss: 0.1574, Accuracy: 0.8872, F1 Micro: 0.6305, F1 Macro: 0.3925\n",
      "Epoch 9/10, Train Loss: 0.1442, Accuracy: 0.8863, F1 Micro: 0.6123, F1 Macro: 0.3886\n",
      "Epoch 10/10, Train Loss: 0.132, Accuracy: 0.8893, F1 Micro: 0.6271, F1 Macro: 0.4151\n",
      "Best result for 1646 samples: F1 Micro: 0.6305\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.80      0.80      1107\n",
      "      Abusive       0.82      0.78      0.80      1030\n",
      "HS_Individual       0.62      0.56      0.59       729\n",
      "     HS_Group       0.64      0.33      0.44       378\n",
      "  HS_Religion       0.78      0.04      0.08       167\n",
      "      HS_Race       0.79      0.17      0.28        88\n",
      "  HS_Physical       0.00      0.00      0.00        74\n",
      "    HS_Gender       0.00      0.00      0.00        75\n",
      "     HS_Other       0.64      0.64      0.64       744\n",
      "      HS_Weak       0.59      0.49      0.54       690\n",
      "  HS_Moderate       0.64      0.07      0.13       338\n",
      "    HS_Strong       0.81      0.28      0.42        79\n",
      "\n",
      "    micro avg       0.71      0.56      0.63      5499\n",
      "    macro avg       0.59      0.35      0.39      5499\n",
      " weighted avg       0.69      0.56      0.59      5499\n",
      "  samples avg       0.38      0.32      0.32      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 37.68176536560059\n",
      "Samples above threshold: 889\n",
      "Acquired samples: 889\n",
      "Sampling duration: 46.5984947681427 seconds\n",
      "\n",
      "Fold 4 - New train size: 2535\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 2535 samples\n",
      "Epoch 1/10, Train Loss: 0.492, Accuracy: 0.8485, F1 Micro: 0.4219, F1 Macro: 0.1319\n",
      "Epoch 2/10, Train Loss: 0.3555, Accuracy: 0.8707, F1 Micro: 0.551, F1 Macro: 0.2537\n",
      "Epoch 3/10, Train Loss: 0.3006, Accuracy: 0.8823, F1 Micro: 0.593, F1 Macro: 0.3823\n",
      "Epoch 4/10, Train Loss: 0.2584, Accuracy: 0.8907, F1 Micro: 0.6593, F1 Macro: 0.4594\n",
      "Epoch 5/10, Train Loss: 0.2308, Accuracy: 0.8961, F1 Micro: 0.658, F1 Macro: 0.4962\n",
      "Epoch 6/10, Train Loss: 0.2095, Accuracy: 0.9031, F1 Micro: 0.6836, F1 Macro: 0.5263\n",
      "Epoch 7/10, Train Loss: 0.1857, Accuracy: 0.9027, F1 Micro: 0.6821, F1 Macro: 0.5324\n",
      "Epoch 8/10, Train Loss: 0.1606, Accuracy: 0.904, F1 Micro: 0.6861, F1 Macro: 0.5332\n",
      "Epoch 9/10, Train Loss: 0.1451, Accuracy: 0.9062, F1 Micro: 0.702, F1 Macro: 0.5536\n",
      "Epoch 10/10, Train Loss: 0.1249, Accuracy: 0.9048, F1 Micro: 0.696, F1 Macro: 0.5531\n",
      "Best result for 2535 samples: F1 Micro: 0.702\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.77      0.80      1107\n",
      "      Abusive       0.85      0.83      0.84      1030\n",
      "HS_Individual       0.71      0.61      0.66       729\n",
      "     HS_Group       0.68      0.55      0.61       378\n",
      "  HS_Religion       0.76      0.50      0.61       167\n",
      "      HS_Race       0.75      0.52      0.62        88\n",
      "  HS_Physical       0.00      0.00      0.00        74\n",
      "    HS_Gender       0.00      0.00      0.00        75\n",
      "     HS_Other       0.75      0.66      0.70       744\n",
      "      HS_Weak       0.69      0.55      0.61       690\n",
      "  HS_Moderate       0.66      0.45      0.53       338\n",
      "    HS_Strong       0.70      0.65      0.67        79\n",
      "\n",
      "    micro avg       0.77      0.65      0.70      5499\n",
      "    macro avg       0.61      0.51      0.55      5499\n",
      " weighted avg       0.74      0.65      0.69      5499\n",
      "  samples avg       0.39      0.35      0.35      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 37.617733001708984\n",
      "Samples above threshold: 801\n",
      "Acquired samples: 801\n",
      "Sampling duration: 42.50384569168091 seconds\n",
      "\n",
      "Fold 4 - New train size: 3336\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 3336 samples\n",
      "Epoch 1/10, Train Loss: 0.468, Accuracy: 0.8517, F1 Micro: 0.4999, F1 Macro: 0.198\n",
      "Epoch 2/10, Train Loss: 0.3314, Accuracy: 0.8819, F1 Micro: 0.5627, F1 Macro: 0.2804\n",
      "Epoch 3/10, Train Loss: 0.2797, Accuracy: 0.8956, F1 Micro: 0.6748, F1 Macro: 0.4328\n",
      "Epoch 4/10, Train Loss: 0.2352, Accuracy: 0.9038, F1 Micro: 0.6905, F1 Macro: 0.4712\n",
      "Epoch 5/10, Train Loss: 0.2092, Accuracy: 0.9075, F1 Micro: 0.6936, F1 Macro: 0.5207\n",
      "Epoch 6/10, Train Loss: 0.1866, Accuracy: 0.9092, F1 Micro: 0.7077, F1 Macro: 0.5104\n",
      "Epoch 7/10, Train Loss: 0.1553, Accuracy: 0.9103, F1 Micro: 0.7177, F1 Macro: 0.5662\n",
      "Epoch 8/10, Train Loss: 0.1386, Accuracy: 0.9095, F1 Micro: 0.7311, F1 Macro: 0.5772\n",
      "Epoch 9/10, Train Loss: 0.1173, Accuracy: 0.9103, F1 Micro: 0.7283, F1 Macro: 0.5896\n",
      "Epoch 10/10, Train Loss: 0.1036, Accuracy: 0.9056, F1 Micro: 0.7288, F1 Macro: 0.5892\n",
      "Best result for 3336 samples: F1 Micro: 0.7311\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.85      0.83      1107\n",
      "      Abusive       0.82      0.89      0.85      1030\n",
      "HS_Individual       0.70      0.68      0.69       729\n",
      "     HS_Group       0.63      0.61      0.62       378\n",
      "  HS_Religion       0.72      0.51      0.60       167\n",
      "      HS_Race       0.74      0.57      0.64        88\n",
      "  HS_Physical       1.00      0.03      0.05        74\n",
      "    HS_Gender       0.00      0.00      0.00        75\n",
      "     HS_Other       0.75      0.76      0.75       744\n",
      "      HS_Weak       0.67      0.66      0.66       690\n",
      "  HS_Moderate       0.60      0.52      0.56       338\n",
      "    HS_Strong       0.70      0.63      0.67        79\n",
      "\n",
      "    micro avg       0.74      0.72      0.73      5499\n",
      "    macro avg       0.68      0.56      0.58      5499\n",
      " weighted avg       0.73      0.72      0.72      5499\n",
      "  samples avg       0.42      0.40      0.39      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 38.12820129394532\n",
      "Samples above threshold: 720\n",
      "Acquired samples: 720\n",
      "Sampling duration: 38.23113012313843 seconds\n",
      "\n",
      "Fold 4 - New train size: 4056\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 4056 samples\n",
      "Epoch 1/10, Train Loss: 0.4537, Accuracy: 0.8652, F1 Micro: 0.4859, F1 Macro: 0.1814\n",
      "Epoch 2/10, Train Loss: 0.3176, Accuracy: 0.8912, F1 Micro: 0.6266, F1 Macro: 0.3649\n",
      "Epoch 3/10, Train Loss: 0.2534, Accuracy: 0.9007, F1 Micro: 0.6929, F1 Macro: 0.4553\n",
      "Epoch 4/10, Train Loss: 0.2194, Accuracy: 0.9076, F1 Micro: 0.6911, F1 Macro: 0.473\n",
      "Epoch 5/10, Train Loss: 0.1905, Accuracy: 0.9121, F1 Micro: 0.7121, F1 Macro: 0.5421\n",
      "Epoch 6/10, Train Loss: 0.1612, Accuracy: 0.9123, F1 Micro: 0.7044, F1 Macro: 0.5365\n",
      "Epoch 7/10, Train Loss: 0.1383, Accuracy: 0.9146, F1 Micro: 0.7283, F1 Macro: 0.5558\n",
      "Epoch 8/10, Train Loss: 0.1201, Accuracy: 0.9129, F1 Micro: 0.7393, F1 Macro: 0.5789\n",
      "Epoch 9/10, Train Loss: 0.1055, Accuracy: 0.9081, F1 Micro: 0.7391, F1 Macro: 0.5952\n",
      "Epoch 10/10, Train Loss: 0.0944, Accuracy: 0.9116, F1 Micro: 0.7419, F1 Macro: 0.594\n",
      "Best result for 4056 samples: F1 Micro: 0.7419\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.86      0.83      1107\n",
      "      Abusive       0.85      0.91      0.88      1030\n",
      "HS_Individual       0.64      0.80      0.71       729\n",
      "     HS_Group       0.79      0.45      0.57       378\n",
      "  HS_Religion       0.75      0.54      0.63       167\n",
      "      HS_Race       0.79      0.52      0.63        88\n",
      "  HS_Physical       0.90      0.12      0.21        74\n",
      "    HS_Gender       0.00      0.00      0.00        75\n",
      "     HS_Other       0.74      0.79      0.77       744\n",
      "      HS_Weak       0.60      0.78      0.68       690\n",
      "  HS_Moderate       0.72      0.39      0.50       338\n",
      "    HS_Strong       0.82      0.63      0.71        79\n",
      "\n",
      "    micro avg       0.74      0.75      0.74      5499\n",
      "    macro avg       0.70      0.57      0.59      5499\n",
      " weighted avg       0.74      0.75      0.73      5499\n",
      "  samples avg       0.43      0.42      0.40      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 38.256107330322266\n",
      "Samples above threshold: 649\n",
      "Acquired samples: 648\n",
      "Sampling duration: 34.85539937019348 seconds\n",
      "\n",
      "Fold 4 - New train size: 4704\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 4704 samples\n",
      "Epoch 1/10, Train Loss: 0.445, Accuracy: 0.8725, F1 Micro: 0.5199, F1 Macro: 0.2111\n",
      "Epoch 2/10, Train Loss: 0.3107, Accuracy: 0.8966, F1 Micro: 0.6581, F1 Macro: 0.3658\n",
      "Epoch 3/10, Train Loss: 0.2486, Accuracy: 0.9049, F1 Micro: 0.6775, F1 Macro: 0.4587\n",
      "Epoch 4/10, Train Loss: 0.2093, Accuracy: 0.913, F1 Micro: 0.7232, F1 Macro: 0.5523\n",
      "Epoch 5/10, Train Loss: 0.1786, Accuracy: 0.9152, F1 Micro: 0.7311, F1 Macro: 0.5572\n",
      "Epoch 6/10, Train Loss: 0.1514, Accuracy: 0.9118, F1 Micro: 0.7452, F1 Macro: 0.5993\n",
      "Epoch 7/10, Train Loss: 0.1314, Accuracy: 0.9141, F1 Micro: 0.7485, F1 Macro: 0.609\n",
      "Epoch 8/10, Train Loss: 0.1177, Accuracy: 0.9156, F1 Micro: 0.7356, F1 Macro: 0.5924\n",
      "Epoch 9/10, Train Loss: 0.101, Accuracy: 0.9144, F1 Micro: 0.7451, F1 Macro: 0.6156\n",
      "Epoch 10/10, Train Loss: 0.0893, Accuracy: 0.9147, F1 Micro: 0.7493, F1 Macro: 0.6128\n",
      "Best result for 4704 samples: F1 Micro: 0.7493\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.81      0.86      0.84      1107\n",
      "      Abusive       0.85      0.90      0.87      1030\n",
      "HS_Individual       0.69      0.74      0.71       729\n",
      "     HS_Group       0.69      0.57      0.62       378\n",
      "  HS_Religion       0.78      0.58      0.67       167\n",
      "      HS_Race       0.76      0.53      0.63        88\n",
      "  HS_Physical       0.57      0.11      0.18        74\n",
      "    HS_Gender       0.80      0.05      0.10        75\n",
      "     HS_Other       0.73      0.82      0.78       744\n",
      "      HS_Weak       0.66      0.72      0.69       690\n",
      "  HS_Moderate       0.62      0.50      0.55       338\n",
      "    HS_Strong       0.81      0.65      0.72        79\n",
      "\n",
      "    micro avg       0.75      0.75      0.75      5499\n",
      "    macro avg       0.73      0.59      0.61      5499\n",
      " weighted avg       0.75      0.75      0.74      5499\n",
      "  samples avg       0.42      0.42      0.40      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 37.83470993041992\n",
      "Samples above threshold: 584\n",
      "Acquired samples: 584\n",
      "Sampling duration: 31.074474096298218 seconds\n",
      "\n",
      "Fold 4 - New train size: 5288\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 5288 samples\n",
      "Epoch 1/10, Train Loss: 0.4262, Accuracy: 0.8696, F1 Micro: 0.4376, F1 Macro: 0.1811\n",
      "Epoch 2/10, Train Loss: 0.2905, Accuracy: 0.8954, F1 Micro: 0.6231, F1 Macro: 0.3612\n",
      "Epoch 3/10, Train Loss: 0.2292, Accuracy: 0.9072, F1 Micro: 0.6824, F1 Macro: 0.4869\n",
      "Epoch 4/10, Train Loss: 0.1864, Accuracy: 0.9133, F1 Micro: 0.7382, F1 Macro: 0.575\n",
      "Epoch 5/10, Train Loss: 0.1647, Accuracy: 0.9134, F1 Micro: 0.7419, F1 Macro: 0.588\n",
      "Epoch 6/10, Train Loss: 0.1401, Accuracy: 0.9151, F1 Micro: 0.7382, F1 Macro: 0.5807\n",
      "Epoch 7/10, Train Loss: 0.1137, Accuracy: 0.9164, F1 Micro: 0.7464, F1 Macro: 0.5835\n",
      "Epoch 8/10, Train Loss: 0.1005, Accuracy: 0.9178, F1 Micro: 0.7365, F1 Macro: 0.602\n",
      "Epoch 9/10, Train Loss: 0.0893, Accuracy: 0.9158, F1 Micro: 0.7497, F1 Macro: 0.6306\n",
      "Epoch 10/10, Train Loss: 0.0774, Accuracy: 0.9181, F1 Micro: 0.7533, F1 Macro: 0.6426\n",
      "Best result for 5288 samples: F1 Micro: 0.7533\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.83      0.83      1107\n",
      "      Abusive       0.88      0.90      0.89      1030\n",
      "HS_Individual       0.71      0.71      0.71       729\n",
      "     HS_Group       0.71      0.58      0.64       378\n",
      "  HS_Religion       0.75      0.63      0.68       167\n",
      "      HS_Race       0.77      0.57      0.65        88\n",
      "  HS_Physical       0.57      0.22      0.31        74\n",
      "    HS_Gender       0.86      0.16      0.27        75\n",
      "     HS_Other       0.78      0.74      0.76       744\n",
      "      HS_Weak       0.68      0.70      0.69       690\n",
      "  HS_Moderate       0.64      0.54      0.58       338\n",
      "    HS_Strong       0.87      0.57      0.69        79\n",
      "\n",
      "    micro avg       0.77      0.73      0.75      5499\n",
      "    macro avg       0.75      0.60      0.64      5499\n",
      " weighted avg       0.77      0.73      0.75      5499\n",
      "  samples avg       0.43      0.41      0.40      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 37.0031063079834\n",
      "Samples above threshold: 525\n",
      "Acquired samples: 525\n",
      "Sampling duration: 28.277388095855713 seconds\n",
      "\n",
      "Fold 4 - New train size: 5813\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 5813 samples\n",
      "Epoch 1/10, Train Loss: 0.42, Accuracy: 0.8711, F1 Micro: 0.4637, F1 Macro: 0.1896\n",
      "Epoch 2/10, Train Loss: 0.2865, Accuracy: 0.9008, F1 Micro: 0.6854, F1 Macro: 0.4601\n",
      "Epoch 3/10, Train Loss: 0.2293, Accuracy: 0.9086, F1 Micro: 0.7159, F1 Macro: 0.4871\n",
      "Epoch 4/10, Train Loss: 0.1865, Accuracy: 0.9163, F1 Micro: 0.7425, F1 Macro: 0.5651\n",
      "Epoch 5/10, Train Loss: 0.1583, Accuracy: 0.9153, F1 Micro: 0.7454, F1 Macro: 0.566\n",
      "Epoch 6/10, Train Loss: 0.1357, Accuracy: 0.9163, F1 Micro: 0.7545, F1 Macro: 0.6242\n",
      "Epoch 7/10, Train Loss: 0.1204, Accuracy: 0.9179, F1 Micro: 0.7629, F1 Macro: 0.6336\n",
      "Epoch 8/10, Train Loss: 0.1055, Accuracy: 0.9187, F1 Micro: 0.761, F1 Macro: 0.6521\n",
      "Epoch 9/10, Train Loss: 0.0872, Accuracy: 0.9164, F1 Micro: 0.7504, F1 Macro: 0.6314\n",
      "Epoch 10/10, Train Loss: 0.0769, Accuracy: 0.9184, F1 Micro: 0.7621, F1 Macro: 0.6729\n",
      "Best result for 5813 samples: F1 Micro: 0.7629\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.79      0.89      0.84      1107\n",
      "      Abusive       0.85      0.91      0.88      1030\n",
      "HS_Individual       0.71      0.76      0.73       729\n",
      "     HS_Group       0.69      0.67      0.68       378\n",
      "  HS_Religion       0.79      0.59      0.68       167\n",
      "      HS_Race       0.72      0.59      0.65        88\n",
      "  HS_Physical       0.78      0.09      0.17        74\n",
      "    HS_Gender       1.00      0.09      0.17        75\n",
      "     HS_Other       0.72      0.83      0.77       744\n",
      "      HS_Weak       0.68      0.72      0.70       690\n",
      "  HS_Moderate       0.63      0.57      0.60       338\n",
      "    HS_Strong       0.78      0.68      0.73        79\n",
      "\n",
      "    micro avg       0.75      0.77      0.76      5499\n",
      "    macro avg       0.76      0.62      0.63      5499\n",
      " weighted avg       0.75      0.77      0.75      5499\n",
      "  samples avg       0.44      0.43      0.42      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 37.33585891723633\n",
      "Samples above threshold: 473\n",
      "Acquired samples: 473\n",
      "Sampling duration: 24.97159719467163 seconds\n",
      "\n",
      "Fold 4 - New train size: 6286\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 6286 samples\n",
      "Epoch 1/10, Train Loss: 0.4026, Accuracy: 0.88, F1 Micro: 0.5767, F1 Macro: 0.2637\n",
      "Epoch 2/10, Train Loss: 0.2669, Accuracy: 0.8977, F1 Micro: 0.6358, F1 Macro: 0.3639\n",
      "Epoch 3/10, Train Loss: 0.2176, Accuracy: 0.9107, F1 Micro: 0.7288, F1 Macro: 0.5126\n",
      "Epoch 4/10, Train Loss: 0.1814, Accuracy: 0.9136, F1 Micro: 0.7479, F1 Macro: 0.5816\n",
      "Epoch 5/10, Train Loss: 0.1558, Accuracy: 0.9176, F1 Micro: 0.7501, F1 Macro: 0.6021\n",
      "Epoch 6/10, Train Loss: 0.1307, Accuracy: 0.9179, F1 Micro: 0.7584, F1 Macro: 0.6158\n",
      "Epoch 7/10, Train Loss: 0.1097, Accuracy: 0.9211, F1 Micro: 0.7592, F1 Macro: 0.6453\n",
      "Epoch 8/10, Train Loss: 0.0971, Accuracy: 0.9218, F1 Micro: 0.7637, F1 Macro: 0.6441\n",
      "Epoch 9/10, Train Loss: 0.0824, Accuracy: 0.9191, F1 Micro: 0.7635, F1 Macro: 0.6615\n",
      "Epoch 10/10, Train Loss: 0.0726, Accuracy: 0.9206, F1 Micro: 0.7638, F1 Macro: 0.6671\n",
      "Best result for 6286 samples: F1 Micro: 0.7638\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.86      0.85      1107\n",
      "      Abusive       0.87      0.91      0.89      1030\n",
      "HS_Individual       0.71      0.73      0.72       729\n",
      "     HS_Group       0.70      0.59      0.64       378\n",
      "  HS_Religion       0.77      0.61      0.68       167\n",
      "      HS_Race       0.77      0.57      0.65        88\n",
      "  HS_Physical       0.68      0.20      0.31        74\n",
      "    HS_Gender       0.86      0.33      0.48        75\n",
      "     HS_Other       0.77      0.79      0.78       744\n",
      "      HS_Weak       0.69      0.71      0.70       690\n",
      "  HS_Moderate       0.64      0.53      0.58       338\n",
      "    HS_Strong       0.82      0.65      0.72        79\n",
      "\n",
      "    micro avg       0.77      0.75      0.76      5499\n",
      "    macro avg       0.76      0.62      0.67      5499\n",
      " weighted avg       0.77      0.75      0.76      5499\n",
      "  samples avg       0.43      0.42      0.41      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 36.027962112426756\n",
      "Samples above threshold: 425\n",
      "Acquired samples: 298\n",
      "Sampling duration: 23.19695019721985 seconds\n",
      "\n",
      "Fold 4 - New train size: 6584\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 6584 samples\n",
      "Epoch 1/10, Train Loss: 0.3999, Accuracy: 0.8804, F1 Micro: 0.5561, F1 Macro: 0.2554\n",
      "Epoch 2/10, Train Loss: 0.2669, Accuracy: 0.9028, F1 Micro: 0.6868, F1 Macro: 0.4222\n",
      "Epoch 3/10, Train Loss: 0.2171, Accuracy: 0.9129, F1 Micro: 0.7331, F1 Macro: 0.5412\n",
      "Epoch 4/10, Train Loss: 0.1829, Accuracy: 0.9166, F1 Micro: 0.7473, F1 Macro: 0.5764\n",
      "Epoch 5/10, Train Loss: 0.1546, Accuracy: 0.9194, F1 Micro: 0.7549, F1 Macro: 0.5937\n",
      "Epoch 6/10, Train Loss: 0.1318, Accuracy: 0.9198, F1 Micro: 0.7639, F1 Macro: 0.6332\n",
      "Epoch 7/10, Train Loss: 0.1077, Accuracy: 0.92, F1 Micro: 0.7636, F1 Macro: 0.6517\n",
      "Epoch 8/10, Train Loss: 0.0984, Accuracy: 0.9215, F1 Micro: 0.7615, F1 Macro: 0.6592\n",
      "Epoch 9/10, Train Loss: 0.0836, Accuracy: 0.9215, F1 Micro: 0.7641, F1 Macro: 0.6691\n",
      "Epoch 10/10, Train Loss: 0.0724, Accuracy: 0.9219, F1 Micro: 0.7645, F1 Macro: 0.6741\n",
      "Best result for 6584 samples: F1 Micro: 0.7645\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.83      0.84      1107\n",
      "      Abusive       0.86      0.91      0.89      1030\n",
      "HS_Individual       0.76      0.69      0.72       729\n",
      "     HS_Group       0.70      0.65      0.67       378\n",
      "  HS_Religion       0.80      0.58      0.67       167\n",
      "      HS_Race       0.80      0.56      0.66        88\n",
      "  HS_Physical       0.65      0.23      0.34        74\n",
      "    HS_Gender       0.89      0.33      0.49        75\n",
      "     HS_Other       0.76      0.78      0.77       744\n",
      "      HS_Weak       0.74      0.66      0.69       690\n",
      "  HS_Moderate       0.62      0.59      0.60       338\n",
      "    HS_Strong       0.77      0.71      0.74        79\n",
      "\n",
      "    micro avg       0.79      0.74      0.76      5499\n",
      "    macro avg       0.77      0.63      0.67      5499\n",
      " weighted avg       0.78      0.74      0.76      5499\n",
      "  samples avg       0.44      0.42      0.41      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 37.92975616455078\n",
      "Samples above threshold: 396\n",
      "Acquired samples: 396\n",
      "Sampling duration: 21.31590700149536 seconds\n",
      "\n",
      "Fold 4 - New train size: 6980\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 6980 samples\n",
      "Epoch 1/10, Train Loss: 0.3914, Accuracy: 0.881, F1 Micro: 0.5621, F1 Macro: 0.2675\n",
      "Epoch 2/10, Train Loss: 0.2591, Accuracy: 0.9026, F1 Micro: 0.704, F1 Macro: 0.4588\n",
      "Epoch 3/10, Train Loss: 0.2109, Accuracy: 0.9101, F1 Micro: 0.6948, F1 Macro: 0.4894\n",
      "Epoch 4/10, Train Loss: 0.1736, Accuracy: 0.9184, F1 Micro: 0.738, F1 Macro: 0.5749\n",
      "Epoch 5/10, Train Loss: 0.141, Accuracy: 0.9185, F1 Micro: 0.7589, F1 Macro: 0.6042\n",
      "Epoch 6/10, Train Loss: 0.1268, Accuracy: 0.92, F1 Micro: 0.766, F1 Macro: 0.6424\n",
      "Epoch 7/10, Train Loss: 0.1046, Accuracy: 0.921, F1 Micro: 0.7676, F1 Macro: 0.6519\n",
      "Epoch 8/10, Train Loss: 0.0889, Accuracy: 0.9234, F1 Micro: 0.764, F1 Macro: 0.6649\n",
      "Epoch 9/10, Train Loss: 0.0803, Accuracy: 0.9222, F1 Micro: 0.7607, F1 Macro: 0.6647\n",
      "Epoch 10/10, Train Loss: 0.0674, Accuracy: 0.9206, F1 Micro: 0.7636, F1 Macro: 0.6771\n",
      "Best result for 6980 samples: F1 Micro: 0.7676\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.88      0.85      1107\n",
      "      Abusive       0.86      0.91      0.88      1030\n",
      "HS_Individual       0.70      0.77      0.73       729\n",
      "     HS_Group       0.77      0.57      0.65       378\n",
      "  HS_Religion       0.73      0.59      0.65       167\n",
      "      HS_Race       0.80      0.49      0.61        88\n",
      "  HS_Physical       0.67      0.16      0.26        74\n",
      "    HS_Gender       0.94      0.23      0.37        75\n",
      "     HS_Other       0.76      0.81      0.79       744\n",
      "      HS_Weak       0.67      0.76      0.71       690\n",
      "  HS_Moderate       0.70      0.51      0.59       338\n",
      "    HS_Strong       0.84      0.65      0.73        79\n",
      "\n",
      "    micro avg       0.77      0.77      0.77      5499\n",
      "    macro avg       0.77      0.61      0.65      5499\n",
      " weighted avg       0.77      0.77      0.76      5499\n",
      "  samples avg       0.44      0.42      0.42      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 35.4583683013916\n",
      "Samples above threshold: 356\n",
      "Acquired samples: 356\n",
      "Sampling duration: 19.046759128570557 seconds\n",
      "\n",
      "Fold 4 - New train size: 7336\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 7336 samples\n",
      "Epoch 1/10, Train Loss: 0.39, Accuracy: 0.8846, F1 Micro: 0.5968, F1 Macro: 0.2848\n",
      "Epoch 2/10, Train Loss: 0.2531, Accuracy: 0.9027, F1 Micro: 0.6762, F1 Macro: 0.4187\n",
      "Epoch 3/10, Train Loss: 0.2042, Accuracy: 0.9129, F1 Micro: 0.7197, F1 Macro: 0.5492\n",
      "Epoch 4/10, Train Loss: 0.1747, Accuracy: 0.9178, F1 Micro: 0.7571, F1 Macro: 0.5911\n",
      "Epoch 5/10, Train Loss: 0.1466, Accuracy: 0.9199, F1 Micro: 0.7502, F1 Macro: 0.587\n",
      "Epoch 6/10, Train Loss: 0.1282, Accuracy: 0.9213, F1 Micro: 0.7671, F1 Macro: 0.631\n",
      "Epoch 7/10, Train Loss: 0.1057, Accuracy: 0.9177, F1 Micro: 0.7439, F1 Macro: 0.6155\n",
      "Epoch 8/10, Train Loss: 0.0907, Accuracy: 0.9176, F1 Micro: 0.7603, F1 Macro: 0.6401\n",
      "Epoch 9/10, Train Loss: 0.0791, Accuracy: 0.9235, F1 Micro: 0.7644, F1 Macro: 0.669\n",
      "Epoch 10/10, Train Loss: 0.0693, Accuracy: 0.9191, F1 Micro: 0.7666, F1 Macro: 0.6724\n",
      "Best result for 7336 samples: F1 Micro: 0.7671\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.88      0.85      1107\n",
      "      Abusive       0.87      0.90      0.88      1030\n",
      "HS_Individual       0.72      0.76      0.74       729\n",
      "     HS_Group       0.74      0.60      0.66       378\n",
      "  HS_Religion       0.71      0.58      0.64       167\n",
      "      HS_Race       0.78      0.51      0.62        88\n",
      "  HS_Physical       0.75      0.08      0.15        74\n",
      "    HS_Gender       0.83      0.13      0.23        75\n",
      "     HS_Other       0.75      0.82      0.78       744\n",
      "      HS_Weak       0.70      0.74      0.72       690\n",
      "  HS_Moderate       0.68      0.53      0.60       338\n",
      "    HS_Strong       0.83      0.62      0.71        79\n",
      "\n",
      "    micro avg       0.77      0.76      0.77      5499\n",
      "    macro avg       0.76      0.60      0.63      5499\n",
      " weighted avg       0.77      0.76      0.76      5499\n",
      "  samples avg       0.44      0.42      0.41      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 34.00336456298828\n",
      "Samples above threshold: 320\n",
      "Acquired samples: 320\n",
      "Sampling duration: 17.345491886138916 seconds\n",
      "\n",
      "Fold 4 - New train size: 7656\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 7656 samples\n",
      "Epoch 1/10, Train Loss: 0.385, Accuracy: 0.8853, F1 Micro: 0.6153, F1 Macro: 0.3119\n",
      "Epoch 2/10, Train Loss: 0.2532, Accuracy: 0.9066, F1 Micro: 0.6934, F1 Macro: 0.4679\n",
      "Epoch 3/10, Train Loss: 0.2061, Accuracy: 0.9119, F1 Micro: 0.699, F1 Macro: 0.5029\n",
      "Epoch 4/10, Train Loss: 0.1721, Accuracy: 0.92, F1 Micro: 0.7461, F1 Macro: 0.5837\n",
      "Epoch 5/10, Train Loss: 0.1473, Accuracy: 0.9191, F1 Micro: 0.7602, F1 Macro: 0.6116\n",
      "Epoch 6/10, Train Loss: 0.1242, Accuracy: 0.9215, F1 Micro: 0.7672, F1 Macro: 0.6373\n",
      "Epoch 7/10, Train Loss: 0.1077, Accuracy: 0.9203, F1 Micro: 0.7709, F1 Macro: 0.6651\n",
      "Epoch 8/10, Train Loss: 0.0901, Accuracy: 0.9209, F1 Micro: 0.7683, F1 Macro: 0.6548\n",
      "Epoch 9/10, Train Loss: 0.0799, Accuracy: 0.9208, F1 Micro: 0.7532, F1 Macro: 0.6636\n",
      "Epoch 10/10, Train Loss: 0.0659, Accuracy: 0.9202, F1 Micro: 0.7645, F1 Macro: 0.6722\n",
      "Best result for 7656 samples: F1 Micro: 0.7709\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.89      0.84      1107\n",
      "      Abusive       0.87      0.91      0.89      1030\n",
      "HS_Individual       0.70      0.78      0.74       729\n",
      "     HS_Group       0.71      0.66      0.68       378\n",
      "  HS_Religion       0.75      0.65      0.70       167\n",
      "      HS_Race       0.74      0.60      0.66        88\n",
      "  HS_Physical       0.74      0.19      0.30        74\n",
      "    HS_Gender       0.81      0.23      0.35        75\n",
      "     HS_Other       0.74      0.82      0.78       744\n",
      "      HS_Weak       0.67      0.76      0.71       690\n",
      "  HS_Moderate       0.66      0.59      0.62       338\n",
      "    HS_Strong       0.79      0.62      0.70        79\n",
      "\n",
      "    micro avg       0.76      0.79      0.77      5499\n",
      "    macro avg       0.75      0.64      0.67      5499\n",
      " weighted avg       0.76      0.79      0.76      5499\n",
      "  samples avg       0.44      0.43      0.42      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 32.287528610229494\n",
      "Samples above threshold: 288\n",
      "Acquired samples: 245\n",
      "Sampling duration: 15.901337623596191 seconds\n",
      "\n",
      "Fold 4 - New train size: 7901\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 7901 samples\n",
      "Epoch 1/10, Train Loss: 0.3901, Accuracy: 0.8845, F1 Micro: 0.5783, F1 Macro: 0.2861\n",
      "Epoch 2/10, Train Loss: 0.2577, Accuracy: 0.9068, F1 Micro: 0.7037, F1 Macro: 0.4813\n",
      "Epoch 3/10, Train Loss: 0.2112, Accuracy: 0.9159, F1 Micro: 0.7433, F1 Macro: 0.5762\n",
      "Epoch 4/10, Train Loss: 0.1703, Accuracy: 0.9207, F1 Micro: 0.7579, F1 Macro: 0.5965\n",
      "Epoch 5/10, Train Loss: 0.1478, Accuracy: 0.9239, F1 Micro: 0.7603, F1 Macro: 0.5944\n",
      "Epoch 6/10, Train Loss: 0.1277, Accuracy: 0.92, F1 Micro: 0.7684, F1 Macro: 0.6435\n",
      "Epoch 7/10, Train Loss: 0.107, Accuracy: 0.925, F1 Micro: 0.7707, F1 Macro: 0.6672\n",
      "Epoch 8/10, Train Loss: 0.0927, Accuracy: 0.9216, F1 Micro: 0.7628, F1 Macro: 0.6538\n",
      "Epoch 9/10, Train Loss: 0.0781, Accuracy: 0.9214, F1 Micro: 0.7698, F1 Macro: 0.6641\n",
      "Epoch 10/10, Train Loss: 0.0677, Accuracy: 0.9219, F1 Micro: 0.769, F1 Macro: 0.6742\n",
      "Best result for 7901 samples: F1 Micro: 0.7707\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.84      0.84      1107\n",
      "      Abusive       0.93      0.88      0.90      1030\n",
      "HS_Individual       0.75      0.71      0.73       729\n",
      "     HS_Group       0.74      0.62      0.68       378\n",
      "  HS_Religion       0.75      0.63      0.69       167\n",
      "      HS_Race       0.75      0.66      0.70        88\n",
      "  HS_Physical       0.67      0.19      0.29        74\n",
      "    HS_Gender       0.90      0.24      0.38        75\n",
      "     HS_Other       0.79      0.77      0.78       744\n",
      "      HS_Weak       0.72      0.70      0.71       690\n",
      "  HS_Moderate       0.67      0.57      0.62       338\n",
      "    HS_Strong       0.87      0.57      0.69        79\n",
      "\n",
      "    micro avg       0.80      0.74      0.77      5499\n",
      "    macro avg       0.78      0.61      0.67      5499\n",
      " weighted avg       0.80      0.74      0.77      5499\n",
      "  samples avg       0.44      0.41      0.41      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 32.99349212646484\n",
      "Samples above threshold: 264\n",
      "Acquired samples: 264\n",
      "Sampling duration: 14.636935949325562 seconds\n",
      "\n",
      "Fold 4 - New train size: 8165\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 8165 samples\n",
      "Epoch 1/10, Train Loss: 0.385, Accuracy: 0.8871, F1 Micro: 0.6179, F1 Macro: 0.3139\n",
      "Epoch 2/10, Train Loss: 0.2568, Accuracy: 0.9074, F1 Micro: 0.7193, F1 Macro: 0.4707\n",
      "Epoch 3/10, Train Loss: 0.2054, Accuracy: 0.9172, F1 Micro: 0.7445, F1 Macro: 0.5609\n",
      "Epoch 4/10, Train Loss: 0.1741, Accuracy: 0.9198, F1 Micro: 0.7476, F1 Macro: 0.5609\n",
      "Epoch 5/10, Train Loss: 0.1467, Accuracy: 0.9245, F1 Micro: 0.7725, F1 Macro: 0.6234\n",
      "Epoch 6/10, Train Loss: 0.1223, Accuracy: 0.9237, F1 Micro: 0.7737, F1 Macro: 0.6425\n",
      "Epoch 7/10, Train Loss: 0.1056, Accuracy: 0.9204, F1 Micro: 0.764, F1 Macro: 0.6321\n",
      "Epoch 8/10, Train Loss: 0.0886, Accuracy: 0.9218, F1 Micro: 0.77, F1 Macro: 0.6679\n",
      "Epoch 9/10, Train Loss: 0.0741, Accuracy: 0.9226, F1 Micro: 0.7676, F1 Macro: 0.6531\n",
      "Epoch 10/10, Train Loss: 0.0676, Accuracy: 0.9237, F1 Micro: 0.7741, F1 Macro: 0.684\n",
      "Best result for 8165 samples: F1 Micro: 0.7741\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.85      0.84      1107\n",
      "      Abusive       0.88      0.92      0.90      1030\n",
      "HS_Individual       0.74      0.72      0.73       729\n",
      "     HS_Group       0.71      0.66      0.68       378\n",
      "  HS_Religion       0.76      0.70      0.73       167\n",
      "      HS_Race       0.75      0.60      0.67        88\n",
      "  HS_Physical       0.64      0.22      0.32        74\n",
      "    HS_Gender       0.87      0.35      0.50        75\n",
      "     HS_Other       0.77      0.80      0.79       744\n",
      "      HS_Weak       0.71      0.71      0.71       690\n",
      "  HS_Moderate       0.62      0.60      0.61       338\n",
      "    HS_Strong       0.81      0.66      0.73        79\n",
      "\n",
      "    micro avg       0.78      0.77      0.77      5499\n",
      "    macro avg       0.76      0.65      0.68      5499\n",
      " weighted avg       0.78      0.77      0.77      5499\n",
      "  samples avg       0.44      0.42      0.42      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 33.66349411010742\n",
      "Samples above threshold: 238\n",
      "Acquired samples: 238\n",
      "Sampling duration: 13.16867733001709 seconds\n",
      "\n",
      "Fold 4 - New train size: 8403\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 8403 samples\n",
      "Epoch 1/10, Train Loss: 0.3854, Accuracy: 0.8891, F1 Micro: 0.6287, F1 Macro: 0.3165\n",
      "Epoch 2/10, Train Loss: 0.2565, Accuracy: 0.9108, F1 Micro: 0.7226, F1 Macro: 0.5096\n",
      "Epoch 3/10, Train Loss: 0.2091, Accuracy: 0.9186, F1 Micro: 0.7405, F1 Macro: 0.5619\n",
      "Epoch 4/10, Train Loss: 0.1761, Accuracy: 0.9218, F1 Micro: 0.7604, F1 Macro: 0.5758\n",
      "Epoch 5/10, Train Loss: 0.1485, Accuracy: 0.9228, F1 Micro: 0.7665, F1 Macro: 0.6201\n",
      "Epoch 6/10, Train Loss: 0.1256, Accuracy: 0.9226, F1 Micro: 0.752, F1 Macro: 0.5979\n",
      "Epoch 7/10, Train Loss: 0.1026, Accuracy: 0.9257, F1 Micro: 0.7687, F1 Macro: 0.6475\n",
      "Epoch 8/10, Train Loss: 0.0884, Accuracy: 0.9244, F1 Micro: 0.7742, F1 Macro: 0.6748\n",
      "Epoch 9/10, Train Loss: 0.0775, Accuracy: 0.9278, F1 Micro: 0.7794, F1 Macro: 0.6719\n",
      "Epoch 10/10, Train Loss: 0.066, Accuracy: 0.926, F1 Micro: 0.7747, F1 Macro: 0.6887\n",
      "Best result for 8403 samples: F1 Micro: 0.7794\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.87      0.84      0.85      1107\n",
      "      Abusive       0.94      0.88      0.91      1030\n",
      "HS_Individual       0.73      0.80      0.76       729\n",
      "     HS_Group       0.84      0.53      0.65       378\n",
      "  HS_Religion       0.84      0.52      0.64       167\n",
      "      HS_Race       0.85      0.52      0.65        88\n",
      "  HS_Physical       0.58      0.20      0.30        74\n",
      "    HS_Gender       0.96      0.31      0.46        75\n",
      "     HS_Other       0.78      0.79      0.79       744\n",
      "      HS_Weak       0.70      0.77      0.74       690\n",
      "  HS_Moderate       0.79      0.45      0.57       338\n",
      "    HS_Strong       0.78      0.71      0.74        79\n",
      "\n",
      "    micro avg       0.81      0.75      0.78      5499\n",
      "    macro avg       0.80      0.61      0.67      5499\n",
      " weighted avg       0.82      0.75      0.77      5499\n",
      "  samples avg       0.43      0.41      0.41      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 36.45129547119141\n",
      "Samples above threshold: 214\n",
      "Acquired samples: 214\n",
      "Sampling duration: 12.081830263137817 seconds\n",
      "\n",
      "Fold 4 - New train size: 8617\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 8617 samples\n",
      "Epoch 1/10, Train Loss: 0.3744, Accuracy: 0.8889, F1 Micro: 0.6108, F1 Macro: 0.3092\n",
      "Epoch 2/10, Train Loss: 0.2524, Accuracy: 0.9101, F1 Micro: 0.7135, F1 Macro: 0.4733\n",
      "Epoch 3/10, Train Loss: 0.2014, Accuracy: 0.9154, F1 Micro: 0.735, F1 Macro: 0.5064\n",
      "Epoch 4/10, Train Loss: 0.1724, Accuracy: 0.9237, F1 Micro: 0.7563, F1 Macro: 0.6021\n",
      "Epoch 5/10, Train Loss: 0.1429, Accuracy: 0.9205, F1 Micro: 0.7687, F1 Macro: 0.6504\n",
      "Epoch 6/10, Train Loss: 0.1253, Accuracy: 0.9244, F1 Micro: 0.7776, F1 Macro: 0.6522\n",
      "Epoch 7/10, Train Loss: 0.1024, Accuracy: 0.9236, F1 Micro: 0.776, F1 Macro: 0.6679\n",
      "Epoch 8/10, Train Loss: 0.0855, Accuracy: 0.925, F1 Micro: 0.7804, F1 Macro: 0.688\n",
      "Epoch 9/10, Train Loss: 0.072, Accuracy: 0.9251, F1 Micro: 0.7732, F1 Macro: 0.6655\n",
      "Epoch 10/10, Train Loss: 0.0656, Accuracy: 0.9227, F1 Micro: 0.7699, F1 Macro: 0.6888\n",
      "Best result for 8617 samples: F1 Micro: 0.7804\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.88      0.85      1107\n",
      "      Abusive       0.90      0.90      0.90      1030\n",
      "HS_Individual       0.70      0.80      0.75       729\n",
      "     HS_Group       0.76      0.61      0.68       378\n",
      "  HS_Religion       0.80      0.58      0.67       167\n",
      "      HS_Race       0.78      0.59      0.67        88\n",
      "  HS_Physical       0.55      0.23      0.32        74\n",
      "    HS_Gender       0.83      0.40      0.54        75\n",
      "     HS_Other       0.75      0.82      0.78       744\n",
      "      HS_Weak       0.69      0.78      0.73       690\n",
      "  HS_Moderate       0.72      0.53      0.61       338\n",
      "    HS_Strong       0.75      0.73      0.74        79\n",
      "\n",
      "    micro avg       0.78      0.78      0.78      5499\n",
      "    macro avg       0.75      0.65      0.69      5499\n",
      " weighted avg       0.78      0.78      0.78      5499\n",
      "  samples avg       0.44      0.43      0.42      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 34.040411376953124\n",
      "Samples above threshold: 192\n",
      "Acquired samples: 200\n",
      "Sampling duration: 10.849629878997803 seconds\n",
      "\n",
      "Fold 4 - New train size: 8817\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 8817 samples\n",
      "Epoch 1/10, Train Loss: 0.3801, Accuracy: 0.8871, F1 Micro: 0.6518, F1 Macro: 0.3311\n",
      "Epoch 2/10, Train Loss: 0.2542, Accuracy: 0.9084, F1 Micro: 0.6968, F1 Macro: 0.4348\n",
      "Epoch 3/10, Train Loss: 0.2049, Accuracy: 0.9189, F1 Micro: 0.7549, F1 Macro: 0.5893\n",
      "Epoch 4/10, Train Loss: 0.1732, Accuracy: 0.9225, F1 Micro: 0.7628, F1 Macro: 0.5845\n",
      "Epoch 5/10, Train Loss: 0.1477, Accuracy: 0.9237, F1 Micro: 0.766, F1 Macro: 0.6046\n",
      "Epoch 6/10, Train Loss: 0.1244, Accuracy: 0.9272, F1 Micro: 0.7752, F1 Macro: 0.6578\n",
      "Epoch 7/10, Train Loss: 0.1025, Accuracy: 0.9263, F1 Micro: 0.7703, F1 Macro: 0.6585\n",
      "Epoch 8/10, Train Loss: 0.0866, Accuracy: 0.9246, F1 Micro: 0.7701, F1 Macro: 0.6651\n",
      "Epoch 9/10, Train Loss: 0.0733, Accuracy: 0.9244, F1 Micro: 0.7792, F1 Macro: 0.6758\n",
      "Epoch 10/10, Train Loss: 0.0677, Accuracy: 0.9237, F1 Micro: 0.7688, F1 Macro: 0.6828\n",
      "Best result for 8817 samples: F1 Micro: 0.7792\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.88      0.85      1107\n",
      "      Abusive       0.90      0.90      0.90      1030\n",
      "HS_Individual       0.70      0.81      0.75       729\n",
      "     HS_Group       0.78      0.58      0.66       378\n",
      "  HS_Religion       0.79      0.62      0.70       167\n",
      "      HS_Race       0.79      0.50      0.61        88\n",
      "  HS_Physical       0.71      0.20      0.32        74\n",
      "    HS_Gender       0.89      0.33      0.49        75\n",
      "     HS_Other       0.75      0.84      0.79       744\n",
      "      HS_Weak       0.67      0.79      0.73       690\n",
      "  HS_Moderate       0.69      0.50      0.58       338\n",
      "    HS_Strong       0.77      0.70      0.73        79\n",
      "\n",
      "    micro avg       0.78      0.78      0.78      5499\n",
      "    macro avg       0.77      0.64      0.68      5499\n",
      " weighted avg       0.78      0.78      0.77      5499\n",
      "  samples avg       0.44      0.43      0.42      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 35.725373077392575\n",
      "Samples above threshold: 172\n",
      "Acquired samples: 200\n",
      "Sampling duration: 9.926446676254272 seconds\n",
      "\n",
      "Fold 4 - New train size: 9017\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 9017 samples\n",
      "Epoch 1/10, Train Loss: 0.3767, Accuracy: 0.889, F1 Micro: 0.6032, F1 Macro: 0.302\n",
      "Epoch 2/10, Train Loss: 0.249, Accuracy: 0.9043, F1 Micro: 0.7212, F1 Macro: 0.4737\n",
      "Epoch 3/10, Train Loss: 0.2042, Accuracy: 0.9207, F1 Micro: 0.7565, F1 Macro: 0.5766\n",
      "Epoch 4/10, Train Loss: 0.1642, Accuracy: 0.9245, F1 Micro: 0.776, F1 Macro: 0.6172\n",
      "Epoch 5/10, Train Loss: 0.144, Accuracy: 0.9212, F1 Micro: 0.7734, F1 Macro: 0.618\n",
      "Epoch 6/10, Train Loss: 0.1229, Accuracy: 0.9262, F1 Micro: 0.7711, F1 Macro: 0.6553\n",
      "Epoch 7/10, Train Loss: 0.1018, Accuracy: 0.9243, F1 Micro: 0.7731, F1 Macro: 0.6496\n",
      "Epoch 8/10, Train Loss: 0.0857, Accuracy: 0.9247, F1 Micro: 0.7638, F1 Macro: 0.6735\n",
      "Epoch 9/10, Train Loss: 0.0755, Accuracy: 0.9218, F1 Micro: 0.7741, F1 Macro: 0.6838\n",
      "Epoch 10/10, Train Loss: 0.0658, Accuracy: 0.9263, F1 Micro: 0.7803, F1 Macro: 0.6979\n",
      "Best result for 9017 samples: F1 Micro: 0.7803\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.85      0.85      1107\n",
      "      Abusive       0.87      0.94      0.90      1030\n",
      "HS_Individual       0.73      0.75      0.74       729\n",
      "     HS_Group       0.76      0.60      0.67       378\n",
      "  HS_Religion       0.82      0.59      0.69       167\n",
      "      HS_Race       0.78      0.60      0.68        88\n",
      "  HS_Physical       0.69      0.30      0.42        74\n",
      "    HS_Gender       0.80      0.48      0.60        75\n",
      "     HS_Other       0.78      0.80      0.79       744\n",
      "      HS_Weak       0.71      0.74      0.73       690\n",
      "  HS_Moderate       0.68      0.55      0.60       338\n",
      "    HS_Strong       0.86      0.61      0.71        79\n",
      "\n",
      "    micro avg       0.79      0.77      0.78      5499\n",
      "    macro avg       0.78      0.65      0.70      5499\n",
      " weighted avg       0.79      0.77      0.78      5499\n",
      "  samples avg       0.45      0.43      0.42      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 28.292643356323243\n",
      "Samples above threshold: 152\n",
      "Acquired samples: 200\n",
      "Sampling duration: 8.746516227722168 seconds\n",
      "\n",
      "Fold 4 - New train size: 9217\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 9217 samples\n",
      "Epoch 1/10, Train Loss: 0.3782, Accuracy: 0.8921, F1 Micro: 0.6512, F1 Macro: 0.3566\n",
      "Epoch 2/10, Train Loss: 0.2472, Accuracy: 0.9114, F1 Micro: 0.7039, F1 Macro: 0.5066\n",
      "Epoch 3/10, Train Loss: 0.2017, Accuracy: 0.9203, F1 Micro: 0.7605, F1 Macro: 0.5832\n",
      "Epoch 4/10, Train Loss: 0.1696, Accuracy: 0.9234, F1 Micro: 0.7526, F1 Macro: 0.5885\n",
      "Epoch 5/10, Train Loss: 0.145, Accuracy: 0.9266, F1 Micro: 0.7775, F1 Macro: 0.6445\n",
      "Epoch 6/10, Train Loss: 0.1228, Accuracy: 0.9259, F1 Micro: 0.7762, F1 Macro: 0.6294\n",
      "Epoch 7/10, Train Loss: 0.1001, Accuracy: 0.9252, F1 Micro: 0.7836, F1 Macro: 0.6736\n",
      "Epoch 8/10, Train Loss: 0.09, Accuracy: 0.9264, F1 Micro: 0.7768, F1 Macro: 0.6823\n",
      "Epoch 9/10, Train Loss: 0.0708, Accuracy: 0.9258, F1 Micro: 0.7834, F1 Macro: 0.6926\n",
      "Epoch 10/10, Train Loss: 0.0634, Accuracy: 0.9285, F1 Micro: 0.781, F1 Macro: 0.6917\n",
      "Best result for 9217 samples: F1 Micro: 0.7836\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.89      0.85      1107\n",
      "      Abusive       0.87      0.92      0.89      1030\n",
      "HS_Individual       0.71      0.80      0.76       729\n",
      "     HS_Group       0.78      0.66      0.71       378\n",
      "  HS_Religion       0.84      0.56      0.67       167\n",
      "      HS_Race       0.75      0.59      0.66        88\n",
      "  HS_Physical       0.62      0.14      0.22        74\n",
      "    HS_Gender       0.88      0.29      0.44        75\n",
      "     HS_Other       0.74      0.84      0.79       744\n",
      "      HS_Weak       0.69      0.79      0.73       690\n",
      "  HS_Moderate       0.71      0.58      0.64       338\n",
      "    HS_Strong       0.81      0.63      0.71        79\n",
      "\n",
      "    micro avg       0.77      0.79      0.78      5499\n",
      "    macro avg       0.77      0.64      0.67      5499\n",
      " weighted avg       0.77      0.79      0.78      5499\n",
      "  samples avg       0.45      0.44      0.43      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 30.731324005126954\n",
      "Samples above threshold: 132\n",
      "Acquired samples: 1\n",
      "Sampling duration: 8.09534215927124 seconds\n",
      "\n",
      "Fold 4 - New train size: 9218\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 9218 samples\n",
      "Epoch 1/10, Train Loss: 0.3812, Accuracy: 0.8857, F1 Micro: 0.5686, F1 Macro: 0.2852\n",
      "Epoch 2/10, Train Loss: 0.2536, Accuracy: 0.9094, F1 Micro: 0.7018, F1 Macro: 0.4508\n",
      "Epoch 3/10, Train Loss: 0.2043, Accuracy: 0.9187, F1 Micro: 0.7339, F1 Macro: 0.5389\n",
      "Epoch 4/10, Train Loss: 0.1731, Accuracy: 0.9211, F1 Micro: 0.7735, F1 Macro: 0.6123\n",
      "Epoch 5/10, Train Loss: 0.1466, Accuracy: 0.9238, F1 Micro: 0.7803, F1 Macro: 0.6266\n",
      "Epoch 6/10, Train Loss: 0.122, Accuracy: 0.9236, F1 Micro: 0.7701, F1 Macro: 0.6419\n",
      "Epoch 7/10, Train Loss: 0.1032, Accuracy: 0.926, F1 Micro: 0.7696, F1 Macro: 0.6403\n",
      "Epoch 8/10, Train Loss: 0.0876, Accuracy: 0.9241, F1 Micro: 0.7789, F1 Macro: 0.6871\n",
      "Epoch 9/10, Train Loss: 0.0721, Accuracy: 0.9258, F1 Micro: 0.7746, F1 Macro: 0.6844\n",
      "Epoch 10/10, Train Loss: 0.0654, Accuracy: 0.9248, F1 Micro: 0.7745, F1 Macro: 0.6893\n",
      "Best result for 9218 samples: F1 Micro: 0.7803\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.91      0.86      1107\n",
      "      Abusive       0.90      0.90      0.90      1030\n",
      "HS_Individual       0.71      0.81      0.76       729\n",
      "     HS_Group       0.75      0.65      0.70       378\n",
      "  HS_Religion       0.83      0.56      0.67       167\n",
      "      HS_Race       0.71      0.57      0.63        88\n",
      "  HS_Physical       1.00      0.04      0.08        74\n",
      "    HS_Gender       0.67      0.03      0.05        75\n",
      "     HS_Other       0.70      0.87      0.77       744\n",
      "      HS_Weak       0.69      0.79      0.74       690\n",
      "  HS_Moderate       0.67      0.60      0.63       338\n",
      "    HS_Strong       0.80      0.66      0.72        79\n",
      "\n",
      "    micro avg       0.77      0.79      0.78      5499\n",
      "    macro avg       0.77      0.62      0.63      5499\n",
      " weighted avg       0.77      0.79      0.77      5499\n",
      "  samples avg       0.44      0.43      0.42      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 27.562068367004393\n",
      "Samples above threshold: 132\n",
      "Acquired samples: 200\n",
      "Sampling duration: 7.866865873336792 seconds\n",
      "\n",
      "Fold 4 - New train size: 9418\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 9418 samples\n",
      "Epoch 1/10, Train Loss: 0.379, Accuracy: 0.8881, F1 Micro: 0.5919, F1 Macro: 0.2994\n",
      "Epoch 2/10, Train Loss: 0.2513, Accuracy: 0.9089, F1 Micro: 0.6874, F1 Macro: 0.4953\n",
      "Epoch 3/10, Train Loss: 0.2103, Accuracy: 0.923, F1 Micro: 0.7567, F1 Macro: 0.58\n",
      "Epoch 4/10, Train Loss: 0.1754, Accuracy: 0.9252, F1 Micro: 0.7725, F1 Macro: 0.6008\n",
      "Epoch 5/10, Train Loss: 0.1498, Accuracy: 0.925, F1 Micro: 0.7758, F1 Macro: 0.6252\n",
      "Epoch 6/10, Train Loss: 0.1222, Accuracy: 0.9266, F1 Micro: 0.7759, F1 Macro: 0.6299\n",
      "Epoch 7/10, Train Loss: 0.1065, Accuracy: 0.9245, F1 Micro: 0.78, F1 Macro: 0.6776\n",
      "Epoch 8/10, Train Loss: 0.0922, Accuracy: 0.9223, F1 Micro: 0.778, F1 Macro: 0.6641\n",
      "Epoch 9/10, Train Loss: 0.08, Accuracy: 0.9253, F1 Micro: 0.778, F1 Macro: 0.6824\n",
      "Epoch 10/10, Train Loss: 0.064, Accuracy: 0.9252, F1 Micro: 0.785, F1 Macro: 0.6969\n",
      "Best result for 9418 samples: F1 Micro: 0.785\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.90      0.86      1107\n",
      "      Abusive       0.90      0.92      0.91      1030\n",
      "HS_Individual       0.70      0.79      0.75       729\n",
      "     HS_Group       0.71      0.66      0.68       378\n",
      "  HS_Religion       0.72      0.70      0.71       167\n",
      "      HS_Race       0.78      0.66      0.72        88\n",
      "  HS_Physical       0.71      0.23      0.35        74\n",
      "    HS_Gender       0.81      0.39      0.52        75\n",
      "     HS_Other       0.76      0.85      0.80       744\n",
      "      HS_Weak       0.68      0.78      0.73       690\n",
      "  HS_Moderate       0.64      0.59      0.62       338\n",
      "    HS_Strong       0.78      0.68      0.73        79\n",
      "\n",
      "    micro avg       0.77      0.80      0.78      5499\n",
      "    macro avg       0.75      0.68      0.70      5499\n",
      " weighted avg       0.77      0.80      0.78      5499\n",
      "  samples avg       0.45      0.44      0.43      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 30.803699111938478\n",
      "Samples above threshold: 112\n",
      "Acquired samples: 200\n",
      "Sampling duration: 6.6871867179870605 seconds\n",
      "\n",
      "Fold 4 - New train size: 9618\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 9618 samples\n",
      "Epoch 1/10, Train Loss: 0.3734, Accuracy: 0.8946, F1 Micro: 0.6539, F1 Macro: 0.3681\n",
      "Epoch 2/10, Train Loss: 0.2497, Accuracy: 0.9087, F1 Micro: 0.7274, F1 Macro: 0.4987\n",
      "Epoch 3/10, Train Loss: 0.2062, Accuracy: 0.9209, F1 Micro: 0.7395, F1 Macro: 0.5647\n",
      "Epoch 4/10, Train Loss: 0.1699, Accuracy: 0.9265, F1 Micro: 0.7725, F1 Macro: 0.6131\n",
      "Epoch 5/10, Train Loss: 0.1456, Accuracy: 0.9271, F1 Micro: 0.7721, F1 Macro: 0.62\n",
      "Epoch 6/10, Train Loss: 0.1197, Accuracy: 0.9289, F1 Micro: 0.7844, F1 Macro: 0.6468\n",
      "Epoch 7/10, Train Loss: 0.0998, Accuracy: 0.9295, F1 Micro: 0.786, F1 Macro: 0.6785\n",
      "Epoch 8/10, Train Loss: 0.0871, Accuracy: 0.9292, F1 Micro: 0.7893, F1 Macro: 0.6865\n",
      "Epoch 9/10, Train Loss: 0.0716, Accuracy: 0.9235, F1 Micro: 0.7797, F1 Macro: 0.6758\n",
      "Epoch 10/10, Train Loss: 0.0639, Accuracy: 0.9268, F1 Micro: 0.7829, F1 Macro: 0.6798\n",
      "Best result for 9618 samples: F1 Micro: 0.7893\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.87      0.86      1107\n",
      "      Abusive       0.91      0.91      0.91      1030\n",
      "HS_Individual       0.73      0.80      0.76       729\n",
      "     HS_Group       0.81      0.62      0.70       378\n",
      "  HS_Religion       0.86      0.54      0.66       167\n",
      "      HS_Race       0.82      0.51      0.63        88\n",
      "  HS_Physical       0.56      0.24      0.34        74\n",
      "    HS_Gender       0.82      0.36      0.50        75\n",
      "     HS_Other       0.77      0.82      0.79       744\n",
      "      HS_Weak       0.71      0.79      0.75       690\n",
      "  HS_Moderate       0.74      0.54      0.63       338\n",
      "    HS_Strong       0.81      0.63      0.71        79\n",
      "\n",
      "    micro avg       0.80      0.78      0.79      5499\n",
      "    macro avg       0.78      0.64      0.69      5499\n",
      " weighted avg       0.80      0.78      0.78      5499\n",
      "  samples avg       0.44      0.43      0.42      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 27.0964921951294\n",
      "Samples above threshold: 92\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.879901647567749 seconds\n",
      "\n",
      "Fold 4 - New train size: 9818\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 9818 samples\n",
      "Epoch 1/10, Train Loss: 0.3782, Accuracy: 0.8921, F1 Micro: 0.6284, F1 Macro: 0.3159\n",
      "Epoch 2/10, Train Loss: 0.2523, Accuracy: 0.9129, F1 Micro: 0.7204, F1 Macro: 0.4919\n",
      "Epoch 3/10, Train Loss: 0.2081, Accuracy: 0.9198, F1 Micro: 0.7544, F1 Macro: 0.5567\n",
      "Epoch 4/10, Train Loss: 0.1696, Accuracy: 0.9271, F1 Micro: 0.7708, F1 Macro: 0.6045\n",
      "Epoch 5/10, Train Loss: 0.1402, Accuracy: 0.9275, F1 Micro: 0.7695, F1 Macro: 0.6293\n",
      "Epoch 6/10, Train Loss: 0.1225, Accuracy: 0.9269, F1 Micro: 0.7868, F1 Macro: 0.6487\n",
      "Epoch 7/10, Train Loss: 0.1004, Accuracy: 0.9237, F1 Micro: 0.7793, F1 Macro: 0.6492\n",
      "Epoch 8/10, Train Loss: 0.0872, Accuracy: 0.9268, F1 Micro: 0.7843, F1 Macro: 0.6802\n",
      "Epoch 9/10, Train Loss: 0.0722, Accuracy: 0.9273, F1 Micro: 0.7749, F1 Macro: 0.6486\n",
      "Epoch 10/10, Train Loss: 0.0639, Accuracy: 0.9229, F1 Micro: 0.7814, F1 Macro: 0.6828\n",
      "Best result for 9818 samples: F1 Micro: 0.7868\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.89      0.86      1107\n",
      "      Abusive       0.89      0.93      0.91      1030\n",
      "HS_Individual       0.76      0.76      0.76       729\n",
      "     HS_Group       0.68      0.73      0.71       378\n",
      "  HS_Religion       0.81      0.63      0.71       167\n",
      "      HS_Race       0.73      0.69      0.71        88\n",
      "  HS_Physical       0.67      0.03      0.05        74\n",
      "    HS_Gender       0.90      0.12      0.21        75\n",
      "     HS_Other       0.75      0.85      0.79       744\n",
      "      HS_Weak       0.73      0.73      0.73       690\n",
      "  HS_Moderate       0.62      0.68      0.65       338\n",
      "    HS_Strong       0.77      0.63      0.69        79\n",
      "\n",
      "    micro avg       0.78      0.79      0.79      5499\n",
      "    macro avg       0.76      0.64      0.65      5499\n",
      " weighted avg       0.78      0.79      0.78      5499\n",
      "  samples avg       0.44      0.44      0.43      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 27.361838722229006\n",
      "Samples above threshold: 72\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.990262269973755 seconds\n",
      "\n",
      "Fold 4 - New train size: 10018\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 10018 samples\n",
      "Epoch 1/10, Train Loss: 0.3765, Accuracy: 0.8875, F1 Micro: 0.5872, F1 Macro: 0.2848\n",
      "Epoch 2/10, Train Loss: 0.2495, Accuracy: 0.9118, F1 Micro: 0.7069, F1 Macro: 0.4847\n",
      "Epoch 3/10, Train Loss: 0.2078, Accuracy: 0.9215, F1 Micro: 0.7597, F1 Macro: 0.5841\n",
      "Epoch 4/10, Train Loss: 0.1697, Accuracy: 0.9245, F1 Micro: 0.7736, F1 Macro: 0.597\n",
      "Epoch 5/10, Train Loss: 0.1436, Accuracy: 0.9258, F1 Micro: 0.785, F1 Macro: 0.6438\n",
      "Epoch 6/10, Train Loss: 0.122, Accuracy: 0.9278, F1 Micro: 0.7844, F1 Macro: 0.6494\n",
      "Epoch 7/10, Train Loss: 0.096, Accuracy: 0.9269, F1 Micro: 0.7872, F1 Macro: 0.6731\n",
      "Epoch 8/10, Train Loss: 0.0849, Accuracy: 0.9293, F1 Micro: 0.7866, F1 Macro: 0.6744\n",
      "Epoch 9/10, Train Loss: 0.0722, Accuracy: 0.9286, F1 Micro: 0.7863, F1 Macro: 0.6903\n",
      "Epoch 10/10, Train Loss: 0.0639, Accuracy: 0.9264, F1 Micro: 0.7786, F1 Macro: 0.6916\n",
      "Best result for 10018 samples: F1 Micro: 0.7872\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.89      0.86      1107\n",
      "      Abusive       0.88      0.93      0.90      1030\n",
      "HS_Individual       0.75      0.75      0.75       729\n",
      "     HS_Group       0.67      0.72      0.70       378\n",
      "  HS_Religion       0.81      0.61      0.70       167\n",
      "      HS_Race       0.74      0.62      0.68        88\n",
      "  HS_Physical       0.53      0.12      0.20        74\n",
      "    HS_Gender       0.90      0.25      0.40        75\n",
      "     HS_Other       0.77      0.84      0.80       744\n",
      "      HS_Weak       0.73      0.74      0.73       690\n",
      "  HS_Moderate       0.62      0.68      0.65       338\n",
      "    HS_Strong       0.83      0.62      0.71        79\n",
      "\n",
      "    micro avg       0.78      0.79      0.79      5499\n",
      "    macro avg       0.76      0.65      0.67      5499\n",
      " weighted avg       0.78      0.79      0.78      5499\n",
      "  samples avg       0.44      0.44      0.43      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 25.974402236938477\n",
      "Samples above threshold: 52\n",
      "Acquired samples: 200\n",
      "Sampling duration: 3.8712100982666016 seconds\n",
      "\n",
      "Fold 4 - New train size: 10218\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 10218 samples\n",
      "Epoch 1/10, Train Loss: 0.3725, Accuracy: 0.8944, F1 Micro: 0.6547, F1 Macro: 0.3543\n",
      "Epoch 2/10, Train Loss: 0.2508, Accuracy: 0.9141, F1 Micro: 0.7227, F1 Macro: 0.5471\n",
      "Epoch 3/10, Train Loss: 0.2031, Accuracy: 0.9198, F1 Micro: 0.7377, F1 Macro: 0.5481\n",
      "Epoch 4/10, Train Loss: 0.1702, Accuracy: 0.9265, F1 Micro: 0.7691, F1 Macro: 0.599\n",
      "Epoch 5/10, Train Loss: 0.1438, Accuracy: 0.9227, F1 Micro: 0.7834, F1 Macro: 0.6355\n",
      "Epoch 6/10, Train Loss: 0.1252, Accuracy: 0.9243, F1 Micro: 0.784, F1 Macro: 0.6597\n",
      "Epoch 7/10, Train Loss: 0.101, Accuracy: 0.9289, F1 Micro: 0.7902, F1 Macro: 0.683\n",
      "Epoch 8/10, Train Loss: 0.0865, Accuracy: 0.9281, F1 Micro: 0.7862, F1 Macro: 0.6813\n",
      "Epoch 9/10, Train Loss: 0.0747, Accuracy: 0.9284, F1 Micro: 0.7884, F1 Macro: 0.6864\n",
      "Epoch 10/10, Train Loss: 0.0663, Accuracy: 0.9266, F1 Micro: 0.7886, F1 Macro: 0.7047\n",
      "Best result for 10218 samples: F1 Micro: 0.7902\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.88      0.86      1107\n",
      "      Abusive       0.91      0.93      0.92      1030\n",
      "HS_Individual       0.75      0.76      0.75       729\n",
      "     HS_Group       0.74      0.68      0.71       378\n",
      "  HS_Religion       0.78      0.60      0.68       167\n",
      "      HS_Race       0.75      0.64      0.69        88\n",
      "  HS_Physical       0.57      0.16      0.25        74\n",
      "    HS_Gender       0.88      0.31      0.46        75\n",
      "     HS_Other       0.77      0.83      0.80       744\n",
      "      HS_Weak       0.72      0.75      0.73       690\n",
      "  HS_Moderate       0.68      0.62      0.65       338\n",
      "    HS_Strong       0.80      0.62      0.70        79\n",
      "\n",
      "    micro avg       0.80      0.79      0.79      5499\n",
      "    macro avg       0.77      0.65      0.68      5499\n",
      " weighted avg       0.79      0.79      0.78      5499\n",
      "  samples avg       0.45      0.44      0.43      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 27.953331184387206\n",
      "Samples above threshold: 32\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.7279510498046875 seconds\n",
      "\n",
      "Fold 4 - New train size: 10418\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 10418 samples\n",
      "Epoch 1/10, Train Loss: 0.3676, Accuracy: 0.89, F1 Micro: 0.5965, F1 Macro: 0.3051\n",
      "Epoch 2/10, Train Loss: 0.248, Accuracy: 0.9151, F1 Micro: 0.7331, F1 Macro: 0.5418\n",
      "Epoch 3/10, Train Loss: 0.1966, Accuracy: 0.9227, F1 Micro: 0.764, F1 Macro: 0.5836\n",
      "Epoch 4/10, Train Loss: 0.1676, Accuracy: 0.9265, F1 Micro: 0.7742, F1 Macro: 0.6172\n",
      "Epoch 5/10, Train Loss: 0.142, Accuracy: 0.9253, F1 Micro: 0.7764, F1 Macro: 0.6468\n",
      "Epoch 6/10, Train Loss: 0.1189, Accuracy: 0.9274, F1 Micro: 0.7817, F1 Macro: 0.6337\n",
      "Epoch 7/10, Train Loss: 0.0991, Accuracy: 0.9285, F1 Micro: 0.7854, F1 Macro: 0.6865\n",
      "Epoch 8/10, Train Loss: 0.082, Accuracy: 0.9288, F1 Micro: 0.7823, F1 Macro: 0.6802\n",
      "Epoch 9/10, Train Loss: 0.0724, Accuracy: 0.9254, F1 Micro: 0.7817, F1 Macro: 0.693\n",
      "Epoch 10/10, Train Loss: 0.0629, Accuracy: 0.9285, F1 Micro: 0.7857, F1 Macro: 0.6928\n",
      "Best result for 10418 samples: F1 Micro: 0.7857\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.87      0.86      1107\n",
      "      Abusive       0.92      0.91      0.92      1030\n",
      "HS_Individual       0.77      0.71      0.74       729\n",
      "     HS_Group       0.68      0.68      0.68       378\n",
      "  HS_Religion       0.76      0.66      0.71       167\n",
      "      HS_Race       0.72      0.65      0.68        88\n",
      "  HS_Physical       0.64      0.24      0.35        74\n",
      "    HS_Gender       0.96      0.33      0.50        75\n",
      "     HS_Other       0.80      0.80      0.80       744\n",
      "      HS_Weak       0.74      0.69      0.71       690\n",
      "  HS_Moderate       0.63      0.63      0.63       338\n",
      "    HS_Strong       0.77      0.68      0.72        79\n",
      "\n",
      "    micro avg       0.80      0.77      0.79      5499\n",
      "    macro avg       0.77      0.66      0.69      5499\n",
      " weighted avg       0.80      0.77      0.78      5499\n",
      "  samples avg       0.45      0.43      0.42      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 19.46111259460449\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 117\n",
      "Sampling duration: 1.8150994777679443 seconds\n",
      "\n",
      "Fold 4 - New train size: 10535\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 10535 samples\n",
      "Epoch 1/10, Train Loss: 0.3712, Accuracy: 0.8942, F1 Micro: 0.6312, F1 Macro: 0.354\n",
      "Epoch 2/10, Train Loss: 0.2459, Accuracy: 0.9133, F1 Micro: 0.7261, F1 Macro: 0.4964\n",
      "Epoch 3/10, Train Loss: 0.1984, Accuracy: 0.9213, F1 Micro: 0.7596, F1 Macro: 0.5662\n",
      "Epoch 4/10, Train Loss: 0.1689, Accuracy: 0.9264, F1 Micro: 0.7821, F1 Macro: 0.6178\n",
      "Epoch 5/10, Train Loss: 0.14, Accuracy: 0.9285, F1 Micro: 0.7806, F1 Macro: 0.6436\n",
      "Epoch 6/10, Train Loss: 0.1142, Accuracy: 0.9271, F1 Micro: 0.7702, F1 Macro: 0.6254\n",
      "Epoch 7/10, Train Loss: 0.0966, Accuracy: 0.9271, F1 Micro: 0.7856, F1 Macro: 0.6812\n",
      "Epoch 8/10, Train Loss: 0.0825, Accuracy: 0.9295, F1 Micro: 0.7882, F1 Macro: 0.6918\n",
      "Epoch 9/10, Train Loss: 0.072, Accuracy: 0.9255, F1 Micro: 0.7851, F1 Macro: 0.6838\n",
      "Epoch 10/10, Train Loss: 0.0609, Accuracy: 0.9287, F1 Micro: 0.7798, F1 Macro: 0.6923\n",
      "Best result for 10535 samples: F1 Micro: 0.7882\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.86      0.86      1107\n",
      "      Abusive       0.91      0.92      0.92      1030\n",
      "HS_Individual       0.77      0.74      0.75       729\n",
      "     HS_Group       0.72      0.67      0.70       378\n",
      "  HS_Religion       0.75      0.69      0.72       167\n",
      "      HS_Race       0.75      0.67      0.71        88\n",
      "  HS_Physical       0.54      0.19      0.28        74\n",
      "    HS_Gender       0.93      0.36      0.52        75\n",
      "     HS_Other       0.81      0.77      0.79       744\n",
      "      HS_Weak       0.73      0.72      0.73       690\n",
      "  HS_Moderate       0.67      0.61      0.64       338\n",
      "    HS_Strong       0.81      0.61      0.70        79\n",
      "\n",
      "    micro avg       0.81      0.77      0.79      5499\n",
      "    macro avg       0.77      0.65      0.69      5499\n",
      " weighted avg       0.81      0.77      0.78      5499\n",
      "  samples avg       0.45      0.43      0.42      5499\n",
      "\n",
      "\n",
      "FOLD 4 COMPLETED in 5799.92 seconds\n",
      "===============================================\n",
      "STARTING FOLD 5/5\n",
      "===============================================\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 658 samples\n",
      "Epoch 1/10, Train Loss: 0.612, Accuracy: 0.8159, F1 Micro: 0.2154, F1 Macro: 0.062\n",
      "Epoch 2/10, Train Loss: 0.4594, Accuracy: 0.8202, F1 Micro: 0.0041, F1 Macro: 0.0018\n",
      "Epoch 3/10, Train Loss: 0.4164, Accuracy: 0.8224, F1 Micro: 0.0357, F1 Macro: 0.0153\n",
      "Epoch 4/10, Train Loss: 0.3858, Accuracy: 0.8233, F1 Micro: 0.0465, F1 Macro: 0.0197\n",
      "Epoch 5/10, Train Loss: 0.3698, Accuracy: 0.8312, F1 Micro: 0.138, F1 Macro: 0.0538\n",
      "Epoch 6/10, Train Loss: 0.3637, Accuracy: 0.843, F1 Micro: 0.2883, F1 Macro: 0.1014\n",
      "Epoch 7/10, Train Loss: 0.3557, Accuracy: 0.8501, F1 Micro: 0.3628, F1 Macro: 0.1452\n",
      "Epoch 8/10, Train Loss: 0.3269, Accuracy: 0.8637, F1 Micro: 0.5003, F1 Macro: 0.2267\n",
      "Epoch 9/10, Train Loss: 0.3068, Accuracy: 0.8713, F1 Micro: 0.5585, F1 Macro: 0.2602\n",
      "Epoch 10/10, Train Loss: 0.295, Accuracy: 0.8748, F1 Micro: 0.5825, F1 Macro: 0.2728\n",
      "Best result for 658 samples: F1 Micro: 0.5825\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.74      0.77      1190\n",
      "      Abusive       0.83      0.71      0.77      1018\n",
      "HS_Individual       0.65      0.56      0.60       768\n",
      "     HS_Group       0.00      0.00      0.00       422\n",
      "  HS_Religion       0.00      0.00      0.00       173\n",
      "      HS_Race       0.00      0.00      0.00       126\n",
      "  HS_Physical       0.00      0.00      0.00        60\n",
      "    HS_Gender       0.00      0.00      0.00        67\n",
      "     HS_Other       0.64      0.54      0.59       792\n",
      "      HS_Weak       0.62      0.49      0.55       725\n",
      "  HS_Moderate       0.00      0.00      0.00       352\n",
      "    HS_Strong       0.00      0.00      0.00       113\n",
      "\n",
      "    micro avg       0.73      0.49      0.58      5806\n",
      "    macro avg       0.30      0.25      0.27      5806\n",
      " weighted avg       0.56      0.49      0.52      5806\n",
      "  samples avg       0.37      0.29      0.30      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 27.2963363647461\n",
      "Samples above threshold: 988\n",
      "Acquired samples: 988\n",
      "Sampling duration: 50.53290510177612 seconds\n",
      "\n",
      "Fold 5 - New train size: 1646\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 1646 samples\n",
      "Epoch 1/10, Train Loss: 0.489, Accuracy: 0.82, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.3024, Accuracy: 0.82, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.2622, Accuracy: 0.82, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 4/10, Train Loss: 0.2438, Accuracy: 0.8426, F1 Micro: 0.309, F1 Macro: 0.1129\n",
      "Epoch 5/10, Train Loss: 0.212, Accuracy: 0.8601, F1 Micro: 0.4873, F1 Macro: 0.2152\n",
      "Epoch 6/10, Train Loss: 0.1972, Accuracy: 0.8672, F1 Micro: 0.5915, F1 Macro: 0.2724\n",
      "Epoch 7/10, Train Loss: 0.1697, Accuracy: 0.8718, F1 Micro: 0.5526, F1 Macro: 0.2564\n",
      "Epoch 8/10, Train Loss: 0.1581, Accuracy: 0.8752, F1 Micro: 0.5832, F1 Macro: 0.2838\n",
      "Epoch 9/10, Train Loss: 0.1377, Accuracy: 0.8756, F1 Micro: 0.6202, F1 Macro: 0.3143\n",
      "Epoch 10/10, Train Loss: 0.134, Accuracy: 0.8784, F1 Micro: 0.6168, F1 Macro: 0.3305\n",
      "Best result for 1646 samples: F1 Micro: 0.6202\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.78      0.81      0.80      1190\n",
      "      Abusive       0.83      0.81      0.82      1018\n",
      "HS_Individual       0.59      0.61      0.60       768\n",
      "     HS_Group       0.63      0.21      0.32       422\n",
      "  HS_Religion       0.00      0.00      0.00       173\n",
      "      HS_Race       0.00      0.00      0.00       126\n",
      "  HS_Physical       0.00      0.00      0.00        60\n",
      "    HS_Gender       0.00      0.00      0.00        67\n",
      "     HS_Other       0.61      0.65      0.63       792\n",
      "      HS_Weak       0.57      0.57      0.57       725\n",
      "  HS_Moderate       0.15      0.01      0.01       352\n",
      "    HS_Strong       1.00      0.02      0.03       113\n",
      "\n",
      "    micro avg       0.69      0.56      0.62      5806\n",
      "    macro avg       0.43      0.31      0.31      5806\n",
      " weighted avg       0.61      0.56      0.57      5806\n",
      "  samples avg       0.40      0.34      0.34      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 39.413665771484375\n",
      "Samples above threshold: 890\n",
      "Acquired samples: 890\n",
      "Sampling duration: 44.98979139328003 seconds\n",
      "\n",
      "Fold 5 - New train size: 2536\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 2536 samples\n",
      "Epoch 1/10, Train Loss: 0.498, Accuracy: 0.8384, F1 Micro: 0.3211, F1 Macro: 0.0945\n",
      "Epoch 2/10, Train Loss: 0.3547, Accuracy: 0.86, F1 Micro: 0.5081, F1 Macro: 0.2291\n",
      "Epoch 3/10, Train Loss: 0.2882, Accuracy: 0.8747, F1 Micro: 0.6058, F1 Macro: 0.3559\n",
      "Epoch 4/10, Train Loss: 0.2517, Accuracy: 0.8861, F1 Micro: 0.6364, F1 Macro: 0.4321\n",
      "Epoch 5/10, Train Loss: 0.2201, Accuracy: 0.8929, F1 Micro: 0.6637, F1 Macro: 0.4709\n",
      "Epoch 6/10, Train Loss: 0.1994, Accuracy: 0.8952, F1 Micro: 0.6641, F1 Macro: 0.4737\n",
      "Epoch 7/10, Train Loss: 0.1655, Accuracy: 0.896, F1 Micro: 0.7107, F1 Macro: 0.5447\n",
      "Epoch 8/10, Train Loss: 0.148, Accuracy: 0.8965, F1 Micro: 0.702, F1 Macro: 0.54\n",
      "Epoch 9/10, Train Loss: 0.1308, Accuracy: 0.8992, F1 Micro: 0.6936, F1 Macro: 0.544\n",
      "Epoch 10/10, Train Loss: 0.1197, Accuracy: 0.8988, F1 Micro: 0.697, F1 Macro: 0.5534\n",
      "Best result for 2536 samples: F1 Micro: 0.7107\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.77      0.87      0.81      1190\n",
      "      Abusive       0.80      0.87      0.83      1018\n",
      "HS_Individual       0.65      0.73      0.69       768\n",
      "     HS_Group       0.69      0.53      0.60       422\n",
      "  HS_Religion       0.68      0.25      0.36       173\n",
      "      HS_Race       0.76      0.56      0.64       126\n",
      "  HS_Physical       0.00      0.00      0.00        60\n",
      "    HS_Gender       0.00      0.00      0.00        67\n",
      "     HS_Other       0.67      0.74      0.70       792\n",
      "      HS_Weak       0.63      0.70      0.66       725\n",
      "  HS_Moderate       0.63      0.34      0.44       352\n",
      "    HS_Strong       0.78      0.80      0.79       113\n",
      "\n",
      "    micro avg       0.71      0.71      0.71      5806\n",
      "    macro avg       0.59      0.53      0.54      5806\n",
      " weighted avg       0.69      0.71      0.69      5806\n",
      "  samples avg       0.43      0.42      0.40      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 35.65656280517578\n",
      "Samples above threshold: 801\n",
      "Acquired samples: 801\n",
      "Sampling duration: 41.34053587913513 seconds\n",
      "\n",
      "Fold 5 - New train size: 3337\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 3337 samples\n",
      "Epoch 1/10, Train Loss: 0.456, Accuracy: 0.8424, F1 Micro: 0.2967, F1 Macro: 0.0927\n",
      "Epoch 2/10, Train Loss: 0.3108, Accuracy: 0.8691, F1 Micro: 0.5261, F1 Macro: 0.252\n",
      "Epoch 3/10, Train Loss: 0.2423, Accuracy: 0.8809, F1 Micro: 0.5797, F1 Macro: 0.3489\n",
      "Epoch 4/10, Train Loss: 0.2122, Accuracy: 0.8925, F1 Micro: 0.6614, F1 Macro: 0.4582\n",
      "Epoch 5/10, Train Loss: 0.1777, Accuracy: 0.8972, F1 Micro: 0.6821, F1 Macro: 0.4722\n",
      "Epoch 6/10, Train Loss: 0.1538, Accuracy: 0.9007, F1 Micro: 0.6924, F1 Macro: 0.5155\n",
      "Epoch 7/10, Train Loss: 0.1361, Accuracy: 0.8993, F1 Micro: 0.7143, F1 Macro: 0.5568\n",
      "Epoch 8/10, Train Loss: 0.1155, Accuracy: 0.9022, F1 Micro: 0.713, F1 Macro: 0.5693\n",
      "Epoch 9/10, Train Loss: 0.1031, Accuracy: 0.9007, F1 Micro: 0.7058, F1 Macro: 0.56\n",
      "Epoch 10/10, Train Loss: 0.0898, Accuracy: 0.9023, F1 Micro: 0.7025, F1 Macro: 0.5704\n",
      "Best result for 3337 samples: F1 Micro: 0.7143\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.77      0.86      0.81      1190\n",
      "      Abusive       0.85      0.85      0.85      1018\n",
      "HS_Individual       0.67      0.69      0.68       768\n",
      "     HS_Group       0.67      0.55      0.61       422\n",
      "  HS_Religion       0.67      0.29      0.40       173\n",
      "      HS_Race       0.78      0.51      0.62       126\n",
      "  HS_Physical       1.00      0.05      0.10        60\n",
      "    HS_Gender       0.00      0.00      0.00        67\n",
      "     HS_Other       0.69      0.75      0.71       792\n",
      "      HS_Weak       0.67      0.65      0.66       725\n",
      "  HS_Moderate       0.58      0.38      0.46       352\n",
      "    HS_Strong       0.76      0.80      0.78       113\n",
      "\n",
      "    micro avg       0.73      0.70      0.71      5806\n",
      "    macro avg       0.68      0.53      0.56      5806\n",
      " weighted avg       0.72      0.70      0.70      5806\n",
      "  samples avg       0.43      0.41      0.40      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 34.60460586547852\n",
      "Samples above threshold: 720\n",
      "Acquired samples: 720\n",
      "Sampling duration: 38.45539617538452 seconds\n",
      "\n",
      "Fold 5 - New train size: 4057\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 4057 samples\n",
      "Epoch 1/10, Train Loss: 0.4655, Accuracy: 0.8509, F1 Micro: 0.4255, F1 Macro: 0.1344\n",
      "Epoch 2/10, Train Loss: 0.3148, Accuracy: 0.8734, F1 Micro: 0.537, F1 Macro: 0.2763\n",
      "Epoch 3/10, Train Loss: 0.2519, Accuracy: 0.8917, F1 Micro: 0.6469, F1 Macro: 0.4706\n",
      "Epoch 4/10, Train Loss: 0.2196, Accuracy: 0.8992, F1 Micro: 0.6915, F1 Macro: 0.4984\n",
      "Epoch 5/10, Train Loss: 0.1844, Accuracy: 0.9067, F1 Micro: 0.7247, F1 Macro: 0.5731\n",
      "Epoch 6/10, Train Loss: 0.1625, Accuracy: 0.9075, F1 Micro: 0.735, F1 Macro: 0.5867\n",
      "Epoch 7/10, Train Loss: 0.1402, Accuracy: 0.9102, F1 Micro: 0.7329, F1 Macro: 0.5914\n",
      "Epoch 8/10, Train Loss: 0.1209, Accuracy: 0.9071, F1 Micro: 0.7173, F1 Macro: 0.582\n",
      "Epoch 9/10, Train Loss: 0.1033, Accuracy: 0.9104, F1 Micro: 0.7382, F1 Macro: 0.6276\n",
      "Epoch 10/10, Train Loss: 0.0935, Accuracy: 0.9092, F1 Micro: 0.7476, F1 Macro: 0.6466\n",
      "Best result for 4057 samples: F1 Micro: 0.7476\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.81      0.86      0.83      1190\n",
      "      Abusive       0.87      0.86      0.87      1018\n",
      "HS_Individual       0.68      0.74      0.71       768\n",
      "     HS_Group       0.71      0.62      0.66       422\n",
      "  HS_Religion       0.65      0.56      0.60       173\n",
      "      HS_Race       0.72      0.75      0.73       126\n",
      "  HS_Physical       0.53      0.17      0.25        60\n",
      "    HS_Gender       0.86      0.18      0.30        67\n",
      "     HS_Other       0.74      0.75      0.74       792\n",
      "      HS_Weak       0.66      0.72      0.69       725\n",
      "  HS_Moderate       0.62      0.52      0.57       352\n",
      "    HS_Strong       0.84      0.77      0.80       113\n",
      "\n",
      "    micro avg       0.75      0.75      0.75      5806\n",
      "    macro avg       0.72      0.63      0.65      5806\n",
      " weighted avg       0.75      0.75      0.74      5806\n",
      "  samples avg       0.45      0.43      0.42      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 40.99077033996582\n",
      "Samples above threshold: 648\n",
      "Acquired samples: 648\n",
      "Sampling duration: 34.475664138793945 seconds\n",
      "\n",
      "Fold 5 - New train size: 4705\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 4705 samples\n",
      "Epoch 1/10, Train Loss: 0.4501, Accuracy: 0.8583, F1 Micro: 0.5437, F1 Macro: 0.2386\n",
      "Epoch 2/10, Train Loss: 0.3024, Accuracy: 0.8873, F1 Micro: 0.6633, F1 Macro: 0.4357\n",
      "Epoch 3/10, Train Loss: 0.2448, Accuracy: 0.8982, F1 Micro: 0.7012, F1 Macro: 0.4955\n",
      "Epoch 4/10, Train Loss: 0.2066, Accuracy: 0.9039, F1 Micro: 0.692, F1 Macro: 0.5114\n",
      "Epoch 5/10, Train Loss: 0.1807, Accuracy: 0.9106, F1 Micro: 0.7298, F1 Macro: 0.5703\n",
      "Epoch 6/10, Train Loss: 0.1576, Accuracy: 0.9116, F1 Micro: 0.7301, F1 Macro: 0.5886\n",
      "Epoch 7/10, Train Loss: 0.1304, Accuracy: 0.912, F1 Micro: 0.7404, F1 Macro: 0.6184\n",
      "Epoch 8/10, Train Loss: 0.1156, Accuracy: 0.9131, F1 Micro: 0.7487, F1 Macro: 0.6393\n",
      "Epoch 9/10, Train Loss: 0.0969, Accuracy: 0.9149, F1 Micro: 0.7586, F1 Macro: 0.6515\n",
      "Epoch 10/10, Train Loss: 0.089, Accuracy: 0.913, F1 Micro: 0.7542, F1 Macro: 0.6507\n",
      "Best result for 4705 samples: F1 Micro: 0.7586\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.85      0.84      1190\n",
      "      Abusive       0.86      0.89      0.87      1018\n",
      "HS_Individual       0.72      0.74      0.73       768\n",
      "     HS_Group       0.73      0.59      0.65       422\n",
      "  HS_Religion       0.64      0.45      0.53       173\n",
      "      HS_Race       0.80      0.68      0.74       126\n",
      "  HS_Physical       0.69      0.15      0.25        60\n",
      "    HS_Gender       0.89      0.24      0.38        67\n",
      "     HS_Other       0.76      0.79      0.78       792\n",
      "      HS_Weak       0.70      0.72      0.71       725\n",
      "  HS_Moderate       0.66      0.47      0.55       352\n",
      "    HS_Strong       0.84      0.77      0.81       113\n",
      "\n",
      "    micro avg       0.77      0.74      0.76      5806\n",
      "    macro avg       0.76      0.61      0.65      5806\n",
      " weighted avg       0.77      0.74      0.75      5806\n",
      "  samples avg       0.45      0.44      0.43      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 28.73066501617432\n",
      "Samples above threshold: 584\n",
      "Acquired samples: 584\n",
      "Sampling duration: 30.653223037719727 seconds\n",
      "\n",
      "Fold 5 - New train size: 5289\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 5289 samples\n",
      "Epoch 1/10, Train Loss: 0.4524, Accuracy: 0.8629, F1 Micro: 0.5173, F1 Macro: 0.2247\n",
      "Epoch 2/10, Train Loss: 0.3134, Accuracy: 0.8909, F1 Micro: 0.6607, F1 Macro: 0.4436\n",
      "Epoch 3/10, Train Loss: 0.2505, Accuracy: 0.9043, F1 Micro: 0.7134, F1 Macro: 0.5476\n",
      "Epoch 4/10, Train Loss: 0.2141, Accuracy: 0.9081, F1 Micro: 0.7283, F1 Macro: 0.5639\n",
      "Epoch 5/10, Train Loss: 0.1794, Accuracy: 0.9084, F1 Micro: 0.746, F1 Macro: 0.6056\n",
      "Epoch 6/10, Train Loss: 0.1552, Accuracy: 0.9144, F1 Micro: 0.752, F1 Macro: 0.6214\n",
      "Epoch 7/10, Train Loss: 0.1329, Accuracy: 0.9166, F1 Micro: 0.7564, F1 Macro: 0.6385\n",
      "Epoch 8/10, Train Loss: 0.1112, Accuracy: 0.9175, F1 Micro: 0.758, F1 Macro: 0.6498\n",
      "Epoch 9/10, Train Loss: 0.0984, Accuracy: 0.9166, F1 Micro: 0.7572, F1 Macro: 0.6659\n",
      "Epoch 10/10, Train Loss: 0.083, Accuracy: 0.9173, F1 Micro: 0.7623, F1 Macro: 0.668\n",
      "Best result for 5289 samples: F1 Micro: 0.7623\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.83      0.84      1190\n",
      "      Abusive       0.88      0.86      0.87      1018\n",
      "HS_Individual       0.74      0.72      0.73       768\n",
      "     HS_Group       0.73      0.62      0.67       422\n",
      "  HS_Religion       0.69      0.55      0.61       173\n",
      "      HS_Race       0.79      0.70      0.74       126\n",
      "  HS_Physical       0.71      0.17      0.27        60\n",
      "    HS_Gender       0.86      0.27      0.41        67\n",
      "     HS_Other       0.78      0.76      0.77       792\n",
      "      HS_Weak       0.71      0.71      0.71       725\n",
      "  HS_Moderate       0.67      0.51      0.58       352\n",
      "    HS_Strong       0.85      0.78      0.81       113\n",
      "\n",
      "    micro avg       0.79      0.74      0.76      5806\n",
      "    macro avg       0.77      0.62      0.67      5806\n",
      " weighted avg       0.79      0.74      0.76      5806\n",
      "  samples avg       0.45      0.43      0.42      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 37.07824172973633\n",
      "Samples above threshold: 525\n",
      "Acquired samples: 525\n",
      "Sampling duration: 27.965927124023438 seconds\n",
      "\n",
      "Fold 5 - New train size: 5814\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 5814 samples\n",
      "Epoch 1/10, Train Loss: 0.4457, Accuracy: 0.8682, F1 Micro: 0.5792, F1 Macro: 0.2706\n",
      "Epoch 2/10, Train Loss: 0.3034, Accuracy: 0.8931, F1 Micro: 0.6966, F1 Macro: 0.4776\n",
      "Epoch 3/10, Train Loss: 0.2423, Accuracy: 0.9047, F1 Micro: 0.7092, F1 Macro: 0.5259\n",
      "Epoch 4/10, Train Loss: 0.2045, Accuracy: 0.9138, F1 Micro: 0.7439, F1 Macro: 0.5913\n",
      "Epoch 5/10, Train Loss: 0.1764, Accuracy: 0.9155, F1 Micro: 0.7517, F1 Macro: 0.6059\n",
      "Epoch 6/10, Train Loss: 0.155, Accuracy: 0.9143, F1 Micro: 0.7539, F1 Macro: 0.6286\n",
      "Epoch 7/10, Train Loss: 0.1293, Accuracy: 0.9157, F1 Micro: 0.755, F1 Macro: 0.666\n",
      "Epoch 8/10, Train Loss: 0.1072, Accuracy: 0.9168, F1 Micro: 0.7492, F1 Macro: 0.6412\n",
      "Epoch 9/10, Train Loss: 0.0941, Accuracy: 0.9186, F1 Micro: 0.7546, F1 Macro: 0.678\n",
      "Epoch 10/10, Train Loss: 0.0841, Accuracy: 0.9177, F1 Micro: 0.7705, F1 Macro: 0.7131\n",
      "Best result for 5814 samples: F1 Micro: 0.7705\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.86      0.85      1190\n",
      "      Abusive       0.86      0.89      0.88      1018\n",
      "HS_Individual       0.74      0.73      0.74       768\n",
      "     HS_Group       0.70      0.67      0.68       422\n",
      "  HS_Religion       0.65      0.61      0.63       173\n",
      "      HS_Race       0.78      0.68      0.73       126\n",
      "  HS_Physical       0.89      0.40      0.55        60\n",
      "    HS_Gender       0.69      0.52      0.59        67\n",
      "     HS_Other       0.77      0.78      0.77       792\n",
      "      HS_Weak       0.71      0.71      0.71       725\n",
      "  HS_Moderate       0.62      0.60      0.61       352\n",
      "    HS_Strong       0.85      0.79      0.82       113\n",
      "\n",
      "    micro avg       0.77      0.77      0.77      5806\n",
      "    macro avg       0.76      0.69      0.71      5806\n",
      " weighted avg       0.77      0.77      0.77      5806\n",
      "  samples avg       0.45      0.45      0.44      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 38.35429306030274\n",
      "Samples above threshold: 473\n",
      "Acquired samples: 473\n",
      "Sampling duration: 25.160421133041382 seconds\n",
      "\n",
      "Fold 5 - New train size: 6287\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 6287 samples\n",
      "Epoch 1/10, Train Loss: 0.4274, Accuracy: 0.8649, F1 Micro: 0.6093, F1 Macro: 0.2939\n",
      "Epoch 2/10, Train Loss: 0.2913, Accuracy: 0.8946, F1 Micro: 0.6599, F1 Macro: 0.4395\n",
      "Epoch 3/10, Train Loss: 0.2316, Accuracy: 0.9047, F1 Micro: 0.7298, F1 Macro: 0.5591\n",
      "Epoch 4/10, Train Loss: 0.1962, Accuracy: 0.9115, F1 Micro: 0.738, F1 Macro: 0.5947\n",
      "Epoch 5/10, Train Loss: 0.162, Accuracy: 0.9128, F1 Micro: 0.7559, F1 Macro: 0.6239\n",
      "Epoch 6/10, Train Loss: 0.1391, Accuracy: 0.9136, F1 Micro: 0.7592, F1 Macro: 0.6312\n",
      "Epoch 7/10, Train Loss: 0.1202, Accuracy: 0.9193, F1 Micro: 0.7675, F1 Macro: 0.6885\n",
      "Epoch 8/10, Train Loss: 0.1048, Accuracy: 0.9128, F1 Micro: 0.763, F1 Macro: 0.6949\n",
      "Epoch 9/10, Train Loss: 0.0849, Accuracy: 0.9199, F1 Micro: 0.7641, F1 Macro: 0.6882\n",
      "Epoch 10/10, Train Loss: 0.0742, Accuracy: 0.919, F1 Micro: 0.7678, F1 Macro: 0.7058\n",
      "Best result for 6287 samples: F1 Micro: 0.7678\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.84      0.85      1190\n",
      "      Abusive       0.88      0.86      0.87      1018\n",
      "HS_Individual       0.75      0.71      0.73       768\n",
      "     HS_Group       0.71      0.64      0.67       422\n",
      "  HS_Religion       0.66      0.60      0.63       173\n",
      "      HS_Race       0.77      0.75      0.76       126\n",
      "  HS_Physical       0.95      0.35      0.51        60\n",
      "    HS_Gender       0.82      0.40      0.54        67\n",
      "     HS_Other       0.79      0.74      0.77       792\n",
      "      HS_Weak       0.72      0.70      0.71       725\n",
      "  HS_Moderate       0.64      0.55      0.59       352\n",
      "    HS_Strong       0.87      0.80      0.83       113\n",
      "\n",
      "    micro avg       0.79      0.74      0.77      5806\n",
      "    macro avg       0.79      0.66      0.71      5806\n",
      " weighted avg       0.79      0.74      0.77      5806\n",
      "  samples avg       0.45      0.43      0.43      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 31.615988731384277\n",
      "Samples above threshold: 425\n",
      "Acquired samples: 297\n",
      "Sampling duration: 22.907862663269043 seconds\n",
      "\n",
      "Fold 5 - New train size: 6584\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 6584 samples\n",
      "Epoch 1/10, Train Loss: 0.4225, Accuracy: 0.8716, F1 Micro: 0.5789, F1 Macro: 0.273\n",
      "Epoch 2/10, Train Loss: 0.2927, Accuracy: 0.8962, F1 Micro: 0.6801, F1 Macro: 0.4561\n",
      "Epoch 3/10, Train Loss: 0.2398, Accuracy: 0.9058, F1 Micro: 0.7201, F1 Macro: 0.5466\n",
      "Epoch 4/10, Train Loss: 0.1962, Accuracy: 0.9137, F1 Micro: 0.7498, F1 Macro: 0.6076\n",
      "Epoch 5/10, Train Loss: 0.1647, Accuracy: 0.9125, F1 Micro: 0.7647, F1 Macro: 0.6473\n",
      "Epoch 6/10, Train Loss: 0.1409, Accuracy: 0.9169, F1 Micro: 0.7655, F1 Macro: 0.6736\n",
      "Epoch 7/10, Train Loss: 0.1202, Accuracy: 0.9192, F1 Micro: 0.7702, F1 Macro: 0.6839\n",
      "Epoch 8/10, Train Loss: 0.1, Accuracy: 0.9188, F1 Micro: 0.7728, F1 Macro: 0.6987\n",
      "Epoch 9/10, Train Loss: 0.0877, Accuracy: 0.9203, F1 Micro: 0.7626, F1 Macro: 0.7012\n",
      "Epoch 10/10, Train Loss: 0.0803, Accuracy: 0.9201, F1 Micro: 0.7748, F1 Macro: 0.7182\n",
      "Best result for 6584 samples: F1 Micro: 0.7748\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.86      0.85      1190\n",
      "      Abusive       0.85      0.89      0.87      1018\n",
      "HS_Individual       0.75      0.73      0.74       768\n",
      "     HS_Group       0.71      0.66      0.69       422\n",
      "  HS_Religion       0.67      0.51      0.58       173\n",
      "      HS_Race       0.86      0.71      0.77       126\n",
      "  HS_Physical       0.96      0.45      0.61        60\n",
      "    HS_Gender       0.87      0.40      0.55        67\n",
      "     HS_Other       0.77      0.79      0.78       792\n",
      "      HS_Weak       0.73      0.71      0.72       725\n",
      "  HS_Moderate       0.65      0.58      0.61       352\n",
      "    HS_Strong       0.88      0.81      0.84       113\n",
      "\n",
      "    micro avg       0.79      0.76      0.77      5806\n",
      "    macro avg       0.80      0.67      0.72      5806\n",
      " weighted avg       0.79      0.76      0.77      5806\n",
      "  samples avg       0.46      0.45      0.44      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 36.95160598754883\n",
      "Samples above threshold: 396\n",
      "Acquired samples: 396\n",
      "Sampling duration: 21.4339120388031 seconds\n",
      "\n",
      "Fold 5 - New train size: 6980\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 6980 samples\n",
      "Epoch 1/10, Train Loss: 0.4162, Accuracy: 0.8736, F1 Micro: 0.5887, F1 Macro: 0.2799\n",
      "Epoch 2/10, Train Loss: 0.2807, Accuracy: 0.896, F1 Micro: 0.6735, F1 Macro: 0.4566\n",
      "Epoch 3/10, Train Loss: 0.2248, Accuracy: 0.9073, F1 Micro: 0.7291, F1 Macro: 0.556\n",
      "Epoch 4/10, Train Loss: 0.1863, Accuracy: 0.9156, F1 Micro: 0.7476, F1 Macro: 0.5747\n",
      "Epoch 5/10, Train Loss: 0.1583, Accuracy: 0.9172, F1 Micro: 0.7598, F1 Macro: 0.6343\n",
      "Epoch 6/10, Train Loss: 0.1366, Accuracy: 0.9163, F1 Micro: 0.7692, F1 Macro: 0.6621\n",
      "Epoch 7/10, Train Loss: 0.1186, Accuracy: 0.9206, F1 Micro: 0.7607, F1 Macro: 0.6551\n",
      "Epoch 8/10, Train Loss: 0.1014, Accuracy: 0.9208, F1 Micro: 0.7733, F1 Macro: 0.6834\n",
      "Epoch 9/10, Train Loss: 0.0868, Accuracy: 0.9217, F1 Micro: 0.7768, F1 Macro: 0.7104\n",
      "Epoch 10/10, Train Loss: 0.0729, Accuracy: 0.9226, F1 Micro: 0.7779, F1 Macro: 0.7023\n",
      "Best result for 6980 samples: F1 Micro: 0.7779\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.87      0.85      0.86      1190\n",
      "      Abusive       0.88      0.86      0.87      1018\n",
      "HS_Individual       0.77      0.72      0.74       768\n",
      "     HS_Group       0.73      0.69      0.71       422\n",
      "  HS_Religion       0.74      0.56      0.64       173\n",
      "      HS_Race       0.83      0.73      0.78       126\n",
      "  HS_Physical       1.00      0.27      0.42        60\n",
      "    HS_Gender       0.91      0.31      0.47        67\n",
      "     HS_Other       0.79      0.78      0.78       792\n",
      "      HS_Weak       0.75      0.70      0.72       725\n",
      "  HS_Moderate       0.66      0.59      0.62       352\n",
      "    HS_Strong       0.83      0.81      0.82       113\n",
      "\n",
      "    micro avg       0.80      0.75      0.78      5806\n",
      "    macro avg       0.81      0.65      0.70      5806\n",
      " weighted avg       0.81      0.75      0.77      5806\n",
      "  samples avg       0.45      0.43      0.43      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 35.780111694335936\n",
      "Samples above threshold: 356\n",
      "Acquired samples: 356\n",
      "Sampling duration: 19.504798889160156 seconds\n",
      "\n",
      "Fold 5 - New train size: 7336\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 7336 samples\n",
      "Epoch 1/10, Train Loss: 0.4088, Accuracy: 0.8726, F1 Micro: 0.5389, F1 Macro: 0.248\n",
      "Epoch 2/10, Train Loss: 0.2719, Accuracy: 0.9002, F1 Micro: 0.6923, F1 Macro: 0.4825\n",
      "Epoch 3/10, Train Loss: 0.2164, Accuracy: 0.9067, F1 Micro: 0.7062, F1 Macro: 0.5191\n",
      "Epoch 4/10, Train Loss: 0.1823, Accuracy: 0.9159, F1 Micro: 0.7598, F1 Macro: 0.605\n",
      "Epoch 5/10, Train Loss: 0.1543, Accuracy: 0.9171, F1 Micro: 0.7661, F1 Macro: 0.6252\n",
      "Epoch 6/10, Train Loss: 0.1331, Accuracy: 0.9172, F1 Micro: 0.7642, F1 Macro: 0.6482\n",
      "Epoch 7/10, Train Loss: 0.1098, Accuracy: 0.9178, F1 Micro: 0.7738, F1 Macro: 0.6754\n",
      "Epoch 8/10, Train Loss: 0.0927, Accuracy: 0.9186, F1 Micro: 0.7684, F1 Macro: 0.6935\n",
      "Epoch 9/10, Train Loss: 0.0814, Accuracy: 0.9213, F1 Micro: 0.7737, F1 Macro: 0.7103\n",
      "Epoch 10/10, Train Loss: 0.0712, Accuracy: 0.9232, F1 Micro: 0.7803, F1 Macro: 0.7239\n",
      "Best result for 7336 samples: F1 Micro: 0.7803\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.87      0.84      0.85      1190\n",
      "      Abusive       0.84      0.91      0.88      1018\n",
      "HS_Individual       0.76      0.73      0.74       768\n",
      "     HS_Group       0.76      0.64      0.69       422\n",
      "  HS_Religion       0.72      0.55      0.63       173\n",
      "      HS_Race       0.88      0.67      0.76       126\n",
      "  HS_Physical       0.93      0.43      0.59        60\n",
      "    HS_Gender       0.76      0.48      0.59        67\n",
      "     HS_Other       0.81      0.76      0.79       792\n",
      "      HS_Weak       0.75      0.71      0.73       725\n",
      "  HS_Moderate       0.67      0.56      0.61       352\n",
      "    HS_Strong       0.87      0.80      0.83       113\n",
      "\n",
      "    micro avg       0.80      0.76      0.78      5806\n",
      "    macro avg       0.80      0.67      0.72      5806\n",
      " weighted avg       0.80      0.76      0.78      5806\n",
      "  samples avg       0.46      0.44      0.44      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 31.02587127685547\n",
      "Samples above threshold: 321\n",
      "Acquired samples: 321\n",
      "Sampling duration: 17.27473783493042 seconds\n",
      "\n",
      "Fold 5 - New train size: 7657\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 7657 samples\n",
      "Epoch 1/10, Train Loss: 0.4074, Accuracy: 0.8769, F1 Micro: 0.589, F1 Macro: 0.2738\n",
      "Epoch 2/10, Train Loss: 0.2739, Accuracy: 0.8999, F1 Micro: 0.6952, F1 Macro: 0.5111\n",
      "Epoch 3/10, Train Loss: 0.2212, Accuracy: 0.9103, F1 Micro: 0.734, F1 Macro: 0.5572\n",
      "Epoch 4/10, Train Loss: 0.1821, Accuracy: 0.9175, F1 Micro: 0.7559, F1 Macro: 0.5921\n",
      "Epoch 5/10, Train Loss: 0.1544, Accuracy: 0.918, F1 Micro: 0.7674, F1 Macro: 0.6241\n",
      "Epoch 6/10, Train Loss: 0.1295, Accuracy: 0.9212, F1 Micro: 0.7677, F1 Macro: 0.6519\n",
      "Epoch 7/10, Train Loss: 0.1084, Accuracy: 0.9223, F1 Micro: 0.7691, F1 Macro: 0.6816\n",
      "Epoch 8/10, Train Loss: 0.0929, Accuracy: 0.9213, F1 Micro: 0.7742, F1 Macro: 0.7091\n",
      "Epoch 9/10, Train Loss: 0.0795, Accuracy: 0.9222, F1 Micro: 0.7663, F1 Macro: 0.701\n",
      "Epoch 10/10, Train Loss: 0.0717, Accuracy: 0.9204, F1 Micro: 0.7808, F1 Macro: 0.7085\n",
      "Best result for 7657 samples: F1 Micro: 0.7808\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.89      0.86      1190\n",
      "      Abusive       0.89      0.88      0.89      1018\n",
      "HS_Individual       0.72      0.77      0.74       768\n",
      "     HS_Group       0.72      0.67      0.69       422\n",
      "  HS_Religion       0.69      0.54      0.60       173\n",
      "      HS_Race       0.82      0.74      0.78       126\n",
      "  HS_Physical       0.91      0.35      0.51        60\n",
      "    HS_Gender       0.85      0.33      0.47        67\n",
      "     HS_Other       0.74      0.84      0.79       792\n",
      "      HS_Weak       0.70      0.75      0.72       725\n",
      "  HS_Moderate       0.63      0.58      0.60       352\n",
      "    HS_Strong       0.88      0.80      0.84       113\n",
      "\n",
      "    micro avg       0.77      0.79      0.78      5806\n",
      "    macro avg       0.78      0.68      0.71      5806\n",
      " weighted avg       0.78      0.79      0.78      5806\n",
      "  samples avg       0.46      0.46      0.44      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 34.259592819213864\n",
      "Samples above threshold: 288\n",
      "Acquired samples: 244\n",
      "Sampling duration: 15.872173309326172 seconds\n",
      "\n",
      "Fold 5 - New train size: 7901\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 7901 samples\n",
      "Epoch 1/10, Train Loss: 0.4083, Accuracy: 0.8713, F1 Micro: 0.5241, F1 Macro: 0.2437\n",
      "Epoch 2/10, Train Loss: 0.2684, Accuracy: 0.9009, F1 Micro: 0.6884, F1 Macro: 0.45\n",
      "Epoch 3/10, Train Loss: 0.2222, Accuracy: 0.9113, F1 Micro: 0.7416, F1 Macro: 0.5645\n",
      "Epoch 4/10, Train Loss: 0.1825, Accuracy: 0.9174, F1 Micro: 0.7523, F1 Macro: 0.6027\n",
      "Epoch 5/10, Train Loss: 0.1537, Accuracy: 0.9183, F1 Micro: 0.7515, F1 Macro: 0.6004\n",
      "Epoch 6/10, Train Loss: 0.1342, Accuracy: 0.9202, F1 Micro: 0.7717, F1 Macro: 0.6952\n",
      "Epoch 7/10, Train Loss: 0.1122, Accuracy: 0.9209, F1 Micro: 0.7717, F1 Macro: 0.6834\n",
      "Epoch 8/10, Train Loss: 0.0933, Accuracy: 0.9193, F1 Micro: 0.7769, F1 Macro: 0.7015\n",
      "Epoch 9/10, Train Loss: 0.0824, Accuracy: 0.9236, F1 Micro: 0.7759, F1 Macro: 0.708\n",
      "Epoch 10/10, Train Loss: 0.0692, Accuracy: 0.9227, F1 Micro: 0.776, F1 Macro: 0.7026\n",
      "Best result for 7901 samples: F1 Micro: 0.7769\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.88      0.86      1190\n",
      "      Abusive       0.86      0.89      0.88      1018\n",
      "HS_Individual       0.73      0.77      0.75       768\n",
      "     HS_Group       0.70      0.67      0.69       422\n",
      "  HS_Religion       0.65      0.65      0.65       173\n",
      "      HS_Race       0.78      0.71      0.74       126\n",
      "  HS_Physical       0.86      0.30      0.44        60\n",
      "    HS_Gender       0.74      0.37      0.50        67\n",
      "     HS_Other       0.78      0.78      0.78       792\n",
      "      HS_Weak       0.70      0.75      0.72       725\n",
      "  HS_Moderate       0.63      0.58      0.60       352\n",
      "    HS_Strong       0.81      0.81      0.81       113\n",
      "\n",
      "    micro avg       0.77      0.78      0.78      5806\n",
      "    macro avg       0.76      0.68      0.70      5806\n",
      " weighted avg       0.77      0.78      0.77      5806\n",
      "  samples avg       0.45      0.45      0.44      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 29.17171001434326\n",
      "Samples above threshold: 264\n",
      "Acquired samples: 264\n",
      "Sampling duration: 14.401961088180542 seconds\n",
      "\n",
      "Fold 5 - New train size: 8165\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 8165 samples\n",
      "Epoch 1/10, Train Loss: 0.4017, Accuracy: 0.8789, F1 Micro: 0.6061, F1 Macro: 0.2827\n",
      "Epoch 2/10, Train Loss: 0.2668, Accuracy: 0.9027, F1 Micro: 0.7167, F1 Macro: 0.537\n",
      "Epoch 3/10, Train Loss: 0.2192, Accuracy: 0.9129, F1 Micro: 0.7385, F1 Macro: 0.5754\n",
      "Epoch 4/10, Train Loss: 0.1821, Accuracy: 0.9171, F1 Micro: 0.7594, F1 Macro: 0.6074\n",
      "Epoch 5/10, Train Loss: 0.153, Accuracy: 0.9185, F1 Micro: 0.7726, F1 Macro: 0.6621\n",
      "Epoch 6/10, Train Loss: 0.1276, Accuracy: 0.9202, F1 Micro: 0.7722, F1 Macro: 0.6766\n",
      "Epoch 7/10, Train Loss: 0.1063, Accuracy: 0.9189, F1 Micro: 0.7625, F1 Macro: 0.6669\n",
      "Epoch 8/10, Train Loss: 0.0918, Accuracy: 0.9216, F1 Micro: 0.7739, F1 Macro: 0.6904\n",
      "Epoch 9/10, Train Loss: 0.0819, Accuracy: 0.9238, F1 Micro: 0.7824, F1 Macro: 0.7193\n",
      "Epoch 10/10, Train Loss: 0.0664, Accuracy: 0.9213, F1 Micro: 0.7792, F1 Macro: 0.7158\n",
      "Best result for 8165 samples: F1 Micro: 0.7824\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.87      0.85      0.86      1190\n",
      "      Abusive       0.86      0.90      0.88      1018\n",
      "HS_Individual       0.79      0.71      0.75       768\n",
      "     HS_Group       0.72      0.72      0.72       422\n",
      "  HS_Religion       0.66      0.53      0.59       173\n",
      "      HS_Race       0.78      0.72      0.75       126\n",
      "  HS_Physical       1.00      0.35      0.52        60\n",
      "    HS_Gender       0.78      0.48      0.59        67\n",
      "     HS_Other       0.82      0.74      0.78       792\n",
      "      HS_Weak       0.77      0.70      0.73       725\n",
      "  HS_Moderate       0.64      0.64      0.64       352\n",
      "    HS_Strong       0.87      0.80      0.83       113\n",
      "\n",
      "    micro avg       0.81      0.76      0.78      5806\n",
      "    macro avg       0.80      0.68      0.72      5806\n",
      " weighted avg       0.80      0.76      0.78      5806\n",
      "  samples avg       0.46      0.45      0.44      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 35.0293155670166\n",
      "Samples above threshold: 238\n",
      "Acquired samples: 238\n",
      "Sampling duration: 13.290546417236328 seconds\n",
      "\n",
      "Fold 5 - New train size: 8403\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 8403 samples\n",
      "Epoch 1/10, Train Loss: 0.3961, Accuracy: 0.878, F1 Micro: 0.5799, F1 Macro: 0.2664\n",
      "Epoch 2/10, Train Loss: 0.2659, Accuracy: 0.9009, F1 Micro: 0.71, F1 Macro: 0.5005\n",
      "Epoch 3/10, Train Loss: 0.2134, Accuracy: 0.908, F1 Micro: 0.7448, F1 Macro: 0.5928\n",
      "Epoch 4/10, Train Loss: 0.1795, Accuracy: 0.9156, F1 Micro: 0.7667, F1 Macro: 0.6137\n",
      "Epoch 5/10, Train Loss: 0.1543, Accuracy: 0.919, F1 Micro: 0.7732, F1 Macro: 0.6391\n",
      "Epoch 6/10, Train Loss: 0.1246, Accuracy: 0.9222, F1 Micro: 0.7747, F1 Macro: 0.6655\n",
      "Epoch 7/10, Train Loss: 0.1082, Accuracy: 0.9192, F1 Micro: 0.7681, F1 Macro: 0.6586\n",
      "Epoch 8/10, Train Loss: 0.0943, Accuracy: 0.9234, F1 Micro: 0.7799, F1 Macro: 0.705\n",
      "Epoch 9/10, Train Loss: 0.0768, Accuracy: 0.9241, F1 Micro: 0.7811, F1 Macro: 0.7113\n",
      "Epoch 10/10, Train Loss: 0.0675, Accuracy: 0.9229, F1 Micro: 0.7758, F1 Macro: 0.7107\n",
      "Best result for 8403 samples: F1 Micro: 0.7811\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.89      0.84      0.86      1190\n",
      "      Abusive       0.87      0.90      0.89      1018\n",
      "HS_Individual       0.77      0.71      0.74       768\n",
      "     HS_Group       0.74      0.66      0.70       422\n",
      "  HS_Religion       0.71      0.55      0.62       173\n",
      "      HS_Race       0.79      0.71      0.75       126\n",
      "  HS_Physical       1.00      0.32      0.48        60\n",
      "    HS_Gender       0.76      0.42      0.54        67\n",
      "     HS_Other       0.82      0.75      0.78       792\n",
      "      HS_Weak       0.75      0.70      0.72       725\n",
      "  HS_Moderate       0.66      0.59      0.62       352\n",
      "    HS_Strong       0.84      0.81      0.83       113\n",
      "\n",
      "    micro avg       0.81      0.75      0.78      5806\n",
      "    macro avg       0.80      0.66      0.71      5806\n",
      " weighted avg       0.81      0.75      0.78      5806\n",
      "  samples avg       0.46      0.44      0.44      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 26.55819664001465\n",
      "Samples above threshold: 214\n",
      "Acquired samples: 214\n",
      "Sampling duration: 11.994753122329712 seconds\n",
      "\n",
      "Fold 5 - New train size: 8617\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 8617 samples\n",
      "Epoch 1/10, Train Loss: 0.3958, Accuracy: 0.8804, F1 Micro: 0.6292, F1 Macro: 0.2973\n",
      "Epoch 2/10, Train Loss: 0.2642, Accuracy: 0.9026, F1 Micro: 0.7147, F1 Macro: 0.5339\n",
      "Epoch 3/10, Train Loss: 0.2175, Accuracy: 0.9126, F1 Micro: 0.7404, F1 Macro: 0.5615\n",
      "Epoch 4/10, Train Loss: 0.1784, Accuracy: 0.9138, F1 Micro: 0.7607, F1 Macro: 0.6068\n",
      "Epoch 5/10, Train Loss: 0.1507, Accuracy: 0.9194, F1 Micro: 0.7701, F1 Macro: 0.6476\n",
      "Epoch 6/10, Train Loss: 0.1266, Accuracy: 0.9199, F1 Micro: 0.7693, F1 Macro: 0.6474\n",
      "Epoch 7/10, Train Loss: 0.1091, Accuracy: 0.9201, F1 Micro: 0.779, F1 Macro: 0.7017\n",
      "Epoch 8/10, Train Loss: 0.0894, Accuracy: 0.9193, F1 Micro: 0.7745, F1 Macro: 0.7002\n",
      "Epoch 9/10, Train Loss: 0.0785, Accuracy: 0.9209, F1 Micro: 0.7749, F1 Macro: 0.7015\n",
      "Epoch 10/10, Train Loss: 0.0686, Accuracy: 0.9209, F1 Micro: 0.7693, F1 Macro: 0.7176\n",
      "Best result for 8617 samples: F1 Micro: 0.779\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.89      0.86      1190\n",
      "      Abusive       0.85      0.92      0.89      1018\n",
      "HS_Individual       0.70      0.79      0.74       768\n",
      "     HS_Group       0.76      0.62      0.68       422\n",
      "  HS_Religion       0.73      0.52      0.61       173\n",
      "      HS_Race       0.79      0.71      0.75       126\n",
      "  HS_Physical       0.83      0.32      0.46        60\n",
      "    HS_Gender       0.76      0.39      0.51        67\n",
      "     HS_Other       0.77      0.79      0.78       792\n",
      "      HS_Weak       0.68      0.78      0.73       725\n",
      "  HS_Moderate       0.68      0.52      0.59       352\n",
      "    HS_Strong       0.89      0.76      0.82       113\n",
      "\n",
      "    micro avg       0.78      0.78      0.78      5806\n",
      "    macro avg       0.77      0.67      0.70      5806\n",
      " weighted avg       0.78      0.78      0.77      5806\n",
      "  samples avg       0.46      0.46      0.44      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 33.28885536193848\n",
      "Samples above threshold: 192\n",
      "Acquired samples: 200\n",
      "Sampling duration: 10.899182558059692 seconds\n",
      "\n",
      "Fold 5 - New train size: 8817\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 8817 samples\n",
      "Epoch 1/10, Train Loss: 0.394, Accuracy: 0.8793, F1 Micro: 0.6384, F1 Macro: 0.2993\n",
      "Epoch 2/10, Train Loss: 0.2617, Accuracy: 0.9029, F1 Micro: 0.7149, F1 Macro: 0.4788\n",
      "Epoch 3/10, Train Loss: 0.2166, Accuracy: 0.912, F1 Micro: 0.749, F1 Macro: 0.5659\n",
      "Epoch 4/10, Train Loss: 0.1814, Accuracy: 0.917, F1 Micro: 0.7631, F1 Macro: 0.6233\n",
      "Epoch 5/10, Train Loss: 0.1495, Accuracy: 0.9198, F1 Micro: 0.7676, F1 Macro: 0.6288\n",
      "Epoch 6/10, Train Loss: 0.1291, Accuracy: 0.9171, F1 Micro: 0.773, F1 Macro: 0.6943\n",
      "Epoch 7/10, Train Loss: 0.1078, Accuracy: 0.9249, F1 Micro: 0.7818, F1 Macro: 0.7159\n",
      "Epoch 8/10, Train Loss: 0.0888, Accuracy: 0.917, F1 Micro: 0.7784, F1 Macro: 0.6902\n",
      "Epoch 9/10, Train Loss: 0.0762, Accuracy: 0.9254, F1 Micro: 0.7843, F1 Macro: 0.7244\n",
      "Epoch 10/10, Train Loss: 0.0655, Accuracy: 0.9241, F1 Micro: 0.775, F1 Macro: 0.7105\n",
      "Best result for 8817 samples: F1 Micro: 0.7843\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.88      0.85      0.87      1190\n",
      "      Abusive       0.92      0.85      0.88      1018\n",
      "HS_Individual       0.76      0.74      0.75       768\n",
      "     HS_Group       0.76      0.63      0.69       422\n",
      "  HS_Religion       0.72      0.56      0.63       173\n",
      "      HS_Race       0.83      0.70      0.76       126\n",
      "  HS_Physical       0.89      0.42      0.57        60\n",
      "    HS_Gender       0.75      0.49      0.59        67\n",
      "     HS_Other       0.81      0.79      0.80       792\n",
      "      HS_Weak       0.74      0.73      0.73       725\n",
      "  HS_Moderate       0.68      0.53      0.60       352\n",
      "    HS_Strong       0.89      0.77      0.82       113\n",
      "\n",
      "    micro avg       0.82      0.75      0.78      5806\n",
      "    macro avg       0.80      0.67      0.72      5806\n",
      " weighted avg       0.82      0.75      0.78      5806\n",
      "  samples avg       0.45      0.43      0.43      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 23.14135627746582\n",
      "Samples above threshold: 172\n",
      "Acquired samples: 200\n",
      "Sampling duration: 10.000442266464233 seconds\n",
      "\n",
      "Fold 5 - New train size: 9017\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 9017 samples\n",
      "Epoch 1/10, Train Loss: 0.3929, Accuracy: 0.8811, F1 Micro: 0.6249, F1 Macro: 0.2987\n",
      "Epoch 2/10, Train Loss: 0.261, Accuracy: 0.9011, F1 Micro: 0.7198, F1 Macro: 0.5335\n",
      "Epoch 3/10, Train Loss: 0.2177, Accuracy: 0.9116, F1 Micro: 0.7312, F1 Macro: 0.5738\n",
      "Epoch 4/10, Train Loss: 0.1779, Accuracy: 0.9182, F1 Micro: 0.762, F1 Macro: 0.6116\n",
      "Epoch 5/10, Train Loss: 0.1505, Accuracy: 0.9199, F1 Micro: 0.7741, F1 Macro: 0.6577\n",
      "Epoch 6/10, Train Loss: 0.1292, Accuracy: 0.9204, F1 Micro: 0.7759, F1 Macro: 0.6725\n",
      "Epoch 7/10, Train Loss: 0.1079, Accuracy: 0.9231, F1 Micro: 0.7768, F1 Macro: 0.6995\n",
      "Epoch 8/10, Train Loss: 0.09, Accuracy: 0.9202, F1 Micro: 0.7771, F1 Macro: 0.6956\n",
      "Epoch 9/10, Train Loss: 0.0791, Accuracy: 0.9229, F1 Micro: 0.7747, F1 Macro: 0.7076\n",
      "Epoch 10/10, Train Loss: 0.0682, Accuracy: 0.9249, F1 Micro: 0.7777, F1 Macro: 0.7228\n",
      "Best result for 9017 samples: F1 Micro: 0.7777\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.91      0.80      0.85      1190\n",
      "      Abusive       0.89      0.89      0.89      1018\n",
      "HS_Individual       0.78      0.70      0.74       768\n",
      "     HS_Group       0.77      0.61      0.68       422\n",
      "  HS_Religion       0.76      0.48      0.59       173\n",
      "      HS_Race       0.89      0.71      0.79       126\n",
      "  HS_Physical       0.82      0.45      0.58        60\n",
      "    HS_Gender       0.80      0.49      0.61        67\n",
      "     HS_Other       0.84      0.73      0.78       792\n",
      "      HS_Weak       0.77      0.68      0.72       725\n",
      "  HS_Moderate       0.67      0.53      0.59       352\n",
      "    HS_Strong       0.90      0.81      0.85       113\n",
      "\n",
      "    micro avg       0.83      0.73      0.78      5806\n",
      "    macro avg       0.82      0.66      0.72      5806\n",
      " weighted avg       0.83      0.73      0.77      5806\n",
      "  samples avg       0.45      0.43      0.43      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 20.529603004455566\n",
      "Samples above threshold: 152\n",
      "Acquired samples: 200\n",
      "Sampling duration: 8.751774787902832 seconds\n",
      "\n",
      "Fold 5 - New train size: 9217\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 9217 samples\n",
      "Epoch 1/10, Train Loss: 0.3899, Accuracy: 0.8807, F1 Micro: 0.6118, F1 Macro: 0.3025\n",
      "Epoch 2/10, Train Loss: 0.2613, Accuracy: 0.9036, F1 Micro: 0.7243, F1 Macro: 0.5413\n",
      "Epoch 3/10, Train Loss: 0.2124, Accuracy: 0.9116, F1 Micro: 0.746, F1 Macro: 0.5708\n",
      "Epoch 4/10, Train Loss: 0.1761, Accuracy: 0.9169, F1 Micro: 0.7674, F1 Macro: 0.64\n",
      "Epoch 5/10, Train Loss: 0.1493, Accuracy: 0.9206, F1 Micro: 0.7721, F1 Macro: 0.6516\n",
      "Epoch 6/10, Train Loss: 0.1265, Accuracy: 0.9197, F1 Micro: 0.7733, F1 Macro: 0.6854\n",
      "Epoch 7/10, Train Loss: 0.1041, Accuracy: 0.9232, F1 Micro: 0.7811, F1 Macro: 0.703\n",
      "Epoch 8/10, Train Loss: 0.0897, Accuracy: 0.9223, F1 Micro: 0.7704, F1 Macro: 0.6974\n",
      "Epoch 9/10, Train Loss: 0.0741, Accuracy: 0.9227, F1 Micro: 0.7838, F1 Macro: 0.7139\n",
      "Epoch 10/10, Train Loss: 0.0651, Accuracy: 0.9228, F1 Micro: 0.7868, F1 Macro: 0.7253\n",
      "Best result for 9217 samples: F1 Micro: 0.7868\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.89      0.87      1190\n",
      "      Abusive       0.88      0.90      0.89      1018\n",
      "HS_Individual       0.73      0.79      0.76       768\n",
      "     HS_Group       0.74      0.65      0.70       422\n",
      "  HS_Religion       0.68      0.58      0.63       173\n",
      "      HS_Race       0.74      0.76      0.75       126\n",
      "  HS_Physical       0.76      0.42      0.54        60\n",
      "    HS_Gender       0.70      0.58      0.63        67\n",
      "     HS_Other       0.78      0.80      0.79       792\n",
      "      HS_Weak       0.70      0.77      0.74       725\n",
      "  HS_Moderate       0.65      0.55      0.59       352\n",
      "    HS_Strong       0.82      0.81      0.82       113\n",
      "\n",
      "    micro avg       0.78      0.79      0.79      5806\n",
      "    macro avg       0.75      0.71      0.73      5806\n",
      " weighted avg       0.78      0.79      0.78      5806\n",
      "  samples avg       0.46      0.46      0.45      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 23.509326553344728\n",
      "Samples above threshold: 132\n",
      "Acquired samples: 1\n",
      "Sampling duration: 8.270816564559937 seconds\n",
      "\n",
      "Fold 5 - New train size: 9218\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 9218 samples\n",
      "Epoch 1/10, Train Loss: 0.3872, Accuracy: 0.8795, F1 Micro: 0.603, F1 Macro: 0.2887\n",
      "Epoch 2/10, Train Loss: 0.2569, Accuracy: 0.9045, F1 Micro: 0.7076, F1 Macro: 0.5203\n",
      "Epoch 3/10, Train Loss: 0.2131, Accuracy: 0.9118, F1 Micro: 0.7473, F1 Macro: 0.5682\n",
      "Epoch 4/10, Train Loss: 0.1747, Accuracy: 0.9174, F1 Micro: 0.7655, F1 Macro: 0.6152\n",
      "Epoch 5/10, Train Loss: 0.1454, Accuracy: 0.9227, F1 Micro: 0.7752, F1 Macro: 0.6748\n",
      "Epoch 6/10, Train Loss: 0.1222, Accuracy: 0.9204, F1 Micro: 0.7752, F1 Macro: 0.6768\n",
      "Epoch 7/10, Train Loss: 0.1064, Accuracy: 0.9202, F1 Micro: 0.7771, F1 Macro: 0.7031\n",
      "Epoch 8/10, Train Loss: 0.087, Accuracy: 0.9209, F1 Micro: 0.7824, F1 Macro: 0.702\n",
      "Epoch 9/10, Train Loss: 0.0766, Accuracy: 0.9231, F1 Micro: 0.7807, F1 Macro: 0.722\n",
      "Epoch 10/10, Train Loss: 0.0655, Accuracy: 0.9205, F1 Micro: 0.7791, F1 Macro: 0.72\n",
      "Best result for 9218 samples: F1 Micro: 0.7824\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.89      0.86      1190\n",
      "      Abusive       0.87      0.91      0.89      1018\n",
      "HS_Individual       0.73      0.79      0.76       768\n",
      "     HS_Group       0.74      0.64      0.69       422\n",
      "  HS_Religion       0.66      0.65      0.65       173\n",
      "      HS_Race       0.78      0.75      0.77       126\n",
      "  HS_Physical       1.00      0.23      0.38        60\n",
      "    HS_Gender       0.73      0.40      0.52        67\n",
      "     HS_Other       0.76      0.81      0.79       792\n",
      "      HS_Weak       0.70      0.77      0.73       725\n",
      "  HS_Moderate       0.63      0.54      0.58       352\n",
      "    HS_Strong       0.88      0.75      0.81       113\n",
      "\n",
      "    micro avg       0.77      0.79      0.78      5806\n",
      "    macro avg       0.78      0.68      0.70      5806\n",
      " weighted avg       0.77      0.79      0.78      5806\n",
      "  samples avg       0.47      0.46      0.45      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10536\n",
      "Threshold: 26.803558349609375\n",
      "Samples above threshold: 133\n",
      "Acquired samples: 200\n",
      "Sampling duration: 7.820739030838013 seconds\n",
      "\n",
      "Fold 5 - New train size: 9418\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 9418 samples\n",
      "Epoch 1/10, Train Loss: 0.3884, Accuracy: 0.8771, F1 Micro: 0.568, F1 Macro: 0.2684\n",
      "Epoch 2/10, Train Loss: 0.2606, Accuracy: 0.9015, F1 Micro: 0.7227, F1 Macro: 0.5261\n",
      "Epoch 3/10, Train Loss: 0.2079, Accuracy: 0.9115, F1 Micro: 0.7387, F1 Macro: 0.5353\n",
      "Epoch 4/10, Train Loss: 0.1771, Accuracy: 0.9158, F1 Micro: 0.7656, F1 Macro: 0.6264\n",
      "Epoch 5/10, Train Loss: 0.1481, Accuracy: 0.9186, F1 Micro: 0.7699, F1 Macro: 0.6424\n",
      "Epoch 6/10, Train Loss: 0.1243, Accuracy: 0.9205, F1 Micro: 0.78, F1 Macro: 0.7078\n",
      "Epoch 7/10, Train Loss: 0.1059, Accuracy: 0.9202, F1 Micro: 0.7784, F1 Macro: 0.6853\n",
      "Epoch 8/10, Train Loss: 0.0883, Accuracy: 0.9217, F1 Micro: 0.7771, F1 Macro: 0.6994\n",
      "Epoch 9/10, Train Loss: 0.0735, Accuracy: 0.9233, F1 Micro: 0.7786, F1 Macro: 0.7114\n",
      "Epoch 10/10, Train Loss: 0.065, Accuracy: 0.9216, F1 Micro: 0.7731, F1 Macro: 0.7065\n",
      "Best result for 9418 samples: F1 Micro: 0.78\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.89      0.87      1190\n",
      "      Abusive       0.87      0.90      0.88      1018\n",
      "HS_Individual       0.74      0.76      0.75       768\n",
      "     HS_Group       0.70      0.68      0.69       422\n",
      "  HS_Religion       0.64      0.66      0.65       173\n",
      "      HS_Race       0.78      0.74      0.76       126\n",
      "  HS_Physical       0.66      0.32      0.43        60\n",
      "    HS_Gender       0.82      0.42      0.55        67\n",
      "     HS_Other       0.78      0.77      0.78       792\n",
      "      HS_Weak       0.71      0.75      0.73       725\n",
      "  HS_Moderate       0.62      0.58      0.60       352\n",
      "    HS_Strong       0.84      0.77      0.81       113\n",
      "\n",
      "    micro avg       0.78      0.78      0.78      5806\n",
      "    macro avg       0.75      0.69      0.71      5806\n",
      " weighted avg       0.78      0.78      0.78      5806\n",
      "  samples avg       0.46      0.46      0.44      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10536\n",
      "Threshold: 29.541444396972658\n",
      "Samples above threshold: 112\n",
      "Acquired samples: 200\n",
      "Sampling duration: 6.856597900390625 seconds\n",
      "\n",
      "Fold 5 - New train size: 9618\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 9618 samples\n",
      "Epoch 1/10, Train Loss: 0.3873, Accuracy: 0.8811, F1 Micro: 0.6152, F1 Macro: 0.2909\n",
      "Epoch 2/10, Train Loss: 0.2574, Accuracy: 0.9055, F1 Micro: 0.7104, F1 Macro: 0.5079\n",
      "Epoch 3/10, Train Loss: 0.2077, Accuracy: 0.9117, F1 Micro: 0.7512, F1 Macro: 0.5838\n",
      "Epoch 4/10, Train Loss: 0.1695, Accuracy: 0.9193, F1 Micro: 0.7673, F1 Macro: 0.6355\n",
      "Epoch 5/10, Train Loss: 0.1448, Accuracy: 0.9231, F1 Micro: 0.7776, F1 Macro: 0.6431\n",
      "Epoch 6/10, Train Loss: 0.1231, Accuracy: 0.9191, F1 Micro: 0.7747, F1 Macro: 0.6789\n",
      "Epoch 7/10, Train Loss: 0.0986, Accuracy: 0.9214, F1 Micro: 0.7743, F1 Macro: 0.6926\n",
      "Epoch 8/10, Train Loss: 0.0864, Accuracy: 0.9227, F1 Micro: 0.7795, F1 Macro: 0.7099\n",
      "Epoch 9/10, Train Loss: 0.0767, Accuracy: 0.9236, F1 Micro: 0.7801, F1 Macro: 0.718\n",
      "Epoch 10/10, Train Loss: 0.0615, Accuracy: 0.923, F1 Micro: 0.7785, F1 Macro: 0.7223\n",
      "Best result for 9618 samples: F1 Micro: 0.7801\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.88      0.85      0.86      1190\n",
      "      Abusive       0.91      0.88      0.89      1018\n",
      "HS_Individual       0.75      0.74      0.74       768\n",
      "     HS_Group       0.74      0.62      0.68       422\n",
      "  HS_Religion       0.76      0.57      0.65       173\n",
      "      HS_Race       0.86      0.71      0.77       126\n",
      "  HS_Physical       1.00      0.38      0.55        60\n",
      "    HS_Gender       0.80      0.42      0.55        67\n",
      "     HS_Other       0.79      0.78      0.78       792\n",
      "      HS_Weak       0.73      0.72      0.72       725\n",
      "  HS_Moderate       0.65      0.53      0.58       352\n",
      "    HS_Strong       0.87      0.78      0.82       113\n",
      "\n",
      "    micro avg       0.81      0.75      0.78      5806\n",
      "    macro avg       0.81      0.66      0.72      5806\n",
      " weighted avg       0.81      0.75      0.78      5806\n",
      "  samples avg       0.45      0.44      0.43      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10536\n",
      "Threshold: 20.9297119140625\n",
      "Samples above threshold: 92\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.8591718673706055 seconds\n",
      "\n",
      "Fold 5 - New train size: 9818\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 9818 samples\n",
      "Epoch 1/10, Train Loss: 0.3817, Accuracy: 0.8844, F1 Micro: 0.6329, F1 Macro: 0.3269\n",
      "Epoch 2/10, Train Loss: 0.2588, Accuracy: 0.9054, F1 Micro: 0.7272, F1 Macro: 0.5501\n",
      "Epoch 3/10, Train Loss: 0.2134, Accuracy: 0.9135, F1 Micro: 0.7521, F1 Macro: 0.5815\n",
      "Epoch 4/10, Train Loss: 0.1754, Accuracy: 0.9174, F1 Micro: 0.7482, F1 Macro: 0.6073\n",
      "Epoch 5/10, Train Loss: 0.1443, Accuracy: 0.9213, F1 Micro: 0.7717, F1 Macro: 0.6457\n",
      "Epoch 6/10, Train Loss: 0.1247, Accuracy: 0.9228, F1 Micro: 0.7712, F1 Macro: 0.6659\n",
      "Epoch 7/10, Train Loss: 0.1043, Accuracy: 0.9214, F1 Micro: 0.7862, F1 Macro: 0.719\n",
      "Epoch 8/10, Train Loss: 0.087, Accuracy: 0.9206, F1 Micro: 0.7815, F1 Macro: 0.7155\n",
      "Epoch 9/10, Train Loss: 0.0782, Accuracy: 0.9219, F1 Micro: 0.7781, F1 Macro: 0.7201\n",
      "Epoch 10/10, Train Loss: 0.067, Accuracy: 0.9242, F1 Micro: 0.7888, F1 Macro: 0.7305\n",
      "Best result for 9818 samples: F1 Micro: 0.7888\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.87      0.86      1190\n",
      "      Abusive       0.86      0.93      0.90      1018\n",
      "HS_Individual       0.75      0.76      0.75       768\n",
      "     HS_Group       0.73      0.67      0.70       422\n",
      "  HS_Religion       0.71      0.60      0.65       173\n",
      "      HS_Race       0.79      0.73      0.76       126\n",
      "  HS_Physical       0.92      0.40      0.56        60\n",
      "    HS_Gender       0.73      0.52      0.61        67\n",
      "     HS_Other       0.79      0.79      0.79       792\n",
      "      HS_Weak       0.73      0.74      0.73       725\n",
      "  HS_Moderate       0.64      0.60      0.62       352\n",
      "    HS_Strong       0.88      0.80      0.84       113\n",
      "\n",
      "    micro avg       0.79      0.79      0.79      5806\n",
      "    macro avg       0.78      0.70      0.73      5806\n",
      " weighted avg       0.79      0.79      0.79      5806\n",
      "  samples avg       0.46      0.46      0.45      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10536\n",
      "Threshold: 33.00737457275391\n",
      "Samples above threshold: 72\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.935241937637329 seconds\n",
      "\n",
      "Fold 5 - New train size: 10018\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 10018 samples\n",
      "Epoch 1/10, Train Loss: 0.3788, Accuracy: 0.8836, F1 Micro: 0.6438, F1 Macro: 0.3217\n",
      "Epoch 2/10, Train Loss: 0.2496, Accuracy: 0.9059, F1 Micro: 0.7351, F1 Macro: 0.5421\n",
      "Epoch 3/10, Train Loss: 0.2075, Accuracy: 0.9137, F1 Micro: 0.7564, F1 Macro: 0.6012\n",
      "Epoch 4/10, Train Loss: 0.1728, Accuracy: 0.9191, F1 Micro: 0.7546, F1 Macro: 0.5787\n",
      "Epoch 5/10, Train Loss: 0.1486, Accuracy: 0.918, F1 Micro: 0.7754, F1 Macro: 0.6594\n",
      "Epoch 6/10, Train Loss: 0.1189, Accuracy: 0.923, F1 Micro: 0.7763, F1 Macro: 0.6748\n",
      "Epoch 7/10, Train Loss: 0.0988, Accuracy: 0.9244, F1 Micro: 0.7762, F1 Macro: 0.6835\n",
      "Epoch 8/10, Train Loss: 0.0889, Accuracy: 0.9235, F1 Micro: 0.7872, F1 Macro: 0.7048\n",
      "Epoch 9/10, Train Loss: 0.0761, Accuracy: 0.9232, F1 Micro: 0.7884, F1 Macro: 0.7176\n",
      "Epoch 10/10, Train Loss: 0.0619, Accuracy: 0.9246, F1 Micro: 0.7891, F1 Macro: 0.7252\n",
      "Best result for 10018 samples: F1 Micro: 0.7891\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.88      0.87      1190\n",
      "      Abusive       0.88      0.91      0.89      1018\n",
      "HS_Individual       0.73      0.78      0.75       768\n",
      "     HS_Group       0.74      0.64      0.69       422\n",
      "  HS_Religion       0.71      0.64      0.67       173\n",
      "      HS_Race       0.79      0.70      0.74       126\n",
      "  HS_Physical       0.92      0.38      0.54        60\n",
      "    HS_Gender       0.74      0.46      0.57        67\n",
      "     HS_Other       0.80      0.79      0.79       792\n",
      "      HS_Weak       0.71      0.76      0.74       725\n",
      "  HS_Moderate       0.67      0.54      0.60       352\n",
      "    HS_Strong       0.86      0.82      0.84       113\n",
      "\n",
      "    micro avg       0.79      0.78      0.79      5806\n",
      "    macro avg       0.78      0.69      0.73      5806\n",
      " weighted avg       0.79      0.78      0.79      5806\n",
      "  samples avg       0.46      0.46      0.45      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10536\n",
      "Threshold: 20.08715782165527\n",
      "Samples above threshold: 52\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.001788854598999 seconds\n",
      "\n",
      "Fold 5 - New train size: 10218\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 10218 samples\n",
      "Epoch 1/10, Train Loss: 0.3784, Accuracy: 0.8792, F1 Micro: 0.5813, F1 Macro: 0.2847\n",
      "Epoch 2/10, Train Loss: 0.2551, Accuracy: 0.9063, F1 Micro: 0.7233, F1 Macro: 0.532\n",
      "Epoch 3/10, Train Loss: 0.2056, Accuracy: 0.9147, F1 Micro: 0.7474, F1 Macro: 0.5672\n",
      "Epoch 4/10, Train Loss: 0.1695, Accuracy: 0.9201, F1 Micro: 0.7683, F1 Macro: 0.5965\n",
      "Epoch 5/10, Train Loss: 0.1432, Accuracy: 0.9232, F1 Micro: 0.7793, F1 Macro: 0.6578\n",
      "Epoch 6/10, Train Loss: 0.1231, Accuracy: 0.9232, F1 Micro: 0.7785, F1 Macro: 0.6529\n",
      "Epoch 7/10, Train Loss: 0.103, Accuracy: 0.9232, F1 Micro: 0.7847, F1 Macro: 0.7036\n",
      "Epoch 8/10, Train Loss: 0.0863, Accuracy: 0.9223, F1 Micro: 0.7864, F1 Macro: 0.7155\n",
      "Epoch 9/10, Train Loss: 0.0741, Accuracy: 0.9254, F1 Micro: 0.7855, F1 Macro: 0.7206\n",
      "Epoch 10/10, Train Loss: 0.064, Accuracy: 0.9214, F1 Micro: 0.7867, F1 Macro: 0.7265\n",
      "Best result for 10218 samples: F1 Micro: 0.7867\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.90      0.86      1190\n",
      "      Abusive       0.88      0.92      0.90      1018\n",
      "HS_Individual       0.73      0.78      0.75       768\n",
      "     HS_Group       0.67      0.68      0.68       422\n",
      "  HS_Religion       0.65      0.68      0.66       173\n",
      "      HS_Race       0.74      0.79      0.76       126\n",
      "  HS_Physical       1.00      0.33      0.50        60\n",
      "    HS_Gender       0.77      0.55      0.64        67\n",
      "     HS_Other       0.77      0.83      0.80       792\n",
      "      HS_Weak       0.70      0.76      0.73       725\n",
      "  HS_Moderate       0.61      0.61      0.61       352\n",
      "    HS_Strong       0.85      0.80      0.82       113\n",
      "\n",
      "    micro avg       0.77      0.81      0.79      5806\n",
      "    macro avg       0.77      0.72      0.73      5806\n",
      " weighted avg       0.77      0.81      0.78      5806\n",
      "  samples avg       0.47      0.47      0.45      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10536\n",
      "Threshold: 32.03544998168945\n",
      "Samples above threshold: 32\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.8006179332733154 seconds\n",
      "\n",
      "Fold 5 - New train size: 10418\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 10418 samples\n",
      "Epoch 1/10, Train Loss: 0.3737, Accuracy: 0.8835, F1 Micro: 0.6074, F1 Macro: 0.2984\n",
      "Epoch 2/10, Train Loss: 0.2525, Accuracy: 0.905, F1 Micro: 0.7164, F1 Macro: 0.5373\n",
      "Epoch 3/10, Train Loss: 0.2014, Accuracy: 0.9164, F1 Micro: 0.7549, F1 Macro: 0.5795\n",
      "Epoch 4/10, Train Loss: 0.1685, Accuracy: 0.9205, F1 Micro: 0.7726, F1 Macro: 0.6107\n",
      "Epoch 5/10, Train Loss: 0.1437, Accuracy: 0.9247, F1 Micro: 0.7816, F1 Macro: 0.6707\n",
      "Epoch 6/10, Train Loss: 0.1231, Accuracy: 0.9224, F1 Micro: 0.7823, F1 Macro: 0.6838\n",
      "Epoch 7/10, Train Loss: 0.104, Accuracy: 0.925, F1 Micro: 0.7869, F1 Macro: 0.6964\n",
      "Epoch 8/10, Train Loss: 0.0863, Accuracy: 0.9218, F1 Micro: 0.7868, F1 Macro: 0.722\n",
      "Epoch 9/10, Train Loss: 0.0742, Accuracy: 0.9222, F1 Micro: 0.7851, F1 Macro: 0.7228\n",
      "Epoch 10/10, Train Loss: 0.0625, Accuracy: 0.9197, F1 Micro: 0.7838, F1 Macro: 0.7285\n",
      "Best result for 10418 samples: F1 Micro: 0.7869\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.87      0.87      0.87      1190\n",
      "      Abusive       0.89      0.90      0.90      1018\n",
      "HS_Individual       0.75      0.76      0.75       768\n",
      "     HS_Group       0.78      0.64      0.71       422\n",
      "  HS_Religion       0.72      0.51      0.59       173\n",
      "      HS_Race       0.82      0.71      0.76       126\n",
      "  HS_Physical       1.00      0.22      0.36        60\n",
      "    HS_Gender       0.81      0.33      0.47        67\n",
      "     HS_Other       0.78      0.79      0.78       792\n",
      "      HS_Weak       0.73      0.74      0.74       725\n",
      "  HS_Moderate       0.70      0.55      0.62       352\n",
      "    HS_Strong       0.85      0.78      0.81       113\n",
      "\n",
      "    micro avg       0.81      0.77      0.79      5806\n",
      "    macro avg       0.81      0.65      0.70      5806\n",
      " weighted avg       0.80      0.77      0.78      5806\n",
      "  samples avg       0.46      0.45      0.44      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10536\n",
      "Threshold: 17.890744400024413\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 118\n",
      "Sampling duration: 1.8214635848999023 seconds\n",
      "\n",
      "Fold 5 - New train size: 10536\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 10536 samples\n",
      "Epoch 1/10, Train Loss: 0.3692, Accuracy: 0.8841, F1 Micro: 0.6507, F1 Macro: 0.3295\n",
      "Epoch 2/10, Train Loss: 0.2445, Accuracy: 0.9064, F1 Micro: 0.7148, F1 Macro: 0.526\n",
      "Epoch 3/10, Train Loss: 0.1981, Accuracy: 0.9156, F1 Micro: 0.7535, F1 Macro: 0.5854\n",
      "Epoch 4/10, Train Loss: 0.165, Accuracy: 0.9208, F1 Micro: 0.7631, F1 Macro: 0.6173\n",
      "Epoch 5/10, Train Loss: 0.1355, Accuracy: 0.9236, F1 Micro: 0.7817, F1 Macro: 0.6634\n",
      "Epoch 6/10, Train Loss: 0.1179, Accuracy: 0.9252, F1 Micro: 0.7813, F1 Macro: 0.6848\n",
      "Epoch 7/10, Train Loss: 0.0945, Accuracy: 0.9228, F1 Micro: 0.7882, F1 Macro: 0.6936\n",
      "Epoch 8/10, Train Loss: 0.0811, Accuracy: 0.9252, F1 Micro: 0.7815, F1 Macro: 0.7033\n",
      "Epoch 9/10, Train Loss: 0.0709, Accuracy: 0.919, F1 Micro: 0.7835, F1 Macro: 0.7085\n",
      "Epoch 10/10, Train Loss: 0.0625, Accuracy: 0.9251, F1 Micro: 0.7852, F1 Macro: 0.7171\n",
      "Best result for 10536 samples: F1 Micro: 0.7882\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.91      0.87      1190\n",
      "      Abusive       0.87      0.93      0.90      1018\n",
      "HS_Individual       0.74      0.76      0.75       768\n",
      "     HS_Group       0.72      0.70      0.71       422\n",
      "  HS_Religion       0.66      0.66      0.66       173\n",
      "      HS_Race       0.81      0.71      0.75       126\n",
      "  HS_Physical       1.00      0.13      0.24        60\n",
      "    HS_Gender       0.77      0.36      0.49        67\n",
      "     HS_Other       0.76      0.82      0.79       792\n",
      "      HS_Weak       0.72      0.74      0.73       725\n",
      "  HS_Moderate       0.63      0.61      0.62       352\n",
      "    HS_Strong       0.85      0.77      0.81       113\n",
      "\n",
      "    micro avg       0.78      0.80      0.79      5806\n",
      "    macro avg       0.78      0.68      0.69      5806\n",
      " weighted avg       0.78      0.80      0.78      5806\n",
      "  samples avg       0.47      0.47      0.45      5806\n",
      "\n",
      "\n",
      "FOLD 5 COMPLETED in 5830.94 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "N_SPLITS = 5\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Prepare data for K-Fold\n",
    "label_columns = data.columns[1:]\n",
    "X = data['Tweet'].values\n",
    "y = data[label_columns].values\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "all_fold_accuracies = []\n",
    "all_fold_f1_micros = []\n",
    "all_fold_f1_macros = []\n",
    "all_fold_data_used = []\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "    print(\"===============================================\")\n",
    "    print(f\"STARTING FOLD {fold + 1}/{N_SPLITS}\")\n",
    "    print(\"===============================================\")\n",
    "\n",
    "    X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "    y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "\n",
    "    train_fold_df = pd.DataFrame(X_train_fold, columns=['Tweet'])\n",
    "    train_fold_df[label_columns] = y_train_fold\n",
    "\n",
    "    val_fold_df = pd.DataFrame(X_val_fold, columns=['Tweet'])\n",
    "    val_fold_df[label_columns] = y_val_fold\n",
    "\n",
    "    fold_data_dir = 'kfold_splits'\n",
    "    if not os.path.exists(fold_data_dir):\n",
    "        os.makedirs(fold_data_dir)\n",
    "\n",
    "    train_fold_df.to_csv(f'{fold_data_dir}/train_fold_{fold + 1}.csv', index=False)\n",
    "    val_fold_df.to_csv(f'{fold_data_dir}/val_fold_{fold + 1}.csv', index=False)\n",
    "\n",
    "    # Shared resources for this fold's processes\n",
    "    accuracies = manager.list()\n",
    "    f1_micros = manager.list()\n",
    "    f1_macros = manager.list()\n",
    "    data_used = manager.list()\n",
    "    sampling_dur = manager.list()\n",
    "    farthest_point = manager.dict()\n",
    "    \n",
    "    set_seed(RANDOM_SEED + fold)\n",
    "    \n",
    "    # Define the initial labeled pool from the current fold's training data\n",
    "    total_train_fold_size = len(X_train_fold) + len(X_val_fold)\n",
    "    initial_train_size = int(0.05 * total_train_fold_size)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train_fold)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train_fold))) - set(train_indices))\n",
    "    current_train_size = initial_train_size\n",
    "\n",
    "    checkpoints = [\n",
    "        # int(0.1 * total_train_fold_size),\n",
    "        int(0.5 * total_train_fold_size), \n",
    "        int(0.6 * total_train_fold_size),\n",
    "        int(0.7 * total_train_fold_size),\n",
    "        len(X_train_fold)\n",
    "    ]\n",
    "    \n",
    "    fold_start_time = time.time()\n",
    "    \n",
    "    while current_train_size < total_train_fold_size:\n",
    "        # Train the model on the current labeled set\n",
    "        train_args = (\n",
    "            current_train_size, train_indices, (data_used, accuracies, f1_micros, f1_macros),\n",
    "            fold, RANDOM_SEED + fold, X_train_fold, y_train_fold, X_val_fold, y_val_fold, label_columns\n",
    "        )\n",
    "        notebook_launcher(train_model, train_args, num_processes=2)\n",
    "        \n",
    "        # Stop if we've reached the last checkpoint\n",
    "        if current_train_size >= checkpoints[-1]:\n",
    "            break\n",
    "\n",
    "        model = BertForSequenceClassification.from_pretrained(f'{filename}-fold-{fold + 1}-model')\n",
    "        \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples_shared = manager.list()\n",
    "        X_pool = [X_train_fold[i] for i in remaining_indices]\n",
    "        sampling_args = (model, farthest_point, X_pool, train_indices, remaining_indices, sampling_dur, new_samples_shared, fold, X_train_fold, y_train_fold)\n",
    "        notebook_launcher(coreset_sampling, sampling_args, num_processes=2)\n",
    "        \n",
    "        # Update the pools\n",
    "        newly_acquired_indices = list(new_samples_shared)\n",
    "        train_indices.extend(newly_acquired_indices)\n",
    "        remaining_indices = list(set(remaining_indices) - set(newly_acquired_indices))\n",
    "    \n",
    "        current_train_size = len(train_indices)\n",
    "        print(f\"\\nFold {fold + 1} - New train size: {current_train_size}\\n\")\n",
    "    \n",
    "    fold_end_time = time.time()\n",
    "    print(f\"\\nFOLD {fold + 1} COMPLETED in {fold_end_time - fold_start_time:.2f} seconds\")\n",
    "    \n",
    "    # Store the results for this fold\n",
    "    all_fold_data_used.append(list(data_used))\n",
    "    all_fold_accuracies.append(list(accuracies))\n",
    "    all_fold_f1_micros.append(list(f1_micros))\n",
    "    all_fold_f1_macros.append(list(f1_macros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98ac16b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T10:15:46.729582Z",
     "iopub.status.busy": "2025-06-29T10:15:46.729225Z",
     "iopub.status.idle": "2025-06-29T10:15:47.441096Z",
     "shell.execute_reply": "2025-06-29T10:15:47.440252Z"
    },
    "papermill": {
     "duration": 0.994188,
     "end_time": "2025-06-29T10:15:47.443304",
     "exception": false,
     "start_time": "2025-06-29T10:15:46.449116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "common_data_points = sorted(list(set(point for fold_points in all_fold_data_used for point in fold_points)))\n",
    "\n",
    "# Interpolate metrics for each fold to the common data points\n",
    "avg_accuracies = []\n",
    "avg_f1_micros = []\n",
    "avg_f1_macros = []\n",
    "std_accuracies = []\n",
    "std_f1_micros = []\n",
    "std_f1_macros = []\n",
    "\n",
    "for point in common_data_points:\n",
    "    point_accuracies = []\n",
    "    point_f1_micros = []\n",
    "    point_f1_macros = []\n",
    "    for i in range(N_SPLITS):\n",
    "        sorted_indices = np.argsort(all_fold_data_used[i])\n",
    "        sorted_data = np.array(all_fold_data_used[i])[sorted_indices]\n",
    "        \n",
    "        sorted_acc = np.array(all_fold_accuracies[i])[sorted_indices]\n",
    "        sorted_f1m = np.array(all_fold_f1_micros[i])[sorted_indices]\n",
    "        sorted_f1ma = np.array(all_fold_f1_macros[i])[sorted_indices]\n",
    "        \n",
    "        # Use interpolation to estimate the metric value at the common 'point'\n",
    "        point_accuracies.append(np.interp(point, sorted_data, sorted_acc))\n",
    "        point_f1_micros.append(np.interp(point, sorted_data, sorted_f1m))\n",
    "        point_f1_macros.append(np.interp(point, sorted_data, sorted_f1ma))\n",
    "    \n",
    "    avg_accuracies.append(np.mean(point_accuracies))\n",
    "    avg_f1_micros.append(np.mean(point_f1_micros))\n",
    "    avg_f1_macros.append(np.mean(point_f1_macros))\n",
    "    \n",
    "    std_accuracies.append(np.std(point_accuracies))\n",
    "    std_f1_micros.append(np.std(point_f1_micros))\n",
    "    std_f1_macros.append(np.std(point_f1_macros))\n",
    "\n",
    "# Convert to numpy arrays for easier plotting\n",
    "avg_accuracies = np.array(avg_accuracies)\n",
    "avg_f1_micros = np.array(avg_f1_micros)\n",
    "avg_f1_macros = np.array(avg_f1_macros)\n",
    "std_accuracies = np.array(std_accuracies)\n",
    "std_f1_micros = np.array(std_f1_micros)\n",
    "std_f1_macros = np.array(std_f1_macros)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "data_used_percent = [round(data / len(X) * 100, 1) for data in common_data_points]\n",
    "\n",
    "# Plot for Accuracy\n",
    "axs[0].plot(data_used_percent, avg_accuracies, label=\"Avg Accuracy\", color=\"blue\")\n",
    "axs[0].fill_between(data_used_percent, avg_accuracies - std_accuracies, avg_accuracies + std_accuracies, color='blue', alpha=0.2)\n",
    "axs[0].set_xlabel(\"Percentage of data used\")\n",
    "axs[0].set_title(\"Average Accuracy Across Folds\")\n",
    "\n",
    "# Plot for F1 Micro\n",
    "axs[1].plot(data_used_percent, avg_f1_micros, label=\"Avg F1 Micro\", color=\"orange\")\n",
    "axs[1].fill_between(data_used_percent, avg_f1_micros - std_f1_micros, avg_f1_micros + std_f1_micros, color='orange', alpha=0.2)\n",
    "axs[1].set_xlabel(\"Percentage of data used\")\n",
    "axs[1].set_title(\"Average F1 Micro Across Folds\")\n",
    "\n",
    "# Plot for F1 Macro\n",
    "axs[2].plot(data_used_percent, avg_f1_macros, label=\"Avg F1 Macro\", color=\"green\")\n",
    "axs[2].fill_between(data_used_percent, avg_f1_macros - std_f1_macros, avg_f1_macros + std_f1_macros, color='green', alpha=0.2)\n",
    "axs[2].set_xlabel(\"Percentage of data used\")\n",
    "axs[2].set_title(\"Average F1 Macro Across Folds\")\n",
    "\n",
    "# Adjust layout and show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "for i in range(N_SPLITS):\n",
    "    result = pd.DataFrame({\n",
    "        'Data Used': all_fold_data_used[i],\n",
    "        'Accuracy': all_fold_accuracies[i],\n",
    "        'F1 Micro': all_fold_f1_micros[i],\n",
    "        'F1 Macro': all_fold_f1_macros[i],\n",
    "    })\n",
    "\n",
    "    result.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7611336,
     "sourceId": 12090808,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 28770.476836,
   "end_time": "2025-06-29T10:15:51.309097",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-29T02:16:20.832261",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "041d150928214c078390f407468ceed6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_cb27e15e06d343228a8b99e567ace482",
       "placeholder": "",
       "style": "IPY_MODEL_3fae4dfc744846db88255b6a609dee02",
       "tabbable": null,
       "tooltip": null,
       "value": "1.53k/?[00:00&lt;00:00,134kB/s]"
      }
     },
     "05b18267526040fe904b439951549d17": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8656e42909d445d4a868747127938988",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_42aed28891ec4c4abe12fbcfbeda23e7",
       "tabbable": null,
       "tooltip": null,
       "value": 2.0
      }
     },
     "095ef972f2f34d3780fcb4c0077e6211": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fd8b791dc193490d9f403bf91195c104",
       "placeholder": "",
       "style": "IPY_MODEL_7baa3d8304cc43e0be9499bb0ebd02bd",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json:100%"
      }
     },
     "09af7541583946c1a0726be4ab3ba926": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0afda120ebc34b91acda435158b7ce6a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0b3a720a3e13408c97f2241dee148968": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "128e43d8fba64ec1848f86d988f7a930": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c4787c39e2a94bc29d60b925b1cc64fd",
       "placeholder": "",
       "style": "IPY_MODEL_377971a95268457cbad3c5ebb4a670da",
       "tabbable": null,
       "tooltip": null,
       "value": "pytorch_model.bin:100%"
      }
     },
     "30fba71e1b214ef6a3b93ba04c63eecd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "35492c49a6194ce7868c306530dbfffb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "377971a95268457cbad3c5ebb4a670da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3916491944bb4abebd8b12835492fcda": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3958ecb42df345ddb7280dce610d06e9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3fae4dfc744846db88255b6a609dee02": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3fd38491efb844c49431bebd29490d12": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "40670e3dfdfd4a47b5e31af580f8f432": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "426fed6c0ae9496c851c669707148124": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0b3a720a3e13408c97f2241dee148968",
       "max": 112.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_765c1d4cc8054a0fa4a30620f075cc56",
       "tabbable": null,
       "tooltip": null,
       "value": 112.0
      }
     },
     "42aed28891ec4c4abe12fbcfbeda23e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "46b5fc0282a2491881f6ebe8393913fb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "49de8f8ad3964a938f6caedeb7312f10": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4aee2ebb27f948bab48cf1ce1cb37d1e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5186f3c972554249bc7b1f79402e37d1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "538b8acdcd9248ec9176efee620d6d8c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5e1af2f40b054a20811a58b295216d08": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3958ecb42df345ddb7280dce610d06e9",
       "placeholder": "",
       "style": "IPY_MODEL_49de8f8ad3964a938f6caedeb7312f10",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json:"
      }
     },
     "5e671c663dc94b779bb24c30e08fd2c2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6c71910ecd0d4367acc8aae7e77e1083": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "71930026e3fa44b38288c434077f9276": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7355a6897ba54a8ba979c0dcfff44f35": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "741be728d95c488e9742834be3e3e626": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_dafad93844504221b237a7bc748a3c81",
       "placeholder": "",
       "style": "IPY_MODEL_a075a2c7f619455aa1e16ee0bf3bc6e8",
       "tabbable": null,
       "tooltip": null,
       "value": "498M/498M[00:02&lt;00:00,254MB/s]"
      }
     },
     "752b26c26af54777827ac1b86121cbe4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "765c1d4cc8054a0fa4a30620f075cc56": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "79c234ee16574257b1353ac989a8abd6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_095ef972f2f34d3780fcb4c0077e6211",
        "IPY_MODEL_05b18267526040fe904b439951549d17",
        "IPY_MODEL_ba0dbb2bc99a49509afe8f4f974bb335"
       ],
       "layout": "IPY_MODEL_cee6a6b5bd1c4b4987571d1e0defb734",
       "tabbable": null,
       "tooltip": null
      }
     },
     "7baa3d8304cc43e0be9499bb0ebd02bd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "851c0a6385df4b8d8391a37e0319a781": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_128e43d8fba64ec1848f86d988f7a930",
        "IPY_MODEL_a78e3064fb94400180e609ccd63027c0",
        "IPY_MODEL_741be728d95c488e9742834be3e3e626"
       ],
       "layout": "IPY_MODEL_6c71910ecd0d4367acc8aae7e77e1083",
       "tabbable": null,
       "tooltip": null
      }
     },
     "8656e42909d445d4a868747127938988": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "912381e6a5a74eec952787b4c968e236": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "929e89e44942450283fc5dd973ece05f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5e1af2f40b054a20811a58b295216d08",
        "IPY_MODEL_a48214c82ce442e3a6d9c0053279b1c8",
        "IPY_MODEL_041d150928214c078390f407468ceed6"
       ],
       "layout": "IPY_MODEL_538b8acdcd9248ec9176efee620d6d8c",
       "tabbable": null,
       "tooltip": null
      }
     },
     "9ec6180e2ba94b79abc746e9a674a144": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a075a2c7f619455aa1e16ee0bf3bc6e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a48214c82ce442e3a6d9c0053279b1c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_912381e6a5a74eec952787b4c968e236",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3fd38491efb844c49431bebd29490d12",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "a78e3064fb94400180e609ccd63027c0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5e671c663dc94b779bb24c30e08fd2c2",
       "max": 497810400.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_46b5fc0282a2491881f6ebe8393913fb",
       "tabbable": null,
       "tooltip": null,
       "value": 497810400.0
      }
     },
     "ba0dbb2bc99a49509afe8f4f974bb335": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_40670e3dfdfd4a47b5e31af580f8f432",
       "placeholder": "",
       "style": "IPY_MODEL_cfc7effe62dc4223ac8f3e5b9714ffb2",
       "tabbable": null,
       "tooltip": null,
       "value": "2.00/2.00[00:00&lt;00:00,160B/s]"
      }
     },
     "bf031d9f7fbd40b9bd69ec6d683cdaa2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3916491944bb4abebd8b12835492fcda",
       "placeholder": "",
       "style": "IPY_MODEL_752b26c26af54777827ac1b86121cbe4",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt:"
      }
     },
     "c0b30660daf84e0c80faa3e2fa961f79": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_bf031d9f7fbd40b9bd69ec6d683cdaa2",
        "IPY_MODEL_e8582329bbf84782b486bad4182b78cb",
        "IPY_MODEL_c879927b4e1949c28b8eb8afb472b519"
       ],
       "layout": "IPY_MODEL_09af7541583946c1a0726be4ab3ba926",
       "tabbable": null,
       "tooltip": null
      }
     },
     "c4787c39e2a94bc29d60b925b1cc64fd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c5e8759ba1434e49a951162e51c39e2f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ea8bb4285d6a4fa4b774bf2616ac1400",
        "IPY_MODEL_426fed6c0ae9496c851c669707148124",
        "IPY_MODEL_ccdd06308ebf4d9d92c4310d2f013f01"
       ],
       "layout": "IPY_MODEL_5186f3c972554249bc7b1f79402e37d1",
       "tabbable": null,
       "tooltip": null
      }
     },
     "c879927b4e1949c28b8eb8afb472b519": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_30fba71e1b214ef6a3b93ba04c63eecd",
       "placeholder": "",
       "style": "IPY_MODEL_7355a6897ba54a8ba979c0dcfff44f35",
       "tabbable": null,
       "tooltip": null,
       "value": "229k/?[00:00&lt;00:00,9.16MB/s]"
      }
     },
     "cb27e15e06d343228a8b99e567ace482": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ccdd06308ebf4d9d92c4310d2f013f01": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_71930026e3fa44b38288c434077f9276",
       "placeholder": "",
       "style": "IPY_MODEL_9ec6180e2ba94b79abc746e9a674a144",
       "tabbable": null,
       "tooltip": null,
       "value": "112/112[00:00&lt;00:00,11.4kB/s]"
      }
     },
     "cee6a6b5bd1c4b4987571d1e0defb734": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cfc7effe62dc4223ac8f3e5b9714ffb2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "dafad93844504221b237a7bc748a3c81": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e2b7eefddf864acaaf13f0335ccdcd8f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e8582329bbf84782b486bad4182b78cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_35492c49a6194ce7868c306530dbfffb",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4aee2ebb27f948bab48cf1ce1cb37d1e",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "ea8bb4285d6a4fa4b774bf2616ac1400": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e2b7eefddf864acaaf13f0335ccdcd8f",
       "placeholder": "",
       "style": "IPY_MODEL_0afda120ebc34b91acda435158b7ce6a",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json:100%"
      }
     },
     "fd8b791dc193490d9f403bf91195c104": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
