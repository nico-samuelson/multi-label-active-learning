{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0046dfdd",
   "metadata": {
    "papermill": {
     "duration": 0.011307,
     "end_time": "2025-06-29T02:17:04.684092",
     "exception": false,
     "start_time": "2025-06-29T02:17:04.672785",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "485ca4ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:04.705553Z",
     "iopub.status.busy": "2025-06-29T02:17:04.705330Z",
     "iopub.status.idle": "2025-06-29T02:17:27.637292Z",
     "shell.execute_reply": "2025-06-29T02:17:27.636584Z"
    },
    "papermill": {
     "duration": 22.944461,
     "end_time": "2025-06-29T02:17:27.639000",
     "exception": false,
     "start_time": "2025-06-29T02:17:04.694539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ebb9a8",
   "metadata": {
    "papermill": {
     "duration": 0.010049,
     "end_time": "2025-06-29T02:17:27.659828",
     "exception": false,
     "start_time": "2025-06-29T02:17:27.649779",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f6d5e40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:27.681117Z",
     "iopub.status.busy": "2025-06-29T02:17:27.680608Z",
     "iopub.status.idle": "2025-06-29T02:17:27.684454Z",
     "shell.execute_reply": "2025-06-29T02:17:27.683687Z"
    },
    "papermill": {
     "duration": 0.015761,
     "end_time": "2025-06-29T02:17:27.685719",
     "exception": false,
     "start_time": "2025-06-29T02:17:27.669958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "301b1866",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:27.707139Z",
     "iopub.status.busy": "2025-06-29T02:17:27.706931Z",
     "iopub.status.idle": "2025-06-29T02:17:27.710586Z",
     "shell.execute_reply": "2025-06-29T02:17:27.709838Z"
    },
    "papermill": {
     "duration": 0.015659,
     "end_time": "2025-06-29T02:17:27.711785",
     "exception": false,
     "start_time": "2025-06-29T02:17:27.696126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/working/results') == False:\n",
    "    os.mkdir('/kaggle/working/results')\n",
    "\n",
    "if os.path.exists('/kaggle/working/acquired_data') == False:\n",
    "    os.mkdir('/kaggle/working/acquired_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0000781e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:27.732861Z",
     "iopub.status.busy": "2025-06-29T02:17:27.732591Z",
     "iopub.status.idle": "2025-06-29T02:17:27.741255Z",
     "shell.execute_reply": "2025-06-29T02:17:27.740458Z"
    },
    "papermill": {
     "duration": 0.020442,
     "end_time": "2025-06-29T02:17:27.742450",
     "exception": false,
     "start_time": "2025-06-29T02:17:27.722008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736586e5",
   "metadata": {
    "papermill": {
     "duration": 0.010262,
     "end_time": "2025-06-29T02:17:27.763381",
     "exception": false,
     "start_time": "2025-06-29T02:17:27.753119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a3c1d6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:27.784711Z",
     "iopub.status.busy": "2025-06-29T02:17:27.784474Z",
     "iopub.status.idle": "2025-06-29T02:17:27.834981Z",
     "shell.execute_reply": "2025-06-29T02:17:27.833536Z"
    },
    "papermill": {
     "duration": 0.062552,
     "end_time": "2025-06-29T02:17:27.836303",
     "exception": false,
     "start_time": "2025-06-29T02:17:27.773751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Shared resources\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "data_used = manager.list()\n",
    "sampling_dur = manager.list()\n",
    "new_samples = manager.list()\n",
    "\n",
    "# Non shared resources\n",
    "filename = 'hsd-kmeans-kfold'\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "sequence_length = 80\n",
    "min_increment = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f23f90a",
   "metadata": {
    "papermill": {
     "duration": 0.010088,
     "end_time": "2025-06-29T02:17:27.856926",
     "exception": false,
     "start_time": "2025-06-29T02:17:27.846838",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c52fc51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:27.883920Z",
     "iopub.status.busy": "2025-06-29T02:17:27.883608Z",
     "iopub.status.idle": "2025-06-29T02:17:28.018715Z",
     "shell.execute_reply": "2025-06-29T02:17:28.017712Z"
    },
    "papermill": {
     "duration": 0.152122,
     "end_time": "2025-06-29T02:17:28.019960",
     "exception": false,
     "start_time": "2025-06-29T02:17:27.867838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (13169, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>HS</th>\n",
       "      <th>Abusive</th>\n",
       "      <th>HS_Individual</th>\n",
       "      <th>HS_Group</th>\n",
       "      <th>HS_Religion</th>\n",
       "      <th>HS_Race</th>\n",
       "      <th>HS_Physical</th>\n",
       "      <th>HS_Gender</th>\n",
       "      <th>HS_Other</th>\n",
       "      <th>HS_Weak</th>\n",
       "      <th>HS_Moderate</th>\n",
       "      <th>HS_Strong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- disaat semua cowok berusaha melacak perhatia...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT USER: USER siapa yang telat ngasih tau elu?...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41. Kadang aku berfikir, kenapa aku tetap perc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USER USER AKU ITU AKU\\n\\nKU TAU MATAMU SIPIT T...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USER USER Kaum cebong kapir udah keliatan dong...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  HS  Abusive  \\\n",
       "0  - disaat semua cowok berusaha melacak perhatia...   1        1   \n",
       "1  RT USER: USER siapa yang telat ngasih tau elu?...   0        1   \n",
       "2  41. Kadang aku berfikir, kenapa aku tetap perc...   0        0   \n",
       "3  USER USER AKU ITU AKU\\n\\nKU TAU MATAMU SIPIT T...   0        0   \n",
       "4  USER USER Kaum cebong kapir udah keliatan dong...   1        1   \n",
       "\n",
       "   HS_Individual  HS_Group  HS_Religion  HS_Race  HS_Physical  HS_Gender  \\\n",
       "0              1         0            0        0            0          0   \n",
       "1              0         0            0        0            0          0   \n",
       "2              0         0            0        0            0          0   \n",
       "3              0         0            0        0            0          0   \n",
       "4              0         1            1        0            0          0   \n",
       "\n",
       "   HS_Other  HS_Weak  HS_Moderate  HS_Strong  \n",
       "0         1        1            0          0  \n",
       "1         0        0            0          0  \n",
       "2         0        0            0          0  \n",
       "3         0        0            0          0  \n",
       "4         0        0            1          0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/kaggle/input/multi-label-hate-speech/re_dataset.csv', encoding='latin-1')\n",
    "\n",
    "alay_dict = pd.read_csv('/kaggle/input/multi-label-hate-speech/new_kamusalay.csv', encoding='latin-1', header=None)\n",
    "alay_dict = alay_dict.rename(columns={0: 'original', \n",
    "                                      1: 'replacement'})\n",
    "\n",
    "print(\"Shape: \", data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "276cc74f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:28.042417Z",
     "iopub.status.busy": "2025-06-29T02:17:28.042164Z",
     "iopub.status.idle": "2025-06-29T02:17:28.054570Z",
     "shell.execute_reply": "2025-06-29T02:17:28.053681Z"
    },
    "papermill": {
     "duration": 0.024835,
     "end_time": "2025-06-29T02:17:28.055843",
     "exception": false,
     "start_time": "2025-06-29T02:17:28.031008",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HS\n",
       "0    7608\n",
       "1    5561\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.HS.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9057c8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:28.078047Z",
     "iopub.status.busy": "2025-06-29T02:17:28.077813Z",
     "iopub.status.idle": "2025-06-29T02:17:28.082906Z",
     "shell.execute_reply": "2025-06-29T02:17:28.082221Z"
    },
    "papermill": {
     "duration": 0.017466,
     "end_time": "2025-06-29T02:17:28.084126",
     "exception": false,
     "start_time": "2025-06-29T02:17:28.066660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Abusive\n",
       "0    8126\n",
       "1    5043\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Abusive.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4c125a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:28.106296Z",
     "iopub.status.busy": "2025-06-29T02:17:28.106089Z",
     "iopub.status.idle": "2025-06-29T02:17:28.116596Z",
     "shell.execute_reply": "2025-06-29T02:17:28.115885Z"
    },
    "papermill": {
     "duration": 0.022988,
     "end_time": "2025-06-29T02:17:28.117903",
     "exception": false,
     "start_time": "2025-06-29T02:17:28.094915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxic shape:  (7309, 13)\n",
      "Non-toxic shape:  (5860, 13)\n"
     ]
    }
   ],
   "source": [
    "print(\"Toxic shape: \", data[(data['HS'] == 1) | (data['Abusive'] == 1)].shape)\n",
    "print(\"Non-toxic shape: \", data[(data['HS'] == 0) & (data['Abusive'] == 0)].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bcffe02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:28.140654Z",
     "iopub.status.busy": "2025-06-29T02:17:28.140424Z",
     "iopub.status.idle": "2025-06-29T02:17:28.147883Z",
     "shell.execute_reply": "2025-06-29T02:17:28.147192Z"
    },
    "papermill": {
     "duration": 0.020233,
     "end_time": "2025-06-29T02:17:28.149159",
     "exception": false,
     "start_time": "2025-06-29T02:17:28.128926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (15167, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>replacement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>anakjakartaasikasik</td>\n",
       "      <td>anak jakarta asyik asyik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pakcikdahtua</td>\n",
       "      <td>pak cik sudah tua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pakcikmudalagi</td>\n",
       "      <td>pak cik muda lagi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t3tapjokowi</td>\n",
       "      <td>tetap jokowi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3x</td>\n",
       "      <td>tiga kali</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aamiin</td>\n",
       "      <td>amin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aamiinn</td>\n",
       "      <td>amin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aamin</td>\n",
       "      <td>amin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>aammiin</td>\n",
       "      <td>amin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>abis</td>\n",
       "      <td>habis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>abisin</td>\n",
       "      <td>habiskan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>acau</td>\n",
       "      <td>kacau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>achok</td>\n",
       "      <td>ahok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ad</td>\n",
       "      <td>ada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>adek</td>\n",
       "      <td>adik</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               original               replacement\n",
       "0   anakjakartaasikasik  anak jakarta asyik asyik\n",
       "1          pakcikdahtua         pak cik sudah tua\n",
       "2        pakcikmudalagi         pak cik muda lagi\n",
       "3           t3tapjokowi              tetap jokowi\n",
       "4                    3x                 tiga kali\n",
       "5                aamiin                      amin\n",
       "6               aamiinn                      amin\n",
       "7                 aamin                      amin\n",
       "8               aammiin                      amin\n",
       "9                  abis                     habis\n",
       "10               abisin                  habiskan\n",
       "11                 acau                     kacau\n",
       "12                achok                      ahok\n",
       "13                   ad                       ada\n",
       "14                 adek                      adik"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape: \", alay_dict.shape)\n",
    "alay_dict.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51b03ed7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:28.177686Z",
     "iopub.status.busy": "2025-06-29T02:17:28.177328Z",
     "iopub.status.idle": "2025-06-29T02:17:28.192045Z",
     "shell.execute_reply": "2025-06-29T02:17:28.191095Z"
    },
    "papermill": {
     "duration": 0.031487,
     "end_time": "2025-06-29T02:17:28.193706",
     "exception": false,
     "start_time": "2025-06-29T02:17:28.162219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove_nonaplhanumeric:  Halooo duniaa \n",
      "lowercase:  halooo, duniaa!\n",
      "remove_unnecessary_char:  Hehe RT USER USER apa kabs hehe URL \n",
      "normalize_alay:  amin adik habis\n"
     ]
    }
   ],
   "source": [
    "def lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_unnecessary_char(text):\n",
    "    text = re.sub('\\n',' ',text) # Remove every '\\n'\n",
    "    text = re.sub('rt',' ',text) # Remove every retweet symbol\n",
    "    text = re.sub('user',' ',text) # Remove every username\n",
    "    text = re.sub('url', ' ', text) # Remove every URL\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+)|(http?://[^\\s]+))',' ',text) # Remove every URL\n",
    "    text = re.sub(r'\\b(?:x[a-fA-F0-9]{2}\\s*)+\\b', '', text) # Remove emoji bytecode\n",
    "    text = re.sub('  +', ' ', text) # Remove extra spaces\n",
    "    return text\n",
    "    \n",
    "def remove_nonaplhanumeric(text):\n",
    "    text = re.sub('[^0-9a-zA-Z]+', ' ', text) \n",
    "    return text\n",
    "\n",
    "alay_dict_map = dict(zip(alay_dict['original'], alay_dict['replacement']))\n",
    "def normalize_alay(text):\n",
    "    return ' '.join([alay_dict_map[word] if word in alay_dict_map else word for word in text.split(' ')])\n",
    "\n",
    "print(\"remove_nonaplhanumeric: \", remove_nonaplhanumeric(\"Halooo,,,,, duniaa \\x8f \\xd2\\1 !!\"))\n",
    "print(\"lowercase: \", lowercase(\"Halooo, duniaa!\"))\n",
    "print(\"remove_unnecessary_char: \", remove_unnecessary_char(\"Hehe\\n\\n RT USER USER apa kabs www.google.com\\n  hehe URL xf8 x2a x89\"))\n",
    "print(\"normalize_alay: \", normalize_alay(\"aamiin adek abis\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "feaf08fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:28.221811Z",
     "iopub.status.busy": "2025-06-29T02:17:28.221565Z",
     "iopub.status.idle": "2025-06-29T02:17:28.224572Z",
     "shell.execute_reply": "2025-06-29T02:17:28.224033Z"
    },
    "papermill": {
     "duration": 0.01774,
     "end_time": "2025-06-29T02:17:28.225868",
     "exception": false,
     "start_time": "2025-06-29T02:17:28.208128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = lowercase(text)\n",
    "    text = remove_nonaplhanumeric(text)\n",
    "    text = remove_unnecessary_char(text)\n",
    "    text = normalize_alay(text) \n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6d075f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:28.250602Z",
     "iopub.status.busy": "2025-06-29T02:17:28.250403Z",
     "iopub.status.idle": "2025-06-29T02:17:28.625200Z",
     "shell.execute_reply": "2025-06-29T02:17:28.624291Z"
    },
    "papermill": {
     "duration": 0.388115,
     "end_time": "2025-06-29T02:17:28.626602",
     "exception": false,
     "start_time": "2025-06-29T02:17:28.238487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['Tweet'] = data['Tweet'].apply(preprocess)\n",
    "label_columns = data.columns[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d807f7",
   "metadata": {
    "papermill": {
     "duration": 0.011158,
     "end_time": "2025-06-29T02:17:28.649369",
     "exception": false,
     "start_time": "2025-06-29T02:17:28.638211",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BUILD DATASET & DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0db08d89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:28.672604Z",
     "iopub.status.busy": "2025-06-29T02:17:28.672347Z",
     "iopub.status.idle": "2025-06-29T02:17:29.279986Z",
     "shell.execute_reply": "2025-06-29T02:17:29.279283Z"
    },
    "papermill": {
     "duration": 0.620918,
     "end_time": "2025-06-29T02:17:29.281448",
     "exception": false,
     "start_time": "2025-06-29T02:17:28.660530",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f5daa4762cb409bbd022ef21dc74779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2ff57c6a84041c086eae0a5631e1e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf676439c3846d5ba0ee37612896fa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc2ac7453864563aaced0aca4f399a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class HateSpeechDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        labels = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(labels, dtype=torch.float if self.use_float else torch.long)\n",
    "        return item\n",
    "\n",
    "# Initialize BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "902c9586",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:29.307463Z",
     "iopub.status.busy": "2025-06-29T02:17:29.307147Z",
     "iopub.status.idle": "2025-06-29T02:17:29.311706Z",
     "shell.execute_reply": "2025-06-29T02:17:29.310936Z"
    },
    "papermill": {
     "duration": 0.018544,
     "end_time": "2025-06-29T02:17:29.312908",
     "exception": false,
     "start_time": "2025-06-29T02:17:29.294364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataloaders(X_train, y_train, X_val, y_val, sequence_length=96, num_workers=4):\n",
    "    train_dataset = HateSpeechDataset(X_train, y_train, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = HateSpeechDataset(X_val, y_val, tokenizer, max_length=sequence_length)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c980b0",
   "metadata": {
    "papermill": {
     "duration": 0.011538,
     "end_time": "2025-06-29T02:17:29.336411",
     "exception": false,
     "start_time": "2025-06-29T02:17:29.324873",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f8287b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:29.361083Z",
     "iopub.status.busy": "2025-06-29T02:17:29.360861Z",
     "iopub.status.idle": "2025-06-29T02:17:29.365512Z",
     "shell.execute_reply": "2025-06-29T02:17:29.364778Z"
    },
    "papermill": {
     "duration": 0.018517,
     "end_time": "2025-06-29T02:17:29.366731",
     "exception": false,
     "start_time": "2025-06-29T02:17:29.348214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        target_names=['HS', 'Abusive', 'HS_Individual', 'HS_Group', 'HS_Religion', 'HS_Race', 'HS_Physical', 'HS_Gender', 'HS_Other', 'HS_Weak', 'HS_Moderate', 'HS_Strong'],\n",
    "        zero_division=0\n",
    "    )   \n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b11a8cc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:29.391015Z",
     "iopub.status.busy": "2025-06-29T02:17:29.390817Z",
     "iopub.status.idle": "2025-06-29T02:17:29.402034Z",
     "shell.execute_reply": "2025-06-29T02:17:29.401419Z"
    },
    "papermill": {
     "duration": 0.024739,
     "end_time": "2025-06-29T02:17:29.403125",
     "exception": false,
     "start_time": "2025-06-29T02:17:29.378386",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, metrics, trials, seed, X_train_fold, y_train_fold, X_val_fold, y_val_fold, label_columns):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "\n",
    "    accelerator.print(f\"Fold {trials + 1} - Training with {current_train_size} samples...\")\n",
    "\n",
    "    with accelerator.main_process_first():\n",
    "        model = BertForSequenceClassification.from_pretrained(\n",
    "            'indobenchmark/indobert-base-p1',\n",
    "            num_labels=len(label_columns),\n",
    "            problem_type=\"multi_label_classification\"\n",
    "        )\n",
    "\n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Define DataLoaders using the fold's data\n",
    "    current_X_train = [X_train_fold[i] for i in train_indices]\n",
    "    current_y_train = [y_train_fold[i] for i in train_indices]\n",
    "    train_loader, val_loader = get_dataloaders(current_X_train, current_y_train, X_val_fold, y_val_fold)\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Prepare everything with Accelerator\n",
    "    model, optimizer, train_loader, val_loader = accelerator.prepare(\n",
    "        model, optimizer, train_loader, val_loader\n",
    "    )\n",
    "\n",
    "    best_result = None\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key != 'labels'}\n",
    "            labels = batch['labels']\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key != 'labels'}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "        result = compute_metrics(type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}))\n",
    "\n",
    "        if best_result is None or result['f1_micro'] >= best_result['f1_micro']:\n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'{filename}-fold-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "            best_result = result\n",
    "        \n",
    "        # This print can be commented out to reduce log spam in a k-fold loop\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    accelerator.print(f\"Best result for {current_train_size} samples: F1 Micro: {round(best_result['f1_micro'], 4)}\")\n",
    "    accelerator.print(best_result['report'])\n",
    "    \n",
    "    # Update the shared lists\n",
    "    if accelerator.is_local_main_process:\n",
    "        metrics[0].append(current_train_size)\n",
    "        metrics[1].append(best_result['accuracy'])\n",
    "        metrics[2].append(best_result['f1_micro'])\n",
    "        metrics[3].append(best_result['f1_macro'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcfb7e4",
   "metadata": {
    "papermill": {
     "duration": 0.011656,
     "end_time": "2025-06-29T02:17:29.427005",
     "exception": false,
     "start_time": "2025-06-29T02:17:29.415349",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PLOT THE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2dcff81a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:29.451246Z",
     "iopub.status.busy": "2025-06-29T02:17:29.451053Z",
     "iopub.status.idle": "2025-06-29T02:17:29.456153Z",
     "shell.execute_reply": "2025-06-29T02:17:29.455565Z"
    },
    "papermill": {
     "duration": 0.018423,
     "end_time": "2025-06-29T02:17:29.457230",
     "exception": false,
     "start_time": "2025-06-29T02:17:29.438807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3b56d4",
   "metadata": {
    "papermill": {
     "duration": 0.011633,
     "end_time": "2025-06-29T02:17:29.480605",
     "exception": false,
     "start_time": "2025-06-29T02:17:29.468972",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QUERY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b6a4e05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:29.505154Z",
     "iopub.status.busy": "2025-06-29T02:17:29.504932Z",
     "iopub.status.idle": "2025-06-29T02:17:29.519926Z",
     "shell.execute_reply": "2025-06-29T02:17:29.519137Z"
    },
    "papermill": {
     "duration": 0.028616,
     "end_time": "2025-06-29T02:17:29.521124",
     "exception": false,
     "start_time": "2025-06-29T02:17:29.492508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kmeans_clustering_sampling(model, X_pool, train_indices, remaining_indices, tokenizer, sampling_dur, new_samples, trials, X_train_fold, y_train_fold, n_clusters=min_increment):\n",
    "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "    device = accelerator.device\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    current_train_size = len(train_indices)\n",
    "    dataset = HateSpeechDataset(X_pool, np.zeros((len(X_pool), 4)), tokenizer, max_length=sequence_length)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    embeddings = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            input_ids = data['input_ids'].to(device)\n",
    "            attention_mask = data['attention_mask'].to(device)\n",
    "            outputs = model.base_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            hidden_states = outputs.last_hidden_state.mean(dim=1)  # Mean of hidden states for vector representation\n",
    "            embeddings.append(hidden_states.cpu().numpy())\n",
    "    \n",
    "    # Convert embeddings list to numpy array\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    embeddings = np.array(embeddings)\n",
    "    \n",
    "    collected_indices = set()  # Initialize set to store selected indices\n",
    "    thresholds = []\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "\n",
    "    if accelerator.is_local_main_process:\n",
    "        target_samples = len(embeddings[:math.ceil(0.1 * len(embeddings))])\n",
    "    \n",
    "        # Check nearest checkpoint\n",
    "        nearest_cp = 0\n",
    "        arrived_at_cp = False\n",
    "        for cp in checkpoints:\n",
    "            if cp > current_train_size:\n",
    "                nearest_cp = cp\n",
    "                break\n",
    "                \n",
    "        # Determine number of maximum samples to be acquired\n",
    "        if target_samples <= n_clusters and n_clusters < nearest_cp - current_train_size:\n",
    "            target_samples = n_clusters\n",
    "        elif target_samples > n_clusters and target_samples < nearest_cp - current_train_size:\n",
    "            target_samples = target_samples\n",
    "        else:\n",
    "            arrived_at_cp = True\n",
    "            target_samples = nearest_cp - current_train_size\n",
    "\n",
    "        # No clustering needed when there's little data left\n",
    "        if current_train_size >= checkpoints[len(checkpoints)-1] - min_increment:\n",
    "            end_time = time.time()\n",
    "            duration = end_time - start_time\n",
    "            \n",
    "            temp = train_indices.copy()\n",
    "            temp.extend(remaining_indices)\n",
    "            \n",
    "            # Save acquired data up to checkpoint\n",
    "            acquired_data = pd.DataFrame({\n",
    "                'processed_text': [X_train_fold[i] for i in temp],\n",
    "                'HS': [y_train_fold[i][0] for i in temp],\n",
    "                'Abusive': [y_train_fold[i][1] for i in temp],\n",
    "                'HS_Individual': [y_train_fold[i][2] for i in temp],\n",
    "                'HS_Group': [y_train_fold[i][3] for i in temp],\n",
    "                'HS_Religion': [y_train_fold[i][4] for i in temp],\n",
    "                'HS_Race': [y_train_fold[i][5] for i in temp],\n",
    "                'HS_Physical': [y_train_fold[i][6] for i in temp],\n",
    "                'HS_Gender': [y_train_fold[i][7] for i in temp],\n",
    "                'HS_Other': [y_train_fold[i][8] for i in temp],\n",
    "                'HS_Weak': [y_train_fold[i][9] for i in temp],\n",
    "                'HS_Moderate': [y_train_fold[i][10] for i in temp],\n",
    "                'HS_Strong': [y_train_fold[i][11] for i in temp],\n",
    "            })\n",
    "            acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "\n",
    "            print(\"Nearest checkpoint:\", nearest_cp)\n",
    "            print(\"Acquired samples:\", len(remaining_indices))\n",
    "            print(f\"Sampling duration: {duration} seconds\")\n",
    "            \n",
    "            sampling_dur.append(duration)\n",
    "            for i in remaining_indices:\n",
    "                new_samples.append(i)\n",
    "        else:\n",
    "            # Cluster the data based on its embeddings\n",
    "            kmeans=KMeans(n_clusters=n_clusters, n_init=1)\n",
    "            kmeans.fit(embeddings)\n",
    "            \n",
    "            for cluster_id in range(n_clusters):\n",
    "                # Cluster center and indices of samples in the current cluster\n",
    "                cluster_center = kmeans.cluster_centers_[cluster_id]\n",
    "                cluster_indices = np.where(kmeans.labels_ == cluster_id)[0]\n",
    "            \n",
    "                if cluster_indices.size == 0:\n",
    "                    # Skip clusters with no members\n",
    "                    print(f\"Cluster {cluster_id} has no members, skipping.\")\n",
    "                    continue\n",
    "            \n",
    "                # Calculate distances of each point in the cluster from the cluster center\n",
    "                cluster_distances = np.linalg.norm(embeddings[cluster_indices] - cluster_center, axis=1)\n",
    "            \n",
    "                # Determine the local threshold (10th percentile of closest distances to cluster center)\n",
    "                local_threshold = np.percentile(cluster_distances, 90)\n",
    "                thresholds.append(local_threshold)\n",
    "            \n",
    "                below_threshold_indices = cluster_indices[cluster_distances >= local_threshold]\n",
    "                collected_indices.update(below_threshold_indices)\n",
    "\n",
    "            # To handle multiple points with same distance\n",
    "            if len(collected_indices) > target_samples:\n",
    "                collected_indices = np.array(list(collected_indices))\n",
    "                np.random.shuffle(collected_indices)\n",
    "                collected_indices = collected_indices[:target_samples]\n",
    "                \n",
    "            end_time = time.time() \n",
    "            duration = end_time - start_time \n",
    "    \n",
    "            if arrived_at_cp:\n",
    "                temp = train_indices.copy()\n",
    "                temp.extend(collected_indices)\n",
    "                \n",
    "                # Save acquired data up to checkpoint\n",
    "                acquired_data = pd.DataFrame({\n",
    "                    'processed_text': [X_train_fold[i] for i in temp],\n",
    "                    'HS': [y_train_fold[i][0] for i in temp],\n",
    "                    'Abusive': [y_train_fold[i][1] for i in temp],\n",
    "                    'HS_Individual': [y_train_fold[i][2] for i in temp],\n",
    "                    'HS_Group': [y_train_fold[i][3] for i in temp],\n",
    "                    'HS_Religion': [y_train_fold[i][4] for i in temp],\n",
    "                    'HS_Race': [y_train_fold[i][5] for i in temp],\n",
    "                    'HS_Physical': [y_train_fold[i][6] for i in temp],\n",
    "                    'HS_Gender': [y_train_fold[i][7] for i in temp],\n",
    "                    'HS_Other': [y_train_fold[i][8] for i in temp],\n",
    "                    'HS_Weak': [y_train_fold[i][9] for i in temp],\n",
    "                    'HS_Moderate': [y_train_fold[i][10] for i in temp],\n",
    "                    'HS_Strong': [y_train_fold[i][11] for i in temp],\n",
    "                })\n",
    "        \n",
    "                acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "            \n",
    "            print(\"Nearest checkpoint:\", nearest_cp)\n",
    "            # print(f\"Thresholds: {thresholds}\")\n",
    "            print(\"Acquired samples:\", len(collected_indices))\n",
    "            print(f\"Sampling duration: {duration} seconds\")\n",
    "        \n",
    "            sampling_dur.append(duration)\n",
    "            for i in collected_indices:\n",
    "                new_samples.append(remaining_indices[i])\n",
    "\n",
    "        # threshold_data = pd.DataFrame({\n",
    "        #     'Threshold': thresholds\n",
    "        # })\n",
    "        # threshold_data.to_csv(f\"results/{filename}-thresholds-{trials+1}-{current_train_size}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4c7352",
   "metadata": {
    "papermill": {
     "duration": 0.011542,
     "end_time": "2025-06-29T02:17:29.544450",
     "exception": false,
     "start_time": "2025-06-29T02:17:29.532908",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e489bef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:29.568763Z",
     "iopub.status.busy": "2025-06-29T02:17:29.568524Z",
     "iopub.status.idle": "2025-06-29T11:25:09.253397Z",
     "shell.execute_reply": "2025-06-29T11:25:09.252443Z"
    },
    "papermill": {
     "duration": 32859.698667,
     "end_time": "2025-06-29T11:25:09.254859",
     "exception": false,
     "start_time": "2025-06-29T02:17:29.556192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "STARTING FOLD 1/5\n",
      "===============================================\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 658 samples...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e2eb0005655417b98f563a89a2f4d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.6381, Accuracy: 0.7985, F1 Micro: 0.3882, F1 Macro: 0.1172\n",
      "Epoch 2/10, Train Loss: 0.4768, Accuracy: 0.8343, F1 Micro: 0.1455, F1 Macro: 0.0462\n",
      "Epoch 3/10, Train Loss: 0.4068, Accuracy: 0.8333, F1 Micro: 0.1123, F1 Macro: 0.0388\n",
      "Epoch 4/10, Train Loss: 0.3813, Accuracy: 0.8332, F1 Micro: 0.1021, F1 Macro: 0.0367\n",
      "Epoch 5/10, Train Loss: 0.3774, Accuracy: 0.8373, F1 Micro: 0.1641, F1 Macro: 0.0541\n",
      "Epoch 6/10, Train Loss: 0.3665, Accuracy: 0.844, F1 Micro: 0.2355, F1 Macro: 0.0791\n",
      "Epoch 7/10, Train Loss: 0.355, Accuracy: 0.8526, F1 Micro: 0.3214, F1 Macro: 0.1069\n",
      "Epoch 8/10, Train Loss: 0.3289, Accuracy: 0.8608, F1 Micro: 0.3921, F1 Macro: 0.1407\n",
      "Epoch 9/10, Train Loss: 0.3142, Accuracy: 0.871, F1 Micro: 0.4906, F1 Macro: 0.2141\n",
      "Epoch 10/10, Train Loss: 0.2951, Accuracy: 0.8741, F1 Micro: 0.5196, F1 Macro: 0.2373\n",
      "Best result for 658 samples: F1 Micro: 0.5196\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.61      0.71      1141\n",
      "      Abusive       0.81      0.74      0.77      1012\n",
      "HS_Individual       0.67      0.36      0.47       737\n",
      "     HS_Group       0.00      0.00      0.00       404\n",
      "  HS_Religion       0.00      0.00      0.00       164\n",
      "      HS_Race       0.00      0.00      0.00       119\n",
      "  HS_Physical       0.00      0.00      0.00        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.72      0.35      0.47       779\n",
      "      HS_Weak       0.67      0.31      0.43       686\n",
      "  HS_Moderate       0.00      0.00      0.00       356\n",
      "    HS_Strong       0.00      0.00      0.00        99\n",
      "\n",
      "    micro avg       0.77      0.39      0.52      5608\n",
      "    macro avg       0.31      0.20      0.24      5608\n",
      " weighted avg       0.59      0.39      0.46      5608\n",
      "  samples avg       0.36      0.25      0.27      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 988\n",
      "Sampling duration: 50.73862147331238 seconds\n",
      "\n",
      "Fold 1 - New train size: 1646\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 1646 samples...\n",
      "Epoch 1/10, Train Loss: 0.5501, Accuracy: 0.8279, F1 Micro: 0.0317, F1 Macro: 0.0133\n",
      "Epoch 2/10, Train Loss: 0.3975, Accuracy: 0.8268, F1 Micro: 0.0071, F1 Macro: 0.0032\n",
      "Epoch 3/10, Train Loss: 0.3719, Accuracy: 0.8355, F1 Micro: 0.1238, F1 Macro: 0.0438\n",
      "Epoch 4/10, Train Loss: 0.3486, Accuracy: 0.8648, F1 Micro: 0.4459, F1 Macro: 0.1732\n",
      "Epoch 5/10, Train Loss: 0.3185, Accuracy: 0.8791, F1 Micro: 0.5478, F1 Macro: 0.2546\n",
      "Epoch 6/10, Train Loss: 0.2847, Accuracy: 0.8849, F1 Micro: 0.6357, F1 Macro: 0.3003\n",
      "Epoch 7/10, Train Loss: 0.2657, Accuracy: 0.8903, F1 Micro: 0.6222, F1 Macro: 0.3212\n",
      "Epoch 8/10, Train Loss: 0.2242, Accuracy: 0.8929, F1 Micro: 0.6252, F1 Macro: 0.3623\n",
      "Epoch 9/10, Train Loss: 0.219, Accuracy: 0.8971, F1 Micro: 0.6689, F1 Macro: 0.3845\n",
      "Epoch 10/10, Train Loss: 0.1887, Accuracy: 0.8986, F1 Micro: 0.6777, F1 Macro: 0.4134\n",
      "Best result for 1646 samples: F1 Micro: 0.6777\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.80      0.81      1141\n",
      "      Abusive       0.88      0.77      0.82      1012\n",
      "HS_Individual       0.68      0.68      0.68       737\n",
      "     HS_Group       0.73      0.35      0.48       404\n",
      "  HS_Religion       0.70      0.04      0.08       164\n",
      "      HS_Race       0.85      0.14      0.24       119\n",
      "  HS_Physical       0.00      0.00      0.00        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.72      0.71      0.71       779\n",
      "      HS_Weak       0.64      0.63      0.64       686\n",
      "  HS_Moderate       0.61      0.24      0.34       356\n",
      "    HS_Strong       1.00      0.08      0.15        99\n",
      "\n",
      "    micro avg       0.76      0.61      0.68      5608\n",
      "    macro avg       0.64      0.37      0.41      5608\n",
      " weighted avg       0.74      0.61      0.65      5608\n",
      "  samples avg       0.39      0.35      0.35      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 889\n",
      "Sampling duration: 48.031808376312256 seconds\n",
      "\n",
      "Fold 1 - New train size: 2535\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 2535 samples...\n",
      "Epoch 1/10, Train Loss: 0.5006, Accuracy: 0.8266, F1 Micro: 0.0053, F1 Macro: 0.0024\n",
      "Epoch 2/10, Train Loss: 0.3826, Accuracy: 0.8331, F1 Micro: 0.0905, F1 Macro: 0.0351\n",
      "Epoch 3/10, Train Loss: 0.3541, Accuracy: 0.8742, F1 Micro: 0.5064, F1 Macro: 0.2235\n",
      "Epoch 4/10, Train Loss: 0.3025, Accuracy: 0.887, F1 Micro: 0.6266, F1 Macro: 0.2915\n",
      "Epoch 5/10, Train Loss: 0.2697, Accuracy: 0.8922, F1 Micro: 0.6286, F1 Macro: 0.3298\n",
      "Epoch 6/10, Train Loss: 0.239, Accuracy: 0.9013, F1 Micro: 0.6867, F1 Macro: 0.421\n",
      "Epoch 7/10, Train Loss: 0.2131, Accuracy: 0.9034, F1 Micro: 0.7017, F1 Macro: 0.4478\n",
      "Epoch 8/10, Train Loss: 0.1826, Accuracy: 0.9049, F1 Micro: 0.7092, F1 Macro: 0.5109\n",
      "Epoch 9/10, Train Loss: 0.1667, Accuracy: 0.9081, F1 Micro: 0.7282, F1 Macro: 0.523\n",
      "Epoch 10/10, Train Loss: 0.1425, Accuracy: 0.9089, F1 Micro: 0.7144, F1 Macro: 0.5258\n",
      "Best result for 2535 samples: F1 Micro: 0.7282\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.81      0.85      0.83      1141\n",
      "      Abusive       0.87      0.83      0.85      1012\n",
      "HS_Individual       0.70      0.75      0.73       737\n",
      "     HS_Group       0.67      0.55      0.61       404\n",
      "  HS_Religion       0.82      0.33      0.47       164\n",
      "      HS_Race       0.80      0.37      0.51       119\n",
      "  HS_Physical       0.00      0.00      0.00        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.72      0.80      0.76       779\n",
      "      HS_Weak       0.66      0.73      0.70       686\n",
      "  HS_Moderate       0.56      0.41      0.47       356\n",
      "    HS_Strong       0.85      0.23      0.37        99\n",
      "\n",
      "    micro avg       0.75      0.71      0.73      5608\n",
      "    macro avg       0.62      0.49      0.52      5608\n",
      " weighted avg       0.74      0.71      0.71      5608\n",
      "  samples avg       0.41      0.40      0.39      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 800\n",
      "Sampling duration: 42.838346004486084 seconds\n",
      "\n",
      "Fold 1 - New train size: 3335\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 3335 samples...\n",
      "Epoch 1/10, Train Loss: 0.4724, Accuracy: 0.8283, F1 Micro: 0.0338, F1 Macro: 0.0142\n",
      "Epoch 2/10, Train Loss: 0.3664, Accuracy: 0.8475, F1 Micro: 0.2541, F1 Macro: 0.088\n",
      "Epoch 3/10, Train Loss: 0.3249, Accuracy: 0.8775, F1 Micro: 0.5156, F1 Macro: 0.2395\n",
      "Epoch 4/10, Train Loss: 0.2754, Accuracy: 0.8985, F1 Micro: 0.6689, F1 Macro: 0.4096\n",
      "Epoch 5/10, Train Loss: 0.236, Accuracy: 0.903, F1 Micro: 0.7178, F1 Macro: 0.502\n",
      "Epoch 6/10, Train Loss: 0.2038, Accuracy: 0.9089, F1 Micro: 0.7266, F1 Macro: 0.5136\n",
      "Epoch 7/10, Train Loss: 0.1723, Accuracy: 0.9106, F1 Micro: 0.7248, F1 Macro: 0.5433\n",
      "Epoch 8/10, Train Loss: 0.1445, Accuracy: 0.9135, F1 Micro: 0.7299, F1 Macro: 0.5423\n",
      "Epoch 9/10, Train Loss: 0.1319, Accuracy: 0.9082, F1 Micro: 0.7369, F1 Macro: 0.568\n",
      "Epoch 10/10, Train Loss: 0.112, Accuracy: 0.9122, F1 Micro: 0.7432, F1 Macro: 0.5511\n",
      "Best result for 3335 samples: F1 Micro: 0.7432\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.85      0.84      1141\n",
      "      Abusive       0.86      0.86      0.86      1012\n",
      "HS_Individual       0.69      0.76      0.72       737\n",
      "     HS_Group       0.71      0.53      0.61       404\n",
      "  HS_Religion       0.77      0.43      0.55       164\n",
      "      HS_Race       0.84      0.51      0.64       119\n",
      "  HS_Physical       0.00      0.00      0.00        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.74      0.83      0.78       779\n",
      "      HS_Weak       0.66      0.74      0.70       686\n",
      "  HS_Moderate       0.63      0.46      0.53       356\n",
      "    HS_Strong       0.81      0.25      0.38        99\n",
      "\n",
      "    micro avg       0.76      0.73      0.74      5608\n",
      "    macro avg       0.63      0.52      0.55      5608\n",
      " weighted avg       0.74      0.73      0.73      5608\n",
      "  samples avg       0.42      0.42      0.40      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 720\n",
      "Sampling duration: 39.09941291809082 seconds\n",
      "\n",
      "Fold 1 - New train size: 4055\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 4055 samples...\n",
      "Epoch 1/10, Train Loss: 0.4602, Accuracy: 0.8308, F1 Micro: 0.0654, F1 Macro: 0.0261\n",
      "Epoch 2/10, Train Loss: 0.3554, Accuracy: 0.8716, F1 Micro: 0.4852, F1 Macro: 0.2054\n",
      "Epoch 3/10, Train Loss: 0.3071, Accuracy: 0.8915, F1 Micro: 0.6276, F1 Macro: 0.3183\n",
      "Epoch 4/10, Train Loss: 0.265, Accuracy: 0.9037, F1 Micro: 0.6969, F1 Macro: 0.4876\n",
      "Epoch 5/10, Train Loss: 0.2269, Accuracy: 0.909, F1 Micro: 0.7182, F1 Macro: 0.4993\n",
      "Epoch 6/10, Train Loss: 0.194, Accuracy: 0.9121, F1 Micro: 0.7415, F1 Macro: 0.5663\n",
      "Epoch 7/10, Train Loss: 0.1675, Accuracy: 0.9157, F1 Micro: 0.7483, F1 Macro: 0.5675\n",
      "Epoch 8/10, Train Loss: 0.138, Accuracy: 0.916, F1 Micro: 0.7508, F1 Macro: 0.5773\n",
      "Epoch 9/10, Train Loss: 0.1209, Accuracy: 0.9169, F1 Micro: 0.7508, F1 Macro: 0.576\n",
      "Epoch 10/10, Train Loss: 0.1047, Accuracy: 0.9177, F1 Micro: 0.7491, F1 Macro: 0.5809\n",
      "Best result for 4055 samples: F1 Micro: 0.7508\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.85      0.85      1141\n",
      "      Abusive       0.86      0.86      0.86      1012\n",
      "HS_Individual       0.75      0.69      0.71       737\n",
      "     HS_Group       0.66      0.65      0.65       404\n",
      "  HS_Religion       0.79      0.57      0.66       164\n",
      "      HS_Race       0.77      0.69      0.73       119\n",
      "  HS_Physical       0.00      0.00      0.00        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.79      0.79      0.79       779\n",
      "      HS_Weak       0.71      0.65      0.68       686\n",
      "  HS_Moderate       0.58      0.60      0.59       356\n",
      "    HS_Strong       0.82      0.27      0.41        99\n",
      "\n",
      "    micro avg       0.77      0.73      0.75      5608\n",
      "    macro avg       0.63      0.55      0.58      5608\n",
      " weighted avg       0.76      0.73      0.74      5608\n",
      "  samples avg       0.43      0.41      0.40      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 648\n",
      "Sampling duration: 34.88990902900696 seconds\n",
      "\n",
      "Fold 1 - New train size: 4703\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 4703 samples...\n",
      "Epoch 1/10, Train Loss: 0.4452, Accuracy: 0.837, F1 Micro: 0.1516, F1 Macro: 0.053\n",
      "Epoch 2/10, Train Loss: 0.3422, Accuracy: 0.883, F1 Micro: 0.5858, F1 Macro: 0.2735\n",
      "Epoch 3/10, Train Loss: 0.2843, Accuracy: 0.8973, F1 Micro: 0.6503, F1 Macro: 0.3553\n",
      "Epoch 4/10, Train Loss: 0.2425, Accuracy: 0.907, F1 Micro: 0.7083, F1 Macro: 0.4658\n",
      "Epoch 5/10, Train Loss: 0.2145, Accuracy: 0.9124, F1 Micro: 0.7188, F1 Macro: 0.5481\n",
      "Epoch 6/10, Train Loss: 0.1805, Accuracy: 0.9183, F1 Micro: 0.7477, F1 Macro: 0.5704\n",
      "Epoch 7/10, Train Loss: 0.1516, Accuracy: 0.918, F1 Micro: 0.7603, F1 Macro: 0.5871\n",
      "Epoch 8/10, Train Loss: 0.1312, Accuracy: 0.9197, F1 Micro: 0.7528, F1 Macro: 0.5697\n",
      "Epoch 9/10, Train Loss: 0.1081, Accuracy: 0.9193, F1 Micro: 0.7565, F1 Macro: 0.5849\n",
      "Epoch 10/10, Train Loss: 0.0918, Accuracy: 0.9206, F1 Micro: 0.7633, F1 Macro: 0.5994\n",
      "Best result for 4703 samples: F1 Micro: 0.7633\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.84      0.85      1141\n",
      "      Abusive       0.88      0.85      0.86      1012\n",
      "HS_Individual       0.75      0.73      0.74       737\n",
      "     HS_Group       0.73      0.62      0.67       404\n",
      "  HS_Religion       0.72      0.62      0.66       164\n",
      "      HS_Race       0.78      0.73      0.75       119\n",
      "  HS_Physical       1.00      0.02      0.04        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.82      0.78      0.80       779\n",
      "      HS_Weak       0.70      0.72      0.71       686\n",
      "  HS_Moderate       0.64      0.53      0.58       356\n",
      "    HS_Strong       0.81      0.39      0.53        99\n",
      "\n",
      "    micro avg       0.79      0.74      0.76      5608\n",
      "    macro avg       0.72      0.57      0.60      5608\n",
      " weighted avg       0.78      0.74      0.75      5608\n",
      "  samples avg       0.44      0.42      0.41      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 584\n",
      "Sampling duration: 31.36405372619629 seconds\n",
      "\n",
      "Fold 1 - New train size: 5287\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 5287 samples...\n",
      "Epoch 1/10, Train Loss: 0.4389, Accuracy: 0.8417, F1 Micro: 0.2012, F1 Macro: 0.0718\n",
      "Epoch 2/10, Train Loss: 0.3321, Accuracy: 0.886, F1 Micro: 0.649, F1 Macro: 0.3127\n",
      "Epoch 3/10, Train Loss: 0.2754, Accuracy: 0.9031, F1 Micro: 0.695, F1 Macro: 0.4814\n",
      "Epoch 4/10, Train Loss: 0.2327, Accuracy: 0.9112, F1 Micro: 0.7344, F1 Macro: 0.5475\n",
      "Epoch 5/10, Train Loss: 0.1971, Accuracy: 0.9176, F1 Micro: 0.7466, F1 Macro: 0.5658\n",
      "Epoch 6/10, Train Loss: 0.1731, Accuracy: 0.9196, F1 Micro: 0.7617, F1 Macro: 0.5797\n",
      "Epoch 7/10, Train Loss: 0.1467, Accuracy: 0.9212, F1 Micro: 0.7662, F1 Macro: 0.589\n",
      "Epoch 8/10, Train Loss: 0.1244, Accuracy: 0.9185, F1 Micro: 0.7656, F1 Macro: 0.6079\n",
      "Epoch 9/10, Train Loss: 0.1054, Accuracy: 0.9183, F1 Micro: 0.7599, F1 Macro: 0.5998\n",
      "Epoch 10/10, Train Loss: 0.0905, Accuracy: 0.9208, F1 Micro: 0.7685, F1 Macro: 0.623\n",
      "Best result for 5287 samples: F1 Micro: 0.7685\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.85      0.85      1141\n",
      "      Abusive       0.87      0.88      0.88      1012\n",
      "HS_Individual       0.73      0.77      0.75       737\n",
      "     HS_Group       0.71      0.59      0.65       404\n",
      "  HS_Religion       0.74      0.63      0.68       164\n",
      "      HS_Race       0.75      0.75      0.75       119\n",
      "  HS_Physical       1.00      0.06      0.11        53\n",
      "    HS_Gender       1.00      0.03      0.07        58\n",
      "     HS_Other       0.80      0.80      0.80       779\n",
      "      HS_Weak       0.68      0.75      0.71       686\n",
      "  HS_Moderate       0.63      0.49      0.56       356\n",
      "    HS_Strong       0.76      0.62      0.68        99\n",
      "\n",
      "    micro avg       0.78      0.76      0.77      5608\n",
      "    macro avg       0.79      0.60      0.62      5608\n",
      " weighted avg       0.78      0.76      0.76      5608\n",
      "  samples avg       0.44      0.43      0.42      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 525\n",
      "Sampling duration: 28.376107931137085 seconds\n",
      "\n",
      "Fold 1 - New train size: 5812\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 5812 samples...\n",
      "Epoch 1/10, Train Loss: 0.4295, Accuracy: 0.853, F1 Micro: 0.32, F1 Macro: 0.1057\n",
      "Epoch 2/10, Train Loss: 0.3249, Accuracy: 0.889, F1 Micro: 0.6098, F1 Macro: 0.3008\n",
      "Epoch 3/10, Train Loss: 0.2692, Accuracy: 0.9046, F1 Micro: 0.7133, F1 Macro: 0.4673\n",
      "Epoch 4/10, Train Loss: 0.2272, Accuracy: 0.9122, F1 Micro: 0.7111, F1 Macro: 0.5191\n",
      "Epoch 5/10, Train Loss: 0.1959, Accuracy: 0.9177, F1 Micro: 0.754, F1 Macro: 0.5824\n",
      "Epoch 6/10, Train Loss: 0.1701, Accuracy: 0.919, F1 Micro: 0.7592, F1 Macro: 0.589\n",
      "Epoch 7/10, Train Loss: 0.1412, Accuracy: 0.9193, F1 Micro: 0.7683, F1 Macro: 0.6125\n",
      "Epoch 8/10, Train Loss: 0.1247, Accuracy: 0.9211, F1 Micro: 0.7646, F1 Macro: 0.6128\n",
      "Epoch 9/10, Train Loss: 0.1074, Accuracy: 0.9194, F1 Micro: 0.7489, F1 Macro: 0.6187\n",
      "Epoch 10/10, Train Loss: 0.0906, Accuracy: 0.9212, F1 Micro: 0.7645, F1 Macro: 0.6259\n",
      "Best result for 5812 samples: F1 Micro: 0.7683\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.88      0.85      1141\n",
      "      Abusive       0.86      0.88      0.87      1012\n",
      "HS_Individual       0.72      0.78      0.75       737\n",
      "     HS_Group       0.71      0.63      0.67       404\n",
      "  HS_Religion       0.69      0.71      0.70       164\n",
      "      HS_Race       0.70      0.79      0.74       119\n",
      "  HS_Physical       1.00      0.04      0.07        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.80      0.76      0.78       779\n",
      "      HS_Weak       0.68      0.77      0.72       686\n",
      "  HS_Moderate       0.64      0.57      0.60       356\n",
      "    HS_Strong       0.81      0.46      0.59        99\n",
      "\n",
      "    micro avg       0.77      0.77      0.77      5608\n",
      "    macro avg       0.70      0.61      0.61      5608\n",
      " weighted avg       0.76      0.77      0.76      5608\n",
      "  samples avg       0.44      0.44      0.43      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 473\n",
      "Sampling duration: 25.573607921600342 seconds\n",
      "\n",
      "Fold 1 - New train size: 6285\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 6285 samples...\n",
      "Epoch 1/10, Train Loss: 0.4304, Accuracy: 0.8596, F1 Micro: 0.3971, F1 Macro: 0.1377\n",
      "Epoch 2/10, Train Loss: 0.3122, Accuracy: 0.8924, F1 Micro: 0.6233, F1 Macro: 0.3193\n",
      "Epoch 3/10, Train Loss: 0.2583, Accuracy: 0.9085, F1 Micro: 0.7217, F1 Macro: 0.5228\n",
      "Epoch 4/10, Train Loss: 0.2227, Accuracy: 0.917, F1 Micro: 0.7507, F1 Macro: 0.5609\n",
      "Epoch 5/10, Train Loss: 0.1906, Accuracy: 0.9203, F1 Micro: 0.7631, F1 Macro: 0.5878\n",
      "Epoch 6/10, Train Loss: 0.1584, Accuracy: 0.9199, F1 Micro: 0.7452, F1 Macro: 0.5861\n",
      "Epoch 7/10, Train Loss: 0.1326, Accuracy: 0.9235, F1 Micro: 0.7677, F1 Macro: 0.6086\n",
      "Epoch 8/10, Train Loss: 0.1167, Accuracy: 0.9262, F1 Micro: 0.779, F1 Macro: 0.6287\n",
      "Epoch 9/10, Train Loss: 0.0968, Accuracy: 0.9227, F1 Micro: 0.7725, F1 Macro: 0.6385\n",
      "Epoch 10/10, Train Loss: 0.0812, Accuracy: 0.926, F1 Micro: 0.7717, F1 Macro: 0.6365\n",
      "Best result for 6285 samples: F1 Micro: 0.779\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.87      0.84      0.86      1141\n",
      "      Abusive       0.91      0.87      0.89      1012\n",
      "HS_Individual       0.79      0.72      0.75       737\n",
      "     HS_Group       0.71      0.64      0.68       404\n",
      "  HS_Religion       0.75      0.58      0.65       164\n",
      "      HS_Race       0.78      0.70      0.73       119\n",
      "  HS_Physical       1.00      0.06      0.11        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.80      0.81      0.81       779\n",
      "      HS_Weak       0.75      0.70      0.72       686\n",
      "  HS_Moderate       0.68      0.54      0.61       356\n",
      "    HS_Strong       0.74      0.74      0.74        99\n",
      "\n",
      "    micro avg       0.81      0.75      0.78      5608\n",
      "    macro avg       0.73      0.60      0.63      5608\n",
      " weighted avg       0.80      0.75      0.77      5608\n",
      "  samples avg       0.44      0.43      0.42      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 299\n",
      "Sampling duration: 23.08775234222412 seconds\n",
      "\n",
      "Fold 1 - New train size: 6584\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 6584 samples...\n",
      "Epoch 1/10, Train Loss: 0.4261, Accuracy: 0.8541, F1 Micro: 0.3193, F1 Macro: 0.1166\n",
      "Epoch 2/10, Train Loss: 0.3145, Accuracy: 0.8964, F1 Micro: 0.6683, F1 Macro: 0.3905\n",
      "Epoch 3/10, Train Loss: 0.2562, Accuracy: 0.9106, F1 Micro: 0.7215, F1 Macro: 0.5219\n",
      "Epoch 4/10, Train Loss: 0.2147, Accuracy: 0.9168, F1 Micro: 0.7552, F1 Macro: 0.5833\n",
      "Epoch 5/10, Train Loss: 0.1878, Accuracy: 0.9199, F1 Micro: 0.7666, F1 Macro: 0.5971\n",
      "Epoch 6/10, Train Loss: 0.1575, Accuracy: 0.9195, F1 Micro: 0.7699, F1 Macro: 0.5987\n",
      "Epoch 7/10, Train Loss: 0.1384, Accuracy: 0.922, F1 Micro: 0.7646, F1 Macro: 0.6155\n",
      "Epoch 8/10, Train Loss: 0.1158, Accuracy: 0.9238, F1 Micro: 0.7692, F1 Macro: 0.632\n",
      "Epoch 9/10, Train Loss: 0.0941, Accuracy: 0.9241, F1 Micro: 0.7778, F1 Macro: 0.6573\n",
      "Epoch 10/10, Train Loss: 0.0837, Accuracy: 0.9249, F1 Micro: 0.7742, F1 Macro: 0.6555\n",
      "Best result for 6584 samples: F1 Micro: 0.7778\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.86      0.86      1141\n",
      "      Abusive       0.90      0.87      0.88      1012\n",
      "HS_Individual       0.75      0.75      0.75       737\n",
      "     HS_Group       0.70      0.65      0.68       404\n",
      "  HS_Religion       0.76      0.59      0.66       164\n",
      "      HS_Race       0.77      0.74      0.75       119\n",
      "  HS_Physical       0.67      0.15      0.25        53\n",
      "    HS_Gender       0.71      0.09      0.15        58\n",
      "     HS_Other       0.81      0.81      0.81       779\n",
      "      HS_Weak       0.71      0.72      0.72       686\n",
      "  HS_Moderate       0.65      0.59      0.62       356\n",
      "    HS_Strong       0.81      0.74      0.77        99\n",
      "\n",
      "    micro avg       0.79      0.76      0.78      5608\n",
      "    macro avg       0.76      0.63      0.66      5608\n",
      " weighted avg       0.79      0.76      0.77      5608\n",
      "  samples avg       0.44      0.43      0.42      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Acquired samples: 396\n",
      "Sampling duration: 21.681837797164917 seconds\n",
      "\n",
      "Fold 1 - New train size: 6980\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 6980 samples...\n",
      "Epoch 1/10, Train Loss: 0.4227, Accuracy: 0.8697, F1 Micro: 0.4959, F1 Macro: 0.2047\n",
      "Epoch 2/10, Train Loss: 0.3026, Accuracy: 0.8943, F1 Micro: 0.6251, F1 Macro: 0.3624\n",
      "Epoch 3/10, Train Loss: 0.2492, Accuracy: 0.9102, F1 Micro: 0.7208, F1 Macro: 0.5076\n",
      "Epoch 4/10, Train Loss: 0.2093, Accuracy: 0.9167, F1 Micro: 0.7544, F1 Macro: 0.5714\n",
      "Epoch 5/10, Train Loss: 0.1795, Accuracy: 0.9209, F1 Micro: 0.748, F1 Macro: 0.5611\n",
      "Epoch 6/10, Train Loss: 0.1531, Accuracy: 0.9236, F1 Micro: 0.775, F1 Macro: 0.6321\n",
      "Epoch 7/10, Train Loss: 0.1334, Accuracy: 0.9269, F1 Micro: 0.7829, F1 Macro: 0.64\n",
      "Epoch 8/10, Train Loss: 0.112, Accuracy: 0.9237, F1 Micro: 0.7621, F1 Macro: 0.617\n",
      "Epoch 9/10, Train Loss: 0.0913, Accuracy: 0.9255, F1 Micro: 0.7804, F1 Macro: 0.6696\n",
      "Epoch 10/10, Train Loss: 0.0777, Accuracy: 0.926, F1 Micro: 0.7823, F1 Macro: 0.6661\n",
      "Best result for 6980 samples: F1 Micro: 0.7829\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.88      0.85      0.87      1141\n",
      "      Abusive       0.90      0.87      0.88      1012\n",
      "HS_Individual       0.76      0.76      0.76       737\n",
      "     HS_Group       0.75      0.62      0.68       404\n",
      "  HS_Religion       0.72      0.65      0.69       164\n",
      "      HS_Race       0.74      0.76      0.75       119\n",
      "  HS_Physical       1.00      0.08      0.14        53\n",
      "    HS_Gender       1.00      0.02      0.03        58\n",
      "     HS_Other       0.83      0.78      0.81       779\n",
      "      HS_Weak       0.71      0.75      0.73       686\n",
      "  HS_Moderate       0.69      0.55      0.61       356\n",
      "    HS_Strong       0.81      0.67      0.73        99\n",
      "\n",
      "    micro avg       0.81      0.76      0.78      5608\n",
      "    macro avg       0.82      0.61      0.64      5608\n",
      " weighted avg       0.81      0.76      0.78      5608\n",
      "  samples avg       0.44      0.42      0.42      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Acquired samples: 356\n",
      "Sampling duration: 19.523247241973877 seconds\n",
      "\n",
      "Fold 1 - New train size: 7336\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 7336 samples...\n",
      "Epoch 1/10, Train Loss: 0.4147, Accuracy: 0.8667, F1 Micro: 0.4358, F1 Macro: 0.1784\n",
      "Epoch 2/10, Train Loss: 0.2948, Accuracy: 0.9015, F1 Micro: 0.6747, F1 Macro: 0.4035\n",
      "Epoch 3/10, Train Loss: 0.2429, Accuracy: 0.912, F1 Micro: 0.7257, F1 Macro: 0.5156\n",
      "Epoch 4/10, Train Loss: 0.2117, Accuracy: 0.9135, F1 Micro: 0.7335, F1 Macro: 0.4992\n",
      "Epoch 5/10, Train Loss: 0.1785, Accuracy: 0.9205, F1 Micro: 0.7463, F1 Macro: 0.5812\n",
      "Epoch 6/10, Train Loss: 0.1519, Accuracy: 0.9218, F1 Micro: 0.7661, F1 Macro: 0.6162\n",
      "Epoch 7/10, Train Loss: 0.1265, Accuracy: 0.9241, F1 Micro: 0.7776, F1 Macro: 0.6351\n",
      "Epoch 8/10, Train Loss: 0.1133, Accuracy: 0.9239, F1 Micro: 0.7777, F1 Macro: 0.6574\n",
      "Epoch 9/10, Train Loss: 0.0927, Accuracy: 0.9261, F1 Micro: 0.7794, F1 Macro: 0.666\n",
      "Epoch 10/10, Train Loss: 0.0801, Accuracy: 0.9249, F1 Micro: 0.7849, F1 Macro: 0.6749\n",
      "Best result for 7336 samples: F1 Micro: 0.7849\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.88      0.86      1141\n",
      "      Abusive       0.87      0.92      0.89      1012\n",
      "HS_Individual       0.74      0.76      0.75       737\n",
      "     HS_Group       0.69      0.67      0.68       404\n",
      "  HS_Religion       0.77      0.59      0.67       164\n",
      "      HS_Race       0.74      0.76      0.75       119\n",
      "  HS_Physical       0.75      0.17      0.28        53\n",
      "    HS_Gender       0.62      0.17      0.27        58\n",
      "     HS_Other       0.80      0.83      0.82       779\n",
      "      HS_Weak       0.70      0.75      0.73       686\n",
      "  HS_Moderate       0.63      0.61      0.62       356\n",
      "    HS_Strong       0.85      0.74      0.79        99\n",
      "\n",
      "    micro avg       0.78      0.79      0.78      5608\n",
      "    macro avg       0.75      0.65      0.67      5608\n",
      " weighted avg       0.78      0.79      0.78      5608\n",
      "  samples avg       0.46      0.45      0.44      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Acquired samples: 320\n",
      "Sampling duration: 18.025370597839355 seconds\n",
      "\n",
      "Fold 1 - New train size: 7656\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 7656 samples...\n",
      "Epoch 1/10, Train Loss: 0.416, Accuracy: 0.8743, F1 Micro: 0.5202, F1 Macro: 0.2264\n",
      "Epoch 2/10, Train Loss: 0.2963, Accuracy: 0.8998, F1 Micro: 0.7104, F1 Macro: 0.4379\n",
      "Epoch 3/10, Train Loss: 0.2413, Accuracy: 0.9149, F1 Micro: 0.7339, F1 Macro: 0.556\n",
      "Epoch 4/10, Train Loss: 0.2044, Accuracy: 0.9186, F1 Micro: 0.7579, F1 Macro: 0.5708\n",
      "Epoch 5/10, Train Loss: 0.1702, Accuracy: 0.9224, F1 Micro: 0.7714, F1 Macro: 0.6058\n",
      "Epoch 6/10, Train Loss: 0.1474, Accuracy: 0.9246, F1 Micro: 0.7662, F1 Macro: 0.59\n",
      "Epoch 7/10, Train Loss: 0.1253, Accuracy: 0.9246, F1 Micro: 0.7787, F1 Macro: 0.6456\n",
      "Epoch 8/10, Train Loss: 0.1057, Accuracy: 0.9271, F1 Micro: 0.7864, F1 Macro: 0.6617\n",
      "Epoch 9/10, Train Loss: 0.0917, Accuracy: 0.9262, F1 Micro: 0.7801, F1 Macro: 0.6733\n",
      "Epoch 10/10, Train Loss: 0.0751, Accuracy: 0.9222, F1 Micro: 0.7754, F1 Macro: 0.6722\n",
      "Best result for 7656 samples: F1 Micro: 0.7864\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.86      0.86      1141\n",
      "      Abusive       0.89      0.90      0.89      1012\n",
      "HS_Individual       0.75      0.77      0.76       737\n",
      "     HS_Group       0.74      0.62      0.68       404\n",
      "  HS_Religion       0.77      0.60      0.68       164\n",
      "      HS_Race       0.78      0.76      0.77       119\n",
      "  HS_Physical       0.75      0.11      0.20        53\n",
      "    HS_Gender       1.00      0.10      0.19        58\n",
      "     HS_Other       0.79      0.81      0.80       779\n",
      "      HS_Weak       0.72      0.76      0.74       686\n",
      "  HS_Moderate       0.68      0.54      0.60       356\n",
      "    HS_Strong       0.81      0.74      0.77        99\n",
      "\n",
      "    micro avg       0.80      0.77      0.79      5608\n",
      "    macro avg       0.80      0.63      0.66      5608\n",
      " weighted avg       0.80      0.77      0.78      5608\n",
      "  samples avg       0.45      0.44      0.43      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Acquired samples: 245\n",
      "Sampling duration: 16.155174255371094 seconds\n",
      "\n",
      "Fold 1 - New train size: 7901\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 7901 samples...\n",
      "Epoch 1/10, Train Loss: 0.4114, Accuracy: 0.8788, F1 Micro: 0.5975, F1 Macro: 0.2779\n",
      "Epoch 2/10, Train Loss: 0.2908, Accuracy: 0.9023, F1 Micro: 0.6747, F1 Macro: 0.4501\n",
      "Epoch 3/10, Train Loss: 0.2392, Accuracy: 0.9144, F1 Micro: 0.7348, F1 Macro: 0.534\n",
      "Epoch 4/10, Train Loss: 0.2031, Accuracy: 0.9196, F1 Micro: 0.7519, F1 Macro: 0.5891\n",
      "Epoch 5/10, Train Loss: 0.1701, Accuracy: 0.922, F1 Micro: 0.7656, F1 Macro: 0.5906\n",
      "Epoch 6/10, Train Loss: 0.1452, Accuracy: 0.9253, F1 Micro: 0.7701, F1 Macro: 0.6205\n",
      "Epoch 7/10, Train Loss: 0.1205, Accuracy: 0.9258, F1 Micro: 0.7812, F1 Macro: 0.6396\n",
      "Epoch 8/10, Train Loss: 0.1066, Accuracy: 0.9248, F1 Micro: 0.7732, F1 Macro: 0.6646\n",
      "Epoch 9/10, Train Loss: 0.0907, Accuracy: 0.928, F1 Micro: 0.7831, F1 Macro: 0.6611\n",
      "Epoch 10/10, Train Loss: 0.0794, Accuracy: 0.9275, F1 Micro: 0.7888, F1 Macro: 0.6683\n",
      "Best result for 7901 samples: F1 Micro: 0.7888\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.87      0.87      1141\n",
      "      Abusive       0.91      0.88      0.89      1012\n",
      "HS_Individual       0.74      0.79      0.76       737\n",
      "     HS_Group       0.73      0.62      0.67       404\n",
      "  HS_Religion       0.75      0.63      0.68       164\n",
      "      HS_Race       0.74      0.78      0.76       119\n",
      "  HS_Physical       0.64      0.17      0.27        53\n",
      "    HS_Gender       0.75      0.10      0.18        58\n",
      "     HS_Other       0.81      0.82      0.81       779\n",
      "      HS_Weak       0.71      0.77      0.74       686\n",
      "  HS_Moderate       0.69      0.54      0.60       356\n",
      "    HS_Strong       0.79      0.76      0.77        99\n",
      "\n",
      "    micro avg       0.80      0.78      0.79      5608\n",
      "    macro avg       0.76      0.64      0.67      5608\n",
      " weighted avg       0.80      0.78      0.78      5608\n",
      "  samples avg       0.45      0.44      0.43      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 264\n",
      "Sampling duration: 14.882798910140991 seconds\n",
      "\n",
      "Fold 1 - New train size: 8165\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 8165 samples...\n",
      "Epoch 1/10, Train Loss: 0.4095, Accuracy: 0.8815, F1 Micro: 0.6284, F1 Macro: 0.3036\n",
      "Epoch 2/10, Train Loss: 0.2857, Accuracy: 0.9029, F1 Micro: 0.7236, F1 Macro: 0.5263\n",
      "Epoch 3/10, Train Loss: 0.2353, Accuracy: 0.914, F1 Micro: 0.7185, F1 Macro: 0.5375\n",
      "Epoch 4/10, Train Loss: 0.203, Accuracy: 0.9198, F1 Micro: 0.7677, F1 Macro: 0.5948\n",
      "Epoch 5/10, Train Loss: 0.1679, Accuracy: 0.9252, F1 Micro: 0.7778, F1 Macro: 0.6091\n",
      "Epoch 6/10, Train Loss: 0.1427, Accuracy: 0.9245, F1 Micro: 0.7713, F1 Macro: 0.6244\n",
      "Epoch 7/10, Train Loss: 0.1209, Accuracy: 0.9244, F1 Micro: 0.784, F1 Macro: 0.6588\n",
      "Epoch 8/10, Train Loss: 0.1014, Accuracy: 0.927, F1 Micro: 0.789, F1 Macro: 0.681\n",
      "Epoch 9/10, Train Loss: 0.0862, Accuracy: 0.9271, F1 Micro: 0.7854, F1 Macro: 0.6497\n",
      "Epoch 10/10, Train Loss: 0.0785, Accuracy: 0.9282, F1 Micro: 0.7884, F1 Macro: 0.6917\n",
      "Best result for 8165 samples: F1 Micro: 0.789\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.87      0.86      1141\n",
      "      Abusive       0.88      0.90      0.89      1012\n",
      "HS_Individual       0.75      0.78      0.76       737\n",
      "     HS_Group       0.72      0.65      0.68       404\n",
      "  HS_Religion       0.73      0.65      0.69       164\n",
      "      HS_Race       0.78      0.76      0.77       119\n",
      "  HS_Physical       0.50      0.17      0.25        53\n",
      "    HS_Gender       0.65      0.22      0.33        58\n",
      "     HS_Other       0.80      0.82      0.81       779\n",
      "      HS_Weak       0.72      0.76      0.74       686\n",
      "  HS_Moderate       0.68      0.60      0.64       356\n",
      "    HS_Strong       0.77      0.72      0.74        99\n",
      "\n",
      "    micro avg       0.79      0.78      0.79      5608\n",
      "    macro avg       0.74      0.66      0.68      5608\n",
      " weighted avg       0.79      0.78      0.78      5608\n",
      "  samples avg       0.44      0.44      0.43      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 237\n",
      "Sampling duration: 13.622646570205688 seconds\n",
      "\n",
      "Fold 1 - New train size: 8402\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 8402 samples...\n",
      "Epoch 1/10, Train Loss: 0.4069, Accuracy: 0.8812, F1 Micro: 0.5863, F1 Macro: 0.2742\n",
      "Epoch 2/10, Train Loss: 0.2831, Accuracy: 0.9055, F1 Micro: 0.7158, F1 Macro: 0.4847\n",
      "Epoch 3/10, Train Loss: 0.2342, Accuracy: 0.9154, F1 Micro: 0.735, F1 Macro: 0.5568\n",
      "Epoch 4/10, Train Loss: 0.194, Accuracy: 0.9216, F1 Micro: 0.7559, F1 Macro: 0.5885\n",
      "Epoch 5/10, Train Loss: 0.1641, Accuracy: 0.9172, F1 Micro: 0.7713, F1 Macro: 0.6165\n",
      "Epoch 6/10, Train Loss: 0.1403, Accuracy: 0.9241, F1 Micro: 0.778, F1 Macro: 0.6295\n",
      "Epoch 7/10, Train Loss: 0.123, Accuracy: 0.9248, F1 Micro: 0.7736, F1 Macro: 0.644\n",
      "Epoch 8/10, Train Loss: 0.1017, Accuracy: 0.9249, F1 Micro: 0.7838, F1 Macro: 0.6416\n",
      "Epoch 9/10, Train Loss: 0.0856, Accuracy: 0.9262, F1 Micro: 0.782, F1 Macro: 0.6753\n",
      "Epoch 10/10, Train Loss: 0.0715, Accuracy: 0.9224, F1 Micro: 0.7808, F1 Macro: 0.6863\n",
      "Best result for 8402 samples: F1 Micro: 0.7838\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.88      0.86      1141\n",
      "      Abusive       0.88      0.91      0.89      1012\n",
      "HS_Individual       0.73      0.77      0.75       737\n",
      "     HS_Group       0.73      0.64      0.68       404\n",
      "  HS_Religion       0.72      0.59      0.65       164\n",
      "      HS_Race       0.79      0.69      0.74       119\n",
      "  HS_Physical       0.75      0.06      0.11        53\n",
      "    HS_Gender       0.75      0.05      0.10        58\n",
      "     HS_Other       0.77      0.85      0.81       779\n",
      "      HS_Weak       0.69      0.76      0.73       686\n",
      "  HS_Moderate       0.68      0.59      0.63       356\n",
      "    HS_Strong       0.83      0.70      0.76        99\n",
      "\n",
      "    micro avg       0.78      0.78      0.78      5608\n",
      "    macro avg       0.76      0.62      0.64      5608\n",
      " weighted avg       0.78      0.78      0.78      5608\n",
      "  samples avg       0.45      0.45      0.44      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 214\n",
      "Sampling duration: 12.342350006103516 seconds\n",
      "\n",
      "Fold 1 - New train size: 8616\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 8616 samples...\n",
      "Epoch 1/10, Train Loss: 0.4078, Accuracy: 0.8777, F1 Micro: 0.6411, F1 Macro: 0.3129\n",
      "Epoch 2/10, Train Loss: 0.2824, Accuracy: 0.9018, F1 Micro: 0.6565, F1 Macro: 0.3984\n",
      "Epoch 3/10, Train Loss: 0.233, Accuracy: 0.9122, F1 Micro: 0.7099, F1 Macro: 0.5162\n",
      "Epoch 4/10, Train Loss: 0.1931, Accuracy: 0.9226, F1 Micro: 0.7545, F1 Macro: 0.5831\n",
      "Epoch 5/10, Train Loss: 0.1631, Accuracy: 0.9235, F1 Micro: 0.7614, F1 Macro: 0.6039\n",
      "Epoch 6/10, Train Loss: 0.1378, Accuracy: 0.9257, F1 Micro: 0.7817, F1 Macro: 0.6435\n",
      "Epoch 7/10, Train Loss: 0.1121, Accuracy: 0.9245, F1 Micro: 0.7791, F1 Macro: 0.6391\n",
      "Epoch 8/10, Train Loss: 0.0992, Accuracy: 0.9241, F1 Micro: 0.7812, F1 Macro: 0.6704\n",
      "Epoch 9/10, Train Loss: 0.0839, Accuracy: 0.9266, F1 Micro: 0.7823, F1 Macro: 0.6654\n",
      "Epoch 10/10, Train Loss: 0.0728, Accuracy: 0.9249, F1 Micro: 0.7852, F1 Macro: 0.6977\n",
      "Best result for 8616 samples: F1 Micro: 0.7852\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.88      0.86      1141\n",
      "      Abusive       0.88      0.92      0.90      1012\n",
      "HS_Individual       0.75      0.72      0.74       737\n",
      "     HS_Group       0.66      0.71      0.68       404\n",
      "  HS_Religion       0.71      0.71      0.71       164\n",
      "      HS_Race       0.75      0.78      0.77       119\n",
      "  HS_Physical       0.64      0.26      0.37        53\n",
      "    HS_Gender       0.76      0.28      0.41        58\n",
      "     HS_Other       0.80      0.83      0.81       779\n",
      "      HS_Weak       0.72      0.70      0.71       686\n",
      "  HS_Moderate       0.62      0.64      0.63       356\n",
      "    HS_Strong       0.77      0.79      0.78        99\n",
      "\n",
      "    micro avg       0.78      0.79      0.79      5608\n",
      "    macro avg       0.74      0.69      0.70      5608\n",
      " weighted avg       0.78      0.79      0.78      5608\n",
      "  samples avg       0.45      0.45      0.44      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 200\n",
      "Sampling duration: 11.24964714050293 seconds\n",
      "\n",
      "Fold 1 - New train size: 8816\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 8816 samples...\n",
      "Epoch 1/10, Train Loss: 0.4015, Accuracy: 0.8723, F1 Micro: 0.4789, F1 Macro: 0.2235\n",
      "Epoch 2/10, Train Loss: 0.2783, Accuracy: 0.908, F1 Micro: 0.7168, F1 Macro: 0.523\n",
      "Epoch 3/10, Train Loss: 0.2286, Accuracy: 0.9137, F1 Micro: 0.7561, F1 Macro: 0.5849\n",
      "Epoch 4/10, Train Loss: 0.1945, Accuracy: 0.9224, F1 Micro: 0.7593, F1 Macro: 0.571\n",
      "Epoch 5/10, Train Loss: 0.1628, Accuracy: 0.9233, F1 Micro: 0.7702, F1 Macro: 0.6221\n",
      "Epoch 6/10, Train Loss: 0.1374, Accuracy: 0.9257, F1 Micro: 0.7859, F1 Macro: 0.6592\n",
      "Epoch 7/10, Train Loss: 0.1218, Accuracy: 0.9269, F1 Micro: 0.7808, F1 Macro: 0.6467\n",
      "Epoch 8/10, Train Loss: 0.1043, Accuracy: 0.9258, F1 Micro: 0.7811, F1 Macro: 0.6824\n",
      "Epoch 9/10, Train Loss: 0.0869, Accuracy: 0.9218, F1 Micro: 0.7788, F1 Macro: 0.686\n",
      "Epoch 10/10, Train Loss: 0.0745, Accuracy: 0.926, F1 Micro: 0.7788, F1 Macro: 0.6619\n",
      "Best result for 8816 samples: F1 Micro: 0.7859\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.89      0.87      1141\n",
      "      Abusive       0.89      0.89      0.89      1012\n",
      "HS_Individual       0.71      0.81      0.76       737\n",
      "     HS_Group       0.75      0.62      0.68       404\n",
      "  HS_Religion       0.73      0.66      0.69       164\n",
      "      HS_Race       0.74      0.73      0.73       119\n",
      "  HS_Physical       0.58      0.13      0.22        53\n",
      "    HS_Gender       0.86      0.10      0.18        58\n",
      "     HS_Other       0.83      0.79      0.81       779\n",
      "      HS_Weak       0.69      0.80      0.74       686\n",
      "  HS_Moderate       0.69      0.56      0.62       356\n",
      "    HS_Strong       0.79      0.68      0.73        99\n",
      "\n",
      "    micro avg       0.79      0.78      0.79      5608\n",
      "    macro avg       0.76      0.64      0.66      5608\n",
      " weighted avg       0.79      0.78      0.78      5608\n",
      "  samples avg       0.44      0.44      0.43      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 200\n",
      "Sampling duration: 10.110695600509644 seconds\n",
      "\n",
      "Fold 1 - New train size: 9016\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 9016 samples...\n",
      "Epoch 1/10, Train Loss: 0.3986, Accuracy: 0.8843, F1 Micro: 0.627, F1 Macro: 0.3078\n",
      "Epoch 2/10, Train Loss: 0.2719, Accuracy: 0.9077, F1 Micro: 0.7148, F1 Macro: 0.4809\n",
      "Epoch 3/10, Train Loss: 0.2286, Accuracy: 0.9137, F1 Micro: 0.7254, F1 Macro: 0.5202\n",
      "Epoch 4/10, Train Loss: 0.1923, Accuracy: 0.9213, F1 Micro: 0.7687, F1 Macro: 0.5895\n",
      "Epoch 5/10, Train Loss: 0.1635, Accuracy: 0.925, F1 Micro: 0.7758, F1 Macro: 0.6278\n",
      "Epoch 6/10, Train Loss: 0.1357, Accuracy: 0.9248, F1 Micro: 0.7806, F1 Macro: 0.6436\n",
      "Epoch 7/10, Train Loss: 0.1191, Accuracy: 0.926, F1 Micro: 0.7768, F1 Macro: 0.6552\n",
      "Epoch 8/10, Train Loss: 0.1005, Accuracy: 0.927, F1 Micro: 0.7802, F1 Macro: 0.6849\n",
      "Epoch 9/10, Train Loss: 0.0836, Accuracy: 0.9271, F1 Micro: 0.7839, F1 Macro: 0.6778\n",
      "Epoch 10/10, Train Loss: 0.0721, Accuracy: 0.9275, F1 Micro: 0.7838, F1 Macro: 0.6921\n",
      "Best result for 9016 samples: F1 Micro: 0.7839\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.88      0.85      0.86      1141\n",
      "      Abusive       0.90      0.89      0.90      1012\n",
      "HS_Individual       0.80      0.71      0.75       737\n",
      "     HS_Group       0.68      0.69      0.68       404\n",
      "  HS_Religion       0.75      0.65      0.70       164\n",
      "      HS_Race       0.72      0.79      0.76       119\n",
      "  HS_Physical       0.65      0.21      0.31        53\n",
      "    HS_Gender       0.89      0.14      0.24        58\n",
      "     HS_Other       0.82      0.78      0.80       779\n",
      "      HS_Weak       0.76      0.68      0.72       686\n",
      "  HS_Moderate       0.62      0.63      0.63       356\n",
      "    HS_Strong       0.82      0.77      0.79        99\n",
      "\n",
      "    micro avg       0.81      0.76      0.78      5608\n",
      "    macro avg       0.77      0.65      0.68      5608\n",
      " weighted avg       0.81      0.76      0.78      5608\n",
      "  samples avg       0.44      0.43      0.42      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 200\n",
      "Sampling duration: 9.17569375038147 seconds\n",
      "\n",
      "Fold 1 - New train size: 9216\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 9216 samples...\n",
      "Epoch 1/10, Train Loss: 0.4011, Accuracy: 0.8794, F1 Micro: 0.5417, F1 Macro: 0.252\n",
      "Epoch 2/10, Train Loss: 0.2749, Accuracy: 0.9065, F1 Micro: 0.7182, F1 Macro: 0.4963\n",
      "Epoch 3/10, Train Loss: 0.2292, Accuracy: 0.9138, F1 Micro: 0.7522, F1 Macro: 0.5877\n",
      "Epoch 4/10, Train Loss: 0.1926, Accuracy: 0.9213, F1 Micro: 0.7683, F1 Macro: 0.5906\n",
      "Epoch 5/10, Train Loss: 0.1633, Accuracy: 0.9252, F1 Micro: 0.7794, F1 Macro: 0.6369\n",
      "Epoch 6/10, Train Loss: 0.137, Accuracy: 0.9245, F1 Micro: 0.7848, F1 Macro: 0.6518\n",
      "Epoch 7/10, Train Loss: 0.1113, Accuracy: 0.927, F1 Micro: 0.7805, F1 Macro: 0.6577\n",
      "Epoch 8/10, Train Loss: 0.0957, Accuracy: 0.9283, F1 Micro: 0.7824, F1 Macro: 0.6805\n",
      "Epoch 9/10, Train Loss: 0.0861, Accuracy: 0.9269, F1 Micro: 0.7868, F1 Macro: 0.6906\n",
      "Epoch 10/10, Train Loss: 0.0702, Accuracy: 0.9237, F1 Micro: 0.7878, F1 Macro: 0.7001\n",
      "Best result for 9216 samples: F1 Micro: 0.7878\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.90      0.86      1141\n",
      "      Abusive       0.88      0.94      0.91      1012\n",
      "HS_Individual       0.71      0.79      0.75       737\n",
      "     HS_Group       0.69      0.70      0.69       404\n",
      "  HS_Religion       0.72      0.68      0.70       164\n",
      "      HS_Race       0.74      0.78      0.76       119\n",
      "  HS_Physical       0.57      0.25      0.34        53\n",
      "    HS_Gender       0.60      0.36      0.45        58\n",
      "     HS_Other       0.77      0.84      0.81       779\n",
      "      HS_Weak       0.68      0.77      0.72       686\n",
      "  HS_Moderate       0.63      0.64      0.64       356\n",
      "    HS_Strong       0.81      0.75      0.78        99\n",
      "\n",
      "    micro avg       0.76      0.81      0.79      5608\n",
      "    macro avg       0.72      0.70      0.70      5608\n",
      " weighted avg       0.76      0.81      0.79      5608\n",
      "  samples avg       0.45      0.46      0.44      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 2\n",
      "Sampling duration: 8.134659767150879 seconds\n",
      "\n",
      "Fold 1 - New train size: 9218\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 9218 samples...\n",
      "Epoch 1/10, Train Loss: 0.4, Accuracy: 0.885, F1 Micro: 0.6368, F1 Macro: 0.3124\n",
      "Epoch 2/10, Train Loss: 0.2766, Accuracy: 0.9088, F1 Micro: 0.7125, F1 Macro: 0.4833\n",
      "Epoch 3/10, Train Loss: 0.224, Accuracy: 0.9166, F1 Micro: 0.7337, F1 Macro: 0.5679\n",
      "Epoch 4/10, Train Loss: 0.1885, Accuracy: 0.9223, F1 Micro: 0.7525, F1 Macro: 0.5924\n",
      "Epoch 5/10, Train Loss: 0.1619, Accuracy: 0.9247, F1 Micro: 0.7807, F1 Macro: 0.6354\n",
      "Epoch 6/10, Train Loss: 0.134, Accuracy: 0.9234, F1 Micro: 0.7729, F1 Macro: 0.634\n",
      "Epoch 7/10, Train Loss: 0.1098, Accuracy: 0.9263, F1 Micro: 0.7816, F1 Macro: 0.6603\n",
      "Epoch 8/10, Train Loss: 0.0909, Accuracy: 0.9251, F1 Micro: 0.7846, F1 Macro: 0.6766\n",
      "Epoch 9/10, Train Loss: 0.0798, Accuracy: 0.9244, F1 Micro: 0.7746, F1 Macro: 0.6764\n",
      "Epoch 10/10, Train Loss: 0.0724, Accuracy: 0.9264, F1 Micro: 0.7853, F1 Macro: 0.6876\n",
      "Best result for 9218 samples: F1 Micro: 0.7853\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.87      0.86      0.87      1141\n",
      "      Abusive       0.89      0.92      0.91      1012\n",
      "HS_Individual       0.72      0.79      0.75       737\n",
      "     HS_Group       0.76      0.55      0.64       404\n",
      "  HS_Religion       0.78      0.62      0.69       164\n",
      "      HS_Race       0.79      0.71      0.74       119\n",
      "  HS_Physical       0.58      0.26      0.36        53\n",
      "    HS_Gender       0.84      0.28      0.42        58\n",
      "     HS_Other       0.81      0.82      0.81       779\n",
      "      HS_Weak       0.68      0.77      0.72       686\n",
      "  HS_Moderate       0.71      0.49      0.58       356\n",
      "    HS_Strong       0.79      0.74      0.76        99\n",
      "\n",
      "    micro avg       0.80      0.77      0.79      5608\n",
      "    macro avg       0.77      0.65      0.69      5608\n",
      " weighted avg       0.80      0.77      0.78      5608\n",
      "  samples avg       0.45      0.44      0.43      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Acquired samples: 200\n",
      "Sampling duration: 8.159422636032104 seconds\n",
      "\n",
      "Fold 1 - New train size: 9418\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 9418 samples...\n",
      "Epoch 1/10, Train Loss: 0.3971, Accuracy: 0.8861, F1 Micro: 0.6128, F1 Macro: 0.2955\n",
      "Epoch 2/10, Train Loss: 0.2742, Accuracy: 0.9078, F1 Micro: 0.7107, F1 Macro: 0.4477\n",
      "Epoch 3/10, Train Loss: 0.2271, Accuracy: 0.9168, F1 Micro: 0.7261, F1 Macro: 0.5288\n",
      "Epoch 4/10, Train Loss: 0.1862, Accuracy: 0.9235, F1 Micro: 0.7744, F1 Macro: 0.6087\n",
      "Epoch 5/10, Train Loss: 0.1559, Accuracy: 0.9247, F1 Micro: 0.7755, F1 Macro: 0.6273\n",
      "Epoch 6/10, Train Loss: 0.1349, Accuracy: 0.9259, F1 Micro: 0.783, F1 Macro: 0.633\n",
      "Epoch 7/10, Train Loss: 0.1112, Accuracy: 0.9284, F1 Micro: 0.7917, F1 Macro: 0.697\n",
      "Epoch 8/10, Train Loss: 0.0982, Accuracy: 0.9257, F1 Micro: 0.7843, F1 Macro: 0.668\n",
      "Epoch 9/10, Train Loss: 0.0853, Accuracy: 0.9226, F1 Micro: 0.7793, F1 Macro: 0.6878\n",
      "Epoch 10/10, Train Loss: 0.0702, Accuracy: 0.9276, F1 Micro: 0.7902, F1 Macro: 0.709\n",
      "Best result for 9418 samples: F1 Micro: 0.7917\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.87      0.86      1141\n",
      "      Abusive       0.89      0.92      0.90      1012\n",
      "HS_Individual       0.76      0.76      0.76       737\n",
      "     HS_Group       0.71      0.66      0.69       404\n",
      "  HS_Religion       0.73      0.70      0.71       164\n",
      "      HS_Race       0.82      0.72      0.77       119\n",
      "  HS_Physical       0.53      0.19      0.28        53\n",
      "    HS_Gender       0.73      0.33      0.45        58\n",
      "     HS_Other       0.83      0.79      0.81       779\n",
      "      HS_Weak       0.73      0.74      0.74       686\n",
      "  HS_Moderate       0.66      0.61      0.63       356\n",
      "    HS_Strong       0.80      0.73      0.76        99\n",
      "\n",
      "    micro avg       0.80      0.78      0.79      5608\n",
      "    macro avg       0.75      0.67      0.70      5608\n",
      " weighted avg       0.80      0.78      0.79      5608\n",
      "  samples avg       0.45      0.44      0.43      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Acquired samples: 200\n",
      "Sampling duration: 7.37602686882019 seconds\n",
      "\n",
      "Fold 1 - New train size: 9618\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 9618 samples...\n",
      "Epoch 1/10, Train Loss: 0.392, Accuracy: 0.8806, F1 Micro: 0.5457, F1 Macro: 0.2587\n",
      "Epoch 2/10, Train Loss: 0.2735, Accuracy: 0.9094, F1 Micro: 0.7117, F1 Macro: 0.5198\n",
      "Epoch 3/10, Train Loss: 0.2235, Accuracy: 0.9193, F1 Micro: 0.7465, F1 Macro: 0.5725\n",
      "Epoch 4/10, Train Loss: 0.1878, Accuracy: 0.9244, F1 Micro: 0.7643, F1 Macro: 0.6023\n",
      "Epoch 5/10, Train Loss: 0.1594, Accuracy: 0.9253, F1 Micro: 0.7843, F1 Macro: 0.6323\n",
      "Epoch 6/10, Train Loss: 0.1305, Accuracy: 0.9235, F1 Micro: 0.7792, F1 Macro: 0.6582\n",
      "Epoch 7/10, Train Loss: 0.1106, Accuracy: 0.9254, F1 Micro: 0.787, F1 Macro: 0.6556\n",
      "Epoch 8/10, Train Loss: 0.0943, Accuracy: 0.9274, F1 Micro: 0.7837, F1 Macro: 0.6691\n",
      "Epoch 9/10, Train Loss: 0.0791, Accuracy: 0.9276, F1 Micro: 0.7859, F1 Macro: 0.6938\n",
      "Epoch 10/10, Train Loss: 0.0695, Accuracy: 0.9263, F1 Micro: 0.7821, F1 Macro: 0.6868\n",
      "Best result for 9618 samples: F1 Micro: 0.787\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.89      0.86      1141\n",
      "      Abusive       0.90      0.91      0.90      1012\n",
      "HS_Individual       0.72      0.80      0.76       737\n",
      "     HS_Group       0.73      0.64      0.68       404\n",
      "  HS_Religion       0.73      0.63      0.67       164\n",
      "      HS_Race       0.81      0.72      0.76       119\n",
      "  HS_Physical       0.56      0.09      0.16        53\n",
      "    HS_Gender       0.83      0.09      0.16        58\n",
      "     HS_Other       0.79      0.85      0.81       779\n",
      "      HS_Weak       0.68      0.78      0.73       686\n",
      "  HS_Moderate       0.67      0.56      0.61       356\n",
      "    HS_Strong       0.79      0.73      0.76        99\n",
      "\n",
      "    micro avg       0.78      0.79      0.79      5608\n",
      "    macro avg       0.75      0.64      0.66      5608\n",
      " weighted avg       0.78      0.79      0.78      5608\n",
      "  samples avg       0.45      0.45      0.44      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Acquired samples: 200\n",
      "Sampling duration: 6.065584659576416 seconds\n",
      "\n",
      "Fold 1 - New train size: 9818\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 9818 samples...\n",
      "Epoch 1/10, Train Loss: 0.3889, Accuracy: 0.8761, F1 Micro: 0.509, F1 Macro: 0.2384\n",
      "Epoch 2/10, Train Loss: 0.2702, Accuracy: 0.91, F1 Micro: 0.726, F1 Macro: 0.5279\n",
      "Epoch 3/10, Train Loss: 0.219, Accuracy: 0.9204, F1 Micro: 0.7577, F1 Macro: 0.5904\n",
      "Epoch 4/10, Train Loss: 0.1845, Accuracy: 0.9228, F1 Micro: 0.7749, F1 Macro: 0.6107\n",
      "Epoch 5/10, Train Loss: 0.1555, Accuracy: 0.9258, F1 Micro: 0.7716, F1 Macro: 0.6259\n",
      "Epoch 6/10, Train Loss: 0.1312, Accuracy: 0.9249, F1 Micro: 0.768, F1 Macro: 0.6254\n",
      "Epoch 7/10, Train Loss: 0.1107, Accuracy: 0.9266, F1 Micro: 0.7851, F1 Macro: 0.673\n",
      "Epoch 8/10, Train Loss: 0.0938, Accuracy: 0.9256, F1 Micro: 0.7817, F1 Macro: 0.6519\n",
      "Epoch 9/10, Train Loss: 0.0781, Accuracy: 0.9255, F1 Micro: 0.7829, F1 Macro: 0.6915\n",
      "Epoch 10/10, Train Loss: 0.0705, Accuracy: 0.9268, F1 Micro: 0.7818, F1 Macro: 0.687\n",
      "Best result for 9818 samples: F1 Micro: 0.7851\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.86      0.86      1141\n",
      "      Abusive       0.90      0.89      0.89      1012\n",
      "HS_Individual       0.74      0.77      0.75       737\n",
      "     HS_Group       0.74      0.64      0.69       404\n",
      "  HS_Religion       0.80      0.62      0.69       164\n",
      "      HS_Race       0.75      0.71      0.73       119\n",
      "  HS_Physical       0.54      0.13      0.21        53\n",
      "    HS_Gender       0.80      0.21      0.33        58\n",
      "     HS_Other       0.82      0.81      0.81       779\n",
      "      HS_Weak       0.70      0.74      0.72       686\n",
      "  HS_Moderate       0.69      0.57      0.62       356\n",
      "    HS_Strong       0.78      0.75      0.76        99\n",
      "\n",
      "    micro avg       0.80      0.77      0.79      5608\n",
      "    macro avg       0.76      0.64      0.67      5608\n",
      " weighted avg       0.80      0.77      0.78      5608\n",
      "  samples avg       0.44      0.44      0.42      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.991616487503052 seconds\n",
      "\n",
      "Fold 1 - New train size: 10018\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 10018 samples...\n",
      "Epoch 1/10, Train Loss: 0.3941, Accuracy: 0.8877, F1 Micro: 0.6514, F1 Macro: 0.3285\n",
      "Epoch 2/10, Train Loss: 0.2654, Accuracy: 0.9076, F1 Micro: 0.69, F1 Macro: 0.4901\n",
      "Epoch 3/10, Train Loss: 0.2149, Accuracy: 0.917, F1 Micro: 0.7571, F1 Macro: 0.5726\n",
      "Epoch 4/10, Train Loss: 0.1818, Accuracy: 0.9223, F1 Micro: 0.756, F1 Macro: 0.6067\n",
      "Epoch 5/10, Train Loss: 0.1518, Accuracy: 0.9276, F1 Micro: 0.784, F1 Macro: 0.6402\n",
      "Epoch 6/10, Train Loss: 0.1276, Accuracy: 0.9257, F1 Micro: 0.7756, F1 Macro: 0.6513\n",
      "Epoch 7/10, Train Loss: 0.1074, Accuracy: 0.9267, F1 Micro: 0.7839, F1 Macro: 0.6434\n",
      "Epoch 8/10, Train Loss: 0.0896, Accuracy: 0.9288, F1 Micro: 0.7878, F1 Macro: 0.682\n",
      "Epoch 9/10, Train Loss: 0.0762, Accuracy: 0.9276, F1 Micro: 0.7865, F1 Macro: 0.7014\n",
      "Epoch 10/10, Train Loss: 0.0647, Accuracy: 0.9295, F1 Micro: 0.7928, F1 Macro: 0.7105\n",
      "Best result for 10018 samples: F1 Micro: 0.7928\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.87      0.86      0.87      1141\n",
      "      Abusive       0.92      0.89      0.91      1012\n",
      "HS_Individual       0.74      0.78      0.76       737\n",
      "     HS_Group       0.76      0.59      0.67       404\n",
      "  HS_Religion       0.76      0.66      0.70       164\n",
      "      HS_Race       0.82      0.71      0.76       119\n",
      "  HS_Physical       0.59      0.32      0.41        53\n",
      "    HS_Gender       0.70      0.40      0.51        58\n",
      "     HS_Other       0.82      0.82      0.82       779\n",
      "      HS_Weak       0.72      0.76      0.74       686\n",
      "  HS_Moderate       0.72      0.51      0.60       356\n",
      "    HS_Strong       0.79      0.80      0.79        99\n",
      "\n",
      "    micro avg       0.81      0.78      0.79      5608\n",
      "    macro avg       0.77      0.67      0.71      5608\n",
      " weighted avg       0.81      0.78      0.79      5608\n",
      "  samples avg       0.45      0.44      0.43      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.019447565078735 seconds\n",
      "\n",
      "Fold 1 - New train size: 10218\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 10218 samples...\n",
      "Epoch 1/10, Train Loss: 0.3858, Accuracy: 0.8898, F1 Micro: 0.6453, F1 Macro: 0.3333\n",
      "Epoch 2/10, Train Loss: 0.2608, Accuracy: 0.9119, F1 Micro: 0.7318, F1 Macro: 0.5345\n",
      "Epoch 3/10, Train Loss: 0.2109, Accuracy: 0.9201, F1 Micro: 0.7613, F1 Macro: 0.5877\n",
      "Epoch 4/10, Train Loss: 0.1751, Accuracy: 0.9254, F1 Micro: 0.7797, F1 Macro: 0.6211\n",
      "Epoch 5/10, Train Loss: 0.1482, Accuracy: 0.927, F1 Micro: 0.7854, F1 Macro: 0.6507\n",
      "Epoch 6/10, Train Loss: 0.1233, Accuracy: 0.9295, F1 Micro: 0.785, F1 Macro: 0.6552\n",
      "Epoch 7/10, Train Loss: 0.1052, Accuracy: 0.921, F1 Micro: 0.7798, F1 Macro: 0.678\n",
      "Epoch 8/10, Train Loss: 0.0916, Accuracy: 0.9281, F1 Micro: 0.7907, F1 Macro: 0.6979\n",
      "Epoch 9/10, Train Loss: 0.0744, Accuracy: 0.9265, F1 Micro: 0.7882, F1 Macro: 0.6919\n",
      "Epoch 10/10, Train Loss: 0.0649, Accuracy: 0.9261, F1 Micro: 0.7878, F1 Macro: 0.7171\n",
      "Best result for 10218 samples: F1 Micro: 0.7907\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.87      0.87      0.87      1141\n",
      "      Abusive       0.92      0.88      0.90      1012\n",
      "HS_Individual       0.74      0.77      0.76       737\n",
      "     HS_Group       0.72      0.65      0.68       404\n",
      "  HS_Religion       0.72      0.69      0.70       164\n",
      "      HS_Race       0.77      0.71      0.74       119\n",
      "  HS_Physical       0.59      0.19      0.29        53\n",
      "    HS_Gender       0.87      0.34      0.49        58\n",
      "     HS_Other       0.81      0.82      0.82       779\n",
      "      HS_Weak       0.72      0.75      0.73       686\n",
      "  HS_Moderate       0.66      0.58      0.62       356\n",
      "    HS_Strong       0.78      0.79      0.78        99\n",
      "\n",
      "    micro avg       0.80      0.78      0.79      5608\n",
      "    macro avg       0.76      0.67      0.70      5608\n",
      " weighted avg       0.80      0.78      0.79      5608\n",
      "  samples avg       0.45      0.44      0.43      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.7967371940612793 seconds\n",
      "\n",
      "Fold 1 - New train size: 10418\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 10418 samples...\n",
      "Epoch 1/10, Train Loss: 0.3819, Accuracy: 0.8904, F1 Micro: 0.644, F1 Macro: 0.3328\n",
      "Epoch 2/10, Train Loss: 0.2521, Accuracy: 0.9108, F1 Micro: 0.7379, F1 Macro: 0.5205\n",
      "Epoch 3/10, Train Loss: 0.2085, Accuracy: 0.9226, F1 Micro: 0.7581, F1 Macro: 0.5928\n",
      "Epoch 4/10, Train Loss: 0.1744, Accuracy: 0.9229, F1 Micro: 0.7793, F1 Macro: 0.623\n",
      "Epoch 5/10, Train Loss: 0.1464, Accuracy: 0.9289, F1 Micro: 0.7826, F1 Macro: 0.6377\n",
      "Epoch 6/10, Train Loss: 0.1209, Accuracy: 0.9267, F1 Micro: 0.7909, F1 Macro: 0.6954\n",
      "Epoch 7/10, Train Loss: 0.102, Accuracy: 0.9255, F1 Micro: 0.7827, F1 Macro: 0.66\n",
      "Epoch 8/10, Train Loss: 0.0902, Accuracy: 0.9265, F1 Micro: 0.7884, F1 Macro: 0.6852\n",
      "Epoch 9/10, Train Loss: 0.0747, Accuracy: 0.9282, F1 Micro: 0.7834, F1 Macro: 0.682\n",
      "Epoch 10/10, Train Loss: 0.0657, Accuracy: 0.9264, F1 Micro: 0.7879, F1 Macro: 0.7197\n",
      "Best result for 10418 samples: F1 Micro: 0.7909\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.89      0.86      1141\n",
      "      Abusive       0.89      0.91      0.90      1012\n",
      "HS_Individual       0.73      0.79      0.76       737\n",
      "     HS_Group       0.72      0.66      0.69       404\n",
      "  HS_Religion       0.75      0.67      0.71       164\n",
      "      HS_Race       0.74      0.76      0.75       119\n",
      "  HS_Physical       0.43      0.23      0.30        53\n",
      "    HS_Gender       0.61      0.34      0.44        58\n",
      "     HS_Other       0.81      0.82      0.82       779\n",
      "      HS_Weak       0.71      0.78      0.74       686\n",
      "  HS_Moderate       0.66      0.57      0.61       356\n",
      "    HS_Strong       0.77      0.77      0.77        99\n",
      "\n",
      "    micro avg       0.78      0.80      0.79      5608\n",
      "    macro avg       0.72      0.68      0.70      5608\n",
      " weighted avg       0.78      0.80      0.79      5608\n",
      "  samples avg       0.45      0.45      0.44      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Acquired samples: 117\n",
      "Sampling duration: 1.429175853729248 seconds\n",
      "\n",
      "Fold 1 - New train size: 10535\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 10535 samples...\n",
      "Epoch 1/10, Train Loss: 0.3821, Accuracy: 0.8879, F1 Micro: 0.6031, F1 Macro: 0.3114\n",
      "Epoch 2/10, Train Loss: 0.2516, Accuracy: 0.9136, F1 Micro: 0.7418, F1 Macro: 0.5548\n",
      "Epoch 3/10, Train Loss: 0.2062, Accuracy: 0.9211, F1 Micro: 0.7522, F1 Macro: 0.5629\n",
      "Epoch 4/10, Train Loss: 0.1699, Accuracy: 0.9238, F1 Micro: 0.7745, F1 Macro: 0.6234\n",
      "Epoch 5/10, Train Loss: 0.1424, Accuracy: 0.9264, F1 Micro: 0.7873, F1 Macro: 0.6747\n",
      "Epoch 6/10, Train Loss: 0.1229, Accuracy: 0.9265, F1 Micro: 0.7838, F1 Macro: 0.6604\n",
      "Epoch 7/10, Train Loss: 0.0992, Accuracy: 0.9238, F1 Micro: 0.785, F1 Macro: 0.6712\n",
      "Epoch 8/10, Train Loss: 0.0828, Accuracy: 0.9286, F1 Micro: 0.7911, F1 Macro: 0.7022\n",
      "Epoch 9/10, Train Loss: 0.0752, Accuracy: 0.9273, F1 Micro: 0.7912, F1 Macro: 0.7119\n",
      "Epoch 10/10, Train Loss: 0.0653, Accuracy: 0.9268, F1 Micro: 0.7825, F1 Macro: 0.7007\n",
      "Best result for 10535 samples: F1 Micro: 0.7912\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.87      0.86      1141\n",
      "      Abusive       0.90      0.91      0.91      1012\n",
      "HS_Individual       0.73      0.77      0.75       737\n",
      "     HS_Group       0.73      0.67      0.70       404\n",
      "  HS_Religion       0.74      0.68      0.71       164\n",
      "      HS_Race       0.77      0.74      0.76       119\n",
      "  HS_Physical       0.62      0.25      0.35        53\n",
      "    HS_Gender       0.71      0.43      0.54        58\n",
      "     HS_Other       0.80      0.82      0.81       779\n",
      "      HS_Weak       0.70      0.75      0.73       686\n",
      "  HS_Moderate       0.67      0.59      0.63       356\n",
      "    HS_Strong       0.78      0.85      0.81        99\n",
      "\n",
      "    micro avg       0.79      0.79      0.79      5608\n",
      "    macro avg       0.75      0.69      0.71      5608\n",
      " weighted avg       0.79      0.79      0.79      5608\n",
      "  samples avg       0.45      0.45      0.44      5608\n",
      "\n",
      "\n",
      "FOLD 1 COMPLETED in 6547.68 seconds\n",
      "===============================================\n",
      "STARTING FOLD 2/5\n",
      "===============================================\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 658 samples...\n",
      "Epoch 1/10, Train Loss: 0.6074, Accuracy: 0.8369, F1 Micro: 0.2789, F1 Macro: 0.0958\n",
      "Epoch 2/10, Train Loss: 0.4725, Accuracy: 0.8453, F1 Micro: 0.2388, F1 Macro: 0.078\n",
      "Epoch 3/10, Train Loss: 0.414, Accuracy: 0.8392, F1 Micro: 0.1207, F1 Macro: 0.0438\n",
      "Epoch 4/10, Train Loss: 0.3877, Accuracy: 0.849, F1 Micro: 0.2496, F1 Macro: 0.0847\n",
      "Epoch 5/10, Train Loss: 0.3756, Accuracy: 0.8507, F1 Micro: 0.271, F1 Macro: 0.0898\n",
      "Epoch 6/10, Train Loss: 0.3627, Accuracy: 0.8593, F1 Micro: 0.3917, F1 Macro: 0.1349\n",
      "Epoch 7/10, Train Loss: 0.347, Accuracy: 0.8698, F1 Micro: 0.4861, F1 Macro: 0.2087\n",
      "Epoch 8/10, Train Loss: 0.3046, Accuracy: 0.8757, F1 Micro: 0.576, F1 Macro: 0.2681\n",
      "Epoch 9/10, Train Loss: 0.295, Accuracy: 0.8795, F1 Micro: 0.5968, F1 Macro: 0.3013\n",
      "Epoch 10/10, Train Loss: 0.2598, Accuracy: 0.8811, F1 Micro: 0.6072, F1 Macro: 0.318\n",
      "Best result for 658 samples: F1 Micro: 0.6072\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.75      0.76      0.75      1094\n",
      "      Abusive       0.81      0.73      0.77      1072\n",
      "HS_Individual       0.60      0.58      0.59       689\n",
      "     HS_Group       0.66      0.29      0.40       405\n",
      "  HS_Religion       0.00      0.00      0.00       124\n",
      "      HS_Race       0.00      0.00      0.00       125\n",
      "  HS_Physical       0.00      0.00      0.00        61\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.64      0.59      0.62       754\n",
      "      HS_Weak       0.59      0.55      0.57       664\n",
      "  HS_Moderate       0.48      0.07      0.12       346\n",
      "    HS_Strong       0.00      0.00      0.00        84\n",
      "\n",
      "    micro avg       0.69      0.54      0.61      5476\n",
      "    macro avg       0.38      0.30      0.32      5476\n",
      " weighted avg       0.62      0.54      0.57      5476\n",
      "  samples avg       0.37      0.32      0.32      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 988\n",
      "Sampling duration: 53.760557651519775 seconds\n",
      "\n",
      "Fold 2 - New train size: 1646\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 1646 samples...\n",
      "Epoch 1/10, Train Loss: 0.5308, Accuracy: 0.8401, F1 Micro: 0.1519, F1 Macro: 0.0521\n",
      "Epoch 2/10, Train Loss: 0.3935, Accuracy: 0.8348, F1 Micro: 0.062, F1 Macro: 0.0241\n",
      "Epoch 3/10, Train Loss: 0.3698, Accuracy: 0.8533, F1 Micro: 0.3301, F1 Macro: 0.1115\n",
      "Epoch 4/10, Train Loss: 0.342, Accuracy: 0.8752, F1 Micro: 0.5055, F1 Macro: 0.2314\n",
      "Epoch 5/10, Train Loss: 0.2975, Accuracy: 0.8808, F1 Micro: 0.6083, F1 Macro: 0.2907\n",
      "Epoch 6/10, Train Loss: 0.2644, Accuracy: 0.8821, F1 Micro: 0.6433, F1 Macro: 0.3437\n",
      "Epoch 7/10, Train Loss: 0.2403, Accuracy: 0.8895, F1 Micro: 0.644, F1 Macro: 0.3656\n",
      "Epoch 8/10, Train Loss: 0.2204, Accuracy: 0.8895, F1 Micro: 0.6192, F1 Macro: 0.3448\n",
      "Epoch 9/10, Train Loss: 0.1877, Accuracy: 0.8912, F1 Micro: 0.663, F1 Macro: 0.3747\n",
      "Epoch 10/10, Train Loss: 0.1624, Accuracy: 0.8965, F1 Micro: 0.669, F1 Macro: 0.4188\n",
      "Best result for 1646 samples: F1 Micro: 0.669\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.77      0.78      1094\n",
      "      Abusive       0.87      0.81      0.84      1072\n",
      "HS_Individual       0.62      0.67      0.65       689\n",
      "     HS_Group       0.77      0.40      0.53       405\n",
      "  HS_Religion       1.00      0.07      0.14       124\n",
      "      HS_Race       0.93      0.21      0.34       125\n",
      "  HS_Physical       0.00      0.00      0.00        61\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.69      0.64      0.67       754\n",
      "      HS_Weak       0.60      0.64      0.62       664\n",
      "  HS_Moderate       0.59      0.23      0.33       346\n",
      "    HS_Strong       0.86      0.07      0.13        84\n",
      "\n",
      "    micro avg       0.73      0.62      0.67      5476\n",
      "    macro avg       0.64      0.38      0.42      5476\n",
      " weighted avg       0.73      0.62      0.64      5476\n",
      "  samples avg       0.39      0.36      0.35      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 889\n",
      "Sampling duration: 47.62254524230957 seconds\n",
      "\n",
      "Fold 2 - New train size: 2535\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 2535 samples...\n",
      "Epoch 1/10, Train Loss: 0.4851, Accuracy: 0.8309, F1 Micro: 0.018, F1 Macro: 0.0073\n",
      "Epoch 2/10, Train Loss: 0.3859, Accuracy: 0.8544, F1 Micro: 0.3402, F1 Macro: 0.1063\n",
      "Epoch 3/10, Train Loss: 0.3371, Accuracy: 0.8771, F1 Micro: 0.5756, F1 Macro: 0.2657\n",
      "Epoch 4/10, Train Loss: 0.3015, Accuracy: 0.8874, F1 Micro: 0.6315, F1 Macro: 0.3256\n",
      "Epoch 5/10, Train Loss: 0.2571, Accuracy: 0.8938, F1 Micro: 0.6694, F1 Macro: 0.4014\n",
      "Epoch 6/10, Train Loss: 0.2262, Accuracy: 0.898, F1 Micro: 0.6907, F1 Macro: 0.4765\n",
      "Epoch 7/10, Train Loss: 0.2011, Accuracy: 0.8992, F1 Micro: 0.6924, F1 Macro: 0.4841\n",
      "Epoch 8/10, Train Loss: 0.175, Accuracy: 0.903, F1 Micro: 0.696, F1 Macro: 0.4857\n",
      "Epoch 9/10, Train Loss: 0.1484, Accuracy: 0.905, F1 Micro: 0.7099, F1 Macro: 0.5217\n",
      "Epoch 10/10, Train Loss: 0.1288, Accuracy: 0.9068, F1 Micro: 0.7053, F1 Macro: 0.5286\n",
      "Best result for 2535 samples: F1 Micro: 0.7099\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.82      0.81      1094\n",
      "      Abusive       0.90      0.82      0.86      1072\n",
      "HS_Individual       0.64      0.72      0.68       689\n",
      "     HS_Group       0.75      0.51      0.61       405\n",
      "  HS_Religion       0.78      0.41      0.54       124\n",
      "      HS_Race       0.86      0.43      0.57       125\n",
      "  HS_Physical       0.00      0.00      0.00        61\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.68      0.74      0.71       754\n",
      "      HS_Weak       0.61      0.69      0.65       664\n",
      "  HS_Moderate       0.61      0.35      0.45       346\n",
      "    HS_Strong       0.88      0.25      0.39        84\n",
      "\n",
      "    micro avg       0.74      0.68      0.71      5476\n",
      "    macro avg       0.63      0.48      0.52      5476\n",
      " weighted avg       0.73      0.68      0.70      5476\n",
      "  samples avg       0.42      0.40      0.39      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 800\n",
      "Sampling duration: 44.039002895355225 seconds\n",
      "\n",
      "Fold 2 - New train size: 3335\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 3335 samples...\n",
      "Epoch 1/10, Train Loss: 0.4657, Accuracy: 0.8336, F1 Micro: 0.0424, F1 Macro: 0.0167\n",
      "Epoch 2/10, Train Loss: 0.3668, Accuracy: 0.8748, F1 Micro: 0.5107, F1 Macro: 0.2227\n",
      "Epoch 3/10, Train Loss: 0.3126, Accuracy: 0.8899, F1 Micro: 0.6355, F1 Macro: 0.3295\n",
      "Epoch 4/10, Train Loss: 0.2599, Accuracy: 0.898, F1 Micro: 0.6835, F1 Macro: 0.4425\n",
      "Epoch 5/10, Train Loss: 0.2225, Accuracy: 0.9012, F1 Micro: 0.6666, F1 Macro: 0.4493\n",
      "Epoch 6/10, Train Loss: 0.1964, Accuracy: 0.9054, F1 Micro: 0.6875, F1 Macro: 0.4875\n",
      "Epoch 7/10, Train Loss: 0.1675, Accuracy: 0.9072, F1 Micro: 0.7066, F1 Macro: 0.5219\n",
      "Epoch 8/10, Train Loss: 0.1378, Accuracy: 0.9101, F1 Micro: 0.7277, F1 Macro: 0.5593\n",
      "Epoch 9/10, Train Loss: 0.1221, Accuracy: 0.9067, F1 Micro: 0.7249, F1 Macro: 0.5504\n",
      "Epoch 10/10, Train Loss: 0.0999, Accuracy: 0.9094, F1 Micro: 0.7301, F1 Macro: 0.5781\n",
      "Best result for 3335 samples: F1 Micro: 0.7301\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.78      0.83      0.80      1094\n",
      "      Abusive       0.90      0.86      0.88      1072\n",
      "HS_Individual       0.68      0.69      0.68       689\n",
      "     HS_Group       0.64      0.63      0.64       405\n",
      "  HS_Religion       0.65      0.60      0.63       124\n",
      "      HS_Race       0.72      0.71      0.72       125\n",
      "  HS_Physical       0.00      0.00      0.00        61\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.72      0.73      0.73       754\n",
      "      HS_Weak       0.67      0.68      0.67       664\n",
      "  HS_Moderate       0.55      0.53      0.54       346\n",
      "    HS_Strong       0.79      0.55      0.65        84\n",
      "\n",
      "    micro avg       0.74      0.72      0.73      5476\n",
      "    macro avg       0.59      0.57      0.58      5476\n",
      " weighted avg       0.72      0.72      0.72      5476\n",
      "  samples avg       0.42      0.41      0.40      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 720\n",
      "Sampling duration: 38.98867630958557 seconds\n",
      "\n",
      "Fold 2 - New train size: 4055\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 4055 samples...\n",
      "Epoch 1/10, Train Loss: 0.4476, Accuracy: 0.8458, F1 Micro: 0.1931, F1 Macro: 0.0694\n",
      "Epoch 2/10, Train Loss: 0.3604, Accuracy: 0.8814, F1 Micro: 0.5739, F1 Macro: 0.2627\n",
      "Epoch 3/10, Train Loss: 0.2982, Accuracy: 0.8928, F1 Micro: 0.6608, F1 Macro: 0.3734\n",
      "Epoch 4/10, Train Loss: 0.2517, Accuracy: 0.9025, F1 Micro: 0.7011, F1 Macro: 0.4851\n",
      "Epoch 5/10, Train Loss: 0.2159, Accuracy: 0.9055, F1 Micro: 0.6821, F1 Macro: 0.4719\n",
      "Epoch 6/10, Train Loss: 0.1789, Accuracy: 0.9082, F1 Micro: 0.7239, F1 Macro: 0.5117\n",
      "Epoch 7/10, Train Loss: 0.1565, Accuracy: 0.9122, F1 Micro: 0.7241, F1 Macro: 0.5391\n",
      "Epoch 8/10, Train Loss: 0.1302, Accuracy: 0.9142, F1 Micro: 0.7396, F1 Macro: 0.5643\n",
      "Epoch 9/10, Train Loss: 0.1116, Accuracy: 0.913, F1 Micro: 0.7429, F1 Macro: 0.5842\n",
      "Epoch 10/10, Train Loss: 0.0978, Accuracy: 0.9117, F1 Micro: 0.7457, F1 Macro: 0.5909\n",
      "Best result for 4055 samples: F1 Micro: 0.7457\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.78      0.88      0.83      1094\n",
      "      Abusive       0.88      0.90      0.89      1072\n",
      "HS_Individual       0.65      0.76      0.70       689\n",
      "     HS_Group       0.69      0.62      0.65       405\n",
      "  HS_Religion       0.68      0.56      0.62       124\n",
      "      HS_Race       0.81      0.68      0.74       125\n",
      "  HS_Physical       0.00      0.00      0.00        61\n",
      "    HS_Gender       1.00      0.02      0.03        58\n",
      "     HS_Other       0.69      0.81      0.74       754\n",
      "      HS_Weak       0.64      0.74      0.68       664\n",
      "  HS_Moderate       0.58      0.50      0.54       346\n",
      "    HS_Strong       0.82      0.56      0.67        84\n",
      "\n",
      "    micro avg       0.73      0.76      0.75      5476\n",
      "    macro avg       0.68      0.59      0.59      5476\n",
      " weighted avg       0.73      0.76      0.74      5476\n",
      "  samples avg       0.44      0.44      0.42      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 648\n",
      "Sampling duration: 35.92328453063965 seconds\n",
      "\n",
      "Fold 2 - New train size: 4703\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 4703 samples...\n",
      "Epoch 1/10, Train Loss: 0.4422, Accuracy: 0.8477, F1 Micro: 0.2235, F1 Macro: 0.074\n",
      "Epoch 2/10, Train Loss: 0.3412, Accuracy: 0.8857, F1 Micro: 0.6109, F1 Macro: 0.294\n",
      "Epoch 3/10, Train Loss: 0.2793, Accuracy: 0.897, F1 Micro: 0.6464, F1 Macro: 0.3849\n",
      "Epoch 4/10, Train Loss: 0.2349, Accuracy: 0.9027, F1 Micro: 0.695, F1 Macro: 0.4462\n",
      "Epoch 5/10, Train Loss: 0.2036, Accuracy: 0.9093, F1 Micro: 0.7275, F1 Macro: 0.5247\n",
      "Epoch 6/10, Train Loss: 0.1738, Accuracy: 0.9116, F1 Micro: 0.7359, F1 Macro: 0.5647\n",
      "Epoch 7/10, Train Loss: 0.1446, Accuracy: 0.9137, F1 Micro: 0.7436, F1 Macro: 0.5736\n",
      "Epoch 8/10, Train Loss: 0.1199, Accuracy: 0.9115, F1 Micro: 0.7419, F1 Macro: 0.5716\n",
      "Epoch 9/10, Train Loss: 0.1085, Accuracy: 0.9133, F1 Micro: 0.7442, F1 Macro: 0.5836\n",
      "Epoch 10/10, Train Loss: 0.0919, Accuracy: 0.9132, F1 Micro: 0.7442, F1 Macro: 0.5955\n",
      "Best result for 4703 samples: F1 Micro: 0.7442\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.86      0.83      1094\n",
      "      Abusive       0.90      0.87      0.88      1072\n",
      "HS_Individual       0.63      0.79      0.70       689\n",
      "     HS_Group       0.76      0.53      0.62       405\n",
      "  HS_Religion       0.74      0.54      0.62       124\n",
      "      HS_Race       0.85      0.64      0.73       125\n",
      "  HS_Physical       0.00      0.00      0.00        61\n",
      "    HS_Gender       0.80      0.07      0.13        58\n",
      "     HS_Other       0.71      0.78      0.74       754\n",
      "      HS_Weak       0.62      0.77      0.69       664\n",
      "  HS_Moderate       0.66      0.44      0.53       346\n",
      "    HS_Strong       0.84      0.56      0.67        84\n",
      "\n",
      "    micro avg       0.74      0.74      0.74      5476\n",
      "    macro avg       0.69      0.57      0.60      5476\n",
      " weighted avg       0.74      0.74      0.73      5476\n",
      "  samples avg       0.43      0.43      0.41      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 584\n",
      "Sampling duration: 31.730116844177246 seconds\n",
      "\n",
      "Fold 2 - New train size: 5287\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 5287 samples...\n",
      "Epoch 1/10, Train Loss: 0.4376, Accuracy: 0.855, F1 Micro: 0.3103, F1 Macro: 0.0992\n",
      "Epoch 2/10, Train Loss: 0.3347, Accuracy: 0.888, F1 Micro: 0.6088, F1 Macro: 0.3129\n",
      "Epoch 3/10, Train Loss: 0.2661, Accuracy: 0.9001, F1 Micro: 0.6973, F1 Macro: 0.4607\n",
      "Epoch 4/10, Train Loss: 0.2228, Accuracy: 0.9021, F1 Micro: 0.6951, F1 Macro: 0.4471\n",
      "Epoch 5/10, Train Loss: 0.1943, Accuracy: 0.9138, F1 Micro: 0.7377, F1 Macro: 0.5831\n",
      "Epoch 6/10, Train Loss: 0.1642, Accuracy: 0.916, F1 Micro: 0.7401, F1 Macro: 0.5638\n",
      "Epoch 7/10, Train Loss: 0.1345, Accuracy: 0.9164, F1 Micro: 0.7419, F1 Macro: 0.5842\n",
      "Epoch 8/10, Train Loss: 0.1135, Accuracy: 0.9162, F1 Micro: 0.7584, F1 Macro: 0.6092\n",
      "Epoch 9/10, Train Loss: 0.0983, Accuracy: 0.9187, F1 Micro: 0.7547, F1 Macro: 0.6244\n",
      "Epoch 10/10, Train Loss: 0.0843, Accuracy: 0.9181, F1 Micro: 0.7547, F1 Macro: 0.6219\n",
      "Best result for 5287 samples: F1 Micro: 0.7584\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.79      0.88      0.83      1094\n",
      "      Abusive       0.90      0.88      0.89      1072\n",
      "HS_Individual       0.65      0.82      0.73       689\n",
      "     HS_Group       0.72      0.61      0.66       405\n",
      "  HS_Religion       0.73      0.56      0.63       124\n",
      "      HS_Race       0.78      0.73      0.75       125\n",
      "  HS_Physical       0.00      0.00      0.00        61\n",
      "    HS_Gender       0.50      0.03      0.06        58\n",
      "     HS_Other       0.71      0.80      0.75       754\n",
      "      HS_Weak       0.64      0.79      0.71       664\n",
      "  HS_Moderate       0.64      0.51      0.57       346\n",
      "    HS_Strong       0.83      0.64      0.72        84\n",
      "\n",
      "    micro avg       0.74      0.77      0.76      5476\n",
      "    macro avg       0.66      0.60      0.61      5476\n",
      " weighted avg       0.74      0.77      0.75      5476\n",
      "  samples avg       0.43      0.44      0.42      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 525\n",
      "Sampling duration: 28.583611488342285 seconds\n",
      "\n",
      "Fold 2 - New train size: 5812\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 5812 samples...\n",
      "Epoch 1/10, Train Loss: 0.4269, Accuracy: 0.8609, F1 Micro: 0.3795, F1 Macro: 0.1267\n",
      "Epoch 2/10, Train Loss: 0.317, Accuracy: 0.8921, F1 Micro: 0.6592, F1 Macro: 0.3337\n",
      "Epoch 3/10, Train Loss: 0.2569, Accuracy: 0.9014, F1 Micro: 0.6662, F1 Macro: 0.4611\n",
      "Epoch 4/10, Train Loss: 0.2159, Accuracy: 0.9099, F1 Micro: 0.733, F1 Macro: 0.5427\n",
      "Epoch 5/10, Train Loss: 0.1874, Accuracy: 0.912, F1 Micro: 0.7087, F1 Macro: 0.5132\n",
      "Epoch 6/10, Train Loss: 0.1553, Accuracy: 0.9162, F1 Micro: 0.734, F1 Macro: 0.5664\n",
      "Epoch 7/10, Train Loss: 0.1297, Accuracy: 0.9177, F1 Micro: 0.7542, F1 Macro: 0.6021\n",
      "Epoch 8/10, Train Loss: 0.1113, Accuracy: 0.9182, F1 Micro: 0.7415, F1 Macro: 0.5966\n",
      "Epoch 9/10, Train Loss: 0.0953, Accuracy: 0.9168, F1 Micro: 0.7522, F1 Macro: 0.6269\n",
      "Epoch 10/10, Train Loss: 0.0826, Accuracy: 0.9178, F1 Micro: 0.757, F1 Macro: 0.618\n",
      "Best result for 5812 samples: F1 Micro: 0.757\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.81      0.85      0.83      1094\n",
      "      Abusive       0.92      0.87      0.89      1072\n",
      "HS_Individual       0.67      0.79      0.72       689\n",
      "     HS_Group       0.73      0.55      0.63       405\n",
      "  HS_Religion       0.78      0.56      0.65       124\n",
      "      HS_Race       0.80      0.63      0.71       125\n",
      "  HS_Physical       0.33      0.02      0.03        61\n",
      "    HS_Gender       0.56      0.09      0.15        58\n",
      "     HS_Other       0.72      0.81      0.76       754\n",
      "      HS_Weak       0.66      0.76      0.71       664\n",
      "  HS_Moderate       0.66      0.46      0.54       346\n",
      "    HS_Strong       0.83      0.76      0.80        84\n",
      "\n",
      "    micro avg       0.76      0.75      0.76      5476\n",
      "    macro avg       0.70      0.60      0.62      5476\n",
      " weighted avg       0.76      0.75      0.75      5476\n",
      "  samples avg       0.44      0.43      0.42      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 473\n",
      "Sampling duration: 25.607298135757446 seconds\n",
      "\n",
      "Fold 2 - New train size: 6285\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 6285 samples...\n",
      "Epoch 1/10, Train Loss: 0.419, Accuracy: 0.8652, F1 Micro: 0.4147, F1 Macro: 0.1498\n",
      "Epoch 2/10, Train Loss: 0.3085, Accuracy: 0.8936, F1 Micro: 0.642, F1 Macro: 0.3547\n",
      "Epoch 3/10, Train Loss: 0.2535, Accuracy: 0.904, F1 Micro: 0.718, F1 Macro: 0.5057\n",
      "Epoch 4/10, Train Loss: 0.2124, Accuracy: 0.9103, F1 Micro: 0.7057, F1 Macro: 0.5054\n",
      "Epoch 5/10, Train Loss: 0.1814, Accuracy: 0.9139, F1 Micro: 0.713, F1 Macro: 0.5298\n",
      "Epoch 6/10, Train Loss: 0.1507, Accuracy: 0.918, F1 Micro: 0.7433, F1 Macro: 0.5858\n",
      "Epoch 7/10, Train Loss: 0.127, Accuracy: 0.9174, F1 Micro: 0.7407, F1 Macro: 0.5929\n",
      "Epoch 8/10, Train Loss: 0.109, Accuracy: 0.9178, F1 Micro: 0.7518, F1 Macro: 0.6025\n",
      "Epoch 9/10, Train Loss: 0.0941, Accuracy: 0.9172, F1 Micro: 0.75, F1 Macro: 0.6175\n",
      "Epoch 10/10, Train Loss: 0.0789, Accuracy: 0.92, F1 Micro: 0.7531, F1 Macro: 0.6165\n",
      "Best result for 6285 samples: F1 Micro: 0.7531\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.81      0.83      1094\n",
      "      Abusive       0.91      0.88      0.89      1072\n",
      "HS_Individual       0.70      0.72      0.71       689\n",
      "     HS_Group       0.78      0.54      0.64       405\n",
      "  HS_Religion       0.76      0.54      0.63       124\n",
      "      HS_Race       0.85      0.58      0.69       125\n",
      "  HS_Physical       0.50      0.02      0.03        61\n",
      "    HS_Gender       0.58      0.12      0.20        58\n",
      "     HS_Other       0.76      0.74      0.75       754\n",
      "      HS_Weak       0.69      0.70      0.70       664\n",
      "  HS_Moderate       0.70      0.45      0.55       346\n",
      "    HS_Strong       0.83      0.74      0.78        84\n",
      "\n",
      "    micro avg       0.79      0.72      0.75      5476\n",
      "    macro avg       0.74      0.57      0.62      5476\n",
      " weighted avg       0.79      0.72      0.74      5476\n",
      "  samples avg       0.44      0.42      0.41      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 299\n",
      "Sampling duration: 23.642791271209717 seconds\n",
      "\n",
      "Fold 2 - New train size: 6584\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 6584 samples...\n",
      "Epoch 1/10, Train Loss: 0.417, Accuracy: 0.8729, F1 Micro: 0.4949, F1 Macro: 0.2103\n",
      "Epoch 2/10, Train Loss: 0.3043, Accuracy: 0.8936, F1 Micro: 0.606, F1 Macro: 0.3601\n",
      "Epoch 3/10, Train Loss: 0.2469, Accuracy: 0.9056, F1 Micro: 0.715, F1 Macro: 0.5273\n",
      "Epoch 4/10, Train Loss: 0.2076, Accuracy: 0.9127, F1 Micro: 0.7156, F1 Macro: 0.5428\n",
      "Epoch 5/10, Train Loss: 0.1755, Accuracy: 0.9156, F1 Micro: 0.729, F1 Macro: 0.5603\n",
      "Epoch 6/10, Train Loss: 0.1506, Accuracy: 0.9181, F1 Micro: 0.7425, F1 Macro: 0.5934\n",
      "Epoch 7/10, Train Loss: 0.1242, Accuracy: 0.9185, F1 Micro: 0.762, F1 Macro: 0.6095\n",
      "Epoch 8/10, Train Loss: 0.1076, Accuracy: 0.9195, F1 Micro: 0.7551, F1 Macro: 0.6073\n",
      "Epoch 9/10, Train Loss: 0.0906, Accuracy: 0.9202, F1 Micro: 0.7495, F1 Macro: 0.638\n",
      "Epoch 10/10, Train Loss: 0.0795, Accuracy: 0.9204, F1 Micro: 0.7574, F1 Macro: 0.6302\n",
      "Best result for 6584 samples: F1 Micro: 0.762\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.88      0.84      1094\n",
      "      Abusive       0.89      0.91      0.90      1072\n",
      "HS_Individual       0.66      0.81      0.72       689\n",
      "     HS_Group       0.76      0.55      0.64       405\n",
      "  HS_Religion       0.70      0.62      0.66       124\n",
      "      HS_Race       0.80      0.67      0.73       125\n",
      "  HS_Physical       0.00      0.00      0.00        61\n",
      "    HS_Gender       0.50      0.03      0.06        58\n",
      "     HS_Other       0.73      0.79      0.76       754\n",
      "      HS_Weak       0.65      0.79      0.71       664\n",
      "  HS_Moderate       0.70      0.42      0.53       346\n",
      "    HS_Strong       0.80      0.73      0.76        84\n",
      "\n",
      "    micro avg       0.76      0.77      0.76      5476\n",
      "    macro avg       0.67      0.60      0.61      5476\n",
      " weighted avg       0.75      0.77      0.75      5476\n",
      "  samples avg       0.45      0.44      0.43      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Acquired samples: 396\n",
      "Sampling duration: 21.586844444274902 seconds\n",
      "\n",
      "Fold 2 - New train size: 6980\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 6980 samples...\n",
      "Epoch 1/10, Train Loss: 0.4135, Accuracy: 0.8738, F1 Micro: 0.4844, F1 Macro: 0.2074\n",
      "Epoch 2/10, Train Loss: 0.2973, Accuracy: 0.8967, F1 Micro: 0.67, F1 Macro: 0.3938\n",
      "Epoch 3/10, Train Loss: 0.2418, Accuracy: 0.9071, F1 Micro: 0.7229, F1 Macro: 0.5455\n",
      "Epoch 4/10, Train Loss: 0.2052, Accuracy: 0.9126, F1 Micro: 0.7382, F1 Macro: 0.5424\n",
      "Epoch 5/10, Train Loss: 0.1711, Accuracy: 0.9128, F1 Micro: 0.7411, F1 Macro: 0.5689\n",
      "Epoch 6/10, Train Loss: 0.1434, Accuracy: 0.9175, F1 Micro: 0.7575, F1 Macro: 0.6018\n",
      "Epoch 7/10, Train Loss: 0.1239, Accuracy: 0.919, F1 Micro: 0.7445, F1 Macro: 0.6038\n",
      "Epoch 8/10, Train Loss: 0.1042, Accuracy: 0.9197, F1 Micro: 0.757, F1 Macro: 0.6213\n",
      "Epoch 9/10, Train Loss: 0.0858, Accuracy: 0.9212, F1 Micro: 0.7619, F1 Macro: 0.6325\n",
      "Epoch 10/10, Train Loss: 0.0783, Accuracy: 0.9202, F1 Micro: 0.7636, F1 Macro: 0.6417\n",
      "Best result for 6980 samples: F1 Micro: 0.7636\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.85      0.83      1094\n",
      "      Abusive       0.89      0.91      0.90      1072\n",
      "HS_Individual       0.69      0.76      0.73       689\n",
      "     HS_Group       0.73      0.60      0.66       405\n",
      "  HS_Religion       0.73      0.61      0.67       124\n",
      "      HS_Race       0.80      0.71      0.75       125\n",
      "  HS_Physical       1.00      0.02      0.03        61\n",
      "    HS_Gender       0.63      0.21      0.31        58\n",
      "     HS_Other       0.74      0.77      0.75       754\n",
      "      HS_Weak       0.68      0.74      0.71       664\n",
      "  HS_Moderate       0.67      0.51      0.57       346\n",
      "    HS_Strong       0.80      0.77      0.79        84\n",
      "\n",
      "    micro avg       0.77      0.76      0.76      5476\n",
      "    macro avg       0.76      0.62      0.64      5476\n",
      " weighted avg       0.77      0.76      0.76      5476\n",
      "  samples avg       0.45      0.44      0.43      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Acquired samples: 356\n",
      "Sampling duration: 19.742921113967896 seconds\n",
      "\n",
      "Fold 2 - New train size: 7336\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 7336 samples...\n",
      "Epoch 1/10, Train Loss: 0.4093, Accuracy: 0.8758, F1 Micro: 0.5043, F1 Macro: 0.2175\n",
      "Epoch 2/10, Train Loss: 0.2923, Accuracy: 0.8995, F1 Micro: 0.6715, F1 Macro: 0.4472\n",
      "Epoch 3/10, Train Loss: 0.237, Accuracy: 0.9068, F1 Micro: 0.7058, F1 Macro: 0.4967\n",
      "Epoch 4/10, Train Loss: 0.1971, Accuracy: 0.9136, F1 Micro: 0.7291, F1 Macro: 0.5636\n",
      "Epoch 5/10, Train Loss: 0.1699, Accuracy: 0.9193, F1 Micro: 0.754, F1 Macro: 0.5974\n",
      "Epoch 6/10, Train Loss: 0.1373, Accuracy: 0.919, F1 Micro: 0.7553, F1 Macro: 0.6108\n",
      "Epoch 7/10, Train Loss: 0.1206, Accuracy: 0.9217, F1 Micro: 0.7654, F1 Macro: 0.6368\n",
      "Epoch 8/10, Train Loss: 0.1004, Accuracy: 0.9213, F1 Micro: 0.758, F1 Macro: 0.6545\n",
      "Epoch 9/10, Train Loss: 0.0871, Accuracy: 0.9209, F1 Micro: 0.7576, F1 Macro: 0.6244\n",
      "Epoch 10/10, Train Loss: 0.0736, Accuracy: 0.921, F1 Micro: 0.7592, F1 Macro: 0.6386\n",
      "Best result for 7336 samples: F1 Micro: 0.7654\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.84      0.83      1094\n",
      "      Abusive       0.92      0.88      0.90      1072\n",
      "HS_Individual       0.70      0.79      0.74       689\n",
      "     HS_Group       0.75      0.57      0.65       405\n",
      "  HS_Religion       0.74      0.59      0.65       124\n",
      "      HS_Race       0.82      0.73      0.77       125\n",
      "  HS_Physical       0.80      0.07      0.12        61\n",
      "    HS_Gender       0.50      0.10      0.17        58\n",
      "     HS_Other       0.75      0.77      0.76       754\n",
      "      HS_Weak       0.67      0.76      0.71       664\n",
      "  HS_Moderate       0.70      0.47      0.56       346\n",
      "    HS_Strong       0.81      0.73      0.77        84\n",
      "\n",
      "    micro avg       0.78      0.75      0.77      5476\n",
      "    macro avg       0.75      0.61      0.64      5476\n",
      " weighted avg       0.78      0.75      0.76      5476\n",
      "  samples avg       0.43      0.43      0.41      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Acquired samples: 320\n",
      "Sampling duration: 17.7557315826416 seconds\n",
      "\n",
      "Fold 2 - New train size: 7656\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 7656 samples...\n",
      "Epoch 1/10, Train Loss: 0.408, Accuracy: 0.8774, F1 Micro: 0.5131, F1 Macro: 0.2322\n",
      "Epoch 2/10, Train Loss: 0.2859, Accuracy: 0.8983, F1 Micro: 0.6912, F1 Macro: 0.4412\n",
      "Epoch 3/10, Train Loss: 0.2392, Accuracy: 0.9091, F1 Micro: 0.7248, F1 Macro: 0.5591\n",
      "Epoch 4/10, Train Loss: 0.2042, Accuracy: 0.9182, F1 Micro: 0.7474, F1 Macro: 0.5948\n",
      "Epoch 5/10, Train Loss: 0.1703, Accuracy: 0.9201, F1 Micro: 0.7577, F1 Macro: 0.6021\n",
      "Epoch 6/10, Train Loss: 0.1412, Accuracy: 0.9181, F1 Micro: 0.7493, F1 Macro: 0.5908\n",
      "Epoch 7/10, Train Loss: 0.1174, Accuracy: 0.9188, F1 Micro: 0.7659, F1 Macro: 0.6175\n",
      "Epoch 8/10, Train Loss: 0.1005, Accuracy: 0.921, F1 Micro: 0.7638, F1 Macro: 0.64\n",
      "Epoch 9/10, Train Loss: 0.0815, Accuracy: 0.922, F1 Micro: 0.7627, F1 Macro: 0.6545\n",
      "Epoch 10/10, Train Loss: 0.0707, Accuracy: 0.9221, F1 Micro: 0.7571, F1 Macro: 0.658\n",
      "Best result for 7656 samples: F1 Micro: 0.7659\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.79      0.89      0.84      1094\n",
      "      Abusive       0.89      0.92      0.90      1072\n",
      "HS_Individual       0.64      0.84      0.73       689\n",
      "     HS_Group       0.77      0.53      0.63       405\n",
      "  HS_Religion       0.70      0.66      0.68       124\n",
      "      HS_Race       0.81      0.70      0.75       125\n",
      "  HS_Physical       0.50      0.02      0.03        61\n",
      "    HS_Gender       0.40      0.03      0.06        58\n",
      "     HS_Other       0.75      0.79      0.77       754\n",
      "      HS_Weak       0.63      0.83      0.71       664\n",
      "  HS_Moderate       0.71      0.43      0.53       346\n",
      "    HS_Strong       0.79      0.74      0.77        84\n",
      "\n",
      "    micro avg       0.75      0.78      0.77      5476\n",
      "    macro avg       0.70      0.62      0.62      5476\n",
      " weighted avg       0.75      0.78      0.75      5476\n",
      "  samples avg       0.45      0.45      0.43      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Acquired samples: 245\n",
      "Sampling duration: 16.06058382987976 seconds\n",
      "\n",
      "Fold 2 - New train size: 7901\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 7901 samples...\n",
      "Epoch 1/10, Train Loss: 0.4049, Accuracy: 0.8794, F1 Micro: 0.5368, F1 Macro: 0.245\n",
      "Epoch 2/10, Train Loss: 0.2827, Accuracy: 0.8989, F1 Micro: 0.6599, F1 Macro: 0.4177\n",
      "Epoch 3/10, Train Loss: 0.2263, Accuracy: 0.9072, F1 Micro: 0.7151, F1 Macro: 0.4883\n",
      "Epoch 4/10, Train Loss: 0.1957, Accuracy: 0.916, F1 Micro: 0.7352, F1 Macro: 0.5718\n",
      "Epoch 5/10, Train Loss: 0.1676, Accuracy: 0.9187, F1 Micro: 0.738, F1 Macro: 0.5799\n",
      "Epoch 6/10, Train Loss: 0.1376, Accuracy: 0.9214, F1 Micro: 0.7583, F1 Macro: 0.6168\n",
      "Epoch 7/10, Train Loss: 0.1144, Accuracy: 0.9222, F1 Micro: 0.7612, F1 Macro: 0.6451\n",
      "Epoch 8/10, Train Loss: 0.0996, Accuracy: 0.9214, F1 Micro: 0.752, F1 Macro: 0.639\n",
      "Epoch 9/10, Train Loss: 0.0832, Accuracy: 0.9209, F1 Micro: 0.7598, F1 Macro: 0.645\n",
      "Epoch 10/10, Train Loss: 0.0714, Accuracy: 0.9201, F1 Micro: 0.7648, F1 Macro: 0.6718\n",
      "Best result for 7901 samples: F1 Micro: 0.7648\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.85      0.84      1094\n",
      "      Abusive       0.88      0.92      0.90      1072\n",
      "HS_Individual       0.69      0.73      0.71       689\n",
      "     HS_Group       0.69      0.65      0.67       405\n",
      "  HS_Religion       0.66      0.69      0.67       124\n",
      "      HS_Race       0.79      0.71      0.75       125\n",
      "  HS_Physical       0.50      0.18      0.27        61\n",
      "    HS_Gender       0.59      0.33      0.42        58\n",
      "     HS_Other       0.78      0.74      0.76       754\n",
      "      HS_Weak       0.68      0.72      0.70       664\n",
      "  HS_Moderate       0.61      0.58      0.60       346\n",
      "    HS_Strong       0.77      0.79      0.78        84\n",
      "\n",
      "    micro avg       0.76      0.76      0.76      5476\n",
      "    macro avg       0.71      0.66      0.67      5476\n",
      " weighted avg       0.76      0.76      0.76      5476\n",
      "  samples avg       0.45      0.44      0.43      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 264\n",
      "Sampling duration: 14.934881925582886 seconds\n",
      "\n",
      "Fold 2 - New train size: 8165\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 8165 samples...\n",
      "Epoch 1/10, Train Loss: 0.3991, Accuracy: 0.8797, F1 Micro: 0.5349, F1 Macro: 0.2455\n",
      "Epoch 2/10, Train Loss: 0.2764, Accuracy: 0.9001, F1 Micro: 0.6699, F1 Macro: 0.4202\n",
      "Epoch 3/10, Train Loss: 0.2338, Accuracy: 0.9095, F1 Micro: 0.7158, F1 Macro: 0.5185\n",
      "Epoch 4/10, Train Loss: 0.1905, Accuracy: 0.9151, F1 Micro: 0.756, F1 Macro: 0.6034\n",
      "Epoch 5/10, Train Loss: 0.1635, Accuracy: 0.9209, F1 Micro: 0.7586, F1 Macro: 0.6058\n",
      "Epoch 6/10, Train Loss: 0.1406, Accuracy: 0.9156, F1 Micro: 0.7633, F1 Macro: 0.6343\n",
      "Epoch 7/10, Train Loss: 0.1128, Accuracy: 0.9198, F1 Micro: 0.7667, F1 Macro: 0.6457\n",
      "Epoch 8/10, Train Loss: 0.0971, Accuracy: 0.9207, F1 Micro: 0.7605, F1 Macro: 0.6272\n",
      "Epoch 9/10, Train Loss: 0.0807, Accuracy: 0.9215, F1 Micro: 0.7702, F1 Macro: 0.6454\n",
      "Epoch 10/10, Train Loss: 0.0729, Accuracy: 0.9213, F1 Micro: 0.7683, F1 Macro: 0.6791\n",
      "Best result for 8165 samples: F1 Micro: 0.7702\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.86      0.84      1094\n",
      "      Abusive       0.90      0.92      0.90      1072\n",
      "HS_Individual       0.70      0.74      0.72       689\n",
      "     HS_Group       0.67      0.65      0.66       405\n",
      "  HS_Religion       0.74      0.63      0.68       124\n",
      "      HS_Race       0.78      0.82      0.80       125\n",
      "  HS_Physical       1.00      0.03      0.06        61\n",
      "    HS_Gender       0.53      0.14      0.22        58\n",
      "     HS_Other       0.75      0.80      0.77       754\n",
      "      HS_Weak       0.70      0.73      0.71       664\n",
      "  HS_Moderate       0.60      0.60      0.60       346\n",
      "    HS_Strong       0.76      0.77      0.77        84\n",
      "\n",
      "    micro avg       0.77      0.77      0.77      5476\n",
      "    macro avg       0.75      0.64      0.65      5476\n",
      " weighted avg       0.77      0.77      0.76      5476\n",
      "  samples avg       0.45      0.45      0.43      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 237\n",
      "Sampling duration: 13.544361352920532 seconds\n",
      "\n",
      "Fold 2 - New train size: 8402\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 8402 samples...\n",
      "Epoch 1/10, Train Loss: 0.3999, Accuracy: 0.8751, F1 Micro: 0.628, F1 Macro: 0.2959\n",
      "Epoch 2/10, Train Loss: 0.2786, Accuracy: 0.9017, F1 Micro: 0.6809, F1 Macro: 0.471\n",
      "Epoch 3/10, Train Loss: 0.2297, Accuracy: 0.9089, F1 Micro: 0.7045, F1 Macro: 0.5065\n",
      "Epoch 4/10, Train Loss: 0.1902, Accuracy: 0.9176, F1 Micro: 0.7547, F1 Macro: 0.5898\n",
      "Epoch 5/10, Train Loss: 0.1578, Accuracy: 0.9187, F1 Micro: 0.7519, F1 Macro: 0.5869\n",
      "Epoch 6/10, Train Loss: 0.1351, Accuracy: 0.9223, F1 Micro: 0.7653, F1 Macro: 0.635\n",
      "Epoch 7/10, Train Loss: 0.1124, Accuracy: 0.9219, F1 Micro: 0.7664, F1 Macro: 0.6359\n",
      "Epoch 8/10, Train Loss: 0.0977, Accuracy: 0.9208, F1 Micro: 0.767, F1 Macro: 0.6604\n",
      "Epoch 9/10, Train Loss: 0.0802, Accuracy: 0.9218, F1 Micro: 0.7569, F1 Macro: 0.6643\n",
      "Epoch 10/10, Train Loss: 0.0696, Accuracy: 0.9228, F1 Micro: 0.769, F1 Macro: 0.676\n",
      "Best result for 8402 samples: F1 Micro: 0.769\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.84      0.84      1094\n",
      "      Abusive       0.91      0.90      0.90      1072\n",
      "HS_Individual       0.68      0.78      0.73       689\n",
      "     HS_Group       0.74      0.54      0.62       405\n",
      "  HS_Religion       0.75      0.62      0.68       124\n",
      "      HS_Race       0.81      0.77      0.79       125\n",
      "  HS_Physical       0.48      0.21      0.30        61\n",
      "    HS_Gender       0.61      0.29      0.40        58\n",
      "     HS_Other       0.78      0.75      0.76       754\n",
      "      HS_Weak       0.68      0.77      0.72       664\n",
      "  HS_Moderate       0.68      0.47      0.56       346\n",
      "    HS_Strong       0.80      0.83      0.81        84\n",
      "\n",
      "    micro avg       0.78      0.76      0.77      5476\n",
      "    macro avg       0.73      0.65      0.68      5476\n",
      " weighted avg       0.78      0.76      0.76      5476\n",
      "  samples avg       0.45      0.44      0.42      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 214\n",
      "Sampling duration: 12.32582139968872 seconds\n",
      "\n",
      "Fold 2 - New train size: 8616\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 8616 samples...\n",
      "Epoch 1/10, Train Loss: 0.3999, Accuracy: 0.881, F1 Micro: 0.5462, F1 Macro: 0.2566\n",
      "Epoch 2/10, Train Loss: 0.2766, Accuracy: 0.9035, F1 Micro: 0.7013, F1 Macro: 0.4718\n",
      "Epoch 3/10, Train Loss: 0.2313, Accuracy: 0.9127, F1 Micro: 0.7358, F1 Macro: 0.56\n",
      "Epoch 4/10, Train Loss: 0.1906, Accuracy: 0.918, F1 Micro: 0.75, F1 Macro: 0.5856\n",
      "Epoch 5/10, Train Loss: 0.1575, Accuracy: 0.9209, F1 Micro: 0.7621, F1 Macro: 0.627\n",
      "Epoch 6/10, Train Loss: 0.1309, Accuracy: 0.9207, F1 Micro: 0.7528, F1 Macro: 0.6283\n",
      "Epoch 7/10, Train Loss: 0.1102, Accuracy: 0.9215, F1 Micro: 0.7607, F1 Macro: 0.6606\n",
      "Epoch 8/10, Train Loss: 0.0939, Accuracy: 0.9189, F1 Micro: 0.7664, F1 Macro: 0.6412\n",
      "Epoch 9/10, Train Loss: 0.0784, Accuracy: 0.9211, F1 Micro: 0.7585, F1 Macro: 0.6613\n",
      "Epoch 10/10, Train Loss: 0.0684, Accuracy: 0.9204, F1 Micro: 0.7634, F1 Macro: 0.6583\n",
      "Best result for 8616 samples: F1 Micro: 0.7664\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.89      0.84      1094\n",
      "      Abusive       0.90      0.90      0.90      1072\n",
      "HS_Individual       0.66      0.77      0.71       689\n",
      "     HS_Group       0.68      0.63      0.65       405\n",
      "  HS_Religion       0.71      0.64      0.67       124\n",
      "      HS_Race       0.82      0.74      0.78       125\n",
      "  HS_Physical       1.00      0.05      0.09        61\n",
      "    HS_Gender       0.54      0.12      0.20        58\n",
      "     HS_Other       0.72      0.85      0.78       754\n",
      "      HS_Weak       0.66      0.75      0.71       664\n",
      "  HS_Moderate       0.61      0.53      0.57       346\n",
      "    HS_Strong       0.77      0.82      0.79        84\n",
      "\n",
      "    micro avg       0.75      0.78      0.77      5476\n",
      "    macro avg       0.74      0.64      0.64      5476\n",
      " weighted avg       0.75      0.78      0.76      5476\n",
      "  samples avg       0.44      0.45      0.43      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 200\n",
      "Sampling duration: 11.252970933914185 seconds\n",
      "\n",
      "Fold 2 - New train size: 8816\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 8816 samples...\n",
      "Epoch 1/10, Train Loss: 0.3971, Accuracy: 0.8854, F1 Micro: 0.5994, F1 Macro: 0.2921\n",
      "Epoch 2/10, Train Loss: 0.2767, Accuracy: 0.904, F1 Micro: 0.6895, F1 Macro: 0.481\n",
      "Epoch 3/10, Train Loss: 0.226, Accuracy: 0.9127, F1 Micro: 0.7335, F1 Macro: 0.5602\n",
      "Epoch 4/10, Train Loss: 0.1879, Accuracy: 0.9183, F1 Micro: 0.7555, F1 Macro: 0.5828\n",
      "Epoch 5/10, Train Loss: 0.1542, Accuracy: 0.9198, F1 Micro: 0.7512, F1 Macro: 0.5987\n",
      "Epoch 6/10, Train Loss: 0.1314, Accuracy: 0.9205, F1 Micro: 0.7617, F1 Macro: 0.627\n",
      "Epoch 7/10, Train Loss: 0.116, Accuracy: 0.9195, F1 Micro: 0.7432, F1 Macro: 0.6236\n",
      "Epoch 8/10, Train Loss: 0.0928, Accuracy: 0.9209, F1 Micro: 0.76, F1 Macro: 0.6602\n",
      "Epoch 9/10, Train Loss: 0.0821, Accuracy: 0.9213, F1 Micro: 0.7676, F1 Macro: 0.674\n",
      "Epoch 10/10, Train Loss: 0.0659, Accuracy: 0.9221, F1 Micro: 0.7667, F1 Macro: 0.6757\n",
      "Best result for 8816 samples: F1 Micro: 0.7676\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.84      0.83      1094\n",
      "      Abusive       0.90      0.91      0.91      1072\n",
      "HS_Individual       0.68      0.77      0.72       689\n",
      "     HS_Group       0.74      0.57      0.65       405\n",
      "  HS_Religion       0.72      0.69      0.71       124\n",
      "      HS_Race       0.82      0.77      0.79       125\n",
      "  HS_Physical       0.59      0.16      0.26        61\n",
      "    HS_Gender       0.73      0.28      0.40        58\n",
      "     HS_Other       0.77      0.77      0.77       754\n",
      "      HS_Weak       0.66      0.77      0.71       664\n",
      "  HS_Moderate       0.65      0.50      0.56       346\n",
      "    HS_Strong       0.81      0.76      0.79        84\n",
      "\n",
      "    micro avg       0.77      0.77      0.77      5476\n",
      "    macro avg       0.74      0.65      0.67      5476\n",
      " weighted avg       0.77      0.77      0.76      5476\n",
      "  samples avg       0.45      0.44      0.43      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 200\n",
      "Sampling duration: 10.265753030776978 seconds\n",
      "\n",
      "Fold 2 - New train size: 9016\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 9016 samples...\n",
      "Epoch 1/10, Train Loss: 0.3935, Accuracy: 0.884, F1 Micro: 0.5688, F1 Macro: 0.2656\n",
      "Epoch 2/10, Train Loss: 0.2704, Accuracy: 0.9033, F1 Micro: 0.7138, F1 Macro: 0.5118\n",
      "Epoch 3/10, Train Loss: 0.2198, Accuracy: 0.9103, F1 Micro: 0.6936, F1 Macro: 0.5297\n",
      "Epoch 4/10, Train Loss: 0.1837, Accuracy: 0.918, F1 Micro: 0.7432, F1 Macro: 0.5702\n",
      "Epoch 5/10, Train Loss: 0.1542, Accuracy: 0.9224, F1 Micro: 0.7695, F1 Macro: 0.628\n",
      "Epoch 6/10, Train Loss: 0.1308, Accuracy: 0.9209, F1 Micro: 0.7569, F1 Macro: 0.6243\n",
      "Epoch 7/10, Train Loss: 0.1083, Accuracy: 0.9222, F1 Micro: 0.7675, F1 Macro: 0.6535\n",
      "Epoch 8/10, Train Loss: 0.093, Accuracy: 0.9215, F1 Micro: 0.7595, F1 Macro: 0.6676\n",
      "Epoch 9/10, Train Loss: 0.0801, Accuracy: 0.9214, F1 Micro: 0.7638, F1 Macro: 0.6632\n",
      "Epoch 10/10, Train Loss: 0.0675, Accuracy: 0.9208, F1 Micro: 0.7743, F1 Macro: 0.6774\n",
      "Best result for 9016 samples: F1 Micro: 0.7743\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.89      0.84      1094\n",
      "      Abusive       0.88      0.93      0.90      1072\n",
      "HS_Individual       0.65      0.83      0.73       689\n",
      "     HS_Group       0.74      0.59      0.65       405\n",
      "  HS_Religion       0.75      0.60      0.66       124\n",
      "      HS_Race       0.81      0.74      0.78       125\n",
      "  HS_Physical       0.65      0.18      0.28        61\n",
      "    HS_Gender       0.63      0.33      0.43        58\n",
      "     HS_Other       0.75      0.83      0.79       754\n",
      "      HS_Weak       0.64      0.82      0.72       664\n",
      "  HS_Moderate       0.66      0.51      0.57       346\n",
      "    HS_Strong       0.80      0.75      0.77        84\n",
      "\n",
      "    micro avg       0.75      0.80      0.77      5476\n",
      "    macro avg       0.73      0.67      0.68      5476\n",
      " weighted avg       0.75      0.80      0.77      5476\n",
      "  samples avg       0.45      0.46      0.44      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 200\n",
      "Sampling duration: 9.143345355987549 seconds\n",
      "\n",
      "Fold 2 - New train size: 9216\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 9216 samples...\n",
      "Epoch 1/10, Train Loss: 0.3901, Accuracy: 0.8881, F1 Micro: 0.6223, F1 Macro: 0.3106\n",
      "Epoch 2/10, Train Loss: 0.2743, Accuracy: 0.9052, F1 Micro: 0.7085, F1 Macro: 0.4858\n",
      "Epoch 3/10, Train Loss: 0.2211, Accuracy: 0.9154, F1 Micro: 0.7306, F1 Macro: 0.5552\n",
      "Epoch 4/10, Train Loss: 0.1874, Accuracy: 0.9185, F1 Micro: 0.7502, F1 Macro: 0.59\n",
      "Epoch 5/10, Train Loss: 0.1548, Accuracy: 0.9218, F1 Micro: 0.7678, F1 Macro: 0.6074\n",
      "Epoch 6/10, Train Loss: 0.1319, Accuracy: 0.9219, F1 Micro: 0.7718, F1 Macro: 0.6469\n",
      "Epoch 7/10, Train Loss: 0.1086, Accuracy: 0.9207, F1 Micro: 0.7694, F1 Macro: 0.6707\n",
      "Epoch 8/10, Train Loss: 0.0915, Accuracy: 0.9213, F1 Micro: 0.7652, F1 Macro: 0.668\n",
      "Epoch 9/10, Train Loss: 0.0789, Accuracy: 0.9214, F1 Micro: 0.7615, F1 Macro: 0.669\n",
      "Epoch 10/10, Train Loss: 0.0679, Accuracy: 0.9217, F1 Micro: 0.766, F1 Macro: 0.6877\n",
      "Best result for 9216 samples: F1 Micro: 0.7718\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.81      0.88      0.84      1094\n",
      "      Abusive       0.88      0.92      0.90      1072\n",
      "HS_Individual       0.70      0.75      0.73       689\n",
      "     HS_Group       0.71      0.64      0.67       405\n",
      "  HS_Religion       0.69      0.68      0.69       124\n",
      "      HS_Race       0.83      0.72      0.77       125\n",
      "  HS_Physical       0.67      0.07      0.12        61\n",
      "    HS_Gender       0.50      0.10      0.17        58\n",
      "     HS_Other       0.73      0.81      0.77       754\n",
      "      HS_Weak       0.70      0.73      0.71       664\n",
      "  HS_Moderate       0.66      0.54      0.59       346\n",
      "    HS_Strong       0.83      0.77      0.80        84\n",
      "\n",
      "    micro avg       0.77      0.78      0.77      5476\n",
      "    macro avg       0.73      0.63      0.65      5476\n",
      " weighted avg       0.76      0.78      0.76      5476\n",
      "  samples avg       0.46      0.45      0.44      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 2\n",
      "Sampling duration: 8.095818758010864 seconds\n",
      "\n",
      "Fold 2 - New train size: 9218\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 9218 samples...\n",
      "Epoch 1/10, Train Loss: 0.3879, Accuracy: 0.8847, F1 Micro: 0.5769, F1 Macro: 0.2899\n",
      "Epoch 2/10, Train Loss: 0.2672, Accuracy: 0.9014, F1 Micro: 0.6467, F1 Macro: 0.4258\n",
      "Epoch 3/10, Train Loss: 0.2169, Accuracy: 0.916, F1 Micro: 0.7452, F1 Macro: 0.5718\n",
      "Epoch 4/10, Train Loss: 0.1838, Accuracy: 0.9213, F1 Micro: 0.7576, F1 Macro: 0.6054\n",
      "Epoch 5/10, Train Loss: 0.1479, Accuracy: 0.9214, F1 Micro: 0.7681, F1 Macro: 0.631\n",
      "Epoch 6/10, Train Loss: 0.1293, Accuracy: 0.9205, F1 Micro: 0.7711, F1 Macro: 0.6419\n",
      "Epoch 7/10, Train Loss: 0.1066, Accuracy: 0.917, F1 Micro: 0.7605, F1 Macro: 0.6603\n",
      "Epoch 8/10, Train Loss: 0.0903, Accuracy: 0.9209, F1 Micro: 0.7673, F1 Macro: 0.6683\n",
      "Epoch 9/10, Train Loss: 0.0765, Accuracy: 0.9219, F1 Micro: 0.7691, F1 Macro: 0.6704\n",
      "Epoch 10/10, Train Loss: 0.0649, Accuracy: 0.9203, F1 Micro: 0.7719, F1 Macro: 0.6941\n",
      "Best result for 9218 samples: F1 Micro: 0.7719\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.89      0.84      1094\n",
      "      Abusive       0.89      0.92      0.90      1072\n",
      "HS_Individual       0.68      0.76      0.72       689\n",
      "     HS_Group       0.66      0.68      0.67       405\n",
      "  HS_Religion       0.71      0.72      0.71       124\n",
      "      HS_Race       0.79      0.79      0.79       125\n",
      "  HS_Physical       0.52      0.23      0.32        61\n",
      "    HS_Gender       0.70      0.40      0.51        58\n",
      "     HS_Other       0.74      0.80      0.77       754\n",
      "      HS_Weak       0.67      0.74      0.70       664\n",
      "  HS_Moderate       0.59      0.61      0.60       346\n",
      "    HS_Strong       0.80      0.79      0.79        84\n",
      "\n",
      "    micro avg       0.75      0.79      0.77      5476\n",
      "    macro avg       0.71      0.69      0.69      5476\n",
      " weighted avg       0.75      0.79      0.77      5476\n",
      "  samples avg       0.45      0.46      0.44      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Acquired samples: 200\n",
      "Sampling duration: 8.039808750152588 seconds\n",
      "\n",
      "Fold 2 - New train size: 9418\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 9418 samples...\n",
      "Epoch 1/10, Train Loss: 0.3903, Accuracy: 0.8861, F1 Micro: 0.6423, F1 Macro: 0.3381\n",
      "Epoch 2/10, Train Loss: 0.2634, Accuracy: 0.9027, F1 Micro: 0.6691, F1 Macro: 0.4301\n",
      "Epoch 3/10, Train Loss: 0.2207, Accuracy: 0.9139, F1 Micro: 0.7475, F1 Macro: 0.5613\n",
      "Epoch 4/10, Train Loss: 0.1854, Accuracy: 0.9204, F1 Micro: 0.746, F1 Macro: 0.5884\n",
      "Epoch 5/10, Train Loss: 0.153, Accuracy: 0.9222, F1 Micro: 0.7603, F1 Macro: 0.6023\n",
      "Epoch 6/10, Train Loss: 0.1266, Accuracy: 0.9216, F1 Micro: 0.7602, F1 Macro: 0.6328\n",
      "Epoch 7/10, Train Loss: 0.1079, Accuracy: 0.9247, F1 Micro: 0.775, F1 Macro: 0.6581\n",
      "Epoch 8/10, Train Loss: 0.0888, Accuracy: 0.9224, F1 Micro: 0.7667, F1 Macro: 0.6594\n",
      "Epoch 9/10, Train Loss: 0.0781, Accuracy: 0.9216, F1 Micro: 0.7552, F1 Macro: 0.657\n",
      "Epoch 10/10, Train Loss: 0.0673, Accuracy: 0.9223, F1 Micro: 0.7682, F1 Macro: 0.672\n",
      "Best result for 9418 samples: F1 Micro: 0.775\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.86      0.85      1094\n",
      "      Abusive       0.92      0.88      0.90      1072\n",
      "HS_Individual       0.70      0.78      0.74       689\n",
      "     HS_Group       0.74      0.59      0.66       405\n",
      "  HS_Religion       0.71      0.71      0.71       124\n",
      "      HS_Race       0.88      0.64      0.74       125\n",
      "  HS_Physical       0.86      0.10      0.18        61\n",
      "    HS_Gender       0.60      0.16      0.25        58\n",
      "     HS_Other       0.77      0.78      0.77       754\n",
      "      HS_Weak       0.69      0.76      0.73       664\n",
      "  HS_Moderate       0.69      0.52      0.59       346\n",
      "    HS_Strong       0.80      0.77      0.79        84\n",
      "\n",
      "    micro avg       0.79      0.76      0.78      5476\n",
      "    macro avg       0.77      0.63      0.66      5476\n",
      " weighted avg       0.79      0.76      0.77      5476\n",
      "  samples avg       0.45      0.44      0.43      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Acquired samples: 200\n",
      "Sampling duration: 7.146216869354248 seconds\n",
      "\n",
      "Fold 2 - New train size: 9618\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 9618 samples...\n",
      "Epoch 1/10, Train Loss: 0.3845, Accuracy: 0.8867, F1 Micro: 0.616, F1 Macro: 0.3091\n",
      "Epoch 2/10, Train Loss: 0.2653, Accuracy: 0.9059, F1 Micro: 0.6855, F1 Macro: 0.47\n",
      "Epoch 3/10, Train Loss: 0.2116, Accuracy: 0.916, F1 Micro: 0.7397, F1 Macro: 0.5609\n",
      "Epoch 4/10, Train Loss: 0.1788, Accuracy: 0.9198, F1 Micro: 0.7606, F1 Macro: 0.6082\n",
      "Epoch 5/10, Train Loss: 0.1511, Accuracy: 0.9223, F1 Micro: 0.7717, F1 Macro: 0.6257\n",
      "Epoch 6/10, Train Loss: 0.1313, Accuracy: 0.9233, F1 Micro: 0.7723, F1 Macro: 0.6569\n",
      "Epoch 7/10, Train Loss: 0.1059, Accuracy: 0.9226, F1 Micro: 0.7589, F1 Macro: 0.6544\n",
      "Epoch 8/10, Train Loss: 0.0876, Accuracy: 0.9213, F1 Micro: 0.767, F1 Macro: 0.6849\n",
      "Epoch 9/10, Train Loss: 0.0745, Accuracy: 0.924, F1 Micro: 0.7724, F1 Macro: 0.681\n",
      "Epoch 10/10, Train Loss: 0.0648, Accuracy: 0.9228, F1 Micro: 0.7683, F1 Macro: 0.6946\n",
      "Best result for 9618 samples: F1 Micro: 0.7724\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.84      0.84      1094\n",
      "      Abusive       0.90      0.91      0.91      1072\n",
      "HS_Individual       0.70      0.75      0.73       689\n",
      "     HS_Group       0.73      0.60      0.66       405\n",
      "  HS_Religion       0.76      0.64      0.69       124\n",
      "      HS_Race       0.81      0.67      0.73       125\n",
      "  HS_Physical       0.65      0.21      0.32        61\n",
      "    HS_Gender       0.69      0.34      0.46        58\n",
      "     HS_Other       0.78      0.76      0.77       754\n",
      "      HS_Weak       0.69      0.75      0.72       664\n",
      "  HS_Moderate       0.66      0.53      0.59       346\n",
      "    HS_Strong       0.82      0.70      0.76        84\n",
      "\n",
      "    micro avg       0.79      0.76      0.77      5476\n",
      "    macro avg       0.75      0.64      0.68      5476\n",
      " weighted avg       0.78      0.76      0.77      5476\n",
      "  samples avg       0.44      0.44      0.42      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Acquired samples: 200\n",
      "Sampling duration: 6.136490821838379 seconds\n",
      "\n",
      "Fold 2 - New train size: 9818\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 9818 samples...\n",
      "Epoch 1/10, Train Loss: 0.3839, Accuracy: 0.8849, F1 Micro: 0.5658, F1 Macro: 0.2762\n",
      "Epoch 2/10, Train Loss: 0.261, Accuracy: 0.8967, F1 Micro: 0.6185, F1 Macro: 0.4388\n",
      "Epoch 3/10, Train Loss: 0.2139, Accuracy: 0.9156, F1 Micro: 0.749, F1 Macro: 0.5825\n",
      "Epoch 4/10, Train Loss: 0.1786, Accuracy: 0.9172, F1 Micro: 0.7572, F1 Macro: 0.604\n",
      "Epoch 5/10, Train Loss: 0.1546, Accuracy: 0.9201, F1 Micro: 0.76, F1 Macro: 0.6311\n",
      "Epoch 6/10, Train Loss: 0.1248, Accuracy: 0.9209, F1 Micro: 0.7601, F1 Macro: 0.6484\n",
      "Epoch 7/10, Train Loss: 0.1039, Accuracy: 0.9222, F1 Micro: 0.7622, F1 Macro: 0.6543\n",
      "Epoch 8/10, Train Loss: 0.0881, Accuracy: 0.9217, F1 Micro: 0.7746, F1 Macro: 0.6766\n",
      "Epoch 9/10, Train Loss: 0.0771, Accuracy: 0.9207, F1 Micro: 0.7635, F1 Macro: 0.6851\n",
      "Epoch 10/10, Train Loss: 0.0648, Accuracy: 0.9227, F1 Micro: 0.7664, F1 Macro: 0.6992\n",
      "Best result for 9818 samples: F1 Micro: 0.7746\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.88      0.84      1094\n",
      "      Abusive       0.89      0.91      0.90      1072\n",
      "HS_Individual       0.67      0.81      0.74       689\n",
      "     HS_Group       0.72      0.62      0.67       405\n",
      "  HS_Religion       0.73      0.66      0.69       124\n",
      "      HS_Race       0.78      0.77      0.77       125\n",
      "  HS_Physical       0.53      0.15      0.23        61\n",
      "    HS_Gender       0.64      0.31      0.42        58\n",
      "     HS_Other       0.75      0.80      0.77       754\n",
      "      HS_Weak       0.67      0.79      0.72       664\n",
      "  HS_Moderate       0.63      0.54      0.58       346\n",
      "    HS_Strong       0.78      0.77      0.78        84\n",
      "\n",
      "    micro avg       0.76      0.79      0.77      5476\n",
      "    macro avg       0.72      0.67      0.68      5476\n",
      " weighted avg       0.76      0.79      0.77      5476\n",
      "  samples avg       0.45      0.45      0.43      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.123552083969116 seconds\n",
      "\n",
      "Fold 2 - New train size: 10018\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 10018 samples...\n",
      "Epoch 1/10, Train Loss: 0.3831, Accuracy: 0.8899, F1 Micro: 0.6235, F1 Macro: 0.315\n",
      "Epoch 2/10, Train Loss: 0.2583, Accuracy: 0.908, F1 Micro: 0.6945, F1 Macro: 0.5109\n",
      "Epoch 3/10, Train Loss: 0.2081, Accuracy: 0.918, F1 Micro: 0.75, F1 Macro: 0.5916\n",
      "Epoch 4/10, Train Loss: 0.1755, Accuracy: 0.9205, F1 Micro: 0.7558, F1 Macro: 0.6101\n",
      "Epoch 5/10, Train Loss: 0.1499, Accuracy: 0.9173, F1 Micro: 0.7698, F1 Macro: 0.6508\n",
      "Epoch 6/10, Train Loss: 0.125, Accuracy: 0.922, F1 Micro: 0.7696, F1 Macro: 0.6587\n",
      "Epoch 7/10, Train Loss: 0.1014, Accuracy: 0.9209, F1 Micro: 0.7507, F1 Macro: 0.6399\n",
      "Epoch 8/10, Train Loss: 0.0856, Accuracy: 0.9231, F1 Micro: 0.7655, F1 Macro: 0.6716\n",
      "Epoch 9/10, Train Loss: 0.074, Accuracy: 0.9213, F1 Micro: 0.7674, F1 Macro: 0.6792\n",
      "Epoch 10/10, Train Loss: 0.0625, Accuracy: 0.9203, F1 Micro: 0.7689, F1 Macro: 0.6749\n",
      "Best result for 10018 samples: F1 Micro: 0.7698\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.76      0.93      0.83      1094\n",
      "      Abusive       0.88      0.91      0.90      1072\n",
      "HS_Individual       0.67      0.79      0.73       689\n",
      "     HS_Group       0.66      0.72      0.69       405\n",
      "  HS_Religion       0.57      0.84      0.68       124\n",
      "      HS_Race       0.79      0.78      0.79       125\n",
      "  HS_Physical       1.00      0.08      0.15        61\n",
      "    HS_Gender       0.55      0.10      0.17        58\n",
      "     HS_Other       0.72      0.84      0.77       754\n",
      "      HS_Weak       0.67      0.76      0.71       664\n",
      "  HS_Moderate       0.58      0.64      0.61       346\n",
      "    HS_Strong       0.78      0.77      0.78        84\n",
      "\n",
      "    micro avg       0.73      0.82      0.77      5476\n",
      "    macro avg       0.72      0.68      0.65      5476\n",
      " weighted avg       0.73      0.82      0.76      5476\n",
      "  samples avg       0.45      0.46      0.44      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Acquired samples: 200\n",
      "Sampling duration: 3.969991445541382 seconds\n",
      "\n",
      "Fold 2 - New train size: 10218\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 10218 samples...\n",
      "Epoch 1/10, Train Loss: 0.3822, Accuracy: 0.8901, F1 Micro: 0.637, F1 Macro: 0.3314\n",
      "Epoch 2/10, Train Loss: 0.2586, Accuracy: 0.9068, F1 Micro: 0.6973, F1 Macro: 0.4627\n",
      "Epoch 3/10, Train Loss: 0.206, Accuracy: 0.9167, F1 Micro: 0.7353, F1 Macro: 0.5748\n",
      "Epoch 4/10, Train Loss: 0.1764, Accuracy: 0.9219, F1 Micro: 0.7592, F1 Macro: 0.6031\n",
      "Epoch 5/10, Train Loss: 0.1443, Accuracy: 0.9232, F1 Micro: 0.7681, F1 Macro: 0.6432\n",
      "Epoch 6/10, Train Loss: 0.1131, Accuracy: 0.9247, F1 Micro: 0.7702, F1 Macro: 0.6588\n",
      "Epoch 7/10, Train Loss: 0.1018, Accuracy: 0.9222, F1 Micro: 0.7738, F1 Macro: 0.6773\n",
      "Epoch 8/10, Train Loss: 0.0864, Accuracy: 0.9228, F1 Micro: 0.773, F1 Macro: 0.6741\n",
      "Epoch 9/10, Train Loss: 0.0742, Accuracy: 0.925, F1 Micro: 0.7734, F1 Macro: 0.7027\n",
      "Epoch 10/10, Train Loss: 0.0622, Accuracy: 0.9249, F1 Micro: 0.7722, F1 Macro: 0.6863\n",
      "Best result for 10218 samples: F1 Micro: 0.7738\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.81      0.88      0.84      1094\n",
      "      Abusive       0.91      0.89      0.90      1072\n",
      "HS_Individual       0.67      0.78      0.72       689\n",
      "     HS_Group       0.74      0.62      0.68       405\n",
      "  HS_Religion       0.67      0.73      0.70       124\n",
      "      HS_Race       0.76      0.82      0.79       125\n",
      "  HS_Physical       0.67      0.13      0.22        61\n",
      "    HS_Gender       0.70      0.28      0.40        58\n",
      "     HS_Other       0.76      0.79      0.78       754\n",
      "      HS_Weak       0.66      0.77      0.71       664\n",
      "  HS_Moderate       0.67      0.55      0.61       346\n",
      "    HS_Strong       0.80      0.77      0.79        84\n",
      "\n",
      "    micro avg       0.76      0.78      0.77      5476\n",
      "    macro avg       0.73      0.67      0.68      5476\n",
      " weighted avg       0.77      0.78      0.77      5476\n",
      "  samples avg       0.46      0.45      0.44      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.798184871673584 seconds\n",
      "\n",
      "Fold 2 - New train size: 10418\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 10418 samples...\n",
      "Epoch 1/10, Train Loss: 0.3715, Accuracy: 0.8904, F1 Micro: 0.6247, F1 Macro: 0.3286\n",
      "Epoch 2/10, Train Loss: 0.2488, Accuracy: 0.9079, F1 Micro: 0.7087, F1 Macro: 0.5093\n",
      "Epoch 3/10, Train Loss: 0.1997, Accuracy: 0.9134, F1 Micro: 0.7208, F1 Macro: 0.5333\n",
      "Epoch 4/10, Train Loss: 0.1695, Accuracy: 0.9218, F1 Micro: 0.7602, F1 Macro: 0.6065\n",
      "Epoch 5/10, Train Loss: 0.1399, Accuracy: 0.9223, F1 Micro: 0.7626, F1 Macro: 0.6366\n",
      "Epoch 6/10, Train Loss: 0.1154, Accuracy: 0.9229, F1 Micro: 0.7714, F1 Macro: 0.6636\n",
      "Epoch 7/10, Train Loss: 0.0975, Accuracy: 0.9223, F1 Micro: 0.7548, F1 Macro: 0.6699\n",
      "Epoch 8/10, Train Loss: 0.083, Accuracy: 0.9244, F1 Micro: 0.7783, F1 Macro: 0.6834\n",
      "Epoch 9/10, Train Loss: 0.0718, Accuracy: 0.9245, F1 Micro: 0.7733, F1 Macro: 0.6858\n",
      "Epoch 10/10, Train Loss: 0.0603, Accuracy: 0.9262, F1 Micro: 0.7836, F1 Macro: 0.717\n",
      "Best result for 10418 samples: F1 Micro: 0.7836\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.88      0.85      1094\n",
      "      Abusive       0.90      0.90      0.90      1072\n",
      "HS_Individual       0.73      0.74      0.74       689\n",
      "     HS_Group       0.68      0.71      0.69       405\n",
      "  HS_Religion       0.72      0.69      0.70       124\n",
      "      HS_Race       0.79      0.79      0.79       125\n",
      "  HS_Physical       0.83      0.25      0.38        61\n",
      "    HS_Gender       0.71      0.55      0.62        58\n",
      "     HS_Other       0.78      0.79      0.79       754\n",
      "      HS_Weak       0.72      0.72      0.72       664\n",
      "  HS_Moderate       0.62      0.63      0.63       346\n",
      "    HS_Strong       0.78      0.83      0.80        84\n",
      "\n",
      "    micro avg       0.78      0.79      0.78      5476\n",
      "    macro avg       0.76      0.71      0.72      5476\n",
      " weighted avg       0.78      0.79      0.78      5476\n",
      "  samples avg       0.45      0.45      0.43      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Acquired samples: 117\n",
      "Sampling duration: 1.4970300197601318 seconds\n",
      "\n",
      "Fold 2 - New train size: 10535\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 10535 samples...\n",
      "Epoch 1/10, Train Loss: 0.3728, Accuracy: 0.8925, F1 Micro: 0.6317, F1 Macro: 0.341\n",
      "Epoch 2/10, Train Loss: 0.248, Accuracy: 0.9085, F1 Micro: 0.7138, F1 Macro: 0.5181\n",
      "Epoch 3/10, Train Loss: 0.1968, Accuracy: 0.9164, F1 Micro: 0.7493, F1 Macro: 0.5994\n",
      "Epoch 4/10, Train Loss: 0.1681, Accuracy: 0.9227, F1 Micro: 0.7664, F1 Macro: 0.6151\n",
      "Epoch 5/10, Train Loss: 0.1384, Accuracy: 0.9241, F1 Micro: 0.766, F1 Macro: 0.6278\n",
      "Epoch 6/10, Train Loss: 0.1151, Accuracy: 0.9236, F1 Micro: 0.7739, F1 Macro: 0.671\n",
      "Epoch 7/10, Train Loss: 0.0964, Accuracy: 0.9224, F1 Micro: 0.7717, F1 Macro: 0.6895\n",
      "Epoch 8/10, Train Loss: 0.0835, Accuracy: 0.9243, F1 Micro: 0.7706, F1 Macro: 0.6884\n",
      "Epoch 9/10, Train Loss: 0.0707, Accuracy: 0.9248, F1 Micro: 0.7796, F1 Macro: 0.6948\n",
      "Epoch 10/10, Train Loss: 0.0616, Accuracy: 0.9237, F1 Micro: 0.771, F1 Macro: 0.6971\n",
      "Best result for 10535 samples: F1 Micro: 0.7796\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.87      0.85      1094\n",
      "      Abusive       0.91      0.89      0.90      1072\n",
      "HS_Individual       0.68      0.82      0.74       689\n",
      "     HS_Group       0.77      0.56      0.64       405\n",
      "  HS_Religion       0.68      0.68      0.68       124\n",
      "      HS_Race       0.83      0.73      0.77       125\n",
      "  HS_Physical       0.48      0.25      0.33        61\n",
      "    HS_Gender       0.69      0.41      0.52        58\n",
      "     HS_Other       0.77      0.80      0.79       754\n",
      "      HS_Weak       0.68      0.80      0.74       664\n",
      "  HS_Moderate       0.71      0.49      0.58       346\n",
      "    HS_Strong       0.78      0.82      0.80        84\n",
      "\n",
      "    micro avg       0.78      0.78      0.78      5476\n",
      "    macro avg       0.73      0.68      0.69      5476\n",
      " weighted avg       0.78      0.78      0.78      5476\n",
      "  samples avg       0.44      0.45      0.43      5476\n",
      "\n",
      "\n",
      "FOLD 2 COMPLETED in 6568.01 seconds\n",
      "===============================================\n",
      "STARTING FOLD 3/5\n",
      "===============================================\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 658 samples...\n",
      "Epoch 1/10, Train Loss: 0.589, Accuracy: 0.8192, F1 Micro: 0.3329, F1 Macro: 0.121\n",
      "Epoch 2/10, Train Loss: 0.462, Accuracy: 0.8328, F1 Micro: 0.1424, F1 Macro: 0.043\n",
      "Epoch 3/10, Train Loss: 0.4096, Accuracy: 0.8379, F1 Micro: 0.1751, F1 Macro: 0.0644\n",
      "Epoch 4/10, Train Loss: 0.3943, Accuracy: 0.8443, F1 Micro: 0.243, F1 Macro: 0.0848\n",
      "Epoch 5/10, Train Loss: 0.3778, Accuracy: 0.8511, F1 Micro: 0.3367, F1 Macro: 0.1065\n",
      "Epoch 6/10, Train Loss: 0.361, Accuracy: 0.8584, F1 Micro: 0.3902, F1 Macro: 0.1412\n",
      "Epoch 7/10, Train Loss: 0.3343, Accuracy: 0.8714, F1 Micro: 0.5554, F1 Macro: 0.2443\n",
      "Epoch 8/10, Train Loss: 0.3088, Accuracy: 0.8736, F1 Micro: 0.5244, F1 Macro: 0.246\n",
      "Epoch 9/10, Train Loss: 0.2861, Accuracy: 0.8776, F1 Micro: 0.6054, F1 Macro: 0.2994\n",
      "Epoch 10/10, Train Loss: 0.2691, Accuracy: 0.8796, F1 Micro: 0.6353, F1 Macro: 0.3468\n",
      "Best result for 658 samples: F1 Micro: 0.6353\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.74      0.82      0.78      1142\n",
      "      Abusive       0.78      0.82      0.80      1026\n",
      "HS_Individual       0.61      0.65      0.63       723\n",
      "     HS_Group       0.59      0.35      0.44       419\n",
      "  HS_Religion       0.00      0.00      0.00       177\n",
      "      HS_Race       0.00      0.00      0.00       119\n",
      "  HS_Physical       0.00      0.00      0.00        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.61      0.71      0.66       746\n",
      "      HS_Weak       0.59      0.58      0.58       685\n",
      "  HS_Moderate       0.61      0.16      0.26       352\n",
      "    HS_Strong       1.00      0.01      0.02       105\n",
      "\n",
      "    micro avg       0.67      0.60      0.64      5634\n",
      "    macro avg       0.46      0.34      0.35      5634\n",
      " weighted avg       0.62      0.60      0.59      5634\n",
      "  samples avg       0.39      0.34      0.34      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 988\n",
      "Sampling duration: 53.14895963668823 seconds\n",
      "\n",
      "Fold 3 - New train size: 1646\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 1646 samples...\n",
      "Epoch 1/10, Train Loss: 0.519, Accuracy: 0.826, F1 Micro: 0.0161, F1 Macro: 0.0065\n",
      "Epoch 2/10, Train Loss: 0.3933, Accuracy: 0.8308, F1 Micro: 0.0762, F1 Macro: 0.0307\n",
      "Epoch 3/10, Train Loss: 0.3747, Accuracy: 0.8535, F1 Micro: 0.3488, F1 Macro: 0.1118\n",
      "Epoch 4/10, Train Loss: 0.3296, Accuracy: 0.8739, F1 Micro: 0.518, F1 Macro: 0.2294\n",
      "Epoch 5/10, Train Loss: 0.312, Accuracy: 0.881, F1 Micro: 0.6287, F1 Macro: 0.3182\n",
      "Epoch 6/10, Train Loss: 0.2698, Accuracy: 0.8893, F1 Micro: 0.637, F1 Macro: 0.3851\n",
      "Epoch 7/10, Train Loss: 0.2362, Accuracy: 0.8941, F1 Micro: 0.6606, F1 Macro: 0.429\n",
      "Epoch 8/10, Train Loss: 0.2124, Accuracy: 0.8953, F1 Micro: 0.6873, F1 Macro: 0.4546\n",
      "Epoch 9/10, Train Loss: 0.192, Accuracy: 0.8924, F1 Micro: 0.6971, F1 Macro: 0.4367\n",
      "Epoch 10/10, Train Loss: 0.175, Accuracy: 0.8974, F1 Micro: 0.6793, F1 Macro: 0.4151\n",
      "Best result for 1646 samples: F1 Micro: 0.6971\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.77      0.88      0.82      1142\n",
      "      Abusive       0.84      0.87      0.85      1026\n",
      "HS_Individual       0.61      0.80      0.69       723\n",
      "     HS_Group       0.72      0.50      0.59       419\n",
      "  HS_Religion       1.00      0.03      0.05       177\n",
      "      HS_Race       0.89      0.07      0.12       119\n",
      "  HS_Physical       0.00      0.00      0.00        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.58      0.84      0.68       746\n",
      "      HS_Weak       0.60      0.75      0.66       685\n",
      "  HS_Moderate       0.61      0.38      0.47       352\n",
      "    HS_Strong       0.90      0.17      0.29       105\n",
      "\n",
      "    micro avg       0.69      0.71      0.70      5634\n",
      "    macro avg       0.63      0.44      0.44      5634\n",
      " weighted avg       0.69      0.71      0.66      5634\n",
      "  samples avg       0.40      0.40      0.38      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 889\n",
      "Sampling duration: 47.71708297729492 seconds\n",
      "\n",
      "Fold 3 - New train size: 2535\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 2535 samples...\n",
      "Epoch 1/10, Train Loss: 0.4772, Accuracy: 0.8281, F1 Micro: 0.0451, F1 Macro: 0.0183\n",
      "Epoch 2/10, Train Loss: 0.3693, Accuracy: 0.8525, F1 Micro: 0.3443, F1 Macro: 0.1115\n",
      "Epoch 3/10, Train Loss: 0.3247, Accuracy: 0.879, F1 Micro: 0.5706, F1 Macro: 0.2664\n",
      "Epoch 4/10, Train Loss: 0.2899, Accuracy: 0.8891, F1 Micro: 0.6544, F1 Macro: 0.3501\n",
      "Epoch 5/10, Train Loss: 0.2452, Accuracy: 0.8954, F1 Micro: 0.6559, F1 Macro: 0.396\n",
      "Epoch 6/10, Train Loss: 0.2156, Accuracy: 0.8988, F1 Micro: 0.6694, F1 Macro: 0.4148\n",
      "Epoch 7/10, Train Loss: 0.1943, Accuracy: 0.899, F1 Micro: 0.7001, F1 Macro: 0.4597\n",
      "Epoch 8/10, Train Loss: 0.1664, Accuracy: 0.9034, F1 Micro: 0.695, F1 Macro: 0.4957\n",
      "Epoch 9/10, Train Loss: 0.1443, Accuracy: 0.9065, F1 Micro: 0.7195, F1 Macro: 0.5165\n",
      "Epoch 10/10, Train Loss: 0.1253, Accuracy: 0.9069, F1 Micro: 0.7187, F1 Macro: 0.5343\n",
      "Best result for 2535 samples: F1 Micro: 0.7195\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.83      0.83      1142\n",
      "      Abusive       0.89      0.82      0.86      1026\n",
      "HS_Individual       0.71      0.67      0.69       723\n",
      "     HS_Group       0.67      0.63      0.65       419\n",
      "  HS_Religion       0.88      0.24      0.38       177\n",
      "      HS_Race       0.91      0.27      0.42       119\n",
      "  HS_Physical       0.00      0.00      0.00        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.69      0.79      0.74       746\n",
      "      HS_Weak       0.69      0.63      0.66       685\n",
      "  HS_Moderate       0.57      0.55      0.56       352\n",
      "    HS_Strong       0.79      0.29      0.42       105\n",
      "\n",
      "    micro avg       0.76      0.69      0.72      5634\n",
      "    macro avg       0.64      0.48      0.52      5634\n",
      " weighted avg       0.74      0.69      0.70      5634\n",
      "  samples avg       0.41      0.38      0.38      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 800\n",
      "Sampling duration: 43.37140679359436 seconds\n",
      "\n",
      "Fold 3 - New train size: 3335\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 3335 samples...\n",
      "Epoch 1/10, Train Loss: 0.4509, Accuracy: 0.8317, F1 Micro: 0.0944, F1 Macro: 0.0352\n",
      "Epoch 2/10, Train Loss: 0.3652, Accuracy: 0.8714, F1 Micro: 0.4942, F1 Macro: 0.2067\n",
      "Epoch 3/10, Train Loss: 0.3168, Accuracy: 0.8862, F1 Micro: 0.669, F1 Macro: 0.3575\n",
      "Epoch 4/10, Train Loss: 0.2677, Accuracy: 0.899, F1 Micro: 0.6676, F1 Macro: 0.3947\n",
      "Epoch 5/10, Train Loss: 0.2276, Accuracy: 0.9037, F1 Micro: 0.6846, F1 Macro: 0.4589\n",
      "Epoch 6/10, Train Loss: 0.1958, Accuracy: 0.907, F1 Micro: 0.7264, F1 Macro: 0.5323\n",
      "Epoch 7/10, Train Loss: 0.1651, Accuracy: 0.9086, F1 Micro: 0.7339, F1 Macro: 0.5495\n",
      "Epoch 8/10, Train Loss: 0.1439, Accuracy: 0.9102, F1 Micro: 0.7422, F1 Macro: 0.5647\n",
      "Epoch 9/10, Train Loss: 0.1212, Accuracy: 0.9092, F1 Micro: 0.7415, F1 Macro: 0.5736\n",
      "Epoch 10/10, Train Loss: 0.1051, Accuracy: 0.9116, F1 Micro: 0.7422, F1 Macro: 0.5777\n",
      "Best result for 3335 samples: F1 Micro: 0.7422\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.85      0.84      1142\n",
      "      Abusive       0.90      0.88      0.89      1026\n",
      "HS_Individual       0.67      0.72      0.70       723\n",
      "     HS_Group       0.72      0.61      0.66       419\n",
      "  HS_Religion       0.68      0.45      0.54       177\n",
      "      HS_Race       0.85      0.57      0.68       119\n",
      "  HS_Physical       0.00      0.00      0.00        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.71      0.78      0.74       746\n",
      "      HS_Weak       0.66      0.70      0.68       685\n",
      "  HS_Moderate       0.63      0.54      0.58       352\n",
      "    HS_Strong       0.81      0.50      0.62       105\n",
      "\n",
      "    micro avg       0.76      0.73      0.74      5634\n",
      "    macro avg       0.62      0.55      0.58      5634\n",
      " weighted avg       0.74      0.73      0.73      5634\n",
      "  samples avg       0.43      0.42      0.41      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 720\n",
      "Sampling duration: 39.502671241760254 seconds\n",
      "\n",
      "Fold 3 - New train size: 4055\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 4055 samples...\n",
      "Epoch 1/10, Train Loss: 0.4424, Accuracy: 0.8295, F1 Micro: 0.0534, F1 Macro: 0.0222\n",
      "Epoch 2/10, Train Loss: 0.3532, Accuracy: 0.8796, F1 Micro: 0.5854, F1 Macro: 0.2714\n",
      "Epoch 3/10, Train Loss: 0.2915, Accuracy: 0.8916, F1 Micro: 0.6884, F1 Macro: 0.4344\n",
      "Epoch 4/10, Train Loss: 0.2511, Accuracy: 0.9027, F1 Micro: 0.7081, F1 Macro: 0.4799\n",
      "Epoch 5/10, Train Loss: 0.2112, Accuracy: 0.9077, F1 Micro: 0.7251, F1 Macro: 0.5314\n",
      "Epoch 6/10, Train Loss: 0.1879, Accuracy: 0.9083, F1 Micro: 0.7411, F1 Macro: 0.5645\n",
      "Epoch 7/10, Train Loss: 0.1552, Accuracy: 0.9131, F1 Micro: 0.733, F1 Macro: 0.563\n",
      "Epoch 8/10, Train Loss: 0.1363, Accuracy: 0.9129, F1 Micro: 0.7407, F1 Macro: 0.5674\n",
      "Epoch 9/10, Train Loss: 0.1145, Accuracy: 0.9121, F1 Micro: 0.7329, F1 Macro: 0.5563\n",
      "Epoch 10/10, Train Loss: 0.1015, Accuracy: 0.9153, F1 Micro: 0.7545, F1 Macro: 0.6003\n",
      "Best result for 4055 samples: F1 Micro: 0.7545\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.85      0.84      1142\n",
      "      Abusive       0.89      0.89      0.89      1026\n",
      "HS_Individual       0.71      0.74      0.73       723\n",
      "     HS_Group       0.70      0.64      0.67       419\n",
      "  HS_Religion       0.76      0.51      0.61       177\n",
      "      HS_Race       0.80      0.67      0.73       119\n",
      "  HS_Physical       0.00      0.00      0.00        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.71      0.79      0.75       746\n",
      "      HS_Weak       0.68      0.71      0.70       685\n",
      "  HS_Moderate       0.61      0.57      0.59       352\n",
      "    HS_Strong       0.82      0.61      0.70       105\n",
      "\n",
      "    micro avg       0.76      0.75      0.75      5634\n",
      "    macro avg       0.63      0.58      0.60      5634\n",
      " weighted avg       0.75      0.75      0.74      5634\n",
      "  samples avg       0.44      0.43      0.41      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 648\n",
      "Sampling duration: 35.10456681251526 seconds\n",
      "\n",
      "Fold 3 - New train size: 4703\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 4703 samples...\n",
      "Epoch 1/10, Train Loss: 0.4263, Accuracy: 0.8335, F1 Micro: 0.1029, F1 Macro: 0.0402\n",
      "Epoch 2/10, Train Loss: 0.3342, Accuracy: 0.8843, F1 Micro: 0.5999, F1 Macro: 0.2937\n",
      "Epoch 3/10, Train Loss: 0.2757, Accuracy: 0.9, F1 Micro: 0.6795, F1 Macro: 0.4535\n",
      "Epoch 4/10, Train Loss: 0.2341, Accuracy: 0.9052, F1 Micro: 0.6883, F1 Macro: 0.4819\n",
      "Epoch 5/10, Train Loss: 0.1976, Accuracy: 0.9066, F1 Micro: 0.7263, F1 Macro: 0.5213\n",
      "Epoch 6/10, Train Loss: 0.1744, Accuracy: 0.9142, F1 Micro: 0.754, F1 Macro: 0.5891\n",
      "Epoch 7/10, Train Loss: 0.1454, Accuracy: 0.9124, F1 Micro: 0.7402, F1 Macro: 0.593\n",
      "Epoch 8/10, Train Loss: 0.1212, Accuracy: 0.9156, F1 Micro: 0.7515, F1 Macro: 0.5895\n",
      "Epoch 9/10, Train Loss: 0.1098, Accuracy: 0.9116, F1 Micro: 0.7464, F1 Macro: 0.5757\n",
      "Epoch 10/10, Train Loss: 0.092, Accuracy: 0.9156, F1 Micro: 0.7505, F1 Macro: 0.594\n",
      "Best result for 4703 samples: F1 Micro: 0.754\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.87      0.85      1142\n",
      "      Abusive       0.88      0.90      0.89      1026\n",
      "HS_Individual       0.70      0.74      0.72       723\n",
      "     HS_Group       0.71      0.65      0.68       419\n",
      "  HS_Religion       0.72      0.58      0.64       177\n",
      "      HS_Race       0.83      0.60      0.69       119\n",
      "  HS_Physical       0.00      0.00      0.00        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.70      0.81      0.75       746\n",
      "      HS_Weak       0.67      0.71      0.69       685\n",
      "  HS_Moderate       0.60      0.58      0.59       352\n",
      "    HS_Strong       0.81      0.44      0.57       105\n",
      "\n",
      "    micro avg       0.75      0.75      0.75      5634\n",
      "    macro avg       0.62      0.57      0.59      5634\n",
      " weighted avg       0.74      0.75      0.74      5634\n",
      "  samples avg       0.43      0.43      0.41      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 584\n",
      "Sampling duration: 31.615792512893677 seconds\n",
      "\n",
      "Fold 3 - New train size: 5287\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 5287 samples...\n",
      "Epoch 1/10, Train Loss: 0.419, Accuracy: 0.8502, F1 Micro: 0.2946, F1 Macro: 0.1003\n",
      "Epoch 2/10, Train Loss: 0.3198, Accuracy: 0.8899, F1 Micro: 0.6669, F1 Macro: 0.3893\n",
      "Epoch 3/10, Train Loss: 0.2637, Accuracy: 0.9047, F1 Micro: 0.7089, F1 Macro: 0.4747\n",
      "Epoch 4/10, Train Loss: 0.2218, Accuracy: 0.9103, F1 Micro: 0.7222, F1 Macro: 0.5346\n",
      "Epoch 5/10, Train Loss: 0.1844, Accuracy: 0.9138, F1 Micro: 0.749, F1 Macro: 0.583\n",
      "Epoch 6/10, Train Loss: 0.1543, Accuracy: 0.9172, F1 Micro: 0.755, F1 Macro: 0.5761\n",
      "Epoch 7/10, Train Loss: 0.1326, Accuracy: 0.9145, F1 Micro: 0.7539, F1 Macro: 0.5825\n",
      "Epoch 8/10, Train Loss: 0.1126, Accuracy: 0.9161, F1 Micro: 0.7462, F1 Macro: 0.5747\n",
      "Epoch 9/10, Train Loss: 0.0956, Accuracy: 0.9151, F1 Micro: 0.7465, F1 Macro: 0.6042\n",
      "Epoch 10/10, Train Loss: 0.0854, Accuracy: 0.9203, F1 Micro: 0.7627, F1 Macro: 0.6121\n",
      "Best result for 5287 samples: F1 Micro: 0.7627\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.87      0.83      0.85      1142\n",
      "      Abusive       0.89      0.91      0.90      1026\n",
      "HS_Individual       0.77      0.68      0.72       723\n",
      "     HS_Group       0.70      0.66      0.68       419\n",
      "  HS_Religion       0.78      0.53      0.63       177\n",
      "      HS_Race       0.87      0.56      0.68       119\n",
      "  HS_Physical       0.00      0.00      0.00        80\n",
      "    HS_Gender       0.67      0.07      0.12        60\n",
      "     HS_Other       0.76      0.77      0.76       746\n",
      "      HS_Weak       0.74      0.67      0.70       685\n",
      "  HS_Moderate       0.59      0.62      0.60       352\n",
      "    HS_Strong       0.84      0.58      0.69       105\n",
      "\n",
      "    micro avg       0.79      0.73      0.76      5634\n",
      "    macro avg       0.71      0.57      0.61      5634\n",
      " weighted avg       0.78      0.73      0.75      5634\n",
      "  samples avg       0.44      0.42      0.41      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 525\n",
      "Sampling duration: 28.19054865837097 seconds\n",
      "\n",
      "Fold 3 - New train size: 5812\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 5812 samples...\n",
      "Epoch 1/10, Train Loss: 0.4201, Accuracy: 0.8558, F1 Micro: 0.3555, F1 Macro: 0.1154\n",
      "Epoch 2/10, Train Loss: 0.3152, Accuracy: 0.8921, F1 Micro: 0.65, F1 Macro: 0.3739\n",
      "Epoch 3/10, Train Loss: 0.2594, Accuracy: 0.9036, F1 Micro: 0.6921, F1 Macro: 0.4715\n",
      "Epoch 4/10, Train Loss: 0.2147, Accuracy: 0.9114, F1 Micro: 0.7345, F1 Macro: 0.5749\n",
      "Epoch 5/10, Train Loss: 0.1842, Accuracy: 0.9114, F1 Micro: 0.7519, F1 Macro: 0.5943\n",
      "Epoch 6/10, Train Loss: 0.1597, Accuracy: 0.912, F1 Micro: 0.7499, F1 Macro: 0.5826\n",
      "Epoch 7/10, Train Loss: 0.1337, Accuracy: 0.9191, F1 Micro: 0.755, F1 Macro: 0.6124\n",
      "Epoch 8/10, Train Loss: 0.1102, Accuracy: 0.9184, F1 Micro: 0.7569, F1 Macro: 0.6048\n",
      "Epoch 9/10, Train Loss: 0.093, Accuracy: 0.9177, F1 Micro: 0.76, F1 Macro: 0.6158\n",
      "Epoch 10/10, Train Loss: 0.0809, Accuracy: 0.9192, F1 Micro: 0.765, F1 Macro: 0.6248\n",
      "Best result for 5812 samples: F1 Micro: 0.765\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.86      0.85      1142\n",
      "      Abusive       0.89      0.91      0.90      1026\n",
      "HS_Individual       0.72      0.73      0.73       723\n",
      "     HS_Group       0.71      0.65      0.67       419\n",
      "  HS_Religion       0.75      0.57      0.65       177\n",
      "      HS_Race       0.82      0.63      0.71       119\n",
      "  HS_Physical       1.00      0.04      0.07        80\n",
      "    HS_Gender       0.80      0.07      0.12        60\n",
      "     HS_Other       0.74      0.80      0.77       746\n",
      "      HS_Weak       0.71      0.70      0.70       685\n",
      "  HS_Moderate       0.61      0.57      0.59       352\n",
      "    HS_Strong       0.80      0.66      0.72       105\n",
      "\n",
      "    micro avg       0.78      0.75      0.77      5634\n",
      "    macro avg       0.78      0.60      0.62      5634\n",
      " weighted avg       0.78      0.75      0.76      5634\n",
      "  samples avg       0.44      0.43      0.42      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 473\n",
      "Sampling duration: 25.786776304244995 seconds\n",
      "\n",
      "Fold 3 - New train size: 6285\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 6285 samples...\n",
      "Epoch 1/10, Train Loss: 0.4133, Accuracy: 0.8646, F1 Micro: 0.4572, F1 Macro: 0.1745\n",
      "Epoch 2/10, Train Loss: 0.3019, Accuracy: 0.9, F1 Micro: 0.6825, F1 Macro: 0.4423\n",
      "Epoch 3/10, Train Loss: 0.2493, Accuracy: 0.908, F1 Micro: 0.7111, F1 Macro: 0.5017\n",
      "Epoch 4/10, Train Loss: 0.2077, Accuracy: 0.914, F1 Micro: 0.7358, F1 Macro: 0.558\n",
      "Epoch 5/10, Train Loss: 0.1761, Accuracy: 0.916, F1 Micro: 0.7354, F1 Macro: 0.576\n",
      "Epoch 6/10, Train Loss: 0.1494, Accuracy: 0.9169, F1 Micro: 0.76, F1 Macro: 0.5931\n",
      "Epoch 7/10, Train Loss: 0.1232, Accuracy: 0.9188, F1 Micro: 0.7627, F1 Macro: 0.6043\n",
      "Epoch 8/10, Train Loss: 0.1075, Accuracy: 0.9164, F1 Micro: 0.7513, F1 Macro: 0.6083\n",
      "Epoch 9/10, Train Loss: 0.0897, Accuracy: 0.9208, F1 Micro: 0.7697, F1 Macro: 0.6406\n",
      "Epoch 10/10, Train Loss: 0.0796, Accuracy: 0.9178, F1 Micro: 0.7605, F1 Macro: 0.6467\n",
      "Best result for 6285 samples: F1 Micro: 0.7697\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.86      0.85      1142\n",
      "      Abusive       0.91      0.88      0.89      1026\n",
      "HS_Individual       0.69      0.79      0.73       723\n",
      "     HS_Group       0.78      0.59      0.67       419\n",
      "  HS_Religion       0.78      0.60      0.68       177\n",
      "      HS_Race       0.88      0.66      0.76       119\n",
      "  HS_Physical       0.71      0.06      0.11        80\n",
      "    HS_Gender       0.75      0.10      0.18        60\n",
      "     HS_Other       0.76      0.80      0.78       746\n",
      "      HS_Weak       0.66      0.77      0.71       685\n",
      "  HS_Moderate       0.71      0.54      0.61       352\n",
      "    HS_Strong       0.84      0.61      0.71       105\n",
      "\n",
      "    micro avg       0.78      0.76      0.77      5634\n",
      "    macro avg       0.78      0.60      0.64      5634\n",
      " weighted avg       0.79      0.76      0.76      5634\n",
      "  samples avg       0.44      0.43      0.42      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 299\n",
      "Sampling duration: 23.718252420425415 seconds\n",
      "\n",
      "Fold 3 - New train size: 6584\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 6584 samples...\n",
      "Epoch 1/10, Train Loss: 0.4089, Accuracy: 0.8713, F1 Micro: 0.492, F1 Macro: 0.2091\n",
      "Epoch 2/10, Train Loss: 0.3045, Accuracy: 0.8943, F1 Micro: 0.6273, F1 Macro: 0.3682\n",
      "Epoch 3/10, Train Loss: 0.2503, Accuracy: 0.9085, F1 Micro: 0.7143, F1 Macro: 0.5094\n",
      "Epoch 4/10, Train Loss: 0.2065, Accuracy: 0.9149, F1 Micro: 0.7363, F1 Macro: 0.5669\n",
      "Epoch 5/10, Train Loss: 0.1775, Accuracy: 0.9146, F1 Micro: 0.7337, F1 Macro: 0.5455\n",
      "Epoch 6/10, Train Loss: 0.148, Accuracy: 0.9146, F1 Micro: 0.7615, F1 Macro: 0.6111\n",
      "Epoch 7/10, Train Loss: 0.1282, Accuracy: 0.9164, F1 Micro: 0.7576, F1 Macro: 0.6041\n",
      "Epoch 8/10, Train Loss: 0.1031, Accuracy: 0.9198, F1 Micro: 0.7648, F1 Macro: 0.6435\n",
      "Epoch 9/10, Train Loss: 0.0856, Accuracy: 0.9195, F1 Micro: 0.7671, F1 Macro: 0.6413\n",
      "Epoch 10/10, Train Loss: 0.0781, Accuracy: 0.9182, F1 Micro: 0.7646, F1 Macro: 0.6432\n",
      "Best result for 6584 samples: F1 Micro: 0.7671\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.87      0.86      1142\n",
      "      Abusive       0.89      0.90      0.90      1026\n",
      "HS_Individual       0.70      0.77      0.73       723\n",
      "     HS_Group       0.75      0.59      0.66       419\n",
      "  HS_Religion       0.76      0.52      0.62       177\n",
      "      HS_Race       0.75      0.74      0.74       119\n",
      "  HS_Physical       0.90      0.11      0.20        80\n",
      "    HS_Gender       0.67      0.10      0.17        60\n",
      "     HS_Other       0.75      0.79      0.77       746\n",
      "      HS_Weak       0.68      0.74      0.71       685\n",
      "  HS_Moderate       0.68      0.51      0.58       352\n",
      "    HS_Strong       0.81      0.70      0.76       105\n",
      "\n",
      "    micro avg       0.78      0.76      0.77      5634\n",
      "    macro avg       0.76      0.61      0.64      5634\n",
      " weighted avg       0.78      0.76      0.76      5634\n",
      "  samples avg       0.45      0.43      0.42      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Acquired samples: 396\n",
      "Sampling duration: 21.966288805007935 seconds\n",
      "\n",
      "Fold 3 - New train size: 6980\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 6980 samples...\n",
      "Epoch 1/10, Train Loss: 0.4063, Accuracy: 0.8748, F1 Micro: 0.5349, F1 Macro: 0.2449\n",
      "Epoch 2/10, Train Loss: 0.2973, Accuracy: 0.9007, F1 Micro: 0.6935, F1 Macro: 0.4971\n",
      "Epoch 3/10, Train Loss: 0.246, Accuracy: 0.9104, F1 Micro: 0.7278, F1 Macro: 0.5487\n",
      "Epoch 4/10, Train Loss: 0.2061, Accuracy: 0.9151, F1 Micro: 0.7508, F1 Macro: 0.5833\n",
      "Epoch 5/10, Train Loss: 0.1753, Accuracy: 0.917, F1 Micro: 0.7554, F1 Macro: 0.5752\n",
      "Epoch 6/10, Train Loss: 0.1425, Accuracy: 0.9187, F1 Micro: 0.7638, F1 Macro: 0.609\n",
      "Epoch 7/10, Train Loss: 0.1223, Accuracy: 0.9196, F1 Micro: 0.754, F1 Macro: 0.6086\n",
      "Epoch 8/10, Train Loss: 0.1034, Accuracy: 0.9214, F1 Micro: 0.7727, F1 Macro: 0.6476\n",
      "Epoch 9/10, Train Loss: 0.0859, Accuracy: 0.9196, F1 Micro: 0.7526, F1 Macro: 0.6333\n",
      "Epoch 10/10, Train Loss: 0.0738, Accuracy: 0.9184, F1 Micro: 0.7594, F1 Macro: 0.6471\n",
      "Best result for 6980 samples: F1 Micro: 0.7727\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.86      0.85      1142\n",
      "      Abusive       0.89      0.91      0.90      1026\n",
      "HS_Individual       0.71      0.77      0.74       723\n",
      "     HS_Group       0.74      0.64      0.68       419\n",
      "  HS_Religion       0.75      0.58      0.65       177\n",
      "      HS_Race       0.77      0.71      0.74       119\n",
      "  HS_Physical       0.80      0.10      0.18        80\n",
      "    HS_Gender       0.75      0.10      0.18        60\n",
      "     HS_Other       0.76      0.79      0.78       746\n",
      "      HS_Weak       0.69      0.74      0.71       685\n",
      "  HS_Moderate       0.65      0.57      0.61       352\n",
      "    HS_Strong       0.84      0.67      0.74       105\n",
      "\n",
      "    micro avg       0.78      0.76      0.77      5634\n",
      "    macro avg       0.77      0.62      0.65      5634\n",
      " weighted avg       0.78      0.76      0.76      5634\n",
      "  samples avg       0.45      0.44      0.43      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Acquired samples: 356\n",
      "Sampling duration: 19.804385662078857 seconds\n",
      "\n",
      "Fold 3 - New train size: 7336\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 7336 samples...\n",
      "Epoch 1/10, Train Loss: 0.402, Accuracy: 0.8783, F1 Micro: 0.5791, F1 Macro: 0.2697\n",
      "Epoch 2/10, Train Loss: 0.2907, Accuracy: 0.9013, F1 Micro: 0.6996, F1 Macro: 0.4746\n",
      "Epoch 3/10, Train Loss: 0.2394, Accuracy: 0.9108, F1 Micro: 0.7445, F1 Macro: 0.5732\n",
      "Epoch 4/10, Train Loss: 0.2038, Accuracy: 0.9179, F1 Micro: 0.7562, F1 Macro: 0.577\n",
      "Epoch 5/10, Train Loss: 0.166, Accuracy: 0.9179, F1 Micro: 0.7641, F1 Macro: 0.5954\n",
      "Epoch 6/10, Train Loss: 0.1451, Accuracy: 0.9211, F1 Micro: 0.7605, F1 Macro: 0.6101\n",
      "Epoch 7/10, Train Loss: 0.1202, Accuracy: 0.9188, F1 Micro: 0.7538, F1 Macro: 0.6111\n",
      "Epoch 8/10, Train Loss: 0.1037, Accuracy: 0.9203, F1 Micro: 0.7711, F1 Macro: 0.6445\n",
      "Epoch 9/10, Train Loss: 0.0874, Accuracy: 0.923, F1 Micro: 0.7723, F1 Macro: 0.6602\n",
      "Epoch 10/10, Train Loss: 0.077, Accuracy: 0.9209, F1 Micro: 0.7737, F1 Macro: 0.6591\n",
      "Best result for 7336 samples: F1 Micro: 0.7737\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.88      0.86      1142\n",
      "      Abusive       0.91      0.92      0.91      1026\n",
      "HS_Individual       0.71      0.74      0.73       723\n",
      "     HS_Group       0.69      0.68      0.69       419\n",
      "  HS_Religion       0.75      0.60      0.66       177\n",
      "      HS_Race       0.80      0.69      0.74       119\n",
      "  HS_Physical       0.71      0.12      0.21        80\n",
      "    HS_Gender       0.58      0.18      0.28        60\n",
      "     HS_Other       0.75      0.81      0.78       746\n",
      "      HS_Weak       0.69      0.71      0.70       685\n",
      "  HS_Moderate       0.63      0.64      0.63       352\n",
      "    HS_Strong       0.80      0.66      0.72       105\n",
      "\n",
      "    micro avg       0.77      0.77      0.77      5634\n",
      "    macro avg       0.74      0.64      0.66      5634\n",
      " weighted avg       0.77      0.77      0.77      5634\n",
      "  samples avg       0.44      0.44      0.43      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Acquired samples: 320\n",
      "Sampling duration: 18.17621874809265 seconds\n",
      "\n",
      "Fold 3 - New train size: 7656\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 7656 samples...\n",
      "Epoch 1/10, Train Loss: 0.3962, Accuracy: 0.8762, F1 Micro: 0.5339, F1 Macro: 0.2515\n",
      "Epoch 2/10, Train Loss: 0.2861, Accuracy: 0.9027, F1 Micro: 0.6874, F1 Macro: 0.4766\n",
      "Epoch 3/10, Train Loss: 0.2378, Accuracy: 0.9124, F1 Micro: 0.7449, F1 Macro: 0.5612\n",
      "Epoch 4/10, Train Loss: 0.197, Accuracy: 0.9175, F1 Micro: 0.7487, F1 Macro: 0.5739\n",
      "Epoch 5/10, Train Loss: 0.1649, Accuracy: 0.9203, F1 Micro: 0.7643, F1 Macro: 0.6049\n",
      "Epoch 6/10, Train Loss: 0.142, Accuracy: 0.9204, F1 Micro: 0.7646, F1 Macro: 0.6254\n",
      "Epoch 7/10, Train Loss: 0.1147, Accuracy: 0.9197, F1 Micro: 0.7682, F1 Macro: 0.6508\n",
      "Epoch 8/10, Train Loss: 0.1032, Accuracy: 0.9187, F1 Micro: 0.7673, F1 Macro: 0.6364\n",
      "Epoch 9/10, Train Loss: 0.0844, Accuracy: 0.9213, F1 Micro: 0.7686, F1 Macro: 0.6551\n",
      "Epoch 10/10, Train Loss: 0.0749, Accuracy: 0.9209, F1 Micro: 0.7744, F1 Macro: 0.6564\n",
      "Best result for 7656 samples: F1 Micro: 0.7744\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.88      0.86      1142\n",
      "      Abusive       0.88      0.93      0.90      1026\n",
      "HS_Individual       0.69      0.78      0.74       723\n",
      "     HS_Group       0.75      0.63      0.69       419\n",
      "  HS_Religion       0.77      0.50      0.60       177\n",
      "      HS_Race       0.84      0.70      0.76       119\n",
      "  HS_Physical       0.64      0.11      0.19        80\n",
      "    HS_Gender       0.61      0.18      0.28        60\n",
      "     HS_Other       0.75      0.83      0.79       746\n",
      "      HS_Weak       0.66      0.76      0.71       685\n",
      "  HS_Moderate       0.67      0.55      0.60       352\n",
      "    HS_Strong       0.85      0.69      0.76       105\n",
      "\n",
      "    micro avg       0.77      0.78      0.77      5634\n",
      "    macro avg       0.75      0.63      0.66      5634\n",
      " weighted avg       0.77      0.78      0.77      5634\n",
      "  samples avg       0.45      0.45      0.43      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Acquired samples: 245\n",
      "Sampling duration: 16.170902252197266 seconds\n",
      "\n",
      "Fold 3 - New train size: 7901\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 7901 samples...\n",
      "Epoch 1/10, Train Loss: 0.3994, Accuracy: 0.8781, F1 Micro: 0.6028, F1 Macro: 0.2776\n",
      "Epoch 2/10, Train Loss: 0.2813, Accuracy: 0.9009, F1 Micro: 0.705, F1 Macro: 0.4566\n",
      "Epoch 3/10, Train Loss: 0.2322, Accuracy: 0.9106, F1 Micro: 0.7116, F1 Macro: 0.5188\n",
      "Epoch 4/10, Train Loss: 0.1964, Accuracy: 0.9151, F1 Micro: 0.7586, F1 Macro: 0.5755\n",
      "Epoch 5/10, Train Loss: 0.1643, Accuracy: 0.9183, F1 Micro: 0.7562, F1 Macro: 0.5915\n",
      "Epoch 6/10, Train Loss: 0.1387, Accuracy: 0.9215, F1 Micro: 0.7663, F1 Macro: 0.6079\n",
      "Epoch 7/10, Train Loss: 0.1135, Accuracy: 0.9191, F1 Micro: 0.7712, F1 Macro: 0.6443\n",
      "Epoch 8/10, Train Loss: 0.0959, Accuracy: 0.9205, F1 Micro: 0.7741, F1 Macro: 0.6414\n",
      "Epoch 9/10, Train Loss: 0.0848, Accuracy: 0.9231, F1 Micro: 0.773, F1 Macro: 0.665\n",
      "Epoch 10/10, Train Loss: 0.0757, Accuracy: 0.9235, F1 Micro: 0.774, F1 Macro: 0.6639\n",
      "Best result for 7901 samples: F1 Micro: 0.7741\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.88      0.85      1142\n",
      "      Abusive       0.88      0.93      0.90      1026\n",
      "HS_Individual       0.71      0.76      0.74       723\n",
      "     HS_Group       0.72      0.68      0.70       419\n",
      "  HS_Religion       0.73      0.55      0.63       177\n",
      "      HS_Race       0.82      0.67      0.74       119\n",
      "  HS_Physical       1.00      0.09      0.16        80\n",
      "    HS_Gender       0.67      0.07      0.12        60\n",
      "     HS_Other       0.73      0.83      0.77       746\n",
      "      HS_Weak       0.69      0.74      0.72       685\n",
      "  HS_Moderate       0.64      0.62      0.63       352\n",
      "    HS_Strong       0.82      0.67      0.74       105\n",
      "\n",
      "    micro avg       0.77      0.78      0.77      5634\n",
      "    macro avg       0.77      0.62      0.64      5634\n",
      " weighted avg       0.77      0.78      0.77      5634\n",
      "  samples avg       0.45      0.45      0.43      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 264\n",
      "Sampling duration: 15.055082082748413 seconds\n",
      "\n",
      "Fold 3 - New train size: 8165\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 8165 samples...\n",
      "Epoch 1/10, Train Loss: 0.3948, Accuracy: 0.8811, F1 Micro: 0.6074, F1 Macro: 0.2846\n",
      "Epoch 2/10, Train Loss: 0.2793, Accuracy: 0.9017, F1 Micro: 0.7048, F1 Macro: 0.4618\n",
      "Epoch 3/10, Train Loss: 0.2331, Accuracy: 0.912, F1 Micro: 0.7421, F1 Macro: 0.5351\n",
      "Epoch 4/10, Train Loss: 0.189, Accuracy: 0.9183, F1 Micro: 0.7594, F1 Macro: 0.5936\n",
      "Epoch 5/10, Train Loss: 0.1679, Accuracy: 0.9198, F1 Micro: 0.7481, F1 Macro: 0.5862\n",
      "Epoch 6/10, Train Loss: 0.1327, Accuracy: 0.9187, F1 Micro: 0.7644, F1 Macro: 0.6383\n",
      "Epoch 7/10, Train Loss: 0.116, Accuracy: 0.922, F1 Micro: 0.773, F1 Macro: 0.6658\n",
      "Epoch 8/10, Train Loss: 0.0954, Accuracy: 0.9212, F1 Micro: 0.7749, F1 Macro: 0.6691\n",
      "Epoch 9/10, Train Loss: 0.0849, Accuracy: 0.9219, F1 Micro: 0.7765, F1 Macro: 0.6691\n",
      "Epoch 10/10, Train Loss: 0.0712, Accuracy: 0.9213, F1 Micro: 0.7672, F1 Macro: 0.6621\n",
      "Best result for 8165 samples: F1 Micro: 0.7765\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.88      0.86      1142\n",
      "      Abusive       0.91      0.89      0.90      1026\n",
      "HS_Individual       0.71      0.75      0.73       723\n",
      "     HS_Group       0.73      0.69      0.71       419\n",
      "  HS_Religion       0.79      0.58      0.67       177\n",
      "      HS_Race       0.85      0.64      0.73       119\n",
      "  HS_Physical       0.75      0.15      0.25        80\n",
      "    HS_Gender       0.67      0.20      0.31        60\n",
      "     HS_Other       0.74      0.82      0.78       746\n",
      "      HS_Weak       0.69      0.75      0.72       685\n",
      "  HS_Moderate       0.64      0.64      0.64       352\n",
      "    HS_Strong       0.85      0.66      0.74       105\n",
      "\n",
      "    micro avg       0.78      0.78      0.78      5634\n",
      "    macro avg       0.76      0.64      0.67      5634\n",
      " weighted avg       0.78      0.78      0.77      5634\n",
      "  samples avg       0.44      0.44      0.43      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 237\n",
      "Sampling duration: 13.749364852905273 seconds\n",
      "\n",
      "Fold 3 - New train size: 8402\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 8402 samples...\n",
      "Epoch 1/10, Train Loss: 0.3924, Accuracy: 0.8811, F1 Micro: 0.603, F1 Macro: 0.2969\n",
      "Epoch 2/10, Train Loss: 0.2735, Accuracy: 0.9064, F1 Micro: 0.7111, F1 Macro: 0.5129\n",
      "Epoch 3/10, Train Loss: 0.2275, Accuracy: 0.9127, F1 Micro: 0.7277, F1 Macro: 0.5101\n",
      "Epoch 4/10, Train Loss: 0.1874, Accuracy: 0.914, F1 Micro: 0.759, F1 Macro: 0.601\n",
      "Epoch 5/10, Train Loss: 0.1594, Accuracy: 0.9156, F1 Micro: 0.7607, F1 Macro: 0.6003\n",
      "Epoch 6/10, Train Loss: 0.134, Accuracy: 0.9255, F1 Micro: 0.7735, F1 Macro: 0.6415\n",
      "Epoch 7/10, Train Loss: 0.1144, Accuracy: 0.9165, F1 Micro: 0.7716, F1 Macro: 0.6587\n",
      "Epoch 8/10, Train Loss: 0.095, Accuracy: 0.92, F1 Micro: 0.7687, F1 Macro: 0.6517\n",
      "Epoch 9/10, Train Loss: 0.0838, Accuracy: 0.9227, F1 Micro: 0.7733, F1 Macro: 0.663\n",
      "Epoch 10/10, Train Loss: 0.069, Accuracy: 0.9209, F1 Micro: 0.7781, F1 Macro: 0.6832\n",
      "Best result for 8402 samples: F1 Micro: 0.7781\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.89      0.85      1142\n",
      "      Abusive       0.89      0.93      0.91      1026\n",
      "HS_Individual       0.68      0.79      0.73       723\n",
      "     HS_Group       0.74      0.67      0.70       419\n",
      "  HS_Religion       0.78      0.58      0.66       177\n",
      "      HS_Race       0.84      0.71      0.77       119\n",
      "  HS_Physical       0.76      0.20      0.32        80\n",
      "    HS_Gender       0.70      0.27      0.39        60\n",
      "     HS_Other       0.71      0.83      0.77       746\n",
      "      HS_Weak       0.66      0.78      0.71       685\n",
      "  HS_Moderate       0.68      0.61      0.65       352\n",
      "    HS_Strong       0.82      0.67      0.74       105\n",
      "\n",
      "    micro avg       0.76      0.79      0.78      5634\n",
      "    macro avg       0.76      0.66      0.68      5634\n",
      " weighted avg       0.76      0.79      0.77      5634\n",
      "  samples avg       0.45      0.45      0.44      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 214\n",
      "Sampling duration: 12.179958820343018 seconds\n",
      "\n",
      "Fold 3 - New train size: 8616\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 8616 samples...\n",
      "Epoch 1/10, Train Loss: 0.3922, Accuracy: 0.8803, F1 Micro: 0.646, F1 Macro: 0.3262\n",
      "Epoch 2/10, Train Loss: 0.2745, Accuracy: 0.9064, F1 Micro: 0.704, F1 Macro: 0.4939\n",
      "Epoch 3/10, Train Loss: 0.2324, Accuracy: 0.9153, F1 Micro: 0.747, F1 Macro: 0.5797\n",
      "Epoch 4/10, Train Loss: 0.1895, Accuracy: 0.9151, F1 Micro: 0.744, F1 Macro: 0.598\n",
      "Epoch 5/10, Train Loss: 0.1568, Accuracy: 0.9211, F1 Micro: 0.7552, F1 Macro: 0.6041\n",
      "Epoch 6/10, Train Loss: 0.1343, Accuracy: 0.9235, F1 Micro: 0.7803, F1 Macro: 0.6326\n",
      "Epoch 7/10, Train Loss: 0.1086, Accuracy: 0.9206, F1 Micro: 0.7729, F1 Macro: 0.6577\n",
      "Epoch 8/10, Train Loss: 0.0948, Accuracy: 0.9213, F1 Micro: 0.7768, F1 Macro: 0.6667\n",
      "Epoch 9/10, Train Loss: 0.0819, Accuracy: 0.9175, F1 Micro: 0.7708, F1 Macro: 0.6871\n",
      "Epoch 10/10, Train Loss: 0.0719, Accuracy: 0.9206, F1 Micro: 0.7724, F1 Macro: 0.6724\n",
      "Best result for 8616 samples: F1 Micro: 0.7803\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.88      0.86      1142\n",
      "      Abusive       0.89      0.91      0.90      1026\n",
      "HS_Individual       0.73      0.78      0.75       723\n",
      "     HS_Group       0.75      0.68      0.72       419\n",
      "  HS_Religion       0.77      0.55      0.64       177\n",
      "      HS_Race       0.78      0.72      0.75       119\n",
      "  HS_Physical       1.00      0.03      0.05        80\n",
      "    HS_Gender       0.67      0.03      0.06        60\n",
      "     HS_Other       0.74      0.81      0.77       746\n",
      "      HS_Weak       0.71      0.76      0.74       685\n",
      "  HS_Moderate       0.68      0.61      0.64       352\n",
      "    HS_Strong       0.85      0.61      0.71       105\n",
      "\n",
      "    micro avg       0.78      0.78      0.78      5634\n",
      "    macro avg       0.78      0.61      0.63      5634\n",
      " weighted avg       0.78      0.78      0.77      5634\n",
      "  samples avg       0.45      0.44      0.43      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 200\n",
      "Sampling duration: 11.257323741912842 seconds\n",
      "\n",
      "Fold 3 - New train size: 8816\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 8816 samples...\n",
      "Epoch 1/10, Train Loss: 0.3938, Accuracy: 0.883, F1 Micro: 0.6164, F1 Macro: 0.3018\n",
      "Epoch 2/10, Train Loss: 0.2701, Accuracy: 0.9046, F1 Micro: 0.7027, F1 Macro: 0.493\n",
      "Epoch 3/10, Train Loss: 0.2231, Accuracy: 0.9151, F1 Micro: 0.7365, F1 Macro: 0.5495\n",
      "Epoch 4/10, Train Loss: 0.1889, Accuracy: 0.9194, F1 Micro: 0.7575, F1 Macro: 0.5901\n",
      "Epoch 5/10, Train Loss: 0.1548, Accuracy: 0.9192, F1 Micro: 0.76, F1 Macro: 0.5877\n",
      "Epoch 6/10, Train Loss: 0.134, Accuracy: 0.9212, F1 Micro: 0.7705, F1 Macro: 0.6393\n",
      "Epoch 7/10, Train Loss: 0.1097, Accuracy: 0.9235, F1 Micro: 0.7738, F1 Macro: 0.6526\n",
      "Epoch 8/10, Train Loss: 0.0941, Accuracy: 0.9178, F1 Micro: 0.7696, F1 Macro: 0.6597\n",
      "Epoch 9/10, Train Loss: 0.0812, Accuracy: 0.9214, F1 Micro: 0.7727, F1 Macro: 0.6798\n",
      "Epoch 10/10, Train Loss: 0.0699, Accuracy: 0.9233, F1 Micro: 0.7789, F1 Macro: 0.6884\n",
      "Best result for 8816 samples: F1 Micro: 0.7789\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.86      0.85      1142\n",
      "      Abusive       0.89      0.92      0.91      1026\n",
      "HS_Individual       0.72      0.76      0.74       723\n",
      "     HS_Group       0.74      0.66      0.70       419\n",
      "  HS_Religion       0.75      0.68      0.71       177\n",
      "      HS_Race       0.80      0.72      0.76       119\n",
      "  HS_Physical       0.72      0.23      0.34        80\n",
      "    HS_Gender       0.68      0.25      0.37        60\n",
      "     HS_Other       0.77      0.78      0.77       746\n",
      "      HS_Weak       0.70      0.74      0.72       685\n",
      "  HS_Moderate       0.68      0.60      0.64       352\n",
      "    HS_Strong       0.82      0.71      0.77       105\n",
      "\n",
      "    micro avg       0.78      0.77      0.78      5634\n",
      "    macro avg       0.76      0.66      0.69      5634\n",
      " weighted avg       0.78      0.77      0.77      5634\n",
      "  samples avg       0.45      0.44      0.43      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 200\n",
      "Sampling duration: 10.199939727783203 seconds\n",
      "\n",
      "Fold 3 - New train size: 9016\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 9016 samples...\n",
      "Epoch 1/10, Train Loss: 0.3873, Accuracy: 0.8816, F1 Micro: 0.5813, F1 Macro: 0.2849\n",
      "Epoch 2/10, Train Loss: 0.2711, Accuracy: 0.9064, F1 Micro: 0.7115, F1 Macro: 0.4749\n",
      "Epoch 3/10, Train Loss: 0.2185, Accuracy: 0.9188, F1 Micro: 0.7515, F1 Macro: 0.5776\n",
      "Epoch 4/10, Train Loss: 0.1852, Accuracy: 0.9218, F1 Micro: 0.7705, F1 Macro: 0.6178\n",
      "Epoch 5/10, Train Loss: 0.1515, Accuracy: 0.9211, F1 Micro: 0.7684, F1 Macro: 0.611\n",
      "Epoch 6/10, Train Loss: 0.1271, Accuracy: 0.9236, F1 Micro: 0.7755, F1 Macro: 0.6354\n",
      "Epoch 7/10, Train Loss: 0.1115, Accuracy: 0.9229, F1 Micro: 0.7788, F1 Macro: 0.6541\n",
      "Epoch 8/10, Train Loss: 0.0915, Accuracy: 0.916, F1 Micro: 0.7674, F1 Macro: 0.6615\n",
      "Epoch 9/10, Train Loss: 0.0809, Accuracy: 0.9212, F1 Micro: 0.7749, F1 Macro: 0.6688\n",
      "Epoch 10/10, Train Loss: 0.0689, Accuracy: 0.922, F1 Micro: 0.7764, F1 Macro: 0.6874\n",
      "Best result for 9016 samples: F1 Micro: 0.7788\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.87      0.85      1142\n",
      "      Abusive       0.90      0.91      0.91      1026\n",
      "HS_Individual       0.71      0.79      0.75       723\n",
      "     HS_Group       0.77      0.64      0.70       419\n",
      "  HS_Religion       0.74      0.62      0.67       177\n",
      "      HS_Race       0.82      0.69      0.75       119\n",
      "  HS_Physical       0.78      0.09      0.16        80\n",
      "    HS_Gender       0.78      0.12      0.20        60\n",
      "     HS_Other       0.74      0.82      0.78       746\n",
      "      HS_Weak       0.69      0.76      0.72       685\n",
      "  HS_Moderate       0.70      0.57      0.63       352\n",
      "    HS_Strong       0.81      0.67      0.73       105\n",
      "\n",
      "    micro avg       0.78      0.78      0.78      5634\n",
      "    macro avg       0.77      0.63      0.65      5634\n",
      " weighted avg       0.78      0.78      0.77      5634\n",
      "  samples avg       0.45      0.44      0.43      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 200\n",
      "Sampling duration: 9.320895433425903 seconds\n",
      "\n",
      "Fold 3 - New train size: 9216\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 9216 samples...\n",
      "Epoch 1/10, Train Loss: 0.3804, Accuracy: 0.8859, F1 Micro: 0.6251, F1 Macro: 0.3052\n",
      "Epoch 2/10, Train Loss: 0.265, Accuracy: 0.9041, F1 Micro: 0.6786, F1 Macro: 0.5074\n",
      "Epoch 3/10, Train Loss: 0.2157, Accuracy: 0.9151, F1 Micro: 0.744, F1 Macro: 0.5759\n",
      "Epoch 4/10, Train Loss: 0.1874, Accuracy: 0.921, F1 Micro: 0.7557, F1 Macro: 0.5978\n",
      "Epoch 5/10, Train Loss: 0.1576, Accuracy: 0.922, F1 Micro: 0.7652, F1 Macro: 0.6057\n",
      "Epoch 6/10, Train Loss: 0.1287, Accuracy: 0.9251, F1 Micro: 0.7777, F1 Macro: 0.6476\n",
      "Epoch 7/10, Train Loss: 0.1076, Accuracy: 0.9195, F1 Micro: 0.7744, F1 Macro: 0.6678\n",
      "Epoch 8/10, Train Loss: 0.0916, Accuracy: 0.9206, F1 Micro: 0.7691, F1 Macro: 0.6556\n",
      "Epoch 9/10, Train Loss: 0.0791, Accuracy: 0.9226, F1 Micro: 0.7734, F1 Macro: 0.6799\n",
      "Epoch 10/10, Train Loss: 0.0702, Accuracy: 0.9192, F1 Micro: 0.7744, F1 Macro: 0.6913\n",
      "Best result for 9216 samples: F1 Micro: 0.7777\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.85      0.85      1142\n",
      "      Abusive       0.91      0.90      0.90      1026\n",
      "HS_Individual       0.75      0.74      0.75       723\n",
      "     HS_Group       0.78      0.66      0.71       419\n",
      "  HS_Religion       0.75      0.60      0.66       177\n",
      "      HS_Race       0.86      0.57      0.69       119\n",
      "  HS_Physical       0.73      0.10      0.18        80\n",
      "    HS_Gender       0.75      0.10      0.18        60\n",
      "     HS_Other       0.77      0.77      0.77       746\n",
      "      HS_Weak       0.73      0.72      0.72       685\n",
      "  HS_Moderate       0.71      0.59      0.64       352\n",
      "    HS_Strong       0.84      0.62      0.71       105\n",
      "\n",
      "    micro avg       0.81      0.75      0.78      5634\n",
      "    macro avg       0.79      0.60      0.65      5634\n",
      " weighted avg       0.80      0.75      0.77      5634\n",
      "  samples avg       0.45      0.43      0.42      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 2\n",
      "Sampling duration: 8.200261354446411 seconds\n",
      "\n",
      "Fold 3 - New train size: 9218\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 9218 samples...\n",
      "Epoch 1/10, Train Loss: 0.3857, Accuracy: 0.8845, F1 Micro: 0.6118, F1 Macro: 0.3005\n",
      "Epoch 2/10, Train Loss: 0.2667, Accuracy: 0.9059, F1 Micro: 0.723, F1 Macro: 0.5052\n",
      "Epoch 3/10, Train Loss: 0.2183, Accuracy: 0.9151, F1 Micro: 0.7527, F1 Macro: 0.5789\n",
      "Epoch 4/10, Train Loss: 0.1817, Accuracy: 0.9199, F1 Micro: 0.7673, F1 Macro: 0.6062\n",
      "Epoch 5/10, Train Loss: 0.1521, Accuracy: 0.9147, F1 Micro: 0.7627, F1 Macro: 0.6209\n",
      "Epoch 6/10, Train Loss: 0.1263, Accuracy: 0.9211, F1 Micro: 0.772, F1 Macro: 0.6446\n",
      "Epoch 7/10, Train Loss: 0.1078, Accuracy: 0.9208, F1 Micro: 0.7666, F1 Macro: 0.6427\n",
      "Epoch 8/10, Train Loss: 0.0894, Accuracy: 0.9204, F1 Micro: 0.7778, F1 Macro: 0.672\n",
      "Epoch 9/10, Train Loss: 0.0788, Accuracy: 0.9205, F1 Micro: 0.7759, F1 Macro: 0.683\n",
      "Epoch 10/10, Train Loss: 0.0672, Accuracy: 0.9245, F1 Micro: 0.7747, F1 Macro: 0.6842\n",
      "Best result for 9218 samples: F1 Micro: 0.7778\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.81      0.89      0.85      1142\n",
      "      Abusive       0.89      0.92      0.91      1026\n",
      "HS_Individual       0.68      0.81      0.74       723\n",
      "     HS_Group       0.75      0.66      0.71       419\n",
      "  HS_Religion       0.72      0.69      0.70       177\n",
      "      HS_Race       0.83      0.71      0.76       119\n",
      "  HS_Physical       0.69      0.14      0.23        80\n",
      "    HS_Gender       0.65      0.18      0.29        60\n",
      "     HS_Other       0.73      0.82      0.77       746\n",
      "      HS_Weak       0.66      0.78      0.71       685\n",
      "  HS_Moderate       0.68      0.59      0.63       352\n",
      "    HS_Strong       0.82      0.71      0.77       105\n",
      "\n",
      "    micro avg       0.76      0.80      0.78      5634\n",
      "    macro avg       0.74      0.66      0.67      5634\n",
      " weighted avg       0.76      0.80      0.77      5634\n",
      "  samples avg       0.45      0.45      0.44      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Acquired samples: 200\n",
      "Sampling duration: 8.269658327102661 seconds\n",
      "\n",
      "Fold 3 - New train size: 9418\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 9418 samples...\n",
      "Epoch 1/10, Train Loss: 0.3816, Accuracy: 0.8858, F1 Micro: 0.6323, F1 Macro: 0.3126\n",
      "Epoch 2/10, Train Loss: 0.2692, Accuracy: 0.9086, F1 Micro: 0.7298, F1 Macro: 0.53\n",
      "Epoch 3/10, Train Loss: 0.2245, Accuracy: 0.9161, F1 Micro: 0.7417, F1 Macro: 0.5704\n",
      "Epoch 4/10, Train Loss: 0.1849, Accuracy: 0.9171, F1 Micro: 0.7648, F1 Macro: 0.6152\n",
      "Epoch 5/10, Train Loss: 0.1531, Accuracy: 0.9225, F1 Micro: 0.771, F1 Macro: 0.6174\n",
      "Epoch 6/10, Train Loss: 0.1307, Accuracy: 0.9169, F1 Micro: 0.769, F1 Macro: 0.6337\n",
      "Epoch 7/10, Train Loss: 0.1059, Accuracy: 0.9231, F1 Micro: 0.7766, F1 Macro: 0.6617\n",
      "Epoch 8/10, Train Loss: 0.0925, Accuracy: 0.9218, F1 Micro: 0.7711, F1 Macro: 0.6555\n",
      "Epoch 9/10, Train Loss: 0.0775, Accuracy: 0.9218, F1 Micro: 0.7754, F1 Macro: 0.6706\n",
      "Epoch 10/10, Train Loss: 0.0655, Accuracy: 0.9225, F1 Micro: 0.7785, F1 Macro: 0.7013\n",
      "Best result for 9418 samples: F1 Micro: 0.7785\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.87      0.85      1142\n",
      "      Abusive       0.89      0.93      0.91      1026\n",
      "HS_Individual       0.71      0.76      0.73       723\n",
      "     HS_Group       0.74      0.66      0.70       419\n",
      "  HS_Religion       0.74      0.61      0.67       177\n",
      "      HS_Race       0.80      0.71      0.75       119\n",
      "  HS_Physical       0.64      0.34      0.44        80\n",
      "    HS_Gender       0.65      0.37      0.47        60\n",
      "     HS_Other       0.77      0.79      0.78       746\n",
      "      HS_Weak       0.68      0.74      0.71       685\n",
      "  HS_Moderate       0.68      0.59      0.63       352\n",
      "    HS_Strong       0.84      0.72      0.78       105\n",
      "\n",
      "    micro avg       0.78      0.78      0.78      5634\n",
      "    macro avg       0.75      0.67      0.70      5634\n",
      " weighted avg       0.78      0.78      0.78      5634\n",
      "  samples avg       0.45      0.45      0.43      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Acquired samples: 200\n",
      "Sampling duration: 6.968152284622192 seconds\n",
      "\n",
      "Fold 3 - New train size: 9618\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 9618 samples...\n",
      "Epoch 1/10, Train Loss: 0.3804, Accuracy: 0.8853, F1 Micro: 0.6551, F1 Macro: 0.3322\n",
      "Epoch 2/10, Train Loss: 0.2702, Accuracy: 0.9079, F1 Micro: 0.7306, F1 Macro: 0.5218\n",
      "Epoch 3/10, Train Loss: 0.2192, Accuracy: 0.9177, F1 Micro: 0.743, F1 Macro: 0.5575\n",
      "Epoch 4/10, Train Loss: 0.1807, Accuracy: 0.9208, F1 Micro: 0.7662, F1 Macro: 0.6059\n",
      "Epoch 5/10, Train Loss: 0.1468, Accuracy: 0.918, F1 Micro: 0.7666, F1 Macro: 0.6233\n",
      "Epoch 6/10, Train Loss: 0.1289, Accuracy: 0.9196, F1 Micro: 0.7731, F1 Macro: 0.6525\n",
      "Epoch 7/10, Train Loss: 0.1018, Accuracy: 0.9208, F1 Micro: 0.7746, F1 Macro: 0.6707\n",
      "Epoch 8/10, Train Loss: 0.0893, Accuracy: 0.919, F1 Micro: 0.7728, F1 Macro: 0.6743\n",
      "Epoch 9/10, Train Loss: 0.0759, Accuracy: 0.9219, F1 Micro: 0.7766, F1 Macro: 0.6851\n",
      "Epoch 10/10, Train Loss: 0.0648, Accuracy: 0.9208, F1 Micro: 0.7744, F1 Macro: 0.6962\n",
      "Best result for 9618 samples: F1 Micro: 0.7766\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.87      0.85      1142\n",
      "      Abusive       0.89      0.92      0.91      1026\n",
      "HS_Individual       0.69      0.77      0.73       723\n",
      "     HS_Group       0.77      0.63      0.69       419\n",
      "  HS_Religion       0.74      0.60      0.66       177\n",
      "      HS_Race       0.83      0.72      0.77       119\n",
      "  HS_Physical       0.76      0.28      0.40        80\n",
      "    HS_Gender       0.65      0.25      0.36        60\n",
      "     HS_Other       0.77      0.81      0.79       746\n",
      "      HS_Weak       0.67      0.76      0.71       685\n",
      "  HS_Moderate       0.69      0.57      0.62       352\n",
      "    HS_Strong       0.83      0.65      0.73       105\n",
      "\n",
      "    micro avg       0.78      0.78      0.78      5634\n",
      "    macro avg       0.76      0.65      0.69      5634\n",
      " weighted avg       0.78      0.78      0.77      5634\n",
      "  samples avg       0.45      0.45      0.43      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Acquired samples: 200\n",
      "Sampling duration: 6.062388181686401 seconds\n",
      "\n",
      "Fold 3 - New train size: 9818\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 9818 samples...\n",
      "Epoch 1/10, Train Loss: 0.3787, Accuracy: 0.8877, F1 Micro: 0.629, F1 Macro: 0.3154\n",
      "Epoch 2/10, Train Loss: 0.2637, Accuracy: 0.909, F1 Micro: 0.7084, F1 Macro: 0.5136\n",
      "Epoch 3/10, Train Loss: 0.2163, Accuracy: 0.9187, F1 Micro: 0.7577, F1 Macro: 0.5951\n",
      "Epoch 4/10, Train Loss: 0.1816, Accuracy: 0.9227, F1 Micro: 0.7734, F1 Macro: 0.6104\n",
      "Epoch 5/10, Train Loss: 0.1542, Accuracy: 0.9229, F1 Micro: 0.7689, F1 Macro: 0.626\n",
      "Epoch 6/10, Train Loss: 0.1254, Accuracy: 0.9245, F1 Micro: 0.7843, F1 Macro: 0.6799\n",
      "Epoch 7/10, Train Loss: 0.1068, Accuracy: 0.9222, F1 Micro: 0.7733, F1 Macro: 0.6504\n",
      "Epoch 8/10, Train Loss: 0.0902, Accuracy: 0.9209, F1 Micro: 0.7802, F1 Macro: 0.6909\n",
      "Epoch 9/10, Train Loss: 0.0806, Accuracy: 0.9225, F1 Micro: 0.7742, F1 Macro: 0.6591\n",
      "Epoch 10/10, Train Loss: 0.0634, Accuracy: 0.9206, F1 Micro: 0.7755, F1 Macro: 0.6953\n",
      "Best result for 9818 samples: F1 Micro: 0.7843\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.89      0.86      1142\n",
      "      Abusive       0.90      0.92      0.91      1026\n",
      "HS_Individual       0.73      0.76      0.74       723\n",
      "     HS_Group       0.72      0.71      0.72       419\n",
      "  HS_Religion       0.76      0.58      0.66       177\n",
      "      HS_Race       0.78      0.76      0.77       119\n",
      "  HS_Physical       0.65      0.14      0.23        80\n",
      "    HS_Gender       0.62      0.25      0.36        60\n",
      "     HS_Other       0.78      0.79      0.78       746\n",
      "      HS_Weak       0.71      0.73      0.72       685\n",
      "  HS_Moderate       0.67      0.65      0.66       352\n",
      "    HS_Strong       0.80      0.72      0.76       105\n",
      "\n",
      "    micro avg       0.78      0.79      0.78      5634\n",
      "    macro avg       0.74      0.66      0.68      5634\n",
      " weighted avg       0.78      0.79      0.78      5634\n",
      "  samples avg       0.45      0.45      0.43      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.049261093139648 seconds\n",
      "\n",
      "Fold 3 - New train size: 10018\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 10018 samples...\n",
      "Epoch 1/10, Train Loss: 0.3779, Accuracy: 0.8895, F1 Micro: 0.6595, F1 Macro: 0.3664\n",
      "Epoch 2/10, Train Loss: 0.2615, Accuracy: 0.9101, F1 Micro: 0.7235, F1 Macro: 0.5312\n",
      "Epoch 3/10, Train Loss: 0.2106, Accuracy: 0.9175, F1 Micro: 0.7448, F1 Macro: 0.5853\n",
      "Epoch 4/10, Train Loss: 0.1782, Accuracy: 0.9207, F1 Micro: 0.7705, F1 Macro: 0.6151\n",
      "Epoch 5/10, Train Loss: 0.1462, Accuracy: 0.9232, F1 Micro: 0.7664, F1 Macro: 0.6176\n",
      "Epoch 6/10, Train Loss: 0.1233, Accuracy: 0.9172, F1 Micro: 0.7726, F1 Macro: 0.6469\n",
      "Epoch 7/10, Train Loss: 0.1046, Accuracy: 0.9251, F1 Micro: 0.7767, F1 Macro: 0.6723\n",
      "Epoch 8/10, Train Loss: 0.0844, Accuracy: 0.9217, F1 Micro: 0.7755, F1 Macro: 0.6612\n",
      "Epoch 9/10, Train Loss: 0.0755, Accuracy: 0.9215, F1 Micro: 0.7773, F1 Macro: 0.6887\n",
      "Epoch 10/10, Train Loss: 0.0634, Accuracy: 0.9249, F1 Micro: 0.7815, F1 Macro: 0.6941\n",
      "Best result for 10018 samples: F1 Micro: 0.7815\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.86      0.86      1142\n",
      "      Abusive       0.91      0.92      0.91      1026\n",
      "HS_Individual       0.73      0.75      0.74       723\n",
      "     HS_Group       0.74      0.65      0.69       419\n",
      "  HS_Religion       0.78      0.56      0.65       177\n",
      "      HS_Race       0.81      0.72      0.76       119\n",
      "  HS_Physical       0.81      0.28      0.41        80\n",
      "    HS_Gender       0.76      0.32      0.45        60\n",
      "     HS_Other       0.77      0.81      0.79       746\n",
      "      HS_Weak       0.71      0.73      0.72       685\n",
      "  HS_Moderate       0.68      0.58      0.62       352\n",
      "    HS_Strong       0.84      0.65      0.73       105\n",
      "\n",
      "    micro avg       0.79      0.77      0.78      5634\n",
      "    macro avg       0.78      0.65      0.69      5634\n",
      " weighted avg       0.79      0.77      0.78      5634\n",
      "  samples avg       0.46      0.44      0.43      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Acquired samples: 200\n",
      "Sampling duration: 3.957111358642578 seconds\n",
      "\n",
      "Fold 3 - New train size: 10218\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 10218 samples...\n",
      "Epoch 1/10, Train Loss: 0.3742, Accuracy: 0.8859, F1 Micro: 0.6157, F1 Macro: 0.3012\n",
      "Epoch 2/10, Train Loss: 0.2565, Accuracy: 0.9101, F1 Micro: 0.7129, F1 Macro: 0.5204\n",
      "Epoch 3/10, Train Loss: 0.2123, Accuracy: 0.9182, F1 Micro: 0.7524, F1 Macro: 0.5773\n",
      "Epoch 4/10, Train Loss: 0.1732, Accuracy: 0.9198, F1 Micro: 0.7668, F1 Macro: 0.6032\n",
      "Epoch 5/10, Train Loss: 0.1493, Accuracy: 0.9228, F1 Micro: 0.7766, F1 Macro: 0.6364\n",
      "Epoch 6/10, Train Loss: 0.1261, Accuracy: 0.9249, F1 Micro: 0.7796, F1 Macro: 0.668\n",
      "Epoch 7/10, Train Loss: 0.1035, Accuracy: 0.9221, F1 Micro: 0.776, F1 Macro: 0.6766\n",
      "Epoch 8/10, Train Loss: 0.0878, Accuracy: 0.924, F1 Micro: 0.7793, F1 Macro: 0.6957\n",
      "Epoch 9/10, Train Loss: 0.0735, Accuracy: 0.9245, F1 Micro: 0.7863, F1 Macro: 0.698\n",
      "Epoch 10/10, Train Loss: 0.0639, Accuracy: 0.9238, F1 Micro: 0.7821, F1 Macro: 0.7039\n",
      "Best result for 10218 samples: F1 Micro: 0.7863\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.89      0.86      1142\n",
      "      Abusive       0.91      0.93      0.92      1026\n",
      "HS_Individual       0.71      0.79      0.75       723\n",
      "     HS_Group       0.73      0.67      0.70       419\n",
      "  HS_Religion       0.74      0.63      0.68       177\n",
      "      HS_Race       0.84      0.68      0.75       119\n",
      "  HS_Physical       0.81      0.26      0.40        80\n",
      "    HS_Gender       0.73      0.32      0.44        60\n",
      "     HS_Other       0.75      0.82      0.79       746\n",
      "      HS_Weak       0.68      0.77      0.72       685\n",
      "  HS_Moderate       0.67      0.62      0.64       352\n",
      "    HS_Strong       0.82      0.66      0.73       105\n",
      "\n",
      "    micro avg       0.78      0.79      0.79      5634\n",
      "    macro avg       0.77      0.67      0.70      5634\n",
      " weighted avg       0.78      0.79      0.78      5634\n",
      "  samples avg       0.45      0.45      0.44      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.8342745304107666 seconds\n",
      "\n",
      "Fold 3 - New train size: 10418\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 10418 samples...\n",
      "Epoch 1/10, Train Loss: 0.3714, Accuracy: 0.8912, F1 Micro: 0.662, F1 Macro: 0.3958\n",
      "Epoch 2/10, Train Loss: 0.2491, Accuracy: 0.9105, F1 Micro: 0.7323, F1 Macro: 0.5408\n",
      "Epoch 3/10, Train Loss: 0.2052, Accuracy: 0.9154, F1 Micro: 0.7631, F1 Macro: 0.5906\n",
      "Epoch 4/10, Train Loss: 0.1725, Accuracy: 0.9217, F1 Micro: 0.758, F1 Macro: 0.5669\n",
      "Epoch 5/10, Train Loss: 0.1409, Accuracy: 0.9263, F1 Micro: 0.7782, F1 Macro: 0.6444\n",
      "Epoch 6/10, Train Loss: 0.1188, Accuracy: 0.9236, F1 Micro: 0.778, F1 Macro: 0.6444\n",
      "Epoch 7/10, Train Loss: 0.0964, Accuracy: 0.92, F1 Micro: 0.7749, F1 Macro: 0.6631\n",
      "Epoch 8/10, Train Loss: 0.0827, Accuracy: 0.9213, F1 Micro: 0.7724, F1 Macro: 0.6719\n",
      "Epoch 9/10, Train Loss: 0.0708, Accuracy: 0.9214, F1 Micro: 0.777, F1 Macro: 0.6824\n",
      "Epoch 10/10, Train Loss: 0.0593, Accuracy: 0.9245, F1 Micro: 0.7803, F1 Macro: 0.6948\n",
      "Best result for 10418 samples: F1 Micro: 0.7803\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.86      0.86      1142\n",
      "      Abusive       0.92      0.91      0.92      1026\n",
      "HS_Individual       0.71      0.76      0.74       723\n",
      "     HS_Group       0.75      0.61      0.67       419\n",
      "  HS_Religion       0.75      0.64      0.69       177\n",
      "      HS_Race       0.84      0.66      0.74       119\n",
      "  HS_Physical       0.82      0.29      0.43        80\n",
      "    HS_Gender       0.80      0.33      0.47        60\n",
      "     HS_Other       0.77      0.81      0.79       746\n",
      "      HS_Weak       0.69      0.74      0.71       685\n",
      "  HS_Moderate       0.68      0.54      0.60       352\n",
      "    HS_Strong       0.83      0.65      0.73       105\n",
      "\n",
      "    micro avg       0.79      0.77      0.78      5634\n",
      "    macro avg       0.79      0.65      0.69      5634\n",
      " weighted avg       0.79      0.77      0.78      5634\n",
      "  samples avg       0.45      0.44      0.43      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Acquired samples: 117\n",
      "Sampling duration: 1.4433541297912598 seconds\n",
      "\n",
      "Fold 3 - New train size: 10535\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 10535 samples...\n",
      "Epoch 1/10, Train Loss: 0.3672, Accuracy: 0.8901, F1 Micro: 0.6397, F1 Macro: 0.3467\n",
      "Epoch 2/10, Train Loss: 0.2514, Accuracy: 0.9138, F1 Micro: 0.7336, F1 Macro: 0.5566\n",
      "Epoch 3/10, Train Loss: 0.2022, Accuracy: 0.9161, F1 Micro: 0.7587, F1 Macro: 0.5784\n",
      "Epoch 4/10, Train Loss: 0.1677, Accuracy: 0.9224, F1 Micro: 0.7746, F1 Macro: 0.6103\n",
      "Epoch 5/10, Train Loss: 0.1434, Accuracy: 0.9224, F1 Micro: 0.7744, F1 Macro: 0.643\n",
      "Epoch 6/10, Train Loss: 0.1176, Accuracy: 0.9245, F1 Micro: 0.781, F1 Macro: 0.665\n",
      "Epoch 7/10, Train Loss: 0.0969, Accuracy: 0.9228, F1 Micro: 0.7759, F1 Macro: 0.6682\n",
      "Epoch 8/10, Train Loss: 0.0822, Accuracy: 0.9228, F1 Micro: 0.7791, F1 Macro: 0.6932\n",
      "Epoch 9/10, Train Loss: 0.071, Accuracy: 0.9232, F1 Micro: 0.7771, F1 Macro: 0.6864\n",
      "Epoch 10/10, Train Loss: 0.0606, Accuracy: 0.9219, F1 Micro: 0.7785, F1 Macro: 0.707\n",
      "Best result for 10535 samples: F1 Micro: 0.781\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.88      0.86      1142\n",
      "      Abusive       0.91      0.90      0.90      1026\n",
      "HS_Individual       0.75      0.74      0.74       723\n",
      "     HS_Group       0.72      0.68      0.70       419\n",
      "  HS_Religion       0.75      0.62      0.68       177\n",
      "      HS_Race       0.79      0.71      0.75       119\n",
      "  HS_Physical       0.78      0.09      0.16        80\n",
      "    HS_Gender       0.85      0.18      0.30        60\n",
      "     HS_Other       0.76      0.80      0.78       746\n",
      "      HS_Weak       0.73      0.72      0.72       685\n",
      "  HS_Moderate       0.66      0.62      0.64       352\n",
      "    HS_Strong       0.82      0.67      0.74       105\n",
      "\n",
      "    micro avg       0.79      0.77      0.78      5634\n",
      "    macro avg       0.78      0.64      0.67      5634\n",
      " weighted avg       0.79      0.77      0.77      5634\n",
      "  samples avg       0.44      0.44      0.42      5634\n",
      "\n",
      "\n",
      "FOLD 3 COMPLETED in 6572.95 seconds\n",
      "===============================================\n",
      "STARTING FOLD 4/5\n",
      "===============================================\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 658 samples...\n",
      "Epoch 1/10, Train Loss: 0.5946, Accuracy: 0.8335, F1 Micro: 0.1121, F1 Macro: 0.0446\n",
      "Epoch 2/10, Train Loss: 0.4551, Accuracy: 0.831, F1 Micro: 0.0309, F1 Macro: 0.0129\n",
      "Epoch 3/10, Train Loss: 0.3992, Accuracy: 0.8345, F1 Micro: 0.0736, F1 Macro: 0.0279\n",
      "Epoch 4/10, Train Loss: 0.365, Accuracy: 0.8375, F1 Micro: 0.1139, F1 Macro: 0.0398\n",
      "Epoch 5/10, Train Loss: 0.3536, Accuracy: 0.8479, F1 Micro: 0.2404, F1 Macro: 0.0824\n",
      "Epoch 6/10, Train Loss: 0.3469, Accuracy: 0.8564, F1 Micro: 0.3297, F1 Macro: 0.1173\n",
      "Epoch 7/10, Train Loss: 0.3272, Accuracy: 0.8666, F1 Micro: 0.429, F1 Macro: 0.1693\n",
      "Epoch 8/10, Train Loss: 0.3093, Accuracy: 0.8769, F1 Micro: 0.534, F1 Macro: 0.2344\n",
      "Epoch 9/10, Train Loss: 0.2709, Accuracy: 0.8785, F1 Micro: 0.5631, F1 Macro: 0.2606\n",
      "Epoch 10/10, Train Loss: 0.261, Accuracy: 0.8819, F1 Micro: 0.5885, F1 Macro: 0.2918\n",
      "Best result for 658 samples: F1 Micro: 0.5885\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.75      0.77      1107\n",
      "      Abusive       0.82      0.74      0.78      1030\n",
      "HS_Individual       0.64      0.49      0.55       729\n",
      "     HS_Group       0.61      0.12      0.21       378\n",
      "  HS_Religion       0.00      0.00      0.00       167\n",
      "      HS_Race       0.00      0.00      0.00        88\n",
      "  HS_Physical       0.00      0.00      0.00        74\n",
      "    HS_Gender       0.00      0.00      0.00        75\n",
      "     HS_Other       0.66      0.58      0.62       744\n",
      "      HS_Weak       0.60      0.41      0.49       690\n",
      "  HS_Moderate       0.48      0.05      0.09       338\n",
      "    HS_Strong       0.00      0.00      0.00        79\n",
      "\n",
      "    micro avg       0.72      0.50      0.59      5499\n",
      "    macro avg       0.38      0.26      0.29      5499\n",
      " weighted avg       0.64      0.50      0.54      5499\n",
      "  samples avg       0.38      0.29      0.30      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 988\n",
      "Sampling duration: 53.33679270744324 seconds\n",
      "\n",
      "Fold 4 - New train size: 1646\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 1646 samples...\n",
      "Epoch 1/10, Train Loss: 0.5109, Accuracy: 0.8296, F1 Micro: 0.0058, F1 Macro: 0.0025\n",
      "Epoch 2/10, Train Loss: 0.3821, Accuracy: 0.8314, F1 Micro: 0.0307, F1 Macro: 0.0126\n",
      "Epoch 3/10, Train Loss: 0.3557, Accuracy: 0.8553, F1 Micro: 0.3214, F1 Macro: 0.1174\n",
      "Epoch 4/10, Train Loss: 0.3195, Accuracy: 0.8715, F1 Micro: 0.4698, F1 Macro: 0.1929\n",
      "Epoch 5/10, Train Loss: 0.2865, Accuracy: 0.8757, F1 Micro: 0.4946, F1 Macro: 0.2272\n",
      "Epoch 6/10, Train Loss: 0.2602, Accuracy: 0.8866, F1 Micro: 0.6296, F1 Macro: 0.3226\n",
      "Epoch 7/10, Train Loss: 0.2309, Accuracy: 0.891, F1 Micro: 0.6122, F1 Macro: 0.3272\n",
      "Epoch 8/10, Train Loss: 0.2187, Accuracy: 0.892, F1 Micro: 0.6599, F1 Macro: 0.3673\n",
      "Epoch 9/10, Train Loss: 0.1915, Accuracy: 0.8959, F1 Micro: 0.6552, F1 Macro: 0.3689\n",
      "Epoch 10/10, Train Loss: 0.1677, Accuracy: 0.8952, F1 Micro: 0.6547, F1 Macro: 0.3652\n",
      "Best result for 1646 samples: F1 Micro: 0.6599\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.79      0.81      0.80      1107\n",
      "      Abusive       0.84      0.82      0.83      1030\n",
      "HS_Individual       0.62      0.63      0.62       729\n",
      "     HS_Group       0.69      0.35      0.46       378\n",
      "  HS_Religion       0.00      0.00      0.00       167\n",
      "      HS_Race       0.75      0.03      0.07        88\n",
      "  HS_Physical       0.00      0.00      0.00        74\n",
      "    HS_Gender       0.00      0.00      0.00        75\n",
      "     HS_Other       0.65      0.74      0.69       744\n",
      "      HS_Weak       0.59      0.62      0.61       690\n",
      "  HS_Moderate       0.64      0.20      0.30       338\n",
      "    HS_Strong       1.00      0.01      0.02        79\n",
      "\n",
      "    micro avg       0.71      0.61      0.66      5499\n",
      "    macro avg       0.55      0.35      0.37      5499\n",
      " weighted avg       0.68      0.61      0.62      5499\n",
      "  samples avg       0.39      0.35      0.35      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 889\n",
      "Sampling duration: 47.35412383079529 seconds\n",
      "\n",
      "Fold 4 - New train size: 2535\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 2535 samples...\n",
      "Epoch 1/10, Train Loss: 0.4719, Accuracy: 0.8305, F1 Micro: 0.0197, F1 Macro: 0.0083\n",
      "Epoch 2/10, Train Loss: 0.3615, Accuracy: 0.8529, F1 Micro: 0.291, F1 Macro: 0.1065\n",
      "Epoch 3/10, Train Loss: 0.3264, Accuracy: 0.8765, F1 Micro: 0.5875, F1 Macro: 0.2566\n",
      "Epoch 4/10, Train Loss: 0.2894, Accuracy: 0.8883, F1 Micro: 0.6418, F1 Macro: 0.32\n",
      "Epoch 5/10, Train Loss: 0.2525, Accuracy: 0.8944, F1 Micro: 0.6389, F1 Macro: 0.3443\n",
      "Epoch 6/10, Train Loss: 0.2168, Accuracy: 0.8977, F1 Micro: 0.6897, F1 Macro: 0.4059\n",
      "Epoch 7/10, Train Loss: 0.201, Accuracy: 0.9018, F1 Micro: 0.6876, F1 Macro: 0.442\n",
      "Epoch 8/10, Train Loss: 0.1711, Accuracy: 0.9032, F1 Micro: 0.6699, F1 Macro: 0.4463\n",
      "Epoch 9/10, Train Loss: 0.1452, Accuracy: 0.9074, F1 Micro: 0.7132, F1 Macro: 0.5073\n",
      "Epoch 10/10, Train Loss: 0.1288, Accuracy: 0.909, F1 Micro: 0.7138, F1 Macro: 0.505\n",
      "Best result for 2535 samples: F1 Micro: 0.7138\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.80      0.82      1107\n",
      "      Abusive       0.89      0.85      0.87      1030\n",
      "HS_Individual       0.70      0.65      0.67       729\n",
      "     HS_Group       0.71      0.54      0.61       378\n",
      "  HS_Religion       0.76      0.20      0.32       167\n",
      "      HS_Race       0.85      0.33      0.48        88\n",
      "  HS_Physical       0.00      0.00      0.00        74\n",
      "    HS_Gender       0.00      0.00      0.00        75\n",
      "     HS_Other       0.70      0.76      0.73       744\n",
      "      HS_Weak       0.68      0.62      0.65       690\n",
      "  HS_Moderate       0.66      0.44      0.53       338\n",
      "    HS_Strong       0.90      0.24      0.38        79\n",
      "\n",
      "    micro avg       0.77      0.67      0.71      5499\n",
      "    macro avg       0.64      0.45      0.51      5499\n",
      " weighted avg       0.75      0.67      0.69      5499\n",
      "  samples avg       0.41      0.37      0.37      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 800\n",
      "Sampling duration: 43.24069690704346 seconds\n",
      "\n",
      "Fold 4 - New train size: 3335\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 3335 samples...\n",
      "Epoch 1/10, Train Loss: 0.4541, Accuracy: 0.8314, F1 Micro: 0.0314, F1 Macro: 0.0128\n",
      "Epoch 2/10, Train Loss: 0.3562, Accuracy: 0.8729, F1 Micro: 0.5297, F1 Macro: 0.2099\n",
      "Epoch 3/10, Train Loss: 0.3085, Accuracy: 0.8872, F1 Micro: 0.6202, F1 Macro: 0.3028\n",
      "Epoch 4/10, Train Loss: 0.2671, Accuracy: 0.8967, F1 Micro: 0.6642, F1 Macro: 0.3888\n",
      "Epoch 5/10, Train Loss: 0.2354, Accuracy: 0.9036, F1 Micro: 0.6954, F1 Macro: 0.437\n",
      "Epoch 6/10, Train Loss: 0.1958, Accuracy: 0.9081, F1 Micro: 0.7043, F1 Macro: 0.4861\n",
      "Epoch 7/10, Train Loss: 0.1734, Accuracy: 0.9114, F1 Micro: 0.7177, F1 Macro: 0.5316\n",
      "Epoch 8/10, Train Loss: 0.1467, Accuracy: 0.9133, F1 Micro: 0.7214, F1 Macro: 0.5225\n",
      "Epoch 9/10, Train Loss: 0.1239, Accuracy: 0.9159, F1 Micro: 0.7351, F1 Macro: 0.5676\n",
      "Epoch 10/10, Train Loss: 0.1028, Accuracy: 0.9168, F1 Micro: 0.7368, F1 Macro: 0.5535\n",
      "Best result for 3335 samples: F1 Micro: 0.7368\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.87      0.79      0.82      1107\n",
      "      Abusive       0.89      0.89      0.89      1030\n",
      "HS_Individual       0.74      0.64      0.69       729\n",
      "     HS_Group       0.72      0.58      0.64       378\n",
      "  HS_Religion       0.81      0.43      0.56       167\n",
      "      HS_Race       0.82      0.42      0.56        88\n",
      "  HS_Physical       0.00      0.00      0.00        74\n",
      "    HS_Gender       0.00      0.00      0.00        75\n",
      "     HS_Other       0.78      0.73      0.75       744\n",
      "      HS_Weak       0.72      0.64      0.67       690\n",
      "  HS_Moderate       0.65      0.51      0.57       338\n",
      "    HS_Strong       0.84      0.34      0.49        79\n",
      "\n",
      "    micro avg       0.80      0.68      0.74      5499\n",
      "    macro avg       0.65      0.50      0.55      5499\n",
      " weighted avg       0.77      0.68      0.72      5499\n",
      "  samples avg       0.43      0.39      0.39      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 720\n",
      "Sampling duration: 39.084150314331055 seconds\n",
      "\n",
      "Fold 4 - New train size: 4055\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 4055 samples...\n",
      "Epoch 1/10, Train Loss: 0.4431, Accuracy: 0.8409, F1 Micro: 0.1565, F1 Macro: 0.057\n",
      "Epoch 2/10, Train Loss: 0.3464, Accuracy: 0.881, F1 Micro: 0.5871, F1 Macro: 0.2615\n",
      "Epoch 3/10, Train Loss: 0.2945, Accuracy: 0.8955, F1 Micro: 0.6564, F1 Macro: 0.3644\n",
      "Epoch 4/10, Train Loss: 0.2447, Accuracy: 0.8986, F1 Micro: 0.6468, F1 Macro: 0.3865\n",
      "Epoch 5/10, Train Loss: 0.2102, Accuracy: 0.9097, F1 Micro: 0.7188, F1 Macro: 0.4943\n",
      "Epoch 6/10, Train Loss: 0.1791, Accuracy: 0.915, F1 Micro: 0.7361, F1 Macro: 0.5475\n",
      "Epoch 7/10, Train Loss: 0.1521, Accuracy: 0.9161, F1 Micro: 0.7382, F1 Macro: 0.5789\n",
      "Epoch 8/10, Train Loss: 0.1384, Accuracy: 0.9176, F1 Micro: 0.7488, F1 Macro: 0.5749\n",
      "Epoch 9/10, Train Loss: 0.1109, Accuracy: 0.9173, F1 Micro: 0.7469, F1 Macro: 0.5692\n",
      "Epoch 10/10, Train Loss: 0.0962, Accuracy: 0.9175, F1 Micro: 0.7492, F1 Macro: 0.5873\n",
      "Best result for 4055 samples: F1 Micro: 0.7492\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.83      0.84      1107\n",
      "      Abusive       0.88      0.90      0.89      1030\n",
      "HS_Individual       0.73      0.67      0.70       729\n",
      "     HS_Group       0.68      0.63      0.66       378\n",
      "  HS_Religion       0.75      0.51      0.61       167\n",
      "      HS_Race       0.81      0.53      0.64        88\n",
      "  HS_Physical       0.00      0.00      0.00        74\n",
      "    HS_Gender       0.00      0.00      0.00        75\n",
      "     HS_Other       0.75      0.78      0.77       744\n",
      "      HS_Weak       0.70      0.66      0.68       690\n",
      "  HS_Moderate       0.62      0.56      0.59       338\n",
      "    HS_Strong       0.82      0.58      0.68        79\n",
      "\n",
      "    micro avg       0.78      0.72      0.75      5499\n",
      "    macro avg       0.63      0.55      0.59      5499\n",
      " weighted avg       0.75      0.72      0.74      5499\n",
      "  samples avg       0.43      0.40      0.40      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 648\n",
      "Sampling duration: 35.34443235397339 seconds\n",
      "\n",
      "Fold 4 - New train size: 4703\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 4703 samples...\n",
      "Epoch 1/10, Train Loss: 0.4351, Accuracy: 0.8521, F1 Micro: 0.2939, F1 Macro: 0.0975\n",
      "Epoch 2/10, Train Loss: 0.3359, Accuracy: 0.885, F1 Micro: 0.6275, F1 Macro: 0.2947\n",
      "Epoch 3/10, Train Loss: 0.2807, Accuracy: 0.8951, F1 Micro: 0.6879, F1 Macro: 0.3936\n",
      "Epoch 4/10, Train Loss: 0.2362, Accuracy: 0.9091, F1 Micro: 0.7068, F1 Macro: 0.4921\n",
      "Epoch 5/10, Train Loss: 0.2027, Accuracy: 0.9141, F1 Micro: 0.7271, F1 Macro: 0.5445\n",
      "Epoch 6/10, Train Loss: 0.1731, Accuracy: 0.9165, F1 Micro: 0.7432, F1 Macro: 0.5746\n",
      "Epoch 7/10, Train Loss: 0.1453, Accuracy: 0.9179, F1 Micro: 0.7511, F1 Macro: 0.5757\n",
      "Epoch 8/10, Train Loss: 0.1283, Accuracy: 0.9184, F1 Micro: 0.7384, F1 Macro: 0.5642\n",
      "Epoch 9/10, Train Loss: 0.1059, Accuracy: 0.9192, F1 Micro: 0.7484, F1 Macro: 0.5801\n",
      "Epoch 10/10, Train Loss: 0.093, Accuracy: 0.9163, F1 Micro: 0.7579, F1 Macro: 0.5915\n",
      "Best result for 4703 samples: F1 Micro: 0.7579\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.88      0.85      1107\n",
      "      Abusive       0.88      0.91      0.90      1030\n",
      "HS_Individual       0.68      0.76      0.72       729\n",
      "     HS_Group       0.69      0.63      0.66       378\n",
      "  HS_Religion       0.76      0.48      0.59       167\n",
      "      HS_Race       0.80      0.50      0.62        88\n",
      "  HS_Physical       1.00      0.03      0.05        74\n",
      "    HS_Gender       0.67      0.03      0.05        75\n",
      "     HS_Other       0.70      0.86      0.77       744\n",
      "      HS_Weak       0.67      0.75      0.70       690\n",
      "  HS_Moderate       0.60      0.58      0.59       338\n",
      "    HS_Strong       0.81      0.48      0.60        79\n",
      "\n",
      "    micro avg       0.75      0.77      0.76      5499\n",
      "    macro avg       0.76      0.57      0.59      5499\n",
      " weighted avg       0.75      0.77      0.75      5499\n",
      "  samples avg       0.44      0.43      0.42      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 584\n",
      "Sampling duration: 31.46752142906189 seconds\n",
      "\n",
      "Fold 4 - New train size: 5287\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 5287 samples...\n",
      "Epoch 1/10, Train Loss: 0.4251, Accuracy: 0.8554, F1 Micro: 0.32, F1 Macro: 0.11\n",
      "Epoch 2/10, Train Loss: 0.3273, Accuracy: 0.8843, F1 Micro: 0.5647, F1 Macro: 0.2698\n",
      "Epoch 3/10, Train Loss: 0.2715, Accuracy: 0.9, F1 Micro: 0.6996, F1 Macro: 0.4286\n",
      "Epoch 4/10, Train Loss: 0.2304, Accuracy: 0.9105, F1 Micro: 0.7316, F1 Macro: 0.5233\n",
      "Epoch 5/10, Train Loss: 0.199, Accuracy: 0.9165, F1 Micro: 0.7391, F1 Macro: 0.5401\n",
      "Epoch 6/10, Train Loss: 0.1602, Accuracy: 0.915, F1 Micro: 0.7474, F1 Macro: 0.5528\n",
      "Epoch 7/10, Train Loss: 0.1451, Accuracy: 0.919, F1 Micro: 0.7574, F1 Macro: 0.5879\n",
      "Epoch 8/10, Train Loss: 0.1137, Accuracy: 0.9196, F1 Micro: 0.7542, F1 Macro: 0.5897\n",
      "Epoch 9/10, Train Loss: 0.1019, Accuracy: 0.9198, F1 Micro: 0.7536, F1 Macro: 0.6\n",
      "Epoch 10/10, Train Loss: 0.0851, Accuracy: 0.9214, F1 Micro: 0.7543, F1 Macro: 0.5969\n",
      "Best result for 5287 samples: F1 Micro: 0.7574\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.86      0.85      1107\n",
      "      Abusive       0.88      0.90      0.89      1030\n",
      "HS_Individual       0.73      0.71      0.72       729\n",
      "     HS_Group       0.69      0.63      0.66       378\n",
      "  HS_Religion       0.81      0.47      0.59       167\n",
      "      HS_Race       0.73      0.56      0.63        88\n",
      "  HS_Physical       0.00      0.00      0.00        74\n",
      "    HS_Gender       0.00      0.00      0.00        75\n",
      "     HS_Other       0.71      0.83      0.76       744\n",
      "      HS_Weak       0.71      0.69      0.70       690\n",
      "  HS_Moderate       0.63      0.55      0.58       338\n",
      "    HS_Strong       0.84      0.54      0.66        79\n",
      "\n",
      "    micro avg       0.77      0.74      0.76      5499\n",
      "    macro avg       0.63      0.56      0.59      5499\n",
      " weighted avg       0.75      0.74      0.74      5499\n",
      "  samples avg       0.43      0.41      0.41      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 525\n",
      "Sampling duration: 28.16173243522644 seconds\n",
      "\n",
      "Fold 4 - New train size: 5812\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 5812 samples...\n",
      "Epoch 1/10, Train Loss: 0.4216, Accuracy: 0.8627, F1 Micro: 0.4095, F1 Macro: 0.1477\n",
      "Epoch 2/10, Train Loss: 0.3135, Accuracy: 0.893, F1 Micro: 0.6343, F1 Macro: 0.3212\n",
      "Epoch 3/10, Train Loss: 0.2633, Accuracy: 0.9066, F1 Micro: 0.7081, F1 Macro: 0.4837\n",
      "Epoch 4/10, Train Loss: 0.2259, Accuracy: 0.9115, F1 Micro: 0.7354, F1 Macro: 0.536\n",
      "Epoch 5/10, Train Loss: 0.1917, Accuracy: 0.9176, F1 Micro: 0.7552, F1 Macro: 0.5575\n",
      "Epoch 6/10, Train Loss: 0.1583, Accuracy: 0.9218, F1 Micro: 0.7535, F1 Macro: 0.577\n",
      "Epoch 7/10, Train Loss: 0.1352, Accuracy: 0.9227, F1 Micro: 0.7631, F1 Macro: 0.5924\n",
      "Epoch 8/10, Train Loss: 0.1137, Accuracy: 0.9224, F1 Micro: 0.7647, F1 Macro: 0.6034\n",
      "Epoch 9/10, Train Loss: 0.101, Accuracy: 0.9171, F1 Micro: 0.7655, F1 Macro: 0.6326\n",
      "Epoch 10/10, Train Loss: 0.086, Accuracy: 0.9218, F1 Micro: 0.7598, F1 Macro: 0.6009\n",
      "Best result for 5812 samples: F1 Micro: 0.7655\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.91      0.85      1107\n",
      "      Abusive       0.85      0.93      0.89      1030\n",
      "HS_Individual       0.69      0.77      0.73       729\n",
      "     HS_Group       0.65      0.69      0.67       378\n",
      "  HS_Religion       0.74      0.59      0.66       167\n",
      "      HS_Race       0.64      0.56      0.60        88\n",
      "  HS_Physical       0.60      0.08      0.14        74\n",
      "    HS_Gender       0.80      0.16      0.27        75\n",
      "     HS_Other       0.72      0.85      0.78       744\n",
      "      HS_Weak       0.68      0.75      0.71       690\n",
      "  HS_Moderate       0.60      0.62      0.61       338\n",
      "    HS_Strong       0.72      0.67      0.69        79\n",
      "\n",
      "    micro avg       0.74      0.79      0.77      5499\n",
      "    macro avg       0.71      0.63      0.63      5499\n",
      " weighted avg       0.74      0.79      0.76      5499\n",
      "  samples avg       0.44      0.44      0.43      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 473\n",
      "Sampling duration: 25.9173641204834 seconds\n",
      "\n",
      "Fold 4 - New train size: 6285\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 6285 samples...\n",
      "Epoch 1/10, Train Loss: 0.4184, Accuracy: 0.8646, F1 Micro: 0.4111, F1 Macro: 0.1524\n",
      "Epoch 2/10, Train Loss: 0.3082, Accuracy: 0.8968, F1 Micro: 0.6495, F1 Macro: 0.353\n",
      "Epoch 3/10, Train Loss: 0.2529, Accuracy: 0.9069, F1 Micro: 0.6907, F1 Macro: 0.4041\n",
      "Epoch 4/10, Train Loss: 0.2147, Accuracy: 0.9154, F1 Micro: 0.7428, F1 Macro: 0.5409\n",
      "Epoch 5/10, Train Loss: 0.184, Accuracy: 0.919, F1 Micro: 0.7437, F1 Macro: 0.5753\n",
      "Epoch 6/10, Train Loss: 0.1458, Accuracy: 0.9204, F1 Micro: 0.7667, F1 Macro: 0.599\n",
      "Epoch 7/10, Train Loss: 0.1287, Accuracy: 0.9177, F1 Micro: 0.7647, F1 Macro: 0.6166\n",
      "Epoch 8/10, Train Loss: 0.1097, Accuracy: 0.9201, F1 Micro: 0.7665, F1 Macro: 0.6098\n",
      "Epoch 9/10, Train Loss: 0.0904, Accuracy: 0.9189, F1 Micro: 0.7682, F1 Macro: 0.6385\n",
      "Epoch 10/10, Train Loss: 0.0804, Accuracy: 0.9194, F1 Micro: 0.7663, F1 Macro: 0.6316\n",
      "Best result for 6285 samples: F1 Micro: 0.7682\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.81      0.89      0.85      1107\n",
      "      Abusive       0.87      0.94      0.90      1030\n",
      "HS_Individual       0.70      0.76      0.73       729\n",
      "     HS_Group       0.66      0.68      0.67       378\n",
      "  HS_Religion       0.71      0.60      0.65       167\n",
      "      HS_Race       0.69      0.67      0.68        88\n",
      "  HS_Physical       0.54      0.09      0.16        74\n",
      "    HS_Gender       0.67      0.13      0.22        75\n",
      "     HS_Other       0.74      0.84      0.78       744\n",
      "      HS_Weak       0.67      0.74      0.70       690\n",
      "  HS_Moderate       0.61      0.63      0.62       338\n",
      "    HS_Strong       0.74      0.65      0.69        79\n",
      "\n",
      "    micro avg       0.75      0.79      0.77      5499\n",
      "    macro avg       0.70      0.64      0.64      5499\n",
      " weighted avg       0.75      0.79      0.76      5499\n",
      "  samples avg       0.45      0.44      0.43      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 299\n",
      "Sampling duration: 23.417627811431885 seconds\n",
      "\n",
      "Fold 4 - New train size: 6584\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 6584 samples...\n",
      "Epoch 1/10, Train Loss: 0.4098, Accuracy: 0.8695, F1 Micro: 0.4474, F1 Macro: 0.17\n",
      "Epoch 2/10, Train Loss: 0.304, Accuracy: 0.8986, F1 Micro: 0.67, F1 Macro: 0.3931\n",
      "Epoch 3/10, Train Loss: 0.2455, Accuracy: 0.91, F1 Micro: 0.7263, F1 Macro: 0.5053\n",
      "Epoch 4/10, Train Loss: 0.2112, Accuracy: 0.9175, F1 Micro: 0.7374, F1 Macro: 0.5347\n",
      "Epoch 5/10, Train Loss: 0.1792, Accuracy: 0.9185, F1 Micro: 0.7622, F1 Macro: 0.5935\n",
      "Epoch 6/10, Train Loss: 0.1472, Accuracy: 0.9223, F1 Micro: 0.7624, F1 Macro: 0.593\n",
      "Epoch 7/10, Train Loss: 0.1219, Accuracy: 0.9203, F1 Micro: 0.7618, F1 Macro: 0.6199\n",
      "Epoch 8/10, Train Loss: 0.1069, Accuracy: 0.9232, F1 Micro: 0.7622, F1 Macro: 0.5967\n",
      "Epoch 9/10, Train Loss: 0.0915, Accuracy: 0.9228, F1 Micro: 0.7704, F1 Macro: 0.6066\n",
      "Epoch 10/10, Train Loss: 0.0799, Accuracy: 0.9202, F1 Micro: 0.7643, F1 Macro: 0.6415\n",
      "Best result for 6584 samples: F1 Micro: 0.7704\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.86      0.85      1107\n",
      "      Abusive       0.88      0.92      0.90      1030\n",
      "HS_Individual       0.72      0.77      0.74       729\n",
      "     HS_Group       0.76      0.60      0.67       378\n",
      "  HS_Religion       0.77      0.48      0.59       167\n",
      "      HS_Race       0.77      0.49      0.60        88\n",
      "  HS_Physical       0.60      0.04      0.08        74\n",
      "    HS_Gender       0.75      0.04      0.08        75\n",
      "     HS_Other       0.75      0.82      0.78       744\n",
      "      HS_Weak       0.69      0.75      0.72       690\n",
      "  HS_Moderate       0.69      0.54      0.61       338\n",
      "    HS_Strong       0.80      0.57      0.67        79\n",
      "\n",
      "    micro avg       0.78      0.76      0.77      5499\n",
      "    macro avg       0.75      0.57      0.61      5499\n",
      " weighted avg       0.78      0.76      0.76      5499\n",
      "  samples avg       0.43      0.42      0.41      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Acquired samples: 396\n",
      "Sampling duration: 21.626103162765503 seconds\n",
      "\n",
      "Fold 4 - New train size: 6980\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 6980 samples...\n",
      "Epoch 1/10, Train Loss: 0.41, Accuracy: 0.8757, F1 Micro: 0.5148, F1 Macro: 0.2108\n",
      "Epoch 2/10, Train Loss: 0.2943, Accuracy: 0.8984, F1 Micro: 0.664, F1 Macro: 0.3583\n",
      "Epoch 3/10, Train Loss: 0.2508, Accuracy: 0.9078, F1 Micro: 0.7347, F1 Macro: 0.524\n",
      "Epoch 4/10, Train Loss: 0.2084, Accuracy: 0.9167, F1 Micro: 0.7511, F1 Macro: 0.5625\n",
      "Epoch 5/10, Train Loss: 0.1739, Accuracy: 0.9211, F1 Micro: 0.7544, F1 Macro: 0.585\n",
      "Epoch 6/10, Train Loss: 0.1423, Accuracy: 0.9186, F1 Micro: 0.7626, F1 Macro: 0.5982\n",
      "Epoch 7/10, Train Loss: 0.1223, Accuracy: 0.9236, F1 Micro: 0.7631, F1 Macro: 0.6007\n",
      "Epoch 8/10, Train Loss: 0.0998, Accuracy: 0.9225, F1 Micro: 0.7621, F1 Macro: 0.6102\n",
      "Epoch 9/10, Train Loss: 0.086, Accuracy: 0.9216, F1 Micro: 0.7687, F1 Macro: 0.6177\n",
      "Epoch 10/10, Train Loss: 0.0747, Accuracy: 0.9238, F1 Micro: 0.7773, F1 Macro: 0.6447\n",
      "Best result for 6980 samples: F1 Micro: 0.7773\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.88      0.86      1107\n",
      "      Abusive       0.88      0.92      0.90      1030\n",
      "HS_Individual       0.70      0.82      0.75       729\n",
      "     HS_Group       0.76      0.57      0.65       378\n",
      "  HS_Religion       0.77      0.56      0.65       167\n",
      "      HS_Race       0.75      0.65      0.70        88\n",
      "  HS_Physical       0.43      0.08      0.14        74\n",
      "    HS_Gender       0.83      0.20      0.32        75\n",
      "     HS_Other       0.76      0.82      0.79       744\n",
      "      HS_Weak       0.67      0.81      0.73       690\n",
      "  HS_Moderate       0.70      0.52      0.60       338\n",
      "    HS_Strong       0.81      0.54      0.65        79\n",
      "\n",
      "    micro avg       0.77      0.78      0.78      5499\n",
      "    macro avg       0.74      0.61      0.64      5499\n",
      " weighted avg       0.77      0.78      0.77      5499\n",
      "  samples avg       0.44      0.43      0.42      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Acquired samples: 356\n",
      "Sampling duration: 19.492146730422974 seconds\n",
      "\n",
      "Fold 4 - New train size: 7336\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 7336 samples...\n",
      "Epoch 1/10, Train Loss: 0.4068, Accuracy: 0.8789, F1 Micro: 0.5596, F1 Macro: 0.2411\n",
      "Epoch 2/10, Train Loss: 0.2918, Accuracy: 0.9009, F1 Micro: 0.6905, F1 Macro: 0.4151\n",
      "Epoch 3/10, Train Loss: 0.2407, Accuracy: 0.9104, F1 Micro: 0.7339, F1 Macro: 0.5045\n",
      "Epoch 4/10, Train Loss: 0.2066, Accuracy: 0.9187, F1 Micro: 0.7362, F1 Macro: 0.5236\n",
      "Epoch 5/10, Train Loss: 0.1727, Accuracy: 0.9201, F1 Micro: 0.7637, F1 Macro: 0.5797\n",
      "Epoch 6/10, Train Loss: 0.143, Accuracy: 0.9205, F1 Micro: 0.7366, F1 Macro: 0.5741\n",
      "Epoch 7/10, Train Loss: 0.1232, Accuracy: 0.9212, F1 Micro: 0.7622, F1 Macro: 0.6122\n",
      "Epoch 8/10, Train Loss: 0.0999, Accuracy: 0.9243, F1 Micro: 0.7758, F1 Macro: 0.6287\n",
      "Epoch 9/10, Train Loss: 0.0866, Accuracy: 0.9253, F1 Micro: 0.7818, F1 Macro: 0.6587\n",
      "Epoch 10/10, Train Loss: 0.0753, Accuracy: 0.9243, F1 Micro: 0.7782, F1 Macro: 0.6658\n",
      "Best result for 7336 samples: F1 Micro: 0.7818\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.88      0.86      1107\n",
      "      Abusive       0.89      0.91      0.90      1030\n",
      "HS_Individual       0.73      0.79      0.76       729\n",
      "     HS_Group       0.72      0.65      0.69       378\n",
      "  HS_Religion       0.76      0.62      0.68       167\n",
      "      HS_Race       0.75      0.64      0.69        88\n",
      "  HS_Physical       0.62      0.11      0.18        74\n",
      "    HS_Gender       0.79      0.20      0.32        75\n",
      "     HS_Other       0.76      0.82      0.79       744\n",
      "      HS_Weak       0.70      0.77      0.73       690\n",
      "  HS_Moderate       0.66      0.59      0.62       338\n",
      "    HS_Strong       0.73      0.65      0.68        79\n",
      "\n",
      "    micro avg       0.78      0.78      0.78      5499\n",
      "    macro avg       0.74      0.64      0.66      5499\n",
      " weighted avg       0.78      0.78      0.77      5499\n",
      "  samples avg       0.44      0.43      0.42      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Acquired samples: 320\n",
      "Sampling duration: 17.96099328994751 seconds\n",
      "\n",
      "Fold 4 - New train size: 7656\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 7656 samples...\n",
      "Epoch 1/10, Train Loss: 0.4027, Accuracy: 0.8826, F1 Micro: 0.5985, F1 Macro: 0.2715\n",
      "Epoch 2/10, Train Loss: 0.2875, Accuracy: 0.9024, F1 Micro: 0.6647, F1 Macro: 0.3976\n",
      "Epoch 3/10, Train Loss: 0.2358, Accuracy: 0.9134, F1 Micro: 0.7304, F1 Macro: 0.5298\n",
      "Epoch 4/10, Train Loss: 0.1968, Accuracy: 0.9211, F1 Micro: 0.7449, F1 Macro: 0.5688\n",
      "Epoch 5/10, Train Loss: 0.169, Accuracy: 0.9235, F1 Micro: 0.7734, F1 Macro: 0.602\n",
      "Epoch 6/10, Train Loss: 0.1385, Accuracy: 0.9245, F1 Micro: 0.779, F1 Macro: 0.6227\n",
      "Epoch 7/10, Train Loss: 0.1209, Accuracy: 0.925, F1 Micro: 0.7759, F1 Macro: 0.6166\n",
      "Epoch 8/10, Train Loss: 0.0987, Accuracy: 0.9247, F1 Micro: 0.7778, F1 Macro: 0.6427\n",
      "Epoch 9/10, Train Loss: 0.0828, Accuracy: 0.9228, F1 Micro: 0.7661, F1 Macro: 0.6438\n",
      "Epoch 10/10, Train Loss: 0.0728, Accuracy: 0.924, F1 Micro: 0.7774, F1 Macro: 0.6521\n",
      "Best result for 7656 samples: F1 Micro: 0.779\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.88      0.85      1107\n",
      "      Abusive       0.90      0.90      0.90      1030\n",
      "HS_Individual       0.71      0.81      0.76       729\n",
      "     HS_Group       0.76      0.62      0.68       378\n",
      "  HS_Religion       0.76      0.61      0.68       167\n",
      "      HS_Race       0.74      0.69      0.72        88\n",
      "  HS_Physical       1.00      0.03      0.05        74\n",
      "    HS_Gender       1.00      0.01      0.03        75\n",
      "     HS_Other       0.73      0.82      0.78       744\n",
      "      HS_Weak       0.69      0.80      0.74       690\n",
      "  HS_Moderate       0.70      0.55      0.62       338\n",
      "    HS_Strong       0.83      0.56      0.67        79\n",
      "\n",
      "    micro avg       0.78      0.78      0.78      5499\n",
      "    macro avg       0.81      0.61      0.62      5499\n",
      " weighted avg       0.79      0.78      0.77      5499\n",
      "  samples avg       0.43      0.43      0.41      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Acquired samples: 245\n",
      "Sampling duration: 15.926472425460815 seconds\n",
      "\n",
      "Fold 4 - New train size: 7901\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 7901 samples...\n",
      "Epoch 1/10, Train Loss: 0.4, Accuracy: 0.8818, F1 Micro: 0.5939, F1 Macro: 0.2657\n",
      "Epoch 2/10, Train Loss: 0.283, Accuracy: 0.9046, F1 Micro: 0.691, F1 Macro: 0.425\n",
      "Epoch 3/10, Train Loss: 0.2413, Accuracy: 0.9156, F1 Micro: 0.7394, F1 Macro: 0.5377\n",
      "Epoch 4/10, Train Loss: 0.1932, Accuracy: 0.9207, F1 Micro: 0.765, F1 Macro: 0.5861\n",
      "Epoch 5/10, Train Loss: 0.1646, Accuracy: 0.918, F1 Micro: 0.7675, F1 Macro: 0.605\n",
      "Epoch 6/10, Train Loss: 0.1403, Accuracy: 0.9249, F1 Micro: 0.768, F1 Macro: 0.6147\n",
      "Epoch 7/10, Train Loss: 0.1175, Accuracy: 0.9248, F1 Micro: 0.7763, F1 Macro: 0.6361\n",
      "Epoch 8/10, Train Loss: 0.0988, Accuracy: 0.9243, F1 Micro: 0.7787, F1 Macro: 0.6427\n",
      "Epoch 9/10, Train Loss: 0.0824, Accuracy: 0.9266, F1 Micro: 0.7784, F1 Macro: 0.6486\n",
      "Epoch 10/10, Train Loss: 0.0744, Accuracy: 0.9239, F1 Micro: 0.7819, F1 Macro: 0.6596\n",
      "Best result for 7901 samples: F1 Micro: 0.7819\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.90      0.86      1107\n",
      "      Abusive       0.90      0.93      0.91      1030\n",
      "HS_Individual       0.68      0.83      0.75       729\n",
      "     HS_Group       0.77      0.60      0.67       378\n",
      "  HS_Religion       0.79      0.59      0.68       167\n",
      "      HS_Race       0.75      0.44      0.56        88\n",
      "  HS_Physical       0.55      0.15      0.23        74\n",
      "    HS_Gender       0.90      0.25      0.40        75\n",
      "     HS_Other       0.73      0.85      0.78       744\n",
      "      HS_Weak       0.66      0.82      0.73       690\n",
      "  HS_Moderate       0.71      0.56      0.62       338\n",
      "    HS_Strong       0.79      0.66      0.72        79\n",
      "\n",
      "    micro avg       0.76      0.80      0.78      5499\n",
      "    macro avg       0.75      0.63      0.66      5499\n",
      " weighted avg       0.77      0.80      0.77      5499\n",
      "  samples avg       0.44      0.44      0.43      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 264\n",
      "Sampling duration: 14.965240478515625 seconds\n",
      "\n",
      "Fold 4 - New train size: 8165\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 8165 samples...\n",
      "Epoch 1/10, Train Loss: 0.3996, Accuracy: 0.8827, F1 Micro: 0.5783, F1 Macro: 0.2652\n",
      "Epoch 2/10, Train Loss: 0.2811, Accuracy: 0.9051, F1 Micro: 0.6901, F1 Macro: 0.4266\n",
      "Epoch 3/10, Train Loss: 0.2319, Accuracy: 0.9181, F1 Micro: 0.7468, F1 Macro: 0.5638\n",
      "Epoch 4/10, Train Loss: 0.1957, Accuracy: 0.9213, F1 Micro: 0.7628, F1 Macro: 0.5984\n",
      "Epoch 5/10, Train Loss: 0.1655, Accuracy: 0.9237, F1 Micro: 0.7762, F1 Macro: 0.5991\n",
      "Epoch 6/10, Train Loss: 0.1361, Accuracy: 0.925, F1 Micro: 0.7747, F1 Macro: 0.619\n",
      "Epoch 7/10, Train Loss: 0.1122, Accuracy: 0.9257, F1 Micro: 0.7699, F1 Macro: 0.6231\n",
      "Epoch 8/10, Train Loss: 0.1011, Accuracy: 0.9224, F1 Micro: 0.7753, F1 Macro: 0.6353\n",
      "Epoch 9/10, Train Loss: 0.0827, Accuracy: 0.9224, F1 Micro: 0.7791, F1 Macro: 0.6634\n",
      "Epoch 10/10, Train Loss: 0.0729, Accuracy: 0.922, F1 Micro: 0.7736, F1 Macro: 0.6446\n",
      "Best result for 8165 samples: F1 Micro: 0.7791\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.81      0.91      0.85      1107\n",
      "      Abusive       0.87      0.93      0.90      1030\n",
      "HS_Individual       0.71      0.79      0.75       729\n",
      "     HS_Group       0.69      0.67      0.68       378\n",
      "  HS_Religion       0.80      0.60      0.69       167\n",
      "      HS_Race       0.73      0.56      0.63        88\n",
      "  HS_Physical       0.50      0.11      0.18        74\n",
      "    HS_Gender       0.74      0.31      0.43        75\n",
      "     HS_Other       0.73      0.86      0.79       744\n",
      "      HS_Weak       0.68      0.77      0.72       690\n",
      "  HS_Moderate       0.63      0.62      0.63       338\n",
      "    HS_Strong       0.75      0.66      0.70        79\n",
      "\n",
      "    micro avg       0.76      0.80      0.78      5499\n",
      "    macro avg       0.72      0.65      0.66      5499\n",
      " weighted avg       0.75      0.80      0.77      5499\n",
      "  samples avg       0.44      0.44      0.43      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 237\n",
      "Sampling duration: 13.653221607208252 seconds\n",
      "\n",
      "Fold 4 - New train size: 8402\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 8402 samples...\n",
      "Epoch 1/10, Train Loss: 0.3961, Accuracy: 0.8837, F1 Micro: 0.5702, F1 Macro: 0.2611\n",
      "Epoch 2/10, Train Loss: 0.2766, Accuracy: 0.9074, F1 Micro: 0.7111, F1 Macro: 0.5021\n",
      "Epoch 3/10, Train Loss: 0.2316, Accuracy: 0.916, F1 Micro: 0.7515, F1 Macro: 0.5545\n",
      "Epoch 4/10, Train Loss: 0.1933, Accuracy: 0.9238, F1 Micro: 0.7585, F1 Macro: 0.5783\n",
      "Epoch 5/10, Train Loss: 0.16, Accuracy: 0.9255, F1 Micro: 0.7737, F1 Macro: 0.5971\n",
      "Epoch 6/10, Train Loss: 0.1382, Accuracy: 0.9248, F1 Micro: 0.7781, F1 Macro: 0.6265\n",
      "Epoch 7/10, Train Loss: 0.1115, Accuracy: 0.9226, F1 Micro: 0.781, F1 Macro: 0.634\n",
      "Epoch 8/10, Train Loss: 0.0998, Accuracy: 0.9264, F1 Micro: 0.7836, F1 Macro: 0.6533\n",
      "Epoch 9/10, Train Loss: 0.0826, Accuracy: 0.9267, F1 Micro: 0.7796, F1 Macro: 0.6374\n",
      "Epoch 10/10, Train Loss: 0.0733, Accuracy: 0.9265, F1 Micro: 0.7779, F1 Macro: 0.6717\n",
      "Best result for 8402 samples: F1 Micro: 0.7836\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.88      0.86      1107\n",
      "      Abusive       0.91      0.91      0.91      1030\n",
      "HS_Individual       0.71      0.81      0.76       729\n",
      "     HS_Group       0.76      0.61      0.68       378\n",
      "  HS_Religion       0.79      0.59      0.68       167\n",
      "      HS_Race       0.72      0.66      0.69        88\n",
      "  HS_Physical       0.56      0.12      0.20        74\n",
      "    HS_Gender       0.83      0.13      0.23        75\n",
      "     HS_Other       0.76      0.83      0.79       744\n",
      "      HS_Weak       0.69      0.79      0.74       690\n",
      "  HS_Moderate       0.70      0.53      0.60       338\n",
      "    HS_Strong       0.78      0.65      0.71        79\n",
      "\n",
      "    micro avg       0.79      0.78      0.78      5499\n",
      "    macro avg       0.76      0.63      0.65      5499\n",
      " weighted avg       0.79      0.78      0.77      5499\n",
      "  samples avg       0.44      0.43      0.42      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 214\n",
      "Sampling duration: 12.106794595718384 seconds\n",
      "\n",
      "Fold 4 - New train size: 8616\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 8616 samples...\n",
      "Epoch 1/10, Train Loss: 0.3933, Accuracy: 0.885, F1 Micro: 0.6183, F1 Macro: 0.2903\n",
      "Epoch 2/10, Train Loss: 0.2757, Accuracy: 0.9054, F1 Micro: 0.6915, F1 Macro: 0.4134\n",
      "Epoch 3/10, Train Loss: 0.2286, Accuracy: 0.9192, F1 Micro: 0.7473, F1 Macro: 0.5618\n",
      "Epoch 4/10, Train Loss: 0.1838, Accuracy: 0.9239, F1 Micro: 0.7614, F1 Macro: 0.6052\n",
      "Epoch 5/10, Train Loss: 0.1588, Accuracy: 0.9229, F1 Micro: 0.765, F1 Macro: 0.5948\n",
      "Epoch 6/10, Train Loss: 0.1356, Accuracy: 0.9266, F1 Micro: 0.7709, F1 Macro: 0.6214\n",
      "Epoch 7/10, Train Loss: 0.1157, Accuracy: 0.9258, F1 Micro: 0.7709, F1 Macro: 0.6225\n",
      "Epoch 8/10, Train Loss: 0.0948, Accuracy: 0.9249, F1 Micro: 0.7803, F1 Macro: 0.6674\n",
      "Epoch 9/10, Train Loss: 0.0858, Accuracy: 0.9268, F1 Micro: 0.7795, F1 Macro: 0.673\n",
      "Epoch 10/10, Train Loss: 0.0709, Accuracy: 0.9245, F1 Micro: 0.775, F1 Macro: 0.6697\n",
      "Best result for 8616 samples: F1 Micro: 0.7803\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.88      0.86      1107\n",
      "      Abusive       0.87      0.93      0.90      1030\n",
      "HS_Individual       0.71      0.82      0.76       729\n",
      "     HS_Group       0.81      0.56      0.66       378\n",
      "  HS_Religion       0.81      0.57      0.67       167\n",
      "      HS_Race       0.74      0.66      0.70        88\n",
      "  HS_Physical       0.59      0.14      0.22        74\n",
      "    HS_Gender       0.79      0.29      0.43        75\n",
      "     HS_Other       0.76      0.80      0.78       744\n",
      "      HS_Weak       0.67      0.80      0.73       690\n",
      "  HS_Moderate       0.74      0.51      0.61       338\n",
      "    HS_Strong       0.84      0.59      0.70        79\n",
      "\n",
      "    micro avg       0.78      0.78      0.78      5499\n",
      "    macro avg       0.76      0.63      0.67      5499\n",
      " weighted avg       0.78      0.78      0.77      5499\n",
      "  samples avg       0.44      0.43      0.42      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 200\n",
      "Sampling duration: 11.20462703704834 seconds\n",
      "\n",
      "Fold 4 - New train size: 8816\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 8816 samples...\n",
      "Epoch 1/10, Train Loss: 0.3938, Accuracy: 0.8867, F1 Micro: 0.6238, F1 Macro: 0.2964\n",
      "Epoch 2/10, Train Loss: 0.2796, Accuracy: 0.9071, F1 Micro: 0.7185, F1 Macro: 0.4962\n",
      "Epoch 3/10, Train Loss: 0.2235, Accuracy: 0.9186, F1 Micro: 0.7365, F1 Macro: 0.5565\n",
      "Epoch 4/10, Train Loss: 0.1866, Accuracy: 0.9212, F1 Micro: 0.772, F1 Macro: 0.5856\n",
      "Epoch 5/10, Train Loss: 0.1585, Accuracy: 0.9212, F1 Micro: 0.7767, F1 Macro: 0.6066\n",
      "Epoch 6/10, Train Loss: 0.1354, Accuracy: 0.9277, F1 Micro: 0.781, F1 Macro: 0.6315\n",
      "Epoch 7/10, Train Loss: 0.1124, Accuracy: 0.9257, F1 Micro: 0.7681, F1 Macro: 0.6183\n",
      "Epoch 8/10, Train Loss: 0.0964, Accuracy: 0.9267, F1 Micro: 0.785, F1 Macro: 0.654\n",
      "Epoch 9/10, Train Loss: 0.0806, Accuracy: 0.9239, F1 Micro: 0.7781, F1 Macro: 0.6719\n",
      "Epoch 10/10, Train Loss: 0.0682, Accuracy: 0.9284, F1 Micro: 0.7855, F1 Macro: 0.6822\n",
      "Best result for 8816 samples: F1 Micro: 0.7855\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.86      0.86      1107\n",
      "      Abusive       0.91      0.90      0.91      1030\n",
      "HS_Individual       0.75      0.74      0.75       729\n",
      "     HS_Group       0.72      0.66      0.69       378\n",
      "  HS_Religion       0.77      0.67      0.72       167\n",
      "      HS_Race       0.73      0.69      0.71        88\n",
      "  HS_Physical       0.50      0.15      0.23        74\n",
      "    HS_Gender       0.83      0.32      0.46        75\n",
      "     HS_Other       0.80      0.79      0.80       744\n",
      "      HS_Weak       0.73      0.73      0.73       690\n",
      "  HS_Moderate       0.67      0.59      0.63       338\n",
      "    HS_Strong       0.76      0.66      0.71        79\n",
      "\n",
      "    micro avg       0.80      0.77      0.79      5499\n",
      "    macro avg       0.75      0.65      0.68      5499\n",
      " weighted avg       0.80      0.77      0.78      5499\n",
      "  samples avg       0.44      0.42      0.42      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 200\n",
      "Sampling duration: 10.128495693206787 seconds\n",
      "\n",
      "Fold 4 - New train size: 9016\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 9016 samples...\n",
      "Epoch 1/10, Train Loss: 0.3889, Accuracy: 0.8873, F1 Micro: 0.6081, F1 Macro: 0.2891\n",
      "Epoch 2/10, Train Loss: 0.2733, Accuracy: 0.9089, F1 Micro: 0.7228, F1 Macro: 0.5074\n",
      "Epoch 3/10, Train Loss: 0.2225, Accuracy: 0.9186, F1 Micro: 0.7496, F1 Macro: 0.5763\n",
      "Epoch 4/10, Train Loss: 0.1869, Accuracy: 0.9231, F1 Micro: 0.7642, F1 Macro: 0.5908\n",
      "Epoch 5/10, Train Loss: 0.1587, Accuracy: 0.9242, F1 Micro: 0.7763, F1 Macro: 0.5947\n",
      "Epoch 6/10, Train Loss: 0.1327, Accuracy: 0.9229, F1 Micro: 0.7727, F1 Macro: 0.6266\n",
      "Epoch 7/10, Train Loss: 0.1122, Accuracy: 0.9249, F1 Micro: 0.7748, F1 Macro: 0.6483\n",
      "Epoch 8/10, Train Loss: 0.0956, Accuracy: 0.9254, F1 Micro: 0.772, F1 Macro: 0.6391\n",
      "Epoch 9/10, Train Loss: 0.0805, Accuracy: 0.9266, F1 Micro: 0.7758, F1 Macro: 0.6686\n",
      "Epoch 10/10, Train Loss: 0.0694, Accuracy: 0.9258, F1 Micro: 0.7785, F1 Macro: 0.6753\n",
      "Best result for 9016 samples: F1 Micro: 0.7785\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.85      0.85      1107\n",
      "      Abusive       0.89      0.93      0.91      1030\n",
      "HS_Individual       0.75      0.72      0.74       729\n",
      "     HS_Group       0.70      0.67      0.68       378\n",
      "  HS_Religion       0.77      0.67      0.72       167\n",
      "      HS_Race       0.75      0.62      0.68        88\n",
      "  HS_Physical       0.61      0.15      0.24        74\n",
      "    HS_Gender       0.88      0.31      0.46        75\n",
      "     HS_Other       0.78      0.79      0.79       744\n",
      "      HS_Weak       0.73      0.70      0.71       690\n",
      "  HS_Moderate       0.64      0.62      0.63       338\n",
      "    HS_Strong       0.79      0.63      0.70        79\n",
      "\n",
      "    micro avg       0.79      0.77      0.78      5499\n",
      "    macro avg       0.76      0.64      0.68      5499\n",
      " weighted avg       0.79      0.77      0.77      5499\n",
      "  samples avg       0.44      0.43      0.42      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 200\n",
      "Sampling duration: 9.016958475112915 seconds\n",
      "\n",
      "Fold 4 - New train size: 9216\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 9216 samples...\n",
      "Epoch 1/10, Train Loss: 0.3914, Accuracy: 0.8844, F1 Micro: 0.5818, F1 Macro: 0.2732\n",
      "Epoch 2/10, Train Loss: 0.2728, Accuracy: 0.9055, F1 Micro: 0.7084, F1 Macro: 0.4481\n",
      "Epoch 3/10, Train Loss: 0.2215, Accuracy: 0.9195, F1 Micro: 0.7621, F1 Macro: 0.5848\n",
      "Epoch 4/10, Train Loss: 0.1864, Accuracy: 0.9227, F1 Micro: 0.7475, F1 Macro: 0.5747\n",
      "Epoch 5/10, Train Loss: 0.1577, Accuracy: 0.9265, F1 Micro: 0.7765, F1 Macro: 0.6091\n",
      "Epoch 6/10, Train Loss: 0.1352, Accuracy: 0.9278, F1 Micro: 0.7777, F1 Macro: 0.6327\n",
      "Epoch 7/10, Train Loss: 0.1141, Accuracy: 0.9251, F1 Micro: 0.7731, F1 Macro: 0.644\n",
      "Epoch 8/10, Train Loss: 0.096, Accuracy: 0.9266, F1 Micro: 0.7766, F1 Macro: 0.6591\n",
      "Epoch 9/10, Train Loss: 0.0776, Accuracy: 0.9283, F1 Micro: 0.7824, F1 Macro: 0.6776\n",
      "Epoch 10/10, Train Loss: 0.0668, Accuracy: 0.9266, F1 Micro: 0.7821, F1 Macro: 0.6781\n",
      "Best result for 9216 samples: F1 Micro: 0.7824\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.84      0.85      1107\n",
      "      Abusive       0.90      0.92      0.91      1030\n",
      "HS_Individual       0.78      0.71      0.74       729\n",
      "     HS_Group       0.71      0.67      0.69       378\n",
      "  HS_Religion       0.84      0.59      0.69       167\n",
      "      HS_Race       0.73      0.64      0.68        88\n",
      "  HS_Physical       0.62      0.18      0.27        74\n",
      "    HS_Gender       0.88      0.28      0.42        75\n",
      "     HS_Other       0.80      0.80      0.80       744\n",
      "      HS_Weak       0.75      0.69      0.72       690\n",
      "  HS_Moderate       0.66      0.60      0.63       338\n",
      "    HS_Strong       0.80      0.66      0.72        79\n",
      "\n",
      "    micro avg       0.81      0.76      0.78      5499\n",
      "    macro avg       0.78      0.63      0.68      5499\n",
      " weighted avg       0.81      0.76      0.78      5499\n",
      "  samples avg       0.44      0.42      0.42      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 2\n",
      "Sampling duration: 8.090271234512329 seconds\n",
      "\n",
      "Fold 4 - New train size: 9218\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 9218 samples...\n",
      "Epoch 1/10, Train Loss: 0.3849, Accuracy: 0.8859, F1 Micro: 0.5841, F1 Macro: 0.2907\n",
      "Epoch 2/10, Train Loss: 0.2709, Accuracy: 0.9096, F1 Micro: 0.7246, F1 Macro: 0.481\n",
      "Epoch 3/10, Train Loss: 0.2193, Accuracy: 0.9206, F1 Micro: 0.7544, F1 Macro: 0.5574\n",
      "Epoch 4/10, Train Loss: 0.1828, Accuracy: 0.9205, F1 Micro: 0.7704, F1 Macro: 0.5966\n",
      "Epoch 5/10, Train Loss: 0.1545, Accuracy: 0.9264, F1 Micro: 0.7788, F1 Macro: 0.6168\n",
      "Epoch 6/10, Train Loss: 0.1262, Accuracy: 0.925, F1 Micro: 0.7829, F1 Macro: 0.6295\n",
      "Epoch 7/10, Train Loss: 0.1058, Accuracy: 0.9216, F1 Micro: 0.7782, F1 Macro: 0.6413\n",
      "Epoch 8/10, Train Loss: 0.0913, Accuracy: 0.9258, F1 Micro: 0.7734, F1 Macro: 0.6385\n",
      "Epoch 9/10, Train Loss: 0.0768, Accuracy: 0.9252, F1 Micro: 0.7762, F1 Macro: 0.6668\n",
      "Epoch 10/10, Train Loss: 0.0678, Accuracy: 0.927, F1 Micro: 0.7838, F1 Macro: 0.6851\n",
      "Best result for 9218 samples: F1 Micro: 0.7838\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.87      0.86      1107\n",
      "      Abusive       0.92      0.91      0.91      1030\n",
      "HS_Individual       0.76      0.72      0.74       729\n",
      "     HS_Group       0.67      0.71      0.69       378\n",
      "  HS_Religion       0.75      0.63      0.69       167\n",
      "      HS_Race       0.71      0.72      0.71        88\n",
      "  HS_Physical       0.58      0.19      0.29        74\n",
      "    HS_Gender       0.86      0.32      0.47        75\n",
      "     HS_Other       0.78      0.83      0.80       744\n",
      "      HS_Weak       0.74      0.69      0.71       690\n",
      "  HS_Moderate       0.63      0.67      0.65       338\n",
      "    HS_Strong       0.75      0.67      0.71        79\n",
      "\n",
      "    micro avg       0.79      0.78      0.78      5499\n",
      "    macro avg       0.75      0.66      0.69      5499\n",
      " weighted avg       0.79      0.78      0.78      5499\n",
      "  samples avg       0.44      0.43      0.42      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Acquired samples: 200\n",
      "Sampling duration: 8.133419036865234 seconds\n",
      "\n",
      "Fold 4 - New train size: 9418\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 9418 samples...\n",
      "Epoch 1/10, Train Loss: 0.385, Accuracy: 0.8829, F1 Micro: 0.5573, F1 Macro: 0.2661\n",
      "Epoch 2/10, Train Loss: 0.2661, Accuracy: 0.9118, F1 Micro: 0.7162, F1 Macro: 0.5051\n",
      "Epoch 3/10, Train Loss: 0.216, Accuracy: 0.9191, F1 Micro: 0.7505, F1 Macro: 0.5604\n",
      "Epoch 4/10, Train Loss: 0.1883, Accuracy: 0.9166, F1 Micro: 0.7686, F1 Macro: 0.6002\n",
      "Epoch 5/10, Train Loss: 0.1577, Accuracy: 0.9259, F1 Micro: 0.7644, F1 Macro: 0.6133\n",
      "Epoch 6/10, Train Loss: 0.1273, Accuracy: 0.929, F1 Micro: 0.7803, F1 Macro: 0.6408\n",
      "Epoch 7/10, Train Loss: 0.1114, Accuracy: 0.9281, F1 Micro: 0.7797, F1 Macro: 0.6476\n",
      "Epoch 8/10, Train Loss: 0.0915, Accuracy: 0.9274, F1 Micro: 0.7734, F1 Macro: 0.6563\n",
      "Epoch 9/10, Train Loss: 0.0793, Accuracy: 0.9276, F1 Micro: 0.7877, F1 Macro: 0.6854\n",
      "Epoch 10/10, Train Loss: 0.0651, Accuracy: 0.9283, F1 Micro: 0.7861, F1 Macro: 0.6647\n",
      "Best result for 9418 samples: F1 Micro: 0.7877\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.88      0.86      1107\n",
      "      Abusive       0.90      0.93      0.91      1030\n",
      "HS_Individual       0.74      0.75      0.75       729\n",
      "     HS_Group       0.70      0.67      0.68       378\n",
      "  HS_Religion       0.75      0.66      0.70       167\n",
      "      HS_Race       0.75      0.70      0.73        88\n",
      "  HS_Physical       0.60      0.16      0.26        74\n",
      "    HS_Gender       0.83      0.33      0.48        75\n",
      "     HS_Other       0.78      0.84      0.81       744\n",
      "      HS_Weak       0.72      0.73      0.73       690\n",
      "  HS_Moderate       0.64      0.62      0.63       338\n",
      "    HS_Strong       0.77      0.63      0.69        79\n",
      "\n",
      "    micro avg       0.79      0.79      0.79      5499\n",
      "    macro avg       0.75      0.66      0.69      5499\n",
      " weighted avg       0.78      0.79      0.78      5499\n",
      "  samples avg       0.45      0.44      0.43      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Acquired samples: 200\n",
      "Sampling duration: 7.061645984649658 seconds\n",
      "\n",
      "Fold 4 - New train size: 9618\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 9618 samples...\n",
      "Epoch 1/10, Train Loss: 0.3799, Accuracy: 0.8911, F1 Micro: 0.6444, F1 Macro: 0.3294\n",
      "Epoch 2/10, Train Loss: 0.2631, Accuracy: 0.9107, F1 Micro: 0.7279, F1 Macro: 0.5315\n",
      "Epoch 3/10, Train Loss: 0.2122, Accuracy: 0.9147, F1 Micro: 0.7609, F1 Macro: 0.5858\n",
      "Epoch 4/10, Train Loss: 0.1831, Accuracy: 0.9247, F1 Micro: 0.7729, F1 Macro: 0.601\n",
      "Epoch 5/10, Train Loss: 0.1497, Accuracy: 0.9264, F1 Micro: 0.781, F1 Macro: 0.6329\n",
      "Epoch 6/10, Train Loss: 0.1283, Accuracy: 0.9279, F1 Micro: 0.7877, F1 Macro: 0.65\n",
      "Epoch 7/10, Train Loss: 0.1055, Accuracy: 0.926, F1 Micro: 0.7789, F1 Macro: 0.6561\n",
      "Epoch 8/10, Train Loss: 0.0915, Accuracy: 0.9267, F1 Micro: 0.7859, F1 Macro: 0.6838\n",
      "Epoch 9/10, Train Loss: 0.0787, Accuracy: 0.9264, F1 Micro: 0.7773, F1 Macro: 0.6632\n",
      "Epoch 10/10, Train Loss: 0.0669, Accuracy: 0.9256, F1 Micro: 0.7747, F1 Macro: 0.6513\n",
      "Best result for 9618 samples: F1 Micro: 0.7877\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.88      0.86      1107\n",
      "      Abusive       0.88      0.92      0.90      1030\n",
      "HS_Individual       0.74      0.82      0.78       729\n",
      "     HS_Group       0.78      0.61      0.68       378\n",
      "  HS_Religion       0.80      0.57      0.67       167\n",
      "      HS_Race       0.77      0.56      0.64        88\n",
      "  HS_Physical       0.67      0.11      0.19        74\n",
      "    HS_Gender       0.91      0.13      0.23        75\n",
      "     HS_Other       0.76      0.83      0.79       744\n",
      "      HS_Weak       0.71      0.79      0.75       690\n",
      "  HS_Moderate       0.69      0.55      0.61       338\n",
      "    HS_Strong       0.76      0.63      0.69        79\n",
      "\n",
      "    micro avg       0.79      0.78      0.79      5499\n",
      "    macro avg       0.78      0.62      0.65      5499\n",
      " weighted avg       0.79      0.78      0.78      5499\n",
      "  samples avg       0.45      0.44      0.43      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Acquired samples: 200\n",
      "Sampling duration: 6.001815557479858 seconds\n",
      "\n",
      "Fold 4 - New train size: 9818\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 9818 samples...\n",
      "Epoch 1/10, Train Loss: 0.3783, Accuracy: 0.8881, F1 Micro: 0.6012, F1 Macro: 0.299\n",
      "Epoch 2/10, Train Loss: 0.2599, Accuracy: 0.9117, F1 Micro: 0.7136, F1 Macro: 0.5234\n",
      "Epoch 3/10, Train Loss: 0.2132, Accuracy: 0.9187, F1 Micro: 0.7534, F1 Macro: 0.5861\n",
      "Epoch 4/10, Train Loss: 0.1782, Accuracy: 0.9229, F1 Micro: 0.7756, F1 Macro: 0.6039\n",
      "Epoch 5/10, Train Loss: 0.1494, Accuracy: 0.9271, F1 Micro: 0.7829, F1 Macro: 0.6339\n",
      "Epoch 6/10, Train Loss: 0.1212, Accuracy: 0.9278, F1 Micro: 0.7834, F1 Macro: 0.6415\n",
      "Epoch 7/10, Train Loss: 0.1078, Accuracy: 0.9225, F1 Micro: 0.7819, F1 Macro: 0.6575\n",
      "Epoch 8/10, Train Loss: 0.0928, Accuracy: 0.9279, F1 Micro: 0.7872, F1 Macro: 0.6778\n",
      "Epoch 9/10, Train Loss: 0.0738, Accuracy: 0.9275, F1 Micro: 0.7846, F1 Macro: 0.6816\n",
      "Epoch 10/10, Train Loss: 0.0648, Accuracy: 0.9284, F1 Micro: 0.7899, F1 Macro: 0.6805\n",
      "Best result for 9818 samples: F1 Micro: 0.7899\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.88      0.86      1107\n",
      "      Abusive       0.92      0.90      0.91      1030\n",
      "HS_Individual       0.73      0.79      0.76       729\n",
      "     HS_Group       0.74      0.65      0.70       378\n",
      "  HS_Religion       0.80      0.64      0.71       167\n",
      "      HS_Race       0.75      0.56      0.64        88\n",
      "  HS_Physical       0.52      0.15      0.23        74\n",
      "    HS_Gender       0.82      0.31      0.45        75\n",
      "     HS_Other       0.77      0.84      0.80       744\n",
      "      HS_Weak       0.70      0.77      0.74       690\n",
      "  HS_Moderate       0.67      0.60      0.63       338\n",
      "    HS_Strong       0.80      0.67      0.73        79\n",
      "\n",
      "    micro avg       0.79      0.79      0.79      5499\n",
      "    macro avg       0.76      0.65      0.68      5499\n",
      " weighted avg       0.79      0.79      0.78      5499\n",
      "  samples avg       0.44      0.43      0.42      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.235649347305298 seconds\n",
      "\n",
      "Fold 4 - New train size: 10018\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 10018 samples...\n",
      "Epoch 1/10, Train Loss: 0.3759, Accuracy: 0.8927, F1 Micro: 0.6367, F1 Macro: 0.3514\n",
      "Epoch 2/10, Train Loss: 0.2599, Accuracy: 0.9122, F1 Micro: 0.7359, F1 Macro: 0.5196\n",
      "Epoch 3/10, Train Loss: 0.2112, Accuracy: 0.9222, F1 Micro: 0.7609, F1 Macro: 0.5927\n",
      "Epoch 4/10, Train Loss: 0.1763, Accuracy: 0.9248, F1 Micro: 0.7748, F1 Macro: 0.617\n",
      "Epoch 5/10, Train Loss: 0.147, Accuracy: 0.9201, F1 Micro: 0.7746, F1 Macro: 0.6259\n",
      "Epoch 6/10, Train Loss: 0.1226, Accuracy: 0.9254, F1 Micro: 0.7794, F1 Macro: 0.6416\n",
      "Epoch 7/10, Train Loss: 0.1037, Accuracy: 0.9296, F1 Micro: 0.7869, F1 Macro: 0.6791\n",
      "Epoch 8/10, Train Loss: 0.0886, Accuracy: 0.9264, F1 Micro: 0.7713, F1 Macro: 0.6621\n",
      "Epoch 9/10, Train Loss: 0.0749, Accuracy: 0.9289, F1 Micro: 0.7886, F1 Macro: 0.6784\n",
      "Epoch 10/10, Train Loss: 0.0663, Accuracy: 0.9285, F1 Micro: 0.7912, F1 Macro: 0.7059\n",
      "Best result for 10018 samples: F1 Micro: 0.7912\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.88      0.86      1107\n",
      "      Abusive       0.89      0.93      0.91      1030\n",
      "HS_Individual       0.75      0.76      0.75       729\n",
      "     HS_Group       0.69      0.69      0.69       378\n",
      "  HS_Religion       0.73      0.68      0.70       167\n",
      "      HS_Race       0.76      0.67      0.71        88\n",
      "  HS_Physical       0.55      0.24      0.34        74\n",
      "    HS_Gender       0.92      0.45      0.61        75\n",
      "     HS_Other       0.79      0.83      0.81       744\n",
      "      HS_Weak       0.72      0.74      0.73       690\n",
      "  HS_Moderate       0.63      0.63      0.63       338\n",
      "    HS_Strong       0.82      0.65      0.72        79\n",
      "\n",
      "    micro avg       0.79      0.79      0.79      5499\n",
      "    macro avg       0.76      0.68      0.71      5499\n",
      " weighted avg       0.79      0.79      0.79      5499\n",
      "  samples avg       0.45      0.44      0.43      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.076555013656616 seconds\n",
      "\n",
      "Fold 4 - New train size: 10218\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 10218 samples...\n",
      "Epoch 1/10, Train Loss: 0.3757, Accuracy: 0.8941, F1 Micro: 0.6507, F1 Macro: 0.3362\n",
      "Epoch 2/10, Train Loss: 0.2578, Accuracy: 0.9127, F1 Micro: 0.7336, F1 Macro: 0.5178\n",
      "Epoch 3/10, Train Loss: 0.2084, Accuracy: 0.923, F1 Micro: 0.7643, F1 Macro: 0.5912\n",
      "Epoch 4/10, Train Loss: 0.1738, Accuracy: 0.9254, F1 Micro: 0.7719, F1 Macro: 0.5971\n",
      "Epoch 5/10, Train Loss: 0.1428, Accuracy: 0.9265, F1 Micro: 0.776, F1 Macro: 0.6286\n",
      "Epoch 6/10, Train Loss: 0.1216, Accuracy: 0.9275, F1 Micro: 0.787, F1 Macro: 0.6528\n",
      "Epoch 7/10, Train Loss: 0.1008, Accuracy: 0.9242, F1 Micro: 0.7801, F1 Macro: 0.652\n",
      "Epoch 8/10, Train Loss: 0.0893, Accuracy: 0.928, F1 Micro: 0.7841, F1 Macro: 0.6625\n",
      "Epoch 9/10, Train Loss: 0.0748, Accuracy: 0.927, F1 Micro: 0.7853, F1 Macro: 0.6716\n",
      "Epoch 10/10, Train Loss: 0.0633, Accuracy: 0.9269, F1 Micro: 0.7741, F1 Macro: 0.6627\n",
      "Best result for 10218 samples: F1 Micro: 0.787\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.89      0.86      1107\n",
      "      Abusive       0.92      0.89      0.91      1030\n",
      "HS_Individual       0.72      0.81      0.77       729\n",
      "     HS_Group       0.75      0.63      0.68       378\n",
      "  HS_Religion       0.79      0.62      0.70       167\n",
      "      HS_Race       0.81      0.65      0.72        88\n",
      "  HS_Physical       0.56      0.12      0.20        74\n",
      "    HS_Gender       0.83      0.07      0.12        75\n",
      "     HS_Other       0.76      0.83      0.80       744\n",
      "      HS_Weak       0.70      0.79      0.74       690\n",
      "  HS_Moderate       0.69      0.58      0.63       338\n",
      "    HS_Strong       0.78      0.65      0.71        79\n",
      "\n",
      "    micro avg       0.79      0.79      0.79      5499\n",
      "    macro avg       0.76      0.63      0.65      5499\n",
      " weighted avg       0.79      0.79      0.78      5499\n",
      "  samples avg       0.43      0.43      0.42      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.7683277130126953 seconds\n",
      "\n",
      "Fold 4 - New train size: 10418\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 10418 samples...\n",
      "Epoch 1/10, Train Loss: 0.3691, Accuracy: 0.8946, F1 Micro: 0.6566, F1 Macro: 0.3825\n",
      "Epoch 2/10, Train Loss: 0.2554, Accuracy: 0.9124, F1 Micro: 0.7261, F1 Macro: 0.5191\n",
      "Epoch 3/10, Train Loss: 0.2061, Accuracy: 0.9222, F1 Micro: 0.7605, F1 Macro: 0.5707\n",
      "Epoch 4/10, Train Loss: 0.1736, Accuracy: 0.9259, F1 Micro: 0.7666, F1 Macro: 0.5995\n",
      "Epoch 5/10, Train Loss: 0.1473, Accuracy: 0.927, F1 Micro: 0.7853, F1 Macro: 0.6484\n",
      "Epoch 6/10, Train Loss: 0.1181, Accuracy: 0.9269, F1 Micro: 0.7805, F1 Macro: 0.6339\n",
      "Epoch 7/10, Train Loss: 0.1024, Accuracy: 0.9285, F1 Micro: 0.7823, F1 Macro: 0.6743\n",
      "Epoch 8/10, Train Loss: 0.0856, Accuracy: 0.9256, F1 Micro: 0.787, F1 Macro: 0.6803\n",
      "Epoch 9/10, Train Loss: 0.0741, Accuracy: 0.9269, F1 Micro: 0.7846, F1 Macro: 0.6816\n",
      "Epoch 10/10, Train Loss: 0.0646, Accuracy: 0.9273, F1 Micro: 0.7799, F1 Macro: 0.6941\n",
      "Best result for 10418 samples: F1 Micro: 0.787\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.81      0.90      0.86      1107\n",
      "      Abusive       0.90      0.93      0.92      1030\n",
      "HS_Individual       0.70      0.81      0.76       729\n",
      "     HS_Group       0.73      0.65      0.68       378\n",
      "  HS_Religion       0.78      0.64      0.70       167\n",
      "      HS_Race       0.76      0.58      0.66        88\n",
      "  HS_Physical       0.62      0.20      0.31        74\n",
      "    HS_Gender       0.91      0.28      0.43        75\n",
      "     HS_Other       0.74      0.86      0.80       744\n",
      "      HS_Weak       0.68      0.80      0.74       690\n",
      "  HS_Moderate       0.67      0.59      0.63       338\n",
      "    HS_Strong       0.76      0.65      0.70        79\n",
      "\n",
      "    micro avg       0.77      0.81      0.79      5499\n",
      "    macro avg       0.76      0.66      0.68      5499\n",
      " weighted avg       0.77      0.81      0.78      5499\n",
      "  samples avg       0.45      0.45      0.43      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Acquired samples: 117\n",
      "Sampling duration: 1.5655264854431152 seconds\n",
      "\n",
      "Fold 4 - New train size: 10535\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 10535 samples...\n",
      "Epoch 1/10, Train Loss: 0.3673, Accuracy: 0.8941, F1 Micro: 0.6625, F1 Macro: 0.3514\n",
      "Epoch 2/10, Train Loss: 0.2476, Accuracy: 0.9121, F1 Micro: 0.706, F1 Macro: 0.4987\n",
      "Epoch 3/10, Train Loss: 0.2023, Accuracy: 0.923, F1 Micro: 0.7555, F1 Macro: 0.579\n",
      "Epoch 4/10, Train Loss: 0.1626, Accuracy: 0.9266, F1 Micro: 0.775, F1 Macro: 0.6149\n",
      "Epoch 5/10, Train Loss: 0.1371, Accuracy: 0.9248, F1 Micro: 0.786, F1 Macro: 0.6754\n",
      "Epoch 6/10, Train Loss: 0.1163, Accuracy: 0.9262, F1 Micro: 0.7817, F1 Macro: 0.6628\n",
      "Epoch 7/10, Train Loss: 0.1006, Accuracy: 0.9295, F1 Micro: 0.7885, F1 Macro: 0.6735\n",
      "Epoch 8/10, Train Loss: 0.083, Accuracy: 0.9312, F1 Micro: 0.7917, F1 Macro: 0.6902\n",
      "Epoch 9/10, Train Loss: 0.0693, Accuracy: 0.9286, F1 Micro: 0.7821, F1 Macro: 0.7003\n",
      "Epoch 10/10, Train Loss: 0.0602, Accuracy: 0.9262, F1 Micro: 0.7701, F1 Macro: 0.6917\n",
      "Best result for 10535 samples: F1 Micro: 0.7917\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.88      0.85      0.86      1107\n",
      "      Abusive       0.91      0.92      0.92      1030\n",
      "HS_Individual       0.76      0.77      0.76       729\n",
      "     HS_Group       0.78      0.62      0.69       378\n",
      "  HS_Religion       0.83      0.60      0.70       167\n",
      "      HS_Race       0.81      0.58      0.68        88\n",
      "  HS_Physical       0.56      0.19      0.28        74\n",
      "    HS_Gender       0.81      0.39      0.52        75\n",
      "     HS_Other       0.81      0.78      0.79       744\n",
      "      HS_Weak       0.73      0.76      0.74       690\n",
      "  HS_Moderate       0.71      0.57      0.63       338\n",
      "    HS_Strong       0.79      0.63      0.70        79\n",
      "\n",
      "    micro avg       0.82      0.77      0.79      5499\n",
      "    macro avg       0.78      0.64      0.69      5499\n",
      " weighted avg       0.81      0.77      0.79      5499\n",
      "  samples avg       0.44      0.42      0.42      5499\n",
      "\n",
      "\n",
      "FOLD 4 COMPLETED in 6565.77 seconds\n",
      "===============================================\n",
      "STARTING FOLD 5/5\n",
      "===============================================\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 658 samples...\n",
      "Epoch 1/10, Train Loss: 0.6136, Accuracy: 0.8169, F1 Micro: 0.2051, F1 Macro: 0.06\n",
      "Epoch 2/10, Train Loss: 0.4588, Accuracy: 0.8201, F1 Micro: 0.0038, F1 Macro: 0.0016\n",
      "Epoch 3/10, Train Loss: 0.4187, Accuracy: 0.8233, F1 Micro: 0.0481, F1 Macro: 0.02\n",
      "Epoch 4/10, Train Loss: 0.386, Accuracy: 0.8238, F1 Micro: 0.0508, F1 Macro: 0.0212\n",
      "Epoch 5/10, Train Loss: 0.3707, Accuracy: 0.8329, F1 Micro: 0.1604, F1 Macro: 0.0612\n",
      "Epoch 6/10, Train Loss: 0.3624, Accuracy: 0.8458, F1 Micro: 0.3243, F1 Macro: 0.1116\n",
      "Epoch 7/10, Train Loss: 0.3537, Accuracy: 0.8506, F1 Micro: 0.3637, F1 Macro: 0.145\n",
      "Epoch 8/10, Train Loss: 0.3241, Accuracy: 0.8632, F1 Micro: 0.4924, F1 Macro: 0.2234\n",
      "Epoch 9/10, Train Loss: 0.3069, Accuracy: 0.8715, F1 Micro: 0.5743, F1 Macro: 0.2679\n",
      "Epoch 10/10, Train Loss: 0.2933, Accuracy: 0.8748, F1 Micro: 0.5872, F1 Macro: 0.2747\n",
      "Best result for 658 samples: F1 Micro: 0.5872\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.79      0.75      0.77      1190\n",
      "      Abusive       0.82      0.72      0.77      1018\n",
      "HS_Individual       0.65      0.57      0.61       768\n",
      "     HS_Group       0.00      0.00      0.00       422\n",
      "  HS_Religion       0.00      0.00      0.00       173\n",
      "      HS_Race       0.00      0.00      0.00       126\n",
      "  HS_Physical       0.00      0.00      0.00        60\n",
      "    HS_Gender       0.00      0.00      0.00        67\n",
      "     HS_Other       0.64      0.56      0.60       792\n",
      "      HS_Weak       0.61      0.50      0.55       725\n",
      "  HS_Moderate       0.00      0.00      0.00       352\n",
      "    HS_Strong       0.00      0.00      0.00       113\n",
      "\n",
      "    micro avg       0.72      0.50      0.59      5806\n",
      "    macro avg       0.29      0.26      0.27      5806\n",
      " weighted avg       0.56      0.50      0.52      5806\n",
      "  samples avg       0.38      0.29      0.30      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 988\n",
      "Sampling duration: 52.49932336807251 seconds\n",
      "\n",
      "Fold 5 - New train size: 1646\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 1646 samples...\n",
      "Epoch 1/10, Train Loss: 0.5273, Accuracy: 0.8202, F1 Micro: 0.0028, F1 Macro: 0.0013\n",
      "Epoch 2/10, Train Loss: 0.3909, Accuracy: 0.8207, F1 Micro: 0.0082, F1 Macro: 0.0038\n",
      "Epoch 3/10, Train Loss: 0.3627, Accuracy: 0.8341, F1 Micro: 0.1819, F1 Macro: 0.0688\n",
      "Epoch 4/10, Train Loss: 0.3333, Accuracy: 0.8637, F1 Micro: 0.493, F1 Macro: 0.2181\n",
      "Epoch 5/10, Train Loss: 0.2846, Accuracy: 0.8746, F1 Micro: 0.5786, F1 Macro: 0.2707\n",
      "Epoch 6/10, Train Loss: 0.2735, Accuracy: 0.8803, F1 Micro: 0.5989, F1 Macro: 0.2815\n",
      "Epoch 7/10, Train Loss: 0.2384, Accuracy: 0.8848, F1 Micro: 0.6312, F1 Macro: 0.334\n",
      "Epoch 8/10, Train Loss: 0.2134, Accuracy: 0.8888, F1 Micro: 0.6535, F1 Macro: 0.403\n",
      "Epoch 9/10, Train Loss: 0.1856, Accuracy: 0.8899, F1 Micro: 0.6756, F1 Macro: 0.4118\n",
      "Epoch 10/10, Train Loss: 0.1755, Accuracy: 0.8914, F1 Micro: 0.6866, F1 Macro: 0.4315\n",
      "Best result for 1646 samples: F1 Micro: 0.6866\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.79      0.85      0.82      1190\n",
      "      Abusive       0.84      0.87      0.85      1018\n",
      "HS_Individual       0.66      0.66      0.66       768\n",
      "     HS_Group       0.66      0.48      0.56       422\n",
      "  HS_Religion       0.00      0.00      0.00       173\n",
      "      HS_Race       0.86      0.25      0.38       126\n",
      "  HS_Physical       0.00      0.00      0.00        60\n",
      "    HS_Gender       0.00      0.00      0.00        67\n",
      "     HS_Other       0.67      0.75      0.71       792\n",
      "      HS_Weak       0.61      0.67      0.64       725\n",
      "  HS_Moderate       0.49      0.32      0.39       352\n",
      "    HS_Strong       0.92      0.10      0.18       113\n",
      "\n",
      "    micro avg       0.71      0.66      0.69      5806\n",
      "    macro avg       0.54      0.41      0.43      5806\n",
      " weighted avg       0.68      0.66      0.66      5806\n",
      "  samples avg       0.42      0.39      0.38      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 889\n",
      "Sampling duration: 47.44290614128113 seconds\n",
      "\n",
      "Fold 5 - New train size: 2535\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 2535 samples...\n",
      "Epoch 1/10, Train Loss: 0.4853, Accuracy: 0.8215, F1 Micro: 0.0227, F1 Macro: 0.0101\n",
      "Epoch 2/10, Train Loss: 0.3672, Accuracy: 0.8356, F1 Micro: 0.2046, F1 Macro: 0.0742\n",
      "Epoch 3/10, Train Loss: 0.3431, Accuracy: 0.8705, F1 Micro: 0.531, F1 Macro: 0.2374\n",
      "Epoch 4/10, Train Loss: 0.2928, Accuracy: 0.8828, F1 Micro: 0.6266, F1 Macro: 0.2939\n",
      "Epoch 5/10, Train Loss: 0.2524, Accuracy: 0.8855, F1 Micro: 0.6778, F1 Macro: 0.3968\n",
      "Epoch 6/10, Train Loss: 0.2259, Accuracy: 0.893, F1 Micro: 0.6534, F1 Macro: 0.3922\n",
      "Epoch 7/10, Train Loss: 0.1911, Accuracy: 0.8969, F1 Micro: 0.6913, F1 Macro: 0.4673\n",
      "Epoch 8/10, Train Loss: 0.1743, Accuracy: 0.8956, F1 Micro: 0.7084, F1 Macro: 0.4802\n",
      "Epoch 9/10, Train Loss: 0.1481, Accuracy: 0.9014, F1 Micro: 0.7081, F1 Macro: 0.4908\n",
      "Epoch 10/10, Train Loss: 0.1334, Accuracy: 0.8976, F1 Micro: 0.7185, F1 Macro: 0.5325\n",
      "Best result for 2535 samples: F1 Micro: 0.7185\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.88      0.84      1190\n",
      "      Abusive       0.87      0.84      0.86      1018\n",
      "HS_Individual       0.67      0.73      0.70       768\n",
      "     HS_Group       0.61      0.59      0.60       422\n",
      "  HS_Religion       0.58      0.36      0.44       173\n",
      "      HS_Race       0.77      0.59      0.67       126\n",
      "  HS_Physical       0.00      0.00      0.00        60\n",
      "    HS_Gender       0.00      0.00      0.00        67\n",
      "     HS_Other       0.67      0.81      0.74       792\n",
      "      HS_Weak       0.63      0.72      0.67       725\n",
      "  HS_Moderate       0.50      0.49      0.49       352\n",
      "    HS_Strong       0.64      0.28      0.39       113\n",
      "\n",
      "    micro avg       0.71      0.73      0.72      5806\n",
      "    macro avg       0.56      0.52      0.53      5806\n",
      " weighted avg       0.70      0.73      0.71      5806\n",
      "  samples avg       0.42      0.42      0.40      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 801\n",
      "Sampling duration: 42.58460545539856 seconds\n",
      "\n",
      "Fold 5 - New train size: 3336\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 3336 samples...\n",
      "Epoch 1/10, Train Loss: 0.4575, Accuracy: 0.8218, F1 Micro: 0.0241, F1 Macro: 0.0107\n",
      "Epoch 2/10, Train Loss: 0.3593, Accuracy: 0.8533, F1 Micro: 0.3609, F1 Macro: 0.1372\n",
      "Epoch 3/10, Train Loss: 0.3128, Accuracy: 0.8785, F1 Micro: 0.58, F1 Macro: 0.2667\n",
      "Epoch 4/10, Train Loss: 0.2777, Accuracy: 0.8923, F1 Micro: 0.6635, F1 Macro: 0.3609\n",
      "Epoch 5/10, Train Loss: 0.2334, Accuracy: 0.8985, F1 Micro: 0.6941, F1 Macro: 0.4616\n",
      "Epoch 6/10, Train Loss: 0.208, Accuracy: 0.9014, F1 Micro: 0.7033, F1 Macro: 0.5056\n",
      "Epoch 7/10, Train Loss: 0.1703, Accuracy: 0.9047, F1 Micro: 0.7228, F1 Macro: 0.5434\n",
      "Epoch 8/10, Train Loss: 0.1525, Accuracy: 0.904, F1 Micro: 0.7272, F1 Macro: 0.5315\n",
      "Epoch 9/10, Train Loss: 0.1312, Accuracy: 0.9084, F1 Micro: 0.7319, F1 Macro: 0.553\n",
      "Epoch 10/10, Train Loss: 0.1078, Accuracy: 0.908, F1 Micro: 0.7381, F1 Macro: 0.5765\n",
      "Best result for 3336 samples: F1 Micro: 0.7381\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.85      0.85      1190\n",
      "      Abusive       0.87      0.85      0.86      1018\n",
      "HS_Individual       0.70      0.73      0.72       768\n",
      "     HS_Group       0.68      0.56      0.61       422\n",
      "  HS_Religion       0.67      0.44      0.53       173\n",
      "      HS_Race       0.74      0.68      0.71       126\n",
      "  HS_Physical       1.00      0.08      0.15        60\n",
      "    HS_Gender       0.00      0.00      0.00        67\n",
      "     HS_Other       0.75      0.77      0.76       792\n",
      "      HS_Weak       0.66      0.72      0.69       725\n",
      "  HS_Moderate       0.56      0.44      0.49       352\n",
      "    HS_Strong       0.78      0.42      0.54       113\n",
      "\n",
      "    micro avg       0.76      0.72      0.74      5806\n",
      "    macro avg       0.69      0.55      0.58      5806\n",
      " weighted avg       0.75      0.72      0.73      5806\n",
      "  samples avg       0.44      0.42      0.42      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 720\n",
      "Sampling duration: 38.71533751487732 seconds\n",
      "\n",
      "Fold 5 - New train size: 4056\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 4056 samples...\n",
      "Epoch 1/10, Train Loss: 0.452, Accuracy: 0.8237, F1 Micro: 0.0492, F1 Macro: 0.0209\n",
      "Epoch 2/10, Train Loss: 0.3497, Accuracy: 0.8726, F1 Micro: 0.5443, F1 Macro: 0.2443\n",
      "Epoch 3/10, Train Loss: 0.2883, Accuracy: 0.887, F1 Micro: 0.6435, F1 Macro: 0.3115\n",
      "Epoch 4/10, Train Loss: 0.2463, Accuracy: 0.8978, F1 Micro: 0.7041, F1 Macro: 0.4361\n",
      "Epoch 5/10, Train Loss: 0.2193, Accuracy: 0.8996, F1 Micro: 0.7035, F1 Macro: 0.4433\n",
      "Epoch 6/10, Train Loss: 0.1869, Accuracy: 0.9054, F1 Micro: 0.7287, F1 Macro: 0.5323\n",
      "Epoch 7/10, Train Loss: 0.1532, Accuracy: 0.908, F1 Micro: 0.7329, F1 Macro: 0.5343\n",
      "Epoch 8/10, Train Loss: 0.1414, Accuracy: 0.9092, F1 Micro: 0.737, F1 Macro: 0.5448\n",
      "Epoch 9/10, Train Loss: 0.1138, Accuracy: 0.9092, F1 Micro: 0.7377, F1 Macro: 0.5689\n",
      "Epoch 10/10, Train Loss: 0.1017, Accuracy: 0.911, F1 Micro: 0.7422, F1 Macro: 0.576\n",
      "Best result for 4056 samples: F1 Micro: 0.7422\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.88      0.84      0.86      1190\n",
      "      Abusive       0.88      0.86      0.87      1018\n",
      "HS_Individual       0.72      0.72      0.72       768\n",
      "     HS_Group       0.70      0.55      0.61       422\n",
      "  HS_Religion       0.67      0.48      0.56       173\n",
      "      HS_Race       0.81      0.63      0.71       126\n",
      "  HS_Physical       1.00      0.05      0.10        60\n",
      "    HS_Gender       1.00      0.01      0.03        67\n",
      "     HS_Other       0.76      0.76      0.76       792\n",
      "      HS_Weak       0.68      0.70      0.69       725\n",
      "  HS_Moderate       0.56      0.46      0.51       352\n",
      "    HS_Strong       0.87      0.35      0.50       113\n",
      "\n",
      "    micro avg       0.78      0.71      0.74      5806\n",
      "    macro avg       0.79      0.53      0.58      5806\n",
      " weighted avg       0.78      0.71      0.73      5806\n",
      "  samples avg       0.44      0.42      0.41      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 648\n",
      "Sampling duration: 34.752201795578 seconds\n",
      "\n",
      "Fold 5 - New train size: 4704\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 4704 samples...\n",
      "Epoch 1/10, Train Loss: 0.4392, Accuracy: 0.842, F1 Micro: 0.2845, F1 Macro: 0.0962\n",
      "Epoch 2/10, Train Loss: 0.3461, Accuracy: 0.8754, F1 Micro: 0.625, F1 Macro: 0.2885\n",
      "Epoch 3/10, Train Loss: 0.2844, Accuracy: 0.8928, F1 Micro: 0.6575, F1 Macro: 0.362\n",
      "Epoch 4/10, Train Loss: 0.2367, Accuracy: 0.8999, F1 Micro: 0.7161, F1 Macro: 0.5033\n",
      "Epoch 5/10, Train Loss: 0.2084, Accuracy: 0.9057, F1 Micro: 0.7361, F1 Macro: 0.5471\n",
      "Epoch 6/10, Train Loss: 0.1777, Accuracy: 0.9054, F1 Micro: 0.7427, F1 Macro: 0.5738\n",
      "Epoch 7/10, Train Loss: 0.1501, Accuracy: 0.9119, F1 Micro: 0.747, F1 Macro: 0.5867\n",
      "Epoch 8/10, Train Loss: 0.1294, Accuracy: 0.9126, F1 Micro: 0.7442, F1 Macro: 0.5982\n",
      "Epoch 9/10, Train Loss: 0.1117, Accuracy: 0.9143, F1 Micro: 0.7555, F1 Macro: 0.6199\n",
      "Epoch 10/10, Train Loss: 0.0976, Accuracy: 0.9137, F1 Micro: 0.7489, F1 Macro: 0.6445\n",
      "Best result for 4704 samples: F1 Micro: 0.7555\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.87      0.85      1190\n",
      "      Abusive       0.89      0.86      0.88      1018\n",
      "HS_Individual       0.72      0.73      0.73       768\n",
      "     HS_Group       0.70      0.58      0.63       422\n",
      "  HS_Religion       0.67      0.46      0.54       173\n",
      "      HS_Race       0.83      0.75      0.79       126\n",
      "  HS_Physical       0.90      0.15      0.26        60\n",
      "    HS_Gender       1.00      0.04      0.09        67\n",
      "     HS_Other       0.76      0.79      0.77       792\n",
      "      HS_Weak       0.70      0.70      0.70       725\n",
      "  HS_Moderate       0.58      0.49      0.53       352\n",
      "    HS_Strong       0.88      0.53      0.66       113\n",
      "\n",
      "    micro avg       0.78      0.74      0.76      5806\n",
      "    macro avg       0.79      0.58      0.62      5806\n",
      " weighted avg       0.78      0.74      0.75      5806\n",
      "  samples avg       0.44      0.43      0.42      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 584\n",
      "Sampling duration: 31.303510904312134 seconds\n",
      "\n",
      "Fold 5 - New train size: 5288\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 5288 samples...\n",
      "Epoch 1/10, Train Loss: 0.4333, Accuracy: 0.8426, F1 Micro: 0.2707, F1 Macro: 0.0929\n",
      "Epoch 2/10, Train Loss: 0.3296, Accuracy: 0.8832, F1 Micro: 0.6284, F1 Macro: 0.2959\n",
      "Epoch 3/10, Train Loss: 0.2679, Accuracy: 0.8961, F1 Micro: 0.6587, F1 Macro: 0.4007\n",
      "Epoch 4/10, Train Loss: 0.2226, Accuracy: 0.9027, F1 Micro: 0.7277, F1 Macro: 0.5451\n",
      "Epoch 5/10, Train Loss: 0.1959, Accuracy: 0.9087, F1 Micro: 0.7308, F1 Macro: 0.552\n",
      "Epoch 6/10, Train Loss: 0.1677, Accuracy: 0.9131, F1 Micro: 0.745, F1 Macro: 0.5695\n",
      "Epoch 7/10, Train Loss: 0.137, Accuracy: 0.9094, F1 Micro: 0.7485, F1 Macro: 0.577\n",
      "Epoch 8/10, Train Loss: 0.1195, Accuracy: 0.9145, F1 Micro: 0.7532, F1 Macro: 0.6152\n",
      "Epoch 9/10, Train Loss: 0.1048, Accuracy: 0.9065, F1 Micro: 0.7484, F1 Macro: 0.6108\n",
      "Epoch 10/10, Train Loss: 0.0897, Accuracy: 0.9143, F1 Micro: 0.7611, F1 Macro: 0.6532\n",
      "Best result for 5288 samples: F1 Micro: 0.7611\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.88      0.86      1190\n",
      "      Abusive       0.85      0.91      0.88      1018\n",
      "HS_Individual       0.71      0.74      0.72       768\n",
      "     HS_Group       0.71      0.60      0.65       422\n",
      "  HS_Religion       0.66      0.54      0.59       173\n",
      "      HS_Race       0.81      0.73      0.77       126\n",
      "  HS_Physical       0.74      0.23      0.35        60\n",
      "    HS_Gender       0.92      0.18      0.30        67\n",
      "     HS_Other       0.77      0.78      0.77       792\n",
      "      HS_Weak       0.67      0.73      0.70       725\n",
      "  HS_Moderate       0.59      0.53      0.56       352\n",
      "    HS_Strong       0.88      0.56      0.68       113\n",
      "\n",
      "    micro avg       0.76      0.76      0.76      5806\n",
      "    macro avg       0.76      0.62      0.65      5806\n",
      " weighted avg       0.76      0.76      0.75      5806\n",
      "  samples avg       0.46      0.45      0.44      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 525\n",
      "Sampling duration: 28.1621515750885 seconds\n",
      "\n",
      "Fold 5 - New train size: 5813\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 5813 samples...\n",
      "Epoch 1/10, Train Loss: 0.4275, Accuracy: 0.8523, F1 Micro: 0.3681, F1 Macro: 0.129\n",
      "Epoch 2/10, Train Loss: 0.3131, Accuracy: 0.8873, F1 Micro: 0.6548, F1 Macro: 0.3245\n",
      "Epoch 3/10, Train Loss: 0.2545, Accuracy: 0.8984, F1 Micro: 0.664, F1 Macro: 0.451\n",
      "Epoch 4/10, Train Loss: 0.2205, Accuracy: 0.9086, F1 Micro: 0.7294, F1 Macro: 0.5366\n",
      "Epoch 5/10, Train Loss: 0.1862, Accuracy: 0.9101, F1 Micro: 0.754, F1 Macro: 0.5873\n",
      "Epoch 6/10, Train Loss: 0.1652, Accuracy: 0.9145, F1 Micro: 0.7461, F1 Macro: 0.5632\n",
      "Epoch 7/10, Train Loss: 0.1331, Accuracy: 0.9113, F1 Micro: 0.7585, F1 Macro: 0.6158\n",
      "Epoch 8/10, Train Loss: 0.1177, Accuracy: 0.9145, F1 Micro: 0.7566, F1 Macro: 0.6232\n",
      "Epoch 9/10, Train Loss: 0.1, Accuracy: 0.9159, F1 Micro: 0.7633, F1 Macro: 0.6495\n",
      "Epoch 10/10, Train Loss: 0.083, Accuracy: 0.9192, F1 Micro: 0.7667, F1 Macro: 0.6706\n",
      "Best result for 5813 samples: F1 Micro: 0.7667\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.88      0.84      0.86      1190\n",
      "      Abusive       0.87      0.89      0.88      1018\n",
      "HS_Individual       0.76      0.70      0.73       768\n",
      "     HS_Group       0.71      0.63      0.66       422\n",
      "  HS_Religion       0.68      0.61      0.64       173\n",
      "      HS_Race       0.83      0.72      0.77       126\n",
      "  HS_Physical       0.71      0.28      0.40        60\n",
      "    HS_Gender       0.77      0.15      0.25        67\n",
      "     HS_Other       0.79      0.75      0.77       792\n",
      "      HS_Weak       0.74      0.69      0.71       725\n",
      "  HS_Moderate       0.61      0.53      0.57       352\n",
      "    HS_Strong       0.86      0.73      0.79       113\n",
      "\n",
      "    micro avg       0.80      0.74      0.77      5806\n",
      "    macro avg       0.77      0.63      0.67      5806\n",
      " weighted avg       0.80      0.74      0.76      5806\n",
      "  samples avg       0.45      0.43      0.43      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 473\n",
      "Sampling duration: 25.797647714614868 seconds\n",
      "\n",
      "Fold 5 - New train size: 6286\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 6286 samples...\n",
      "Epoch 1/10, Train Loss: 0.4183, Accuracy: 0.8603, F1 Micro: 0.4493, F1 Macro: 0.1746\n",
      "Epoch 2/10, Train Loss: 0.3081, Accuracy: 0.8913, F1 Micro: 0.6592, F1 Macro: 0.3523\n",
      "Epoch 3/10, Train Loss: 0.2474, Accuracy: 0.903, F1 Micro: 0.689, F1 Macro: 0.47\n",
      "Epoch 4/10, Train Loss: 0.2152, Accuracy: 0.9117, F1 Micro: 0.7317, F1 Macro: 0.5465\n",
      "Epoch 5/10, Train Loss: 0.182, Accuracy: 0.9134, F1 Micro: 0.7407, F1 Macro: 0.5721\n",
      "Epoch 6/10, Train Loss: 0.1598, Accuracy: 0.9145, F1 Micro: 0.7535, F1 Macro: 0.5805\n",
      "Epoch 7/10, Train Loss: 0.1259, Accuracy: 0.9169, F1 Micro: 0.7611, F1 Macro: 0.6382\n",
      "Epoch 8/10, Train Loss: 0.1093, Accuracy: 0.9148, F1 Micro: 0.7631, F1 Macro: 0.6487\n",
      "Epoch 9/10, Train Loss: 0.091, Accuracy: 0.918, F1 Micro: 0.7604, F1 Macro: 0.6536\n",
      "Epoch 10/10, Train Loss: 0.0805, Accuracy: 0.9195, F1 Micro: 0.7683, F1 Macro: 0.6836\n",
      "Best result for 6286 samples: F1 Micro: 0.7683\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.87      0.85      0.86      1190\n",
      "      Abusive       0.90      0.87      0.89      1018\n",
      "HS_Individual       0.73      0.74      0.73       768\n",
      "     HS_Group       0.74      0.57      0.65       422\n",
      "  HS_Religion       0.67      0.54      0.60       173\n",
      "      HS_Race       0.81      0.72      0.76       126\n",
      "  HS_Physical       0.70      0.32      0.44        60\n",
      "    HS_Gender       0.90      0.28      0.43        67\n",
      "     HS_Other       0.80      0.75      0.78       792\n",
      "      HS_Weak       0.70      0.72      0.71       725\n",
      "  HS_Moderate       0.66      0.49      0.56       352\n",
      "    HS_Strong       0.85      0.75      0.80       113\n",
      "\n",
      "    micro avg       0.80      0.74      0.77      5806\n",
      "    macro avg       0.78      0.63      0.68      5806\n",
      " weighted avg       0.79      0.74      0.76      5806\n",
      "  samples avg       0.45      0.43      0.43      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Acquired samples: 298\n",
      "Sampling duration: 23.010236024856567 seconds\n",
      "\n",
      "Fold 5 - New train size: 6584\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 6584 samples...\n",
      "Epoch 1/10, Train Loss: 0.4167, Accuracy: 0.8628, F1 Micro: 0.4714, F1 Macro: 0.1887\n",
      "Epoch 2/10, Train Loss: 0.304, Accuracy: 0.8888, F1 Micro: 0.63, F1 Macro: 0.3394\n",
      "Epoch 3/10, Train Loss: 0.2525, Accuracy: 0.9036, F1 Micro: 0.7157, F1 Macro: 0.5179\n",
      "Epoch 4/10, Train Loss: 0.216, Accuracy: 0.9078, F1 Micro: 0.6986, F1 Macro: 0.4777\n",
      "Epoch 5/10, Train Loss: 0.1849, Accuracy: 0.913, F1 Micro: 0.7449, F1 Macro: 0.5581\n",
      "Epoch 6/10, Train Loss: 0.1531, Accuracy: 0.916, F1 Micro: 0.745, F1 Macro: 0.5772\n",
      "Epoch 7/10, Train Loss: 0.1237, Accuracy: 0.9145, F1 Micro: 0.7581, F1 Macro: 0.6463\n",
      "Epoch 8/10, Train Loss: 0.1073, Accuracy: 0.9187, F1 Micro: 0.7611, F1 Macro: 0.6481\n",
      "Epoch 9/10, Train Loss: 0.0937, Accuracy: 0.9175, F1 Micro: 0.7613, F1 Macro: 0.6494\n",
      "Epoch 10/10, Train Loss: 0.0791, Accuracy: 0.9176, F1 Micro: 0.7687, F1 Macro: 0.6694\n",
      "Best result for 6584 samples: F1 Micro: 0.7687\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.87      0.86      1190\n",
      "      Abusive       0.89      0.88      0.88      1018\n",
      "HS_Individual       0.72      0.74      0.73       768\n",
      "     HS_Group       0.72      0.63      0.67       422\n",
      "  HS_Religion       0.70      0.56      0.62       173\n",
      "      HS_Race       0.83      0.72      0.77       126\n",
      "  HS_Physical       1.00      0.17      0.29        60\n",
      "    HS_Gender       0.93      0.21      0.34        67\n",
      "     HS_Other       0.74      0.81      0.77       792\n",
      "      HS_Weak       0.69      0.72      0.71       725\n",
      "  HS_Moderate       0.64      0.55      0.59       352\n",
      "    HS_Strong       0.88      0.73      0.80       113\n",
      "\n",
      "    micro avg       0.78      0.76      0.77      5806\n",
      "    macro avg       0.80      0.63      0.67      5806\n",
      " weighted avg       0.78      0.76      0.76      5806\n",
      "  samples avg       0.46      0.44      0.43      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Acquired samples: 396\n",
      "Sampling duration: 21.412178993225098 seconds\n",
      "\n",
      "Fold 5 - New train size: 6980\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 6980 samples...\n",
      "Epoch 1/10, Train Loss: 0.4129, Accuracy: 0.8575, F1 Micro: 0.3994, F1 Macro: 0.1598\n",
      "Epoch 2/10, Train Loss: 0.2983, Accuracy: 0.8916, F1 Micro: 0.6409, F1 Macro: 0.3888\n",
      "Epoch 3/10, Train Loss: 0.2432, Accuracy: 0.9067, F1 Micro: 0.7183, F1 Macro: 0.5149\n",
      "Epoch 4/10, Train Loss: 0.2019, Accuracy: 0.9121, F1 Micro: 0.7362, F1 Macro: 0.5587\n",
      "Epoch 5/10, Train Loss: 0.1726, Accuracy: 0.9165, F1 Micro: 0.7562, F1 Macro: 0.5989\n",
      "Epoch 6/10, Train Loss: 0.1433, Accuracy: 0.9134, F1 Micro: 0.7631, F1 Macro: 0.6399\n",
      "Epoch 7/10, Train Loss: 0.1235, Accuracy: 0.9168, F1 Micro: 0.7702, F1 Macro: 0.6521\n",
      "Epoch 8/10, Train Loss: 0.1071, Accuracy: 0.9201, F1 Micro: 0.7734, F1 Macro: 0.6806\n",
      "Epoch 9/10, Train Loss: 0.091, Accuracy: 0.9205, F1 Micro: 0.7757, F1 Macro: 0.6788\n",
      "Epoch 10/10, Train Loss: 0.077, Accuracy: 0.9209, F1 Micro: 0.7738, F1 Macro: 0.6876\n",
      "Best result for 6980 samples: F1 Micro: 0.7757\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.88      0.87      1190\n",
      "      Abusive       0.91      0.86      0.88      1018\n",
      "HS_Individual       0.76      0.74      0.75       768\n",
      "     HS_Group       0.67      0.67      0.67       422\n",
      "  HS_Religion       0.65      0.62      0.63       173\n",
      "      HS_Race       0.80      0.71      0.76       126\n",
      "  HS_Physical       1.00      0.20      0.33        60\n",
      "    HS_Gender       0.94      0.22      0.36        67\n",
      "     HS_Other       0.78      0.79      0.79       792\n",
      "      HS_Weak       0.74      0.71      0.73       725\n",
      "  HS_Moderate       0.59      0.57      0.58       352\n",
      "    HS_Strong       0.83      0.77      0.80       113\n",
      "\n",
      "    micro avg       0.79      0.76      0.78      5806\n",
      "    macro avg       0.79      0.65      0.68      5806\n",
      " weighted avg       0.79      0.76      0.77      5806\n",
      "  samples avg       0.45      0.44      0.43      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Acquired samples: 356\n",
      "Sampling duration: 19.57528829574585 seconds\n",
      "\n",
      "Fold 5 - New train size: 7336\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 7336 samples...\n",
      "Epoch 1/10, Train Loss: 0.405, Accuracy: 0.8688, F1 Micro: 0.5187, F1 Macro: 0.2309\n",
      "Epoch 2/10, Train Loss: 0.2955, Accuracy: 0.8962, F1 Micro: 0.6793, F1 Macro: 0.4183\n",
      "Epoch 3/10, Train Loss: 0.2418, Accuracy: 0.9061, F1 Micro: 0.7236, F1 Macro: 0.5151\n",
      "Epoch 4/10, Train Loss: 0.1997, Accuracy: 0.9144, F1 Micro: 0.7448, F1 Macro: 0.5681\n",
      "Epoch 5/10, Train Loss: 0.1762, Accuracy: 0.9126, F1 Micro: 0.7576, F1 Macro: 0.588\n",
      "Epoch 6/10, Train Loss: 0.1447, Accuracy: 0.9173, F1 Micro: 0.7612, F1 Macro: 0.6194\n",
      "Epoch 7/10, Train Loss: 0.1259, Accuracy: 0.9203, F1 Micro: 0.7719, F1 Macro: 0.6652\n",
      "Epoch 8/10, Train Loss: 0.0992, Accuracy: 0.9202, F1 Micro: 0.7719, F1 Macro: 0.6697\n",
      "Epoch 9/10, Train Loss: 0.0877, Accuracy: 0.9209, F1 Micro: 0.7741, F1 Macro: 0.6814\n",
      "Epoch 10/10, Train Loss: 0.0747, Accuracy: 0.9235, F1 Micro: 0.7796, F1 Macro: 0.6943\n",
      "Best result for 7336 samples: F1 Micro: 0.7796\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.89      0.84      0.86      1190\n",
      "      Abusive       0.89      0.89      0.89      1018\n",
      "HS_Individual       0.75      0.73      0.74       768\n",
      "     HS_Group       0.74      0.61      0.67       422\n",
      "  HS_Religion       0.78      0.51      0.62       173\n",
      "      HS_Race       0.86      0.71      0.78       126\n",
      "  HS_Physical       1.00      0.23      0.38        60\n",
      "    HS_Gender       0.84      0.31      0.46        67\n",
      "     HS_Other       0.79      0.80      0.79       792\n",
      "      HS_Weak       0.73      0.71      0.72       725\n",
      "  HS_Moderate       0.67      0.54      0.60       352\n",
      "    HS_Strong       0.86      0.79      0.82       113\n",
      "\n",
      "    micro avg       0.81      0.75      0.78      5806\n",
      "    macro avg       0.82      0.64      0.69      5806\n",
      " weighted avg       0.81      0.75      0.77      5806\n",
      "  samples avg       0.45      0.44      0.43      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Acquired samples: 320\n",
      "Sampling duration: 17.661192893981934 seconds\n",
      "\n",
      "Fold 5 - New train size: 7656\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 7656 samples...\n",
      "Epoch 1/10, Train Loss: 0.4036, Accuracy: 0.8717, F1 Micro: 0.5344, F1 Macro: 0.2436\n",
      "Epoch 2/10, Train Loss: 0.2936, Accuracy: 0.8968, F1 Micro: 0.7052, F1 Macro: 0.4922\n",
      "Epoch 3/10, Train Loss: 0.2361, Accuracy: 0.9063, F1 Micro: 0.6988, F1 Macro: 0.4922\n",
      "Epoch 4/10, Train Loss: 0.2007, Accuracy: 0.9091, F1 Micro: 0.7523, F1 Macro: 0.5761\n",
      "Epoch 5/10, Train Loss: 0.1745, Accuracy: 0.9163, F1 Micro: 0.7574, F1 Macro: 0.595\n",
      "Epoch 6/10, Train Loss: 0.1483, Accuracy: 0.9204, F1 Micro: 0.769, F1 Macro: 0.63\n",
      "Epoch 7/10, Train Loss: 0.1189, Accuracy: 0.9204, F1 Micro: 0.769, F1 Macro: 0.668\n",
      "Epoch 8/10, Train Loss: 0.0948, Accuracy: 0.9178, F1 Micro: 0.776, F1 Macro: 0.6893\n",
      "Epoch 9/10, Train Loss: 0.0888, Accuracy: 0.9232, F1 Micro: 0.7767, F1 Macro: 0.6898\n",
      "Epoch 10/10, Train Loss: 0.0761, Accuracy: 0.9224, F1 Micro: 0.7782, F1 Macro: 0.7096\n",
      "Best result for 7656 samples: F1 Micro: 0.7782\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.87      0.85      0.86      1190\n",
      "      Abusive       0.88      0.89      0.89      1018\n",
      "HS_Individual       0.73      0.74      0.74       768\n",
      "     HS_Group       0.75      0.62      0.68       422\n",
      "  HS_Religion       0.74      0.56      0.64       173\n",
      "      HS_Race       0.82      0.70      0.76       126\n",
      "  HS_Physical       0.81      0.42      0.55        60\n",
      "    HS_Gender       0.82      0.34      0.48        67\n",
      "     HS_Other       0.80      0.76      0.78       792\n",
      "      HS_Weak       0.71      0.73      0.72       725\n",
      "  HS_Moderate       0.67      0.55      0.60       352\n",
      "    HS_Strong       0.91      0.74      0.82       113\n",
      "\n",
      "    micro avg       0.80      0.76      0.78      5806\n",
      "    macro avg       0.79      0.66      0.71      5806\n",
      " weighted avg       0.80      0.76      0.77      5806\n",
      "  samples avg       0.45      0.44      0.43      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Acquired samples: 245\n",
      "Sampling duration: 16.034616708755493 seconds\n",
      "\n",
      "Fold 5 - New train size: 7901\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 7901 samples...\n",
      "Epoch 1/10, Train Loss: 0.4076, Accuracy: 0.8732, F1 Micro: 0.5841, F1 Macro: 0.269\n",
      "Epoch 2/10, Train Loss: 0.2857, Accuracy: 0.8994, F1 Micro: 0.6972, F1 Macro: 0.4541\n",
      "Epoch 3/10, Train Loss: 0.2347, Accuracy: 0.9085, F1 Micro: 0.7311, F1 Macro: 0.5467\n",
      "Epoch 4/10, Train Loss: 0.1977, Accuracy: 0.9145, F1 Micro: 0.747, F1 Macro: 0.5813\n",
      "Epoch 5/10, Train Loss: 0.1661, Accuracy: 0.9145, F1 Micro: 0.7585, F1 Macro: 0.6096\n",
      "Epoch 6/10, Train Loss: 0.148, Accuracy: 0.9202, F1 Micro: 0.7724, F1 Macro: 0.6409\n",
      "Epoch 7/10, Train Loss: 0.1176, Accuracy: 0.9189, F1 Micro: 0.7739, F1 Macro: 0.6521\n",
      "Epoch 8/10, Train Loss: 0.0985, Accuracy: 0.922, F1 Micro: 0.783, F1 Macro: 0.6973\n",
      "Epoch 9/10, Train Loss: 0.0882, Accuracy: 0.9182, F1 Micro: 0.7794, F1 Macro: 0.6919\n",
      "Epoch 10/10, Train Loss: 0.0738, Accuracy: 0.9204, F1 Micro: 0.7822, F1 Macro: 0.698\n",
      "Best result for 7901 samples: F1 Micro: 0.783\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.89      0.86      1190\n",
      "      Abusive       0.87      0.90      0.89      1018\n",
      "HS_Individual       0.73      0.78      0.75       768\n",
      "     HS_Group       0.72      0.65      0.68       422\n",
      "  HS_Religion       0.68      0.62      0.65       173\n",
      "      HS_Race       0.79      0.75      0.77       126\n",
      "  HS_Physical       0.83      0.25      0.38        60\n",
      "    HS_Gender       0.87      0.30      0.44        67\n",
      "     HS_Other       0.80      0.79      0.79       792\n",
      "      HS_Weak       0.72      0.76      0.74       725\n",
      "  HS_Moderate       0.64      0.56      0.60       352\n",
      "    HS_Strong       0.82      0.79      0.81       113\n",
      "\n",
      "    micro avg       0.78      0.78      0.78      5806\n",
      "    macro avg       0.78      0.67      0.70      5806\n",
      " weighted avg       0.78      0.78      0.78      5806\n",
      "  samples avg       0.46      0.45      0.44      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 264\n",
      "Sampling duration: 14.934598684310913 seconds\n",
      "\n",
      "Fold 5 - New train size: 8165\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 8165 samples...\n",
      "Epoch 1/10, Train Loss: 0.3997, Accuracy: 0.8744, F1 Micro: 0.6022, F1 Macro: 0.2785\n",
      "Epoch 2/10, Train Loss: 0.2815, Accuracy: 0.8977, F1 Micro: 0.709, F1 Macro: 0.4996\n",
      "Epoch 3/10, Train Loss: 0.2298, Accuracy: 0.9078, F1 Micro: 0.6999, F1 Macro: 0.5146\n",
      "Epoch 4/10, Train Loss: 0.1965, Accuracy: 0.915, F1 Micro: 0.7528, F1 Macro: 0.5739\n",
      "Epoch 5/10, Train Loss: 0.1624, Accuracy: 0.9177, F1 Micro: 0.7636, F1 Macro: 0.6019\n",
      "Epoch 6/10, Train Loss: 0.1363, Accuracy: 0.9178, F1 Micro: 0.7679, F1 Macro: 0.6485\n",
      "Epoch 7/10, Train Loss: 0.1187, Accuracy: 0.9181, F1 Micro: 0.7749, F1 Macro: 0.6734\n",
      "Epoch 8/10, Train Loss: 0.0998, Accuracy: 0.9225, F1 Micro: 0.7783, F1 Macro: 0.6909\n",
      "Epoch 9/10, Train Loss: 0.0822, Accuracy: 0.92, F1 Micro: 0.7795, F1 Macro: 0.6901\n",
      "Epoch 10/10, Train Loss: 0.0712, Accuracy: 0.9202, F1 Micro: 0.7744, F1 Macro: 0.6998\n",
      "Best result for 8165 samples: F1 Micro: 0.7795\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.89      0.86      1190\n",
      "      Abusive       0.88      0.89      0.89      1018\n",
      "HS_Individual       0.70      0.81      0.75       768\n",
      "     HS_Group       0.77      0.61      0.68       422\n",
      "  HS_Religion       0.74      0.51      0.61       173\n",
      "      HS_Race       0.78      0.75      0.76       126\n",
      "  HS_Physical       0.77      0.28      0.41        60\n",
      "    HS_Gender       0.78      0.27      0.40        67\n",
      "     HS_Other       0.75      0.82      0.78       792\n",
      "      HS_Weak       0.67      0.79      0.73       725\n",
      "  HS_Moderate       0.69      0.53      0.60       352\n",
      "    HS_Strong       0.89      0.73      0.81       113\n",
      "\n",
      "    micro avg       0.77      0.79      0.78      5806\n",
      "    macro avg       0.77      0.66      0.69      5806\n",
      " weighted avg       0.78      0.79      0.77      5806\n",
      "  samples avg       0.46      0.46      0.44      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 238\n",
      "Sampling duration: 13.386362075805664 seconds\n",
      "\n",
      "Fold 5 - New train size: 8403\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 8403 samples...\n",
      "Epoch 1/10, Train Loss: 0.3983, Accuracy: 0.8746, F1 Micro: 0.5603, F1 Macro: 0.2577\n",
      "Epoch 2/10, Train Loss: 0.2792, Accuracy: 0.8986, F1 Micro: 0.7023, F1 Macro: 0.4615\n",
      "Epoch 3/10, Train Loss: 0.2328, Accuracy: 0.9061, F1 Micro: 0.7281, F1 Macro: 0.5069\n",
      "Epoch 4/10, Train Loss: 0.1923, Accuracy: 0.9141, F1 Micro: 0.753, F1 Macro: 0.589\n",
      "Epoch 5/10, Train Loss: 0.1619, Accuracy: 0.9178, F1 Micro: 0.7679, F1 Macro: 0.6334\n",
      "Epoch 6/10, Train Loss: 0.1324, Accuracy: 0.9175, F1 Micro: 0.7643, F1 Macro: 0.6324\n",
      "Epoch 7/10, Train Loss: 0.1165, Accuracy: 0.9167, F1 Micro: 0.7724, F1 Macro: 0.6665\n",
      "Epoch 8/10, Train Loss: 0.099, Accuracy: 0.9218, F1 Micro: 0.7729, F1 Macro: 0.6802\n",
      "Epoch 9/10, Train Loss: 0.0851, Accuracy: 0.9203, F1 Micro: 0.7808, F1 Macro: 0.7032\n",
      "Epoch 10/10, Train Loss: 0.0722, Accuracy: 0.9235, F1 Micro: 0.78, F1 Macro: 0.7023\n",
      "Best result for 8403 samples: F1 Micro: 0.7808\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.90      0.87      1190\n",
      "      Abusive       0.89      0.89      0.89      1018\n",
      "HS_Individual       0.70      0.80      0.75       768\n",
      "     HS_Group       0.73      0.62      0.67       422\n",
      "  HS_Religion       0.73      0.55      0.63       173\n",
      "      HS_Race       0.80      0.67      0.73       126\n",
      "  HS_Physical       0.81      0.37      0.51        60\n",
      "    HS_Gender       0.82      0.34      0.48        67\n",
      "     HS_Other       0.75      0.84      0.79       792\n",
      "      HS_Weak       0.68      0.78      0.73       725\n",
      "  HS_Moderate       0.66      0.55      0.60       352\n",
      "    HS_Strong       0.85      0.75      0.80       113\n",
      "\n",
      "    micro avg       0.77      0.79      0.78      5806\n",
      "    macro avg       0.77      0.67      0.70      5806\n",
      " weighted avg       0.77      0.79      0.78      5806\n",
      "  samples avg       0.46      0.46      0.44      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 214\n",
      "Sampling duration: 12.247583627700806 seconds\n",
      "\n",
      "Fold 5 - New train size: 8617\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 8617 samples...\n",
      "Epoch 1/10, Train Loss: 0.3954, Accuracy: 0.8718, F1 Micro: 0.5365, F1 Macro: 0.2459\n",
      "Epoch 2/10, Train Loss: 0.2779, Accuracy: 0.9, F1 Micro: 0.7121, F1 Macro: 0.5148\n",
      "Epoch 3/10, Train Loss: 0.228, Accuracy: 0.9108, F1 Micro: 0.7309, F1 Macro: 0.534\n",
      "Epoch 4/10, Train Loss: 0.189, Accuracy: 0.9145, F1 Micro: 0.7402, F1 Macro: 0.5846\n",
      "Epoch 5/10, Train Loss: 0.1556, Accuracy: 0.9197, F1 Micro: 0.7517, F1 Macro: 0.6051\n",
      "Epoch 6/10, Train Loss: 0.1374, Accuracy: 0.9218, F1 Micro: 0.7766, F1 Macro: 0.6512\n",
      "Epoch 7/10, Train Loss: 0.1158, Accuracy: 0.9155, F1 Micro: 0.7686, F1 Macro: 0.6792\n",
      "Epoch 8/10, Train Loss: 0.1004, Accuracy: 0.9202, F1 Micro: 0.781, F1 Macro: 0.6965\n",
      "Epoch 9/10, Train Loss: 0.082, Accuracy: 0.9226, F1 Micro: 0.7793, F1 Macro: 0.6996\n",
      "Epoch 10/10, Train Loss: 0.0694, Accuracy: 0.9211, F1 Micro: 0.7817, F1 Macro: 0.7143\n",
      "Best result for 8617 samples: F1 Micro: 0.7817\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.88      0.86      1190\n",
      "      Abusive       0.86      0.92      0.89      1018\n",
      "HS_Individual       0.73      0.76      0.74       768\n",
      "     HS_Group       0.72      0.66      0.68       422\n",
      "  HS_Religion       0.70      0.55      0.62       173\n",
      "      HS_Race       0.81      0.73      0.77       126\n",
      "  HS_Physical       0.85      0.38      0.53        60\n",
      "    HS_Gender       0.84      0.40      0.55        67\n",
      "     HS_Other       0.77      0.82      0.79       792\n",
      "      HS_Weak       0.71      0.74      0.73       725\n",
      "  HS_Moderate       0.63      0.59      0.61       352\n",
      "    HS_Strong       0.88      0.75      0.81       113\n",
      "\n",
      "    micro avg       0.78      0.78      0.78      5806\n",
      "    macro avg       0.78      0.68      0.71      5806\n",
      " weighted avg       0.78      0.78      0.78      5806\n",
      "  samples avg       0.47      0.46      0.45      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 200\n",
      "Sampling duration: 11.053860425949097 seconds\n",
      "\n",
      "Fold 5 - New train size: 8817\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 8817 samples...\n",
      "Epoch 1/10, Train Loss: 0.3982, Accuracy: 0.8724, F1 Micro: 0.5317, F1 Macro: 0.2446\n",
      "Epoch 2/10, Train Loss: 0.2791, Accuracy: 0.9017, F1 Micro: 0.7036, F1 Macro: 0.4843\n",
      "Epoch 3/10, Train Loss: 0.2277, Accuracy: 0.9099, F1 Micro: 0.7352, F1 Macro: 0.5411\n",
      "Epoch 4/10, Train Loss: 0.1901, Accuracy: 0.918, F1 Micro: 0.7548, F1 Macro: 0.5949\n",
      "Epoch 5/10, Train Loss: 0.1594, Accuracy: 0.9182, F1 Micro: 0.7602, F1 Macro: 0.5961\n",
      "Epoch 6/10, Train Loss: 0.1348, Accuracy: 0.9187, F1 Micro: 0.7763, F1 Macro: 0.6496\n",
      "Epoch 7/10, Train Loss: 0.1119, Accuracy: 0.9214, F1 Micro: 0.7818, F1 Macro: 0.6775\n",
      "Epoch 8/10, Train Loss: 0.0954, Accuracy: 0.9238, F1 Micro: 0.7815, F1 Macro: 0.6977\n",
      "Epoch 9/10, Train Loss: 0.0815, Accuracy: 0.919, F1 Micro: 0.7796, F1 Macro: 0.707\n",
      "Epoch 10/10, Train Loss: 0.0712, Accuracy: 0.9246, F1 Micro: 0.7874, F1 Macro: 0.7293\n",
      "Best result for 8817 samples: F1 Micro: 0.7874\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.87      0.86      0.87      1190\n",
      "      Abusive       0.90      0.88      0.89      1018\n",
      "HS_Individual       0.73      0.77      0.75       768\n",
      "     HS_Group       0.76      0.64      0.69       422\n",
      "  HS_Religion       0.70      0.66      0.68       173\n",
      "      HS_Race       0.79      0.73      0.76       126\n",
      "  HS_Physical       0.80      0.47      0.59        60\n",
      "    HS_Gender       0.83      0.43      0.57        67\n",
      "     HS_Other       0.80      0.78      0.79       792\n",
      "      HS_Weak       0.71      0.76      0.73       725\n",
      "  HS_Moderate       0.69      0.56      0.61       352\n",
      "    HS_Strong       0.86      0.77      0.81       113\n",
      "\n",
      "    micro avg       0.80      0.78      0.79      5806\n",
      "    macro avg       0.79      0.69      0.73      5806\n",
      " weighted avg       0.80      0.78      0.79      5806\n",
      "  samples avg       0.45      0.45      0.44      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 200\n",
      "Sampling duration: 10.100735187530518 seconds\n",
      "\n",
      "Fold 5 - New train size: 9017\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 9017 samples...\n",
      "Epoch 1/10, Train Loss: 0.3964, Accuracy: 0.8752, F1 Micro: 0.5609, F1 Macro: 0.2575\n",
      "Epoch 2/10, Train Loss: 0.2697, Accuracy: 0.9014, F1 Micro: 0.7165, F1 Macro: 0.5111\n",
      "Epoch 3/10, Train Loss: 0.2251, Accuracy: 0.9134, F1 Micro: 0.7363, F1 Macro: 0.5483\n",
      "Epoch 4/10, Train Loss: 0.1867, Accuracy: 0.918, F1 Micro: 0.7591, F1 Macro: 0.6014\n",
      "Epoch 5/10, Train Loss: 0.1559, Accuracy: 0.9195, F1 Micro: 0.7714, F1 Macro: 0.6159\n",
      "Epoch 6/10, Train Loss: 0.1312, Accuracy: 0.9214, F1 Micro: 0.7806, F1 Macro: 0.6876\n",
      "Epoch 7/10, Train Loss: 0.1104, Accuracy: 0.9188, F1 Micro: 0.7781, F1 Macro: 0.6892\n",
      "Epoch 8/10, Train Loss: 0.0928, Accuracy: 0.9235, F1 Micro: 0.7818, F1 Macro: 0.6835\n",
      "Epoch 9/10, Train Loss: 0.083, Accuracy: 0.9229, F1 Micro: 0.7801, F1 Macro: 0.7089\n",
      "Epoch 10/10, Train Loss: 0.0726, Accuracy: 0.9247, F1 Micro: 0.788, F1 Macro: 0.7222\n",
      "Best result for 9017 samples: F1 Micro: 0.788\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.87      0.87      1190\n",
      "      Abusive       0.88      0.92      0.90      1018\n",
      "HS_Individual       0.75      0.75      0.75       768\n",
      "     HS_Group       0.75      0.67      0.71       422\n",
      "  HS_Religion       0.69      0.58      0.63       173\n",
      "      HS_Race       0.83      0.73      0.78       126\n",
      "  HS_Physical       0.86      0.42      0.56        60\n",
      "    HS_Gender       0.81      0.43      0.56        67\n",
      "     HS_Other       0.79      0.79      0.79       792\n",
      "      HS_Weak       0.74      0.72      0.73       725\n",
      "  HS_Moderate       0.64      0.58      0.61       352\n",
      "    HS_Strong       0.82      0.75      0.78       113\n",
      "\n",
      "    micro avg       0.80      0.78      0.79      5806\n",
      "    macro avg       0.79      0.68      0.72      5806\n",
      " weighted avg       0.80      0.78      0.78      5806\n",
      "  samples avg       0.46      0.45      0.44      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 200\n",
      "Sampling duration: 9.156816959381104 seconds\n",
      "\n",
      "Fold 5 - New train size: 9217\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 9217 samples...\n",
      "Epoch 1/10, Train Loss: 0.3943, Accuracy: 0.8791, F1 Micro: 0.614, F1 Macro: 0.292\n",
      "Epoch 2/10, Train Loss: 0.2693, Accuracy: 0.9029, F1 Micro: 0.7047, F1 Macro: 0.4631\n",
      "Epoch 3/10, Train Loss: 0.2253, Accuracy: 0.9115, F1 Micro: 0.7422, F1 Macro: 0.5477\n",
      "Epoch 4/10, Train Loss: 0.1865, Accuracy: 0.9181, F1 Micro: 0.7645, F1 Macro: 0.6146\n",
      "Epoch 5/10, Train Loss: 0.1575, Accuracy: 0.9213, F1 Micro: 0.778, F1 Macro: 0.6441\n",
      "Epoch 6/10, Train Loss: 0.1325, Accuracy: 0.92, F1 Micro: 0.7794, F1 Macro: 0.6909\n",
      "Epoch 7/10, Train Loss: 0.1102, Accuracy: 0.9234, F1 Micro: 0.7792, F1 Macro: 0.6874\n",
      "Epoch 8/10, Train Loss: 0.095, Accuracy: 0.9248, F1 Micro: 0.7853, F1 Macro: 0.6977\n",
      "Epoch 9/10, Train Loss: 0.0768, Accuracy: 0.9251, F1 Micro: 0.7807, F1 Macro: 0.7133\n",
      "Epoch 10/10, Train Loss: 0.0698, Accuracy: 0.9228, F1 Micro: 0.7749, F1 Macro: 0.7048\n",
      "Best result for 9217 samples: F1 Micro: 0.7853\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.87      0.87      0.87      1190\n",
      "      Abusive       0.90      0.89      0.89      1018\n",
      "HS_Individual       0.75      0.75      0.75       768\n",
      "     HS_Group       0.76      0.64      0.69       422\n",
      "  HS_Religion       0.79      0.52      0.63       173\n",
      "      HS_Race       0.82      0.67      0.74       126\n",
      "  HS_Physical       0.94      0.27      0.42        60\n",
      "    HS_Gender       0.95      0.30      0.45        67\n",
      "     HS_Other       0.78      0.81      0.79       792\n",
      "      HS_Weak       0.73      0.73      0.73       725\n",
      "  HS_Moderate       0.68      0.54      0.60       352\n",
      "    HS_Strong       0.86      0.76      0.81       113\n",
      "\n",
      "    micro avg       0.81      0.76      0.79      5806\n",
      "    macro avg       0.82      0.64      0.70      5806\n",
      " weighted avg       0.81      0.76      0.78      5806\n",
      "  samples avg       0.46      0.44      0.44      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Acquired samples: 1\n",
      "Sampling duration: 8.112718343734741 seconds\n",
      "\n",
      "Fold 5 - New train size: 9218\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 9218 samples...\n",
      "Epoch 1/10, Train Loss: 0.389, Accuracy: 0.8792, F1 Micro: 0.6412, F1 Macro: 0.3071\n",
      "Epoch 2/10, Train Loss: 0.2722, Accuracy: 0.9021, F1 Micro: 0.7043, F1 Macro: 0.4414\n",
      "Epoch 3/10, Train Loss: 0.2224, Accuracy: 0.9101, F1 Micro: 0.7488, F1 Macro: 0.5734\n",
      "Epoch 4/10, Train Loss: 0.1861, Accuracy: 0.917, F1 Micro: 0.7621, F1 Macro: 0.5988\n",
      "Epoch 5/10, Train Loss: 0.1542, Accuracy: 0.9208, F1 Micro: 0.7715, F1 Macro: 0.6415\n",
      "Epoch 6/10, Train Loss: 0.1311, Accuracy: 0.9217, F1 Micro: 0.7721, F1 Macro: 0.6563\n",
      "Epoch 7/10, Train Loss: 0.1114, Accuracy: 0.9241, F1 Micro: 0.7834, F1 Macro: 0.679\n",
      "Epoch 8/10, Train Loss: 0.0917, Accuracy: 0.9228, F1 Micro: 0.7825, F1 Macro: 0.7023\n",
      "Epoch 9/10, Train Loss: 0.0759, Accuracy: 0.9268, F1 Micro: 0.7827, F1 Macro: 0.7107\n",
      "Epoch 10/10, Train Loss: 0.0721, Accuracy: 0.9244, F1 Micro: 0.7849, F1 Macro: 0.7161\n",
      "Best result for 9218 samples: F1 Micro: 0.7849\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.88      0.86      0.87      1190\n",
      "      Abusive       0.88      0.91      0.89      1018\n",
      "HS_Individual       0.76      0.74      0.75       768\n",
      "     HS_Group       0.73      0.66      0.69       422\n",
      "  HS_Religion       0.68      0.62      0.65       173\n",
      "      HS_Race       0.76      0.72      0.74       126\n",
      "  HS_Physical       0.85      0.38      0.53        60\n",
      "    HS_Gender       0.73      0.40      0.52        67\n",
      "     HS_Other       0.82      0.76      0.79       792\n",
      "      HS_Weak       0.74      0.72      0.73       725\n",
      "  HS_Moderate       0.64      0.58      0.61       352\n",
      "    HS_Strong       0.86      0.80      0.83       113\n",
      "\n",
      "    micro avg       0.80      0.77      0.78      5806\n",
      "    macro avg       0.78      0.68      0.72      5806\n",
      " weighted avg       0.80      0.77      0.78      5806\n",
      "  samples avg       0.46      0.45      0.44      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10536\n",
      "Acquired samples: 200\n",
      "Sampling duration: 8.042986869812012 seconds\n",
      "\n",
      "Fold 5 - New train size: 9418\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 9418 samples...\n",
      "Epoch 1/10, Train Loss: 0.3961, Accuracy: 0.8804, F1 Micro: 0.6138, F1 Macro: 0.286\n",
      "Epoch 2/10, Train Loss: 0.2708, Accuracy: 0.9017, F1 Micro: 0.689, F1 Macro: 0.4776\n",
      "Epoch 3/10, Train Loss: 0.2187, Accuracy: 0.913, F1 Micro: 0.7448, F1 Macro: 0.5635\n",
      "Epoch 4/10, Train Loss: 0.1861, Accuracy: 0.9182, F1 Micro: 0.7678, F1 Macro: 0.6081\n",
      "Epoch 5/10, Train Loss: 0.1554, Accuracy: 0.9176, F1 Micro: 0.7765, F1 Macro: 0.6664\n",
      "Epoch 6/10, Train Loss: 0.1342, Accuracy: 0.9253, F1 Micro: 0.7833, F1 Macro: 0.6826\n",
      "Epoch 7/10, Train Loss: 0.1142, Accuracy: 0.9195, F1 Micro: 0.7836, F1 Macro: 0.6943\n",
      "Epoch 8/10, Train Loss: 0.0937, Accuracy: 0.9193, F1 Micro: 0.7823, F1 Macro: 0.7021\n",
      "Epoch 9/10, Train Loss: 0.0774, Accuracy: 0.9232, F1 Micro: 0.7853, F1 Macro: 0.7119\n",
      "Epoch 10/10, Train Loss: 0.0689, Accuracy: 0.9262, F1 Micro: 0.7862, F1 Macro: 0.7281\n",
      "Best result for 9418 samples: F1 Micro: 0.7862\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.89      0.84      0.86      1190\n",
      "      Abusive       0.91      0.88      0.89      1018\n",
      "HS_Individual       0.78      0.72      0.75       768\n",
      "     HS_Group       0.75      0.67      0.71       422\n",
      "  HS_Religion       0.72      0.59      0.65       173\n",
      "      HS_Race       0.83      0.73      0.78       126\n",
      "  HS_Physical       0.88      0.38      0.53        60\n",
      "    HS_Gender       0.82      0.48      0.60        67\n",
      "     HS_Other       0.82      0.77      0.79       792\n",
      "      HS_Weak       0.75      0.69      0.72       725\n",
      "  HS_Moderate       0.67      0.60      0.63       352\n",
      "    HS_Strong       0.86      0.79      0.82       113\n",
      "\n",
      "    micro avg       0.82      0.75      0.79      5806\n",
      "    macro avg       0.81      0.68      0.73      5806\n",
      " weighted avg       0.82      0.75      0.78      5806\n",
      "  samples avg       0.45      0.44      0.43      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10536\n",
      "Acquired samples: 200\n",
      "Sampling duration: 7.085698127746582 seconds\n",
      "\n",
      "Fold 5 - New train size: 9618\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 9618 samples...\n",
      "Epoch 1/10, Train Loss: 0.3865, Accuracy: 0.8809, F1 Micro: 0.6197, F1 Macro: 0.2967\n",
      "Epoch 2/10, Train Loss: 0.2667, Accuracy: 0.9019, F1 Micro: 0.6838, F1 Macro: 0.4905\n",
      "Epoch 3/10, Train Loss: 0.2166, Accuracy: 0.9128, F1 Micro: 0.7532, F1 Macro: 0.5837\n",
      "Epoch 4/10, Train Loss: 0.1817, Accuracy: 0.9161, F1 Micro: 0.7683, F1 Macro: 0.6073\n",
      "Epoch 5/10, Train Loss: 0.1521, Accuracy: 0.9225, F1 Micro: 0.7698, F1 Macro: 0.6355\n",
      "Epoch 6/10, Train Loss: 0.1292, Accuracy: 0.9227, F1 Micro: 0.774, F1 Macro: 0.6524\n",
      "Epoch 7/10, Train Loss: 0.1087, Accuracy: 0.9222, F1 Micro: 0.7818, F1 Macro: 0.6839\n",
      "Epoch 8/10, Train Loss: 0.09, Accuracy: 0.9244, F1 Micro: 0.7859, F1 Macro: 0.7047\n",
      "Epoch 9/10, Train Loss: 0.079, Accuracy: 0.9267, F1 Micro: 0.7854, F1 Macro: 0.7175\n",
      "Epoch 10/10, Train Loss: 0.0666, Accuracy: 0.9238, F1 Micro: 0.787, F1 Macro: 0.7241\n",
      "Best result for 9618 samples: F1 Micro: 0.787\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.88      0.87      1190\n",
      "      Abusive       0.90      0.89      0.90      1018\n",
      "HS_Individual       0.72      0.77      0.75       768\n",
      "     HS_Group       0.75      0.64      0.69       422\n",
      "  HS_Religion       0.73      0.51      0.60       173\n",
      "      HS_Race       0.84      0.71      0.77       126\n",
      "  HS_Physical       1.00      0.40      0.57        60\n",
      "    HS_Gender       0.80      0.48      0.60        67\n",
      "     HS_Other       0.76      0.83      0.80       792\n",
      "      HS_Weak       0.70      0.76      0.73       725\n",
      "  HS_Moderate       0.67      0.57      0.61       352\n",
      "    HS_Strong       0.89      0.74      0.81       113\n",
      "\n",
      "    micro avg       0.79      0.78      0.79      5806\n",
      "    macro avg       0.80      0.68      0.72      5806\n",
      " weighted avg       0.79      0.78      0.78      5806\n",
      "  samples avg       0.46      0.45      0.44      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10536\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.988922357559204 seconds\n",
      "\n",
      "Fold 5 - New train size: 9818\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 9818 samples...\n",
      "Epoch 1/10, Train Loss: 0.3857, Accuracy: 0.8801, F1 Micro: 0.6187, F1 Macro: 0.3166\n",
      "Epoch 2/10, Train Loss: 0.2609, Accuracy: 0.9007, F1 Micro: 0.6861, F1 Macro: 0.4717\n",
      "Epoch 3/10, Train Loss: 0.2169, Accuracy: 0.9134, F1 Micro: 0.7493, F1 Macro: 0.5727\n",
      "Epoch 4/10, Train Loss: 0.1804, Accuracy: 0.9185, F1 Micro: 0.7613, F1 Macro: 0.5882\n",
      "Epoch 5/10, Train Loss: 0.1486, Accuracy: 0.9215, F1 Micro: 0.7743, F1 Macro: 0.6352\n",
      "Epoch 6/10, Train Loss: 0.1253, Accuracy: 0.9223, F1 Micro: 0.7746, F1 Macro: 0.6737\n",
      "Epoch 7/10, Train Loss: 0.1068, Accuracy: 0.9249, F1 Micro: 0.7843, F1 Macro: 0.6769\n",
      "Epoch 8/10, Train Loss: 0.0908, Accuracy: 0.9233, F1 Micro: 0.7852, F1 Macro: 0.7165\n",
      "Epoch 9/10, Train Loss: 0.0746, Accuracy: 0.9256, F1 Micro: 0.7872, F1 Macro: 0.7213\n",
      "Epoch 10/10, Train Loss: 0.067, Accuracy: 0.9242, F1 Micro: 0.7845, F1 Macro: 0.7226\n",
      "Best result for 9818 samples: F1 Micro: 0.7872\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.88      0.85      0.86      1190\n",
      "      Abusive       0.88      0.90      0.89      1018\n",
      "HS_Individual       0.75      0.75      0.75       768\n",
      "     HS_Group       0.77      0.62      0.69       422\n",
      "  HS_Religion       0.75      0.57      0.65       173\n",
      "      HS_Race       0.88      0.63      0.73       126\n",
      "  HS_Physical       0.96      0.37      0.53        60\n",
      "    HS_Gender       0.86      0.46      0.60        67\n",
      "     HS_Other       0.80      0.79      0.80       792\n",
      "      HS_Weak       0.74      0.73      0.73       725\n",
      "  HS_Moderate       0.70      0.52      0.60       352\n",
      "    HS_Strong       0.83      0.81      0.82       113\n",
      "\n",
      "    micro avg       0.81      0.76      0.79      5806\n",
      "    macro avg       0.82      0.67      0.72      5806\n",
      " weighted avg       0.81      0.76      0.78      5806\n",
      "  samples avg       0.46      0.45      0.44      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10536\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.095667123794556 seconds\n",
      "\n",
      "Fold 5 - New train size: 10018\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 10018 samples...\n",
      "Epoch 1/10, Train Loss: 0.3825, Accuracy: 0.879, F1 Micro: 0.5875, F1 Macro: 0.2986\n",
      "Epoch 2/10, Train Loss: 0.2625, Accuracy: 0.904, F1 Micro: 0.7255, F1 Macro: 0.522\n",
      "Epoch 3/10, Train Loss: 0.21, Accuracy: 0.9126, F1 Micro: 0.7494, F1 Macro: 0.5676\n",
      "Epoch 4/10, Train Loss: 0.1731, Accuracy: 0.9182, F1 Micro: 0.7606, F1 Macro: 0.5783\n",
      "Epoch 5/10, Train Loss: 0.1497, Accuracy: 0.9198, F1 Micro: 0.7702, F1 Macro: 0.662\n",
      "Epoch 6/10, Train Loss: 0.1266, Accuracy: 0.9237, F1 Micro: 0.7836, F1 Macro: 0.6781\n",
      "Epoch 7/10, Train Loss: 0.1053, Accuracy: 0.9225, F1 Micro: 0.7828, F1 Macro: 0.7058\n",
      "Epoch 8/10, Train Loss: 0.0875, Accuracy: 0.925, F1 Micro: 0.7851, F1 Macro: 0.7124\n",
      "Epoch 9/10, Train Loss: 0.0734, Accuracy: 0.9262, F1 Micro: 0.789, F1 Macro: 0.7161\n",
      "Epoch 10/10, Train Loss: 0.0657, Accuracy: 0.9231, F1 Micro: 0.7802, F1 Macro: 0.7177\n",
      "Best result for 10018 samples: F1 Micro: 0.789\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.88      0.86      0.87      1190\n",
      "      Abusive       0.90      0.90      0.90      1018\n",
      "HS_Individual       0.74      0.76      0.75       768\n",
      "     HS_Group       0.78      0.62      0.69       422\n",
      "  HS_Religion       0.76      0.56      0.65       173\n",
      "      HS_Race       0.86      0.69      0.77       126\n",
      "  HS_Physical       1.00      0.32      0.48        60\n",
      "    HS_Gender       0.84      0.40      0.55        67\n",
      "     HS_Other       0.80      0.80      0.80       792\n",
      "      HS_Weak       0.72      0.74      0.73       725\n",
      "  HS_Moderate       0.70      0.51      0.59       352\n",
      "    HS_Strong       0.87      0.78      0.82       113\n",
      "\n",
      "    micro avg       0.81      0.77      0.79      5806\n",
      "    macro avg       0.82      0.66      0.72      5806\n",
      " weighted avg       0.81      0.77      0.78      5806\n",
      "  samples avg       0.46      0.45      0.44      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10536\n",
      "Acquired samples: 200\n",
      "Sampling duration: 3.9412858486175537 seconds\n",
      "\n",
      "Fold 5 - New train size: 10218\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 10218 samples...\n",
      "Epoch 1/10, Train Loss: 0.3796, Accuracy: 0.8819, F1 Micro: 0.6213, F1 Macro: 0.3024\n",
      "Epoch 2/10, Train Loss: 0.2601, Accuracy: 0.9012, F1 Micro: 0.6797, F1 Macro: 0.4822\n",
      "Epoch 3/10, Train Loss: 0.2124, Accuracy: 0.9132, F1 Micro: 0.7545, F1 Macro: 0.5741\n",
      "Epoch 4/10, Train Loss: 0.1776, Accuracy: 0.9178, F1 Micro: 0.7687, F1 Macro: 0.6127\n",
      "Epoch 5/10, Train Loss: 0.1487, Accuracy: 0.9216, F1 Micro: 0.7797, F1 Macro: 0.6709\n",
      "Epoch 6/10, Train Loss: 0.1249, Accuracy: 0.923, F1 Micro: 0.7838, F1 Macro: 0.6858\n",
      "Epoch 7/10, Train Loss: 0.1019, Accuracy: 0.9219, F1 Micro: 0.7817, F1 Macro: 0.6861\n",
      "Epoch 8/10, Train Loss: 0.0888, Accuracy: 0.9237, F1 Micro: 0.7891, F1 Macro: 0.7245\n",
      "Epoch 9/10, Train Loss: 0.0744, Accuracy: 0.926, F1 Micro: 0.7827, F1 Macro: 0.7202\n",
      "Epoch 10/10, Train Loss: 0.0645, Accuracy: 0.9243, F1 Micro: 0.7919, F1 Macro: 0.7337\n",
      "Best result for 10218 samples: F1 Micro: 0.7919\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.90      0.87      1190\n",
      "      Abusive       0.89      0.90      0.90      1018\n",
      "HS_Individual       0.71      0.81      0.75       768\n",
      "     HS_Group       0.76      0.64      0.70       422\n",
      "  HS_Religion       0.72      0.63      0.67       173\n",
      "      HS_Race       0.83      0.71      0.77       126\n",
      "  HS_Physical       0.96      0.38      0.55        60\n",
      "    HS_Gender       0.77      0.55      0.64        67\n",
      "     HS_Other       0.76      0.84      0.80       792\n",
      "      HS_Weak       0.69      0.78      0.73       725\n",
      "  HS_Moderate       0.70      0.52      0.59       352\n",
      "    HS_Strong       0.80      0.86      0.83       113\n",
      "\n",
      "    micro avg       0.78      0.80      0.79      5806\n",
      "    macro avg       0.79      0.71      0.73      5806\n",
      " weighted avg       0.78      0.80      0.79      5806\n",
      "  samples avg       0.46      0.46      0.45      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10536\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.8297150135040283 seconds\n",
      "\n",
      "Fold 5 - New train size: 10418\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 10418 samples...\n",
      "Epoch 1/10, Train Loss: 0.377, Accuracy: 0.8847, F1 Micro: 0.6312, F1 Macro: 0.3207\n",
      "Epoch 2/10, Train Loss: 0.2489, Accuracy: 0.9056, F1 Micro: 0.7232, F1 Macro: 0.526\n",
      "Epoch 3/10, Train Loss: 0.2039, Accuracy: 0.9145, F1 Micro: 0.7566, F1 Macro: 0.5859\n",
      "Epoch 4/10, Train Loss: 0.1719, Accuracy: 0.9201, F1 Micro: 0.7632, F1 Macro: 0.6185\n",
      "Epoch 5/10, Train Loss: 0.143, Accuracy: 0.9236, F1 Micro: 0.7756, F1 Macro: 0.6526\n",
      "Epoch 6/10, Train Loss: 0.1201, Accuracy: 0.9233, F1 Micro: 0.7861, F1 Macro: 0.6966\n",
      "Epoch 7/10, Train Loss: 0.101, Accuracy: 0.9246, F1 Micro: 0.7847, F1 Macro: 0.7173\n",
      "Epoch 8/10, Train Loss: 0.0868, Accuracy: 0.9235, F1 Micro: 0.7843, F1 Macro: 0.7138\n",
      "Epoch 9/10, Train Loss: 0.0738, Accuracy: 0.9224, F1 Micro: 0.7858, F1 Macro: 0.7304\n",
      "Epoch 10/10, Train Loss: 0.0628, Accuracy: 0.9234, F1 Micro: 0.7848, F1 Macro: 0.7254\n",
      "Best result for 10418 samples: F1 Micro: 0.7861\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.88      0.86      1190\n",
      "      Abusive       0.88      0.90      0.89      1018\n",
      "HS_Individual       0.73      0.79      0.76       768\n",
      "     HS_Group       0.77      0.65      0.70       422\n",
      "  HS_Religion       0.68      0.66      0.67       173\n",
      "      HS_Race       0.79      0.73      0.76       126\n",
      "  HS_Physical       0.86      0.20      0.32        60\n",
      "    HS_Gender       0.85      0.33      0.47        67\n",
      "     HS_Other       0.77      0.79      0.78       792\n",
      "      HS_Weak       0.71      0.77      0.74       725\n",
      "  HS_Moderate       0.72      0.55      0.62       352\n",
      "    HS_Strong       0.78      0.77      0.78       113\n",
      "\n",
      "    micro avg       0.79      0.78      0.79      5806\n",
      "    macro avg       0.78      0.67      0.70      5806\n",
      " weighted avg       0.79      0.78      0.78      5806\n",
      "  samples avg       0.46      0.46      0.44      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10536\n",
      "Acquired samples: 118\n",
      "Sampling duration: 1.532545804977417 seconds\n",
      "\n",
      "Fold 5 - New train size: 10536\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 10536 samples...\n",
      "Epoch 1/10, Train Loss: 0.37, Accuracy: 0.8848, F1 Micro: 0.6417, F1 Macro: 0.3388\n",
      "Epoch 2/10, Train Loss: 0.2436, Accuracy: 0.9031, F1 Micro: 0.7332, F1 Macro: 0.5433\n",
      "Epoch 3/10, Train Loss: 0.198, Accuracy: 0.9159, F1 Micro: 0.7555, F1 Macro: 0.5946\n",
      "Epoch 4/10, Train Loss: 0.1675, Accuracy: 0.9189, F1 Micro: 0.771, F1 Macro: 0.6286\n",
      "Epoch 5/10, Train Loss: 0.1411, Accuracy: 0.9217, F1 Micro: 0.779, F1 Macro: 0.6651\n",
      "Epoch 6/10, Train Loss: 0.1179, Accuracy: 0.9238, F1 Micro: 0.7831, F1 Macro: 0.6782\n",
      "Epoch 7/10, Train Loss: 0.098, Accuracy: 0.9246, F1 Micro: 0.78, F1 Macro: 0.6965\n",
      "Epoch 8/10, Train Loss: 0.0794, Accuracy: 0.9227, F1 Micro: 0.7879, F1 Macro: 0.7361\n",
      "Epoch 9/10, Train Loss: 0.072, Accuracy: 0.9241, F1 Micro: 0.7832, F1 Macro: 0.7088\n",
      "Epoch 10/10, Train Loss: 0.0595, Accuracy: 0.9266, F1 Micro: 0.7857, F1 Macro: 0.7275\n",
      "Best result for 10536 samples: F1 Micro: 0.7879\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.89      0.86      1190\n",
      "      Abusive       0.88      0.91      0.90      1018\n",
      "HS_Individual       0.72      0.77      0.75       768\n",
      "     HS_Group       0.72      0.69      0.70       422\n",
      "  HS_Religion       0.67      0.68      0.67       173\n",
      "      HS_Race       0.83      0.72      0.77       126\n",
      "  HS_Physical       0.76      0.47      0.58        60\n",
      "    HS_Gender       0.68      0.58      0.63        67\n",
      "     HS_Other       0.78      0.81      0.79       792\n",
      "      HS_Weak       0.70      0.75      0.73       725\n",
      "  HS_Moderate       0.64      0.62      0.63       352\n",
      "    HS_Strong       0.90      0.75      0.82       113\n",
      "\n",
      "    micro avg       0.78      0.80      0.79      5806\n",
      "    macro avg       0.76      0.72      0.74      5806\n",
      " weighted avg       0.78      0.80      0.79      5806\n",
      "  samples avg       0.46      0.46      0.45      5806\n",
      "\n",
      "\n",
      "FOLD 5 COMPLETED in 6605.08 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "N_SPLITS = 5\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Prepare data for K-Fold\n",
    "label_columns = data.columns[1:]\n",
    "X = data['Tweet'].values\n",
    "y = data[label_columns].values\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "# Each element in these lists will be a list of metrics for one fold's learning curve\n",
    "all_fold_accuracies = []\n",
    "all_fold_f1_micros = []\n",
    "all_fold_f1_macros = []\n",
    "all_fold_data_used = []\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "    print(\"===============================================\")\n",
    "    print(f\"STARTING FOLD {fold + 1}/{N_SPLITS}\")\n",
    "    print(\"===============================================\")\n",
    "\n",
    "    X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "    y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "\n",
    "    # Shared resources for this fold's processes\n",
    "    accuracies = manager.list()\n",
    "    f1_micros = manager.list()\n",
    "    f1_macros = manager.list()\n",
    "    data_used = manager.list()\n",
    "    sampling_dur = manager.list()\n",
    "    \n",
    "    set_seed(RANDOM_SEED + fold)\n",
    "    \n",
    "    # Define the initial labeled pool from the current fold's training data\n",
    "    total_train_fold_size = len(X_train_fold) + len(X_val_fold)\n",
    "    initial_train_size = int(0.05 * total_train_fold_size)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train_fold)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train_fold))) - set(train_indices))\n",
    "    current_train_size = initial_train_size\n",
    "\n",
    "    # Adjust checkpoints based on the current fold's training size\n",
    "    checkpoints = [\n",
    "        # int(0.1 * total_train_fold_size),\n",
    "        int(0.5 * total_train_fold_size), \n",
    "        int(0.6 * total_train_fold_size),\n",
    "        int(0.7 * total_train_fold_size),\n",
    "        len(X_train_fold)\n",
    "    ]\n",
    "    \n",
    "    fold_start_time = time.time()\n",
    "    \n",
    "    while current_train_size < total_train_fold_size:\n",
    "        # 1. Train the model on the current labeled set\n",
    "        train_args = (\n",
    "            current_train_size, train_indices, (data_used, accuracies, f1_micros, f1_macros),\n",
    "            fold, RANDOM_SEED + fold, X_train_fold, y_train_fold, X_val_fold, y_val_fold, label_columns\n",
    "        )\n",
    "        notebook_launcher(train_model, train_args, num_processes=2)\n",
    "        \n",
    "        # Stop if we've reached the last checkpoint\n",
    "        if current_train_size >= checkpoints[-1]:\n",
    "            break\n",
    "\n",
    "        model = BertForSequenceClassification.from_pretrained(f'{filename}-fold-{fold + 1}-model')\n",
    "        \n",
    "        # 3. Perform query strategy to select new samples\n",
    "        new_samples_shared = manager.list()\n",
    "        X_pool = [X_train_fold[i] for i in remaining_indices]\n",
    "        sampling_args = (model, X_pool, train_indices, remaining_indices, tokenizer, sampling_dur, new_samples_shared, fold, X_train_fold, y_train_fold)\n",
    "        notebook_launcher(kmeans_clustering_sampling, sampling_args, num_processes=2)\n",
    "        \n",
    "        # 4. Update the pools\n",
    "        newly_acquired_indices = list(new_samples_shared)\n",
    "        train_indices.extend(newly_acquired_indices)\n",
    "        remaining_indices = list(set(remaining_indices) - set(newly_acquired_indices))\n",
    "    \n",
    "        current_train_size = len(train_indices)\n",
    "        print(f\"\\nFold {fold + 1} - New train size: {current_train_size}\\n\")\n",
    "    \n",
    "    fold_end_time = time.time()\n",
    "    print(f\"\\nFOLD {fold + 1} COMPLETED in {fold_end_time - fold_start_time:.2f} seconds\")\n",
    "    \n",
    "    # Store the results for this fold\n",
    "    all_fold_data_used.append(list(data_used))\n",
    "    all_fold_accuracies.append(list(accuracies))\n",
    "    all_fold_f1_micros.append(list(f1_micros))\n",
    "    all_fold_f1_macros.append(list(f1_macros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "baff5405",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T11:25:09.738291Z",
     "iopub.status.busy": "2025-06-29T11:25:09.737975Z",
     "iopub.status.idle": "2025-06-29T11:25:10.402561Z",
     "shell.execute_reply": "2025-06-29T11:25:10.401773Z"
    },
    "papermill": {
     "duration": 0.904825,
     "end_time": "2025-06-29T11:25:10.404032",
     "exception": false,
     "start_time": "2025-06-29T11:25:09.499207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "common_data_points = sorted(list(set(point for fold_points in all_fold_data_used for point in fold_points)))\n",
    "\n",
    "# Interpolate metrics for each fold to the common data points\n",
    "avg_accuracies = []\n",
    "avg_f1_micros = []\n",
    "avg_f1_macros = []\n",
    "std_accuracies = []\n",
    "std_f1_micros = []\n",
    "std_f1_macros = []\n",
    "\n",
    "for point in common_data_points:\n",
    "    point_accuracies = []\n",
    "    point_f1_micros = []\n",
    "    point_f1_macros = []\n",
    "    for i in range(N_SPLITS):\n",
    "        sorted_indices = np.argsort(all_fold_data_used[i])\n",
    "        sorted_data = np.array(all_fold_data_used[i])[sorted_indices]\n",
    "        \n",
    "        sorted_acc = np.array(all_fold_accuracies[i])[sorted_indices]\n",
    "        sorted_f1m = np.array(all_fold_f1_micros[i])[sorted_indices]\n",
    "        sorted_f1ma = np.array(all_fold_f1_macros[i])[sorted_indices]\n",
    "        \n",
    "        # Use interpolation to estimate the metric value at the common 'point'\n",
    "        point_accuracies.append(np.interp(point, sorted_data, sorted_acc))\n",
    "        point_f1_micros.append(np.interp(point, sorted_data, sorted_f1m))\n",
    "        point_f1_macros.append(np.interp(point, sorted_data, sorted_f1ma))\n",
    "    \n",
    "    avg_accuracies.append(np.mean(point_accuracies))\n",
    "    avg_f1_micros.append(np.mean(point_f1_micros))\n",
    "    avg_f1_macros.append(np.mean(point_f1_macros))\n",
    "    \n",
    "    std_accuracies.append(np.std(point_accuracies))\n",
    "    std_f1_micros.append(np.std(point_f1_micros))\n",
    "    std_f1_macros.append(np.std(point_f1_macros))\n",
    "\n",
    "# Convert to numpy arrays for easier plotting\n",
    "avg_accuracies = np.array(avg_accuracies)\n",
    "avg_f1_micros = np.array(avg_f1_micros)\n",
    "avg_f1_macros = np.array(avg_f1_macros)\n",
    "std_accuracies = np.array(std_accuracies)\n",
    "std_f1_micros = np.array(std_f1_micros)\n",
    "std_f1_macros = np.array(std_f1_macros)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "data_used_percent = [round(data / len(X) * 100, 1) for data in common_data_points]\n",
    "\n",
    "# Plot for Accuracy\n",
    "axs[0].plot(data_used_percent, avg_accuracies, label=\"Avg Accuracy\", color=\"blue\")\n",
    "axs[0].fill_between(data_used_percent, avg_accuracies - std_accuracies, avg_accuracies + std_accuracies, color='blue', alpha=0.2)\n",
    "axs[0].set_xlabel(\"Percentage of data used\")\n",
    "axs[0].set_title(\"Average Accuracy Across Folds\")\n",
    "\n",
    "# Plot for F1 Micro\n",
    "axs[1].plot(data_used_percent, avg_f1_micros, label=\"Avg F1 Micro\", color=\"orange\")\n",
    "axs[1].fill_between(data_used_percent, avg_f1_micros - std_f1_micros, avg_f1_micros + std_f1_micros, color='orange', alpha=0.2)\n",
    "axs[1].set_xlabel(\"Percentage of data used\")\n",
    "axs[1].set_title(\"Average F1 Micro Across Folds\")\n",
    "\n",
    "# Plot for F1 Macro\n",
    "axs[2].plot(data_used_percent, avg_f1_macros, label=\"Avg F1 Macro\", color=\"green\")\n",
    "axs[2].fill_between(data_used_percent, avg_f1_macros - std_f1_macros, avg_f1_macros + std_f1_macros, color='green', alpha=0.2)\n",
    "axs[2].set_xlabel(\"Percentage of data used\")\n",
    "axs[2].set_title(\"Average F1 Macro Across Folds\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "for i in range(N_SPLITS):\n",
    "    result = pd.DataFrame({\n",
    "        'Data Used': all_fold_data_used[i],\n",
    "        'Accuracy': all_fold_accuracies[i],\n",
    "        'F1 Micro': all_fold_f1_micros[i],\n",
    "        'F1 Macro': all_fold_f1_macros[i],\n",
    "    })\n",
    "\n",
    "    result.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6473829,
     "sourceId": 10457689,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 32891.403544,
   "end_time": "2025-06-29T11:25:13.484467",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-29T02:17:02.080923",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0a178152d689458e9dd8d276cdd18f14": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a7877cd402b141718aeaa8566aba306e",
       "placeholder": "",
       "style": "IPY_MODEL_b67daa26e50542259ff1c85e902b191f",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json:"
      }
     },
     "19a725ed623c47f5a12f96a36bd9ec57": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e39ccd8476a94c2dab191e7d44d63606",
       "placeholder": "",
       "style": "IPY_MODEL_41128d98f5c240a0aaddcf0392ae4212",
       "tabbable": null,
       "tooltip": null,
       "value": "498M/498M[00:02&lt;00:00,253MB/s]"
      }
     },
     "1b65fad56f454cc9bc58585764a50893": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b01e411cf3764c4791d76e0c6fa9f43b",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7bbedd9f9589430991d455a4895b942e",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "275118a9c3c644efad1f380d4f6d3fd1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2d2e0f0d3a2e4c42ba232c1f05f4b594": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2e185a800ae14cc2ae066a1d80fd1019": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "36232c92ddc648ebb30db7a0c08f6231": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a954dab3d6e44364bbcf0d58311778ca",
       "placeholder": "",
       "style": "IPY_MODEL_38aa0e8085f4458f9468c4c51ba53cf4",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json:100%"
      }
     },
     "381e6c35e2c14e6db335247f78800d7e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_bfea3767b473436e896eb915c9bc8621",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_275118a9c3c644efad1f380d4f6d3fd1",
       "tabbable": null,
       "tooltip": null,
       "value": 1.0
      }
     },
     "38aa0e8085f4458f9468c4c51ba53cf4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "39c685df01944175ba47d4403ecfbb83": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3ed2c726cf2d4568a49fbd0357a4cc8f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3f5daa4762cb409bbd022ef21dc74779": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_36232c92ddc648ebb30db7a0c08f6231",
        "IPY_MODEL_aaf991a6a2be4fd1b2561992fe6b31df",
        "IPY_MODEL_efbebbdd681d4e9597c9c92f9ee39771"
       ],
       "layout": "IPY_MODEL_aab920e4c3b54b658ce33453b067ddf1",
       "tabbable": null,
       "tooltip": null
      }
     },
     "40498758c9734e4ea5800a91a51054d1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "41128d98f5c240a0aaddcf0392ae4212": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "42c9246b7a9d404fa21282f7cb32cea3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "44353ad8d65f4ae2adfc641b000b5982": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "53ce43f3e1a84cea969bb503aeec092a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2e185a800ae14cc2ae066a1d80fd1019",
       "max": 112.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a6f5e61064384948a36c26edb9b7f407",
       "tabbable": null,
       "tooltip": null,
       "value": 112.0
      }
     },
     "53d6313a7bd8409dabe8902eff067977": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6b1034c62fcb4fc8af977b8b0f8ba14c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "75a4654cbe2c407c9d943b4bb1eca713": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "77e1ead6d5874c7e819da32ef2606a99": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7bbedd9f9589430991d455a4895b942e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "84daa8d09349438f8cd1fb70b47a671f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_90bae3a5add642e3a58656f6148638d9",
       "placeholder": "",
       "style": "IPY_MODEL_6b1034c62fcb4fc8af977b8b0f8ba14c",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json:100%"
      }
     },
     "90bae3a5add642e3a58656f6148638d9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9e2eb0005655417b98f563a89a2f4d71": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_fc2448b80b924437a8809526f21b6b02",
        "IPY_MODEL_f12da0d724c640fe8752d99fe4abd863",
        "IPY_MODEL_19a725ed623c47f5a12f96a36bd9ec57"
       ],
       "layout": "IPY_MODEL_2d2e0f0d3a2e4c42ba232c1f05f4b594",
       "tabbable": null,
       "tooltip": null
      }
     },
     "9e616837f30443e38e59460c3bb167b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a6f5e61064384948a36c26edb9b7f407": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a7877cd402b141718aeaa8566aba306e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a954dab3d6e44364bbcf0d58311778ca": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aab920e4c3b54b658ce33453b067ddf1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aaf991a6a2be4fd1b2561992fe6b31df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_44353ad8d65f4ae2adfc641b000b5982",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ece238e5e5b5499ca410a109ad4b4f76",
       "tabbable": null,
       "tooltip": null,
       "value": 2.0
      }
     },
     "abf600321c9540ed8d2a42f1c68adc8a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d73210da4be94d42a493236f6a7cbbca",
       "placeholder": "",
       "style": "IPY_MODEL_f01ea479a81340df823e5fc482802ecd",
       "tabbable": null,
       "tooltip": null,
       "value": "1.53k/?[00:00&lt;00:00,148kB/s]"
      }
     },
     "b01e411cf3764c4791d76e0c6fa9f43b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "b2ff57c6a84041c086eae0a5631e1e80": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f72c8b178f6b45fab417ffabf8666cbd",
        "IPY_MODEL_381e6c35e2c14e6db335247f78800d7e",
        "IPY_MODEL_b808079816904be9ab614ff0d0eed877"
       ],
       "layout": "IPY_MODEL_77e1ead6d5874c7e819da32ef2606a99",
       "tabbable": null,
       "tooltip": null
      }
     },
     "b67daa26e50542259ff1c85e902b191f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b721ab5ba87b4bb9b0937e6a51bd79a7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b808079816904be9ab614ff0d0eed877": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_40498758c9734e4ea5800a91a51054d1",
       "placeholder": "",
       "style": "IPY_MODEL_3ed2c726cf2d4568a49fbd0357a4cc8f",
       "tabbable": null,
       "tooltip": null,
       "value": "229k/?[00:00&lt;00:00,6.39MB/s]"
      }
     },
     "bfea3767b473436e896eb915c9bc8621": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "cf4328e7d7fb4bc78a95b55136d3a2ac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fe2c6fc6114e4c088660863b536a09b9",
       "placeholder": "",
       "style": "IPY_MODEL_9e616837f30443e38e59460c3bb167b9",
       "tabbable": null,
       "tooltip": null,
       "value": "112/112[00:00&lt;00:00,12.6kB/s]"
      }
     },
     "d73210da4be94d42a493236f6a7cbbca": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "deb00031241e459880c5e08e60db8081": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e105150fa9b44296b7984f8b157d0782": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e39ccd8476a94c2dab191e7d44d63606": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ece238e5e5b5499ca410a109ad4b4f76": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ecf676439c3846d5ba0ee37612896fa7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_84daa8d09349438f8cd1fb70b47a671f",
        "IPY_MODEL_53ce43f3e1a84cea969bb503aeec092a",
        "IPY_MODEL_cf4328e7d7fb4bc78a95b55136d3a2ac"
       ],
       "layout": "IPY_MODEL_75a4654cbe2c407c9d943b4bb1eca713",
       "tabbable": null,
       "tooltip": null
      }
     },
     "eed107bb83384af5ab9a2e0569c34e32": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "efbebbdd681d4e9597c9c92f9ee39771": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_53d6313a7bd8409dabe8902eff067977",
       "placeholder": "",
       "style": "IPY_MODEL_39c685df01944175ba47d4403ecfbb83",
       "tabbable": null,
       "tooltip": null,
       "value": "2.00/2.00[00:00&lt;00:00,161B/s]"
      }
     },
     "f01ea479a81340df823e5fc482802ecd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f074c52f1dd4424da2246c036b5d1020": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f12da0d724c640fe8752d99fe4abd863": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_deb00031241e459880c5e08e60db8081",
       "max": 497810400.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e105150fa9b44296b7984f8b157d0782",
       "tabbable": null,
       "tooltip": null,
       "value": 497810400.0
      }
     },
     "f31d945154f048b5b49015f8b6ddbe10": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f72c8b178f6b45fab417ffabf8666cbd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b721ab5ba87b4bb9b0937e6a51bd79a7",
       "placeholder": "",
       "style": "IPY_MODEL_42c9246b7a9d404fa21282f7cb32cea3",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt:"
      }
     },
     "fc2448b80b924437a8809526f21b6b02": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f31d945154f048b5b49015f8b6ddbe10",
       "placeholder": "",
       "style": "IPY_MODEL_f074c52f1dd4424da2246c036b5d1020",
       "tabbable": null,
       "tooltip": null,
       "value": "pytorch_model.bin:100%"
      }
     },
     "fe2c6fc6114e4c088660863b536a09b9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ffc2ac7453864563aaced0aca4f399a9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0a178152d689458e9dd8d276cdd18f14",
        "IPY_MODEL_1b65fad56f454cc9bc58585764a50893",
        "IPY_MODEL_abf600321c9540ed8d2a42f1c68adc8a"
       ],
       "layout": "IPY_MODEL_eed107bb83384af5ab9a2e0569c34e32",
       "tabbable": null,
       "tooltip": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
