{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7236337d",
   "metadata": {
    "papermill": {
     "duration": 0.011782,
     "end_time": "2025-06-29T02:17:41.105603",
     "exception": false,
     "start_time": "2025-06-29T02:17:41.093821",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9738a9a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:41.130035Z",
     "iopub.status.busy": "2025-06-29T02:17:41.129344Z",
     "iopub.status.idle": "2025-06-29T02:17:48.418361Z",
     "shell.execute_reply": "2025-06-29T02:17:48.417653Z"
    },
    "papermill": {
     "duration": 7.302882,
     "end_time": "2025-06-29T02:17:48.420315",
     "exception": false,
     "start_time": "2025-06-29T02:17:41.117433",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dc57b4",
   "metadata": {
    "papermill": {
     "duration": 0.010133,
     "end_time": "2025-06-29T02:17:48.441174",
     "exception": false,
     "start_time": "2025-06-29T02:17:48.431041",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90d43977",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:48.462877Z",
     "iopub.status.busy": "2025-06-29T02:17:48.462454Z",
     "iopub.status.idle": "2025-06-29T02:17:48.466521Z",
     "shell.execute_reply": "2025-06-29T02:17:48.465874Z"
    },
    "papermill": {
     "duration": 0.016645,
     "end_time": "2025-06-29T02:17:48.468063",
     "exception": false,
     "start_time": "2025-06-29T02:17:48.451418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9ec2699",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:48.489364Z",
     "iopub.status.busy": "2025-06-29T02:17:48.489141Z",
     "iopub.status.idle": "2025-06-29T02:17:48.493157Z",
     "shell.execute_reply": "2025-06-29T02:17:48.492494Z"
    },
    "papermill": {
     "duration": 0.016418,
     "end_time": "2025-06-29T02:17:48.494617",
     "exception": false,
     "start_time": "2025-06-29T02:17:48.478199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/working/results') == False:\n",
    "    os.mkdir('/kaggle/working/results')\n",
    "\n",
    "if os.path.exists('/kaggle/working/acquired_data') == False:\n",
    "    os.mkdir('/kaggle/working/acquired_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06b70d31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:48.516625Z",
     "iopub.status.busy": "2025-06-29T02:17:48.515957Z",
     "iopub.status.idle": "2025-06-29T02:17:48.523772Z",
     "shell.execute_reply": "2025-06-29T02:17:48.523222Z"
    },
    "papermill": {
     "duration": 0.020186,
     "end_time": "2025-06-29T02:17:48.525259",
     "exception": false,
     "start_time": "2025-06-29T02:17:48.505073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fe90fb",
   "metadata": {
    "papermill": {
     "duration": 0.01012,
     "end_time": "2025-06-29T02:17:48.545612",
     "exception": false,
     "start_time": "2025-06-29T02:17:48.535492",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52682761",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:48.566891Z",
     "iopub.status.busy": "2025-06-29T02:17:48.566672Z",
     "iopub.status.idle": "2025-06-29T02:17:48.613533Z",
     "shell.execute_reply": "2025-06-29T02:17:48.612023Z"
    },
    "papermill": {
     "duration": 0.059825,
     "end_time": "2025-06-29T02:17:48.615624",
     "exception": false,
     "start_time": "2025-06-29T02:17:48.555799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Shared resources\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "data_used = manager.list()\n",
    "sampling_dur = manager.list()\n",
    "new_samples = manager.list()\n",
    "\n",
    "# Non shared resources\n",
    "filename = 'hsd-lc-kfold'\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "sequence_length = 80\n",
    "min_increment = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de5fc2d",
   "metadata": {
    "papermill": {
     "duration": 0.010765,
     "end_time": "2025-06-29T02:17:48.637538",
     "exception": false,
     "start_time": "2025-06-29T02:17:48.626773",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bc5cd8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:48.662456Z",
     "iopub.status.busy": "2025-06-29T02:17:48.661458Z",
     "iopub.status.idle": "2025-06-29T02:17:48.777377Z",
     "shell.execute_reply": "2025-06-29T02:17:48.776527Z"
    },
    "papermill": {
     "duration": 0.130346,
     "end_time": "2025-06-29T02:17:48.779201",
     "exception": false,
     "start_time": "2025-06-29T02:17:48.648855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (13169, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>HS</th>\n",
       "      <th>Abusive</th>\n",
       "      <th>HS_Individual</th>\n",
       "      <th>HS_Group</th>\n",
       "      <th>HS_Religion</th>\n",
       "      <th>HS_Race</th>\n",
       "      <th>HS_Physical</th>\n",
       "      <th>HS_Gender</th>\n",
       "      <th>HS_Other</th>\n",
       "      <th>HS_Weak</th>\n",
       "      <th>HS_Moderate</th>\n",
       "      <th>HS_Strong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- disaat semua cowok berusaha melacak perhatia...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT USER: USER siapa yang telat ngasih tau elu?...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41. Kadang aku berfikir, kenapa aku tetap perc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USER USER AKU ITU AKU\\n\\nKU TAU MATAMU SIPIT T...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USER USER Kaum cebong kapir udah keliatan dong...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet  HS  Abusive  \\\n",
       "0  - disaat semua cowok berusaha melacak perhatia...   1        1   \n",
       "1  RT USER: USER siapa yang telat ngasih tau elu?...   0        1   \n",
       "2  41. Kadang aku berfikir, kenapa aku tetap perc...   0        0   \n",
       "3  USER USER AKU ITU AKU\\n\\nKU TAU MATAMU SIPIT T...   0        0   \n",
       "4  USER USER Kaum cebong kapir udah keliatan dong...   1        1   \n",
       "\n",
       "   HS_Individual  HS_Group  HS_Religion  HS_Race  HS_Physical  HS_Gender  \\\n",
       "0              1         0            0        0            0          0   \n",
       "1              0         0            0        0            0          0   \n",
       "2              0         0            0        0            0          0   \n",
       "3              0         0            0        0            0          0   \n",
       "4              0         1            1        0            0          0   \n",
       "\n",
       "   HS_Other  HS_Weak  HS_Moderate  HS_Strong  \n",
       "0         1        1            0          0  \n",
       "1         0        0            0          0  \n",
       "2         0        0            0          0  \n",
       "3         0        0            0          0  \n",
       "4         0        0            1          0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/kaggle/input/multi-label-hate-speech-3/re_dataset.csv', encoding='latin-1')\n",
    "\n",
    "alay_dict = pd.read_csv('/kaggle/input/multi-label-hate-speech-3/new_kamusalay.csv', encoding='latin-1', header=None)\n",
    "alay_dict = alay_dict.rename(columns={0: 'original', \n",
    "                                      1: 'replacement'})\n",
    "\n",
    "print(\"Shape: \", data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb1076e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:48.803090Z",
     "iopub.status.busy": "2025-06-29T02:17:48.802477Z",
     "iopub.status.idle": "2025-06-29T02:17:48.814760Z",
     "shell.execute_reply": "2025-06-29T02:17:48.813758Z"
    },
    "papermill": {
     "duration": 0.025798,
     "end_time": "2025-06-29T02:17:48.816558",
     "exception": false,
     "start_time": "2025-06-29T02:17:48.790760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove_nonaplhanumeric:  Halooo duniaa \n",
      "lowercase:  halooo, duniaa!\n",
      "remove_unnecessary_char:  Hehe RT USER USER apa kabs hehe URL \n",
      "normalize_alay:  amin adik habis\n"
     ]
    }
   ],
   "source": [
    "def lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_unnecessary_char(text):\n",
    "    text = re.sub('\\n',' ',text) # Remove every '\\n'\n",
    "    text = re.sub('rt',' ',text) # Remove every retweet symbol\n",
    "    text = re.sub('user',' ',text) # Remove every username\n",
    "    text = re.sub('url', ' ', text) # Remove every URL\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+)|(http?://[^\\s]+))',' ',text) # Remove every URL\n",
    "    text = re.sub(r'\\b(?:x[a-fA-F0-9]{2}\\s*)+\\b', '', text) # Remove emoji bytecode\n",
    "    text = re.sub('  +', ' ', text) # Remove extra spaces\n",
    "    return text\n",
    "    \n",
    "def remove_nonaplhanumeric(text):\n",
    "    text = re.sub('[^0-9a-zA-Z]+', ' ', text) \n",
    "    return text\n",
    "\n",
    "alay_dict_map = dict(zip(alay_dict['original'], alay_dict['replacement']))\n",
    "def normalize_alay(text):\n",
    "    return ' '.join([alay_dict_map[word] if word in alay_dict_map else word for word in text.split(' ')])\n",
    "\n",
    "print(\"remove_nonaplhanumeric: \", remove_nonaplhanumeric(\"Halooo,,,,, duniaa \\x8f \\xd2\\1 !!\"))\n",
    "print(\"lowercase: \", lowercase(\"Halooo, duniaa!\"))\n",
    "print(\"remove_unnecessary_char: \", remove_unnecessary_char(\"Hehe\\n\\n RT USER USER apa kabs www.google.com\\n  hehe URL xf8 x2a x89\"))\n",
    "print(\"normalize_alay: \", normalize_alay(\"aamiin adek abis\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbcea975",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:48.839011Z",
     "iopub.status.busy": "2025-06-29T02:17:48.838760Z",
     "iopub.status.idle": "2025-06-29T02:17:48.842688Z",
     "shell.execute_reply": "2025-06-29T02:17:48.841911Z"
    },
    "papermill": {
     "duration": 0.017065,
     "end_time": "2025-06-29T02:17:48.844278",
     "exception": false,
     "start_time": "2025-06-29T02:17:48.827213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = lowercase(text)\n",
    "    text = remove_nonaplhanumeric(text)\n",
    "    text = remove_unnecessary_char(text)\n",
    "    text = normalize_alay(text) \n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e5b72cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:48.866252Z",
     "iopub.status.busy": "2025-06-29T02:17:48.866006Z",
     "iopub.status.idle": "2025-06-29T02:17:49.209948Z",
     "shell.execute_reply": "2025-06-29T02:17:49.209116Z"
    },
    "papermill": {
     "duration": 0.357051,
     "end_time": "2025-06-29T02:17:49.211820",
     "exception": false,
     "start_time": "2025-06-29T02:17:48.854769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['Tweet'] = data['Tweet'].apply(preprocess)\n",
    "\n",
    "# Define the labels columns for multi-label classification\n",
    "label_columns = data.columns[1:]  # Assuming label columns start from the third column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a20a6b",
   "metadata": {
    "papermill": {
     "duration": 0.010482,
     "end_time": "2025-06-29T02:17:49.233264",
     "exception": false,
     "start_time": "2025-06-29T02:17:49.222782",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BUILD DATASET & DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "619c039a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:49.255487Z",
     "iopub.status.busy": "2025-06-29T02:17:49.255232Z",
     "iopub.status.idle": "2025-06-29T02:17:49.794645Z",
     "shell.execute_reply": "2025-06-29T02:17:49.794016Z"
    },
    "papermill": {
     "duration": 0.55256,
     "end_time": "2025-06-29T02:17:49.796403",
     "exception": false,
     "start_time": "2025-06-29T02:17:49.243843",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d7bb277ef3428fa9778ce4108bbc2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b946fa452f274193b144bc02faf40999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6acaf229ee9345c583f7821c99210c89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d88b9cb18fcf4ff08cba5246953c0866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class HateSpeechDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        labels = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(labels, dtype=torch.float if self.use_float else torch.long)\n",
    "        return item\n",
    "\n",
    "# Initialize BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc14eb21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:49.820143Z",
     "iopub.status.busy": "2025-06-29T02:17:49.819867Z",
     "iopub.status.idle": "2025-06-29T02:17:49.824722Z",
     "shell.execute_reply": "2025-06-29T02:17:49.823886Z"
    },
    "papermill": {
     "duration": 0.018244,
     "end_time": "2025-06-29T02:17:49.826187",
     "exception": false,
     "start_time": "2025-06-29T02:17:49.807943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataloaders(X_train, y_train, X_val, y_val, sequence_length=96, num_workers=4):\n",
    "    train_dataset = HateSpeechDataset(X_train, y_train, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = HateSpeechDataset(X_val, y_val, tokenizer, max_length=sequence_length)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241a3bf5",
   "metadata": {
    "papermill": {
     "duration": 0.01063,
     "end_time": "2025-06-29T02:17:49.847677",
     "exception": false,
     "start_time": "2025-06-29T02:17:49.837047",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "195b22ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:49.870171Z",
     "iopub.status.busy": "2025-06-29T02:17:49.869913Z",
     "iopub.status.idle": "2025-06-29T02:17:49.875230Z",
     "shell.execute_reply": "2025-06-29T02:17:49.874555Z"
    },
    "papermill": {
     "duration": 0.018428,
     "end_time": "2025-06-29T02:17:49.876873",
     "exception": false,
     "start_time": "2025-06-29T02:17:49.858445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        target_names=['HS', 'Abusive', 'HS_Individual', 'HS_Group', 'HS_Religion', 'HS_Race', 'HS_Physical', 'HS_Gender', 'HS_Other', 'HS_Weak', 'HS_Moderate', 'HS_Strong'],\n",
    "        zero_division=0\n",
    "    )   \n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "422564be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:49.899976Z",
     "iopub.status.busy": "2025-06-29T02:17:49.899642Z",
     "iopub.status.idle": "2025-06-29T02:17:49.912624Z",
     "shell.execute_reply": "2025-06-29T02:17:49.911846Z"
    },
    "papermill": {
     "duration": 0.026461,
     "end_time": "2025-06-29T02:17:49.914252",
     "exception": false,
     "start_time": "2025-06-29T02:17:49.887791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, metrics, trials, seed, X_train_fold, y_train_fold, X_val_fold, y_val_fold, label_columns):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "\n",
    "    accelerator.print(f\"Fold {trials + 1} - Training with {current_train_size} samples...\")\n",
    "\n",
    "    with accelerator.main_process_first():\n",
    "        model = BertForSequenceClassification.from_pretrained(\n",
    "            'indobenchmark/indobert-base-p1',\n",
    "            num_labels=len(label_columns),\n",
    "            problem_type=\"multi_label_classification\"\n",
    "        )\n",
    "\n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Define DataLoaders using the fold's data\n",
    "    current_X_train = [X_train_fold[i] for i in train_indices]\n",
    "    current_y_train = [y_train_fold[i] for i in train_indices]\n",
    "    train_loader, val_loader = get_dataloaders(current_X_train, current_y_train, X_val_fold, y_val_fold)\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Prepare everything with Accelerator\n",
    "    model, optimizer, train_loader, val_loader = accelerator.prepare(\n",
    "        model, optimizer, train_loader, val_loader\n",
    "    )\n",
    "\n",
    "    best_result = None\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key != 'labels'}\n",
    "            labels = batch['labels']\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key != 'labels'}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "        result = compute_metrics(type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}))\n",
    "\n",
    "        if best_result is None or result['f1_micro'] >= best_result['f1_micro']:\n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'{filename}-fold-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "            best_result = result\n",
    "        \n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    accelerator.print(f\"Best result for {current_train_size} samples: F1 Micro: {round(best_result['f1_micro'], 4)}\")\n",
    "    accelerator.print(best_result['report'])\n",
    "    \n",
    "    # Update the shared lists\n",
    "    if accelerator.is_local_main_process:\n",
    "        metrics[0].append(current_train_size)\n",
    "        metrics[1].append(best_result['accuracy'])\n",
    "        metrics[2].append(best_result['f1_micro'])\n",
    "        metrics[3].append(best_result['f1_macro'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a055f32d",
   "metadata": {
    "papermill": {
     "duration": 0.010902,
     "end_time": "2025-06-29T02:17:49.936003",
     "exception": false,
     "start_time": "2025-06-29T02:17:49.925101",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PLOT THE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b87c213",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:49.959413Z",
     "iopub.status.busy": "2025-06-29T02:17:49.958804Z",
     "iopub.status.idle": "2025-06-29T02:17:49.965420Z",
     "shell.execute_reply": "2025-06-29T02:17:49.964648Z"
    },
    "papermill": {
     "duration": 0.02018,
     "end_time": "2025-06-29T02:17:49.967088",
     "exception": false,
     "start_time": "2025-06-29T02:17:49.946908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bec3dd",
   "metadata": {
    "papermill": {
     "duration": 0.011278,
     "end_time": "2025-06-29T02:17:49.989947",
     "exception": false,
     "start_time": "2025-06-29T02:17:49.978669",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QUERY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4723a058",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:50.014644Z",
     "iopub.status.busy": "2025-06-29T02:17:50.014120Z",
     "iopub.status.idle": "2025-06-29T02:17:50.027118Z",
     "shell.execute_reply": "2025-06-29T02:17:50.026450Z"
    },
    "papermill": {
     "duration": 0.027028,
     "end_time": "2025-06-29T02:17:50.028615",
     "exception": false,
     "start_time": "2025-06-29T02:17:50.001587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def least_confidence_sampling(model, X_pool, train_indices, remaining_indices, sampling_dur, new_samples, trials, X_train_fold, y_train_fold, n_samples=min_increment):\n",
    "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "    device = accelerator.device\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    current_train_size = len(train_indices)\n",
    "    dataset = HateSpeechDataset(X_pool, np.zeros((len(X_pool), 4)), tokenizer, max_length=sequence_length)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    \n",
    "    uncertainties = []\n",
    "    for data in dataloader:\n",
    "        input_ids = data['input_ids'].to(device, non_blocking=True)\n",
    "        attention_mask = data['attention_mask'].to(device, non_blocking=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask).logits\n",
    "\n",
    "        for output in outputs:\n",
    "            probs = torch.sigmoid(output).cpu().numpy()\n",
    "            uncertainty = np.absolute(1 - np.max(probs))\n",
    "            uncertainties.append(uncertainty)\n",
    "    \n",
    "    uncertainties = np.array(uncertainties)\n",
    "    sorted_unc = np.argsort(uncertainties)\n",
    "    sorted_unc = sorted_unc[::-1]\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "\n",
    "    if accelerator.is_local_main_process:\n",
    "        threshold = np.percentile(uncertainties, 90)\n",
    "        items_greater_than_average = uncertainties[uncertainties >= threshold]\n",
    "        num_of_candidates = len(items_greater_than_average)\n",
    "    \n",
    "        # Check nearest checkpoint\n",
    "        nearest_cp = 0\n",
    "        for cp in checkpoints:\n",
    "            if cp > current_train_size:\n",
    "                nearest_cp = cp\n",
    "                break\n",
    "        \n",
    "        if num_of_candidates <= n_samples and n_samples < nearest_cp - current_train_size:\n",
    "            least_confident_indices = sorted_unc[:n_samples]\n",
    "        elif num_of_candidates > n_samples and num_of_candidates < nearest_cp - current_train_size:\n",
    "             least_confident_indices = sorted_unc[:max(n_samples, min(math.ceil(0.1*len(sorted_unc)), num_of_candidates))]\n",
    "        else:\n",
    "            least_confident_indices = sorted_unc[:nearest_cp - current_train_size]\n",
    "    \n",
    "            temp = train_indices.copy()\n",
    "            temp.extend([remaining_indices[i] for i in least_confident_indices])\n",
    "            \n",
    "            # Save acquired data up to checkpoint\n",
    "            acquired_data = pd.DataFrame({\n",
    "                'processed_text': [X_train_fold[i] for i in temp],\n",
    "                'HS': [y_train_fold[i][0] for i in temp],\n",
    "                'Abusive': [y_train_fold[i][1] for i in temp],\n",
    "                'HS_Individual': [y_train_fold[i][2] for i in temp],\n",
    "                'HS_Group': [y_train_fold[i][3] for i in temp],\n",
    "                'HS_Religion': [y_train_fold[i][4] for i in temp],\n",
    "                'HS_Race': [y_train_fold[i][5] for i in temp],\n",
    "                'HS_Physical': [y_train_fold[i][6] for i in temp],\n",
    "                'HS_Gender': [y_train_fold[i][7] for i in temp],\n",
    "                'HS_Other': [y_train_fold[i][8] for i in temp],\n",
    "                'HS_Weak': [y_train_fold[i][9] for i in temp],\n",
    "                'HS_Moderate': [y_train_fold[i][10] for i in temp],\n",
    "                'HS_Strong': [y_train_fold[i][11] for i in temp],\n",
    "            })\n",
    "    \n",
    "            acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "    \n",
    "        end_time = time.time() \n",
    "        duration = end_time - start_time\n",
    "    \n",
    "        sampling_dur.append(duration)\n",
    "        for i in least_confident_indices:\n",
    "            new_samples.append(remaining_indices[i])\n",
    "            \n",
    "        print(\"Nearest checkpoint:\", nearest_cp)\n",
    "        print(\"Threshold:\", threshold)\n",
    "        print(\"Samples above threshold:\", num_of_candidates)\n",
    "        print(\"Acquired samples:\", len(least_confident_indices))\n",
    "        print(f\"Sampling duration: {duration} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c15a4cf",
   "metadata": {
    "papermill": {
     "duration": 0.010767,
     "end_time": "2025-06-29T02:17:50.050721",
     "exception": false,
     "start_time": "2025-06-29T02:17:50.039954",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e24477c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T02:17:50.074163Z",
     "iopub.status.busy": "2025-06-29T02:17:50.073910Z",
     "iopub.status.idle": "2025-06-29T11:03:47.242121Z",
     "shell.execute_reply": "2025-06-29T11:03:47.240958Z"
    },
    "papermill": {
     "duration": 31557.181955,
     "end_time": "2025-06-29T11:03:47.244019",
     "exception": false,
     "start_time": "2025-06-29T02:17:50.062064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "STARTING FOLD 1/5\n",
      "===============================================\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 658 samples...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "308f68b0d93a468883c8af35ae7a52d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.6381, Accuracy: 0.7985, F1 Micro: 0.3882, F1 Macro: 0.1172\n",
      "Epoch 2/10, Train Loss: 0.4768, Accuracy: 0.8343, F1 Micro: 0.1455, F1 Macro: 0.0462\n",
      "Epoch 3/10, Train Loss: 0.4068, Accuracy: 0.8333, F1 Micro: 0.1123, F1 Macro: 0.0388\n",
      "Epoch 4/10, Train Loss: 0.3813, Accuracy: 0.8332, F1 Micro: 0.1021, F1 Macro: 0.0367\n",
      "Epoch 5/10, Train Loss: 0.3774, Accuracy: 0.8373, F1 Micro: 0.1641, F1 Macro: 0.0541\n",
      "Epoch 6/10, Train Loss: 0.3665, Accuracy: 0.844, F1 Micro: 0.2355, F1 Macro: 0.0791\n",
      "Epoch 7/10, Train Loss: 0.355, Accuracy: 0.8526, F1 Micro: 0.3214, F1 Macro: 0.1069\n",
      "Epoch 8/10, Train Loss: 0.3289, Accuracy: 0.8608, F1 Micro: 0.3921, F1 Macro: 0.1407\n",
      "Epoch 9/10, Train Loss: 0.3142, Accuracy: 0.871, F1 Micro: 0.4906, F1 Macro: 0.2141\n",
      "Epoch 10/10, Train Loss: 0.2951, Accuracy: 0.8741, F1 Micro: 0.5196, F1 Macro: 0.2373\n",
      "Best result for 658 samples: F1 Micro: 0.5196\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.61      0.71      1141\n",
      "      Abusive       0.81      0.74      0.77      1012\n",
      "HS_Individual       0.67      0.36      0.47       737\n",
      "     HS_Group       0.00      0.00      0.00       404\n",
      "  HS_Religion       0.00      0.00      0.00       164\n",
      "      HS_Race       0.00      0.00      0.00       119\n",
      "  HS_Physical       0.00      0.00      0.00        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.72      0.35      0.47       779\n",
      "      HS_Weak       0.67      0.31      0.43       686\n",
      "  HS_Moderate       0.00      0.00      0.00       356\n",
      "    HS_Strong       0.00      0.00      0.00        99\n",
      "\n",
      "    micro avg       0.77      0.39      0.52      5608\n",
      "    macro avg       0.31      0.20      0.24      5608\n",
      " weighted avg       0.59      0.39      0.46      5608\n",
      "  samples avg       0.36      0.25      0.27      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.831237080693245\n",
      "Samples above threshold: 988\n",
      "Acquired samples: 988\n",
      "Sampling duration: 40.152653217315674 seconds\n",
      "\n",
      "Fold 1 - New train size: 1646\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 1646 samples...\n",
      "Epoch 1/10, Train Loss: 0.5067, Accuracy: 0.8262, F1 Micro: 0.0007, F1 Macro: 0.0003\n",
      "Epoch 2/10, Train Loss: 0.2849, Accuracy: 0.8261, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.2487, Accuracy: 0.8295, F1 Micro: 0.0421, F1 Macro: 0.0176\n",
      "Epoch 4/10, Train Loss: 0.2265, Accuracy: 0.8406, F1 Micro: 0.2087, F1 Macro: 0.0727\n",
      "Epoch 5/10, Train Loss: 0.2008, Accuracy: 0.8522, F1 Micro: 0.3301, F1 Macro: 0.1168\n",
      "Epoch 6/10, Train Loss: 0.1799, Accuracy: 0.8668, F1 Micro: 0.5592, F1 Macro: 0.2523\n",
      "Epoch 7/10, Train Loss: 0.177, Accuracy: 0.8647, F1 Micro: 0.4378, F1 Macro: 0.1957\n",
      "Epoch 8/10, Train Loss: 0.1535, Accuracy: 0.8744, F1 Micro: 0.5913, F1 Macro: 0.2752\n",
      "Epoch 9/10, Train Loss: 0.1477, Accuracy: 0.876, F1 Micro: 0.5575, F1 Macro: 0.2642\n",
      "Epoch 10/10, Train Loss: 0.1313, Accuracy: 0.8767, F1 Micro: 0.5975, F1 Macro: 0.307\n",
      "Best result for 1646 samples: F1 Micro: 0.5975\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.78      0.80      0.79      1141\n",
      "      Abusive       0.84      0.73      0.78      1012\n",
      "HS_Individual       0.58      0.53      0.56       737\n",
      "     HS_Group       0.56      0.29      0.38       404\n",
      "  HS_Religion       0.00      0.00      0.00       164\n",
      "      HS_Race       0.00      0.00      0.00       119\n",
      "  HS_Physical       0.00      0.00      0.00        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.62      0.59      0.61       779\n",
      "      HS_Weak       0.56      0.47      0.51       686\n",
      "  HS_Moderate       0.65      0.03      0.06       356\n",
      "    HS_Strong       0.00      0.00      0.00        99\n",
      "\n",
      "    micro avg       0.69      0.53      0.60      5608\n",
      "    macro avg       0.38      0.29      0.31      5608\n",
      " weighted avg       0.62      0.53      0.55      5608\n",
      "  samples avg       0.37      0.30      0.30      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.9085251659154892\n",
      "Samples above threshold: 889\n",
      "Acquired samples: 889\n",
      "Sampling duration: 38.499608278274536 seconds\n",
      "\n",
      "Fold 1 - New train size: 2535\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 2535 samples...\n",
      "Epoch 1/10, Train Loss: 0.4179, Accuracy: 0.8261, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.2302, Accuracy: 0.8261, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.2002, Accuracy: 0.8284, F1 Micro: 0.0271, F1 Macro: 0.0118\n",
      "Epoch 4/10, Train Loss: 0.1746, Accuracy: 0.8505, F1 Micro: 0.3118, F1 Macro: 0.1169\n",
      "Epoch 5/10, Train Loss: 0.1459, Accuracy: 0.8637, F1 Micro: 0.4649, F1 Macro: 0.2009\n",
      "Epoch 6/10, Train Loss: 0.1371, Accuracy: 0.8694, F1 Micro: 0.5032, F1 Macro: 0.2265\n",
      "Epoch 7/10, Train Loss: 0.1188, Accuracy: 0.8734, F1 Micro: 0.5482, F1 Macro: 0.2532\n",
      "Epoch 8/10, Train Loss: 0.1125, Accuracy: 0.8725, F1 Micro: 0.5352, F1 Macro: 0.2458\n",
      "Epoch 9/10, Train Loss: 0.1008, Accuracy: 0.8779, F1 Micro: 0.5892, F1 Macro: 0.283\n",
      "Epoch 10/10, Train Loss: 0.0892, Accuracy: 0.8797, F1 Micro: 0.6124, F1 Macro: 0.3205\n",
      "Best result for 2535 samples: F1 Micro: 0.6124\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.78      0.80      1141\n",
      "      Abusive       0.85      0.74      0.79      1012\n",
      "HS_Individual       0.58      0.57      0.57       737\n",
      "     HS_Group       0.60      0.32      0.42       404\n",
      "  HS_Religion       0.00      0.00      0.00       164\n",
      "      HS_Race       0.00      0.00      0.00       119\n",
      "  HS_Physical       0.00      0.00      0.00        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.63      0.62      0.63       779\n",
      "      HS_Weak       0.54      0.55      0.55       686\n",
      "  HS_Moderate       0.62      0.05      0.09       356\n",
      "    HS_Strong       0.00      0.00      0.00        99\n",
      "\n",
      "    micro avg       0.70      0.55      0.61      5608\n",
      "    macro avg       0.39      0.30      0.32      5608\n",
      " weighted avg       0.63      0.55      0.57      5608\n",
      "  samples avg       0.37      0.31      0.31      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.9227269589900972\n",
      "Samples above threshold: 800\n",
      "Acquired samples: 800\n",
      "Sampling duration: 34.49529314041138 seconds\n",
      "\n",
      "Fold 1 - New train size: 3335\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 3335 samples...\n",
      "Epoch 1/10, Train Loss: 0.3756, Accuracy: 0.8261, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.1991, Accuracy: 0.8261, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.1866, Accuracy: 0.8269, F1 Micro: 0.0082, F1 Macro: 0.0037\n",
      "Epoch 4/10, Train Loss: 0.1586, Accuracy: 0.8588, F1 Micro: 0.4227, F1 Macro: 0.1666\n",
      "Epoch 5/10, Train Loss: 0.1397, Accuracy: 0.8695, F1 Micro: 0.5613, F1 Macro: 0.258\n",
      "Epoch 6/10, Train Loss: 0.1245, Accuracy: 0.8726, F1 Micro: 0.6017, F1 Macro: 0.2791\n",
      "Epoch 7/10, Train Loss: 0.1128, Accuracy: 0.877, F1 Micro: 0.6142, F1 Macro: 0.2862\n",
      "Epoch 8/10, Train Loss: 0.0961, Accuracy: 0.8823, F1 Micro: 0.637, F1 Macro: 0.3186\n",
      "Epoch 9/10, Train Loss: 0.0837, Accuracy: 0.8806, F1 Micro: 0.6364, F1 Macro: 0.3192\n",
      "Epoch 10/10, Train Loss: 0.0758, Accuracy: 0.8844, F1 Micro: 0.6648, F1 Macro: 0.3761\n",
      "Best result for 3335 samples: F1 Micro: 0.6648\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.74      0.88      0.81      1141\n",
      "      Abusive       0.83      0.75      0.79      1012\n",
      "HS_Individual       0.58      0.77      0.66       737\n",
      "     HS_Group       0.62      0.45      0.52       404\n",
      "  HS_Religion       0.62      0.11      0.19       164\n",
      "      HS_Race       0.00      0.00      0.00       119\n",
      "  HS_Physical       0.00      0.00      0.00        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.63      0.80      0.71       779\n",
      "      HS_Weak       0.57      0.72      0.64       686\n",
      "  HS_Moderate       0.56      0.13      0.21       356\n",
      "    HS_Strong       0.00      0.00      0.00        99\n",
      "\n",
      "    micro avg       0.67      0.66      0.66      5608\n",
      "    macro avg       0.43      0.38      0.38      5608\n",
      " weighted avg       0.63      0.66      0.63      5608\n",
      "  samples avg       0.39      0.38      0.36      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.8207654595375063\n",
      "Samples above threshold: 720\n",
      "Acquired samples: 720\n",
      "Sampling duration: 30.916542530059814 seconds\n",
      "\n",
      "Fold 1 - New train size: 4055\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 4055 samples...\n",
      "Epoch 1/10, Train Loss: 0.3473, Accuracy: 0.8261, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.2045, Accuracy: 0.8261, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.1829, Accuracy: 0.8261, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 4/10, Train Loss: 0.1638, Accuracy: 0.8593, F1 Micro: 0.3862, F1 Macro: 0.1495\n",
      "Epoch 5/10, Train Loss: 0.1432, Accuracy: 0.876, F1 Micro: 0.5715, F1 Macro: 0.2607\n",
      "Epoch 6/10, Train Loss: 0.1208, Accuracy: 0.879, F1 Micro: 0.644, F1 Macro: 0.3037\n",
      "Epoch 7/10, Train Loss: 0.1091, Accuracy: 0.8849, F1 Micro: 0.6434, F1 Macro: 0.3077\n",
      "Epoch 8/10, Train Loss: 0.0862, Accuracy: 0.8837, F1 Micro: 0.6601, F1 Macro: 0.3305\n",
      "Epoch 9/10, Train Loss: 0.0795, Accuracy: 0.8913, F1 Micro: 0.6538, F1 Macro: 0.3986\n",
      "Epoch 10/10, Train Loss: 0.0657, Accuracy: 0.8957, F1 Micro: 0.6572, F1 Macro: 0.3934\n",
      "Best result for 4055 samples: F1 Micro: 0.6601\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.76      0.88      0.81      1141\n",
      "      Abusive       0.82      0.85      0.83      1012\n",
      "HS_Individual       0.57      0.78      0.66       737\n",
      "     HS_Group       0.71      0.23      0.34       404\n",
      "  HS_Religion       0.00      0.00      0.00       164\n",
      "      HS_Race       0.00      0.00      0.00       119\n",
      "  HS_Physical       0.00      0.00      0.00        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.62      0.77      0.68       779\n",
      "      HS_Weak       0.54      0.75      0.63       686\n",
      "  HS_Moderate       0.00      0.00      0.00       356\n",
      "    HS_Strong       0.00      0.00      0.00        99\n",
      "\n",
      "    micro avg       0.67      0.65      0.66      5608\n",
      "    macro avg       0.34      0.35      0.33      5608\n",
      " weighted avg       0.58      0.65      0.60      5608\n",
      "  samples avg       0.41      0.38      0.37      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.3757442474365237\n",
      "Samples above threshold: 648\n",
      "Acquired samples: 648\n",
      "Sampling duration: 27.802924871444702 seconds\n",
      "\n",
      "Fold 1 - New train size: 4703\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 4703 samples...\n",
      "Epoch 1/10, Train Loss: 0.337, Accuracy: 0.8261, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.2035, Accuracy: 0.8261, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.1895, Accuracy: 0.8276, F1 Micro: 0.0166, F1 Macro: 0.0074\n",
      "Epoch 4/10, Train Loss: 0.1698, Accuracy: 0.8702, F1 Micro: 0.4682, F1 Macro: 0.1998\n",
      "Epoch 5/10, Train Loss: 0.1448, Accuracy: 0.881, F1 Micro: 0.5594, F1 Macro: 0.2548\n",
      "Epoch 6/10, Train Loss: 0.1168, Accuracy: 0.8902, F1 Micro: 0.6435, F1 Macro: 0.3244\n",
      "Epoch 7/10, Train Loss: 0.096, Accuracy: 0.8916, F1 Micro: 0.6851, F1 Macro: 0.4044\n",
      "Epoch 8/10, Train Loss: 0.0811, Accuracy: 0.8985, F1 Micro: 0.6847, F1 Macro: 0.4601\n",
      "Epoch 9/10, Train Loss: 0.0662, Accuracy: 0.8981, F1 Micro: 0.6724, F1 Macro: 0.4537\n",
      "Epoch 10/10, Train Loss: 0.0621, Accuracy: 0.8954, F1 Micro: 0.6966, F1 Macro: 0.4636\n",
      "Best result for 4703 samples: F1 Micro: 0.6966\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.85      0.82      1141\n",
      "      Abusive       0.83      0.85      0.84      1012\n",
      "HS_Individual       0.63      0.74      0.68       737\n",
      "     HS_Group       0.62      0.42      0.50       404\n",
      "  HS_Religion       0.59      0.41      0.49       164\n",
      "      HS_Race       0.73      0.30      0.43       119\n",
      "  HS_Physical       0.00      0.00      0.00        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.70      0.75      0.72       779\n",
      "      HS_Weak       0.59      0.72      0.65       686\n",
      "  HS_Moderate       0.52      0.36      0.43       356\n",
      "    HS_Strong       0.00      0.00      0.00        99\n",
      "\n",
      "    micro avg       0.70      0.69      0.70      5608\n",
      "    macro avg       0.50      0.45      0.46      5608\n",
      " weighted avg       0.67      0.69      0.68      5608\n",
      "  samples avg       0.42      0.41      0.40      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.18631453514099136\n",
      "Samples above threshold: 584\n",
      "Acquired samples: 584\n",
      "Sampling duration: 24.93478536605835 seconds\n",
      "\n",
      "Fold 1 - New train size: 5287\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 5287 samples...\n",
      "Epoch 1/10, Train Loss: 0.3321, Accuracy: 0.8261, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.2151, Accuracy: 0.8261, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.1968, Accuracy: 0.8382, F1 Micro: 0.1329, F1 Macro: 0.0542\n",
      "Epoch 4/10, Train Loss: 0.167, Accuracy: 0.8841, F1 Micro: 0.619, F1 Macro: 0.2866\n",
      "Epoch 5/10, Train Loss: 0.1389, Accuracy: 0.8925, F1 Micro: 0.6439, F1 Macro: 0.3352\n",
      "Epoch 6/10, Train Loss: 0.1217, Accuracy: 0.8978, F1 Micro: 0.6833, F1 Macro: 0.4282\n",
      "Epoch 7/10, Train Loss: 0.0973, Accuracy: 0.9027, F1 Micro: 0.7006, F1 Macro: 0.453\n",
      "Epoch 8/10, Train Loss: 0.0772, Accuracy: 0.8969, F1 Micro: 0.7083, F1 Macro: 0.4635\n",
      "Epoch 9/10, Train Loss: 0.0696, Accuracy: 0.9028, F1 Micro: 0.7081, F1 Macro: 0.4589\n",
      "Epoch 10/10, Train Loss: 0.0595, Accuracy: 0.902, F1 Micro: 0.7155, F1 Macro: 0.4785\n",
      "Best result for 5287 samples: F1 Micro: 0.7155\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.87      0.83      1141\n",
      "      Abusive       0.86      0.87      0.87      1012\n",
      "HS_Individual       0.66      0.75      0.70       737\n",
      "     HS_Group       0.62      0.50      0.56       404\n",
      "  HS_Religion       0.68      0.43      0.53       164\n",
      "      HS_Race       0.78      0.24      0.37       119\n",
      "  HS_Physical       0.00      0.00      0.00        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.71      0.76      0.74       779\n",
      "      HS_Weak       0.62      0.72      0.67       686\n",
      "  HS_Moderate       0.52      0.45      0.48       356\n",
      "    HS_Strong       0.00      0.00      0.00        99\n",
      "\n",
      "    micro avg       0.72      0.71      0.72      5608\n",
      "    macro avg       0.52      0.47      0.48      5608\n",
      " weighted avg       0.69      0.71      0.70      5608\n",
      "  samples avg       0.43      0.41      0.40      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.09117059707641603\n",
      "Samples above threshold: 525\n",
      "Acquired samples: 525\n",
      "Sampling duration: 22.57577681541443 seconds\n",
      "\n",
      "Fold 1 - New train size: 5812\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 5812 samples...\n",
      "Epoch 1/10, Train Loss: 0.3364, Accuracy: 0.8261, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.2355, Accuracy: 0.8298, F1 Micro: 0.0422, F1 Macro: 0.0178\n",
      "Epoch 3/10, Train Loss: 0.2066, Accuracy: 0.8845, F1 Micro: 0.6048, F1 Macro: 0.2896\n",
      "Epoch 4/10, Train Loss: 0.1704, Accuracy: 0.8974, F1 Micro: 0.6696, F1 Macro: 0.3662\n",
      "Epoch 5/10, Train Loss: 0.1362, Accuracy: 0.9031, F1 Micro: 0.6938, F1 Macro: 0.4232\n",
      "Epoch 6/10, Train Loss: 0.1128, Accuracy: 0.8969, F1 Micro: 0.7063, F1 Macro: 0.4288\n",
      "Epoch 7/10, Train Loss: 0.0929, Accuracy: 0.9072, F1 Micro: 0.7309, F1 Macro: 0.5031\n",
      "Epoch 8/10, Train Loss: 0.08, Accuracy: 0.906, F1 Micro: 0.7253, F1 Macro: 0.4982\n",
      "Epoch 9/10, Train Loss: 0.0733, Accuracy: 0.9094, F1 Micro: 0.7342, F1 Macro: 0.5003\n",
      "Epoch 10/10, Train Loss: 0.0606, Accuracy: 0.9107, F1 Micro: 0.7143, F1 Macro: 0.4962\n",
      "Best result for 5812 samples: F1 Micro: 0.7342\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.88      0.85      1141\n",
      "      Abusive       0.89      0.86      0.87      1012\n",
      "HS_Individual       0.69      0.76      0.72       737\n",
      "     HS_Group       0.70      0.50      0.59       404\n",
      "  HS_Religion       0.71      0.47      0.57       164\n",
      "      HS_Race       0.82      0.31      0.45       119\n",
      "  HS_Physical       0.00      0.00      0.00        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.72      0.80      0.76       779\n",
      "      HS_Weak       0.64      0.75      0.69       686\n",
      "  HS_Moderate       0.59      0.42      0.49       356\n",
      "    HS_Strong       1.00      0.01      0.02        99\n",
      "\n",
      "    micro avg       0.75      0.72      0.73      5608\n",
      "    macro avg       0.63      0.48      0.50      5608\n",
      " weighted avg       0.74      0.72      0.71      5608\n",
      "  samples avg       0.44      0.42      0.41      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.08110568523406984\n",
      "Samples above threshold: 473\n",
      "Acquired samples: 473\n",
      "Sampling duration: 20.518015384674072 seconds\n",
      "\n",
      "Fold 1 - New train size: 6285\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 6285 samples...\n",
      "Epoch 1/10, Train Loss: 0.3516, Accuracy: 0.8261, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.2441, Accuracy: 0.8595, F1 Micro: 0.368, F1 Macro: 0.167\n",
      "Epoch 3/10, Train Loss: 0.1968, Accuracy: 0.8941, F1 Micro: 0.6404, F1 Macro: 0.3797\n",
      "Epoch 4/10, Train Loss: 0.1647, Accuracy: 0.9046, F1 Micro: 0.682, F1 Macro: 0.4274\n",
      "Epoch 5/10, Train Loss: 0.1339, Accuracy: 0.9054, F1 Micro: 0.711, F1 Macro: 0.4878\n",
      "Epoch 6/10, Train Loss: 0.115, Accuracy: 0.9087, F1 Micro: 0.7306, F1 Macro: 0.5142\n",
      "Epoch 7/10, Train Loss: 0.093, Accuracy: 0.9111, F1 Micro: 0.7324, F1 Macro: 0.5331\n",
      "Epoch 8/10, Train Loss: 0.0787, Accuracy: 0.9126, F1 Micro: 0.7258, F1 Macro: 0.5396\n",
      "Epoch 9/10, Train Loss: 0.069, Accuracy: 0.9121, F1 Micro: 0.7389, F1 Macro: 0.5451\n",
      "Epoch 10/10, Train Loss: 0.0615, Accuracy: 0.9138, F1 Micro: 0.7441, F1 Macro: 0.5562\n",
      "Best result for 6285 samples: F1 Micro: 0.7441\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.84      0.84      1141\n",
      "      Abusive       0.87      0.91      0.89      1012\n",
      "HS_Individual       0.70      0.75      0.73       737\n",
      "     HS_Group       0.74      0.53      0.62       404\n",
      "  HS_Religion       0.69      0.49      0.57       164\n",
      "      HS_Race       0.80      0.36      0.50       119\n",
      "  HS_Physical       0.00      0.00      0.00        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.75      0.76      0.75       779\n",
      "      HS_Weak       0.67      0.71      0.69       686\n",
      "  HS_Moderate       0.61      0.45      0.52       356\n",
      "    HS_Strong       0.83      0.43      0.57        99\n",
      "\n",
      "    micro avg       0.77      0.72      0.74      5608\n",
      "    macro avg       0.63      0.52      0.56      5608\n",
      " weighted avg       0.75      0.72      0.73      5608\n",
      "  samples avg       0.45      0.42      0.42      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.05845886468887329\n",
      "Samples above threshold: 426\n",
      "Acquired samples: 299\n",
      "Sampling duration: 18.6384494304657 seconds\n",
      "\n",
      "Fold 1 - New train size: 6584\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 6584 samples...\n",
      "Epoch 1/10, Train Loss: 0.3604, Accuracy: 0.8261, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.2502, Accuracy: 0.8612, F1 Micro: 0.3738, F1 Macro: 0.1773\n",
      "Epoch 3/10, Train Loss: 0.202, Accuracy: 0.899, F1 Micro: 0.6548, F1 Macro: 0.4464\n",
      "Epoch 4/10, Train Loss: 0.1601, Accuracy: 0.9048, F1 Micro: 0.6796, F1 Macro: 0.4563\n",
      "Epoch 5/10, Train Loss: 0.1294, Accuracy: 0.9092, F1 Micro: 0.7088, F1 Macro: 0.5562\n",
      "Epoch 6/10, Train Loss: 0.1121, Accuracy: 0.9114, F1 Micro: 0.7214, F1 Macro: 0.5395\n",
      "Epoch 7/10, Train Loss: 0.0974, Accuracy: 0.915, F1 Micro: 0.7237, F1 Macro: 0.5445\n",
      "Epoch 8/10, Train Loss: 0.0788, Accuracy: 0.9128, F1 Micro: 0.7402, F1 Macro: 0.5811\n",
      "Epoch 9/10, Train Loss: 0.0714, Accuracy: 0.9162, F1 Micro: 0.75, F1 Macro: 0.589\n",
      "Epoch 10/10, Train Loss: 0.0595, Accuracy: 0.9165, F1 Micro: 0.7522, F1 Macro: 0.5944\n",
      "Best result for 6584 samples: F1 Micro: 0.7522\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.85      0.85      1141\n",
      "      Abusive       0.90      0.87      0.88      1012\n",
      "HS_Individual       0.72      0.69      0.70       737\n",
      "     HS_Group       0.67      0.64      0.66       404\n",
      "  HS_Religion       0.73      0.51      0.60       164\n",
      "      HS_Race       0.77      0.55      0.64       119\n",
      "  HS_Physical       0.00      0.00      0.00        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.77      0.78      0.77       779\n",
      "      HS_Weak       0.70      0.64      0.67       686\n",
      "  HS_Moderate       0.60      0.57      0.59       356\n",
      "    HS_Strong       0.83      0.73      0.77        99\n",
      "\n",
      "    micro avg       0.78      0.73      0.75      5608\n",
      "    macro avg       0.63      0.57      0.59      5608\n",
      " weighted avg       0.76      0.73      0.74      5608\n",
      "  samples avg       0.44      0.42      0.41      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 0.047644972801208496\n",
      "Samples above threshold: 396\n",
      "Acquired samples: 396\n",
      "Sampling duration: 17.375513792037964 seconds\n",
      "\n",
      "Fold 1 - New train size: 6980\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 6980 samples...\n",
      "Epoch 1/10, Train Loss: 0.3622, Accuracy: 0.8264, F1 Micro: 0.0032, F1 Macro: 0.0013\n",
      "Epoch 2/10, Train Loss: 0.2546, Accuracy: 0.8745, F1 Micro: 0.4765, F1 Macro: 0.2656\n",
      "Epoch 3/10, Train Loss: 0.2017, Accuracy: 0.9051, F1 Micro: 0.7009, F1 Macro: 0.5057\n",
      "Epoch 4/10, Train Loss: 0.166, Accuracy: 0.9121, F1 Micro: 0.7318, F1 Macro: 0.5684\n",
      "Epoch 5/10, Train Loss: 0.1345, Accuracy: 0.9155, F1 Micro: 0.7431, F1 Macro: 0.5752\n",
      "Epoch 6/10, Train Loss: 0.1131, Accuracy: 0.9064, F1 Micro: 0.7401, F1 Macro: 0.5797\n",
      "Epoch 7/10, Train Loss: 0.103, Accuracy: 0.9169, F1 Micro: 0.7531, F1 Macro: 0.5876\n",
      "Epoch 8/10, Train Loss: 0.0833, Accuracy: 0.917, F1 Micro: 0.745, F1 Macro: 0.5798\n",
      "Epoch 9/10, Train Loss: 0.0686, Accuracy: 0.9184, F1 Micro: 0.7527, F1 Macro: 0.5982\n",
      "Epoch 10/10, Train Loss: 0.0593, Accuracy: 0.9187, F1 Micro: 0.7588, F1 Macro: 0.6035\n",
      "Best result for 6980 samples: F1 Micro: 0.7588\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.85      0.85      1141\n",
      "      Abusive       0.91      0.87      0.89      1012\n",
      "HS_Individual       0.73      0.68      0.71       737\n",
      "     HS_Group       0.66      0.65      0.66       404\n",
      "  HS_Religion       0.82      0.49      0.61       164\n",
      "      HS_Race       0.74      0.66      0.69       119\n",
      "  HS_Physical       0.00      0.00      0.00        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.77      0.81      0.79       779\n",
      "      HS_Weak       0.70      0.64      0.67       686\n",
      "  HS_Moderate       0.60      0.59      0.60       356\n",
      "    HS_Strong       0.85      0.72      0.78        99\n",
      "\n",
      "    micro avg       0.78      0.74      0.76      5608\n",
      "    macro avg       0.64      0.58      0.60      5608\n",
      " weighted avg       0.77      0.74      0.75      5608\n",
      "  samples avg       0.44      0.42      0.41      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 0.042318856716156004\n",
      "Samples above threshold: 356\n",
      "Acquired samples: 356\n",
      "Sampling duration: 15.694233179092407 seconds\n",
      "\n",
      "Fold 1 - New train size: 7336\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 7336 samples...\n",
      "Epoch 1/10, Train Loss: 0.3692, Accuracy: 0.8375, F1 Micro: 0.141, F1 Macro: 0.0544\n",
      "Epoch 2/10, Train Loss: 0.257, Accuracy: 0.8956, F1 Micro: 0.65, F1 Macro: 0.4535\n",
      "Epoch 3/10, Train Loss: 0.1986, Accuracy: 0.9038, F1 Micro: 0.6623, F1 Macro: 0.4335\n",
      "Epoch 4/10, Train Loss: 0.1669, Accuracy: 0.9137, F1 Micro: 0.7476, F1 Macro: 0.5816\n",
      "Epoch 5/10, Train Loss: 0.1385, Accuracy: 0.9127, F1 Micro: 0.7544, F1 Macro: 0.5911\n",
      "Epoch 6/10, Train Loss: 0.1148, Accuracy: 0.9133, F1 Micro: 0.7511, F1 Macro: 0.5958\n",
      "Epoch 7/10, Train Loss: 0.0967, Accuracy: 0.919, F1 Micro: 0.7477, F1 Macro: 0.6013\n",
      "Epoch 8/10, Train Loss: 0.0841, Accuracy: 0.9164, F1 Micro: 0.7567, F1 Macro: 0.6011\n",
      "Epoch 9/10, Train Loss: 0.0717, Accuracy: 0.9156, F1 Micro: 0.7543, F1 Macro: 0.6029\n",
      "Epoch 10/10, Train Loss: 0.0622, Accuracy: 0.9186, F1 Micro: 0.761, F1 Macro: 0.6089\n",
      "Best result for 7336 samples: F1 Micro: 0.761\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.85      0.85      1141\n",
      "      Abusive       0.90      0.89      0.90      1012\n",
      "HS_Individual       0.72      0.71      0.71       737\n",
      "     HS_Group       0.67      0.64      0.66       404\n",
      "  HS_Religion       0.71      0.55      0.62       164\n",
      "      HS_Race       0.78      0.66      0.72       119\n",
      "  HS_Physical       0.00      0.00      0.00        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.78      0.78      0.78       779\n",
      "      HS_Weak       0.69      0.69      0.69       686\n",
      "  HS_Moderate       0.61      0.57      0.59       356\n",
      "    HS_Strong       0.83      0.77      0.80        99\n",
      "\n",
      "    micro avg       0.78      0.75      0.76      5608\n",
      "    macro avg       0.63      0.59      0.61      5608\n",
      " weighted avg       0.76      0.75      0.75      5608\n",
      "  samples avg       0.44      0.43      0.42      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 0.031107079982757576\n",
      "Samples above threshold: 320\n",
      "Acquired samples: 320\n",
      "Sampling duration: 14.274118661880493 seconds\n",
      "\n",
      "Fold 1 - New train size: 7656\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 7656 samples...\n",
      "Epoch 1/10, Train Loss: 0.3738, Accuracy: 0.8475, F1 Micro: 0.2539, F1 Macro: 0.0962\n",
      "Epoch 2/10, Train Loss: 0.2533, Accuracy: 0.8975, F1 Micro: 0.6532, F1 Macro: 0.4386\n",
      "Epoch 3/10, Train Loss: 0.199, Accuracy: 0.91, F1 Micro: 0.7209, F1 Macro: 0.5176\n",
      "Epoch 4/10, Train Loss: 0.1639, Accuracy: 0.9158, F1 Micro: 0.753, F1 Macro: 0.594\n",
      "Epoch 5/10, Train Loss: 0.1376, Accuracy: 0.9182, F1 Micro: 0.7478, F1 Macro: 0.5788\n",
      "Epoch 6/10, Train Loss: 0.1156, Accuracy: 0.9186, F1 Micro: 0.764, F1 Macro: 0.5903\n",
      "Epoch 7/10, Train Loss: 0.0982, Accuracy: 0.9203, F1 Micro: 0.7641, F1 Macro: 0.5953\n",
      "Epoch 8/10, Train Loss: 0.0824, Accuracy: 0.9208, F1 Micro: 0.7609, F1 Macro: 0.6108\n",
      "Epoch 9/10, Train Loss: 0.0746, Accuracy: 0.9185, F1 Micro: 0.7661, F1 Macro: 0.6101\n",
      "Epoch 10/10, Train Loss: 0.0595, Accuracy: 0.9201, F1 Micro: 0.7654, F1 Macro: 0.6157\n",
      "Best result for 7656 samples: F1 Micro: 0.7661\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.88      0.85      1141\n",
      "      Abusive       0.90      0.88      0.89      1012\n",
      "HS_Individual       0.69      0.79      0.74       737\n",
      "     HS_Group       0.70      0.58      0.64       404\n",
      "  HS_Religion       0.69      0.62      0.66       164\n",
      "      HS_Race       0.76      0.66      0.71       119\n",
      "  HS_Physical       0.00      0.00      0.00        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.76      0.82      0.78       779\n",
      "      HS_Weak       0.67      0.76      0.71       686\n",
      "  HS_Moderate       0.63      0.50      0.56       356\n",
      "    HS_Strong       0.82      0.76      0.79        99\n",
      "\n",
      "    micro avg       0.76      0.77      0.77      5608\n",
      "    macro avg       0.62      0.60      0.61      5608\n",
      " weighted avg       0.75      0.77      0.76      5608\n",
      "  samples avg       0.45      0.44      0.43      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 0.031591963768005375\n",
      "Samples above threshold: 288\n",
      "Acquired samples: 245\n",
      "Sampling duration: 13.075850009918213 seconds\n",
      "\n",
      "Fold 1 - New train size: 7901\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 7901 samples...\n",
      "Epoch 1/10, Train Loss: 0.3763, Accuracy: 0.8575, F1 Micro: 0.3534, F1 Macro: 0.1413\n",
      "Epoch 2/10, Train Loss: 0.2509, Accuracy: 0.8893, F1 Micro: 0.5736, F1 Macro: 0.3462\n",
      "Epoch 3/10, Train Loss: 0.2, Accuracy: 0.9124, F1 Micro: 0.7285, F1 Macro: 0.5414\n",
      "Epoch 4/10, Train Loss: 0.1681, Accuracy: 0.9151, F1 Micro: 0.7243, F1 Macro: 0.5687\n",
      "Epoch 5/10, Train Loss: 0.14, Accuracy: 0.9198, F1 Micro: 0.7603, F1 Macro: 0.5998\n",
      "Epoch 6/10, Train Loss: 0.1172, Accuracy: 0.9205, F1 Micro: 0.7721, F1 Macro: 0.614\n",
      "Epoch 7/10, Train Loss: 0.0986, Accuracy: 0.9181, F1 Micro: 0.7629, F1 Macro: 0.6135\n",
      "Epoch 8/10, Train Loss: 0.0853, Accuracy: 0.9212, F1 Micro: 0.7709, F1 Macro: 0.6156\n",
      "Epoch 9/10, Train Loss: 0.0728, Accuracy: 0.9237, F1 Micro: 0.7709, F1 Macro: 0.6164\n",
      "Epoch 10/10, Train Loss: 0.0607, Accuracy: 0.923, F1 Micro: 0.7737, F1 Macro: 0.6171\n",
      "Best result for 7901 samples: F1 Micro: 0.7737\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.86      0.86      1141\n",
      "      Abusive       0.91      0.89      0.90      1012\n",
      "HS_Individual       0.70      0.79      0.74       737\n",
      "     HS_Group       0.77      0.54      0.64       404\n",
      "  HS_Religion       0.78      0.60      0.68       164\n",
      "      HS_Race       0.72      0.74      0.73       119\n",
      "  HS_Physical       0.00      0.00      0.00        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.80      0.79      0.80       779\n",
      "      HS_Weak       0.68      0.77      0.72       686\n",
      "  HS_Moderate       0.69      0.46      0.56       356\n",
      "    HS_Strong       0.85      0.75      0.80        99\n",
      "\n",
      "    micro avg       0.79      0.76      0.77      5608\n",
      "    macro avg       0.65      0.60      0.62      5608\n",
      " weighted avg       0.78      0.76      0.76      5608\n",
      "  samples avg       0.44      0.43      0.42      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.027456289529800434\n",
      "Samples above threshold: 264\n",
      "Acquired samples: 264\n",
      "Sampling duration: 11.809282302856445 seconds\n",
      "\n",
      "Fold 1 - New train size: 8165\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 8165 samples...\n",
      "Epoch 1/10, Train Loss: 0.3789, Accuracy: 0.8668, F1 Micro: 0.4835, F1 Macro: 0.2038\n",
      "Epoch 2/10, Train Loss: 0.2584, Accuracy: 0.9007, F1 Micro: 0.6804, F1 Macro: 0.4561\n",
      "Epoch 3/10, Train Loss: 0.2054, Accuracy: 0.9106, F1 Micro: 0.7029, F1 Macro: 0.5358\n",
      "Epoch 4/10, Train Loss: 0.1739, Accuracy: 0.9167, F1 Micro: 0.7249, F1 Macro: 0.5717\n",
      "Epoch 5/10, Train Loss: 0.144, Accuracy: 0.9219, F1 Micro: 0.7688, F1 Macro: 0.6119\n",
      "Epoch 6/10, Train Loss: 0.1195, Accuracy: 0.92, F1 Micro: 0.7503, F1 Macro: 0.6125\n",
      "Epoch 7/10, Train Loss: 0.1009, Accuracy: 0.9204, F1 Micro: 0.7673, F1 Macro: 0.6165\n",
      "Epoch 8/10, Train Loss: 0.0796, Accuracy: 0.9217, F1 Micro: 0.7756, F1 Macro: 0.6253\n",
      "Epoch 9/10, Train Loss: 0.072, Accuracy: 0.9232, F1 Micro: 0.7726, F1 Macro: 0.6228\n",
      "Epoch 10/10, Train Loss: 0.0644, Accuracy: 0.9213, F1 Micro: 0.7721, F1 Macro: 0.6273\n",
      "Best result for 8165 samples: F1 Micro: 0.7756\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.87      0.85      1141\n",
      "      Abusive       0.88      0.90      0.89      1012\n",
      "HS_Individual       0.74      0.74      0.74       737\n",
      "     HS_Group       0.68      0.70      0.69       404\n",
      "  HS_Religion       0.69      0.68      0.68       164\n",
      "      HS_Race       0.71      0.76      0.73       119\n",
      "  HS_Physical       0.00      0.00      0.00        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.76      0.83      0.79       779\n",
      "      HS_Weak       0.72      0.71      0.71       686\n",
      "  HS_Moderate       0.62      0.63      0.62       356\n",
      "    HS_Strong       0.78      0.80      0.79        99\n",
      "\n",
      "    micro avg       0.77      0.78      0.78      5608\n",
      "    macro avg       0.62      0.63      0.63      5608\n",
      " weighted avg       0.76      0.78      0.77      5608\n",
      "  samples avg       0.45      0.44      0.43      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.028960716724395746\n",
      "Samples above threshold: 237\n",
      "Acquired samples: 237\n",
      "Sampling duration: 10.749891519546509 seconds\n",
      "\n",
      "Fold 1 - New train size: 8402\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 8402 samples...\n",
      "Epoch 1/10, Train Loss: 0.38, Accuracy: 0.87, F1 Micro: 0.4902, F1 Macro: 0.2219\n",
      "Epoch 2/10, Train Loss: 0.256, Accuracy: 0.9029, F1 Micro: 0.6716, F1 Macro: 0.4476\n",
      "Epoch 3/10, Train Loss: 0.2054, Accuracy: 0.9131, F1 Micro: 0.7346, F1 Macro: 0.5781\n",
      "Epoch 4/10, Train Loss: 0.1667, Accuracy: 0.9208, F1 Micro: 0.7658, F1 Macro: 0.6012\n",
      "Epoch 5/10, Train Loss: 0.1358, Accuracy: 0.9228, F1 Micro: 0.7644, F1 Macro: 0.6135\n",
      "Epoch 6/10, Train Loss: 0.1163, Accuracy: 0.9189, F1 Micro: 0.7736, F1 Macro: 0.6185\n",
      "Epoch 7/10, Train Loss: 0.1015, Accuracy: 0.924, F1 Micro: 0.7766, F1 Macro: 0.6172\n",
      "Epoch 8/10, Train Loss: 0.0812, Accuracy: 0.922, F1 Micro: 0.7772, F1 Macro: 0.6285\n",
      "Epoch 9/10, Train Loss: 0.0721, Accuracy: 0.9224, F1 Micro: 0.763, F1 Macro: 0.6197\n",
      "Epoch 10/10, Train Loss: 0.0636, Accuracy: 0.9224, F1 Micro: 0.7692, F1 Macro: 0.6299\n",
      "Best result for 8402 samples: F1 Micro: 0.7772\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.88      0.86      1141\n",
      "      Abusive       0.85      0.92      0.89      1012\n",
      "HS_Individual       0.75      0.73      0.74       737\n",
      "     HS_Group       0.67      0.71      0.69       404\n",
      "  HS_Religion       0.67      0.70      0.68       164\n",
      "      HS_Race       0.79      0.76      0.77       119\n",
      "  HS_Physical       0.00      0.00      0.00        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.77      0.83      0.79       779\n",
      "      HS_Weak       0.72      0.68      0.70       686\n",
      "  HS_Moderate       0.63      0.66      0.65       356\n",
      "    HS_Strong       0.79      0.76      0.77        99\n",
      "\n",
      "    micro avg       0.77      0.78      0.78      5608\n",
      "    macro avg       0.62      0.63      0.63      5608\n",
      " weighted avg       0.75      0.78      0.77      5608\n",
      "  samples avg       0.45      0.45      0.43      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.024490475654602047\n",
      "Samples above threshold: 214\n",
      "Acquired samples: 214\n",
      "Sampling duration: 9.72736382484436 seconds\n",
      "\n",
      "Fold 1 - New train size: 8616\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 8616 samples...\n",
      "Epoch 1/10, Train Loss: 0.3804, Accuracy: 0.8723, F1 Micro: 0.4873, F1 Macro: 0.225\n",
      "Epoch 2/10, Train Loss: 0.2552, Accuracy: 0.9056, F1 Micro: 0.6973, F1 Macro: 0.449\n",
      "Epoch 3/10, Train Loss: 0.1998, Accuracy: 0.9172, F1 Micro: 0.7441, F1 Macro: 0.5805\n",
      "Epoch 4/10, Train Loss: 0.167, Accuracy: 0.9225, F1 Micro: 0.7695, F1 Macro: 0.6138\n",
      "Epoch 5/10, Train Loss: 0.1426, Accuracy: 0.9236, F1 Micro: 0.7654, F1 Macro: 0.6016\n",
      "Epoch 6/10, Train Loss: 0.1205, Accuracy: 0.9218, F1 Micro: 0.7639, F1 Macro: 0.6215\n",
      "Epoch 7/10, Train Loss: 0.0985, Accuracy: 0.924, F1 Micro: 0.7765, F1 Macro: 0.625\n",
      "Epoch 8/10, Train Loss: 0.0845, Accuracy: 0.9236, F1 Micro: 0.7681, F1 Macro: 0.6261\n",
      "Epoch 9/10, Train Loss: 0.0714, Accuracy: 0.9222, F1 Micro: 0.7716, F1 Macro: 0.6278\n",
      "Epoch 10/10, Train Loss: 0.0609, Accuracy: 0.9195, F1 Micro: 0.7712, F1 Macro: 0.6274\n",
      "Best result for 8616 samples: F1 Micro: 0.7765\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.86      0.85      1141\n",
      "      Abusive       0.88      0.90      0.89      1012\n",
      "HS_Individual       0.78      0.69      0.73       737\n",
      "     HS_Group       0.67      0.71      0.69       404\n",
      "  HS_Religion       0.70      0.62      0.66       164\n",
      "      HS_Race       0.78      0.70      0.73       119\n",
      "  HS_Physical       0.00      0.00      0.00        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.80      0.80      0.80       779\n",
      "      HS_Weak       0.76      0.66      0.70       686\n",
      "  HS_Moderate       0.65      0.65      0.65       356\n",
      "    HS_Strong       0.79      0.79      0.79        99\n",
      "\n",
      "    micro avg       0.79      0.76      0.78      5608\n",
      "    macro avg       0.64      0.61      0.63      5608\n",
      " weighted avg       0.78      0.76      0.77      5608\n",
      "  samples avg       0.44      0.43      0.42      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.025374436378479005\n",
      "Samples above threshold: 192\n",
      "Acquired samples: 200\n",
      "Sampling duration: 8.86690616607666 seconds\n",
      "\n",
      "Fold 1 - New train size: 8816\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 8816 samples...\n",
      "Epoch 1/10, Train Loss: 0.3821, Accuracy: 0.8802, F1 Micro: 0.5775, F1 Macro: 0.278\n",
      "Epoch 2/10, Train Loss: 0.2538, Accuracy: 0.9056, F1 Micro: 0.695, F1 Macro: 0.4722\n",
      "Epoch 3/10, Train Loss: 0.2063, Accuracy: 0.9167, F1 Micro: 0.7425, F1 Macro: 0.5842\n",
      "Epoch 4/10, Train Loss: 0.169, Accuracy: 0.9214, F1 Micro: 0.7683, F1 Macro: 0.6144\n",
      "Epoch 5/10, Train Loss: 0.1431, Accuracy: 0.9249, F1 Micro: 0.7721, F1 Macro: 0.6183\n",
      "Epoch 6/10, Train Loss: 0.1167, Accuracy: 0.9182, F1 Micro: 0.7704, F1 Macro: 0.6187\n",
      "Epoch 7/10, Train Loss: 0.0977, Accuracy: 0.9243, F1 Micro: 0.7806, F1 Macro: 0.6288\n",
      "Epoch 8/10, Train Loss: 0.0858, Accuracy: 0.9236, F1 Micro: 0.7742, F1 Macro: 0.6293\n",
      "Epoch 9/10, Train Loss: 0.0747, Accuracy: 0.9197, F1 Micro: 0.7713, F1 Macro: 0.6273\n",
      "Epoch 10/10, Train Loss: 0.0622, Accuracy: 0.924, F1 Micro: 0.7748, F1 Macro: 0.6284\n",
      "Best result for 8816 samples: F1 Micro: 0.7806\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.87      0.86      1141\n",
      "      Abusive       0.89      0.91      0.90      1012\n",
      "HS_Individual       0.75      0.72      0.73       737\n",
      "     HS_Group       0.68      0.72      0.70       404\n",
      "  HS_Religion       0.73      0.65      0.69       164\n",
      "      HS_Race       0.79      0.71      0.75       119\n",
      "  HS_Physical       0.00      0.00      0.00        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.78      0.83      0.80       779\n",
      "      HS_Weak       0.72      0.69      0.71       686\n",
      "  HS_Moderate       0.65      0.65      0.65       356\n",
      "    HS_Strong       0.77      0.75      0.76        99\n",
      "\n",
      "    micro avg       0.79      0.77      0.78      5608\n",
      "    macro avg       0.63      0.62      0.63      5608\n",
      " weighted avg       0.77      0.77      0.77      5608\n",
      "  samples avg       0.44      0.44      0.43      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.025229609012603762\n",
      "Samples above threshold: 172\n",
      "Acquired samples: 200\n",
      "Sampling duration: 8.11549162864685 seconds\n",
      "\n",
      "Fold 1 - New train size: 9016\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 9016 samples...\n",
      "Epoch 1/10, Train Loss: 0.3811, Accuracy: 0.8733, F1 Micro: 0.4804, F1 Macro: 0.2226\n",
      "Epoch 2/10, Train Loss: 0.255, Accuracy: 0.9059, F1 Micro: 0.6903, F1 Macro: 0.4878\n",
      "Epoch 3/10, Train Loss: 0.2078, Accuracy: 0.9187, F1 Micro: 0.7472, F1 Macro: 0.5737\n",
      "Epoch 4/10, Train Loss: 0.1711, Accuracy: 0.9216, F1 Micro: 0.7702, F1 Macro: 0.6124\n",
      "Epoch 5/10, Train Loss: 0.143, Accuracy: 0.9241, F1 Micro: 0.7697, F1 Macro: 0.6194\n",
      "Epoch 6/10, Train Loss: 0.1212, Accuracy: 0.9243, F1 Micro: 0.7726, F1 Macro: 0.6143\n",
      "Epoch 7/10, Train Loss: 0.1014, Accuracy: 0.9239, F1 Micro: 0.7785, F1 Macro: 0.6285\n",
      "Epoch 8/10, Train Loss: 0.0812, Accuracy: 0.9257, F1 Micro: 0.7754, F1 Macro: 0.6318\n",
      "Epoch 9/10, Train Loss: 0.0733, Accuracy: 0.9248, F1 Micro: 0.7767, F1 Macro: 0.6344\n",
      "Epoch 10/10, Train Loss: 0.0652, Accuracy: 0.925, F1 Micro: 0.7781, F1 Macro: 0.6358\n",
      "Best result for 9016 samples: F1 Micro: 0.7785\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.87      0.86      1141\n",
      "      Abusive       0.88      0.91      0.89      1012\n",
      "HS_Individual       0.78      0.70      0.74       737\n",
      "     HS_Group       0.67      0.73      0.70       404\n",
      "  HS_Religion       0.69      0.66      0.68       164\n",
      "      HS_Race       0.71      0.80      0.75       119\n",
      "  HS_Physical       0.00      0.00      0.00        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.79      0.79      0.79       779\n",
      "      HS_Weak       0.76      0.67      0.71       686\n",
      "  HS_Moderate       0.61      0.66      0.63       356\n",
      "    HS_Strong       0.80      0.78      0.79        99\n",
      "\n",
      "    micro avg       0.79      0.77      0.78      5608\n",
      "    macro avg       0.63      0.63      0.63      5608\n",
      " weighted avg       0.77      0.77      0.77      5608\n",
      "  samples avg       0.45      0.44      0.43      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.02003237009048462\n",
      "Samples above threshold: 152\n",
      "Acquired samples: 200\n",
      "Sampling duration: 7.312933683395386 seconds\n",
      "\n",
      "Fold 1 - New train size: 9216\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 9216 samples...\n",
      "Epoch 1/10, Train Loss: 0.3892, Accuracy: 0.8841, F1 Micro: 0.6204, F1 Macro: 0.2919\n",
      "Epoch 2/10, Train Loss: 0.2565, Accuracy: 0.9068, F1 Micro: 0.705, F1 Macro: 0.5091\n",
      "Epoch 3/10, Train Loss: 0.2057, Accuracy: 0.9178, F1 Micro: 0.747, F1 Macro: 0.5587\n",
      "Epoch 4/10, Train Loss: 0.1687, Accuracy: 0.9224, F1 Micro: 0.7673, F1 Macro: 0.5978\n",
      "Epoch 5/10, Train Loss: 0.1438, Accuracy: 0.9237, F1 Micro: 0.7782, F1 Macro: 0.627\n",
      "Epoch 6/10, Train Loss: 0.12, Accuracy: 0.9234, F1 Micro: 0.7589, F1 Macro: 0.5986\n",
      "Epoch 7/10, Train Loss: 0.1005, Accuracy: 0.9254, F1 Micro: 0.7832, F1 Macro: 0.6281\n",
      "Epoch 8/10, Train Loss: 0.0849, Accuracy: 0.9235, F1 Micro: 0.7763, F1 Macro: 0.628\n",
      "Epoch 9/10, Train Loss: 0.075, Accuracy: 0.9242, F1 Micro: 0.7704, F1 Macro: 0.6325\n",
      "Epoch 10/10, Train Loss: 0.0659, Accuracy: 0.9233, F1 Micro: 0.7753, F1 Macro: 0.6451\n",
      "Best result for 9216 samples: F1 Micro: 0.7832\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.87      0.86      1141\n",
      "      Abusive       0.90      0.90      0.90      1012\n",
      "HS_Individual       0.72      0.80      0.76       737\n",
      "     HS_Group       0.78      0.60      0.68       404\n",
      "  HS_Religion       0.74      0.63      0.68       164\n",
      "      HS_Race       0.79      0.73      0.76       119\n",
      "  HS_Physical       0.00      0.00      0.00        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.79      0.81      0.80       779\n",
      "      HS_Weak       0.69      0.78      0.73       686\n",
      "  HS_Moderate       0.72      0.52      0.61       356\n",
      "    HS_Strong       0.82      0.73      0.77        99\n",
      "\n",
      "    micro avg       0.79      0.78      0.78      5608\n",
      "    macro avg       0.65      0.61      0.63      5608\n",
      " weighted avg       0.78      0.78      0.77      5608\n",
      "  samples avg       0.45      0.44      0.43      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.016379630565643316\n",
      "Samples above threshold: 132\n",
      "Acquired samples: 2\n",
      "Sampling duration: 6.6504552364349365 seconds\n",
      "\n",
      "Fold 1 - New train size: 9218\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 9218 samples...\n",
      "Epoch 1/10, Train Loss: 0.3838, Accuracy: 0.8779, F1 Micro: 0.5227, F1 Macro: 0.2496\n",
      "Epoch 2/10, Train Loss: 0.2553, Accuracy: 0.9075, F1 Micro: 0.7131, F1 Macro: 0.5204\n",
      "Epoch 3/10, Train Loss: 0.2013, Accuracy: 0.9167, F1 Micro: 0.7336, F1 Macro: 0.5705\n",
      "Epoch 4/10, Train Loss: 0.1668, Accuracy: 0.9205, F1 Micro: 0.7735, F1 Macro: 0.6122\n",
      "Epoch 5/10, Train Loss: 0.144, Accuracy: 0.9259, F1 Micro: 0.7831, F1 Macro: 0.6276\n",
      "Epoch 6/10, Train Loss: 0.1177, Accuracy: 0.9243, F1 Micro: 0.7764, F1 Macro: 0.6143\n",
      "Epoch 7/10, Train Loss: 0.1032, Accuracy: 0.9254, F1 Micro: 0.7744, F1 Macro: 0.6125\n",
      "Epoch 8/10, Train Loss: 0.0857, Accuracy: 0.9219, F1 Micro: 0.7795, F1 Macro: 0.6304\n",
      "Epoch 9/10, Train Loss: 0.0745, Accuracy: 0.9227, F1 Micro: 0.7841, F1 Macro: 0.6472\n",
      "Epoch 10/10, Train Loss: 0.0633, Accuracy: 0.9238, F1 Micro: 0.7793, F1 Macro: 0.6393\n",
      "Best result for 9218 samples: F1 Micro: 0.7841\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.91      0.86      1141\n",
      "      Abusive       0.89      0.93      0.91      1012\n",
      "HS_Individual       0.71      0.78      0.74       737\n",
      "     HS_Group       0.67      0.71      0.69       404\n",
      "  HS_Religion       0.72      0.67      0.70       164\n",
      "      HS_Race       0.70      0.83      0.76       119\n",
      "  HS_Physical       1.00      0.09      0.17        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.76      0.84      0.80       779\n",
      "      HS_Weak       0.68      0.76      0.72       686\n",
      "  HS_Moderate       0.62      0.66      0.64       356\n",
      "    HS_Strong       0.79      0.78      0.78        99\n",
      "\n",
      "    micro avg       0.76      0.81      0.78      5608\n",
      "    macro avg       0.70      0.66      0.65      5608\n",
      " weighted avg       0.76      0.81      0.78      5608\n",
      "  samples avg       0.46      0.46      0.44      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 0.012336695194244386\n",
      "Samples above threshold: 132\n",
      "Acquired samples: 200\n",
      "Sampling duration: 6.5674591064453125 seconds\n",
      "\n",
      "Fold 1 - New train size: 9418\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 9418 samples...\n",
      "Epoch 1/10, Train Loss: 0.3838, Accuracy: 0.8848, F1 Micro: 0.5838, F1 Macro: 0.2821\n",
      "Epoch 2/10, Train Loss: 0.2522, Accuracy: 0.9097, F1 Micro: 0.7169, F1 Macro: 0.4963\n",
      "Epoch 3/10, Train Loss: 0.2035, Accuracy: 0.9185, F1 Micro: 0.75, F1 Macro: 0.5668\n",
      "Epoch 4/10, Train Loss: 0.1653, Accuracy: 0.9252, F1 Micro: 0.774, F1 Macro: 0.6157\n",
      "Epoch 5/10, Train Loss: 0.139, Accuracy: 0.9259, F1 Micro: 0.7828, F1 Macro: 0.6266\n",
      "Epoch 6/10, Train Loss: 0.1186, Accuracy: 0.9221, F1 Micro: 0.7763, F1 Macro: 0.6212\n",
      "Epoch 7/10, Train Loss: 0.1015, Accuracy: 0.926, F1 Micro: 0.781, F1 Macro: 0.6316\n",
      "Epoch 8/10, Train Loss: 0.0865, Accuracy: 0.9254, F1 Micro: 0.7818, F1 Macro: 0.6329\n",
      "Epoch 9/10, Train Loss: 0.0746, Accuracy: 0.9257, F1 Micro: 0.7793, F1 Macro: 0.641\n",
      "Epoch 10/10, Train Loss: 0.0652, Accuracy: 0.9228, F1 Micro: 0.7799, F1 Macro: 0.6547\n",
      "Best result for 9418 samples: F1 Micro: 0.7828\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.88      0.87      1141\n",
      "      Abusive       0.90      0.87      0.89      1012\n",
      "HS_Individual       0.77      0.72      0.74       737\n",
      "     HS_Group       0.71      0.70      0.71       404\n",
      "  HS_Religion       0.76      0.57      0.65       164\n",
      "      HS_Race       0.82      0.67      0.74       119\n",
      "  HS_Physical       0.00      0.00      0.00        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.77      0.84      0.80       779\n",
      "      HS_Weak       0.73      0.71      0.72       686\n",
      "  HS_Moderate       0.67      0.64      0.66       356\n",
      "    HS_Strong       0.85      0.68      0.75        99\n",
      "\n",
      "    micro avg       0.80      0.77      0.78      5608\n",
      "    macro avg       0.65      0.61      0.63      5608\n",
      " weighted avg       0.78      0.77      0.77      5608\n",
      "  samples avg       0.44      0.43      0.43      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 0.030859780311584473\n",
      "Samples above threshold: 112\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.710249900817871 seconds\n",
      "\n",
      "Fold 1 - New train size: 9618\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 9618 samples...\n",
      "Epoch 1/10, Train Loss: 0.3817, Accuracy: 0.8844, F1 Micro: 0.5757, F1 Macro: 0.2845\n",
      "Epoch 2/10, Train Loss: 0.2516, Accuracy: 0.9088, F1 Micro: 0.7136, F1 Macro: 0.534\n",
      "Epoch 3/10, Train Loss: 0.2058, Accuracy: 0.9188, F1 Micro: 0.7498, F1 Macro: 0.5682\n",
      "Epoch 4/10, Train Loss: 0.1702, Accuracy: 0.9224, F1 Micro: 0.7541, F1 Macro: 0.5913\n",
      "Epoch 5/10, Train Loss: 0.1484, Accuracy: 0.9243, F1 Micro: 0.769, F1 Macro: 0.6167\n",
      "Epoch 6/10, Train Loss: 0.1178, Accuracy: 0.9244, F1 Micro: 0.7824, F1 Macro: 0.6288\n",
      "Epoch 7/10, Train Loss: 0.1029, Accuracy: 0.9245, F1 Micro: 0.7717, F1 Macro: 0.6209\n",
      "Epoch 8/10, Train Loss: 0.0881, Accuracy: 0.924, F1 Micro: 0.7816, F1 Macro: 0.6382\n",
      "Epoch 9/10, Train Loss: 0.0782, Accuracy: 0.9233, F1 Micro: 0.7725, F1 Macro: 0.6346\n",
      "Epoch 10/10, Train Loss: 0.064, Accuracy: 0.9264, F1 Micro: 0.7748, F1 Macro: 0.6402\n",
      "Best result for 9618 samples: F1 Micro: 0.7824\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.89      0.86      1141\n",
      "      Abusive       0.91      0.89      0.90      1012\n",
      "HS_Individual       0.75      0.77      0.76       737\n",
      "     HS_Group       0.71      0.67      0.69       404\n",
      "  HS_Religion       0.70      0.60      0.65       164\n",
      "      HS_Race       0.85      0.66      0.74       119\n",
      "  HS_Physical       1.00      0.02      0.04        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.75      0.85      0.80       779\n",
      "      HS_Weak       0.72      0.74      0.73       686\n",
      "  HS_Moderate       0.66      0.57      0.61       356\n",
      "    HS_Strong       0.78      0.78      0.78        99\n",
      "\n",
      "    micro avg       0.78      0.78      0.78      5608\n",
      "    macro avg       0.72      0.62      0.63      5608\n",
      " weighted avg       0.78      0.78      0.77      5608\n",
      "  samples avg       0.44      0.44      0.43      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 0.018614351749420166\n",
      "Samples above threshold: 93\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.741461992263794 seconds\n",
      "\n",
      "Fold 1 - New train size: 9818\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 9818 samples...\n",
      "Epoch 1/10, Train Loss: 0.3842, Accuracy: 0.8844, F1 Micro: 0.5846, F1 Macro: 0.2857\n",
      "Epoch 2/10, Train Loss: 0.2514, Accuracy: 0.9106, F1 Micro: 0.7383, F1 Macro: 0.5482\n",
      "Epoch 3/10, Train Loss: 0.2029, Accuracy: 0.9177, F1 Micro: 0.7476, F1 Macro: 0.5888\n",
      "Epoch 4/10, Train Loss: 0.1712, Accuracy: 0.9236, F1 Micro: 0.778, F1 Macro: 0.6228\n",
      "Epoch 5/10, Train Loss: 0.1403, Accuracy: 0.9251, F1 Micro: 0.7849, F1 Macro: 0.6276\n",
      "Epoch 6/10, Train Loss: 0.1183, Accuracy: 0.9248, F1 Micro: 0.7772, F1 Macro: 0.6353\n",
      "Epoch 7/10, Train Loss: 0.1025, Accuracy: 0.9263, F1 Micro: 0.7782, F1 Macro: 0.6401\n",
      "Epoch 8/10, Train Loss: 0.086, Accuracy: 0.9259, F1 Micro: 0.779, F1 Macro: 0.6381\n",
      "Epoch 9/10, Train Loss: 0.0714, Accuracy: 0.9245, F1 Micro: 0.7734, F1 Macro: 0.6307\n",
      "Epoch 10/10, Train Loss: 0.0647, Accuracy: 0.9266, F1 Micro: 0.7815, F1 Macro: 0.6518\n",
      "Best result for 9818 samples: F1 Micro: 0.7849\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.89      0.86      1141\n",
      "      Abusive       0.90      0.89      0.89      1012\n",
      "HS_Individual       0.73      0.80      0.76       737\n",
      "     HS_Group       0.73      0.65      0.69       404\n",
      "  HS_Religion       0.74      0.62      0.67       164\n",
      "      HS_Race       0.70      0.78      0.74       119\n",
      "  HS_Physical       0.00      0.00      0.00        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.78      0.84      0.81       779\n",
      "      HS_Weak       0.70      0.76      0.73       686\n",
      "  HS_Moderate       0.70      0.55      0.61       356\n",
      "    HS_Strong       0.75      0.78      0.76        99\n",
      "\n",
      "    micro avg       0.78      0.79      0.78      5608\n",
      "    macro avg       0.63      0.63      0.63      5608\n",
      " weighted avg       0.77      0.79      0.78      5608\n",
      "  samples avg       0.44      0.44      0.43      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 0.017217254638671874\n",
      "Samples above threshold: 72\n",
      "Acquired samples: 200\n",
      "Sampling duration: 3.9755687713623047 seconds\n",
      "\n",
      "Fold 1 - New train size: 10018\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 10018 samples...\n",
      "Epoch 1/10, Train Loss: 0.3833, Accuracy: 0.8819, F1 Micro: 0.547, F1 Macro: 0.2623\n",
      "Epoch 2/10, Train Loss: 0.2561, Accuracy: 0.9086, F1 Micro: 0.7008, F1 Macro: 0.5341\n",
      "Epoch 3/10, Train Loss: 0.2052, Accuracy: 0.9175, F1 Micro: 0.7547, F1 Macro: 0.5777\n",
      "Epoch 4/10, Train Loss: 0.1702, Accuracy: 0.9218, F1 Micro: 0.7746, F1 Macro: 0.615\n",
      "Epoch 5/10, Train Loss: 0.1407, Accuracy: 0.9242, F1 Micro: 0.7821, F1 Macro: 0.6331\n",
      "Epoch 6/10, Train Loss: 0.1204, Accuracy: 0.9257, F1 Micro: 0.7851, F1 Macro: 0.6439\n",
      "Epoch 7/10, Train Loss: 0.101, Accuracy: 0.9252, F1 Micro: 0.7846, F1 Macro: 0.649\n",
      "Epoch 8/10, Train Loss: 0.0849, Accuracy: 0.9244, F1 Micro: 0.7781, F1 Macro: 0.6456\n",
      "Epoch 9/10, Train Loss: 0.0734, Accuracy: 0.9225, F1 Micro: 0.7794, F1 Macro: 0.6732\n",
      "Epoch 10/10, Train Loss: 0.0676, Accuracy: 0.9252, F1 Micro: 0.7794, F1 Macro: 0.6827\n",
      "Best result for 10018 samples: F1 Micro: 0.7851\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.87      0.86      1141\n",
      "      Abusive       0.90      0.90      0.90      1012\n",
      "HS_Individual       0.73      0.77      0.75       737\n",
      "     HS_Group       0.73      0.66      0.69       404\n",
      "  HS_Religion       0.73      0.63      0.68       164\n",
      "      HS_Race       0.78      0.73      0.75       119\n",
      "  HS_Physical       0.71      0.09      0.17        53\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.79      0.82      0.81       779\n",
      "      HS_Weak       0.70      0.75      0.73       686\n",
      "  HS_Moderate       0.68      0.57      0.62       356\n",
      "    HS_Strong       0.80      0.75      0.77        99\n",
      "\n",
      "    micro avg       0.79      0.78      0.79      5608\n",
      "    macro avg       0.70      0.63      0.64      5608\n",
      " weighted avg       0.78      0.78      0.78      5608\n",
      "  samples avg       0.45      0.44      0.43      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 0.01234122514724732\n",
      "Samples above threshold: 52\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.099557161331177 seconds\n",
      "\n",
      "Fold 1 - New train size: 10218\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 10218 samples...\n",
      "Epoch 1/10, Train Loss: 0.3825, Accuracy: 0.8884, F1 Micro: 0.618, F1 Macro: 0.3078\n",
      "Epoch 2/10, Train Loss: 0.2563, Accuracy: 0.9101, F1 Micro: 0.7342, F1 Macro: 0.5375\n",
      "Epoch 3/10, Train Loss: 0.2043, Accuracy: 0.922, F1 Micro: 0.7542, F1 Macro: 0.5833\n",
      "Epoch 4/10, Train Loss: 0.1736, Accuracy: 0.9266, F1 Micro: 0.7819, F1 Macro: 0.6228\n",
      "Epoch 5/10, Train Loss: 0.1456, Accuracy: 0.9237, F1 Micro: 0.7795, F1 Macro: 0.6244\n",
      "Epoch 6/10, Train Loss: 0.12, Accuracy: 0.9286, F1 Micro: 0.7864, F1 Macro: 0.6402\n",
      "Epoch 7/10, Train Loss: 0.1044, Accuracy: 0.9252, F1 Micro: 0.7877, F1 Macro: 0.6501\n",
      "Epoch 8/10, Train Loss: 0.0879, Accuracy: 0.9275, F1 Micro: 0.7837, F1 Macro: 0.6612\n",
      "Epoch 9/10, Train Loss: 0.0734, Accuracy: 0.9241, F1 Micro: 0.781, F1 Macro: 0.6591\n",
      "Epoch 10/10, Train Loss: 0.0651, Accuracy: 0.9274, F1 Micro: 0.7877, F1 Macro: 0.6683\n",
      "Best result for 10218 samples: F1 Micro: 0.7877\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.87      0.86      0.87      1141\n",
      "      Abusive       0.91      0.91      0.91      1012\n",
      "HS_Individual       0.76      0.72      0.74       737\n",
      "     HS_Group       0.69      0.70      0.69       404\n",
      "  HS_Religion       0.75      0.71      0.73       164\n",
      "      HS_Race       0.75      0.76      0.75       119\n",
      "  HS_Physical       0.70      0.13      0.22        53\n",
      "    HS_Gender       0.62      0.09      0.15        58\n",
      "     HS_Other       0.81      0.82      0.81       779\n",
      "      HS_Weak       0.73      0.68      0.71       686\n",
      "  HS_Moderate       0.65      0.64      0.64       356\n",
      "    HS_Strong       0.82      0.78      0.80        99\n",
      "\n",
      "    micro avg       0.80      0.77      0.79      5608\n",
      "    macro avg       0.75      0.65      0.67      5608\n",
      " weighted avg       0.80      0.77      0.78      5608\n",
      "  samples avg       0.45      0.44      0.43      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 0.005549335479736329\n",
      "Samples above threshold: 32\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.1723992824554443 seconds\n",
      "\n",
      "Fold 1 - New train size: 10418\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 10418 samples...\n",
      "Epoch 1/10, Train Loss: 0.3799, Accuracy: 0.8897, F1 Micro: 0.6278, F1 Macro: 0.3149\n",
      "Epoch 2/10, Train Loss: 0.2538, Accuracy: 0.9116, F1 Micro: 0.72, F1 Macro: 0.5294\n",
      "Epoch 3/10, Train Loss: 0.2039, Accuracy: 0.9208, F1 Micro: 0.7555, F1 Macro: 0.5648\n",
      "Epoch 4/10, Train Loss: 0.1738, Accuracy: 0.9269, F1 Micro: 0.7766, F1 Macro: 0.6199\n",
      "Epoch 5/10, Train Loss: 0.1473, Accuracy: 0.9254, F1 Micro: 0.7842, F1 Macro: 0.6312\n",
      "Epoch 6/10, Train Loss: 0.1212, Accuracy: 0.9244, F1 Micro: 0.7783, F1 Macro: 0.652\n",
      "Epoch 7/10, Train Loss: 0.1034, Accuracy: 0.9283, F1 Micro: 0.7815, F1 Macro: 0.657\n",
      "Epoch 8/10, Train Loss: 0.0879, Accuracy: 0.9279, F1 Micro: 0.7887, F1 Macro: 0.6749\n",
      "Epoch 9/10, Train Loss: 0.0755, Accuracy: 0.9282, F1 Micro: 0.7863, F1 Macro: 0.6828\n",
      "Epoch 10/10, Train Loss: 0.0615, Accuracy: 0.9266, F1 Micro: 0.7886, F1 Macro: 0.7068\n",
      "Best result for 10418 samples: F1 Micro: 0.7887\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.87      0.86      0.86      1141\n",
      "      Abusive       0.90      0.90      0.90      1012\n",
      "HS_Individual       0.77      0.71      0.74       737\n",
      "     HS_Group       0.69      0.71      0.70       404\n",
      "  HS_Religion       0.75      0.65      0.70       164\n",
      "      HS_Race       0.75      0.76      0.75       119\n",
      "  HS_Physical       0.56      0.17      0.26        53\n",
      "    HS_Gender       0.78      0.12      0.21        58\n",
      "     HS_Other       0.80      0.83      0.81       779\n",
      "      HS_Weak       0.75      0.68      0.72       686\n",
      "  HS_Moderate       0.65      0.66      0.65       356\n",
      "    HS_Strong       0.80      0.77      0.78        99\n",
      "\n",
      "    micro avg       0.80      0.77      0.79      5608\n",
      "    macro avg       0.76      0.65      0.67      5608\n",
      " weighted avg       0.80      0.77      0.78      5608\n",
      "  samples avg       0.45      0.44      0.43      5608\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 0.002720022201538086\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 117\n",
      "Sampling duration: 1.6906158924102783 seconds\n",
      "\n",
      "Fold 1 - New train size: 10535\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 1 - Training with 10535 samples...\n",
      "Epoch 1/10, Train Loss: 0.382, Accuracy: 0.8907, F1 Micro: 0.6566, F1 Macro: 0.3355\n",
      "Epoch 2/10, Train Loss: 0.2519, Accuracy: 0.9131, F1 Micro: 0.7279, F1 Macro: 0.5222\n",
      "Epoch 3/10, Train Loss: 0.2063, Accuracy: 0.9212, F1 Micro: 0.7553, F1 Macro: 0.5708\n",
      "Epoch 4/10, Train Loss: 0.1711, Accuracy: 0.9267, F1 Micro: 0.7798, F1 Macro: 0.6278\n",
      "Epoch 5/10, Train Loss: 0.1468, Accuracy: 0.9268, F1 Micro: 0.7869, F1 Macro: 0.6557\n",
      "Epoch 6/10, Train Loss: 0.1209, Accuracy: 0.928, F1 Micro: 0.7895, F1 Macro: 0.6679\n",
      "Epoch 7/10, Train Loss: 0.104, Accuracy: 0.9279, F1 Micro: 0.7756, F1 Macro: 0.6663\n",
      "Epoch 8/10, Train Loss: 0.0897, Accuracy: 0.9282, F1 Micro: 0.7918, F1 Macro: 0.7098\n",
      "Epoch 9/10, Train Loss: 0.0757, Accuracy: 0.929, F1 Micro: 0.7936, F1 Macro: 0.7061\n",
      "Epoch 10/10, Train Loss: 0.066, Accuracy: 0.9274, F1 Micro: 0.7794, F1 Macro: 0.6919\n",
      "Best result for 10535 samples: F1 Micro: 0.7936\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.87      0.86      1141\n",
      "      Abusive       0.91      0.90      0.91      1012\n",
      "HS_Individual       0.76      0.76      0.76       737\n",
      "     HS_Group       0.71      0.68      0.69       404\n",
      "  HS_Religion       0.70      0.70      0.70       164\n",
      "      HS_Race       0.73      0.75      0.74       119\n",
      "  HS_Physical       0.73      0.21      0.32        53\n",
      "    HS_Gender       0.76      0.38      0.51        58\n",
      "     HS_Other       0.82      0.81      0.82       779\n",
      "      HS_Weak       0.73      0.73      0.73       686\n",
      "  HS_Moderate       0.66      0.60      0.63       356\n",
      "    HS_Strong       0.81      0.80      0.81        99\n",
      "\n",
      "    micro avg       0.80      0.78      0.79      5608\n",
      "    macro avg       0.77      0.68      0.71      5608\n",
      " weighted avg       0.80      0.78      0.79      5608\n",
      "  samples avg       0.45      0.45      0.44      5608\n",
      "\n",
      "\n",
      "FOLD 1 COMPLETED in 6282.22 seconds\n",
      "===============================================\n",
      "STARTING FOLD 2/5\n",
      "===============================================\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 658 samples...\n",
      "Epoch 1/10, Train Loss: 0.6074, Accuracy: 0.8369, F1 Micro: 0.2789, F1 Macro: 0.0958\n",
      "Epoch 2/10, Train Loss: 0.4725, Accuracy: 0.8453, F1 Micro: 0.2388, F1 Macro: 0.078\n",
      "Epoch 3/10, Train Loss: 0.414, Accuracy: 0.8392, F1 Micro: 0.1207, F1 Macro: 0.0438\n",
      "Epoch 4/10, Train Loss: 0.3877, Accuracy: 0.849, F1 Micro: 0.2496, F1 Macro: 0.0847\n",
      "Epoch 5/10, Train Loss: 0.3756, Accuracy: 0.8507, F1 Micro: 0.271, F1 Macro: 0.0898\n",
      "Epoch 6/10, Train Loss: 0.3627, Accuracy: 0.8593, F1 Micro: 0.3917, F1 Macro: 0.1349\n",
      "Epoch 7/10, Train Loss: 0.347, Accuracy: 0.8698, F1 Micro: 0.4861, F1 Macro: 0.2087\n",
      "Epoch 8/10, Train Loss: 0.3046, Accuracy: 0.8757, F1 Micro: 0.576, F1 Macro: 0.2681\n",
      "Epoch 9/10, Train Loss: 0.295, Accuracy: 0.8795, F1 Micro: 0.5968, F1 Macro: 0.3013\n",
      "Epoch 10/10, Train Loss: 0.2598, Accuracy: 0.8811, F1 Micro: 0.6072, F1 Macro: 0.318\n",
      "Best result for 658 samples: F1 Micro: 0.6072\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.75      0.76      0.75      1094\n",
      "      Abusive       0.81      0.73      0.77      1072\n",
      "HS_Individual       0.60      0.58      0.59       689\n",
      "     HS_Group       0.66      0.29      0.40       405\n",
      "  HS_Religion       0.00      0.00      0.00       124\n",
      "      HS_Race       0.00      0.00      0.00       125\n",
      "  HS_Physical       0.00      0.00      0.00        61\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.64      0.59      0.62       754\n",
      "      HS_Weak       0.59      0.55      0.57       664\n",
      "  HS_Moderate       0.48      0.07      0.12       346\n",
      "    HS_Strong       0.00      0.00      0.00        84\n",
      "\n",
      "    micro avg       0.69      0.54      0.61      5476\n",
      "    macro avg       0.38      0.30      0.32      5476\n",
      " weighted avg       0.62      0.54      0.57      5476\n",
      "  samples avg       0.37      0.32      0.32      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.8251348823308945\n",
      "Samples above threshold: 988\n",
      "Acquired samples: 988\n",
      "Sampling duration: 42.27770733833313 seconds\n",
      "\n",
      "Fold 2 - New train size: 1646\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 1646 samples...\n",
      "Epoch 1/10, Train Loss: 0.4786, Accuracy: 0.8302, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.2884, Accuracy: 0.8302, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.2564, Accuracy: 0.8421, F1 Micro: 0.2065, F1 Macro: 0.0719\n",
      "Epoch 4/10, Train Loss: 0.2309, Accuracy: 0.8512, F1 Micro: 0.3288, F1 Macro: 0.1277\n",
      "Epoch 5/10, Train Loss: 0.1923, Accuracy: 0.8658, F1 Micro: 0.5177, F1 Macro: 0.2356\n",
      "Epoch 6/10, Train Loss: 0.1773, Accuracy: 0.8623, F1 Micro: 0.5839, F1 Macro: 0.2685\n",
      "Epoch 7/10, Train Loss: 0.1614, Accuracy: 0.871, F1 Micro: 0.5351, F1 Macro: 0.2471\n",
      "Epoch 8/10, Train Loss: 0.1586, Accuracy: 0.8758, F1 Micro: 0.5519, F1 Macro: 0.2728\n",
      "Epoch 9/10, Train Loss: 0.1291, Accuracy: 0.8781, F1 Micro: 0.5931, F1 Macro: 0.3144\n",
      "Epoch 10/10, Train Loss: 0.1146, Accuracy: 0.8808, F1 Micro: 0.609, F1 Macro: 0.3292\n",
      "Best result for 1646 samples: F1 Micro: 0.609\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.76      0.79      0.78      1094\n",
      "      Abusive       0.82      0.70      0.76      1072\n",
      "HS_Individual       0.59      0.58      0.58       689\n",
      "     HS_Group       0.63      0.33      0.43       405\n",
      "  HS_Religion       0.80      0.03      0.06       124\n",
      "      HS_Race       0.00      0.00      0.00       125\n",
      "  HS_Physical       0.00      0.00      0.00        61\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.64      0.58      0.61       754\n",
      "      HS_Weak       0.57      0.56      0.56       664\n",
      "  HS_Moderate       0.40      0.11      0.17       346\n",
      "    HS_Strong       0.00      0.00      0.00        84\n",
      "\n",
      "    micro avg       0.69      0.55      0.61      5476\n",
      "    macro avg       0.44      0.31      0.33      5476\n",
      " weighted avg       0.64      0.55      0.57      5476\n",
      "  samples avg       0.37      0.31      0.31      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.9283307686448097\n",
      "Samples above threshold: 889\n",
      "Acquired samples: 889\n",
      "Sampling duration: 37.77622699737549 seconds\n",
      "\n",
      "Fold 2 - New train size: 2535\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 2535 samples...\n",
      "Epoch 1/10, Train Loss: 0.3998, Accuracy: 0.8302, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.2327, Accuracy: 0.8302, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.1955, Accuracy: 0.8423, F1 Micro: 0.2092, F1 Macro: 0.0799\n",
      "Epoch 4/10, Train Loss: 0.1632, Accuracy: 0.8613, F1 Micro: 0.5042, F1 Macro: 0.2272\n",
      "Epoch 5/10, Train Loss: 0.1455, Accuracy: 0.8664, F1 Micro: 0.4953, F1 Macro: 0.2286\n",
      "Epoch 6/10, Train Loss: 0.1281, Accuracy: 0.8686, F1 Micro: 0.5892, F1 Macro: 0.2772\n",
      "Epoch 7/10, Train Loss: 0.1244, Accuracy: 0.8681, F1 Micro: 0.6029, F1 Macro: 0.3093\n",
      "Epoch 8/10, Train Loss: 0.1036, Accuracy: 0.8727, F1 Micro: 0.5973, F1 Macro: 0.3091\n",
      "Epoch 9/10, Train Loss: 0.0877, Accuracy: 0.8725, F1 Micro: 0.6234, F1 Macro: 0.3304\n",
      "Epoch 10/10, Train Loss: 0.082, Accuracy: 0.8766, F1 Micro: 0.6286, F1 Macro: 0.3497\n",
      "Best result for 2535 samples: F1 Micro: 0.6286\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.72      0.82      0.77      1094\n",
      "      Abusive       0.79      0.75      0.77      1072\n",
      "HS_Individual       0.54      0.69      0.61       689\n",
      "     HS_Group       0.61      0.35      0.45       405\n",
      "  HS_Religion       0.50      0.05      0.09       124\n",
      "      HS_Race       0.00      0.00      0.00       125\n",
      "  HS_Physical       0.00      0.00      0.00        61\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.59      0.71      0.65       754\n",
      "      HS_Weak       0.54      0.66      0.59       664\n",
      "  HS_Moderate       0.47      0.19      0.27       346\n",
      "    HS_Strong       0.00      0.00      0.00        84\n",
      "\n",
      "    micro avg       0.64      0.62      0.63      5476\n",
      "    macro avg       0.40      0.35      0.35      5476\n",
      " weighted avg       0.60      0.62      0.59      5476\n",
      "  samples avg       0.37      0.36      0.34      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.9248801089823246\n",
      "Samples above threshold: 800\n",
      "Acquired samples: 800\n",
      "Sampling duration: 34.38208794593811 seconds\n",
      "\n",
      "Fold 2 - New train size: 3335\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 3335 samples...\n",
      "Epoch 1/10, Train Loss: 0.3607, Accuracy: 0.8302, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.2013, Accuracy: 0.8302, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.1848, Accuracy: 0.8459, F1 Micro: 0.2303, F1 Macro: 0.0904\n",
      "Epoch 4/10, Train Loss: 0.1509, Accuracy: 0.8661, F1 Micro: 0.5429, F1 Macro: 0.2498\n",
      "Epoch 5/10, Train Loss: 0.1372, Accuracy: 0.8677, F1 Micro: 0.5424, F1 Macro: 0.2528\n",
      "Epoch 6/10, Train Loss: 0.112, Accuracy: 0.8752, F1 Micro: 0.573, F1 Macro: 0.2737\n",
      "Epoch 7/10, Train Loss: 0.1011, Accuracy: 0.8761, F1 Micro: 0.5914, F1 Macro: 0.318\n",
      "Epoch 8/10, Train Loss: 0.0882, Accuracy: 0.8783, F1 Micro: 0.6118, F1 Macro: 0.3735\n",
      "Epoch 9/10, Train Loss: 0.0746, Accuracy: 0.8773, F1 Micro: 0.6416, F1 Macro: 0.3813\n",
      "Epoch 10/10, Train Loss: 0.0628, Accuracy: 0.884, F1 Micro: 0.6343, F1 Macro: 0.3849\n",
      "Best result for 3335 samples: F1 Micro: 0.6416\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.72      0.84      0.77      1094\n",
      "      Abusive       0.79      0.79      0.79      1072\n",
      "HS_Individual       0.53      0.72      0.61       689\n",
      "     HS_Group       0.62      0.38      0.47       405\n",
      "  HS_Religion       0.42      0.11      0.18       124\n",
      "      HS_Race       0.86      0.10      0.17       125\n",
      "  HS_Physical       0.00      0.00      0.00        61\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.61      0.71      0.66       754\n",
      "      HS_Weak       0.51      0.71      0.60       664\n",
      "  HS_Moderate       0.45      0.24      0.32       346\n",
      "    HS_Strong       0.00      0.00      0.00        84\n",
      "\n",
      "    micro avg       0.64      0.65      0.64      5476\n",
      "    macro avg       0.46      0.38      0.38      5476\n",
      " weighted avg       0.62      0.65      0.61      5476\n",
      "  samples avg       0.38      0.37      0.35      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.8642495200037957\n",
      "Samples above threshold: 720\n",
      "Acquired samples: 720\n",
      "Sampling duration: 31.14509868621826 seconds\n",
      "\n",
      "Fold 2 - New train size: 4055\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 4055 samples...\n",
      "Epoch 1/10, Train Loss: 0.3319, Accuracy: 0.8302, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.2064, Accuracy: 0.8302, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.1802, Accuracy: 0.8396, F1 Micro: 0.1236, F1 Macro: 0.0468\n",
      "Epoch 4/10, Train Loss: 0.1508, Accuracy: 0.8659, F1 Micro: 0.4752, F1 Macro: 0.2174\n",
      "Epoch 5/10, Train Loss: 0.1293, Accuracy: 0.8763, F1 Micro: 0.5802, F1 Macro: 0.2757\n",
      "Epoch 6/10, Train Loss: 0.1099, Accuracy: 0.8807, F1 Micro: 0.615, F1 Macro: 0.3173\n",
      "Epoch 7/10, Train Loss: 0.0972, Accuracy: 0.8764, F1 Micro: 0.62, F1 Macro: 0.3526\n",
      "Epoch 8/10, Train Loss: 0.083, Accuracy: 0.8794, F1 Micro: 0.649, F1 Macro: 0.3888\n",
      "Epoch 9/10, Train Loss: 0.0721, Accuracy: 0.8879, F1 Micro: 0.6323, F1 Macro: 0.3967\n",
      "Epoch 10/10, Train Loss: 0.06, Accuracy: 0.8825, F1 Micro: 0.6558, F1 Macro: 0.423\n",
      "Best result for 4055 samples: F1 Micro: 0.6558\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.73      0.85      0.79      1094\n",
      "      Abusive       0.85      0.74      0.79      1072\n",
      "HS_Individual       0.54      0.74      0.62       689\n",
      "     HS_Group       0.62      0.44      0.51       405\n",
      "  HS_Religion       0.43      0.23      0.30       124\n",
      "      HS_Race       0.80      0.26      0.40       125\n",
      "  HS_Physical       0.00      0.00      0.00        61\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.64      0.74      0.68       754\n",
      "      HS_Weak       0.54      0.71      0.61       664\n",
      "  HS_Moderate       0.45      0.31      0.36       346\n",
      "    HS_Strong       0.00      0.00      0.00        84\n",
      "\n",
      "    micro avg       0.65      0.66      0.66      5476\n",
      "    macro avg       0.47      0.42      0.42      5476\n",
      " weighted avg       0.64      0.66      0.64      5476\n",
      "  samples avg       0.39      0.38      0.36      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.6349295079708103\n",
      "Samples above threshold: 648\n",
      "Acquired samples: 648\n",
      "Sampling duration: 27.81871247291565 seconds\n",
      "\n",
      "Fold 2 - New train size: 4703\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 4703 samples...\n",
      "Epoch 1/10, Train Loss: 0.3221, Accuracy: 0.8302, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.1932, Accuracy: 0.8302, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.1823, Accuracy: 0.843, F1 Micro: 0.1563, F1 Macro: 0.0505\n",
      "Epoch 4/10, Train Loss: 0.1594, Accuracy: 0.8739, F1 Micro: 0.5321, F1 Macro: 0.247\n",
      "Epoch 5/10, Train Loss: 0.1383, Accuracy: 0.8792, F1 Micro: 0.6298, F1 Macro: 0.3117\n",
      "Epoch 6/10, Train Loss: 0.1088, Accuracy: 0.8843, F1 Micro: 0.6131, F1 Macro: 0.3011\n",
      "Epoch 7/10, Train Loss: 0.0917, Accuracy: 0.8846, F1 Micro: 0.6407, F1 Macro: 0.3547\n",
      "Epoch 8/10, Train Loss: 0.074, Accuracy: 0.8914, F1 Micro: 0.6658, F1 Macro: 0.4203\n",
      "Epoch 9/10, Train Loss: 0.0658, Accuracy: 0.8846, F1 Micro: 0.6635, F1 Macro: 0.4389\n",
      "Epoch 10/10, Train Loss: 0.0601, Accuracy: 0.8905, F1 Micro: 0.6604, F1 Macro: 0.4084\n",
      "Best result for 4703 samples: F1 Micro: 0.6658\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.77      0.82      0.79      1094\n",
      "      Abusive       0.88      0.79      0.83      1072\n",
      "HS_Individual       0.61      0.65      0.63       689\n",
      "     HS_Group       0.61      0.48      0.54       405\n",
      "  HS_Religion       0.49      0.18      0.26       124\n",
      "      HS_Race       0.85      0.18      0.30       125\n",
      "  HS_Physical       0.00      0.00      0.00        61\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.66      0.69      0.68       754\n",
      "      HS_Weak       0.59      0.64      0.61       664\n",
      "  HS_Moderate       0.48      0.35      0.40       346\n",
      "    HS_Strong       0.00      0.00      0.00        84\n",
      "\n",
      "    micro avg       0.70      0.64      0.67      5476\n",
      "    macro avg       0.49      0.40      0.42      5476\n",
      " weighted avg       0.67      0.64      0.65      5476\n",
      "  samples avg       0.40      0.37      0.36      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.4072496891021739\n",
      "Samples above threshold: 584\n",
      "Acquired samples: 584\n",
      "Sampling duration: 25.248512506484985 seconds\n",
      "\n",
      "Fold 2 - New train size: 5287\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 5287 samples...\n",
      "Epoch 1/10, Train Loss: 0.3264, Accuracy: 0.8302, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.2084, Accuracy: 0.8302, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.189, Accuracy: 0.8703, F1 Micro: 0.5008, F1 Macro: 0.2251\n",
      "Epoch 4/10, Train Loss: 0.1595, Accuracy: 0.8803, F1 Micro: 0.5781, F1 Macro: 0.2916\n",
      "Epoch 5/10, Train Loss: 0.1309, Accuracy: 0.8862, F1 Micro: 0.5865, F1 Macro: 0.3054\n",
      "Epoch 6/10, Train Loss: 0.1081, Accuracy: 0.8864, F1 Micro: 0.6866, F1 Macro: 0.4506\n",
      "Epoch 7/10, Train Loss: 0.0946, Accuracy: 0.8947, F1 Micro: 0.6613, F1 Macro: 0.4124\n",
      "Epoch 8/10, Train Loss: 0.0769, Accuracy: 0.8964, F1 Micro: 0.6829, F1 Macro: 0.4509\n",
      "Epoch 9/10, Train Loss: 0.0646, Accuracy: 0.897, F1 Micro: 0.6868, F1 Macro: 0.4652\n",
      "Epoch 10/10, Train Loss: 0.0534, Accuracy: 0.8963, F1 Micro: 0.6845, F1 Macro: 0.4586\n",
      "Best result for 5287 samples: F1 Micro: 0.6868\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.78      0.83      0.80      1094\n",
      "      Abusive       0.90      0.80      0.85      1072\n",
      "HS_Individual       0.61      0.68      0.64       689\n",
      "     HS_Group       0.66      0.50      0.57       405\n",
      "  HS_Religion       0.66      0.36      0.47       124\n",
      "      HS_Race       0.79      0.36      0.49       125\n",
      "  HS_Physical       0.00      0.00      0.00        61\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.67      0.72      0.69       754\n",
      "      HS_Weak       0.59      0.67      0.63       664\n",
      "  HS_Moderate       0.51      0.38      0.43       346\n",
      "    HS_Strong       0.00      0.00      0.00        84\n",
      "\n",
      "    micro avg       0.71      0.67      0.69      5476\n",
      "    macro avg       0.51      0.44      0.47      5476\n",
      " weighted avg       0.69      0.67      0.67      5476\n",
      "  samples avg       0.42      0.39      0.38      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.14620615243911747\n",
      "Samples above threshold: 525\n",
      "Acquired samples: 525\n",
      "Sampling duration: 22.559158325195312 seconds\n",
      "\n",
      "Fold 2 - New train size: 5812\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 5812 samples...\n",
      "Epoch 1/10, Train Loss: 0.3217, Accuracy: 0.8302, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.2293, Accuracy: 0.8396, F1 Micro: 0.1209, F1 Macro: 0.04\n",
      "Epoch 3/10, Train Loss: 0.2053, Accuracy: 0.8751, F1 Micro: 0.4983, F1 Macro: 0.2313\n",
      "Epoch 4/10, Train Loss: 0.1619, Accuracy: 0.8877, F1 Micro: 0.6217, F1 Macro: 0.3343\n",
      "Epoch 5/10, Train Loss: 0.1377, Accuracy: 0.8946, F1 Micro: 0.6703, F1 Macro: 0.3782\n",
      "Epoch 6/10, Train Loss: 0.1072, Accuracy: 0.8987, F1 Micro: 0.696, F1 Macro: 0.4612\n",
      "Epoch 7/10, Train Loss: 0.0902, Accuracy: 0.8962, F1 Micro: 0.6873, F1 Macro: 0.4601\n",
      "Epoch 8/10, Train Loss: 0.0734, Accuracy: 0.9025, F1 Micro: 0.7083, F1 Macro: 0.4786\n",
      "Epoch 9/10, Train Loss: 0.0692, Accuracy: 0.9039, F1 Micro: 0.712, F1 Macro: 0.4973\n",
      "Epoch 10/10, Train Loss: 0.0524, Accuracy: 0.8999, F1 Micro: 0.7039, F1 Macro: 0.4912\n",
      "Best result for 5812 samples: F1 Micro: 0.712\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.79      0.85      0.82      1094\n",
      "      Abusive       0.88      0.87      0.88      1072\n",
      "HS_Individual       0.64      0.71      0.67       689\n",
      "     HS_Group       0.68      0.54      0.60       405\n",
      "  HS_Religion       0.66      0.57      0.61       124\n",
      "      HS_Race       0.88      0.41      0.56       125\n",
      "  HS_Physical       0.00      0.00      0.00        61\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.68      0.71      0.70       754\n",
      "      HS_Weak       0.61      0.69      0.65       664\n",
      "  HS_Moderate       0.53      0.44      0.48       346\n",
      "    HS_Strong       0.00      0.00      0.00        84\n",
      "\n",
      "    micro avg       0.72      0.70      0.71      5476\n",
      "    macro avg       0.53      0.48      0.50      5476\n",
      " weighted avg       0.70      0.70      0.70      5476\n",
      "  samples avg       0.43      0.41      0.40      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.07187503576278687\n",
      "Samples above threshold: 473\n",
      "Acquired samples: 473\n",
      "Sampling duration: 20.511995315551758 seconds\n",
      "\n",
      "Fold 2 - New train size: 6285\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 6285 samples...\n",
      "Epoch 1/10, Train Loss: 0.3342, Accuracy: 0.8302, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.242, Accuracy: 0.8607, F1 Micro: 0.3455, F1 Macro: 0.1409\n",
      "Epoch 3/10, Train Loss: 0.195, Accuracy: 0.8889, F1 Micro: 0.6056, F1 Macro: 0.3626\n",
      "Epoch 4/10, Train Loss: 0.1568, Accuracy: 0.8966, F1 Micro: 0.6901, F1 Macro: 0.4628\n",
      "Epoch 5/10, Train Loss: 0.1323, Accuracy: 0.8939, F1 Micro: 0.7085, F1 Macro: 0.4919\n",
      "Epoch 6/10, Train Loss: 0.1019, Accuracy: 0.8969, F1 Micro: 0.7056, F1 Macro: 0.4704\n",
      "Epoch 7/10, Train Loss: 0.0882, Accuracy: 0.904, F1 Micro: 0.7035, F1 Macro: 0.4802\n",
      "Epoch 8/10, Train Loss: 0.0745, Accuracy: 0.9034, F1 Micro: 0.7173, F1 Macro: 0.495\n",
      "Epoch 9/10, Train Loss: 0.0651, Accuracy: 0.905, F1 Micro: 0.7048, F1 Macro: 0.467\n",
      "Epoch 10/10, Train Loss: 0.055, Accuracy: 0.9074, F1 Micro: 0.7165, F1 Macro: 0.5237\n",
      "Best result for 6285 samples: F1 Micro: 0.7173\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.77      0.88      0.82      1094\n",
      "      Abusive       0.87      0.87      0.87      1072\n",
      "HS_Individual       0.62      0.74      0.68       689\n",
      "     HS_Group       0.68      0.54      0.60       405\n",
      "  HS_Religion       0.66      0.49      0.56       124\n",
      "      HS_Race       0.76      0.44      0.56       125\n",
      "  HS_Physical       0.00      0.00      0.00        61\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.67      0.79      0.72       754\n",
      "      HS_Weak       0.60      0.72      0.66       664\n",
      "  HS_Moderate       0.55      0.40      0.46       346\n",
      "    HS_Strong       0.00      0.00      0.00        84\n",
      "\n",
      "    micro avg       0.71      0.72      0.72      5476\n",
      "    macro avg       0.52      0.49      0.50      5476\n",
      " weighted avg       0.69      0.72      0.70      5476\n",
      "  samples avg       0.45      0.43      0.42      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.051419198513031006\n",
      "Samples above threshold: 425\n",
      "Acquired samples: 299\n",
      "Sampling duration: 18.688754558563232 seconds\n",
      "\n",
      "Fold 2 - New train size: 6584\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 6584 samples...\n",
      "Epoch 1/10, Train Loss: 0.3406, Accuracy: 0.8302, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.2487, Accuracy: 0.8808, F1 Micro: 0.5514, F1 Macro: 0.2768\n",
      "Epoch 3/10, Train Loss: 0.201, Accuracy: 0.8987, F1 Micro: 0.6825, F1 Macro: 0.4417\n",
      "Epoch 4/10, Train Loss: 0.1552, Accuracy: 0.9023, F1 Micro: 0.6946, F1 Macro: 0.4778\n",
      "Epoch 5/10, Train Loss: 0.1291, Accuracy: 0.9052, F1 Micro: 0.6823, F1 Macro: 0.4585\n",
      "Epoch 6/10, Train Loss: 0.1056, Accuracy: 0.9018, F1 Micro: 0.7166, F1 Macro: 0.5242\n",
      "Epoch 7/10, Train Loss: 0.0847, Accuracy: 0.9064, F1 Micro: 0.7234, F1 Macro: 0.5467\n",
      "Epoch 8/10, Train Loss: 0.0732, Accuracy: 0.9081, F1 Micro: 0.7136, F1 Macro: 0.5263\n",
      "Epoch 9/10, Train Loss: 0.0606, Accuracy: 0.9095, F1 Micro: 0.7255, F1 Macro: 0.563\n",
      "Epoch 10/10, Train Loss: 0.0531, Accuracy: 0.9105, F1 Micro: 0.7274, F1 Macro: 0.559\n",
      "Best result for 6584 samples: F1 Micro: 0.7274\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.83      0.83      1094\n",
      "      Abusive       0.89      0.88      0.88      1072\n",
      "HS_Individual       0.67      0.66      0.67       689\n",
      "     HS_Group       0.67      0.58      0.62       405\n",
      "  HS_Religion       0.74      0.45      0.56       124\n",
      "      HS_Race       0.81      0.50      0.61       125\n",
      "  HS_Physical       0.00      0.00      0.00        61\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.72      0.73      0.73       754\n",
      "      HS_Weak       0.66      0.65      0.65       664\n",
      "  HS_Moderate       0.57      0.48      0.52       346\n",
      "    HS_Strong       0.86      0.51      0.64        84\n",
      "\n",
      "    micro avg       0.75      0.70      0.73      5476\n",
      "    macro avg       0.62      0.52      0.56      5476\n",
      " weighted avg       0.73      0.70      0.72      5476\n",
      "  samples avg       0.45      0.42      0.41      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 0.04668104648590088\n",
      "Samples above threshold: 396\n",
      "Acquired samples: 396\n",
      "Sampling duration: 17.303385972976685 seconds\n",
      "\n",
      "Fold 2 - New train size: 6980\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 6980 samples...\n",
      "Epoch 1/10, Train Loss: 0.3586, Accuracy: 0.8304, F1 Micro: 0.0015, F1 Macro: 0.0006\n",
      "Epoch 2/10, Train Loss: 0.2504, Accuracy: 0.8802, F1 Micro: 0.5288, F1 Macro: 0.2941\n",
      "Epoch 3/10, Train Loss: 0.1904, Accuracy: 0.8995, F1 Micro: 0.7055, F1 Macro: 0.5243\n",
      "Epoch 4/10, Train Loss: 0.1594, Accuracy: 0.9081, F1 Micro: 0.6983, F1 Macro: 0.5366\n",
      "Epoch 5/10, Train Loss: 0.1262, Accuracy: 0.9071, F1 Micro: 0.7362, F1 Macro: 0.5818\n",
      "Epoch 6/10, Train Loss: 0.1092, Accuracy: 0.9136, F1 Micro: 0.7384, F1 Macro: 0.571\n",
      "Epoch 7/10, Train Loss: 0.0894, Accuracy: 0.914, F1 Micro: 0.731, F1 Macro: 0.5832\n",
      "Epoch 8/10, Train Loss: 0.0726, Accuracy: 0.9114, F1 Micro: 0.7334, F1 Macro: 0.5766\n",
      "Epoch 9/10, Train Loss: 0.0632, Accuracy: 0.9128, F1 Micro: 0.7442, F1 Macro: 0.5936\n",
      "Epoch 10/10, Train Loss: 0.0584, Accuracy: 0.9126, F1 Micro: 0.7365, F1 Macro: 0.577\n",
      "Best result for 6980 samples: F1 Micro: 0.7442\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.86      0.83      1094\n",
      "      Abusive       0.89      0.89      0.89      1072\n",
      "HS_Individual       0.64      0.76      0.69       689\n",
      "     HS_Group       0.69      0.54      0.61       405\n",
      "  HS_Religion       0.68      0.69      0.69       124\n",
      "      HS_Race       0.81      0.63      0.71       125\n",
      "  HS_Physical       0.00      0.00      0.00        61\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.71      0.77      0.74       754\n",
      "      HS_Weak       0.64      0.73      0.68       664\n",
      "  HS_Moderate       0.61      0.44      0.51       346\n",
      "    HS_Strong       0.80      0.75      0.77        84\n",
      "\n",
      "    micro avg       0.74      0.75      0.74      5476\n",
      "    macro avg       0.61      0.59      0.59      5476\n",
      " weighted avg       0.73      0.75      0.73      5476\n",
      "  samples avg       0.44      0.44      0.42      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 0.034412193298339847\n",
      "Samples above threshold: 356\n",
      "Acquired samples: 356\n",
      "Sampling duration: 15.987797498703003 seconds\n",
      "\n",
      "Fold 2 - New train size: 7336\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 7336 samples...\n",
      "Epoch 1/10, Train Loss: 0.3646, Accuracy: 0.8497, F1 Micro: 0.2332, F1 Macro: 0.0831\n",
      "Epoch 2/10, Train Loss: 0.2475, Accuracy: 0.8891, F1 Micro: 0.5882, F1 Macro: 0.3569\n",
      "Epoch 3/10, Train Loss: 0.1919, Accuracy: 0.9034, F1 Micro: 0.7181, F1 Macro: 0.5385\n",
      "Epoch 4/10, Train Loss: 0.1569, Accuracy: 0.9063, F1 Micro: 0.7301, F1 Macro: 0.5669\n",
      "Epoch 5/10, Train Loss: 0.1333, Accuracy: 0.9128, F1 Micro: 0.7236, F1 Macro: 0.5558\n",
      "Epoch 6/10, Train Loss: 0.1074, Accuracy: 0.9076, F1 Micro: 0.7401, F1 Macro: 0.5822\n",
      "Epoch 7/10, Train Loss: 0.0891, Accuracy: 0.9162, F1 Micro: 0.7379, F1 Macro: 0.5881\n",
      "Epoch 8/10, Train Loss: 0.075, Accuracy: 0.9134, F1 Micro: 0.7347, F1 Macro: 0.5888\n",
      "Epoch 9/10, Train Loss: 0.0659, Accuracy: 0.9156, F1 Micro: 0.7382, F1 Macro: 0.5938\n",
      "Epoch 10/10, Train Loss: 0.0567, Accuracy: 0.9155, F1 Micro: 0.744, F1 Macro: 0.5981\n",
      "Best result for 7336 samples: F1 Micro: 0.744\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.83      0.84      1094\n",
      "      Abusive       0.89      0.89      0.89      1072\n",
      "HS_Individual       0.73      0.63      0.67       689\n",
      "     HS_Group       0.62      0.67      0.64       405\n",
      "  HS_Religion       0.69      0.64      0.66       124\n",
      "      HS_Race       0.82      0.68      0.74       125\n",
      "  HS_Physical       0.00      0.00      0.00        61\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.74      0.73      0.73       754\n",
      "      HS_Weak       0.71      0.62      0.66       664\n",
      "  HS_Moderate       0.56      0.60      0.58       346\n",
      "    HS_Strong       0.80      0.71      0.75        84\n",
      "\n",
      "    micro avg       0.77      0.72      0.74      5476\n",
      "    macro avg       0.62      0.58      0.60      5476\n",
      " weighted avg       0.75      0.72      0.74      5476\n",
      "  samples avg       0.45      0.43      0.42      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 0.02586064338684082\n",
      "Samples above threshold: 320\n",
      "Acquired samples: 320\n",
      "Sampling duration: 14.073009014129639 seconds\n",
      "\n",
      "Fold 2 - New train size: 7656\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 7656 samples...\n",
      "Epoch 1/10, Train Loss: 0.3657, Accuracy: 0.8617, F1 Micro: 0.4025, F1 Macro: 0.1615\n",
      "Epoch 2/10, Train Loss: 0.2493, Accuracy: 0.897, F1 Micro: 0.6595, F1 Macro: 0.4463\n",
      "Epoch 3/10, Train Loss: 0.1977, Accuracy: 0.9073, F1 Micro: 0.6957, F1 Macro: 0.5447\n",
      "Epoch 4/10, Train Loss: 0.1624, Accuracy: 0.9093, F1 Micro: 0.7403, F1 Macro: 0.5819\n",
      "Epoch 5/10, Train Loss: 0.1315, Accuracy: 0.9128, F1 Micro: 0.7441, F1 Macro: 0.586\n",
      "Epoch 6/10, Train Loss: 0.1066, Accuracy: 0.9135, F1 Micro: 0.725, F1 Macro: 0.5709\n",
      "Epoch 7/10, Train Loss: 0.0898, Accuracy: 0.9147, F1 Micro: 0.7491, F1 Macro: 0.6035\n",
      "Epoch 8/10, Train Loss: 0.078, Accuracy: 0.9167, F1 Micro: 0.7485, F1 Macro: 0.5952\n",
      "Epoch 9/10, Train Loss: 0.0685, Accuracy: 0.9141, F1 Micro: 0.7499, F1 Macro: 0.6023\n",
      "Epoch 10/10, Train Loss: 0.0574, Accuracy: 0.9154, F1 Micro: 0.7499, F1 Macro: 0.6034\n",
      "Best result for 7656 samples: F1 Micro: 0.7499\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.81      0.86      0.84      1094\n",
      "      Abusive       0.89      0.90      0.90      1072\n",
      "HS_Individual       0.66      0.73      0.69       689\n",
      "     HS_Group       0.67      0.59      0.63       405\n",
      "  HS_Religion       0.71      0.60      0.65       124\n",
      "      HS_Race       0.85      0.73      0.78       125\n",
      "  HS_Physical       0.00      0.00      0.00        61\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.73      0.75      0.74       754\n",
      "      HS_Weak       0.66      0.71      0.68       664\n",
      "  HS_Moderate       0.59      0.48      0.53       346\n",
      "    HS_Strong       0.78      0.81      0.80        84\n",
      "\n",
      "    micro avg       0.75      0.75      0.75      5476\n",
      "    macro avg       0.61      0.60      0.60      5476\n",
      " weighted avg       0.74      0.75      0.74      5476\n",
      "  samples avg       0.44      0.44      0.42      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 0.02178192138671876\n",
      "Samples above threshold: 288\n",
      "Acquired samples: 245\n",
      "Sampling duration: 13.00564694404602 seconds\n",
      "\n",
      "Fold 2 - New train size: 7901\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 7901 samples...\n",
      "Epoch 1/10, Train Loss: 0.37, Accuracy: 0.8673, F1 Micro: 0.4354, F1 Macro: 0.1988\n",
      "Epoch 2/10, Train Loss: 0.2459, Accuracy: 0.8982, F1 Micro: 0.6649, F1 Macro: 0.4048\n",
      "Epoch 3/10, Train Loss: 0.1921, Accuracy: 0.9083, F1 Micro: 0.713, F1 Macro: 0.5435\n",
      "Epoch 4/10, Train Loss: 0.1585, Accuracy: 0.9102, F1 Micro: 0.7178, F1 Macro: 0.5323\n",
      "Epoch 5/10, Train Loss: 0.1324, Accuracy: 0.9132, F1 Micro: 0.723, F1 Macro: 0.5631\n",
      "Epoch 6/10, Train Loss: 0.1072, Accuracy: 0.911, F1 Micro: 0.7455, F1 Macro: 0.5827\n",
      "Epoch 7/10, Train Loss: 0.0915, Accuracy: 0.916, F1 Micro: 0.7433, F1 Macro: 0.5931\n",
      "Epoch 8/10, Train Loss: 0.0779, Accuracy: 0.9166, F1 Micro: 0.7523, F1 Macro: 0.6054\n",
      "Epoch 9/10, Train Loss: 0.0642, Accuracy: 0.9154, F1 Micro: 0.752, F1 Macro: 0.6007\n",
      "Epoch 10/10, Train Loss: 0.0585, Accuracy: 0.917, F1 Micro: 0.7498, F1 Macro: 0.601\n",
      "Best result for 7901 samples: F1 Micro: 0.7523\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.86      0.84      1094\n",
      "      Abusive       0.90      0.89      0.90      1072\n",
      "HS_Individual       0.69      0.71      0.70       689\n",
      "     HS_Group       0.65      0.63      0.64       405\n",
      "  HS_Religion       0.70      0.67      0.68       124\n",
      "      HS_Race       0.81      0.70      0.75       125\n",
      "  HS_Physical       0.00      0.00      0.00        61\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.72      0.77      0.75       754\n",
      "      HS_Weak       0.68      0.67      0.68       664\n",
      "  HS_Moderate       0.59      0.52      0.55       346\n",
      "    HS_Strong       0.78      0.77      0.78        84\n",
      "\n",
      "    micro avg       0.76      0.75      0.75      5476\n",
      "    macro avg       0.61      0.60      0.61      5476\n",
      " weighted avg       0.74      0.75      0.74      5476\n",
      "  samples avg       0.44      0.43      0.42      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.027188235521316547\n",
      "Samples above threshold: 264\n",
      "Acquired samples: 264\n",
      "Sampling duration: 11.958920001983643 seconds\n",
      "\n",
      "Fold 2 - New train size: 8165\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 8165 samples...\n",
      "Epoch 1/10, Train Loss: 0.3705, Accuracy: 0.874, F1 Micro: 0.529, F1 Macro: 0.2466\n",
      "Epoch 2/10, Train Loss: 0.2485, Accuracy: 0.8961, F1 Micro: 0.6208, F1 Macro: 0.4137\n",
      "Epoch 3/10, Train Loss: 0.1947, Accuracy: 0.9089, F1 Micro: 0.7258, F1 Macro: 0.5491\n",
      "Epoch 4/10, Train Loss: 0.1611, Accuracy: 0.9157, F1 Micro: 0.7428, F1 Macro: 0.5801\n",
      "Epoch 5/10, Train Loss: 0.1303, Accuracy: 0.917, F1 Micro: 0.7495, F1 Macro: 0.6032\n",
      "Epoch 6/10, Train Loss: 0.109, Accuracy: 0.9127, F1 Micro: 0.7398, F1 Macro: 0.5727\n",
      "Epoch 7/10, Train Loss: 0.0932, Accuracy: 0.9163, F1 Micro: 0.7486, F1 Macro: 0.6092\n",
      "Epoch 8/10, Train Loss: 0.0768, Accuracy: 0.9186, F1 Micro: 0.7554, F1 Macro: 0.6171\n",
      "Epoch 9/10, Train Loss: 0.068, Accuracy: 0.9181, F1 Micro: 0.7403, F1 Macro: 0.6043\n",
      "Epoch 10/10, Train Loss: 0.0583, Accuracy: 0.9189, F1 Micro: 0.7517, F1 Macro: 0.6255\n",
      "Best result for 8165 samples: F1 Micro: 0.7554\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.84      0.83      1094\n",
      "      Abusive       0.90      0.89      0.90      1072\n",
      "HS_Individual       0.69      0.73      0.71       689\n",
      "     HS_Group       0.71      0.59      0.65       405\n",
      "  HS_Religion       0.67      0.70      0.69       124\n",
      "      HS_Race       0.80      0.72      0.76       125\n",
      "  HS_Physical       0.60      0.05      0.09        61\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.77      0.72      0.74       754\n",
      "      HS_Weak       0.68      0.72      0.70       664\n",
      "  HS_Moderate       0.62      0.49      0.55       346\n",
      "    HS_Strong       0.80      0.80      0.80        84\n",
      "\n",
      "    micro avg       0.77      0.74      0.76      5476\n",
      "    macro avg       0.67      0.60      0.62      5476\n",
      " weighted avg       0.76      0.74      0.75      5476\n",
      "  samples avg       0.45      0.43      0.42      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.022265094518661495\n",
      "Samples above threshold: 237\n",
      "Acquired samples: 237\n",
      "Sampling duration: 10.79295015335083 seconds\n",
      "\n",
      "Fold 2 - New train size: 8402\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 8402 samples...\n",
      "Epoch 1/10, Train Loss: 0.3698, Accuracy: 0.8797, F1 Micro: 0.6038, F1 Macro: 0.3024\n",
      "Epoch 2/10, Train Loss: 0.2465, Accuracy: 0.9007, F1 Micro: 0.6662, F1 Macro: 0.4784\n",
      "Epoch 3/10, Train Loss: 0.1912, Accuracy: 0.9092, F1 Micro: 0.7296, F1 Macro: 0.5603\n",
      "Epoch 4/10, Train Loss: 0.1618, Accuracy: 0.9141, F1 Micro: 0.7454, F1 Macro: 0.5957\n",
      "Epoch 5/10, Train Loss: 0.1361, Accuracy: 0.9162, F1 Micro: 0.7488, F1 Macro: 0.6025\n",
      "Epoch 6/10, Train Loss: 0.1099, Accuracy: 0.9143, F1 Micro: 0.7518, F1 Macro: 0.6074\n",
      "Epoch 7/10, Train Loss: 0.0936, Accuracy: 0.9169, F1 Micro: 0.7455, F1 Macro: 0.611\n",
      "Epoch 8/10, Train Loss: 0.0737, Accuracy: 0.9183, F1 Micro: 0.7544, F1 Macro: 0.6212\n",
      "Epoch 9/10, Train Loss: 0.0671, Accuracy: 0.9185, F1 Micro: 0.7551, F1 Macro: 0.6228\n",
      "Epoch 10/10, Train Loss: 0.0594, Accuracy: 0.9187, F1 Micro: 0.755, F1 Macro: 0.6302\n",
      "Best result for 8402 samples: F1 Micro: 0.7551\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.84      0.83      1094\n",
      "      Abusive       0.91      0.89      0.90      1072\n",
      "HS_Individual       0.69      0.71      0.70       689\n",
      "     HS_Group       0.68      0.61      0.65       405\n",
      "  HS_Religion       0.68      0.65      0.66       124\n",
      "      HS_Race       0.84      0.69      0.76       125\n",
      "  HS_Physical       0.78      0.11      0.20        61\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.76      0.75      0.75       754\n",
      "      HS_Weak       0.68      0.70      0.69       664\n",
      "  HS_Moderate       0.59      0.54      0.56       346\n",
      "    HS_Strong       0.80      0.73      0.76        84\n",
      "\n",
      "    micro avg       0.77      0.74      0.76      5476\n",
      "    macro avg       0.69      0.60      0.62      5476\n",
      " weighted avg       0.76      0.74      0.75      5476\n",
      "  samples avg       0.44      0.43      0.42      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.01743553876876831\n",
      "Samples above threshold: 214\n",
      "Acquired samples: 214\n",
      "Sampling duration: 9.914402723312378 seconds\n",
      "\n",
      "Fold 2 - New train size: 8616\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 8616 samples...\n",
      "Epoch 1/10, Train Loss: 0.3763, Accuracy: 0.8782, F1 Micro: 0.5266, F1 Macro: 0.2556\n",
      "Epoch 2/10, Train Loss: 0.2507, Accuracy: 0.9059, F1 Micro: 0.6971, F1 Macro: 0.4882\n",
      "Epoch 3/10, Train Loss: 0.1951, Accuracy: 0.9116, F1 Micro: 0.7096, F1 Macro: 0.5274\n",
      "Epoch 4/10, Train Loss: 0.1577, Accuracy: 0.9157, F1 Micro: 0.7345, F1 Macro: 0.5726\n",
      "Epoch 5/10, Train Loss: 0.1276, Accuracy: 0.9165, F1 Micro: 0.7509, F1 Macro: 0.5996\n",
      "Epoch 6/10, Train Loss: 0.1122, Accuracy: 0.9162, F1 Micro: 0.7353, F1 Macro: 0.589\n",
      "Epoch 7/10, Train Loss: 0.0889, Accuracy: 0.9172, F1 Micro: 0.7507, F1 Macro: 0.6054\n",
      "Epoch 8/10, Train Loss: 0.0775, Accuracy: 0.918, F1 Micro: 0.7592, F1 Macro: 0.6081\n",
      "Epoch 9/10, Train Loss: 0.0651, Accuracy: 0.9192, F1 Micro: 0.7609, F1 Macro: 0.6322\n",
      "Epoch 10/10, Train Loss: 0.0587, Accuracy: 0.9184, F1 Micro: 0.7548, F1 Macro: 0.6242\n",
      "Best result for 8616 samples: F1 Micro: 0.7609\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.86      0.84      1094\n",
      "      Abusive       0.91      0.90      0.90      1072\n",
      "HS_Individual       0.68      0.73      0.71       689\n",
      "     HS_Group       0.68      0.62      0.65       405\n",
      "  HS_Religion       0.68      0.69      0.68       124\n",
      "      HS_Race       0.82      0.71      0.76       125\n",
      "  HS_Physical       0.80      0.13      0.23        61\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.76      0.76      0.76       754\n",
      "      HS_Weak       0.67      0.70      0.69       664\n",
      "  HS_Moderate       0.61      0.53      0.57       346\n",
      "    HS_Strong       0.77      0.83      0.80        84\n",
      "\n",
      "    micro avg       0.76      0.76      0.76      5476\n",
      "    macro avg       0.68      0.62      0.63      5476\n",
      " weighted avg       0.76      0.76      0.75      5476\n",
      "  samples avg       0.44      0.44      0.42      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.01782301664352417\n",
      "Samples above threshold: 192\n",
      "Acquired samples: 200\n",
      "Sampling duration: 9.03704285621643 seconds\n",
      "\n",
      "Fold 2 - New train size: 8816\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 8816 samples...\n",
      "Epoch 1/10, Train Loss: 0.3701, Accuracy: 0.8813, F1 Micro: 0.5815, F1 Macro: 0.3046\n",
      "Epoch 2/10, Train Loss: 0.2484, Accuracy: 0.902, F1 Micro: 0.707, F1 Macro: 0.5122\n",
      "Epoch 3/10, Train Loss: 0.196, Accuracy: 0.9114, F1 Micro: 0.7307, F1 Macro: 0.5633\n",
      "Epoch 4/10, Train Loss: 0.1678, Accuracy: 0.9157, F1 Micro: 0.7466, F1 Macro: 0.595\n",
      "Epoch 5/10, Train Loss: 0.1383, Accuracy: 0.9179, F1 Micro: 0.7513, F1 Macro: 0.5911\n",
      "Epoch 6/10, Train Loss: 0.1082, Accuracy: 0.92, F1 Micro: 0.7598, F1 Macro: 0.6101\n",
      "Epoch 7/10, Train Loss: 0.0964, Accuracy: 0.9164, F1 Micro: 0.7416, F1 Macro: 0.599\n",
      "Epoch 8/10, Train Loss: 0.0781, Accuracy: 0.921, F1 Micro: 0.7635, F1 Macro: 0.6227\n",
      "Epoch 9/10, Train Loss: 0.0681, Accuracy: 0.921, F1 Micro: 0.7609, F1 Macro: 0.619\n",
      "Epoch 10/10, Train Loss: 0.0607, Accuracy: 0.919, F1 Micro: 0.756, F1 Macro: 0.617\n",
      "Best result for 8816 samples: F1 Micro: 0.7635\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.84      0.84      1094\n",
      "      Abusive       0.90      0.90      0.90      1072\n",
      "HS_Individual       0.69      0.76      0.73       689\n",
      "     HS_Group       0.72      0.58      0.64       405\n",
      "  HS_Religion       0.67      0.67      0.67       124\n",
      "      HS_Race       0.78      0.71      0.74       125\n",
      "  HS_Physical       0.56      0.08      0.14        61\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.78      0.75      0.76       754\n",
      "      HS_Weak       0.69      0.74      0.71       664\n",
      "  HS_Moderate       0.63      0.51      0.56       346\n",
      "    HS_Strong       0.85      0.71      0.77        84\n",
      "\n",
      "    micro avg       0.78      0.75      0.76      5476\n",
      "    macro avg       0.67      0.60      0.62      5476\n",
      " weighted avg       0.77      0.75      0.75      5476\n",
      "  samples avg       0.44      0.43      0.42      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.018588125705718994\n",
      "Samples above threshold: 173\n",
      "Acquired samples: 200\n",
      "Sampling duration: 8.237798690795898 seconds\n",
      "\n",
      "Fold 2 - New train size: 9016\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 9016 samples...\n",
      "Epoch 1/10, Train Loss: 0.3709, Accuracy: 0.8803, F1 Micro: 0.5468, F1 Macro: 0.2727\n",
      "Epoch 2/10, Train Loss: 0.2423, Accuracy: 0.9039, F1 Micro: 0.6826, F1 Macro: 0.4629\n",
      "Epoch 3/10, Train Loss: 0.1902, Accuracy: 0.9116, F1 Micro: 0.7123, F1 Macro: 0.5378\n",
      "Epoch 4/10, Train Loss: 0.1596, Accuracy: 0.916, F1 Micro: 0.7368, F1 Macro: 0.5851\n",
      "Epoch 5/10, Train Loss: 0.1362, Accuracy: 0.9186, F1 Micro: 0.7523, F1 Macro: 0.603\n",
      "Epoch 6/10, Train Loss: 0.1131, Accuracy: 0.9166, F1 Micro: 0.7604, F1 Macro: 0.6138\n",
      "Epoch 7/10, Train Loss: 0.0966, Accuracy: 0.9181, F1 Micro: 0.765, F1 Macro: 0.6247\n",
      "Epoch 8/10, Train Loss: 0.0798, Accuracy: 0.9207, F1 Micro: 0.7653, F1 Macro: 0.6335\n",
      "Epoch 9/10, Train Loss: 0.0673, Accuracy: 0.9195, F1 Micro: 0.7635, F1 Macro: 0.6317\n",
      "Epoch 10/10, Train Loss: 0.059, Accuracy: 0.9177, F1 Micro: 0.7541, F1 Macro: 0.6142\n",
      "Best result for 9016 samples: F1 Micro: 0.7653\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.85      0.83      1094\n",
      "      Abusive       0.91      0.90      0.90      1072\n",
      "HS_Individual       0.68      0.77      0.72       689\n",
      "     HS_Group       0.72      0.62      0.67       405\n",
      "  HS_Religion       0.74      0.64      0.68       124\n",
      "      HS_Race       0.80      0.79      0.80       125\n",
      "  HS_Physical       1.00      0.08      0.15        61\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.74      0.77      0.75       754\n",
      "      HS_Weak       0.67      0.74      0.71       664\n",
      "  HS_Moderate       0.66      0.53      0.59       346\n",
      "    HS_Strong       0.79      0.81      0.80        84\n",
      "\n",
      "    micro avg       0.77      0.76      0.77      5476\n",
      "    macro avg       0.71      0.62      0.63      5476\n",
      " weighted avg       0.76      0.76      0.76      5476\n",
      "  samples avg       0.44      0.44      0.42      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.014099800586700439\n",
      "Samples above threshold: 152\n",
      "Acquired samples: 200\n",
      "Sampling duration: 8.242587566375732 seconds\n",
      "\n",
      "Fold 2 - New train size: 9216\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 9216 samples...\n",
      "Epoch 1/10, Train Loss: 0.3771, Accuracy: 0.8853, F1 Micro: 0.6133, F1 Macro: 0.3123\n",
      "Epoch 2/10, Train Loss: 0.2479, Accuracy: 0.9068, F1 Micro: 0.6997, F1 Macro: 0.477\n",
      "Epoch 3/10, Train Loss: 0.1995, Accuracy: 0.9094, F1 Micro: 0.7406, F1 Macro: 0.5924\n",
      "Epoch 4/10, Train Loss: 0.1648, Accuracy: 0.9184, F1 Micro: 0.7361, F1 Macro: 0.5801\n",
      "Epoch 5/10, Train Loss: 0.1347, Accuracy: 0.9174, F1 Micro: 0.7411, F1 Macro: 0.5879\n",
      "Epoch 6/10, Train Loss: 0.1115, Accuracy: 0.9195, F1 Micro: 0.7567, F1 Macro: 0.6121\n",
      "Epoch 7/10, Train Loss: 0.0928, Accuracy: 0.9204, F1 Micro: 0.7532, F1 Macro: 0.6154\n",
      "Epoch 8/10, Train Loss: 0.0786, Accuracy: 0.9198, F1 Micro: 0.7649, F1 Macro: 0.637\n",
      "Epoch 9/10, Train Loss: 0.0695, Accuracy: 0.92, F1 Micro: 0.7574, F1 Macro: 0.6271\n",
      "Epoch 10/10, Train Loss: 0.0592, Accuracy: 0.9195, F1 Micro: 0.7571, F1 Macro: 0.6368\n",
      "Best result for 9216 samples: F1 Micro: 0.7649\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.81      0.86      0.83      1094\n",
      "      Abusive       0.90      0.89      0.90      1072\n",
      "HS_Individual       0.70      0.74      0.72       689\n",
      "     HS_Group       0.68      0.66      0.67       405\n",
      "  HS_Religion       0.68      0.73      0.70       124\n",
      "      HS_Race       0.81      0.74      0.77       125\n",
      "  HS_Physical       0.56      0.15      0.23        61\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.75      0.79      0.77       754\n",
      "      HS_Weak       0.68      0.73      0.71       664\n",
      "  HS_Moderate       0.59      0.59      0.59       346\n",
      "    HS_Strong       0.79      0.71      0.75        84\n",
      "\n",
      "    micro avg       0.76      0.77      0.76      5476\n",
      "    macro avg       0.66      0.63      0.64      5476\n",
      " weighted avg       0.75      0.77      0.76      5476\n",
      "  samples avg       0.45      0.44      0.43      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.01375182867050171\n",
      "Samples above threshold: 132\n",
      "Acquired samples: 2\n",
      "Sampling duration: 6.894475698471069 seconds\n",
      "\n",
      "Fold 2 - New train size: 9218\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 9218 samples...\n",
      "Epoch 1/10, Train Loss: 0.3711, Accuracy: 0.885, F1 Micro: 0.6243, F1 Macro: 0.3162\n",
      "Epoch 2/10, Train Loss: 0.2476, Accuracy: 0.9071, F1 Micro: 0.7057, F1 Macro: 0.5274\n",
      "Epoch 3/10, Train Loss: 0.1959, Accuracy: 0.9131, F1 Micro: 0.7128, F1 Macro: 0.5512\n",
      "Epoch 4/10, Train Loss: 0.1584, Accuracy: 0.9181, F1 Micro: 0.7575, F1 Macro: 0.5937\n",
      "Epoch 5/10, Train Loss: 0.1344, Accuracy: 0.9167, F1 Micro: 0.7547, F1 Macro: 0.6086\n",
      "Epoch 6/10, Train Loss: 0.1064, Accuracy: 0.9187, F1 Micro: 0.7533, F1 Macro: 0.6076\n",
      "Epoch 7/10, Train Loss: 0.0952, Accuracy: 0.9185, F1 Micro: 0.748, F1 Macro: 0.6139\n",
      "Epoch 8/10, Train Loss: 0.0768, Accuracy: 0.9207, F1 Micro: 0.7612, F1 Macro: 0.6398\n",
      "Epoch 9/10, Train Loss: 0.0693, Accuracy: 0.9189, F1 Micro: 0.7479, F1 Macro: 0.6243\n",
      "Epoch 10/10, Train Loss: 0.0571, Accuracy: 0.9199, F1 Micro: 0.7601, F1 Macro: 0.6419\n",
      "Best result for 9218 samples: F1 Micro: 0.7612\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.84      0.84      1094\n",
      "      Abusive       0.89      0.91      0.90      1072\n",
      "HS_Individual       0.72      0.69      0.70       689\n",
      "     HS_Group       0.69      0.65      0.67       405\n",
      "  HS_Religion       0.68      0.74      0.71       124\n",
      "      HS_Race       0.80      0.84      0.82       125\n",
      "  HS_Physical       0.50      0.15      0.23        61\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.78      0.71      0.74       754\n",
      "      HS_Weak       0.71      0.66      0.68       664\n",
      "  HS_Moderate       0.62      0.58      0.60       346\n",
      "    HS_Strong       0.81      0.76      0.79        84\n",
      "\n",
      "    micro avg       0.78      0.74      0.76      5476\n",
      "    macro avg       0.67      0.63      0.64      5476\n",
      " weighted avg       0.77      0.74      0.75      5476\n",
      "  samples avg       0.45      0.43      0.42      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 0.015321755409240722\n",
      "Samples above threshold: 132\n",
      "Acquired samples: 200\n",
      "Sampling duration: 6.570993661880493 seconds\n",
      "\n",
      "Fold 2 - New train size: 9418\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 9418 samples...\n",
      "Epoch 1/10, Train Loss: 0.3754, Accuracy: 0.8872, F1 Micro: 0.6308, F1 Macro: 0.339\n",
      "Epoch 2/10, Train Loss: 0.2431, Accuracy: 0.9052, F1 Micro: 0.6958, F1 Macro: 0.4715\n",
      "Epoch 3/10, Train Loss: 0.1985, Accuracy: 0.9139, F1 Micro: 0.7337, F1 Macro: 0.5817\n",
      "Epoch 4/10, Train Loss: 0.1646, Accuracy: 0.9178, F1 Micro: 0.7381, F1 Macro: 0.5801\n",
      "Epoch 5/10, Train Loss: 0.1339, Accuracy: 0.9177, F1 Micro: 0.7593, F1 Macro: 0.6062\n",
      "Epoch 6/10, Train Loss: 0.1098, Accuracy: 0.9207, F1 Micro: 0.759, F1 Macro: 0.6058\n",
      "Epoch 7/10, Train Loss: 0.0929, Accuracy: 0.9195, F1 Micro: 0.7609, F1 Macro: 0.6278\n",
      "Epoch 8/10, Train Loss: 0.084, Accuracy: 0.9177, F1 Micro: 0.7418, F1 Macro: 0.6251\n",
      "Epoch 9/10, Train Loss: 0.0687, Accuracy: 0.9201, F1 Micro: 0.7585, F1 Macro: 0.6402\n",
      "Epoch 10/10, Train Loss: 0.0613, Accuracy: 0.919, F1 Micro: 0.7528, F1 Macro: 0.6236\n",
      "Best result for 9418 samples: F1 Micro: 0.7609\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.81      0.84      0.83      1094\n",
      "      Abusive       0.89      0.91      0.90      1072\n",
      "HS_Individual       0.66      0.77      0.71       689\n",
      "     HS_Group       0.78      0.57      0.66       405\n",
      "  HS_Religion       0.72      0.68      0.70       124\n",
      "      HS_Race       0.84      0.71      0.77       125\n",
      "  HS_Physical       0.86      0.10      0.18        61\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.74      0.77      0.76       754\n",
      "      HS_Weak       0.67      0.75      0.71       664\n",
      "  HS_Moderate       0.69      0.46      0.55       346\n",
      "    HS_Strong       0.76      0.80      0.78        84\n",
      "\n",
      "    micro avg       0.77      0.76      0.76      5476\n",
      "    macro avg       0.70      0.61      0.63      5476\n",
      " weighted avg       0.76      0.76      0.75      5476\n",
      "  samples avg       0.45      0.44      0.42      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 0.013506507873535155\n",
      "Samples above threshold: 112\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.792763710021973 seconds\n",
      "\n",
      "Fold 2 - New train size: 9618\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 9618 samples...\n",
      "Epoch 1/10, Train Loss: 0.3758, Accuracy: 0.8834, F1 Micro: 0.5683, F1 Macro: 0.2929\n",
      "Epoch 2/10, Train Loss: 0.2478, Accuracy: 0.9068, F1 Micro: 0.7056, F1 Macro: 0.4997\n",
      "Epoch 3/10, Train Loss: 0.1963, Accuracy: 0.9152, F1 Micro: 0.7432, F1 Macro: 0.5853\n",
      "Epoch 4/10, Train Loss: 0.1696, Accuracy: 0.9195, F1 Micro: 0.761, F1 Macro: 0.6097\n",
      "Epoch 5/10, Train Loss: 0.1409, Accuracy: 0.9201, F1 Micro: 0.751, F1 Macro: 0.6093\n",
      "Epoch 6/10, Train Loss: 0.1115, Accuracy: 0.9177, F1 Micro: 0.7591, F1 Macro: 0.6143\n",
      "Epoch 7/10, Train Loss: 0.0978, Accuracy: 0.9191, F1 Micro: 0.7611, F1 Macro: 0.6334\n",
      "Epoch 8/10, Train Loss: 0.0794, Accuracy: 0.9223, F1 Micro: 0.7686, F1 Macro: 0.6425\n",
      "Epoch 9/10, Train Loss: 0.0674, Accuracy: 0.9185, F1 Micro: 0.7545, F1 Macro: 0.6367\n",
      "Epoch 10/10, Train Loss: 0.0575, Accuracy: 0.921, F1 Micro: 0.7642, F1 Macro: 0.6453\n",
      "Best result for 9618 samples: F1 Micro: 0.7686\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.86      0.84      1094\n",
      "      Abusive       0.90      0.90      0.90      1072\n",
      "HS_Individual       0.71      0.73      0.72       689\n",
      "     HS_Group       0.70      0.62      0.66       405\n",
      "  HS_Religion       0.76      0.63      0.69       124\n",
      "      HS_Race       0.81      0.73      0.77       125\n",
      "  HS_Physical       0.75      0.15      0.25        61\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.74      0.79      0.76       754\n",
      "      HS_Weak       0.70      0.71      0.70       664\n",
      "  HS_Moderate       0.65      0.55      0.59       346\n",
      "    HS_Strong       0.79      0.86      0.82        84\n",
      "\n",
      "    micro avg       0.78      0.76      0.77      5476\n",
      "    macro avg       0.70      0.63      0.64      5476\n",
      " weighted avg       0.77      0.76      0.76      5476\n",
      "  samples avg       0.44      0.44      0.42      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 0.00923932790756225\n",
      "Samples above threshold: 92\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.801522493362427 seconds\n",
      "\n",
      "Fold 2 - New train size: 9818\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 9818 samples...\n",
      "Epoch 1/10, Train Loss: 0.3727, Accuracy: 0.8874, F1 Micro: 0.6493, F1 Macro: 0.3586\n",
      "Epoch 2/10, Train Loss: 0.2466, Accuracy: 0.9029, F1 Micro: 0.6599, F1 Macro: 0.4732\n",
      "Epoch 3/10, Train Loss: 0.1989, Accuracy: 0.9156, F1 Micro: 0.7355, F1 Macro: 0.5682\n",
      "Epoch 4/10, Train Loss: 0.1594, Accuracy: 0.9191, F1 Micro: 0.7392, F1 Macro: 0.5932\n",
      "Epoch 5/10, Train Loss: 0.1361, Accuracy: 0.9217, F1 Micro: 0.7602, F1 Macro: 0.6222\n",
      "Epoch 6/10, Train Loss: 0.1112, Accuracy: 0.9213, F1 Micro: 0.7646, F1 Macro: 0.6266\n",
      "Epoch 7/10, Train Loss: 0.0963, Accuracy: 0.9216, F1 Micro: 0.7622, F1 Macro: 0.634\n",
      "Epoch 8/10, Train Loss: 0.0778, Accuracy: 0.9208, F1 Micro: 0.771, F1 Macro: 0.6518\n",
      "Epoch 9/10, Train Loss: 0.0689, Accuracy: 0.9198, F1 Micro: 0.7704, F1 Macro: 0.6432\n",
      "Epoch 10/10, Train Loss: 0.0602, Accuracy: 0.9212, F1 Micro: 0.7657, F1 Macro: 0.6579\n",
      "Best result for 9818 samples: F1 Micro: 0.771\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.88      0.84      1094\n",
      "      Abusive       0.90      0.90      0.90      1072\n",
      "HS_Individual       0.67      0.79      0.73       689\n",
      "     HS_Group       0.71      0.63      0.67       405\n",
      "  HS_Religion       0.69      0.72      0.70       124\n",
      "      HS_Race       0.79      0.76      0.78       125\n",
      "  HS_Physical       0.50      0.16      0.25        61\n",
      "    HS_Gender       0.67      0.03      0.07        58\n",
      "     HS_Other       0.75      0.79      0.77       754\n",
      "      HS_Weak       0.67      0.77      0.71       664\n",
      "  HS_Moderate       0.64      0.56      0.60       346\n",
      "    HS_Strong       0.79      0.85      0.82        84\n",
      "\n",
      "    micro avg       0.76      0.79      0.77      5476\n",
      "    macro avg       0.71      0.65      0.65      5476\n",
      " weighted avg       0.76      0.79      0.76      5476\n",
      "  samples avg       0.45      0.45      0.43      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 0.008163273334503172\n",
      "Samples above threshold: 72\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.090653419494629 seconds\n",
      "\n",
      "Fold 2 - New train size: 10018\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 10018 samples...\n",
      "Epoch 1/10, Train Loss: 0.3738, Accuracy: 0.8836, F1 Micro: 0.5637, F1 Macro: 0.295\n",
      "Epoch 2/10, Train Loss: 0.2492, Accuracy: 0.9079, F1 Micro: 0.6964, F1 Macro: 0.5069\n",
      "Epoch 3/10, Train Loss: 0.1943, Accuracy: 0.9178, F1 Micro: 0.7542, F1 Macro: 0.601\n",
      "Epoch 4/10, Train Loss: 0.1657, Accuracy: 0.9201, F1 Micro: 0.7553, F1 Macro: 0.6022\n",
      "Epoch 5/10, Train Loss: 0.1367, Accuracy: 0.9213, F1 Micro: 0.7592, F1 Macro: 0.6161\n",
      "Epoch 6/10, Train Loss: 0.1128, Accuracy: 0.9219, F1 Micro: 0.7716, F1 Macro: 0.6421\n",
      "Epoch 7/10, Train Loss: 0.0972, Accuracy: 0.9221, F1 Micro: 0.7633, F1 Macro: 0.6298\n",
      "Epoch 8/10, Train Loss: 0.0802, Accuracy: 0.9192, F1 Micro: 0.769, F1 Macro: 0.6382\n",
      "Epoch 9/10, Train Loss: 0.0693, Accuracy: 0.9209, F1 Micro: 0.767, F1 Macro: 0.6556\n",
      "Epoch 10/10, Train Loss: 0.06, Accuracy: 0.9241, F1 Micro: 0.7669, F1 Macro: 0.674\n",
      "Best result for 10018 samples: F1 Micro: 0.7716\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.86      0.84      1094\n",
      "      Abusive       0.88      0.92      0.90      1072\n",
      "HS_Individual       0.72      0.72      0.72       689\n",
      "     HS_Group       0.68      0.70      0.69       405\n",
      "  HS_Religion       0.66      0.75      0.70       124\n",
      "      HS_Race       0.72      0.84      0.78       125\n",
      "  HS_Physical       0.75      0.10      0.17        61\n",
      "    HS_Gender       0.00      0.00      0.00        58\n",
      "     HS_Other       0.76      0.78      0.77       754\n",
      "      HS_Weak       0.70      0.70      0.70       664\n",
      "  HS_Moderate       0.60      0.63      0.62       346\n",
      "    HS_Strong       0.79      0.82      0.81        84\n",
      "\n",
      "    micro avg       0.77      0.78      0.77      5476\n",
      "    macro avg       0.68      0.65      0.64      5476\n",
      " weighted avg       0.76      0.78      0.76      5476\n",
      "  samples avg       0.45      0.45      0.43      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 0.007902562618255615\n",
      "Samples above threshold: 52\n",
      "Acquired samples: 200\n",
      "Sampling duration: 3.1409778594970703 seconds\n",
      "\n",
      "Fold 2 - New train size: 10218\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 10218 samples...\n",
      "Epoch 1/10, Train Loss: 0.3752, Accuracy: 0.886, F1 Micro: 0.5855, F1 Macro: 0.2977\n",
      "Epoch 2/10, Train Loss: 0.2488, Accuracy: 0.908, F1 Micro: 0.7028, F1 Macro: 0.4942\n",
      "Epoch 3/10, Train Loss: 0.2039, Accuracy: 0.9166, F1 Micro: 0.7448, F1 Macro: 0.5527\n",
      "Epoch 4/10, Train Loss: 0.1711, Accuracy: 0.921, F1 Micro: 0.7631, F1 Macro: 0.6084\n",
      "Epoch 5/10, Train Loss: 0.1416, Accuracy: 0.9231, F1 Micro: 0.7705, F1 Macro: 0.6324\n",
      "Epoch 6/10, Train Loss: 0.1165, Accuracy: 0.9228, F1 Micro: 0.7724, F1 Macro: 0.6561\n",
      "Epoch 7/10, Train Loss: 0.0969, Accuracy: 0.923, F1 Micro: 0.7689, F1 Macro: 0.6592\n",
      "Epoch 8/10, Train Loss: 0.0806, Accuracy: 0.9221, F1 Micro: 0.7655, F1 Macro: 0.6534\n",
      "Epoch 9/10, Train Loss: 0.0674, Accuracy: 0.9215, F1 Micro: 0.7551, F1 Macro: 0.6695\n",
      "Epoch 10/10, Train Loss: 0.0617, Accuracy: 0.9222, F1 Micro: 0.7695, F1 Macro: 0.6904\n",
      "Best result for 10218 samples: F1 Micro: 0.7724\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.81      0.88      0.84      1094\n",
      "      Abusive       0.90      0.89      0.90      1072\n",
      "HS_Individual       0.68      0.78      0.73       689\n",
      "     HS_Group       0.77      0.59      0.67       405\n",
      "  HS_Religion       0.69      0.69      0.69       124\n",
      "      HS_Race       0.84      0.75      0.79       125\n",
      "  HS_Physical       0.42      0.23      0.30        61\n",
      "    HS_Gender       0.50      0.05      0.09        58\n",
      "     HS_Other       0.77      0.77      0.77       754\n",
      "      HS_Weak       0.68      0.77      0.72       664\n",
      "  HS_Moderate       0.70      0.48      0.57       346\n",
      "    HS_Strong       0.78      0.81      0.80        84\n",
      "\n",
      "    micro avg       0.77      0.77      0.77      5476\n",
      "    macro avg       0.71      0.64      0.66      5476\n",
      " weighted avg       0.77      0.77      0.77      5476\n",
      "  samples avg       0.45      0.44      0.43      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 0.005794990062713624\n",
      "Samples above threshold: 32\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.3666093349456787 seconds\n",
      "\n",
      "Fold 2 - New train size: 10418\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 10418 samples...\n",
      "Epoch 1/10, Train Loss: 0.372, Accuracy: 0.8915, F1 Micro: 0.6498, F1 Macro: 0.3438\n",
      "Epoch 2/10, Train Loss: 0.2484, Accuracy: 0.9079, F1 Micro: 0.7019, F1 Macro: 0.4998\n",
      "Epoch 3/10, Train Loss: 0.1977, Accuracy: 0.916, F1 Micro: 0.7459, F1 Macro: 0.5738\n",
      "Epoch 4/10, Train Loss: 0.1695, Accuracy: 0.9188, F1 Micro: 0.7673, F1 Macro: 0.6153\n",
      "Epoch 5/10, Train Loss: 0.1375, Accuracy: 0.9203, F1 Micro: 0.7623, F1 Macro: 0.6274\n",
      "Epoch 6/10, Train Loss: 0.1193, Accuracy: 0.9215, F1 Micro: 0.7553, F1 Macro: 0.654\n",
      "Epoch 7/10, Train Loss: 0.0957, Accuracy: 0.9226, F1 Micro: 0.7701, F1 Macro: 0.6516\n",
      "Epoch 8/10, Train Loss: 0.0845, Accuracy: 0.9246, F1 Micro: 0.7712, F1 Macro: 0.6683\n",
      "Epoch 9/10, Train Loss: 0.0691, Accuracy: 0.921, F1 Micro: 0.7481, F1 Macro: 0.6649\n",
      "Epoch 10/10, Train Loss: 0.062, Accuracy: 0.9227, F1 Micro: 0.7602, F1 Macro: 0.6907\n",
      "Best result for 10418 samples: F1 Micro: 0.7712\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.83      0.84      1094\n",
      "      Abusive       0.91      0.90      0.91      1072\n",
      "HS_Individual       0.71      0.73      0.72       689\n",
      "     HS_Group       0.76      0.62      0.68       405\n",
      "  HS_Religion       0.73      0.65      0.69       124\n",
      "      HS_Race       0.81      0.73      0.77       125\n",
      "  HS_Physical       0.80      0.13      0.23        61\n",
      "    HS_Gender       0.65      0.22      0.33        58\n",
      "     HS_Other       0.79      0.73      0.76       754\n",
      "      HS_Weak       0.71      0.71      0.71       664\n",
      "  HS_Moderate       0.68      0.53      0.59       346\n",
      "    HS_Strong       0.78      0.82      0.80        84\n",
      "\n",
      "    micro avg       0.80      0.75      0.77      5476\n",
      "    macro avg       0.76      0.63      0.67      5476\n",
      " weighted avg       0.79      0.75      0.77      5476\n",
      "  samples avg       0.45      0.43      0.43      5476\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 0.003270304203033447\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 117\n",
      "Sampling duration: 1.6289606094360352 seconds\n",
      "\n",
      "Fold 2 - New train size: 10535\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 2 - Training with 10535 samples...\n",
      "Epoch 1/10, Train Loss: 0.3724, Accuracy: 0.8815, F1 Micro: 0.5357, F1 Macro: 0.267\n",
      "Epoch 2/10, Train Loss: 0.2467, Accuracy: 0.9055, F1 Micro: 0.7291, F1 Macro: 0.5221\n",
      "Epoch 3/10, Train Loss: 0.1964, Accuracy: 0.917, F1 Micro: 0.7471, F1 Macro: 0.5783\n",
      "Epoch 4/10, Train Loss: 0.1686, Accuracy: 0.9219, F1 Micro: 0.7718, F1 Macro: 0.6244\n",
      "Epoch 5/10, Train Loss: 0.1413, Accuracy: 0.9248, F1 Micro: 0.7784, F1 Macro: 0.6515\n",
      "Epoch 6/10, Train Loss: 0.1158, Accuracy: 0.9249, F1 Micro: 0.7808, F1 Macro: 0.6694\n",
      "Epoch 7/10, Train Loss: 0.0941, Accuracy: 0.9228, F1 Micro: 0.7705, F1 Macro: 0.6747\n",
      "Epoch 8/10, Train Loss: 0.0823, Accuracy: 0.9233, F1 Micro: 0.7689, F1 Macro: 0.6856\n",
      "Epoch 9/10, Train Loss: 0.0671, Accuracy: 0.9242, F1 Micro: 0.7682, F1 Macro: 0.691\n",
      "Epoch 10/10, Train Loss: 0.0608, Accuracy: 0.9235, F1 Micro: 0.7757, F1 Macro: 0.6987\n",
      "Best result for 10535 samples: F1 Micro: 0.7808\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.89      0.85      1094\n",
      "      Abusive       0.90      0.90      0.90      1072\n",
      "HS_Individual       0.70      0.77      0.73       689\n",
      "     HS_Group       0.73      0.64      0.68       405\n",
      "  HS_Religion       0.72      0.63      0.67       124\n",
      "      HS_Race       0.81      0.72      0.76       125\n",
      "  HS_Physical       0.67      0.13      0.22        61\n",
      "    HS_Gender       0.52      0.19      0.28        58\n",
      "     HS_Other       0.74      0.84      0.79       754\n",
      "      HS_Weak       0.70      0.76      0.73       664\n",
      "  HS_Moderate       0.68      0.54      0.60       346\n",
      "    HS_Strong       0.77      0.86      0.81        84\n",
      "\n",
      "    micro avg       0.77      0.79      0.78      5476\n",
      "    macro avg       0.73      0.66      0.67      5476\n",
      " weighted avg       0.77      0.79      0.77      5476\n",
      "  samples avg       0.45      0.45      0.44      5476\n",
      "\n",
      "\n",
      "FOLD 2 COMPLETED in 6277.21 seconds\n",
      "===============================================\n",
      "STARTING FOLD 3/5\n",
      "===============================================\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 658 samples...\n",
      "Epoch 1/10, Train Loss: 0.589, Accuracy: 0.8192, F1 Micro: 0.3329, F1 Macro: 0.121\n",
      "Epoch 2/10, Train Loss: 0.462, Accuracy: 0.8328, F1 Micro: 0.1424, F1 Macro: 0.043\n",
      "Epoch 3/10, Train Loss: 0.4096, Accuracy: 0.8379, F1 Micro: 0.1751, F1 Macro: 0.0644\n",
      "Epoch 4/10, Train Loss: 0.3943, Accuracy: 0.8443, F1 Micro: 0.243, F1 Macro: 0.0848\n",
      "Epoch 5/10, Train Loss: 0.3778, Accuracy: 0.8511, F1 Micro: 0.3367, F1 Macro: 0.1065\n",
      "Epoch 6/10, Train Loss: 0.361, Accuracy: 0.8584, F1 Micro: 0.3902, F1 Macro: 0.1412\n",
      "Epoch 7/10, Train Loss: 0.3343, Accuracy: 0.8714, F1 Micro: 0.5554, F1 Macro: 0.2443\n",
      "Epoch 8/10, Train Loss: 0.3088, Accuracy: 0.8736, F1 Micro: 0.5244, F1 Macro: 0.246\n",
      "Epoch 9/10, Train Loss: 0.2861, Accuracy: 0.8776, F1 Micro: 0.6054, F1 Macro: 0.2994\n",
      "Epoch 10/10, Train Loss: 0.2691, Accuracy: 0.8796, F1 Micro: 0.6353, F1 Macro: 0.3468\n",
      "Best result for 658 samples: F1 Micro: 0.6353\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.74      0.82      0.78      1142\n",
      "      Abusive       0.78      0.82      0.80      1026\n",
      "HS_Individual       0.61      0.65      0.63       723\n",
      "     HS_Group       0.59      0.35      0.44       419\n",
      "  HS_Religion       0.00      0.00      0.00       177\n",
      "      HS_Race       0.00      0.00      0.00       119\n",
      "  HS_Physical       0.00      0.00      0.00        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.61      0.71      0.66       746\n",
      "      HS_Weak       0.59      0.58      0.58       685\n",
      "  HS_Moderate       0.61      0.16      0.26       352\n",
      "    HS_Strong       1.00      0.01      0.02       105\n",
      "\n",
      "    micro avg       0.67      0.60      0.64      5634\n",
      "    macro avg       0.46      0.34      0.35      5634\n",
      " weighted avg       0.62      0.60      0.59      5634\n",
      "  samples avg       0.39      0.34      0.34      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.8318631440401077\n",
      "Samples above threshold: 988\n",
      "Acquired samples: 988\n",
      "Sampling duration: 42.00051212310791 seconds\n",
      "\n",
      "Fold 3 - New train size: 1646\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 1646 samples...\n",
      "Epoch 1/10, Train Loss: 0.4768, Accuracy: 0.8253, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.2885, Accuracy: 0.8253, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.2602, Accuracy: 0.8279, F1 Micro: 0.0314, F1 Macro: 0.0134\n",
      "Epoch 4/10, Train Loss: 0.2257, Accuracy: 0.8515, F1 Micro: 0.3612, F1 Macro: 0.1389\n",
      "Epoch 5/10, Train Loss: 0.2105, Accuracy: 0.8641, F1 Micro: 0.5544, F1 Macro: 0.2519\n",
      "Epoch 6/10, Train Loss: 0.1846, Accuracy: 0.8677, F1 Micro: 0.5407, F1 Macro: 0.2585\n",
      "Epoch 7/10, Train Loss: 0.1675, Accuracy: 0.8711, F1 Micro: 0.5167, F1 Macro: 0.239\n",
      "Epoch 8/10, Train Loss: 0.1556, Accuracy: 0.8758, F1 Micro: 0.5909, F1 Macro: 0.3094\n",
      "Epoch 9/10, Train Loss: 0.1355, Accuracy: 0.8748, F1 Micro: 0.6384, F1 Macro: 0.3578\n",
      "Epoch 10/10, Train Loss: 0.1255, Accuracy: 0.8762, F1 Micro: 0.647, F1 Macro: 0.371\n",
      "Best result for 1646 samples: F1 Micro: 0.647\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.72      0.89      0.80      1142\n",
      "      Abusive       0.83      0.76      0.79      1026\n",
      "HS_Individual       0.59      0.70      0.64       723\n",
      "     HS_Group       0.53      0.60      0.56       419\n",
      "  HS_Religion       0.00      0.00      0.00       177\n",
      "      HS_Race       0.00      0.00      0.00       119\n",
      "  HS_Physical       0.00      0.00      0.00        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.56      0.75      0.64       746\n",
      "      HS_Weak       0.58      0.59      0.59       685\n",
      "  HS_Moderate       0.46      0.40      0.43       352\n",
      "    HS_Strong       0.00      0.00      0.00       105\n",
      "\n",
      "    micro avg       0.64      0.65      0.65      5634\n",
      "    macro avg       0.36      0.39      0.37      5634\n",
      " weighted avg       0.59      0.65      0.61      5634\n",
      "  samples avg       0.37      0.36      0.34      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.9054085001349449\n",
      "Samples above threshold: 889\n",
      "Acquired samples: 889\n",
      "Sampling duration: 37.58013200759888 seconds\n",
      "\n",
      "Fold 3 - New train size: 2535\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 2535 samples...\n",
      "Epoch 1/10, Train Loss: 0.4031, Accuracy: 0.8253, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.2273, Accuracy: 0.8253, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.1993, Accuracy: 0.8312, F1 Micro: 0.0801, F1 Macro: 0.0325\n",
      "Epoch 4/10, Train Loss: 0.1673, Accuracy: 0.8605, F1 Micro: 0.4497, F1 Macro: 0.1974\n",
      "Epoch 5/10, Train Loss: 0.1432, Accuracy: 0.8671, F1 Micro: 0.5343, F1 Macro: 0.2551\n",
      "Epoch 6/10, Train Loss: 0.1275, Accuracy: 0.8709, F1 Micro: 0.5818, F1 Macro: 0.2757\n",
      "Epoch 7/10, Train Loss: 0.1184, Accuracy: 0.8739, F1 Micro: 0.6084, F1 Macro: 0.3052\n",
      "Epoch 8/10, Train Loss: 0.1029, Accuracy: 0.877, F1 Micro: 0.633, F1 Macro: 0.342\n",
      "Epoch 9/10, Train Loss: 0.0935, Accuracy: 0.8806, F1 Micro: 0.6487, F1 Macro: 0.3532\n",
      "Epoch 10/10, Train Loss: 0.0838, Accuracy: 0.881, F1 Micro: 0.6607, F1 Macro: 0.3746\n",
      "Best result for 2535 samples: F1 Micro: 0.6607\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.76      0.86      0.80      1142\n",
      "      Abusive       0.75      0.87      0.81      1026\n",
      "HS_Individual       0.59      0.73      0.65       723\n",
      "     HS_Group       0.61      0.48      0.54       419\n",
      "  HS_Religion       0.00      0.00      0.00       177\n",
      "      HS_Race       0.00      0.00      0.00       119\n",
      "  HS_Physical       0.00      0.00      0.00        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.57      0.77      0.66       746\n",
      "      HS_Weak       0.58      0.65      0.61       685\n",
      "  HS_Moderate       0.55      0.34      0.42       352\n",
      "    HS_Strong       0.00      0.00      0.00       105\n",
      "\n",
      "    micro avg       0.66      0.66      0.66      5634\n",
      "    macro avg       0.37      0.39      0.37      5634\n",
      " weighted avg       0.59      0.66      0.62      5634\n",
      "  samples avg       0.39      0.38      0.36      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.8457611903548241\n",
      "Samples above threshold: 800\n",
      "Acquired samples: 800\n",
      "Sampling duration: 34.54448676109314 seconds\n",
      "\n",
      "Fold 3 - New train size: 3335\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 3335 samples...\n",
      "Epoch 1/10, Train Loss: 0.3544, Accuracy: 0.8253, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.1977, Accuracy: 0.8253, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.1757, Accuracy: 0.8317, F1 Micro: 0.0772, F1 Macro: 0.0316\n",
      "Epoch 4/10, Train Loss: 0.149, Accuracy: 0.8656, F1 Micro: 0.553, F1 Macro: 0.2602\n",
      "Epoch 5/10, Train Loss: 0.1323, Accuracy: 0.8624, F1 Micro: 0.427, F1 Macro: 0.1954\n",
      "Epoch 6/10, Train Loss: 0.1135, Accuracy: 0.8734, F1 Micro: 0.6369, F1 Macro: 0.338\n",
      "Epoch 7/10, Train Loss: 0.0991, Accuracy: 0.8709, F1 Micro: 0.6559, F1 Macro: 0.3595\n",
      "Epoch 8/10, Train Loss: 0.087, Accuracy: 0.8876, F1 Micro: 0.643, F1 Macro: 0.362\n",
      "Epoch 9/10, Train Loss: 0.0731, Accuracy: 0.8886, F1 Micro: 0.6755, F1 Macro: 0.3883\n",
      "Epoch 10/10, Train Loss: 0.0607, Accuracy: 0.8854, F1 Micro: 0.6843, F1 Macro: 0.4647\n",
      "Best result for 3335 samples: F1 Micro: 0.6843\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.77      0.88      0.82      1142\n",
      "      Abusive       0.85      0.86      0.85      1026\n",
      "HS_Individual       0.63      0.68      0.65       723\n",
      "     HS_Group       0.54      0.69      0.60       419\n",
      "  HS_Religion       0.42      0.37      0.39       177\n",
      "      HS_Race       0.56      0.34      0.42       119\n",
      "  HS_Physical       0.00      0.00      0.00        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.62      0.77      0.69       746\n",
      "      HS_Weak       0.59      0.64      0.62       685\n",
      "  HS_Moderate       0.44      0.62      0.51       352\n",
      "    HS_Strong       0.50      0.01      0.02       105\n",
      "\n",
      "    micro avg       0.66      0.71      0.68      5634\n",
      "    macro avg       0.49      0.49      0.46      5634\n",
      " weighted avg       0.65      0.71      0.67      5634\n",
      "  samples avg       0.40      0.40      0.38      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.802353493869305\n",
      "Samples above threshold: 720\n",
      "Acquired samples: 720\n",
      "Sampling duration: 30.893199920654297 seconds\n",
      "\n",
      "Fold 3 - New train size: 4055\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 4055 samples...\n",
      "Epoch 1/10, Train Loss: 0.3323, Accuracy: 0.8253, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.199, Accuracy: 0.8253, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.1705, Accuracy: 0.8291, F1 Micro: 0.0434, F1 Macro: 0.0184\n",
      "Epoch 4/10, Train Loss: 0.1565, Accuracy: 0.8687, F1 Micro: 0.5469, F1 Macro: 0.2681\n",
      "Epoch 5/10, Train Loss: 0.1279, Accuracy: 0.8732, F1 Micro: 0.5386, F1 Macro: 0.2594\n",
      "Epoch 6/10, Train Loss: 0.1129, Accuracy: 0.881, F1 Micro: 0.6303, F1 Macro: 0.3225\n",
      "Epoch 7/10, Train Loss: 0.1004, Accuracy: 0.8824, F1 Micro: 0.6581, F1 Macro: 0.3695\n",
      "Epoch 8/10, Train Loss: 0.0817, Accuracy: 0.8893, F1 Micro: 0.6733, F1 Macro: 0.3951\n",
      "Epoch 9/10, Train Loss: 0.0695, Accuracy: 0.8903, F1 Micro: 0.6822, F1 Macro: 0.434\n",
      "Epoch 10/10, Train Loss: 0.0614, Accuracy: 0.8881, F1 Micro: 0.6859, F1 Macro: 0.4327\n",
      "Best result for 4055 samples: F1 Micro: 0.6859\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.77      0.89      0.82      1142\n",
      "      Abusive       0.83      0.88      0.85      1026\n",
      "HS_Individual       0.61      0.67      0.64       723\n",
      "     HS_Group       0.57      0.69      0.62       419\n",
      "  HS_Religion       0.47      0.18      0.26       177\n",
      "      HS_Race       0.67      0.08      0.15       119\n",
      "  HS_Physical       0.00      0.00      0.00        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.63      0.75      0.68       746\n",
      "      HS_Weak       0.60      0.62      0.61       685\n",
      "  HS_Moderate       0.48      0.63      0.55       352\n",
      "    HS_Strong       0.00      0.00      0.00       105\n",
      "\n",
      "    micro avg       0.67      0.70      0.69      5634\n",
      "    macro avg       0.47      0.45      0.43      5634\n",
      " weighted avg       0.64      0.70      0.66      5634\n",
      "  samples avg       0.41      0.40      0.39      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.46029138565063477\n",
      "Samples above threshold: 663\n",
      "Acquired samples: 648\n",
      "Sampling duration: 27.669705867767334 seconds\n",
      "\n",
      "Fold 3 - New train size: 4703\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 4703 samples...\n",
      "Epoch 1/10, Train Loss: 0.321, Accuracy: 0.8253, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.2045, Accuracy: 0.8253, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.1847, Accuracy: 0.8281, F1 Micro: 0.0318, F1 Macro: 0.0136\n",
      "Epoch 4/10, Train Loss: 0.1655, Accuracy: 0.8574, F1 Micro: 0.357, F1 Macro: 0.159\n",
      "Epoch 5/10, Train Loss: 0.135, Accuracy: 0.8799, F1 Micro: 0.6385, F1 Macro: 0.3363\n",
      "Epoch 6/10, Train Loss: 0.1109, Accuracy: 0.8779, F1 Micro: 0.6619, F1 Macro: 0.3728\n",
      "Epoch 7/10, Train Loss: 0.096, Accuracy: 0.8901, F1 Micro: 0.6435, F1 Macro: 0.3982\n",
      "Epoch 8/10, Train Loss: 0.082, Accuracy: 0.8949, F1 Micro: 0.6746, F1 Macro: 0.4113\n",
      "Epoch 9/10, Train Loss: 0.0675, Accuracy: 0.8946, F1 Micro: 0.6887, F1 Macro: 0.4553\n",
      "Epoch 10/10, Train Loss: 0.0584, Accuracy: 0.8957, F1 Micro: 0.6908, F1 Macro: 0.4357\n",
      "Best result for 4703 samples: F1 Micro: 0.6908\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.87      0.83      1142\n",
      "      Abusive       0.90      0.82      0.86      1026\n",
      "HS_Individual       0.64      0.67      0.65       723\n",
      "     HS_Group       0.63      0.62      0.62       419\n",
      "  HS_Religion       0.77      0.14      0.23       177\n",
      "      HS_Race       0.87      0.11      0.19       119\n",
      "  HS_Physical       0.00      0.00      0.00        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.65      0.73      0.69       746\n",
      "      HS_Weak       0.62      0.61      0.61       685\n",
      "  HS_Moderate       0.53      0.55      0.54       352\n",
      "    HS_Strong       0.00      0.00      0.00       105\n",
      "\n",
      "    micro avg       0.72      0.67      0.69      5634\n",
      "    macro avg       0.53      0.42      0.44      5634\n",
      " weighted avg       0.69      0.67      0.67      5634\n",
      "  samples avg       0.41      0.39      0.38      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.35848728418350223\n",
      "Samples above threshold: 584\n",
      "Acquired samples: 584\n",
      "Sampling duration: 25.1138653755188 seconds\n",
      "\n",
      "Fold 3 - New train size: 5287\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 5287 samples...\n",
      "Epoch 1/10, Train Loss: 0.3182, Accuracy: 0.8253, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.2202, Accuracy: 0.8253, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.1994, Accuracy: 0.8664, F1 Micro: 0.4639, F1 Macro: 0.2083\n",
      "Epoch 4/10, Train Loss: 0.1625, Accuracy: 0.8833, F1 Micro: 0.622, F1 Macro: 0.3236\n",
      "Epoch 5/10, Train Loss: 0.1368, Accuracy: 0.8904, F1 Micro: 0.651, F1 Macro: 0.3567\n",
      "Epoch 6/10, Train Loss: 0.1154, Accuracy: 0.8928, F1 Micro: 0.7006, F1 Macro: 0.4343\n",
      "Epoch 7/10, Train Loss: 0.0909, Accuracy: 0.8953, F1 Micro: 0.7039, F1 Macro: 0.4836\n",
      "Epoch 8/10, Train Loss: 0.0772, Accuracy: 0.8993, F1 Micro: 0.7051, F1 Macro: 0.4792\n",
      "Epoch 9/10, Train Loss: 0.0667, Accuracy: 0.8987, F1 Micro: 0.6984, F1 Macro: 0.4642\n",
      "Epoch 10/10, Train Loss: 0.0572, Accuracy: 0.9001, F1 Micro: 0.7014, F1 Macro: 0.4747\n",
      "Best result for 5287 samples: F1 Micro: 0.7051\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.81      0.87      0.84      1142\n",
      "      Abusive       0.89      0.84      0.86      1026\n",
      "HS_Individual       0.67      0.68      0.68       723\n",
      "     HS_Group       0.62      0.63      0.62       419\n",
      "  HS_Religion       0.54      0.35      0.43       177\n",
      "      HS_Race       0.66      0.34      0.44       119\n",
      "  HS_Physical       0.00      0.00      0.00        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.67      0.71      0.69       746\n",
      "      HS_Weak       0.63      0.65      0.64       685\n",
      "  HS_Moderate       0.53      0.55      0.54       352\n",
      "    HS_Strong       0.00      0.00      0.00       105\n",
      "\n",
      "    micro avg       0.72      0.69      0.71      5634\n",
      "    macro avg       0.50      0.47      0.48      5634\n",
      " weighted avg       0.69      0.69      0.69      5634\n",
      "  samples avg       0.42      0.40      0.39      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.1498563170433045\n",
      "Samples above threshold: 525\n",
      "Acquired samples: 525\n",
      "Sampling duration: 22.603553771972656 seconds\n",
      "\n",
      "Fold 3 - New train size: 5812\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 5812 samples...\n",
      "Epoch 1/10, Train Loss: 0.3206, Accuracy: 0.8253, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.2313, Accuracy: 0.8296, F1 Micro: 0.0498, F1 Macro: 0.0204\n",
      "Epoch 3/10, Train Loss: 0.1988, Accuracy: 0.8765, F1 Micro: 0.5721, F1 Macro: 0.2975\n",
      "Epoch 4/10, Train Loss: 0.164, Accuracy: 0.8883, F1 Micro: 0.6432, F1 Macro: 0.3687\n",
      "Epoch 5/10, Train Loss: 0.139, Accuracy: 0.8921, F1 Micro: 0.7025, F1 Macro: 0.458\n",
      "Epoch 6/10, Train Loss: 0.1131, Accuracy: 0.8963, F1 Micro: 0.7059, F1 Macro: 0.4905\n",
      "Epoch 7/10, Train Loss: 0.0876, Accuracy: 0.9, F1 Micro: 0.7114, F1 Macro: 0.4854\n",
      "Epoch 8/10, Train Loss: 0.0758, Accuracy: 0.9012, F1 Micro: 0.7212, F1 Macro: 0.4823\n",
      "Epoch 9/10, Train Loss: 0.0704, Accuracy: 0.9014, F1 Micro: 0.7186, F1 Macro: 0.4941\n",
      "Epoch 10/10, Train Loss: 0.0586, Accuracy: 0.9039, F1 Micro: 0.7293, F1 Macro: 0.5067\n",
      "Best result for 5812 samples: F1 Micro: 0.7293\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.90      0.85      1142\n",
      "      Abusive       0.89      0.88      0.88      1026\n",
      "HS_Individual       0.65      0.77      0.70       723\n",
      "     HS_Group       0.68      0.58      0.63       419\n",
      "  HS_Religion       0.69      0.44      0.53       177\n",
      "      HS_Race       0.82      0.39      0.53       119\n",
      "  HS_Physical       0.00      0.00      0.00        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.65      0.84      0.73       746\n",
      "      HS_Weak       0.61      0.74      0.67       685\n",
      "  HS_Moderate       0.57      0.53      0.55       352\n",
      "    HS_Strong       0.00      0.00      0.00       105\n",
      "\n",
      "    micro avg       0.72      0.74      0.73      5634\n",
      "    macro avg       0.53      0.51      0.51      5634\n",
      " weighted avg       0.69      0.74      0.71      5634\n",
      "  samples avg       0.43      0.43      0.41      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.05979487895965577\n",
      "Samples above threshold: 473\n",
      "Acquired samples: 473\n",
      "Sampling duration: 20.370057106018066 seconds\n",
      "\n",
      "Fold 3 - New train size: 6285\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 6285 samples...\n",
      "Epoch 1/10, Train Loss: 0.3369, Accuracy: 0.8253, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.2424, Accuracy: 0.858, F1 Micro: 0.3605, F1 Macro: 0.1589\n",
      "Epoch 3/10, Train Loss: 0.1932, Accuracy: 0.8888, F1 Micro: 0.6176, F1 Macro: 0.3897\n",
      "Epoch 4/10, Train Loss: 0.1602, Accuracy: 0.9001, F1 Micro: 0.7075, F1 Macro: 0.457\n",
      "Epoch 5/10, Train Loss: 0.1313, Accuracy: 0.8996, F1 Micro: 0.7227, F1 Macro: 0.4889\n",
      "Epoch 6/10, Train Loss: 0.1061, Accuracy: 0.9032, F1 Micro: 0.726, F1 Macro: 0.5326\n",
      "Epoch 7/10, Train Loss: 0.0876, Accuracy: 0.9056, F1 Micro: 0.7323, F1 Macro: 0.5391\n",
      "Epoch 8/10, Train Loss: 0.0757, Accuracy: 0.9074, F1 Micro: 0.7215, F1 Macro: 0.5442\n",
      "Epoch 9/10, Train Loss: 0.0651, Accuracy: 0.9083, F1 Micro: 0.733, F1 Macro: 0.5334\n",
      "Epoch 10/10, Train Loss: 0.0559, Accuracy: 0.9101, F1 Micro: 0.7373, F1 Macro: 0.5586\n",
      "Best result for 6285 samples: F1 Micro: 0.7373\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.86      0.84      1142\n",
      "      Abusive       0.89      0.88      0.89      1026\n",
      "HS_Individual       0.72      0.66      0.69       723\n",
      "     HS_Group       0.65      0.68      0.67       419\n",
      "  HS_Religion       0.71      0.60      0.65       177\n",
      "      HS_Race       0.79      0.59      0.67       119\n",
      "  HS_Physical       0.00      0.00      0.00        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.71      0.77      0.74       746\n",
      "      HS_Weak       0.69      0.63      0.66       685\n",
      "  HS_Moderate       0.54      0.61      0.58       352\n",
      "    HS_Strong       0.84      0.20      0.32       105\n",
      "\n",
      "    micro avg       0.75      0.72      0.74      5634\n",
      "    macro avg       0.61      0.54      0.56      5634\n",
      " weighted avg       0.74      0.72      0.72      5634\n",
      "  samples avg       0.43      0.41      0.41      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.05656689405441284\n",
      "Samples above threshold: 425\n",
      "Acquired samples: 299\n",
      "Sampling duration: 18.702157497406006 seconds\n",
      "\n",
      "Fold 3 - New train size: 6584\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 6584 samples...\n",
      "Epoch 1/10, Train Loss: 0.3374, Accuracy: 0.8253, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.2448, Accuracy: 0.8663, F1 Micro: 0.4627, F1 Macro: 0.2588\n",
      "Epoch 3/10, Train Loss: 0.2024, Accuracy: 0.8948, F1 Micro: 0.6652, F1 Macro: 0.44\n",
      "Epoch 4/10, Train Loss: 0.1582, Accuracy: 0.9035, F1 Micro: 0.7083, F1 Macro: 0.5239\n",
      "Epoch 5/10, Train Loss: 0.1326, Accuracy: 0.9005, F1 Micro: 0.7265, F1 Macro: 0.54\n",
      "Epoch 6/10, Train Loss: 0.1124, Accuracy: 0.909, F1 Micro: 0.7239, F1 Macro: 0.5475\n",
      "Epoch 7/10, Train Loss: 0.0874, Accuracy: 0.9056, F1 Micro: 0.7316, F1 Macro: 0.5627\n",
      "Epoch 8/10, Train Loss: 0.0753, Accuracy: 0.9082, F1 Micro: 0.7334, F1 Macro: 0.5593\n",
      "Epoch 9/10, Train Loss: 0.0659, Accuracy: 0.9055, F1 Micro: 0.7388, F1 Macro: 0.5666\n",
      "Epoch 10/10, Train Loss: 0.0566, Accuracy: 0.9083, F1 Micro: 0.7352, F1 Macro: 0.5706\n",
      "Best result for 6584 samples: F1 Micro: 0.7388\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.79      0.90      0.84      1142\n",
      "      Abusive       0.85      0.94      0.89      1026\n",
      "HS_Individual       0.64      0.72      0.68       723\n",
      "     HS_Group       0.63      0.68      0.65       419\n",
      "  HS_Religion       0.74      0.54      0.62       177\n",
      "      HS_Race       0.78      0.58      0.67       119\n",
      "  HS_Physical       0.00      0.00      0.00        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.67      0.84      0.74       746\n",
      "      HS_Weak       0.62      0.70      0.66       685\n",
      "  HS_Moderate       0.58      0.60      0.59       352\n",
      "    HS_Strong       0.85      0.31      0.46       105\n",
      "\n",
      "    micro avg       0.71      0.77      0.74      5634\n",
      "    macro avg       0.60      0.57      0.57      5634\n",
      " weighted avg       0.70      0.77      0.73      5634\n",
      "  samples avg       0.44      0.44      0.42      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 0.03977513313293457\n",
      "Samples above threshold: 396\n",
      "Acquired samples: 396\n",
      "Sampling duration: 17.413050651550293 seconds\n",
      "\n",
      "Fold 3 - New train size: 6980\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 6980 samples...\n",
      "Epoch 1/10, Train Loss: 0.3581, Accuracy: 0.8279, F1 Micro: 0.0304, F1 Macro: 0.013\n",
      "Epoch 2/10, Train Loss: 0.2508, Accuracy: 0.8833, F1 Micro: 0.5917, F1 Macro: 0.3754\n",
      "Epoch 3/10, Train Loss: 0.1953, Accuracy: 0.8956, F1 Micro: 0.6292, F1 Macro: 0.4324\n",
      "Epoch 4/10, Train Loss: 0.1628, Accuracy: 0.907, F1 Micro: 0.7236, F1 Macro: 0.5595\n",
      "Epoch 5/10, Train Loss: 0.1335, Accuracy: 0.908, F1 Micro: 0.7288, F1 Macro: 0.5562\n",
      "Epoch 6/10, Train Loss: 0.1072, Accuracy: 0.9085, F1 Micro: 0.7383, F1 Macro: 0.5734\n",
      "Epoch 7/10, Train Loss: 0.0967, Accuracy: 0.9125, F1 Micro: 0.7468, F1 Macro: 0.5839\n",
      "Epoch 8/10, Train Loss: 0.0791, Accuracy: 0.9095, F1 Micro: 0.7398, F1 Macro: 0.565\n",
      "Epoch 9/10, Train Loss: 0.0687, Accuracy: 0.9109, F1 Micro: 0.7433, F1 Macro: 0.5871\n",
      "Epoch 10/10, Train Loss: 0.059, Accuracy: 0.916, F1 Micro: 0.7501, F1 Macro: 0.5951\n",
      "Best result for 6980 samples: F1 Micro: 0.7501\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.84      0.85      1142\n",
      "      Abusive       0.91      0.89      0.90      1026\n",
      "HS_Individual       0.70      0.70      0.70       723\n",
      "     HS_Group       0.72      0.58      0.64       419\n",
      "  HS_Religion       0.78      0.50      0.61       177\n",
      "      HS_Race       0.85      0.66      0.75       119\n",
      "  HS_Physical       0.00      0.00      0.00        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.73      0.76      0.75       746\n",
      "      HS_Weak       0.67      0.68      0.67       685\n",
      "  HS_Moderate       0.68      0.50      0.57       352\n",
      "    HS_Strong       0.81      0.62      0.70       105\n",
      "\n",
      "    micro avg       0.78      0.72      0.75      5634\n",
      "    macro avg       0.64      0.56      0.60      5634\n",
      " weighted avg       0.76      0.72      0.74      5634\n",
      "  samples avg       0.44      0.42      0.41      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 0.03942873477935789\n",
      "Samples above threshold: 356\n",
      "Acquired samples: 356\n",
      "Sampling duration: 15.639606237411499 seconds\n",
      "\n",
      "Fold 3 - New train size: 7336\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 7336 samples...\n",
      "Epoch 1/10, Train Loss: 0.3583, Accuracy: 0.837, F1 Micro: 0.14, F1 Macro: 0.0533\n",
      "Epoch 2/10, Train Loss: 0.2544, Accuracy: 0.8774, F1 Micro: 0.5009, F1 Macro: 0.3186\n",
      "Epoch 3/10, Train Loss: 0.1969, Accuracy: 0.9036, F1 Micro: 0.7257, F1 Macro: 0.5527\n",
      "Epoch 4/10, Train Loss: 0.1588, Accuracy: 0.9096, F1 Micro: 0.7206, F1 Macro: 0.5475\n",
      "Epoch 5/10, Train Loss: 0.1363, Accuracy: 0.9107, F1 Micro: 0.7384, F1 Macro: 0.5784\n",
      "Epoch 6/10, Train Loss: 0.1103, Accuracy: 0.9132, F1 Micro: 0.7449, F1 Macro: 0.5856\n",
      "Epoch 7/10, Train Loss: 0.0944, Accuracy: 0.9097, F1 Micro: 0.7459, F1 Macro: 0.6019\n",
      "Epoch 8/10, Train Loss: 0.0792, Accuracy: 0.9143, F1 Micro: 0.7513, F1 Macro: 0.5979\n",
      "Epoch 9/10, Train Loss: 0.069, Accuracy: 0.9156, F1 Micro: 0.7532, F1 Macro: 0.6011\n",
      "Epoch 10/10, Train Loss: 0.0576, Accuracy: 0.9137, F1 Micro: 0.7509, F1 Macro: 0.6018\n",
      "Best result for 7336 samples: F1 Micro: 0.7532\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.85      0.85      1142\n",
      "      Abusive       0.90      0.91      0.90      1026\n",
      "HS_Individual       0.67      0.75      0.71       723\n",
      "     HS_Group       0.75      0.54      0.63       419\n",
      "  HS_Religion       0.75      0.58      0.66       177\n",
      "      HS_Race       0.82      0.71      0.76       119\n",
      "  HS_Physical       0.00      0.00      0.00        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.74      0.76      0.75       746\n",
      "      HS_Weak       0.65      0.72      0.68       685\n",
      "  HS_Moderate       0.67      0.47      0.55       352\n",
      "    HS_Strong       0.87      0.62      0.72       105\n",
      "\n",
      "    micro avg       0.77      0.74      0.75      5634\n",
      "    macro avg       0.64      0.58      0.60      5634\n",
      " weighted avg       0.75      0.74      0.74      5634\n",
      "  samples avg       0.44      0.43      0.42      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 0.03542453050613403\n",
      "Samples above threshold: 321\n",
      "Acquired samples: 320\n",
      "Sampling duration: 14.12679672241211 seconds\n",
      "\n",
      "Fold 3 - New train size: 7656\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 7656 samples...\n",
      "Epoch 1/10, Train Loss: 0.3626, Accuracy: 0.8481, F1 Micro: 0.2728, F1 Macro: 0.1054\n",
      "Epoch 2/10, Train Loss: 0.2495, Accuracy: 0.8953, F1 Micro: 0.6453, F1 Macro: 0.4358\n",
      "Epoch 3/10, Train Loss: 0.2022, Accuracy: 0.9065, F1 Micro: 0.7274, F1 Macro: 0.5483\n",
      "Epoch 4/10, Train Loss: 0.1627, Accuracy: 0.908, F1 Micro: 0.745, F1 Macro: 0.5854\n",
      "Epoch 5/10, Train Loss: 0.1342, Accuracy: 0.9116, F1 Micro: 0.7444, F1 Macro: 0.5861\n",
      "Epoch 6/10, Train Loss: 0.107, Accuracy: 0.911, F1 Micro: 0.7507, F1 Macro: 0.5963\n",
      "Epoch 7/10, Train Loss: 0.0915, Accuracy: 0.9094, F1 Micro: 0.7366, F1 Macro: 0.5694\n",
      "Epoch 8/10, Train Loss: 0.0811, Accuracy: 0.9158, F1 Micro: 0.7578, F1 Macro: 0.6104\n",
      "Epoch 9/10, Train Loss: 0.0745, Accuracy: 0.9106, F1 Micro: 0.7442, F1 Macro: 0.5836\n",
      "Epoch 10/10, Train Loss: 0.0631, Accuracy: 0.9127, F1 Micro: 0.7533, F1 Macro: 0.6061\n",
      "Best result for 7656 samples: F1 Micro: 0.7578\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.86      0.84      1142\n",
      "      Abusive       0.88      0.92      0.90      1026\n",
      "HS_Individual       0.70      0.73      0.71       723\n",
      "     HS_Group       0.71      0.65      0.68       419\n",
      "  HS_Religion       0.73      0.59      0.65       177\n",
      "      HS_Race       0.79      0.72      0.75       119\n",
      "  HS_Physical       0.00      0.00      0.00        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.72      0.78      0.75       746\n",
      "      HS_Weak       0.68      0.68      0.68       685\n",
      "  HS_Moderate       0.63      0.57      0.60       352\n",
      "    HS_Strong       0.79      0.72      0.76       105\n",
      "\n",
      "    micro avg       0.76      0.75      0.76      5634\n",
      "    macro avg       0.62      0.60      0.61      5634\n",
      " weighted avg       0.74      0.75      0.75      5634\n",
      "  samples avg       0.44      0.43      0.42      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 0.03003488779067994\n",
      "Samples above threshold: 288\n",
      "Acquired samples: 245\n",
      "Sampling duration: 14.110798597335815 seconds\n",
      "\n",
      "Fold 3 - New train size: 7901\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 7901 samples...\n",
      "Epoch 1/10, Train Loss: 0.3611, Accuracy: 0.8584, F1 Micro: 0.372, F1 Macro: 0.146\n",
      "Epoch 2/10, Train Loss: 0.2475, Accuracy: 0.9001, F1 Micro: 0.6945, F1 Macro: 0.519\n",
      "Epoch 3/10, Train Loss: 0.1936, Accuracy: 0.9059, F1 Micro: 0.7354, F1 Macro: 0.5682\n",
      "Epoch 4/10, Train Loss: 0.1621, Accuracy: 0.9053, F1 Micro: 0.7443, F1 Macro: 0.5876\n",
      "Epoch 5/10, Train Loss: 0.1333, Accuracy: 0.9023, F1 Micro: 0.7404, F1 Macro: 0.5825\n",
      "Epoch 6/10, Train Loss: 0.1096, Accuracy: 0.9139, F1 Micro: 0.7481, F1 Macro: 0.5913\n",
      "Epoch 7/10, Train Loss: 0.0929, Accuracy: 0.9171, F1 Micro: 0.7575, F1 Macro: 0.6003\n",
      "Epoch 8/10, Train Loss: 0.0798, Accuracy: 0.916, F1 Micro: 0.7594, F1 Macro: 0.6029\n",
      "Epoch 9/10, Train Loss: 0.0681, Accuracy: 0.9161, F1 Micro: 0.7521, F1 Macro: 0.6032\n",
      "Epoch 10/10, Train Loss: 0.0564, Accuracy: 0.9136, F1 Micro: 0.7529, F1 Macro: 0.6015\n",
      "Best result for 7901 samples: F1 Micro: 0.7594\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.88      0.85      1142\n",
      "      Abusive       0.88      0.93      0.91      1026\n",
      "HS_Individual       0.68      0.77      0.72       723\n",
      "     HS_Group       0.73      0.58      0.64       419\n",
      "  HS_Religion       0.77      0.51      0.62       177\n",
      "      HS_Race       0.81      0.69      0.75       119\n",
      "  HS_Physical       0.00      0.00      0.00        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.70      0.82      0.76       746\n",
      "      HS_Weak       0.66      0.74      0.70       685\n",
      "  HS_Moderate       0.65      0.46      0.54       352\n",
      "    HS_Strong       0.83      0.70      0.76       105\n",
      "\n",
      "    micro avg       0.76      0.76      0.76      5634\n",
      "    macro avg       0.63      0.59      0.60      5634\n",
      " weighted avg       0.74      0.76      0.75      5634\n",
      "  samples avg       0.45      0.44      0.43      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.02583563327789307\n",
      "Samples above threshold: 264\n",
      "Acquired samples: 264\n",
      "Sampling duration: 11.808204650878906 seconds\n",
      "\n",
      "Fold 3 - New train size: 8165\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 8165 samples...\n",
      "Epoch 1/10, Train Loss: 0.3649, Accuracy: 0.8701, F1 Micro: 0.483, F1 Macro: 0.2214\n",
      "Epoch 2/10, Train Loss: 0.2465, Accuracy: 0.8994, F1 Micro: 0.7025, F1 Macro: 0.4916\n",
      "Epoch 3/10, Train Loss: 0.2, Accuracy: 0.9064, F1 Micro: 0.7285, F1 Macro: 0.5241\n",
      "Epoch 4/10, Train Loss: 0.1629, Accuracy: 0.9141, F1 Micro: 0.7375, F1 Macro: 0.5819\n",
      "Epoch 5/10, Train Loss: 0.134, Accuracy: 0.9151, F1 Micro: 0.751, F1 Macro: 0.5927\n",
      "Epoch 6/10, Train Loss: 0.1138, Accuracy: 0.9126, F1 Micro: 0.7521, F1 Macro: 0.5925\n",
      "Epoch 7/10, Train Loss: 0.0956, Accuracy: 0.9143, F1 Micro: 0.7502, F1 Macro: 0.5888\n",
      "Epoch 8/10, Train Loss: 0.0786, Accuracy: 0.9174, F1 Micro: 0.7613, F1 Macro: 0.6091\n",
      "Epoch 9/10, Train Loss: 0.0711, Accuracy: 0.9168, F1 Micro: 0.7624, F1 Macro: 0.6156\n",
      "Epoch 10/10, Train Loss: 0.0626, Accuracy: 0.9182, F1 Micro: 0.7559, F1 Macro: 0.5968\n",
      "Best result for 8165 samples: F1 Micro: 0.7624\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.88      0.85      1142\n",
      "      Abusive       0.90      0.91      0.91      1026\n",
      "HS_Individual       0.72      0.70      0.71       723\n",
      "     HS_Group       0.65      0.71      0.68       419\n",
      "  HS_Religion       0.68      0.63      0.66       177\n",
      "      HS_Race       0.80      0.74      0.77       119\n",
      "  HS_Physical       0.00      0.00      0.00        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.73      0.80      0.76       746\n",
      "      HS_Weak       0.70      0.66      0.68       685\n",
      "  HS_Moderate       0.59      0.68      0.63       352\n",
      "    HS_Strong       0.82      0.68      0.74       105\n",
      "\n",
      "    micro avg       0.76      0.76      0.76      5634\n",
      "    macro avg       0.62      0.62      0.62      5634\n",
      " weighted avg       0.74      0.76      0.75      5634\n",
      "  samples avg       0.44      0.44      0.42      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.022017967700958253\n",
      "Samples above threshold: 237\n",
      "Acquired samples: 237\n",
      "Sampling duration: 10.880099296569824 seconds\n",
      "\n",
      "Fold 3 - New train size: 8402\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 8402 samples...\n",
      "Epoch 1/10, Train Loss: 0.37, Accuracy: 0.8774, F1 Micro: 0.5943, F1 Macro: 0.3\n",
      "Epoch 2/10, Train Loss: 0.2439, Accuracy: 0.9016, F1 Micro: 0.6824, F1 Macro: 0.4523\n",
      "Epoch 3/10, Train Loss: 0.2009, Accuracy: 0.9115, F1 Micro: 0.7247, F1 Macro: 0.5571\n",
      "Epoch 4/10, Train Loss: 0.1636, Accuracy: 0.9157, F1 Micro: 0.7533, F1 Macro: 0.5884\n",
      "Epoch 5/10, Train Loss: 0.1345, Accuracy: 0.9154, F1 Micro: 0.7484, F1 Macro: 0.59\n",
      "Epoch 6/10, Train Loss: 0.1131, Accuracy: 0.9166, F1 Micro: 0.7625, F1 Macro: 0.6083\n",
      "Epoch 7/10, Train Loss: 0.0943, Accuracy: 0.9192, F1 Micro: 0.7655, F1 Macro: 0.6181\n",
      "Epoch 8/10, Train Loss: 0.0784, Accuracy: 0.9188, F1 Micro: 0.7639, F1 Macro: 0.6184\n",
      "Epoch 9/10, Train Loss: 0.0698, Accuracy: 0.9201, F1 Micro: 0.7639, F1 Macro: 0.6117\n",
      "Epoch 10/10, Train Loss: 0.0583, Accuracy: 0.9172, F1 Micro: 0.7653, F1 Macro: 0.6296\n",
      "Best result for 8402 samples: F1 Micro: 0.7655\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.86      0.84      1142\n",
      "      Abusive       0.91      0.90      0.90      1026\n",
      "HS_Individual       0.70      0.75      0.73       723\n",
      "     HS_Group       0.74      0.63      0.68       419\n",
      "  HS_Religion       0.79      0.60      0.69       177\n",
      "      HS_Race       0.76      0.77      0.77       119\n",
      "  HS_Physical       0.00      0.00      0.00        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.72      0.79      0.75       746\n",
      "      HS_Weak       0.70      0.72      0.71       685\n",
      "  HS_Moderate       0.67      0.55      0.61       352\n",
      "    HS_Strong       0.82      0.69      0.75       105\n",
      "\n",
      "    micro avg       0.78      0.75      0.77      5634\n",
      "    macro avg       0.64      0.60      0.62      5634\n",
      " weighted avg       0.76      0.75      0.75      5634\n",
      "  samples avg       0.43      0.43      0.42      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.026893413066864012\n",
      "Samples above threshold: 214\n",
      "Acquired samples: 214\n",
      "Sampling duration: 9.864590406417847 seconds\n",
      "\n",
      "Fold 3 - New train size: 8616\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 8616 samples...\n",
      "Epoch 1/10, Train Loss: 0.3682, Accuracy: 0.8793, F1 Micro: 0.5897, F1 Macro: 0.2922\n",
      "Epoch 2/10, Train Loss: 0.2479, Accuracy: 0.9037, F1 Micro: 0.7012, F1 Macro: 0.5339\n",
      "Epoch 3/10, Train Loss: 0.194, Accuracy: 0.9125, F1 Micro: 0.7334, F1 Macro: 0.5669\n",
      "Epoch 4/10, Train Loss: 0.1586, Accuracy: 0.9144, F1 Micro: 0.7542, F1 Macro: 0.5991\n",
      "Epoch 5/10, Train Loss: 0.1299, Accuracy: 0.9169, F1 Micro: 0.7559, F1 Macro: 0.588\n",
      "Epoch 6/10, Train Loss: 0.1085, Accuracy: 0.9143, F1 Micro: 0.7558, F1 Macro: 0.5874\n",
      "Epoch 7/10, Train Loss: 0.0946, Accuracy: 0.9204, F1 Micro: 0.7618, F1 Macro: 0.6062\n",
      "Epoch 8/10, Train Loss: 0.0793, Accuracy: 0.9144, F1 Micro: 0.762, F1 Macro: 0.6131\n",
      "Epoch 9/10, Train Loss: 0.0675, Accuracy: 0.9155, F1 Micro: 0.7578, F1 Macro: 0.6042\n",
      "Epoch 10/10, Train Loss: 0.0603, Accuracy: 0.9184, F1 Micro: 0.7687, F1 Macro: 0.6273\n",
      "Best result for 8616 samples: F1 Micro: 0.7687\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.87      0.84      1142\n",
      "      Abusive       0.91      0.91      0.91      1026\n",
      "HS_Individual       0.68      0.78      0.73       723\n",
      "     HS_Group       0.73      0.66      0.69       419\n",
      "  HS_Religion       0.74      0.56      0.64       177\n",
      "      HS_Race       0.81      0.70      0.75       119\n",
      "  HS_Physical       0.80      0.05      0.09        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.72      0.82      0.77       746\n",
      "      HS_Weak       0.66      0.75      0.70       685\n",
      "  HS_Moderate       0.67      0.60      0.63       352\n",
      "    HS_Strong       0.83      0.73      0.78       105\n",
      "\n",
      "    micro avg       0.76      0.78      0.77      5634\n",
      "    macro avg       0.70      0.62      0.63      5634\n",
      " weighted avg       0.76      0.78      0.76      5634\n",
      "  samples avg       0.44      0.44      0.43      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.01433340311050415\n",
      "Samples above threshold: 192\n",
      "Acquired samples: 200\n",
      "Sampling duration: 8.906514883041382 seconds\n",
      "\n",
      "Fold 3 - New train size: 8816\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 8816 samples...\n",
      "Epoch 1/10, Train Loss: 0.3688, Accuracy: 0.88, F1 Micro: 0.6082, F1 Macro: 0.3154\n",
      "Epoch 2/10, Train Loss: 0.2505, Accuracy: 0.9017, F1 Micro: 0.6988, F1 Macro: 0.4687\n",
      "Epoch 3/10, Train Loss: 0.1959, Accuracy: 0.9102, F1 Micro: 0.7441, F1 Macro: 0.5819\n",
      "Epoch 4/10, Train Loss: 0.1633, Accuracy: 0.9191, F1 Micro: 0.7559, F1 Macro: 0.6051\n",
      "Epoch 5/10, Train Loss: 0.1364, Accuracy: 0.9199, F1 Micro: 0.7545, F1 Macro: 0.5944\n",
      "Epoch 6/10, Train Loss: 0.1154, Accuracy: 0.9205, F1 Micro: 0.7705, F1 Macro: 0.6137\n",
      "Epoch 7/10, Train Loss: 0.093, Accuracy: 0.9156, F1 Micro: 0.7648, F1 Macro: 0.6135\n",
      "Epoch 8/10, Train Loss: 0.0809, Accuracy: 0.9197, F1 Micro: 0.768, F1 Macro: 0.619\n",
      "Epoch 9/10, Train Loss: 0.0692, Accuracy: 0.9207, F1 Micro: 0.7679, F1 Macro: 0.6253\n",
      "Epoch 10/10, Train Loss: 0.0606, Accuracy: 0.9209, F1 Micro: 0.7633, F1 Macro: 0.638\n",
      "Best result for 8816 samples: F1 Micro: 0.7705\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.87      0.85      1142\n",
      "      Abusive       0.90      0.91      0.90      1026\n",
      "HS_Individual       0.71      0.79      0.74       723\n",
      "     HS_Group       0.77      0.59      0.67       419\n",
      "  HS_Religion       0.79      0.54      0.64       177\n",
      "      HS_Race       0.79      0.66      0.72       119\n",
      "  HS_Physical       0.00      0.00      0.00        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.72      0.81      0.76       746\n",
      "      HS_Weak       0.68      0.76      0.72       685\n",
      "  HS_Moderate       0.73      0.51      0.60       352\n",
      "    HS_Strong       0.84      0.68      0.75       105\n",
      "\n",
      "    micro avg       0.78      0.76      0.77      5634\n",
      "    macro avg       0.65      0.59      0.61      5634\n",
      " weighted avg       0.76      0.76      0.76      5634\n",
      "  samples avg       0.45      0.44      0.43      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.03256793022155762\n",
      "Samples above threshold: 172\n",
      "Acquired samples: 200\n",
      "Sampling duration: 8.23191523551941 seconds\n",
      "\n",
      "Fold 3 - New train size: 9016\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 9016 samples...\n",
      "Epoch 1/10, Train Loss: 0.3668, Accuracy: 0.8833, F1 Micro: 0.6145, F1 Macro: 0.3115\n",
      "Epoch 2/10, Train Loss: 0.245, Accuracy: 0.9036, F1 Micro: 0.676, F1 Macro: 0.4896\n",
      "Epoch 3/10, Train Loss: 0.192, Accuracy: 0.9142, F1 Micro: 0.7411, F1 Macro: 0.5666\n",
      "Epoch 4/10, Train Loss: 0.1644, Accuracy: 0.9131, F1 Micro: 0.7557, F1 Macro: 0.5942\n",
      "Epoch 5/10, Train Loss: 0.1344, Accuracy: 0.9176, F1 Micro: 0.7678, F1 Macro: 0.6195\n",
      "Epoch 6/10, Train Loss: 0.1154, Accuracy: 0.9174, F1 Micro: 0.7654, F1 Macro: 0.6119\n",
      "Epoch 7/10, Train Loss: 0.0988, Accuracy: 0.9193, F1 Micro: 0.7627, F1 Macro: 0.6138\n",
      "Epoch 8/10, Train Loss: 0.0789, Accuracy: 0.9209, F1 Micro: 0.7736, F1 Macro: 0.6264\n",
      "Epoch 9/10, Train Loss: 0.0714, Accuracy: 0.9212, F1 Micro: 0.7704, F1 Macro: 0.6203\n",
      "Epoch 10/10, Train Loss: 0.0598, Accuracy: 0.9196, F1 Micro: 0.7694, F1 Macro: 0.6257\n",
      "Best result for 9016 samples: F1 Micro: 0.7736\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.88      0.85      1142\n",
      "      Abusive       0.90      0.93      0.91      1026\n",
      "HS_Individual       0.71      0.77      0.74       723\n",
      "     HS_Group       0.72      0.65      0.68       419\n",
      "  HS_Religion       0.73      0.66      0.69       177\n",
      "      HS_Race       0.79      0.76      0.77       119\n",
      "  HS_Physical       0.00      0.00      0.00        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.74      0.80      0.77       746\n",
      "      HS_Weak       0.69      0.72      0.70       685\n",
      "  HS_Moderate       0.67      0.57      0.62       352\n",
      "    HS_Strong       0.79      0.77      0.78       105\n",
      "\n",
      "    micro avg       0.77      0.77      0.77      5634\n",
      "    macro avg       0.63      0.62      0.63      5634\n",
      " weighted avg       0.75      0.77      0.76      5634\n",
      "  samples avg       0.46      0.44      0.43      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.016475152969360356\n",
      "Samples above threshold: 152\n",
      "Acquired samples: 200\n",
      "Sampling duration: 7.313767671585083 seconds\n",
      "\n",
      "Fold 3 - New train size: 9216\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 9216 samples...\n",
      "Epoch 1/10, Train Loss: 0.3705, Accuracy: 0.8817, F1 Micro: 0.6399, F1 Macro: 0.3265\n",
      "Epoch 2/10, Train Loss: 0.2494, Accuracy: 0.9068, F1 Micro: 0.7178, F1 Macro: 0.5439\n",
      "Epoch 3/10, Train Loss: 0.2001, Accuracy: 0.914, F1 Micro: 0.7345, F1 Macro: 0.5565\n",
      "Epoch 4/10, Train Loss: 0.1685, Accuracy: 0.9163, F1 Micro: 0.7552, F1 Macro: 0.5981\n",
      "Epoch 5/10, Train Loss: 0.137, Accuracy: 0.921, F1 Micro: 0.7643, F1 Macro: 0.6143\n",
      "Epoch 6/10, Train Loss: 0.1153, Accuracy: 0.9209, F1 Micro: 0.7664, F1 Macro: 0.6171\n",
      "Epoch 7/10, Train Loss: 0.0933, Accuracy: 0.9182, F1 Micro: 0.7701, F1 Macro: 0.6238\n",
      "Epoch 8/10, Train Loss: 0.0849, Accuracy: 0.9178, F1 Micro: 0.7688, F1 Macro: 0.6211\n",
      "Epoch 9/10, Train Loss: 0.0753, Accuracy: 0.9192, F1 Micro: 0.7662, F1 Macro: 0.6313\n",
      "Epoch 10/10, Train Loss: 0.0637, Accuracy: 0.9186, F1 Micro: 0.7687, F1 Macro: 0.6305\n",
      "Best result for 9216 samples: F1 Micro: 0.7701\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.89      0.84      1142\n",
      "      Abusive       0.89      0.91      0.90      1026\n",
      "HS_Individual       0.68      0.78      0.73       723\n",
      "     HS_Group       0.73      0.65      0.69       419\n",
      "  HS_Religion       0.71      0.66      0.68       177\n",
      "      HS_Race       0.80      0.72      0.76       119\n",
      "  HS_Physical       0.00      0.00      0.00        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.71      0.82      0.76       746\n",
      "      HS_Weak       0.66      0.76      0.71       685\n",
      "  HS_Moderate       0.70      0.61      0.65       352\n",
      "    HS_Strong       0.77      0.75      0.76       105\n",
      "\n",
      "    micro avg       0.76      0.78      0.77      5634\n",
      "    macro avg       0.62      0.63      0.62      5634\n",
      " weighted avg       0.74      0.78      0.76      5634\n",
      "  samples avg       0.44      0.44      0.43      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.013576209545135498\n",
      "Samples above threshold: 133\n",
      "Acquired samples: 2\n",
      "Sampling duration: 7.102845668792725 seconds\n",
      "\n",
      "Fold 3 - New train size: 9218\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 9218 samples...\n",
      "Epoch 1/10, Train Loss: 0.3674, Accuracy: 0.8818, F1 Micro: 0.5805, F1 Macro: 0.2906\n",
      "Epoch 2/10, Train Loss: 0.2448, Accuracy: 0.9076, F1 Micro: 0.7164, F1 Macro: 0.5171\n",
      "Epoch 3/10, Train Loss: 0.1933, Accuracy: 0.915, F1 Micro: 0.747, F1 Macro: 0.5752\n",
      "Epoch 4/10, Train Loss: 0.1604, Accuracy: 0.9156, F1 Micro: 0.7592, F1 Macro: 0.5931\n",
      "Epoch 5/10, Train Loss: 0.1325, Accuracy: 0.9158, F1 Micro: 0.7635, F1 Macro: 0.5989\n",
      "Epoch 6/10, Train Loss: 0.1108, Accuracy: 0.92, F1 Micro: 0.7705, F1 Macro: 0.6198\n",
      "Epoch 7/10, Train Loss: 0.0973, Accuracy: 0.919, F1 Micro: 0.7725, F1 Macro: 0.6259\n",
      "Epoch 8/10, Train Loss: 0.0809, Accuracy: 0.9185, F1 Micro: 0.773, F1 Macro: 0.6257\n",
      "Epoch 9/10, Train Loss: 0.0722, Accuracy: 0.9165, F1 Micro: 0.7669, F1 Macro: 0.6258\n",
      "Epoch 10/10, Train Loss: 0.0617, Accuracy: 0.9198, F1 Micro: 0.7695, F1 Macro: 0.6312\n",
      "Best result for 9218 samples: F1 Micro: 0.773\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.90      0.85      1142\n",
      "      Abusive       0.90      0.92      0.91      1026\n",
      "HS_Individual       0.71      0.76      0.74       723\n",
      "     HS_Group       0.66      0.74      0.70       419\n",
      "  HS_Religion       0.74      0.59      0.65       177\n",
      "      HS_Race       0.78      0.79      0.79       119\n",
      "  HS_Physical       0.00      0.00      0.00        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.70      0.84      0.76       746\n",
      "      HS_Weak       0.69      0.73      0.71       685\n",
      "  HS_Moderate       0.60      0.69      0.64       352\n",
      "    HS_Strong       0.81      0.70      0.76       105\n",
      "\n",
      "    micro avg       0.75      0.79      0.77      5634\n",
      "    macro avg       0.62      0.64      0.63      5634\n",
      " weighted avg       0.74      0.79      0.76      5634\n",
      "  samples avg       0.45      0.45      0.43      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 0.015252697467803958\n",
      "Samples above threshold: 132\n",
      "Acquired samples: 200\n",
      "Sampling duration: 6.567776441574097 seconds\n",
      "\n",
      "Fold 3 - New train size: 9418\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 9418 samples...\n",
      "Epoch 1/10, Train Loss: 0.3718, Accuracy: 0.8821, F1 Micro: 0.5742, F1 Macro: 0.2883\n",
      "Epoch 2/10, Train Loss: 0.2457, Accuracy: 0.9071, F1 Micro: 0.7064, F1 Macro: 0.5139\n",
      "Epoch 3/10, Train Loss: 0.199, Accuracy: 0.9162, F1 Micro: 0.7363, F1 Macro: 0.5781\n",
      "Epoch 4/10, Train Loss: 0.1629, Accuracy: 0.9181, F1 Micro: 0.7607, F1 Macro: 0.6018\n",
      "Epoch 5/10, Train Loss: 0.1441, Accuracy: 0.9203, F1 Micro: 0.7693, F1 Macro: 0.6097\n",
      "Epoch 6/10, Train Loss: 0.116, Accuracy: 0.92, F1 Micro: 0.7687, F1 Macro: 0.6116\n",
      "Epoch 7/10, Train Loss: 0.1005, Accuracy: 0.9152, F1 Micro: 0.7654, F1 Macro: 0.6111\n",
      "Epoch 8/10, Train Loss: 0.0829, Accuracy: 0.9232, F1 Micro: 0.7667, F1 Macro: 0.6224\n",
      "Epoch 9/10, Train Loss: 0.0703, Accuracy: 0.9219, F1 Micro: 0.7701, F1 Macro: 0.6288\n",
      "Epoch 10/10, Train Loss: 0.0632, Accuracy: 0.9225, F1 Micro: 0.7724, F1 Macro: 0.6459\n",
      "Best result for 9418 samples: F1 Micro: 0.7724\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.85      0.85      1142\n",
      "      Abusive       0.90      0.91      0.91      1026\n",
      "HS_Individual       0.79      0.66      0.72       723\n",
      "     HS_Group       0.65      0.78      0.71       419\n",
      "  HS_Religion       0.72      0.66      0.69       177\n",
      "      HS_Race       0.81      0.72      0.76       119\n",
      "  HS_Physical       0.82      0.11      0.20        80\n",
      "    HS_Gender       1.00      0.02      0.03        60\n",
      "     HS_Other       0.78      0.76      0.77       746\n",
      "      HS_Weak       0.78      0.62      0.69       685\n",
      "  HS_Moderate       0.60      0.72      0.66       352\n",
      "    HS_Strong       0.80      0.73      0.77       105\n",
      "\n",
      "    micro avg       0.79      0.75      0.77      5634\n",
      "    macro avg       0.79      0.63      0.65      5634\n",
      " weighted avg       0.80      0.75      0.76      5634\n",
      "  samples avg       0.45      0.43      0.43      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 0.009093391895294189\n",
      "Samples above threshold: 112\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.517925977706909 seconds\n",
      "\n",
      "Fold 3 - New train size: 9618\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 9618 samples...\n",
      "Epoch 1/10, Train Loss: 0.3649, Accuracy: 0.885, F1 Micro: 0.6514, F1 Macro: 0.3607\n",
      "Epoch 2/10, Train Loss: 0.2454, Accuracy: 0.9076, F1 Micro: 0.729, F1 Macro: 0.5523\n",
      "Epoch 3/10, Train Loss: 0.1958, Accuracy: 0.9187, F1 Micro: 0.7432, F1 Macro: 0.5575\n",
      "Epoch 4/10, Train Loss: 0.1626, Accuracy: 0.9183, F1 Micro: 0.761, F1 Macro: 0.5922\n",
      "Epoch 5/10, Train Loss: 0.1349, Accuracy: 0.9222, F1 Micro: 0.7624, F1 Macro: 0.6016\n",
      "Epoch 6/10, Train Loss: 0.115, Accuracy: 0.9239, F1 Micro: 0.7784, F1 Macro: 0.6182\n",
      "Epoch 7/10, Train Loss: 0.0955, Accuracy: 0.9221, F1 Micro: 0.772, F1 Macro: 0.621\n",
      "Epoch 8/10, Train Loss: 0.0798, Accuracy: 0.9211, F1 Micro: 0.7686, F1 Macro: 0.6304\n",
      "Epoch 9/10, Train Loss: 0.0686, Accuracy: 0.9217, F1 Micro: 0.7715, F1 Macro: 0.6377\n",
      "Epoch 10/10, Train Loss: 0.063, Accuracy: 0.9233, F1 Micro: 0.7721, F1 Macro: 0.6614\n",
      "Best result for 9618 samples: F1 Micro: 0.7784\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.88      0.86      1142\n",
      "      Abusive       0.90      0.90      0.90      1026\n",
      "HS_Individual       0.72      0.78      0.75       723\n",
      "     HS_Group       0.81      0.62      0.70       419\n",
      "  HS_Religion       0.82      0.53      0.64       177\n",
      "      HS_Race       0.85      0.62      0.72       119\n",
      "  HS_Physical       0.00      0.00      0.00        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.73      0.82      0.77       746\n",
      "      HS_Weak       0.70      0.76      0.73       685\n",
      "  HS_Moderate       0.76      0.55      0.64       352\n",
      "    HS_Strong       0.80      0.64      0.71       105\n",
      "\n",
      "    micro avg       0.79      0.77      0.78      5634\n",
      "    macro avg       0.66      0.59      0.62      5634\n",
      " weighted avg       0.77      0.77      0.77      5634\n",
      "  samples avg       0.45      0.44      0.43      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 0.020444035530090332\n",
      "Samples above threshold: 92\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.874364614486694 seconds\n",
      "\n",
      "Fold 3 - New train size: 9818\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 9818 samples...\n",
      "Epoch 1/10, Train Loss: 0.3645, Accuracy: 0.888, F1 Micro: 0.6265, F1 Macro: 0.3377\n",
      "Epoch 2/10, Train Loss: 0.2496, Accuracy: 0.9098, F1 Micro: 0.7093, F1 Macro: 0.4984\n",
      "Epoch 3/10, Train Loss: 0.1983, Accuracy: 0.9131, F1 Micro: 0.7511, F1 Macro: 0.581\n",
      "Epoch 4/10, Train Loss: 0.1639, Accuracy: 0.9186, F1 Micro: 0.7553, F1 Macro: 0.5837\n",
      "Epoch 5/10, Train Loss: 0.1386, Accuracy: 0.9225, F1 Micro: 0.7739, F1 Macro: 0.6155\n",
      "Epoch 6/10, Train Loss: 0.1154, Accuracy: 0.9235, F1 Micro: 0.7759, F1 Macro: 0.6326\n",
      "Epoch 7/10, Train Loss: 0.0984, Accuracy: 0.9208, F1 Micro: 0.7641, F1 Macro: 0.6155\n",
      "Epoch 8/10, Train Loss: 0.0835, Accuracy: 0.9237, F1 Micro: 0.7818, F1 Macro: 0.6519\n",
      "Epoch 9/10, Train Loss: 0.0704, Accuracy: 0.9214, F1 Micro: 0.7783, F1 Macro: 0.6534\n",
      "Epoch 10/10, Train Loss: 0.062, Accuracy: 0.9201, F1 Micro: 0.7734, F1 Macro: 0.6633\n",
      "Best result for 9818 samples: F1 Micro: 0.7818\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.87      0.85      1142\n",
      "      Abusive       0.90      0.92      0.91      1026\n",
      "HS_Individual       0.73      0.75      0.74       723\n",
      "     HS_Group       0.72      0.72      0.72       419\n",
      "  HS_Religion       0.74      0.64      0.68       177\n",
      "      HS_Race       0.85      0.71      0.77       119\n",
      "  HS_Physical       0.64      0.11      0.19        80\n",
      "    HS_Gender       1.00      0.02      0.03        60\n",
      "     HS_Other       0.74      0.82      0.78       746\n",
      "      HS_Weak       0.71      0.72      0.72       685\n",
      "  HS_Moderate       0.67      0.66      0.66       352\n",
      "    HS_Strong       0.83      0.70      0.76       105\n",
      "\n",
      "    micro avg       0.78      0.78      0.78      5634\n",
      "    macro avg       0.78      0.64      0.65      5634\n",
      " weighted avg       0.78      0.78      0.77      5634\n",
      "  samples avg       0.45      0.44      0.43      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 0.007000041007995604\n",
      "Samples above threshold: 72\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.049659013748169 seconds\n",
      "\n",
      "Fold 3 - New train size: 10018\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 10018 samples...\n",
      "Epoch 1/10, Train Loss: 0.3688, Accuracy: 0.8764, F1 Micro: 0.5124, F1 Macro: 0.2742\n",
      "Epoch 2/10, Train Loss: 0.2506, Accuracy: 0.9071, F1 Micro: 0.6947, F1 Macro: 0.5052\n",
      "Epoch 3/10, Train Loss: 0.2015, Accuracy: 0.9162, F1 Micro: 0.7581, F1 Macro: 0.5959\n",
      "Epoch 4/10, Train Loss: 0.1682, Accuracy: 0.9227, F1 Micro: 0.7662, F1 Macro: 0.613\n",
      "Epoch 5/10, Train Loss: 0.1402, Accuracy: 0.9212, F1 Micro: 0.7744, F1 Macro: 0.6156\n",
      "Epoch 6/10, Train Loss: 0.1152, Accuracy: 0.9241, F1 Micro: 0.7772, F1 Macro: 0.6433\n",
      "Epoch 7/10, Train Loss: 0.1021, Accuracy: 0.9218, F1 Micro: 0.7719, F1 Macro: 0.6338\n",
      "Epoch 8/10, Train Loss: 0.0831, Accuracy: 0.9193, F1 Micro: 0.7721, F1 Macro: 0.6553\n",
      "Epoch 9/10, Train Loss: 0.0741, Accuracy: 0.922, F1 Micro: 0.7746, F1 Macro: 0.6719\n",
      "Epoch 10/10, Train Loss: 0.0618, Accuracy: 0.9217, F1 Micro: 0.7712, F1 Macro: 0.6601\n",
      "Best result for 10018 samples: F1 Micro: 0.7772\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.86      0.86      1142\n",
      "      Abusive       0.90      0.91      0.90      1026\n",
      "HS_Individual       0.75      0.72      0.74       723\n",
      "     HS_Group       0.72      0.68      0.70       419\n",
      "  HS_Religion       0.74      0.68      0.71       177\n",
      "      HS_Race       0.86      0.68      0.76       119\n",
      "  HS_Physical       0.89      0.10      0.18        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.77      0.76      0.77       746\n",
      "      HS_Weak       0.73      0.70      0.72       685\n",
      "  HS_Moderate       0.66      0.62      0.64       352\n",
      "    HS_Strong       0.82      0.69      0.75       105\n",
      "\n",
      "    micro avg       0.80      0.76      0.78      5634\n",
      "    macro avg       0.72      0.62      0.64      5634\n",
      " weighted avg       0.79      0.76      0.77      5634\n",
      "  samples avg       0.44      0.43      0.42      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 0.007460844516754153\n",
      "Samples above threshold: 52\n",
      "Acquired samples: 200\n",
      "Sampling duration: 3.2392642498016357 seconds\n",
      "\n",
      "Fold 3 - New train size: 10218\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 10218 samples...\n",
      "Epoch 1/10, Train Loss: 0.3655, Accuracy: 0.8889, F1 Micro: 0.6467, F1 Macro: 0.3503\n",
      "Epoch 2/10, Train Loss: 0.2461, Accuracy: 0.9111, F1 Micro: 0.7237, F1 Macro: 0.5404\n",
      "Epoch 3/10, Train Loss: 0.1962, Accuracy: 0.9175, F1 Micro: 0.7553, F1 Macro: 0.583\n",
      "Epoch 4/10, Train Loss: 0.1698, Accuracy: 0.9178, F1 Micro: 0.7665, F1 Macro: 0.6108\n",
      "Epoch 5/10, Train Loss: 0.14, Accuracy: 0.9233, F1 Micro: 0.7729, F1 Macro: 0.6162\n",
      "Epoch 6/10, Train Loss: 0.1178, Accuracy: 0.9227, F1 Micro: 0.7756, F1 Macro: 0.6292\n",
      "Epoch 7/10, Train Loss: 0.0979, Accuracy: 0.9196, F1 Micro: 0.7778, F1 Macro: 0.6405\n",
      "Epoch 8/10, Train Loss: 0.0823, Accuracy: 0.9229, F1 Micro: 0.7719, F1 Macro: 0.6624\n",
      "Epoch 9/10, Train Loss: 0.0718, Accuracy: 0.922, F1 Micro: 0.7715, F1 Macro: 0.6663\n",
      "Epoch 10/10, Train Loss: 0.0616, Accuracy: 0.9226, F1 Micro: 0.7745, F1 Macro: 0.6863\n",
      "Best result for 10218 samples: F1 Micro: 0.7778\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.91      0.85      1142\n",
      "      Abusive       0.88      0.94      0.91      1026\n",
      "HS_Individual       0.68      0.81      0.74       723\n",
      "     HS_Group       0.74      0.68      0.71       419\n",
      "  HS_Religion       0.78      0.60      0.68       177\n",
      "      HS_Race       0.79      0.71      0.75       119\n",
      "  HS_Physical       0.75      0.11      0.20        80\n",
      "    HS_Gender       0.00      0.00      0.00        60\n",
      "     HS_Other       0.71      0.86      0.78       746\n",
      "      HS_Weak       0.66      0.79      0.72       685\n",
      "  HS_Moderate       0.68      0.62      0.65       352\n",
      "    HS_Strong       0.82      0.64      0.72       105\n",
      "\n",
      "    micro avg       0.75      0.81      0.78      5634\n",
      "    macro avg       0.69      0.64      0.64      5634\n",
      " weighted avg       0.75      0.81      0.77      5634\n",
      "  samples avg       0.45      0.46      0.44      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 0.007192492485046396\n",
      "Samples above threshold: 32\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.2132391929626465 seconds\n",
      "\n",
      "Fold 3 - New train size: 10418\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 10418 samples...\n",
      "Epoch 1/10, Train Loss: 0.3686, Accuracy: 0.8896, F1 Micro: 0.6385, F1 Macro: 0.3345\n",
      "Epoch 2/10, Train Loss: 0.2478, Accuracy: 0.9129, F1 Micro: 0.7265, F1 Macro: 0.5496\n",
      "Epoch 3/10, Train Loss: 0.1973, Accuracy: 0.9197, F1 Micro: 0.7513, F1 Macro: 0.5848\n",
      "Epoch 4/10, Train Loss: 0.1658, Accuracy: 0.9216, F1 Micro: 0.7701, F1 Macro: 0.6048\n",
      "Epoch 5/10, Train Loss: 0.1372, Accuracy: 0.9233, F1 Micro: 0.7678, F1 Macro: 0.6122\n",
      "Epoch 6/10, Train Loss: 0.1173, Accuracy: 0.9202, F1 Micro: 0.7721, F1 Macro: 0.6305\n",
      "Epoch 7/10, Train Loss: 0.0962, Accuracy: 0.9257, F1 Micro: 0.776, F1 Macro: 0.6676\n",
      "Epoch 8/10, Train Loss: 0.0838, Accuracy: 0.9227, F1 Micro: 0.7775, F1 Macro: 0.6742\n",
      "Epoch 9/10, Train Loss: 0.0721, Accuracy: 0.9233, F1 Micro: 0.7796, F1 Macro: 0.6785\n",
      "Epoch 10/10, Train Loss: 0.0586, Accuracy: 0.9254, F1 Micro: 0.7789, F1 Macro: 0.6861\n",
      "Best result for 10418 samples: F1 Micro: 0.7796\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.88      0.86      1142\n",
      "      Abusive       0.91      0.91      0.91      1026\n",
      "HS_Individual       0.72      0.74      0.73       723\n",
      "     HS_Group       0.69      0.67      0.68       419\n",
      "  HS_Religion       0.71      0.62      0.66       177\n",
      "      HS_Race       0.81      0.74      0.78       119\n",
      "  HS_Physical       0.76      0.20      0.32        80\n",
      "    HS_Gender       0.79      0.18      0.30        60\n",
      "     HS_Other       0.77      0.82      0.79       746\n",
      "      HS_Weak       0.71      0.73      0.72       685\n",
      "  HS_Moderate       0.63      0.62      0.63       352\n",
      "    HS_Strong       0.84      0.71      0.77       105\n",
      "\n",
      "    micro avg       0.78      0.78      0.78      5634\n",
      "    macro avg       0.77      0.65      0.68      5634\n",
      " weighted avg       0.78      0.78      0.77      5634\n",
      "  samples avg       0.45      0.44      0.43      5634\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 0.002096176147460938\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 117\n",
      "Sampling duration: 1.6087884902954102 seconds\n",
      "\n",
      "Fold 3 - New train size: 10535\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 3 - Training with 10535 samples...\n",
      "Epoch 1/10, Train Loss: 0.3671, Accuracy: 0.8894, F1 Micro: 0.6233, F1 Macro: 0.3431\n",
      "Epoch 2/10, Train Loss: 0.2481, Accuracy: 0.9126, F1 Micro: 0.7367, F1 Macro: 0.5675\n",
      "Epoch 3/10, Train Loss: 0.2018, Accuracy: 0.9191, F1 Micro: 0.7624, F1 Macro: 0.5918\n",
      "Epoch 4/10, Train Loss: 0.1712, Accuracy: 0.9228, F1 Micro: 0.7682, F1 Macro: 0.6088\n",
      "Epoch 5/10, Train Loss: 0.1441, Accuracy: 0.922, F1 Micro: 0.7788, F1 Macro: 0.6321\n",
      "Epoch 6/10, Train Loss: 0.1171, Accuracy: 0.9209, F1 Micro: 0.7785, F1 Macro: 0.6606\n",
      "Epoch 7/10, Train Loss: 0.0984, Accuracy: 0.9264, F1 Micro: 0.7872, F1 Macro: 0.672\n",
      "Epoch 8/10, Train Loss: 0.0839, Accuracy: 0.9168, F1 Micro: 0.773, F1 Macro: 0.6816\n",
      "Epoch 9/10, Train Loss: 0.0699, Accuracy: 0.9232, F1 Micro: 0.7781, F1 Macro: 0.6978\n",
      "Epoch 10/10, Train Loss: 0.06, Accuracy: 0.9252, F1 Micro: 0.7861, F1 Macro: 0.7076\n",
      "Best result for 10535 samples: F1 Micro: 0.7872\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.87      0.86      1142\n",
      "      Abusive       0.90      0.91      0.91      1026\n",
      "HS_Individual       0.76      0.74      0.75       723\n",
      "     HS_Group       0.72      0.73      0.73       419\n",
      "  HS_Religion       0.75      0.57      0.65       177\n",
      "      HS_Race       0.83      0.69      0.75       119\n",
      "  HS_Physical       0.90      0.11      0.20        80\n",
      "    HS_Gender       0.80      0.20      0.32        60\n",
      "     HS_Other       0.76      0.82      0.79       746\n",
      "      HS_Weak       0.74      0.73      0.73       685\n",
      "  HS_Moderate       0.64      0.69      0.67       352\n",
      "    HS_Strong       0.81      0.63      0.71       105\n",
      "\n",
      "    micro avg       0.79      0.78      0.79      5634\n",
      "    macro avg       0.79      0.64      0.67      5634\n",
      " weighted avg       0.80      0.78      0.78      5634\n",
      "  samples avg       0.44      0.44      0.43      5634\n",
      "\n",
      "\n",
      "FOLD 3 COMPLETED in 6313.82 seconds\n",
      "===============================================\n",
      "STARTING FOLD 4/5\n",
      "===============================================\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 658 samples...\n",
      "Epoch 1/10, Train Loss: 0.5946, Accuracy: 0.8335, F1 Micro: 0.1121, F1 Macro: 0.0446\n",
      "Epoch 2/10, Train Loss: 0.4551, Accuracy: 0.831, F1 Micro: 0.0309, F1 Macro: 0.0129\n",
      "Epoch 3/10, Train Loss: 0.3992, Accuracy: 0.8345, F1 Micro: 0.0736, F1 Macro: 0.0279\n",
      "Epoch 4/10, Train Loss: 0.365, Accuracy: 0.8375, F1 Micro: 0.1139, F1 Macro: 0.0398\n",
      "Epoch 5/10, Train Loss: 0.3536, Accuracy: 0.8479, F1 Micro: 0.2404, F1 Macro: 0.0824\n",
      "Epoch 6/10, Train Loss: 0.3469, Accuracy: 0.8564, F1 Micro: 0.3297, F1 Macro: 0.1173\n",
      "Epoch 7/10, Train Loss: 0.3272, Accuracy: 0.8666, F1 Micro: 0.429, F1 Macro: 0.1693\n",
      "Epoch 8/10, Train Loss: 0.3093, Accuracy: 0.8769, F1 Micro: 0.534, F1 Macro: 0.2344\n",
      "Epoch 9/10, Train Loss: 0.2709, Accuracy: 0.8785, F1 Micro: 0.5631, F1 Macro: 0.2606\n",
      "Epoch 10/10, Train Loss: 0.261, Accuracy: 0.8819, F1 Micro: 0.5885, F1 Macro: 0.2918\n",
      "Best result for 658 samples: F1 Micro: 0.5885\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.75      0.77      1107\n",
      "      Abusive       0.82      0.74      0.78      1030\n",
      "HS_Individual       0.64      0.49      0.55       729\n",
      "     HS_Group       0.61      0.12      0.21       378\n",
      "  HS_Religion       0.00      0.00      0.00       167\n",
      "      HS_Race       0.00      0.00      0.00        88\n",
      "  HS_Physical       0.00      0.00      0.00        74\n",
      "    HS_Gender       0.00      0.00      0.00        75\n",
      "     HS_Other       0.66      0.58      0.62       744\n",
      "      HS_Weak       0.60      0.41      0.49       690\n",
      "  HS_Moderate       0.48      0.05      0.09       338\n",
      "    HS_Strong       0.00      0.00      0.00        79\n",
      "\n",
      "    micro avg       0.72      0.50      0.59      5499\n",
      "    macro avg       0.38      0.26      0.29      5499\n",
      " weighted avg       0.64      0.50      0.54      5499\n",
      "  samples avg       0.38      0.29      0.30      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.8369141608476639\n",
      "Samples above threshold: 988\n",
      "Acquired samples: 988\n",
      "Sampling duration: 42.34292554855347 seconds\n",
      "\n",
      "Fold 4 - New train size: 1646\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 1646 samples...\n",
      "Epoch 1/10, Train Loss: 0.4575, Accuracy: 0.8295, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.2731, Accuracy: 0.8295, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.2456, Accuracy: 0.8311, F1 Micro: 0.0194, F1 Macro: 0.0083\n",
      "Epoch 4/10, Train Loss: 0.2104, Accuracy: 0.8539, F1 Micro: 0.3368, F1 Macro: 0.127\n",
      "Epoch 5/10, Train Loss: 0.1898, Accuracy: 0.869, F1 Micro: 0.4759, F1 Macro: 0.2023\n",
      "Epoch 6/10, Train Loss: 0.1683, Accuracy: 0.8741, F1 Micro: 0.5204, F1 Macro: 0.2374\n",
      "Epoch 7/10, Train Loss: 0.146, Accuracy: 0.8782, F1 Micro: 0.5776, F1 Macro: 0.2701\n",
      "Epoch 8/10, Train Loss: 0.1348, Accuracy: 0.8799, F1 Micro: 0.5728, F1 Macro: 0.2824\n",
      "Epoch 9/10, Train Loss: 0.1122, Accuracy: 0.881, F1 Micro: 0.5991, F1 Macro: 0.3039\n",
      "Epoch 10/10, Train Loss: 0.1085, Accuracy: 0.8826, F1 Micro: 0.5975, F1 Macro: 0.3168\n",
      "Best result for 1646 samples: F1 Micro: 0.5991\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.75      0.78      1107\n",
      "      Abusive       0.80      0.78      0.79      1030\n",
      "HS_Individual       0.60      0.51      0.55       729\n",
      "     HS_Group       0.66      0.21      0.31       378\n",
      "  HS_Religion       0.00      0.00      0.00       167\n",
      "      HS_Race       0.00      0.00      0.00        88\n",
      "  HS_Physical       0.00      0.00      0.00        74\n",
      "    HS_Gender       0.00      0.00      0.00        75\n",
      "     HS_Other       0.63      0.58      0.60       744\n",
      "      HS_Weak       0.57      0.49      0.53       690\n",
      "  HS_Moderate       0.42      0.04      0.08       338\n",
      "    HS_Strong       0.00      0.00      0.00        79\n",
      "\n",
      "    micro avg       0.70      0.52      0.60      5499\n",
      "    macro avg       0.37      0.28      0.30      5499\n",
      " weighted avg       0.62      0.52      0.55      5499\n",
      "  samples avg       0.37      0.30      0.30      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.9191987127065658\n",
      "Samples above threshold: 889\n",
      "Acquired samples: 889\n",
      "Sampling duration: 37.81724810600281 seconds\n",
      "\n",
      "Fold 4 - New train size: 2535\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 2535 samples...\n",
      "Epoch 1/10, Train Loss: 0.385, Accuracy: 0.8295, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.2224, Accuracy: 0.8295, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.1954, Accuracy: 0.8382, F1 Micro: 0.1141, F1 Macro: 0.041\n",
      "Epoch 4/10, Train Loss: 0.1674, Accuracy: 0.8626, F1 Micro: 0.4023, F1 Macro: 0.1637\n",
      "Epoch 5/10, Train Loss: 0.1463, Accuracy: 0.8704, F1 Micro: 0.4913, F1 Macro: 0.2234\n",
      "Epoch 6/10, Train Loss: 0.129, Accuracy: 0.8739, F1 Micro: 0.5062, F1 Macro: 0.23\n",
      "Epoch 7/10, Train Loss: 0.1167, Accuracy: 0.8764, F1 Micro: 0.5409, F1 Macro: 0.2504\n",
      "Epoch 8/10, Train Loss: 0.0989, Accuracy: 0.8816, F1 Micro: 0.5905, F1 Macro: 0.2899\n",
      "Epoch 9/10, Train Loss: 0.0932, Accuracy: 0.8839, F1 Micro: 0.6296, F1 Macro: 0.3322\n",
      "Epoch 10/10, Train Loss: 0.0818, Accuracy: 0.8844, F1 Micro: 0.6247, F1 Macro: 0.3499\n",
      "Best result for 2535 samples: F1 Micro: 0.6296\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.79      0.81      0.80      1107\n",
      "      Abusive       0.82      0.79      0.80      1030\n",
      "HS_Individual       0.58      0.60      0.59       729\n",
      "     HS_Group       0.70      0.30      0.42       378\n",
      "  HS_Religion       0.00      0.00      0.00       167\n",
      "      HS_Race       0.00      0.00      0.00        88\n",
      "  HS_Physical       0.00      0.00      0.00        74\n",
      "    HS_Gender       0.00      0.00      0.00        75\n",
      "     HS_Other       0.63      0.69      0.65       744\n",
      "      HS_Weak       0.57      0.56      0.57       690\n",
      "  HS_Moderate       0.44      0.10      0.16       338\n",
      "    HS_Strong       0.00      0.00      0.00        79\n",
      "\n",
      "    micro avg       0.69      0.58      0.63      5499\n",
      "    macro avg       0.38      0.32      0.33      5499\n",
      " weighted avg       0.62      0.58      0.59      5499\n",
      "  samples avg       0.38      0.33      0.32      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.8954091764986516\n",
      "Samples above threshold: 800\n",
      "Acquired samples: 800\n",
      "Sampling duration: 34.87182068824768 seconds\n",
      "\n",
      "Fold 4 - New train size: 3335\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 3335 samples...\n",
      "Epoch 1/10, Train Loss: 0.3464, Accuracy: 0.8295, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.1958, Accuracy: 0.8295, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.1785, Accuracy: 0.8321, F1 Micro: 0.0304, F1 Macro: 0.0127\n",
      "Epoch 4/10, Train Loss: 0.1538, Accuracy: 0.8714, F1 Micro: 0.5289, F1 Macro: 0.2389\n",
      "Epoch 5/10, Train Loss: 0.1345, Accuracy: 0.8785, F1 Micro: 0.5878, F1 Macro: 0.2666\n",
      "Epoch 6/10, Train Loss: 0.1116, Accuracy: 0.8819, F1 Micro: 0.6094, F1 Macro: 0.2869\n",
      "Epoch 7/10, Train Loss: 0.102, Accuracy: 0.8848, F1 Micro: 0.6156, F1 Macro: 0.288\n",
      "Epoch 8/10, Train Loss: 0.0872, Accuracy: 0.8852, F1 Micro: 0.6147, F1 Macro: 0.341\n",
      "Epoch 9/10, Train Loss: 0.0745, Accuracy: 0.8878, F1 Micro: 0.6426, F1 Macro: 0.3785\n",
      "Epoch 10/10, Train Loss: 0.0676, Accuracy: 0.891, F1 Micro: 0.6393, F1 Macro: 0.3467\n",
      "Best result for 3335 samples: F1 Micro: 0.6426\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.80      0.80      1107\n",
      "      Abusive       0.87      0.74      0.80      1030\n",
      "HS_Individual       0.62      0.57      0.59       729\n",
      "     HS_Group       0.59      0.45      0.51       378\n",
      "  HS_Religion       0.54      0.08      0.15       167\n",
      "      HS_Race       1.00      0.02      0.04        88\n",
      "  HS_Physical       0.00      0.00      0.00        74\n",
      "    HS_Gender       0.00      0.00      0.00        75\n",
      "     HS_Other       0.66      0.68      0.67       744\n",
      "      HS_Weak       0.57      0.56      0.57       690\n",
      "  HS_Moderate       0.55      0.34      0.42       338\n",
      "    HS_Strong       0.00      0.00      0.00        79\n",
      "\n",
      "    micro avg       0.70      0.59      0.64      5499\n",
      "    macro avg       0.52      0.35      0.38      5499\n",
      " weighted avg       0.67      0.59      0.62      5499\n",
      "  samples avg       0.38      0.33      0.33      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.8703422725200654\n",
      "Samples above threshold: 720\n",
      "Acquired samples: 720\n",
      "Sampling duration: 31.16408610343933 seconds\n",
      "\n",
      "Fold 4 - New train size: 4055\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 4055 samples...\n",
      "Epoch 1/10, Train Loss: 0.3273, Accuracy: 0.8295, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.194, Accuracy: 0.8295, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.1828, Accuracy: 0.8335, F1 Micro: 0.0462, F1 Macro: 0.0188\n",
      "Epoch 4/10, Train Loss: 0.15, Accuracy: 0.87, F1 Micro: 0.4774, F1 Macro: 0.2107\n",
      "Epoch 5/10, Train Loss: 0.1291, Accuracy: 0.8794, F1 Micro: 0.5689, F1 Macro: 0.2611\n",
      "Epoch 6/10, Train Loss: 0.1173, Accuracy: 0.8828, F1 Micro: 0.6196, F1 Macro: 0.297\n",
      "Epoch 7/10, Train Loss: 0.0935, Accuracy: 0.8862, F1 Micro: 0.6524, F1 Macro: 0.3657\n",
      "Epoch 8/10, Train Loss: 0.0838, Accuracy: 0.889, F1 Micro: 0.6672, F1 Macro: 0.3957\n",
      "Epoch 9/10, Train Loss: 0.0628, Accuracy: 0.8897, F1 Micro: 0.6711, F1 Macro: 0.3915\n",
      "Epoch 10/10, Train Loss: 0.0593, Accuracy: 0.8925, F1 Micro: 0.6559, F1 Macro: 0.4302\n",
      "Best result for 4055 samples: F1 Micro: 0.6711\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.79      0.85      0.82      1107\n",
      "      Abusive       0.86      0.81      0.83      1030\n",
      "HS_Individual       0.59      0.74      0.65       729\n",
      "     HS_Group       0.65      0.32      0.43       378\n",
      "  HS_Religion       0.69      0.12      0.20       167\n",
      "      HS_Race       0.86      0.07      0.13        88\n",
      "  HS_Physical       0.00      0.00      0.00        74\n",
      "    HS_Gender       0.00      0.00      0.00        75\n",
      "     HS_Other       0.61      0.83      0.71       744\n",
      "      HS_Weak       0.56      0.69      0.62       690\n",
      "  HS_Moderate       0.50      0.22      0.31       338\n",
      "    HS_Strong       0.00      0.00      0.00        79\n",
      "\n",
      "    micro avg       0.68      0.66      0.67      5499\n",
      "    macro avg       0.51      0.39      0.39      5499\n",
      " weighted avg       0.66      0.66      0.64      5499\n",
      "  samples avg       0.40      0.37      0.37      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.5225769758224488\n",
      "Samples above threshold: 648\n",
      "Acquired samples: 648\n",
      "Sampling duration: 28.09532880783081 seconds\n",
      "\n",
      "Fold 4 - New train size: 4703\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 4703 samples...\n",
      "Epoch 1/10, Train Loss: 0.3154, Accuracy: 0.8295, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.2043, Accuracy: 0.8295, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.1887, Accuracy: 0.847, F1 Micro: 0.1982, F1 Macro: 0.0792\n",
      "Epoch 4/10, Train Loss: 0.1559, Accuracy: 0.8812, F1 Micro: 0.5755, F1 Macro: 0.2646\n",
      "Epoch 5/10, Train Loss: 0.1296, Accuracy: 0.8843, F1 Micro: 0.6065, F1 Macro: 0.3154\n",
      "Epoch 6/10, Train Loss: 0.1074, Accuracy: 0.8892, F1 Micro: 0.6229, F1 Macro: 0.3503\n",
      "Epoch 7/10, Train Loss: 0.0938, Accuracy: 0.8913, F1 Micro: 0.6696, F1 Macro: 0.4188\n",
      "Epoch 8/10, Train Loss: 0.0751, Accuracy: 0.892, F1 Micro: 0.6705, F1 Macro: 0.3865\n",
      "Epoch 9/10, Train Loss: 0.0582, Accuracy: 0.8962, F1 Micro: 0.657, F1 Macro: 0.4173\n",
      "Epoch 10/10, Train Loss: 0.0572, Accuracy: 0.8924, F1 Micro: 0.6886, F1 Macro: 0.4261\n",
      "Best result for 4703 samples: F1 Micro: 0.6886\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.78      0.86      0.82      1107\n",
      "      Abusive       0.86      0.86      0.86      1030\n",
      "HS_Individual       0.59      0.77      0.67       729\n",
      "     HS_Group       0.65      0.42      0.51       378\n",
      "  HS_Religion       0.65      0.26      0.37       167\n",
      "      HS_Race       0.70      0.08      0.14        88\n",
      "  HS_Physical       0.00      0.00      0.00        74\n",
      "    HS_Gender       0.00      0.00      0.00        75\n",
      "     HS_Other       0.62      0.80      0.70       744\n",
      "      HS_Weak       0.56      0.76      0.64       690\n",
      "  HS_Moderate       0.53      0.33      0.41       338\n",
      "    HS_Strong       0.00      0.00      0.00        79\n",
      "\n",
      "    micro avg       0.68      0.70      0.69      5499\n",
      "    macro avg       0.49      0.43      0.43      5499\n",
      " weighted avg       0.66      0.70      0.66      5499\n",
      "  samples avg       0.41      0.40      0.38      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.13267954587936434\n",
      "Samples above threshold: 584\n",
      "Acquired samples: 584\n",
      "Sampling duration: 25.408425331115723 seconds\n",
      "\n",
      "Fold 4 - New train size: 5287\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 5287 samples...\n",
      "Epoch 1/10, Train Loss: 0.3147, Accuracy: 0.8295, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.2148, Accuracy: 0.8295, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.1902, Accuracy: 0.8697, F1 Micro: 0.4443, F1 Macro: 0.1876\n",
      "Epoch 4/10, Train Loss: 0.157, Accuracy: 0.8797, F1 Micro: 0.5303, F1 Macro: 0.2535\n",
      "Epoch 5/10, Train Loss: 0.1372, Accuracy: 0.8935, F1 Micro: 0.6808, F1 Macro: 0.3966\n",
      "Epoch 6/10, Train Loss: 0.1073, Accuracy: 0.8977, F1 Micro: 0.6699, F1 Macro: 0.4162\n",
      "Epoch 7/10, Train Loss: 0.0861, Accuracy: 0.9008, F1 Micro: 0.6902, F1 Macro: 0.4628\n",
      "Epoch 8/10, Train Loss: 0.0718, Accuracy: 0.8998, F1 Micro: 0.7066, F1 Macro: 0.4373\n",
      "Epoch 9/10, Train Loss: 0.0624, Accuracy: 0.9036, F1 Micro: 0.7046, F1 Macro: 0.4586\n",
      "Epoch 10/10, Train Loss: 0.0529, Accuracy: 0.9063, F1 Micro: 0.7132, F1 Macro: 0.4883\n",
      "Best result for 5287 samples: F1 Micro: 0.7132\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.82      0.83      1107\n",
      "      Abusive       0.92      0.83      0.87      1030\n",
      "HS_Individual       0.66      0.71      0.68       729\n",
      "     HS_Group       0.70      0.49      0.58       378\n",
      "  HS_Religion       0.73      0.51      0.60       167\n",
      "      HS_Race       0.84      0.31      0.45        88\n",
      "  HS_Physical       0.00      0.00      0.00        74\n",
      "    HS_Gender       0.00      0.00      0.00        75\n",
      "     HS_Other       0.69      0.76      0.72       744\n",
      "      HS_Weak       0.62      0.70      0.66       690\n",
      "  HS_Moderate       0.58      0.40      0.47       338\n",
      "    HS_Strong       0.00      0.00      0.00        79\n",
      "\n",
      "    micro avg       0.75      0.68      0.71      5499\n",
      "    macro avg       0.55      0.46      0.49      5499\n",
      " weighted avg       0.72      0.68      0.69      5499\n",
      "  samples avg       0.41      0.39      0.38      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.14900974035263073\n",
      "Samples above threshold: 525\n",
      "Acquired samples: 525\n",
      "Sampling duration: 23.645703315734863 seconds\n",
      "\n",
      "Fold 4 - New train size: 5812\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 5812 samples...\n",
      "Epoch 1/10, Train Loss: 0.3165, Accuracy: 0.8295, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.2278, Accuracy: 0.8435, F1 Micro: 0.1703, F1 Macro: 0.0601\n",
      "Epoch 3/10, Train Loss: 0.1997, Accuracy: 0.878, F1 Micro: 0.5331, F1 Macro: 0.2645\n",
      "Epoch 4/10, Train Loss: 0.167, Accuracy: 0.8941, F1 Micro: 0.6381, F1 Macro: 0.3757\n",
      "Epoch 5/10, Train Loss: 0.1339, Accuracy: 0.8989, F1 Micro: 0.6806, F1 Macro: 0.4272\n",
      "Epoch 6/10, Train Loss: 0.1116, Accuracy: 0.8988, F1 Micro: 0.7122, F1 Macro: 0.4759\n",
      "Epoch 7/10, Train Loss: 0.0921, Accuracy: 0.9054, F1 Micro: 0.7065, F1 Macro: 0.4843\n",
      "Epoch 8/10, Train Loss: 0.0767, Accuracy: 0.9058, F1 Micro: 0.7063, F1 Macro: 0.4822\n",
      "Epoch 9/10, Train Loss: 0.0651, Accuracy: 0.9056, F1 Micro: 0.7214, F1 Macro: 0.499\n",
      "Epoch 10/10, Train Loss: 0.0586, Accuracy: 0.9024, F1 Micro: 0.7126, F1 Macro: 0.486\n",
      "Best result for 5812 samples: F1 Micro: 0.7214\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.81      0.86      0.83      1107\n",
      "      Abusive       0.91      0.89      0.90      1030\n",
      "HS_Individual       0.67      0.68      0.67       729\n",
      "     HS_Group       0.62      0.58      0.60       378\n",
      "  HS_Religion       0.68      0.55      0.61       167\n",
      "      HS_Race       0.60      0.40      0.48        88\n",
      "  HS_Physical       0.00      0.00      0.00        74\n",
      "    HS_Gender       0.00      0.00      0.00        75\n",
      "     HS_Other       0.68      0.80      0.73       744\n",
      "      HS_Weak       0.63      0.68      0.65       690\n",
      "  HS_Moderate       0.52      0.51      0.51       338\n",
      "    HS_Strong       0.00      0.00      0.00        79\n",
      "\n",
      "    micro avg       0.73      0.72      0.72      5499\n",
      "    macro avg       0.51      0.50      0.50      5499\n",
      " weighted avg       0.70      0.72      0.71      5499\n",
      "  samples avg       0.42      0.41      0.40      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.06318249702453614\n",
      "Samples above threshold: 473\n",
      "Acquired samples: 473\n",
      "Sampling duration: 20.80338716506958 seconds\n",
      "\n",
      "Fold 4 - New train size: 6285\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 6285 samples...\n",
      "Epoch 1/10, Train Loss: 0.3237, Accuracy: 0.8295, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.2353, Accuracy: 0.8587, F1 Micro: 0.3156, F1 Macro: 0.1302\n",
      "Epoch 3/10, Train Loss: 0.1883, Accuracy: 0.8941, F1 Micro: 0.6459, F1 Macro: 0.3698\n",
      "Epoch 4/10, Train Loss: 0.1633, Accuracy: 0.9006, F1 Micro: 0.7044, F1 Macro: 0.461\n",
      "Epoch 5/10, Train Loss: 0.1238, Accuracy: 0.9041, F1 Micro: 0.7019, F1 Macro: 0.441\n",
      "Epoch 6/10, Train Loss: 0.0993, Accuracy: 0.9031, F1 Micro: 0.6822, F1 Macro: 0.4478\n",
      "Epoch 7/10, Train Loss: 0.0913, Accuracy: 0.9083, F1 Micro: 0.7139, F1 Macro: 0.4894\n",
      "Epoch 8/10, Train Loss: 0.0778, Accuracy: 0.9032, F1 Micro: 0.7214, F1 Macro: 0.4921\n",
      "Epoch 9/10, Train Loss: 0.0625, Accuracy: 0.9065, F1 Micro: 0.7235, F1 Macro: 0.485\n",
      "Epoch 10/10, Train Loss: 0.0537, Accuracy: 0.9103, F1 Micro: 0.7258, F1 Macro: 0.4946\n",
      "Best result for 6285 samples: F1 Micro: 0.7258\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.83      0.84      1107\n",
      "      Abusive       0.89      0.90      0.89      1030\n",
      "HS_Individual       0.68      0.70      0.69       729\n",
      "     HS_Group       0.70      0.47      0.56       378\n",
      "  HS_Religion       0.81      0.46      0.58       167\n",
      "      HS_Race       0.82      0.35      0.49        88\n",
      "  HS_Physical       0.00      0.00      0.00        74\n",
      "    HS_Gender       0.00      0.00      0.00        75\n",
      "     HS_Other       0.71      0.80      0.75       744\n",
      "      HS_Weak       0.65      0.68      0.66       690\n",
      "  HS_Moderate       0.55      0.40      0.46       338\n",
      "    HS_Strong       0.00      0.00      0.00        79\n",
      "\n",
      "    micro avg       0.76      0.70      0.73      5499\n",
      "    macro avg       0.55      0.46      0.49      5499\n",
      " weighted avg       0.72      0.70      0.70      5499\n",
      "  samples avg       0.43      0.40      0.40      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.052953249216079704\n",
      "Samples above threshold: 425\n",
      "Acquired samples: 299\n",
      "Sampling duration: 18.913517475128174 seconds\n",
      "\n",
      "Fold 4 - New train size: 6584\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 6584 samples...\n",
      "Epoch 1/10, Train Loss: 0.3332, Accuracy: 0.8296, F1 Micro: 0.0004, F1 Macro: 0.0002\n",
      "Epoch 2/10, Train Loss: 0.2414, Accuracy: 0.875, F1 Micro: 0.4805, F1 Macro: 0.2208\n",
      "Epoch 3/10, Train Loss: 0.1968, Accuracy: 0.8987, F1 Micro: 0.6875, F1 Macro: 0.4604\n",
      "Epoch 4/10, Train Loss: 0.1621, Accuracy: 0.9055, F1 Micro: 0.6901, F1 Macro: 0.4915\n",
      "Epoch 5/10, Train Loss: 0.128, Accuracy: 0.9076, F1 Micro: 0.7328, F1 Macro: 0.554\n",
      "Epoch 6/10, Train Loss: 0.1125, Accuracy: 0.91, F1 Micro: 0.7313, F1 Macro: 0.5446\n",
      "Epoch 7/10, Train Loss: 0.088, Accuracy: 0.91, F1 Micro: 0.7363, F1 Macro: 0.5587\n",
      "Epoch 8/10, Train Loss: 0.0727, Accuracy: 0.9115, F1 Micro: 0.7327, F1 Macro: 0.5457\n",
      "Epoch 9/10, Train Loss: 0.0599, Accuracy: 0.9121, F1 Micro: 0.721, F1 Macro: 0.5307\n",
      "Epoch 10/10, Train Loss: 0.0541, Accuracy: 0.9149, F1 Micro: 0.734, F1 Macro: 0.5625\n",
      "Best result for 6584 samples: F1 Micro: 0.7363\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.81      0.89      0.85      1107\n",
      "      Abusive       0.90      0.87      0.88      1030\n",
      "HS_Individual       0.66      0.74      0.70       729\n",
      "     HS_Group       0.66      0.53      0.59       378\n",
      "  HS_Religion       0.65      0.54      0.59       167\n",
      "      HS_Race       0.72      0.49      0.58        88\n",
      "  HS_Physical       0.00      0.00      0.00        74\n",
      "    HS_Gender       0.00      0.00      0.00        75\n",
      "     HS_Other       0.69      0.83      0.75       744\n",
      "      HS_Weak       0.64      0.74      0.68       690\n",
      "  HS_Moderate       0.57      0.39      0.46       338\n",
      "    HS_Strong       0.80      0.49      0.61        79\n",
      "\n",
      "    micro avg       0.74      0.74      0.74      5499\n",
      "    macro avg       0.59      0.54      0.56      5499\n",
      " weighted avg       0.72      0.74      0.72      5499\n",
      "  samples avg       0.43      0.41      0.40      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 0.056912899017333984\n",
      "Samples above threshold: 396\n",
      "Acquired samples: 396\n",
      "Sampling duration: 17.49073839187622 seconds\n",
      "\n",
      "Fold 4 - New train size: 6980\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 6980 samples...\n",
      "Epoch 1/10, Train Loss: 0.3432, Accuracy: 0.8391, F1 Micro: 0.1173, F1 Macro: 0.0492\n",
      "Epoch 2/10, Train Loss: 0.2407, Accuracy: 0.8892, F1 Micro: 0.6178, F1 Macro: 0.3866\n",
      "Epoch 3/10, Train Loss: 0.1983, Accuracy: 0.9032, F1 Micro: 0.6816, F1 Macro: 0.4502\n",
      "Epoch 4/10, Train Loss: 0.1566, Accuracy: 0.9095, F1 Micro: 0.7073, F1 Macro: 0.5201\n",
      "Epoch 5/10, Train Loss: 0.1303, Accuracy: 0.9085, F1 Micro: 0.7229, F1 Macro: 0.5133\n",
      "Epoch 6/10, Train Loss: 0.1064, Accuracy: 0.9101, F1 Micro: 0.7322, F1 Macro: 0.5371\n",
      "Epoch 7/10, Train Loss: 0.0886, Accuracy: 0.9132, F1 Micro: 0.7383, F1 Macro: 0.5545\n",
      "Epoch 8/10, Train Loss: 0.0742, Accuracy: 0.9149, F1 Micro: 0.7412, F1 Macro: 0.563\n",
      "Epoch 9/10, Train Loss: 0.0643, Accuracy: 0.9148, F1 Micro: 0.7438, F1 Macro: 0.5729\n",
      "Epoch 10/10, Train Loss: 0.0556, Accuracy: 0.9126, F1 Micro: 0.7415, F1 Macro: 0.5783\n",
      "Best result for 6980 samples: F1 Micro: 0.7438\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.86      0.85      1107\n",
      "      Abusive       0.91      0.88      0.89      1030\n",
      "HS_Individual       0.71      0.67      0.69       729\n",
      "     HS_Group       0.65      0.65      0.65       378\n",
      "  HS_Religion       0.71      0.53      0.61       167\n",
      "      HS_Race       0.77      0.39      0.52        88\n",
      "  HS_Physical       0.00      0.00      0.00        74\n",
      "    HS_Gender       0.00      0.00      0.00        75\n",
      "     HS_Other       0.71      0.81      0.76       744\n",
      "      HS_Weak       0.68      0.64      0.66       690\n",
      "  HS_Moderate       0.60      0.53      0.56       338\n",
      "    HS_Strong       0.75      0.62      0.68        79\n",
      "\n",
      "    micro avg       0.76      0.73      0.74      5499\n",
      "    macro avg       0.61      0.55      0.57      5499\n",
      " weighted avg       0.74      0.73      0.73      5499\n",
      "  samples avg       0.43      0.41      0.40      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 0.038697528839111324\n",
      "Samples above threshold: 356\n",
      "Acquired samples: 356\n",
      "Sampling duration: 15.762675762176514 seconds\n",
      "\n",
      "Fold 4 - New train size: 7336\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 7336 samples...\n",
      "Epoch 1/10, Train Loss: 0.3551, Accuracy: 0.8488, F1 Micro: 0.2398, F1 Macro: 0.0938\n",
      "Epoch 2/10, Train Loss: 0.2413, Accuracy: 0.8942, F1 Micro: 0.6216, F1 Macro: 0.3796\n",
      "Epoch 3/10, Train Loss: 0.1934, Accuracy: 0.9086, F1 Micro: 0.7119, F1 Macro: 0.546\n",
      "Epoch 4/10, Train Loss: 0.1548, Accuracy: 0.9118, F1 Micro: 0.7404, F1 Macro: 0.559\n",
      "Epoch 5/10, Train Loss: 0.1304, Accuracy: 0.9142, F1 Micro: 0.741, F1 Macro: 0.5611\n",
      "Epoch 6/10, Train Loss: 0.107, Accuracy: 0.916, F1 Micro: 0.749, F1 Macro: 0.5612\n",
      "Epoch 7/10, Train Loss: 0.0904, Accuracy: 0.9157, F1 Micro: 0.7432, F1 Macro: 0.5713\n",
      "Epoch 8/10, Train Loss: 0.076, Accuracy: 0.9166, F1 Micro: 0.7575, F1 Macro: 0.592\n",
      "Epoch 9/10, Train Loss: 0.0634, Accuracy: 0.9179, F1 Micro: 0.7547, F1 Macro: 0.5862\n",
      "Epoch 10/10, Train Loss: 0.056, Accuracy: 0.919, F1 Micro: 0.7552, F1 Macro: 0.5898\n",
      "Best result for 7336 samples: F1 Micro: 0.7575\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.88      0.85      1107\n",
      "      Abusive       0.90      0.90      0.90      1030\n",
      "HS_Individual       0.68      0.79      0.73       729\n",
      "     HS_Group       0.71      0.58      0.64       378\n",
      "  HS_Religion       0.75      0.52      0.61       167\n",
      "      HS_Race       0.76      0.59      0.67        88\n",
      "  HS_Physical       0.00      0.00      0.00        74\n",
      "    HS_Gender       0.00      0.00      0.00        75\n",
      "     HS_Other       0.71      0.84      0.77       744\n",
      "      HS_Weak       0.65      0.77      0.70       690\n",
      "  HS_Moderate       0.61      0.46      0.52       338\n",
      "    HS_Strong       0.76      0.67      0.71        79\n",
      "\n",
      "    micro avg       0.75      0.76      0.76      5499\n",
      "    macro avg       0.61      0.58      0.59      5499\n",
      " weighted avg       0.73      0.76      0.74      5499\n",
      "  samples avg       0.43      0.43      0.41      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 0.03398123979568482\n",
      "Samples above threshold: 320\n",
      "Acquired samples: 320\n",
      "Sampling duration: 14.159948825836182 seconds\n",
      "\n",
      "Fold 4 - New train size: 7656\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 7656 samples...\n",
      "Epoch 1/10, Train Loss: 0.3571, Accuracy: 0.8541, F1 Micro: 0.2839, F1 Macro: 0.11\n",
      "Epoch 2/10, Train Loss: 0.2402, Accuracy: 0.8907, F1 Micro: 0.5969, F1 Macro: 0.357\n",
      "Epoch 3/10, Train Loss: 0.1944, Accuracy: 0.9094, F1 Micro: 0.7052, F1 Macro: 0.5227\n",
      "Epoch 4/10, Train Loss: 0.1585, Accuracy: 0.9144, F1 Micro: 0.7402, F1 Macro: 0.5722\n",
      "Epoch 5/10, Train Loss: 0.1332, Accuracy: 0.9126, F1 Micro: 0.75, F1 Macro: 0.5768\n",
      "Epoch 6/10, Train Loss: 0.114, Accuracy: 0.9185, F1 Micro: 0.7489, F1 Macro: 0.5839\n",
      "Epoch 7/10, Train Loss: 0.0919, Accuracy: 0.9184, F1 Micro: 0.7491, F1 Macro: 0.5802\n",
      "Epoch 8/10, Train Loss: 0.0787, Accuracy: 0.9177, F1 Micro: 0.7528, F1 Macro: 0.583\n",
      "Epoch 9/10, Train Loss: 0.0659, Accuracy: 0.919, F1 Micro: 0.7564, F1 Macro: 0.5838\n",
      "Epoch 10/10, Train Loss: 0.0553, Accuracy: 0.9196, F1 Micro: 0.7632, F1 Macro: 0.6002\n",
      "Best result for 7656 samples: F1 Micro: 0.7632\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.87      0.85      1107\n",
      "      Abusive       0.89      0.92      0.90      1030\n",
      "HS_Individual       0.71      0.73      0.72       729\n",
      "     HS_Group       0.68      0.64      0.66       378\n",
      "  HS_Religion       0.73      0.60      0.66       167\n",
      "      HS_Race       0.74      0.58      0.65        88\n",
      "  HS_Physical       0.00      0.00      0.00        74\n",
      "    HS_Gender       0.00      0.00      0.00        75\n",
      "     HS_Other       0.75      0.83      0.79       744\n",
      "      HS_Weak       0.69      0.69      0.69       690\n",
      "  HS_Moderate       0.63      0.54      0.58       338\n",
      "    HS_Strong       0.72      0.68      0.70        79\n",
      "\n",
      "    micro avg       0.77      0.76      0.76      5499\n",
      "    macro avg       0.61      0.59      0.60      5499\n",
      " weighted avg       0.74      0.76      0.75      5499\n",
      "  samples avg       0.44      0.43      0.42      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 0.023992919921875\n",
      "Samples above threshold: 288\n",
      "Acquired samples: 245\n",
      "Sampling duration: 13.208529710769653 seconds\n",
      "\n",
      "Fold 4 - New train size: 7901\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 7901 samples...\n",
      "Epoch 1/10, Train Loss: 0.3657, Accuracy: 0.8673, F1 Micro: 0.4279, F1 Macro: 0.1766\n",
      "Epoch 2/10, Train Loss: 0.2391, Accuracy: 0.898, F1 Micro: 0.6444, F1 Macro: 0.3932\n",
      "Epoch 3/10, Train Loss: 0.1909, Accuracy: 0.9136, F1 Micro: 0.7345, F1 Macro: 0.5686\n",
      "Epoch 4/10, Train Loss: 0.1568, Accuracy: 0.9166, F1 Micro: 0.7469, F1 Macro: 0.5742\n",
      "Epoch 5/10, Train Loss: 0.1278, Accuracy: 0.9157, F1 Micro: 0.7522, F1 Macro: 0.5903\n",
      "Epoch 6/10, Train Loss: 0.1099, Accuracy: 0.9156, F1 Micro: 0.7541, F1 Macro: 0.5844\n",
      "Epoch 7/10, Train Loss: 0.0928, Accuracy: 0.9186, F1 Micro: 0.7647, F1 Macro: 0.6039\n",
      "Epoch 8/10, Train Loss: 0.0781, Accuracy: 0.9222, F1 Micro: 0.7552, F1 Macro: 0.5996\n",
      "Epoch 9/10, Train Loss: 0.068, Accuracy: 0.9184, F1 Micro: 0.7605, F1 Macro: 0.5895\n",
      "Epoch 10/10, Train Loss: 0.0568, Accuracy: 0.9196, F1 Micro: 0.7601, F1 Macro: 0.5873\n",
      "Best result for 7901 samples: F1 Micro: 0.7647\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.91      0.85      1107\n",
      "      Abusive       0.87      0.93      0.90      1030\n",
      "HS_Individual       0.71      0.75      0.73       729\n",
      "     HS_Group       0.66      0.67      0.66       378\n",
      "  HS_Religion       0.69      0.60      0.64       167\n",
      "      HS_Race       0.75      0.65      0.70        88\n",
      "  HS_Physical       0.00      0.00      0.00        74\n",
      "    HS_Gender       0.00      0.00      0.00        75\n",
      "     HS_Other       0.75      0.79      0.77       744\n",
      "      HS_Weak       0.68      0.74      0.71       690\n",
      "  HS_Moderate       0.62      0.57      0.59       338\n",
      "    HS_Strong       0.73      0.67      0.70        79\n",
      "\n",
      "    micro avg       0.75      0.78      0.76      5499\n",
      "    macro avg       0.60      0.61      0.60      5499\n",
      " weighted avg       0.73      0.78      0.75      5499\n",
      "  samples avg       0.44      0.44      0.42      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.027389705181121854\n",
      "Samples above threshold: 264\n",
      "Acquired samples: 264\n",
      "Sampling duration: 11.777536869049072 seconds\n",
      "\n",
      "Fold 4 - New train size: 8165\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 8165 samples...\n",
      "Epoch 1/10, Train Loss: 0.3648, Accuracy: 0.8774, F1 Micro: 0.5231, F1 Macro: 0.2358\n",
      "Epoch 2/10, Train Loss: 0.2407, Accuracy: 0.9058, F1 Micro: 0.6966, F1 Macro: 0.496\n",
      "Epoch 3/10, Train Loss: 0.1907, Accuracy: 0.9107, F1 Micro: 0.7346, F1 Macro: 0.5301\n",
      "Epoch 4/10, Train Loss: 0.1534, Accuracy: 0.9198, F1 Micro: 0.7575, F1 Macro: 0.5837\n",
      "Epoch 5/10, Train Loss: 0.1299, Accuracy: 0.9188, F1 Micro: 0.7451, F1 Macro: 0.5826\n",
      "Epoch 6/10, Train Loss: 0.1084, Accuracy: 0.9211, F1 Micro: 0.7559, F1 Macro: 0.5899\n",
      "Epoch 7/10, Train Loss: 0.0955, Accuracy: 0.9202, F1 Micro: 0.765, F1 Macro: 0.6044\n",
      "Epoch 8/10, Train Loss: 0.0795, Accuracy: 0.9219, F1 Micro: 0.7525, F1 Macro: 0.5946\n",
      "Epoch 9/10, Train Loss: 0.0701, Accuracy: 0.9205, F1 Micro: 0.765, F1 Macro: 0.6147\n",
      "Epoch 10/10, Train Loss: 0.0593, Accuracy: 0.9205, F1 Micro: 0.7607, F1 Macro: 0.6038\n",
      "Best result for 8165 samples: F1 Micro: 0.765\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.87      0.85      1107\n",
      "      Abusive       0.89      0.93      0.91      1030\n",
      "HS_Individual       0.71      0.72      0.72       729\n",
      "     HS_Group       0.67      0.66      0.66       378\n",
      "  HS_Religion       0.74      0.64      0.69       167\n",
      "      HS_Race       0.74      0.59      0.66        88\n",
      "  HS_Physical       0.00      0.00      0.00        74\n",
      "    HS_Gender       0.00      0.00      0.00        75\n",
      "     HS_Other       0.74      0.81      0.77       744\n",
      "      HS_Weak       0.68      0.69      0.69       690\n",
      "  HS_Moderate       0.64      0.60      0.62       338\n",
      "    HS_Strong       0.75      0.63      0.68        79\n",
      "\n",
      "    micro avg       0.77      0.76      0.77      5499\n",
      "    macro avg       0.62      0.60      0.60      5499\n",
      " weighted avg       0.75      0.76      0.75      5499\n",
      "  samples avg       0.44      0.43      0.41      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.027940201759338378\n",
      "Samples above threshold: 237\n",
      "Acquired samples: 237\n",
      "Sampling duration: 10.782711029052734 seconds\n",
      "\n",
      "Fold 4 - New train size: 8402\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 8402 samples...\n",
      "Epoch 1/10, Train Loss: 0.364, Accuracy: 0.8807, F1 Micro: 0.5492, F1 Macro: 0.2528\n",
      "Epoch 2/10, Train Loss: 0.2431, Accuracy: 0.906, F1 Micro: 0.7062, F1 Macro: 0.5134\n",
      "Epoch 3/10, Train Loss: 0.1906, Accuracy: 0.912, F1 Micro: 0.7089, F1 Macro: 0.5203\n",
      "Epoch 4/10, Train Loss: 0.1619, Accuracy: 0.9186, F1 Micro: 0.7571, F1 Macro: 0.5959\n",
      "Epoch 5/10, Train Loss: 0.1324, Accuracy: 0.9208, F1 Micro: 0.7586, F1 Macro: 0.5966\n",
      "Epoch 6/10, Train Loss: 0.1066, Accuracy: 0.9181, F1 Micro: 0.7594, F1 Macro: 0.6033\n",
      "Epoch 7/10, Train Loss: 0.0945, Accuracy: 0.9218, F1 Micro: 0.7659, F1 Macro: 0.6003\n",
      "Epoch 8/10, Train Loss: 0.0778, Accuracy: 0.9219, F1 Micro: 0.7682, F1 Macro: 0.6031\n",
      "Epoch 9/10, Train Loss: 0.0695, Accuracy: 0.9229, F1 Micro: 0.7631, F1 Macro: 0.6134\n",
      "Epoch 10/10, Train Loss: 0.0584, Accuracy: 0.9237, F1 Micro: 0.773, F1 Macro: 0.6229\n",
      "Best result for 8402 samples: F1 Micro: 0.773\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.86      0.85      1107\n",
      "      Abusive       0.88      0.93      0.91      1030\n",
      "HS_Individual       0.74      0.75      0.75       729\n",
      "     HS_Group       0.70      0.63      0.66       378\n",
      "  HS_Religion       0.80      0.61      0.69       167\n",
      "      HS_Race       0.76      0.57      0.65        88\n",
      "  HS_Physical       0.50      0.04      0.07        74\n",
      "    HS_Gender       0.75      0.04      0.08        75\n",
      "     HS_Other       0.76      0.81      0.79       744\n",
      "      HS_Weak       0.71      0.71      0.71       690\n",
      "  HS_Moderate       0.62      0.58      0.60       338\n",
      "    HS_Strong       0.77      0.67      0.72        79\n",
      "\n",
      "    micro avg       0.78      0.76      0.77      5499\n",
      "    macro avg       0.74      0.60      0.62      5499\n",
      " weighted avg       0.78      0.76      0.76      5499\n",
      "  samples avg       0.44      0.43      0.42      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.016831803321838375\n",
      "Samples above threshold: 214\n",
      "Acquired samples: 214\n",
      "Sampling duration: 9.912269592285156 seconds\n",
      "\n",
      "Fold 4 - New train size: 8616\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 8616 samples...\n",
      "Epoch 1/10, Train Loss: 0.3652, Accuracy: 0.8842, F1 Micro: 0.6037, F1 Macro: 0.3072\n",
      "Epoch 2/10, Train Loss: 0.2433, Accuracy: 0.905, F1 Micro: 0.7084, F1 Macro: 0.4824\n",
      "Epoch 3/10, Train Loss: 0.1913, Accuracy: 0.9138, F1 Micro: 0.7454, F1 Macro: 0.5812\n",
      "Epoch 4/10, Train Loss: 0.1622, Accuracy: 0.9182, F1 Micro: 0.7618, F1 Macro: 0.5941\n",
      "Epoch 5/10, Train Loss: 0.1311, Accuracy: 0.9198, F1 Micro: 0.7616, F1 Macro: 0.5889\n",
      "Epoch 6/10, Train Loss: 0.1091, Accuracy: 0.9222, F1 Micro: 0.7527, F1 Macro: 0.5945\n",
      "Epoch 7/10, Train Loss: 0.091, Accuracy: 0.9228, F1 Micro: 0.7647, F1 Macro: 0.6037\n",
      "Epoch 8/10, Train Loss: 0.0819, Accuracy: 0.9226, F1 Micro: 0.7674, F1 Macro: 0.6123\n",
      "Epoch 9/10, Train Loss: 0.0645, Accuracy: 0.9232, F1 Micro: 0.7696, F1 Macro: 0.6165\n",
      "Epoch 10/10, Train Loss: 0.0558, Accuracy: 0.9207, F1 Micro: 0.752, F1 Macro: 0.6104\n",
      "Best result for 8616 samples: F1 Micro: 0.7696\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.85      0.85      1107\n",
      "      Abusive       0.89      0.93      0.91      1030\n",
      "HS_Individual       0.76      0.71      0.73       729\n",
      "     HS_Group       0.67      0.65      0.66       378\n",
      "  HS_Religion       0.78      0.59      0.67       167\n",
      "      HS_Race       0.78      0.60      0.68        88\n",
      "  HS_Physical       1.00      0.03      0.05        74\n",
      "    HS_Gender       1.00      0.03      0.05        75\n",
      "     HS_Other       0.77      0.78      0.78       744\n",
      "      HS_Weak       0.73      0.69      0.71       690\n",
      "  HS_Moderate       0.59      0.62      0.61       338\n",
      "    HS_Strong       0.83      0.61      0.70        79\n",
      "\n",
      "    micro avg       0.79      0.75      0.77      5499\n",
      "    macro avg       0.80      0.59      0.62      5499\n",
      " weighted avg       0.79      0.75      0.76      5499\n",
      "  samples avg       0.44      0.42      0.42      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.016392385959625246\n",
      "Samples above threshold: 192\n",
      "Acquired samples: 200\n",
      "Sampling duration: 9.04542589187622 seconds\n",
      "\n",
      "Fold 4 - New train size: 8816\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 8816 samples...\n",
      "Epoch 1/10, Train Loss: 0.3702, Accuracy: 0.8755, F1 Micro: 0.4872, F1 Macro: 0.2323\n",
      "Epoch 2/10, Train Loss: 0.2497, Accuracy: 0.9085, F1 Micro: 0.7092, F1 Macro: 0.5022\n",
      "Epoch 3/10, Train Loss: 0.1995, Accuracy: 0.9164, F1 Micro: 0.7271, F1 Macro: 0.5601\n",
      "Epoch 4/10, Train Loss: 0.162, Accuracy: 0.9161, F1 Micro: 0.7629, F1 Macro: 0.6026\n",
      "Epoch 5/10, Train Loss: 0.1395, Accuracy: 0.9234, F1 Micro: 0.7661, F1 Macro: 0.602\n",
      "Epoch 6/10, Train Loss: 0.1125, Accuracy: 0.9249, F1 Micro: 0.77, F1 Macro: 0.6104\n",
      "Epoch 7/10, Train Loss: 0.0953, Accuracy: 0.9243, F1 Micro: 0.7767, F1 Macro: 0.6157\n",
      "Epoch 8/10, Train Loss: 0.0807, Accuracy: 0.9237, F1 Micro: 0.7755, F1 Macro: 0.6225\n",
      "Epoch 9/10, Train Loss: 0.0698, Accuracy: 0.9244, F1 Micro: 0.7741, F1 Macro: 0.6147\n",
      "Epoch 10/10, Train Loss: 0.0599, Accuracy: 0.9242, F1 Micro: 0.7767, F1 Macro: 0.6318\n",
      "Best result for 8816 samples: F1 Micro: 0.7767\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.87      0.85      1107\n",
      "      Abusive       0.90      0.93      0.91      1030\n",
      "HS_Individual       0.72      0.77      0.74       729\n",
      "     HS_Group       0.72      0.63      0.67       378\n",
      "  HS_Religion       0.73      0.65      0.69       167\n",
      "      HS_Race       0.80      0.64      0.71        88\n",
      "  HS_Physical       0.33      0.04      0.07        74\n",
      "    HS_Gender       0.75      0.04      0.08        75\n",
      "     HS_Other       0.76      0.81      0.78       744\n",
      "      HS_Weak       0.70      0.75      0.72       690\n",
      "  HS_Moderate       0.65      0.58      0.61       338\n",
      "    HS_Strong       0.79      0.68      0.73        79\n",
      "\n",
      "    micro avg       0.78      0.77      0.78      5499\n",
      "    macro avg       0.72      0.62      0.63      5499\n",
      " weighted avg       0.77      0.77      0.77      5499\n",
      "  samples avg       0.45      0.43      0.43      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.01543501615524292\n",
      "Samples above threshold: 172\n",
      "Acquired samples: 200\n",
      "Sampling duration: 8.2483549118042 seconds\n",
      "\n",
      "Fold 4 - New train size: 9016\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 9016 samples...\n",
      "Epoch 1/10, Train Loss: 0.3713, Accuracy: 0.8885, F1 Micro: 0.6318, F1 Macro: 0.3441\n",
      "Epoch 2/10, Train Loss: 0.2447, Accuracy: 0.9053, F1 Micro: 0.6803, F1 Macro: 0.4353\n",
      "Epoch 3/10, Train Loss: 0.1968, Accuracy: 0.9181, F1 Micro: 0.7584, F1 Macro: 0.5911\n",
      "Epoch 4/10, Train Loss: 0.1607, Accuracy: 0.9202, F1 Micro: 0.7655, F1 Macro: 0.61\n",
      "Epoch 5/10, Train Loss: 0.136, Accuracy: 0.9235, F1 Micro: 0.7756, F1 Macro: 0.6162\n",
      "Epoch 6/10, Train Loss: 0.1098, Accuracy: 0.9257, F1 Micro: 0.7785, F1 Macro: 0.6125\n",
      "Epoch 7/10, Train Loss: 0.0947, Accuracy: 0.9237, F1 Micro: 0.7715, F1 Macro: 0.6213\n",
      "Epoch 8/10, Train Loss: 0.079, Accuracy: 0.92, F1 Micro: 0.7728, F1 Macro: 0.6164\n",
      "Epoch 9/10, Train Loss: 0.0668, Accuracy: 0.9251, F1 Micro: 0.7673, F1 Macro: 0.6159\n",
      "Epoch 10/10, Train Loss: 0.0597, Accuracy: 0.9249, F1 Micro: 0.7763, F1 Macro: 0.6202\n",
      "Best result for 9016 samples: F1 Micro: 0.7785\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.86      0.86      1107\n",
      "      Abusive       0.88      0.92      0.90      1030\n",
      "HS_Individual       0.75      0.74      0.74       729\n",
      "     HS_Group       0.73      0.68      0.70       378\n",
      "  HS_Religion       0.80      0.60      0.69       167\n",
      "      HS_Race       0.78      0.52      0.63        88\n",
      "  HS_Physical       0.00      0.00      0.00        74\n",
      "    HS_Gender       0.00      0.00      0.00        75\n",
      "     HS_Other       0.75      0.82      0.78       744\n",
      "      HS_Weak       0.72      0.72      0.72       690\n",
      "  HS_Moderate       0.68      0.63      0.65       338\n",
      "    HS_Strong       0.79      0.58      0.67        79\n",
      "\n",
      "    micro avg       0.79      0.77      0.78      5499\n",
      "    macro avg       0.64      0.59      0.61      5499\n",
      " weighted avg       0.77      0.77      0.77      5499\n",
      "  samples avg       0.44      0.43      0.42      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.023397946357727056\n",
      "Samples above threshold: 152\n",
      "Acquired samples: 200\n",
      "Sampling duration: 7.3600475788116455 seconds\n",
      "\n",
      "Fold 4 - New train size: 9216\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 9216 samples...\n",
      "Epoch 1/10, Train Loss: 0.371, Accuracy: 0.8868, F1 Micro: 0.6006, F1 Macro: 0.3007\n",
      "Epoch 2/10, Train Loss: 0.2462, Accuracy: 0.9098, F1 Micro: 0.7083, F1 Macro: 0.5183\n",
      "Epoch 3/10, Train Loss: 0.1975, Accuracy: 0.9188, F1 Micro: 0.7588, F1 Macro: 0.5867\n",
      "Epoch 4/10, Train Loss: 0.1586, Accuracy: 0.9185, F1 Micro: 0.7668, F1 Macro: 0.6067\n",
      "Epoch 5/10, Train Loss: 0.1416, Accuracy: 0.9247, F1 Micro: 0.7699, F1 Macro: 0.6087\n",
      "Epoch 6/10, Train Loss: 0.109, Accuracy: 0.9255, F1 Micro: 0.771, F1 Macro: 0.6118\n",
      "Epoch 7/10, Train Loss: 0.0944, Accuracy: 0.9252, F1 Micro: 0.7761, F1 Macro: 0.6083\n",
      "Epoch 8/10, Train Loss: 0.0772, Accuracy: 0.9241, F1 Micro: 0.7766, F1 Macro: 0.6219\n",
      "Epoch 9/10, Train Loss: 0.0666, Accuracy: 0.9253, F1 Micro: 0.7722, F1 Macro: 0.6046\n",
      "Epoch 10/10, Train Loss: 0.0603, Accuracy: 0.9227, F1 Micro: 0.7712, F1 Macro: 0.646\n",
      "Best result for 9216 samples: F1 Micro: 0.7766\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.86      0.85      1107\n",
      "      Abusive       0.87      0.95      0.91      1030\n",
      "HS_Individual       0.72      0.77      0.75       729\n",
      "     HS_Group       0.73      0.63      0.68       378\n",
      "  HS_Religion       0.78      0.65      0.71       167\n",
      "      HS_Race       0.76      0.64      0.69        88\n",
      "  HS_Physical       1.00      0.03      0.05        74\n",
      "    HS_Gender       0.00      0.00      0.00        75\n",
      "     HS_Other       0.75      0.80      0.78       744\n",
      "      HS_Weak       0.70      0.74      0.72       690\n",
      "  HS_Moderate       0.67      0.57      0.62       338\n",
      "    HS_Strong       0.77      0.67      0.72        79\n",
      "\n",
      "    micro avg       0.78      0.77      0.78      5499\n",
      "    macro avg       0.72      0.61      0.62      5499\n",
      " weighted avg       0.77      0.77      0.76      5499\n",
      "  samples avg       0.45      0.43      0.42      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.012436378002166747\n",
      "Samples above threshold: 132\n",
      "Acquired samples: 2\n",
      "Sampling duration: 6.7854156494140625 seconds\n",
      "\n",
      "Fold 4 - New train size: 9218\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 9218 samples...\n",
      "Epoch 1/10, Train Loss: 0.367, Accuracy: 0.8889, F1 Micro: 0.6027, F1 Macro: 0.3176\n",
      "Epoch 2/10, Train Loss: 0.2521, Accuracy: 0.9116, F1 Micro: 0.7176, F1 Macro: 0.5207\n",
      "Epoch 3/10, Train Loss: 0.1931, Accuracy: 0.9191, F1 Micro: 0.7468, F1 Macro: 0.5799\n",
      "Epoch 4/10, Train Loss: 0.1621, Accuracy: 0.9223, F1 Micro: 0.7692, F1 Macro: 0.6092\n",
      "Epoch 5/10, Train Loss: 0.1361, Accuracy: 0.923, F1 Micro: 0.778, F1 Macro: 0.6145\n",
      "Epoch 6/10, Train Loss: 0.1104, Accuracy: 0.9219, F1 Micro: 0.776, F1 Macro: 0.6114\n",
      "Epoch 7/10, Train Loss: 0.0959, Accuracy: 0.9234, F1 Micro: 0.7746, F1 Macro: 0.6008\n",
      "Epoch 8/10, Train Loss: 0.079, Accuracy: 0.9256, F1 Micro: 0.7797, F1 Macro: 0.6278\n",
      "Epoch 9/10, Train Loss: 0.0708, Accuracy: 0.9233, F1 Micro: 0.7764, F1 Macro: 0.6116\n",
      "Epoch 10/10, Train Loss: 0.0606, Accuracy: 0.924, F1 Micro: 0.7762, F1 Macro: 0.6352\n",
      "Best result for 9218 samples: F1 Micro: 0.7797\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.86      0.85      1107\n",
      "      Abusive       0.89      0.93      0.91      1030\n",
      "HS_Individual       0.73      0.76      0.75       729\n",
      "     HS_Group       0.74      0.65      0.69       378\n",
      "  HS_Religion       0.79      0.62      0.70       167\n",
      "      HS_Race       0.85      0.62      0.72        88\n",
      "  HS_Physical       0.67      0.03      0.05        74\n",
      "    HS_Gender       0.00      0.00      0.00        75\n",
      "     HS_Other       0.75      0.82      0.78       744\n",
      "      HS_Weak       0.70      0.74      0.72       690\n",
      "  HS_Moderate       0.67      0.59      0.63       338\n",
      "    HS_Strong       0.79      0.67      0.73        79\n",
      "\n",
      "    micro avg       0.79      0.77      0.78      5499\n",
      "    macro avg       0.70      0.61      0.63      5499\n",
      " weighted avg       0.77      0.77      0.77      5499\n",
      "  samples avg       0.44      0.43      0.42      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 0.01189153194427491\n",
      "Samples above threshold: 132\n",
      "Acquired samples: 200\n",
      "Sampling duration: 6.564429044723511 seconds\n",
      "\n",
      "Fold 4 - New train size: 9418\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 9418 samples...\n",
      "Epoch 1/10, Train Loss: 0.3658, Accuracy: 0.8876, F1 Micro: 0.587, F1 Macro: 0.302\n",
      "Epoch 2/10, Train Loss: 0.2453, Accuracy: 0.9088, F1 Micro: 0.72, F1 Macro: 0.5088\n",
      "Epoch 3/10, Train Loss: 0.1918, Accuracy: 0.92, F1 Micro: 0.7507, F1 Macro: 0.5845\n",
      "Epoch 4/10, Train Loss: 0.1592, Accuracy: 0.9223, F1 Micro: 0.7581, F1 Macro: 0.5694\n",
      "Epoch 5/10, Train Loss: 0.1348, Accuracy: 0.923, F1 Micro: 0.7651, F1 Macro: 0.5992\n",
      "Epoch 6/10, Train Loss: 0.1121, Accuracy: 0.9247, F1 Micro: 0.7743, F1 Macro: 0.6153\n",
      "Epoch 7/10, Train Loss: 0.0924, Accuracy: 0.9251, F1 Micro: 0.7655, F1 Macro: 0.6152\n",
      "Epoch 8/10, Train Loss: 0.0809, Accuracy: 0.9213, F1 Micro: 0.7655, F1 Macro: 0.6134\n",
      "Epoch 9/10, Train Loss: 0.0703, Accuracy: 0.9254, F1 Micro: 0.773, F1 Macro: 0.6155\n",
      "Epoch 10/10, Train Loss: 0.0593, Accuracy: 0.9248, F1 Micro: 0.7784, F1 Macro: 0.6548\n",
      "Best result for 9418 samples: F1 Micro: 0.7784\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.87      0.85      1107\n",
      "      Abusive       0.90      0.93      0.92      1030\n",
      "HS_Individual       0.73      0.76      0.74       729\n",
      "     HS_Group       0.71      0.65      0.68       378\n",
      "  HS_Religion       0.78      0.65      0.71       167\n",
      "      HS_Race       0.74      0.67      0.70        88\n",
      "  HS_Physical       0.37      0.14      0.20        74\n",
      "    HS_Gender       0.91      0.13      0.23        75\n",
      "     HS_Other       0.78      0.78      0.78       744\n",
      "      HS_Weak       0.70      0.75      0.72       690\n",
      "  HS_Moderate       0.63      0.59      0.61       338\n",
      "    HS_Strong       0.83      0.62      0.71        79\n",
      "\n",
      "    micro avg       0.78      0.77      0.78      5499\n",
      "    macro avg       0.74      0.63      0.65      5499\n",
      " weighted avg       0.78      0.77      0.77      5499\n",
      "  samples avg       0.44      0.43      0.42      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 0.00627821683883667\n",
      "Samples above threshold: 113\n",
      "Acquired samples: 200\n",
      "Sampling duration: 5.900035381317139 seconds\n",
      "\n",
      "Fold 4 - New train size: 9618\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 9618 samples...\n",
      "Epoch 1/10, Train Loss: 0.3668, Accuracy: 0.8908, F1 Micro: 0.6484, F1 Macro: 0.3787\n",
      "Epoch 2/10, Train Loss: 0.2442, Accuracy: 0.9119, F1 Micro: 0.716, F1 Macro: 0.519\n",
      "Epoch 3/10, Train Loss: 0.1984, Accuracy: 0.9211, F1 Micro: 0.7483, F1 Macro: 0.5724\n",
      "Epoch 4/10, Train Loss: 0.1629, Accuracy: 0.9249, F1 Micro: 0.7665, F1 Macro: 0.5922\n",
      "Epoch 5/10, Train Loss: 0.1332, Accuracy: 0.924, F1 Micro: 0.7562, F1 Macro: 0.5954\n",
      "Epoch 6/10, Train Loss: 0.1117, Accuracy: 0.925, F1 Micro: 0.7661, F1 Macro: 0.6116\n",
      "Epoch 7/10, Train Loss: 0.0947, Accuracy: 0.9229, F1 Micro: 0.7795, F1 Macro: 0.6286\n",
      "Epoch 8/10, Train Loss: 0.0783, Accuracy: 0.925, F1 Micro: 0.7803, F1 Macro: 0.6429\n",
      "Epoch 9/10, Train Loss: 0.0693, Accuracy: 0.9243, F1 Micro: 0.7817, F1 Macro: 0.6505\n",
      "Epoch 10/10, Train Loss: 0.0608, Accuracy: 0.9222, F1 Micro: 0.7776, F1 Macro: 0.6363\n",
      "Best result for 9618 samples: F1 Micro: 0.7817\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.89      0.86      1107\n",
      "      Abusive       0.89      0.94      0.91      1030\n",
      "HS_Individual       0.71      0.78      0.75       729\n",
      "     HS_Group       0.71      0.67      0.69       378\n",
      "  HS_Religion       0.70      0.72      0.71       167\n",
      "      HS_Race       0.76      0.69      0.73        88\n",
      "  HS_Physical       0.45      0.19      0.27        74\n",
      "    HS_Gender       1.00      0.03      0.05        75\n",
      "     HS_Other       0.76      0.82      0.79       744\n",
      "      HS_Weak       0.68      0.76      0.72       690\n",
      "  HS_Moderate       0.65      0.61      0.63       338\n",
      "    HS_Strong       0.78      0.65      0.71        79\n",
      "\n",
      "    micro avg       0.77      0.79      0.78      5499\n",
      "    macro avg       0.74      0.65      0.65      5499\n",
      " weighted avg       0.77      0.79      0.77      5499\n",
      "  samples avg       0.45      0.44      0.43      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 0.005823314189910889\n",
      "Samples above threshold: 92\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.926168203353882 seconds\n",
      "\n",
      "Fold 4 - New train size: 9818\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 9818 samples...\n",
      "Epoch 1/10, Train Loss: 0.3694, Accuracy: 0.8888, F1 Micro: 0.594, F1 Macro: 0.297\n",
      "Epoch 2/10, Train Loss: 0.2443, Accuracy: 0.9133, F1 Micro: 0.725, F1 Macro: 0.5276\n",
      "Epoch 3/10, Train Loss: 0.1997, Accuracy: 0.9163, F1 Micro: 0.7544, F1 Macro: 0.5751\n",
      "Epoch 4/10, Train Loss: 0.1646, Accuracy: 0.9249, F1 Micro: 0.7657, F1 Macro: 0.5945\n",
      "Epoch 5/10, Train Loss: 0.1399, Accuracy: 0.9258, F1 Micro: 0.779, F1 Macro: 0.6125\n",
      "Epoch 6/10, Train Loss: 0.1158, Accuracy: 0.9279, F1 Micro: 0.7771, F1 Macro: 0.6299\n",
      "Epoch 7/10, Train Loss: 0.0963, Accuracy: 0.9278, F1 Micro: 0.7825, F1 Macro: 0.6269\n",
      "Epoch 8/10, Train Loss: 0.0821, Accuracy: 0.9273, F1 Micro: 0.7814, F1 Macro: 0.634\n",
      "Epoch 9/10, Train Loss: 0.0712, Accuracy: 0.9255, F1 Micro: 0.7804, F1 Macro: 0.6371\n",
      "Epoch 10/10, Train Loss: 0.0612, Accuracy: 0.9234, F1 Micro: 0.77, F1 Macro: 0.6604\n",
      "Best result for 9818 samples: F1 Micro: 0.7825\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.86      0.86      1107\n",
      "      Abusive       0.92      0.91      0.92      1030\n",
      "HS_Individual       0.75      0.76      0.75       729\n",
      "     HS_Group       0.76      0.63      0.69       378\n",
      "  HS_Religion       0.80      0.55      0.65       167\n",
      "      HS_Race       0.77      0.47      0.58        88\n",
      "  HS_Physical       0.57      0.11      0.18        74\n",
      "    HS_Gender       1.00      0.01      0.03        75\n",
      "     HS_Other       0.77      0.82      0.79       744\n",
      "      HS_Weak       0.72      0.74      0.73       690\n",
      "  HS_Moderate       0.70      0.57      0.63       338\n",
      "    HS_Strong       0.76      0.66      0.71        79\n",
      "\n",
      "    micro avg       0.80      0.76      0.78      5499\n",
      "    macro avg       0.78      0.59      0.63      5499\n",
      " weighted avg       0.80      0.76      0.77      5499\n",
      "  samples avg       0.44      0.42      0.42      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 0.01383974552154541\n",
      "Samples above threshold: 72\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.100224018096924 seconds\n",
      "\n",
      "Fold 4 - New train size: 10018\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 10018 samples...\n",
      "Epoch 1/10, Train Loss: 0.3709, Accuracy: 0.8901, F1 Micro: 0.6154, F1 Macro: 0.3272\n",
      "Epoch 2/10, Train Loss: 0.2451, Accuracy: 0.9139, F1 Micro: 0.7291, F1 Macro: 0.5188\n",
      "Epoch 3/10, Train Loss: 0.1989, Accuracy: 0.9216, F1 Micro: 0.7628, F1 Macro: 0.5893\n",
      "Epoch 4/10, Train Loss: 0.1655, Accuracy: 0.9236, F1 Micro: 0.7695, F1 Macro: 0.5932\n",
      "Epoch 5/10, Train Loss: 0.1366, Accuracy: 0.9264, F1 Micro: 0.7727, F1 Macro: 0.619\n",
      "Epoch 6/10, Train Loss: 0.114, Accuracy: 0.9266, F1 Micro: 0.7833, F1 Macro: 0.6308\n",
      "Epoch 7/10, Train Loss: 0.0984, Accuracy: 0.9255, F1 Micro: 0.7731, F1 Macro: 0.6167\n",
      "Epoch 8/10, Train Loss: 0.08, Accuracy: 0.9254, F1 Micro: 0.7745, F1 Macro: 0.6432\n",
      "Epoch 9/10, Train Loss: 0.0719, Accuracy: 0.9259, F1 Micro: 0.7808, F1 Macro: 0.6706\n",
      "Epoch 10/10, Train Loss: 0.0651, Accuracy: 0.9257, F1 Micro: 0.7686, F1 Macro: 0.6452\n",
      "Best result for 10018 samples: F1 Micro: 0.7833\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.89      0.86      1107\n",
      "      Abusive       0.91      0.92      0.91      1030\n",
      "HS_Individual       0.75      0.77      0.76       729\n",
      "     HS_Group       0.71      0.65      0.68       378\n",
      "  HS_Religion       0.79      0.57      0.66       167\n",
      "      HS_Race       0.79      0.51      0.62        88\n",
      "  HS_Physical       0.80      0.11      0.19        74\n",
      "    HS_Gender       1.00      0.01      0.03        75\n",
      "     HS_Other       0.75      0.83      0.79       744\n",
      "      HS_Weak       0.71      0.76      0.74       690\n",
      "  HS_Moderate       0.65      0.59      0.62       338\n",
      "    HS_Strong       0.81      0.63      0.71        79\n",
      "\n",
      "    micro avg       0.79      0.78      0.78      5499\n",
      "    macro avg       0.79      0.60      0.63      5499\n",
      " weighted avg       0.79      0.78      0.77      5499\n",
      "  samples avg       0.44      0.43      0.42      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 0.0091783881187439\n",
      "Samples above threshold: 52\n",
      "Acquired samples: 200\n",
      "Sampling duration: 3.13340163230896 seconds\n",
      "\n",
      "Fold 4 - New train size: 10218\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 10218 samples...\n",
      "Epoch 1/10, Train Loss: 0.373, Accuracy: 0.8919, F1 Micro: 0.6527, F1 Macro: 0.3587\n",
      "Epoch 2/10, Train Loss: 0.2487, Accuracy: 0.9094, F1 Micro: 0.727, F1 Macro: 0.4937\n",
      "Epoch 3/10, Train Loss: 0.202, Accuracy: 0.92, F1 Micro: 0.743, F1 Macro: 0.566\n",
      "Epoch 4/10, Train Loss: 0.1647, Accuracy: 0.9256, F1 Micro: 0.7667, F1 Macro: 0.5981\n",
      "Epoch 5/10, Train Loss: 0.1385, Accuracy: 0.9256, F1 Micro: 0.7805, F1 Macro: 0.6202\n",
      "Epoch 6/10, Train Loss: 0.1155, Accuracy: 0.9247, F1 Micro: 0.783, F1 Macro: 0.6434\n",
      "Epoch 7/10, Train Loss: 0.1016, Accuracy: 0.9244, F1 Micro: 0.7835, F1 Macro: 0.644\n",
      "Epoch 8/10, Train Loss: 0.0814, Accuracy: 0.9295, F1 Micro: 0.7851, F1 Macro: 0.6358\n",
      "Epoch 9/10, Train Loss: 0.0741, Accuracy: 0.9297, F1 Micro: 0.7863, F1 Macro: 0.6628\n",
      "Epoch 10/10, Train Loss: 0.0622, Accuracy: 0.9257, F1 Micro: 0.7812, F1 Macro: 0.6803\n",
      "Best result for 10218 samples: F1 Micro: 0.7863\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.87      0.83      0.85      1107\n",
      "      Abusive       0.90      0.93      0.91      1030\n",
      "HS_Individual       0.75      0.78      0.76       729\n",
      "     HS_Group       0.82      0.57      0.67       378\n",
      "  HS_Religion       0.81      0.60      0.69       167\n",
      "      HS_Race       0.78      0.57      0.66        88\n",
      "  HS_Physical       0.50      0.16      0.24        74\n",
      "    HS_Gender       0.87      0.17      0.29        75\n",
      "     HS_Other       0.81      0.78      0.80       744\n",
      "      HS_Weak       0.72      0.76      0.74       690\n",
      "  HS_Moderate       0.75      0.51      0.60       338\n",
      "    HS_Strong       0.80      0.66      0.72        79\n",
      "\n",
      "    micro avg       0.82      0.76      0.79      5499\n",
      "    macro avg       0.78      0.61      0.66      5499\n",
      " weighted avg       0.81      0.76      0.78      5499\n",
      "  samples avg       0.45      0.42      0.42      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 0.004689502716064457\n",
      "Samples above threshold: 32\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.2009971141815186 seconds\n",
      "\n",
      "Fold 4 - New train size: 10418\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 10418 samples...\n",
      "Epoch 1/10, Train Loss: 0.3665, Accuracy: 0.8929, F1 Micro: 0.6391, F1 Macro: 0.332\n",
      "Epoch 2/10, Train Loss: 0.2468, Accuracy: 0.9146, F1 Micro: 0.7303, F1 Macro: 0.5479\n",
      "Epoch 3/10, Train Loss: 0.1941, Accuracy: 0.9234, F1 Micro: 0.765, F1 Macro: 0.5984\n",
      "Epoch 4/10, Train Loss: 0.1635, Accuracy: 0.9257, F1 Micro: 0.7734, F1 Macro: 0.6127\n",
      "Epoch 5/10, Train Loss: 0.1402, Accuracy: 0.9234, F1 Micro: 0.7754, F1 Macro: 0.6241\n",
      "Epoch 6/10, Train Loss: 0.1186, Accuracy: 0.9285, F1 Micro: 0.7829, F1 Macro: 0.6659\n",
      "Epoch 7/10, Train Loss: 0.097, Accuracy: 0.927, F1 Micro: 0.7824, F1 Macro: 0.6407\n",
      "Epoch 8/10, Train Loss: 0.0813, Accuracy: 0.9272, F1 Micro: 0.7817, F1 Macro: 0.6499\n",
      "Epoch 9/10, Train Loss: 0.0723, Accuracy: 0.9261, F1 Micro: 0.7871, F1 Macro: 0.6845\n",
      "Epoch 10/10, Train Loss: 0.0616, Accuracy: 0.9266, F1 Micro: 0.7859, F1 Macro: 0.6805\n",
      "Best result for 10418 samples: F1 Micro: 0.7871\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.90      0.86      1107\n",
      "      Abusive       0.89      0.93      0.91      1030\n",
      "HS_Individual       0.71      0.81      0.76       729\n",
      "     HS_Group       0.72      0.63      0.67       378\n",
      "  HS_Religion       0.75      0.62      0.68       167\n",
      "      HS_Race       0.74      0.52      0.61        88\n",
      "  HS_Physical       0.48      0.22      0.30        74\n",
      "    HS_Gender       0.88      0.40      0.55        75\n",
      "     HS_Other       0.75      0.85      0.80       744\n",
      "      HS_Weak       0.69      0.79      0.73       690\n",
      "  HS_Moderate       0.66      0.58      0.62       338\n",
      "    HS_Strong       0.82      0.63      0.71        79\n",
      "\n",
      "    micro avg       0.77      0.80      0.79      5499\n",
      "    macro avg       0.74      0.66      0.68      5499\n",
      " weighted avg       0.77      0.80      0.78      5499\n",
      "  samples avg       0.45      0.44      0.43      5499\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10535\n",
      "Threshold: 0.0021651625633239756\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 117\n",
      "Sampling duration: 1.7288939952850342 seconds\n",
      "\n",
      "Fold 4 - New train size: 10535\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 4 - Training with 10535 samples...\n",
      "Epoch 1/10, Train Loss: 0.3676, Accuracy: 0.8935, F1 Micro: 0.6301, F1 Macro: 0.3651\n",
      "Epoch 2/10, Train Loss: 0.2474, Accuracy: 0.9121, F1 Micro: 0.7047, F1 Macro: 0.4784\n",
      "Epoch 3/10, Train Loss: 0.2026, Accuracy: 0.9228, F1 Micro: 0.7559, F1 Macro: 0.558\n",
      "Epoch 4/10, Train Loss: 0.1692, Accuracy: 0.9251, F1 Micro: 0.768, F1 Macro: 0.6025\n",
      "Epoch 5/10, Train Loss: 0.1408, Accuracy: 0.9294, F1 Micro: 0.7842, F1 Macro: 0.6464\n",
      "Epoch 6/10, Train Loss: 0.1192, Accuracy: 0.9306, F1 Micro: 0.7898, F1 Macro: 0.6603\n",
      "Epoch 7/10, Train Loss: 0.0981, Accuracy: 0.9275, F1 Micro: 0.7841, F1 Macro: 0.6383\n",
      "Epoch 8/10, Train Loss: 0.0829, Accuracy: 0.9279, F1 Micro: 0.7751, F1 Macro: 0.6692\n",
      "Epoch 9/10, Train Loss: 0.0722, Accuracy: 0.9273, F1 Micro: 0.7844, F1 Macro: 0.6843\n",
      "Epoch 10/10, Train Loss: 0.0621, Accuracy: 0.9271, F1 Micro: 0.7835, F1 Macro: 0.6908\n",
      "Best result for 10535 samples: F1 Micro: 0.7898\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.87      0.86      0.86      1107\n",
      "      Abusive       0.91      0.92      0.92      1030\n",
      "HS_Individual       0.76      0.79      0.77       729\n",
      "     HS_Group       0.80      0.61      0.69       378\n",
      "  HS_Religion       0.79      0.60      0.68       167\n",
      "      HS_Race       0.82      0.58      0.68        88\n",
      "  HS_Physical       0.53      0.12      0.20        74\n",
      "    HS_Gender       0.80      0.16      0.27        75\n",
      "     HS_Other       0.80      0.78      0.79       744\n",
      "      HS_Weak       0.73      0.75      0.74       690\n",
      "  HS_Moderate       0.74      0.53      0.62       338\n",
      "    HS_Strong       0.76      0.66      0.71        79\n",
      "\n",
      "    micro avg       0.82      0.76      0.79      5499\n",
      "    macro avg       0.78      0.61      0.66      5499\n",
      " weighted avg       0.81      0.76      0.78      5499\n",
      "  samples avg       0.45      0.42      0.42      5499\n",
      "\n",
      "\n",
      "FOLD 4 COMPLETED in 6334.53 seconds\n",
      "===============================================\n",
      "STARTING FOLD 5/5\n",
      "===============================================\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 658 samples...\n",
      "Epoch 1/10, Train Loss: 0.6136, Accuracy: 0.8169, F1 Micro: 0.2051, F1 Macro: 0.06\n",
      "Epoch 2/10, Train Loss: 0.4588, Accuracy: 0.8201, F1 Micro: 0.0038, F1 Macro: 0.0016\n",
      "Epoch 3/10, Train Loss: 0.4187, Accuracy: 0.8233, F1 Micro: 0.0481, F1 Macro: 0.02\n",
      "Epoch 4/10, Train Loss: 0.386, Accuracy: 0.8238, F1 Micro: 0.0508, F1 Macro: 0.0212\n",
      "Epoch 5/10, Train Loss: 0.3707, Accuracy: 0.8329, F1 Micro: 0.1604, F1 Macro: 0.0612\n",
      "Epoch 6/10, Train Loss: 0.3624, Accuracy: 0.8458, F1 Micro: 0.3243, F1 Macro: 0.1116\n",
      "Epoch 7/10, Train Loss: 0.3537, Accuracy: 0.8506, F1 Micro: 0.3637, F1 Macro: 0.145\n",
      "Epoch 8/10, Train Loss: 0.3241, Accuracy: 0.8632, F1 Micro: 0.4924, F1 Macro: 0.2234\n",
      "Epoch 9/10, Train Loss: 0.3069, Accuracy: 0.8715, F1 Micro: 0.5743, F1 Macro: 0.2679\n",
      "Epoch 10/10, Train Loss: 0.2933, Accuracy: 0.8748, F1 Micro: 0.5872, F1 Macro: 0.2747\n",
      "Best result for 658 samples: F1 Micro: 0.5872\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.79      0.75      0.77      1190\n",
      "      Abusive       0.82      0.72      0.77      1018\n",
      "HS_Individual       0.65      0.57      0.61       768\n",
      "     HS_Group       0.00      0.00      0.00       422\n",
      "  HS_Religion       0.00      0.00      0.00       173\n",
      "      HS_Race       0.00      0.00      0.00       126\n",
      "  HS_Physical       0.00      0.00      0.00        60\n",
      "    HS_Gender       0.00      0.00      0.00        67\n",
      "     HS_Other       0.64      0.56      0.60       792\n",
      "      HS_Weak       0.61      0.50      0.55       725\n",
      "  HS_Moderate       0.00      0.00      0.00       352\n",
      "    HS_Strong       0.00      0.00      0.00       113\n",
      "\n",
      "    micro avg       0.72      0.50      0.59      5806\n",
      "    macro avg       0.29      0.26      0.27      5806\n",
      " weighted avg       0.56      0.50      0.52      5806\n",
      "  samples avg       0.38      0.29      0.30      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.8479217469692231\n",
      "Samples above threshold: 988\n",
      "Acquired samples: 988\n",
      "Sampling duration: 43.78427076339722 seconds\n",
      "\n",
      "Fold 5 - New train size: 1646\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 1646 samples...\n",
      "Epoch 1/10, Train Loss: 0.4812, Accuracy: 0.82, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.282, Accuracy: 0.82, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.2402, Accuracy: 0.8214, F1 Micro: 0.0187, F1 Macro: 0.0085\n",
      "Epoch 4/10, Train Loss: 0.2165, Accuracy: 0.842, F1 Micro: 0.3505, F1 Macro: 0.1394\n",
      "Epoch 5/10, Train Loss: 0.192, Accuracy: 0.857, F1 Micro: 0.5015, F1 Macro: 0.2266\n",
      "Epoch 6/10, Train Loss: 0.1757, Accuracy: 0.8598, F1 Micro: 0.464, F1 Macro: 0.2149\n",
      "Epoch 7/10, Train Loss: 0.1528, Accuracy: 0.8657, F1 Micro: 0.5399, F1 Macro: 0.2524\n",
      "Epoch 8/10, Train Loss: 0.1507, Accuracy: 0.8702, F1 Micro: 0.5633, F1 Macro: 0.2624\n",
      "Epoch 9/10, Train Loss: 0.1346, Accuracy: 0.871, F1 Micro: 0.6176, F1 Macro: 0.2876\n",
      "Epoch 10/10, Train Loss: 0.1253, Accuracy: 0.8722, F1 Micro: 0.5736, F1 Macro: 0.2659\n",
      "Best result for 1646 samples: F1 Micro: 0.6176\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.75      0.84      0.79      1190\n",
      "      Abusive       0.81      0.78      0.79      1018\n",
      "HS_Individual       0.58      0.68      0.62       768\n",
      "     HS_Group       0.33      0.00      0.00       422\n",
      "  HS_Religion       0.00      0.00      0.00       173\n",
      "      HS_Race       0.00      0.00      0.00       126\n",
      "  HS_Physical       0.00      0.00      0.00        60\n",
      "    HS_Gender       0.00      0.00      0.00        67\n",
      "     HS_Other       0.59      0.71      0.65       792\n",
      "      HS_Weak       0.54      0.65      0.59       725\n",
      "  HS_Moderate       0.00      0.00      0.00       352\n",
      "    HS_Strong       0.00      0.00      0.00       113\n",
      "\n",
      "    micro avg       0.66      0.58      0.62      5806\n",
      "    macro avg       0.30      0.31      0.29      5806\n",
      " weighted avg       0.54      0.58      0.55      5806\n",
      "  samples avg       0.38      0.34      0.33      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.9043969929218293\n",
      "Samples above threshold: 889\n",
      "Acquired samples: 889\n",
      "Sampling duration: 38.127015829086304 seconds\n",
      "\n",
      "Fold 5 - New train size: 2535\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 2535 samples...\n",
      "Epoch 1/10, Train Loss: 0.4017, Accuracy: 0.82, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.2183, Accuracy: 0.82, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.1965, Accuracy: 0.8252, F1 Micro: 0.0877, F1 Macro: 0.0378\n",
      "Epoch 4/10, Train Loss: 0.1643, Accuracy: 0.8502, F1 Micro: 0.5132, F1 Macro: 0.2313\n",
      "Epoch 5/10, Train Loss: 0.1441, Accuracy: 0.8602, F1 Micro: 0.5303, F1 Macro: 0.2446\n",
      "Epoch 6/10, Train Loss: 0.1229, Accuracy: 0.8645, F1 Micro: 0.5382, F1 Macro: 0.2501\n",
      "Epoch 7/10, Train Loss: 0.1117, Accuracy: 0.8659, F1 Micro: 0.533, F1 Macro: 0.2482\n",
      "Epoch 8/10, Train Loss: 0.1078, Accuracy: 0.8672, F1 Micro: 0.6027, F1 Macro: 0.2792\n",
      "Epoch 9/10, Train Loss: 0.0917, Accuracy: 0.8709, F1 Micro: 0.6046, F1 Macro: 0.3058\n",
      "Epoch 10/10, Train Loss: 0.0896, Accuracy: 0.8736, F1 Micro: 0.6028, F1 Macro: 0.2867\n",
      "Best result for 2535 samples: F1 Micro: 0.6046\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.76      0.83      0.79      1190\n",
      "      Abusive       0.88      0.68      0.77      1018\n",
      "HS_Individual       0.57      0.61      0.59       768\n",
      "     HS_Group       0.58      0.20      0.30       422\n",
      "  HS_Religion       0.00      0.00      0.00       173\n",
      "      HS_Race       0.00      0.00      0.00       126\n",
      "  HS_Physical       0.00      0.00      0.00        60\n",
      "    HS_Gender       0.00      0.00      0.00        67\n",
      "     HS_Other       0.60      0.69      0.64       792\n",
      "      HS_Weak       0.53      0.54      0.54       725\n",
      "  HS_Moderate       0.47      0.02      0.04       352\n",
      "    HS_Strong       0.00      0.00      0.00       113\n",
      "\n",
      "    micro avg       0.67      0.55      0.60      5806\n",
      "    macro avg       0.37      0.30      0.31      5806\n",
      " weighted avg       0.60      0.55      0.55      5806\n",
      "  samples avg       0.37      0.31      0.31      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.9128620252013206\n",
      "Samples above threshold: 801\n",
      "Acquired samples: 801\n",
      "Sampling duration: 34.422752380371094 seconds\n",
      "\n",
      "Fold 5 - New train size: 3336\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 3336 samples...\n",
      "Epoch 1/10, Train Loss: 0.3492, Accuracy: 0.82, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.1974, Accuracy: 0.82, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.1737, Accuracy: 0.822, F1 Micro: 0.0265, F1 Macro: 0.012\n",
      "Epoch 4/10, Train Loss: 0.1514, Accuracy: 0.8571, F1 Micro: 0.4883, F1 Macro: 0.2267\n",
      "Epoch 5/10, Train Loss: 0.1268, Accuracy: 0.8643, F1 Micro: 0.5415, F1 Macro: 0.2506\n",
      "Epoch 6/10, Train Loss: 0.1155, Accuracy: 0.8713, F1 Micro: 0.5963, F1 Macro: 0.2769\n",
      "Epoch 7/10, Train Loss: 0.0984, Accuracy: 0.8729, F1 Micro: 0.6197, F1 Macro: 0.2877\n",
      "Epoch 8/10, Train Loss: 0.0829, Accuracy: 0.8715, F1 Micro: 0.6037, F1 Macro: 0.2803\n",
      "Epoch 9/10, Train Loss: 0.0789, Accuracy: 0.8752, F1 Micro: 0.5968, F1 Macro: 0.2813\n",
      "Epoch 10/10, Train Loss: 0.0711, Accuracy: 0.8782, F1 Micro: 0.6418, F1 Macro: 0.3302\n",
      "Best result for 3336 samples: F1 Micro: 0.6418\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.77      0.85      0.81      1190\n",
      "      Abusive       0.84      0.85      0.84      1018\n",
      "HS_Individual       0.57      0.66      0.61       768\n",
      "     HS_Group       0.75      0.26      0.39       422\n",
      "  HS_Religion       1.00      0.01      0.02       173\n",
      "      HS_Race       0.00      0.00      0.00       126\n",
      "  HS_Physical       0.00      0.00      0.00        60\n",
      "    HS_Gender       0.00      0.00      0.00        67\n",
      "     HS_Other       0.60      0.71      0.65       792\n",
      "      HS_Weak       0.55      0.62      0.58       725\n",
      "  HS_Moderate       0.48      0.03      0.05       352\n",
      "    HS_Strong       0.00      0.00      0.00       113\n",
      "\n",
      "    micro avg       0.68      0.61      0.64      5806\n",
      "    macro avg       0.46      0.33      0.33      5806\n",
      " weighted avg       0.64      0.61      0.59      5806\n",
      "  samples avg       0.42      0.37      0.36      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.7988959684967994\n",
      "Samples above threshold: 720\n",
      "Acquired samples: 720\n",
      "Sampling duration: 31.303003549575806 seconds\n",
      "\n",
      "Fold 5 - New train size: 4056\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 4056 samples...\n",
      "Epoch 1/10, Train Loss: 0.3336, Accuracy: 0.82, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.1885, Accuracy: 0.82, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.1762, Accuracy: 0.8238, F1 Micro: 0.0476, F1 Macro: 0.0204\n",
      "Epoch 4/10, Train Loss: 0.1562, Accuracy: 0.8593, F1 Micro: 0.4875, F1 Macro: 0.229\n",
      "Epoch 5/10, Train Loss: 0.1275, Accuracy: 0.8708, F1 Micro: 0.5594, F1 Macro: 0.261\n",
      "Epoch 6/10, Train Loss: 0.1036, Accuracy: 0.8762, F1 Micro: 0.6295, F1 Macro: 0.2928\n",
      "Epoch 7/10, Train Loss: 0.0871, Accuracy: 0.8748, F1 Micro: 0.6278, F1 Macro: 0.2932\n",
      "Epoch 8/10, Train Loss: 0.08, Accuracy: 0.8748, F1 Micro: 0.6486, F1 Macro: 0.33\n",
      "Epoch 9/10, Train Loss: 0.0696, Accuracy: 0.8809, F1 Micro: 0.6455, F1 Macro: 0.3318\n",
      "Epoch 10/10, Train Loss: 0.0632, Accuracy: 0.886, F1 Micro: 0.6714, F1 Macro: 0.3963\n",
      "Best result for 4056 samples: F1 Micro: 0.6714\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.85      0.82      1190\n",
      "      Abusive       0.85      0.84      0.84      1018\n",
      "HS_Individual       0.62      0.69      0.66       768\n",
      "     HS_Group       0.60      0.40      0.48       422\n",
      "  HS_Religion       0.48      0.14      0.22       173\n",
      "      HS_Race       1.00      0.02      0.03       126\n",
      "  HS_Physical       0.00      0.00      0.00        60\n",
      "    HS_Gender       0.00      0.00      0.00        67\n",
      "     HS_Other       0.65      0.75      0.70       792\n",
      "      HS_Weak       0.60      0.63      0.61       725\n",
      "  HS_Moderate       0.47      0.34      0.39       352\n",
      "    HS_Strong       0.00      0.00      0.00       113\n",
      "\n",
      "    micro avg       0.70      0.65      0.67      5806\n",
      "    macro avg       0.51      0.39      0.40      5806\n",
      " weighted avg       0.67      0.65      0.64      5806\n",
      "  samples avg       0.42      0.39      0.38      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.6012552827596664\n",
      "Samples above threshold: 648\n",
      "Acquired samples: 648\n",
      "Sampling duration: 28.005051851272583 seconds\n",
      "\n",
      "Fold 5 - New train size: 4704\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 4704 samples...\n",
      "Epoch 1/10, Train Loss: 0.3231, Accuracy: 0.82, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.2011, Accuracy: 0.82, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.1895, Accuracy: 0.8381, F1 Micro: 0.2098, F1 Macro: 0.0803\n",
      "Epoch 4/10, Train Loss: 0.157, Accuracy: 0.8657, F1 Micro: 0.5289, F1 Macro: 0.248\n",
      "Epoch 5/10, Train Loss: 0.1425, Accuracy: 0.8759, F1 Micro: 0.5966, F1 Macro: 0.28\n",
      "Epoch 6/10, Train Loss: 0.1091, Accuracy: 0.8784, F1 Micro: 0.6462, F1 Macro: 0.3201\n",
      "Epoch 7/10, Train Loss: 0.0906, Accuracy: 0.8707, F1 Micro: 0.6604, F1 Macro: 0.3603\n",
      "Epoch 8/10, Train Loss: 0.0735, Accuracy: 0.8801, F1 Micro: 0.6766, F1 Macro: 0.4248\n",
      "Epoch 9/10, Train Loss: 0.0683, Accuracy: 0.8832, F1 Micro: 0.6781, F1 Macro: 0.4302\n",
      "Epoch 10/10, Train Loss: 0.0633, Accuracy: 0.8837, F1 Micro: 0.6867, F1 Macro: 0.4624\n",
      "Best result for 4704 samples: F1 Micro: 0.6867\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.78      0.89      0.83      1190\n",
      "      Abusive       0.88      0.84      0.86      1018\n",
      "HS_Individual       0.62      0.71      0.66       768\n",
      "     HS_Group       0.52      0.58      0.55       422\n",
      "  HS_Religion       0.37      0.39      0.38       173\n",
      "      HS_Race       0.72      0.35      0.47       126\n",
      "  HS_Physical       0.00      0.00      0.00        60\n",
      "    HS_Gender       0.00      0.00      0.00        67\n",
      "     HS_Other       0.64      0.79      0.71       792\n",
      "      HS_Weak       0.59      0.68      0.63       725\n",
      "  HS_Moderate       0.41      0.52      0.46       352\n",
      "    HS_Strong       0.00      0.00      0.00       113\n",
      "\n",
      "    micro avg       0.67      0.71      0.69      5806\n",
      "    macro avg       0.46      0.48      0.46      5806\n",
      " weighted avg       0.65      0.71      0.67      5806\n",
      "  samples avg       0.41      0.42      0.40      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.1721702814102173\n",
      "Samples above threshold: 584\n",
      "Acquired samples: 584\n",
      "Sampling duration: 25.465312957763672 seconds\n",
      "\n",
      "Fold 5 - New train size: 5288\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 5288 samples...\n",
      "Epoch 1/10, Train Loss: 0.3144, Accuracy: 0.82, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.2032, Accuracy: 0.82, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 3/10, Train Loss: 0.1854, Accuracy: 0.8647, F1 Micro: 0.4835, F1 Macro: 0.2212\n",
      "Epoch 4/10, Train Loss: 0.1568, Accuracy: 0.8722, F1 Micro: 0.5305, F1 Macro: 0.2496\n",
      "Epoch 5/10, Train Loss: 0.1303, Accuracy: 0.8809, F1 Micro: 0.6326, F1 Macro: 0.2991\n",
      "Epoch 6/10, Train Loss: 0.1083, Accuracy: 0.8843, F1 Micro: 0.6612, F1 Macro: 0.3407\n",
      "Epoch 7/10, Train Loss: 0.0888, Accuracy: 0.8868, F1 Micro: 0.6856, F1 Macro: 0.4303\n",
      "Epoch 8/10, Train Loss: 0.0739, Accuracy: 0.8865, F1 Micro: 0.685, F1 Macro: 0.4081\n",
      "Epoch 9/10, Train Loss: 0.0658, Accuracy: 0.8954, F1 Micro: 0.6943, F1 Macro: 0.4187\n",
      "Epoch 10/10, Train Loss: 0.057, Accuracy: 0.8889, F1 Micro: 0.6867, F1 Macro: 0.4545\n",
      "Best result for 5288 samples: F1 Micro: 0.6943\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.82      0.84      0.83      1190\n",
      "      Abusive       0.88      0.85      0.86      1018\n",
      "HS_Individual       0.67      0.69      0.68       768\n",
      "     HS_Group       0.67      0.44      0.53       422\n",
      "  HS_Religion       0.68      0.20      0.30       173\n",
      "      HS_Race       0.33      0.01      0.02       126\n",
      "  HS_Physical       0.00      0.00      0.00        60\n",
      "    HS_Gender       0.00      0.00      0.00        67\n",
      "     HS_Other       0.67      0.75      0.71       792\n",
      "      HS_Weak       0.63      0.66      0.65       725\n",
      "  HS_Moderate       0.51      0.38      0.43       352\n",
      "    HS_Strong       0.00      0.00      0.00       113\n",
      "\n",
      "    micro avg       0.73      0.66      0.69      5806\n",
      "    macro avg       0.49      0.40      0.42      5806\n",
      " weighted avg       0.69      0.66      0.66      5806\n",
      "  samples avg       0.42      0.40      0.39      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.14307417273521425\n",
      "Samples above threshold: 525\n",
      "Acquired samples: 525\n",
      "Sampling duration: 22.890665769577026 seconds\n",
      "\n",
      "Fold 5 - New train size: 5813\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 5813 samples...\n",
      "Epoch 1/10, Train Loss: 0.3211, Accuracy: 0.82, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.2185, Accuracy: 0.8248, F1 Micro: 0.0567, F1 Macro: 0.0235\n",
      "Epoch 3/10, Train Loss: 0.1945, Accuracy: 0.8753, F1 Micro: 0.5607, F1 Macro: 0.2621\n",
      "Epoch 4/10, Train Loss: 0.1646, Accuracy: 0.8753, F1 Micro: 0.6785, F1 Macro: 0.4395\n",
      "Epoch 5/10, Train Loss: 0.1401, Accuracy: 0.8875, F1 Micro: 0.6862, F1 Macro: 0.4331\n",
      "Epoch 6/10, Train Loss: 0.1146, Accuracy: 0.895, F1 Micro: 0.6925, F1 Macro: 0.4696\n",
      "Epoch 7/10, Train Loss: 0.0963, Accuracy: 0.8982, F1 Micro: 0.7021, F1 Macro: 0.4803\n",
      "Epoch 8/10, Train Loss: 0.0794, Accuracy: 0.8998, F1 Micro: 0.7054, F1 Macro: 0.4887\n",
      "Epoch 9/10, Train Loss: 0.0677, Accuracy: 0.9031, F1 Micro: 0.7209, F1 Macro: 0.4953\n",
      "Epoch 10/10, Train Loss: 0.0555, Accuracy: 0.9016, F1 Micro: 0.7221, F1 Macro: 0.4959\n",
      "Best result for 5813 samples: F1 Micro: 0.7221\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.85      0.84      1190\n",
      "      Abusive       0.90      0.87      0.88      1018\n",
      "HS_Individual       0.67      0.75      0.70       768\n",
      "     HS_Group       0.70      0.51      0.59       422\n",
      "  HS_Religion       0.75      0.38      0.51       173\n",
      "      HS_Race       0.91      0.39      0.54       126\n",
      "  HS_Physical       0.00      0.00      0.00        60\n",
      "    HS_Gender       0.00      0.00      0.00        67\n",
      "     HS_Other       0.67      0.79      0.73       792\n",
      "      HS_Weak       0.62      0.74      0.68       725\n",
      "  HS_Moderate       0.53      0.44      0.48       352\n",
      "    HS_Strong       0.00      0.00      0.00       113\n",
      "\n",
      "    micro avg       0.73      0.71      0.72      5806\n",
      "    macro avg       0.55      0.48      0.50      5806\n",
      " weighted avg       0.71      0.71      0.70      5806\n",
      "  samples avg       0.42      0.42      0.41      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.06254940032958985\n",
      "Samples above threshold: 473\n",
      "Acquired samples: 473\n",
      "Sampling duration: 20.599481105804443 seconds\n",
      "\n",
      "Fold 5 - New train size: 6286\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 6286 samples...\n",
      "Epoch 1/10, Train Loss: 0.3373, Accuracy: 0.82, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.2343, Accuracy: 0.854, F1 Micro: 0.3724, F1 Macro: 0.1598\n",
      "Epoch 3/10, Train Loss: 0.1936, Accuracy: 0.8848, F1 Micro: 0.6172, F1 Macro: 0.3688\n",
      "Epoch 4/10, Train Loss: 0.1561, Accuracy: 0.8952, F1 Micro: 0.6739, F1 Macro: 0.4442\n",
      "Epoch 5/10, Train Loss: 0.1311, Accuracy: 0.8984, F1 Micro: 0.7126, F1 Macro: 0.5039\n",
      "Epoch 6/10, Train Loss: 0.1095, Accuracy: 0.8992, F1 Micro: 0.7053, F1 Macro: 0.4696\n",
      "Epoch 7/10, Train Loss: 0.0911, Accuracy: 0.9014, F1 Micro: 0.7194, F1 Macro: 0.5272\n",
      "Epoch 8/10, Train Loss: 0.0735, Accuracy: 0.902, F1 Micro: 0.7226, F1 Macro: 0.5302\n",
      "Epoch 9/10, Train Loss: 0.0661, Accuracy: 0.8989, F1 Micro: 0.7235, F1 Macro: 0.543\n",
      "Epoch 10/10, Train Loss: 0.0561, Accuracy: 0.9015, F1 Micro: 0.7292, F1 Macro: 0.5413\n",
      "Best result for 6286 samples: F1 Micro: 0.7292\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.81      0.88      0.84      1190\n",
      "      Abusive       0.88      0.87      0.88      1018\n",
      "HS_Individual       0.68      0.70      0.69       768\n",
      "     HS_Group       0.61      0.66      0.64       422\n",
      "  HS_Religion       0.60      0.49      0.54       173\n",
      "      HS_Race       0.77      0.58      0.66       126\n",
      "  HS_Physical       0.00      0.00      0.00        60\n",
      "    HS_Gender       0.00      0.00      0.00        67\n",
      "     HS_Other       0.70      0.81      0.75       792\n",
      "      HS_Weak       0.64      0.69      0.66       725\n",
      "  HS_Moderate       0.49      0.56      0.52       352\n",
      "    HS_Strong       0.81      0.19      0.31       113\n",
      "\n",
      "    micro avg       0.72      0.74      0.73      5806\n",
      "    macro avg       0.58      0.54      0.54      5806\n",
      " weighted avg       0.71      0.74      0.72      5806\n",
      "  samples avg       0.43      0.44      0.42      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 6584\n",
      "Threshold: 0.043854916095733644\n",
      "Samples above threshold: 425\n",
      "Acquired samples: 298\n",
      "Sampling duration: 18.88219904899597 seconds\n",
      "\n",
      "Fold 5 - New train size: 6584\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 6584 samples...\n",
      "Epoch 1/10, Train Loss: 0.3405, Accuracy: 0.82, F1 Micro: 0.0, F1 Macro: 0.0\n",
      "Epoch 2/10, Train Loss: 0.2442, Accuracy: 0.8655, F1 Micro: 0.5143, F1 Macro: 0.2873\n",
      "Epoch 3/10, Train Loss: 0.2023, Accuracy: 0.8935, F1 Micro: 0.6673, F1 Macro: 0.4595\n",
      "Epoch 4/10, Train Loss: 0.1613, Accuracy: 0.9001, F1 Micro: 0.6809, F1 Macro: 0.5168\n",
      "Epoch 5/10, Train Loss: 0.1261, Accuracy: 0.9058, F1 Micro: 0.7248, F1 Macro: 0.5532\n",
      "Epoch 6/10, Train Loss: 0.1032, Accuracy: 0.9016, F1 Micro: 0.7274, F1 Macro: 0.5482\n",
      "Epoch 7/10, Train Loss: 0.0878, Accuracy: 0.9076, F1 Micro: 0.7371, F1 Macro: 0.5715\n",
      "Epoch 8/10, Train Loss: 0.0741, Accuracy: 0.9067, F1 Micro: 0.7368, F1 Macro: 0.5732\n",
      "Epoch 9/10, Train Loss: 0.0615, Accuracy: 0.9084, F1 Micro: 0.7422, F1 Macro: 0.5897\n",
      "Epoch 10/10, Train Loss: 0.0542, Accuracy: 0.9102, F1 Micro: 0.7272, F1 Macro: 0.5787\n",
      "Best result for 6584 samples: F1 Micro: 0.7422\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.86      0.85      1190\n",
      "      Abusive       0.90      0.84      0.87      1018\n",
      "HS_Individual       0.66      0.76      0.71       768\n",
      "     HS_Group       0.70      0.57      0.63       422\n",
      "  HS_Religion       0.75      0.46      0.57       173\n",
      "      HS_Race       0.79      0.67      0.72       126\n",
      "  HS_Physical       0.00      0.00      0.00        60\n",
      "    HS_Gender       0.00      0.00      0.00        67\n",
      "     HS_Other       0.70      0.80      0.75       792\n",
      "      HS_Weak       0.64      0.73      0.69       725\n",
      "  HS_Moderate       0.63      0.40      0.49       352\n",
      "    HS_Strong       0.86      0.76      0.81       113\n",
      "\n",
      "    micro avg       0.75      0.73      0.74      5806\n",
      "    macro avg       0.62      0.57      0.59      5806\n",
      " weighted avg       0.74      0.73      0.73      5806\n",
      "  samples avg       0.43      0.43      0.42      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 0.04369315505027771\n",
      "Samples above threshold: 396\n",
      "Acquired samples: 396\n",
      "Sampling duration: 17.369835138320923 seconds\n",
      "\n",
      "Fold 5 - New train size: 6980\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 6980 samples...\n",
      "Epoch 1/10, Train Loss: 0.3496, Accuracy: 0.8207, F1 Micro: 0.0075, F1 Macro: 0.003\n",
      "Epoch 2/10, Train Loss: 0.2418, Accuracy: 0.8831, F1 Micro: 0.6242, F1 Macro: 0.4265\n",
      "Epoch 3/10, Train Loss: 0.1914, Accuracy: 0.8918, F1 Micro: 0.633, F1 Macro: 0.4808\n",
      "Epoch 4/10, Train Loss: 0.1549, Accuracy: 0.9041, F1 Micro: 0.7201, F1 Macro: 0.5512\n",
      "Epoch 5/10, Train Loss: 0.1312, Accuracy: 0.9058, F1 Micro: 0.7231, F1 Macro: 0.5643\n",
      "Epoch 6/10, Train Loss: 0.1047, Accuracy: 0.9064, F1 Micro: 0.7318, F1 Macro: 0.5576\n",
      "Epoch 7/10, Train Loss: 0.0889, Accuracy: 0.91, F1 Micro: 0.7421, F1 Macro: 0.5855\n",
      "Epoch 8/10, Train Loss: 0.0782, Accuracy: 0.9132, F1 Micro: 0.7494, F1 Macro: 0.5936\n",
      "Epoch 9/10, Train Loss: 0.0648, Accuracy: 0.912, F1 Micro: 0.7449, F1 Macro: 0.5905\n",
      "Epoch 10/10, Train Loss: 0.0547, Accuracy: 0.9133, F1 Micro: 0.7452, F1 Macro: 0.5978\n",
      "Best result for 6980 samples: F1 Micro: 0.7494\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.86      0.85      1190\n",
      "      Abusive       0.90      0.86      0.88      1018\n",
      "HS_Individual       0.72      0.72      0.72       768\n",
      "     HS_Group       0.71      0.59      0.65       422\n",
      "  HS_Religion       0.71      0.49      0.58       173\n",
      "      HS_Race       0.80      0.59      0.68       126\n",
      "  HS_Physical       0.00      0.00      0.00        60\n",
      "    HS_Gender       0.00      0.00      0.00        67\n",
      "     HS_Other       0.74      0.73      0.74       792\n",
      "      HS_Weak       0.69      0.69      0.69       725\n",
      "  HS_Moderate       0.65      0.47      0.54       352\n",
      "    HS_Strong       0.87      0.74      0.80       113\n",
      "\n",
      "    micro avg       0.78      0.72      0.75      5806\n",
      "    macro avg       0.64      0.56      0.59      5806\n",
      " weighted avg       0.76      0.72      0.74      5806\n",
      "  samples avg       0.45      0.43      0.42      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 0.04100388288497925\n",
      "Samples above threshold: 356\n",
      "Acquired samples: 356\n",
      "Sampling duration: 15.900053977966309 seconds\n",
      "\n",
      "Fold 5 - New train size: 7336\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 7336 samples...\n",
      "Epoch 1/10, Train Loss: 0.361, Accuracy: 0.8273, F1 Micro: 0.0878, F1 Macro: 0.0358\n",
      "Epoch 2/10, Train Loss: 0.2506, Accuracy: 0.8904, F1 Micro: 0.6813, F1 Macro: 0.4918\n",
      "Epoch 3/10, Train Loss: 0.1955, Accuracy: 0.8947, F1 Micro: 0.6507, F1 Macro: 0.4984\n",
      "Epoch 4/10, Train Loss: 0.1576, Accuracy: 0.9077, F1 Micro: 0.7217, F1 Macro: 0.569\n",
      "Epoch 5/10, Train Loss: 0.1368, Accuracy: 0.9074, F1 Micro: 0.7184, F1 Macro: 0.5716\n",
      "Epoch 6/10, Train Loss: 0.1142, Accuracy: 0.9088, F1 Micro: 0.7364, F1 Macro: 0.5793\n",
      "Epoch 7/10, Train Loss: 0.0917, Accuracy: 0.9071, F1 Micro: 0.7506, F1 Macro: 0.6021\n",
      "Epoch 8/10, Train Loss: 0.0777, Accuracy: 0.9088, F1 Micro: 0.7438, F1 Macro: 0.5931\n",
      "Epoch 9/10, Train Loss: 0.0675, Accuracy: 0.9114, F1 Micro: 0.7475, F1 Macro: 0.6029\n",
      "Epoch 10/10, Train Loss: 0.0544, Accuracy: 0.9147, F1 Micro: 0.7481, F1 Macro: 0.6007\n",
      "Best result for 7336 samples: F1 Micro: 0.7506\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.80      0.92      0.85      1190\n",
      "      Abusive       0.87      0.90      0.88      1018\n",
      "HS_Individual       0.67      0.76      0.71       768\n",
      "     HS_Group       0.66      0.64      0.65       422\n",
      "  HS_Religion       0.63      0.61      0.62       173\n",
      "      HS_Race       0.77      0.75      0.76       126\n",
      "  HS_Physical       0.00      0.00      0.00        60\n",
      "    HS_Gender       0.00      0.00      0.00        67\n",
      "     HS_Other       0.68      0.82      0.74       792\n",
      "      HS_Weak       0.64      0.74      0.69       725\n",
      "  HS_Moderate       0.57      0.50      0.53       352\n",
      "    HS_Strong       0.83      0.74      0.79       113\n",
      "\n",
      "    micro avg       0.73      0.78      0.75      5806\n",
      "    macro avg       0.59      0.62      0.60      5806\n",
      " weighted avg       0.71      0.78      0.74      5806\n",
      "  samples avg       0.44      0.45      0.43      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 0.03421613574028015\n",
      "Samples above threshold: 320\n",
      "Acquired samples: 320\n",
      "Sampling duration: 14.287525415420532 seconds\n",
      "\n",
      "Fold 5 - New train size: 7656\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 7656 samples...\n",
      "Epoch 1/10, Train Loss: 0.3613, Accuracy: 0.8481, F1 Micro: 0.3063, F1 Macro: 0.1153\n",
      "Epoch 2/10, Train Loss: 0.2436, Accuracy: 0.8955, F1 Micro: 0.6746, F1 Macro: 0.4815\n",
      "Epoch 3/10, Train Loss: 0.1976, Accuracy: 0.9053, F1 Micro: 0.7095, F1 Macro: 0.5412\n",
      "Epoch 4/10, Train Loss: 0.1584, Accuracy: 0.9072, F1 Micro: 0.737, F1 Macro: 0.5814\n",
      "Epoch 5/10, Train Loss: 0.1341, Accuracy: 0.9127, F1 Micro: 0.7502, F1 Macro: 0.5843\n",
      "Epoch 6/10, Train Loss: 0.1127, Accuracy: 0.9154, F1 Micro: 0.7419, F1 Macro: 0.5897\n",
      "Epoch 7/10, Train Loss: 0.0954, Accuracy: 0.9171, F1 Micro: 0.7511, F1 Macro: 0.5942\n",
      "Epoch 8/10, Train Loss: 0.0791, Accuracy: 0.9101, F1 Micro: 0.7548, F1 Macro: 0.6078\n",
      "Epoch 9/10, Train Loss: 0.067, Accuracy: 0.9171, F1 Micro: 0.762, F1 Macro: 0.6058\n",
      "Epoch 10/10, Train Loss: 0.0599, Accuracy: 0.9186, F1 Micro: 0.7664, F1 Macro: 0.6346\n",
      "Best result for 7656 samples: F1 Micro: 0.7664\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.86      0.86      1190\n",
      "      Abusive       0.89      0.90      0.90      1018\n",
      "HS_Individual       0.73      0.72      0.73       768\n",
      "     HS_Group       0.71      0.64      0.67       422\n",
      "  HS_Religion       0.77      0.51      0.62       173\n",
      "      HS_Race       0.87      0.68      0.76       126\n",
      "  HS_Physical       1.00      0.13      0.24        60\n",
      "    HS_Gender       0.00      0.00      0.00        67\n",
      "     HS_Other       0.77      0.76      0.76       792\n",
      "      HS_Weak       0.71      0.69      0.70       725\n",
      "  HS_Moderate       0.62      0.54      0.58       352\n",
      "    HS_Strong       0.93      0.71      0.80       113\n",
      "\n",
      "    micro avg       0.79      0.74      0.77      5806\n",
      "    macro avg       0.74      0.60      0.63      5806\n",
      " weighted avg       0.78      0.74      0.76      5806\n",
      "  samples avg       0.46      0.44      0.43      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 7901\n",
      "Threshold: 0.024784213304519652\n",
      "Samples above threshold: 288\n",
      "Acquired samples: 245\n",
      "Sampling duration: 13.281105995178223 seconds\n",
      "\n",
      "Fold 5 - New train size: 7901\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 7901 samples...\n",
      "Epoch 1/10, Train Loss: 0.3726, Accuracy: 0.863, F1 Micro: 0.4753, F1 Macro: 0.2048\n",
      "Epoch 2/10, Train Loss: 0.2504, Accuracy: 0.897, F1 Micro: 0.6913, F1 Macro: 0.498\n",
      "Epoch 3/10, Train Loss: 0.1886, Accuracy: 0.9061, F1 Micro: 0.7265, F1 Macro: 0.5594\n",
      "Epoch 4/10, Train Loss: 0.1684, Accuracy: 0.9131, F1 Micro: 0.7487, F1 Macro: 0.5909\n",
      "Epoch 5/10, Train Loss: 0.1332, Accuracy: 0.9098, F1 Micro: 0.7526, F1 Macro: 0.604\n",
      "Epoch 6/10, Train Loss: 0.1169, Accuracy: 0.9146, F1 Micro: 0.7636, F1 Macro: 0.6021\n",
      "Epoch 7/10, Train Loss: 0.0917, Accuracy: 0.9169, F1 Micro: 0.7616, F1 Macro: 0.6088\n",
      "Epoch 8/10, Train Loss: 0.0783, Accuracy: 0.918, F1 Micro: 0.7681, F1 Macro: 0.6184\n",
      "Epoch 9/10, Train Loss: 0.0728, Accuracy: 0.9079, F1 Micro: 0.7573, F1 Macro: 0.6141\n",
      "Epoch 10/10, Train Loss: 0.0623, Accuracy: 0.9148, F1 Micro: 0.7682, F1 Macro: 0.6263\n",
      "Best result for 7901 samples: F1 Micro: 0.7682\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.81      0.90      0.85      1190\n",
      "      Abusive       0.89      0.89      0.89      1018\n",
      "HS_Individual       0.68      0.81      0.74       768\n",
      "     HS_Group       0.72      0.60      0.66       422\n",
      "  HS_Religion       0.74      0.50      0.60       173\n",
      "      HS_Race       0.83      0.68      0.75       126\n",
      "  HS_Physical       1.00      0.08      0.15        60\n",
      "    HS_Gender       0.00      0.00      0.00        67\n",
      "     HS_Other       0.71      0.86      0.78       792\n",
      "      HS_Weak       0.66      0.79      0.72       725\n",
      "  HS_Moderate       0.63      0.50      0.56       352\n",
      "    HS_Strong       0.85      0.80      0.82       113\n",
      "\n",
      "    micro avg       0.75      0.78      0.77      5806\n",
      "    macro avg       0.71      0.62      0.63      5806\n",
      " weighted avg       0.75      0.78      0.76      5806\n",
      "  samples avg       0.45      0.46      0.44      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.01717602014541626\n",
      "Samples above threshold: 264\n",
      "Acquired samples: 264\n",
      "Sampling duration: 11.925373315811157 seconds\n",
      "\n",
      "Fold 5 - New train size: 8165\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 8165 samples...\n",
      "Epoch 1/10, Train Loss: 0.37, Accuracy: 0.8669, F1 Micro: 0.5058, F1 Macro: 0.2323\n",
      "Epoch 2/10, Train Loss: 0.2478, Accuracy: 0.8973, F1 Micro: 0.6741, F1 Macro: 0.4656\n",
      "Epoch 3/10, Train Loss: 0.1991, Accuracy: 0.9081, F1 Micro: 0.7217, F1 Macro: 0.5407\n",
      "Epoch 4/10, Train Loss: 0.1638, Accuracy: 0.9104, F1 Micro: 0.7173, F1 Macro: 0.5475\n",
      "Epoch 5/10, Train Loss: 0.1382, Accuracy: 0.9153, F1 Micro: 0.7539, F1 Macro: 0.6014\n",
      "Epoch 6/10, Train Loss: 0.1153, Accuracy: 0.9158, F1 Micro: 0.7581, F1 Macro: 0.6046\n",
      "Epoch 7/10, Train Loss: 0.0985, Accuracy: 0.9156, F1 Micro: 0.7551, F1 Macro: 0.6079\n",
      "Epoch 8/10, Train Loss: 0.0841, Accuracy: 0.9191, F1 Micro: 0.7632, F1 Macro: 0.6167\n",
      "Epoch 9/10, Train Loss: 0.0705, Accuracy: 0.9123, F1 Micro: 0.7558, F1 Macro: 0.608\n",
      "Epoch 10/10, Train Loss: 0.06, Accuracy: 0.9184, F1 Micro: 0.7602, F1 Macro: 0.6225\n",
      "Best result for 8165 samples: F1 Micro: 0.7632\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.88      0.83      0.85      1190\n",
      "      Abusive       0.89      0.89      0.89      1018\n",
      "HS_Individual       0.76      0.68      0.72       768\n",
      "     HS_Group       0.74      0.65      0.69       422\n",
      "  HS_Religion       0.76      0.53      0.62       173\n",
      "      HS_Race       0.82      0.70      0.76       126\n",
      "  HS_Physical       0.00      0.00      0.00        60\n",
      "    HS_Gender       0.00      0.00      0.00        67\n",
      "     HS_Other       0.78      0.73      0.75       792\n",
      "      HS_Weak       0.74      0.66      0.70       725\n",
      "  HS_Moderate       0.66      0.57      0.61       352\n",
      "    HS_Strong       0.89      0.74      0.81       113\n",
      "\n",
      "    micro avg       0.81      0.72      0.76      5806\n",
      "    macro avg       0.66      0.58      0.62      5806\n",
      " weighted avg       0.79      0.72      0.75      5806\n",
      "  samples avg       0.45      0.42      0.42      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.025645673274993896\n",
      "Samples above threshold: 238\n",
      "Acquired samples: 238\n",
      "Sampling duration: 10.848515033721924 seconds\n",
      "\n",
      "Fold 5 - New train size: 8403\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 8403 samples...\n",
      "Epoch 1/10, Train Loss: 0.3724, Accuracy: 0.8685, F1 Micro: 0.5374, F1 Macro: 0.2654\n",
      "Epoch 2/10, Train Loss: 0.2477, Accuracy: 0.896, F1 Micro: 0.6638, F1 Macro: 0.456\n",
      "Epoch 3/10, Train Loss: 0.1925, Accuracy: 0.9082, F1 Micro: 0.7108, F1 Macro: 0.5392\n",
      "Epoch 4/10, Train Loss: 0.1625, Accuracy: 0.9096, F1 Micro: 0.745, F1 Macro: 0.5933\n",
      "Epoch 5/10, Train Loss: 0.1403, Accuracy: 0.91, F1 Micro: 0.7578, F1 Macro: 0.5971\n",
      "Epoch 6/10, Train Loss: 0.1148, Accuracy: 0.9164, F1 Micro: 0.7574, F1 Macro: 0.61\n",
      "Epoch 7/10, Train Loss: 0.0978, Accuracy: 0.9182, F1 Micro: 0.7554, F1 Macro: 0.6113\n",
      "Epoch 8/10, Train Loss: 0.0827, Accuracy: 0.9186, F1 Micro: 0.7666, F1 Macro: 0.6179\n",
      "Epoch 9/10, Train Loss: 0.0675, Accuracy: 0.9171, F1 Micro: 0.77, F1 Macro: 0.6169\n",
      "Epoch 10/10, Train Loss: 0.0593, Accuracy: 0.9173, F1 Micro: 0.7684, F1 Macro: 0.6327\n",
      "Best result for 8403 samples: F1 Micro: 0.77\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.84      0.89      0.86      1190\n",
      "      Abusive       0.88      0.89      0.89      1018\n",
      "HS_Individual       0.68      0.79      0.73       768\n",
      "     HS_Group       0.78      0.59      0.67       422\n",
      "  HS_Religion       0.76      0.45      0.56       173\n",
      "      HS_Race       0.85      0.72      0.78       126\n",
      "  HS_Physical       0.00      0.00      0.00        60\n",
      "    HS_Gender       0.00      0.00      0.00        67\n",
      "     HS_Other       0.71      0.83      0.77       792\n",
      "      HS_Weak       0.66      0.78      0.72       725\n",
      "  HS_Moderate       0.71      0.49      0.58       352\n",
      "    HS_Strong       0.87      0.81      0.83       113\n",
      "\n",
      "    micro avg       0.77      0.77      0.77      5806\n",
      "    macro avg       0.65      0.60      0.62      5806\n",
      " weighted avg       0.76      0.77      0.76      5806\n",
      "  samples avg       0.45      0.45      0.43      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.018251776695251465\n",
      "Samples above threshold: 214\n",
      "Acquired samples: 214\n",
      "Sampling duration: 9.890583276748657 seconds\n",
      "\n",
      "Fold 5 - New train size: 8617\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 8617 samples...\n",
      "Epoch 1/10, Train Loss: 0.3768, Accuracy: 0.8734, F1 Micro: 0.6123, F1 Macro: 0.3064\n",
      "Epoch 2/10, Train Loss: 0.2526, Accuracy: 0.8982, F1 Micro: 0.6927, F1 Macro: 0.4741\n",
      "Epoch 3/10, Train Loss: 0.2001, Accuracy: 0.9057, F1 Micro: 0.711, F1 Macro: 0.5647\n",
      "Epoch 4/10, Train Loss: 0.1659, Accuracy: 0.9145, F1 Micro: 0.7557, F1 Macro: 0.5956\n",
      "Epoch 5/10, Train Loss: 0.1393, Accuracy: 0.9166, F1 Micro: 0.7597, F1 Macro: 0.6008\n",
      "Epoch 6/10, Train Loss: 0.1163, Accuracy: 0.9174, F1 Micro: 0.7501, F1 Macro: 0.5896\n",
      "Epoch 7/10, Train Loss: 0.0982, Accuracy: 0.9198, F1 Micro: 0.7707, F1 Macro: 0.6184\n",
      "Epoch 8/10, Train Loss: 0.0816, Accuracy: 0.9182, F1 Micro: 0.7675, F1 Macro: 0.6195\n",
      "Epoch 9/10, Train Loss: 0.0716, Accuracy: 0.9191, F1 Micro: 0.7688, F1 Macro: 0.629\n",
      "Epoch 10/10, Train Loss: 0.0612, Accuracy: 0.9155, F1 Micro: 0.7647, F1 Macro: 0.6221\n",
      "Best result for 8617 samples: F1 Micro: 0.7707\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.86      0.86      1190\n",
      "      Abusive       0.91      0.86      0.88      1018\n",
      "HS_Individual       0.73      0.76      0.74       768\n",
      "     HS_Group       0.78      0.61      0.68       422\n",
      "  HS_Religion       0.73      0.48      0.58       173\n",
      "      HS_Race       0.86      0.68      0.76       126\n",
      "  HS_Physical       0.00      0.00      0.00        60\n",
      "    HS_Gender       0.00      0.00      0.00        67\n",
      "     HS_Other       0.73      0.80      0.77       792\n",
      "      HS_Weak       0.71      0.75      0.73       725\n",
      "  HS_Moderate       0.70      0.52      0.60       352\n",
      "    HS_Strong       0.88      0.77      0.82       113\n",
      "\n",
      "    micro avg       0.79      0.75      0.77      5806\n",
      "    macro avg       0.66      0.59      0.62      5806\n",
      " weighted avg       0.78      0.75      0.76      5806\n",
      "  samples avg       0.44      0.43      0.42      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.026885867118835456\n",
      "Samples above threshold: 192\n",
      "Acquired samples: 200\n",
      "Sampling duration: 9.029202699661255 seconds\n",
      "\n",
      "Fold 5 - New train size: 8817\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 8817 samples...\n",
      "Epoch 1/10, Train Loss: 0.3746, Accuracy: 0.8708, F1 Micro: 0.5267, F1 Macro: 0.2456\n",
      "Epoch 2/10, Train Loss: 0.2445, Accuracy: 0.8995, F1 Micro: 0.6923, F1 Macro: 0.4575\n",
      "Epoch 3/10, Train Loss: 0.1985, Accuracy: 0.9095, F1 Micro: 0.7162, F1 Macro: 0.5435\n",
      "Epoch 4/10, Train Loss: 0.1621, Accuracy: 0.9171, F1 Micro: 0.7512, F1 Macro: 0.5949\n",
      "Epoch 5/10, Train Loss: 0.1392, Accuracy: 0.9157, F1 Micro: 0.7666, F1 Macro: 0.6003\n",
      "Epoch 6/10, Train Loss: 0.1159, Accuracy: 0.9145, F1 Micro: 0.7641, F1 Macro: 0.6114\n",
      "Epoch 7/10, Train Loss: 0.0976, Accuracy: 0.9192, F1 Micro: 0.7618, F1 Macro: 0.6087\n",
      "Epoch 8/10, Train Loss: 0.0853, Accuracy: 0.9175, F1 Micro: 0.7688, F1 Macro: 0.6267\n",
      "Epoch 9/10, Train Loss: 0.0716, Accuracy: 0.9193, F1 Micro: 0.7653, F1 Macro: 0.6272\n",
      "Epoch 10/10, Train Loss: 0.0612, Accuracy: 0.9212, F1 Micro: 0.7707, F1 Macro: 0.6328\n",
      "Best result for 8817 samples: F1 Micro: 0.7707\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.88      0.85      0.86      1190\n",
      "      Abusive       0.91      0.88      0.89      1018\n",
      "HS_Individual       0.74      0.73      0.74       768\n",
      "     HS_Group       0.78      0.59      0.67       422\n",
      "  HS_Religion       0.68      0.54      0.60       173\n",
      "      HS_Race       0.85      0.67      0.75       126\n",
      "  HS_Physical       0.56      0.08      0.14        60\n",
      "    HS_Gender       1.00      0.01      0.03        67\n",
      "     HS_Other       0.78      0.75      0.77       792\n",
      "      HS_Weak       0.72      0.72      0.72       725\n",
      "  HS_Moderate       0.71      0.49      0.58       352\n",
      "    HS_Strong       0.87      0.80      0.83       113\n",
      "\n",
      "    micro avg       0.81      0.74      0.77      5806\n",
      "    macro avg       0.79      0.59      0.63      5806\n",
      " weighted avg       0.81      0.74      0.76      5806\n",
      "  samples avg       0.45      0.43      0.43      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.016671800613403325\n",
      "Samples above threshold: 172\n",
      "Acquired samples: 200\n",
      "Sampling duration: 8.050448656082153 seconds\n",
      "\n",
      "Fold 5 - New train size: 9017\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 9017 samples...\n",
      "Epoch 1/10, Train Loss: 0.3726, Accuracy: 0.8724, F1 Micro: 0.5418, F1 Macro: 0.2513\n",
      "Epoch 2/10, Train Loss: 0.2454, Accuracy: 0.8999, F1 Micro: 0.7094, F1 Macro: 0.4824\n",
      "Epoch 3/10, Train Loss: 0.1963, Accuracy: 0.9095, F1 Micro: 0.7295, F1 Macro: 0.5377\n",
      "Epoch 4/10, Train Loss: 0.1649, Accuracy: 0.9145, F1 Micro: 0.7364, F1 Macro: 0.5756\n",
      "Epoch 5/10, Train Loss: 0.1389, Accuracy: 0.9174, F1 Micro: 0.7649, F1 Macro: 0.6008\n",
      "Epoch 6/10, Train Loss: 0.1162, Accuracy: 0.9206, F1 Micro: 0.7654, F1 Macro: 0.6161\n",
      "Epoch 7/10, Train Loss: 0.095, Accuracy: 0.9165, F1 Micro: 0.7639, F1 Macro: 0.6107\n",
      "Epoch 8/10, Train Loss: 0.0826, Accuracy: 0.9189, F1 Micro: 0.77, F1 Macro: 0.6198\n",
      "Epoch 9/10, Train Loss: 0.0739, Accuracy: 0.9181, F1 Micro: 0.7512, F1 Macro: 0.6029\n",
      "Epoch 10/10, Train Loss: 0.0627, Accuracy: 0.9197, F1 Micro: 0.775, F1 Macro: 0.6355\n",
      "Best result for 9017 samples: F1 Micro: 0.775\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.87      0.86      1190\n",
      "      Abusive       0.88      0.91      0.90      1018\n",
      "HS_Individual       0.70      0.78      0.74       768\n",
      "     HS_Group       0.77      0.57      0.65       422\n",
      "  HS_Religion       0.72      0.53      0.61       173\n",
      "      HS_Race       0.83      0.71      0.76       126\n",
      "  HS_Physical       0.75      0.10      0.18        60\n",
      "    HS_Gender       0.00      0.00      0.00        67\n",
      "     HS_Other       0.76      0.83      0.79       792\n",
      "      HS_Weak       0.68      0.76      0.72       725\n",
      "  HS_Moderate       0.71      0.47      0.56       352\n",
      "    HS_Strong       0.84      0.86      0.85       113\n",
      "\n",
      "    micro avg       0.78      0.77      0.78      5806\n",
      "    macro avg       0.71      0.62      0.64      5806\n",
      " weighted avg       0.77      0.77      0.76      5806\n",
      "  samples avg       0.46      0.45      0.44      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.011184537410736089\n",
      "Samples above threshold: 152\n",
      "Acquired samples: 200\n",
      "Sampling duration: 7.301624059677124 seconds\n",
      "\n",
      "Fold 5 - New train size: 9217\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 9217 samples...\n",
      "Epoch 1/10, Train Loss: 0.3704, Accuracy: 0.8792, F1 Micro: 0.6143, F1 Macro: 0.3115\n",
      "Epoch 2/10, Train Loss: 0.2441, Accuracy: 0.8992, F1 Micro: 0.7009, F1 Macro: 0.4566\n",
      "Epoch 3/10, Train Loss: 0.197, Accuracy: 0.9131, F1 Micro: 0.7452, F1 Macro: 0.5703\n",
      "Epoch 4/10, Train Loss: 0.1618, Accuracy: 0.9116, F1 Micro: 0.7579, F1 Macro: 0.6019\n",
      "Epoch 5/10, Train Loss: 0.1407, Accuracy: 0.9138, F1 Micro: 0.7648, F1 Macro: 0.6078\n",
      "Epoch 6/10, Train Loss: 0.117, Accuracy: 0.9149, F1 Micro: 0.771, F1 Macro: 0.6199\n",
      "Epoch 7/10, Train Loss: 0.0955, Accuracy: 0.9212, F1 Micro: 0.7669, F1 Macro: 0.6205\n",
      "Epoch 8/10, Train Loss: 0.0811, Accuracy: 0.9164, F1 Micro: 0.7695, F1 Macro: 0.6141\n",
      "Epoch 9/10, Train Loss: 0.068, Accuracy: 0.9225, F1 Micro: 0.7763, F1 Macro: 0.6326\n",
      "Epoch 10/10, Train Loss: 0.0599, Accuracy: 0.9217, F1 Micro: 0.7716, F1 Macro: 0.642\n",
      "Best result for 9217 samples: F1 Micro: 0.7763\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.88      0.85      0.86      1190\n",
      "      Abusive       0.90      0.88      0.89      1018\n",
      "HS_Individual       0.76      0.73      0.74       768\n",
      "     HS_Group       0.74      0.65      0.69       422\n",
      "  HS_Religion       0.73      0.55      0.63       173\n",
      "      HS_Race       0.86      0.68      0.76       126\n",
      "  HS_Physical       0.57      0.07      0.12        60\n",
      "    HS_Gender       0.00      0.00      0.00        67\n",
      "     HS_Other       0.80      0.77      0.78       792\n",
      "      HS_Weak       0.73      0.72      0.73       725\n",
      "  HS_Moderate       0.65      0.57      0.60       352\n",
      "    HS_Strong       0.89      0.69      0.78       113\n",
      "\n",
      "    micro avg       0.81      0.75      0.78      5806\n",
      "    macro avg       0.71      0.60      0.63      5806\n",
      " weighted avg       0.79      0.75      0.77      5806\n",
      "  samples avg       0.45      0.44      0.43      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 9218\n",
      "Threshold: 0.010915982723236085\n",
      "Samples above threshold: 132\n",
      "Acquired samples: 1\n",
      "Sampling duration: 6.839584589004517 seconds\n",
      "\n",
      "Fold 5 - New train size: 9218\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 9218 samples...\n",
      "Epoch 1/10, Train Loss: 0.3751, Accuracy: 0.8762, F1 Micro: 0.579, F1 Macro: 0.2794\n",
      "Epoch 2/10, Train Loss: 0.245, Accuracy: 0.901, F1 Micro: 0.6971, F1 Macro: 0.5128\n",
      "Epoch 3/10, Train Loss: 0.1974, Accuracy: 0.9101, F1 Micro: 0.7456, F1 Macro: 0.5959\n",
      "Epoch 4/10, Train Loss: 0.1638, Accuracy: 0.9129, F1 Micro: 0.762, F1 Macro: 0.6008\n",
      "Epoch 5/10, Train Loss: 0.1377, Accuracy: 0.9145, F1 Micro: 0.7664, F1 Macro: 0.6125\n",
      "Epoch 6/10, Train Loss: 0.1142, Accuracy: 0.921, F1 Micro: 0.7729, F1 Macro: 0.619\n",
      "Epoch 7/10, Train Loss: 0.0976, Accuracy: 0.9194, F1 Micro: 0.7729, F1 Macro: 0.6195\n",
      "Epoch 8/10, Train Loss: 0.0866, Accuracy: 0.9208, F1 Micro: 0.7786, F1 Macro: 0.643\n",
      "Epoch 9/10, Train Loss: 0.0716, Accuracy: 0.9203, F1 Micro: 0.774, F1 Macro: 0.6459\n",
      "Epoch 10/10, Train Loss: 0.0609, Accuracy: 0.9228, F1 Micro: 0.7759, F1 Macro: 0.6455\n",
      "Best result for 9218 samples: F1 Micro: 0.7786\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.88      0.87      1190\n",
      "      Abusive       0.87      0.91      0.89      1018\n",
      "HS_Individual       0.74      0.74      0.74       768\n",
      "     HS_Group       0.71      0.69      0.70       422\n",
      "  HS_Religion       0.73      0.57      0.64       173\n",
      "      HS_Race       0.83      0.67      0.74       126\n",
      "  HS_Physical       0.86      0.10      0.18        60\n",
      "    HS_Gender       0.00      0.00      0.00        67\n",
      "     HS_Other       0.76      0.80      0.78       792\n",
      "      HS_Weak       0.72      0.72      0.72       725\n",
      "  HS_Moderate       0.66      0.61      0.63       352\n",
      "    HS_Strong       0.86      0.81      0.83       113\n",
      "\n",
      "    micro avg       0.78      0.77      0.78      5806\n",
      "    macro avg       0.71      0.63      0.64      5806\n",
      " weighted avg       0.77      0.77      0.77      5806\n",
      "  samples avg       0.45      0.45      0.44      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10536\n",
      "Threshold: 0.011591768264770506\n",
      "Samples above threshold: 132\n",
      "Acquired samples: 200\n",
      "Sampling duration: 6.495371341705322 seconds\n",
      "\n",
      "Fold 5 - New train size: 9418\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 9418 samples...\n",
      "Epoch 1/10, Train Loss: 0.3748, Accuracy: 0.877, F1 Micro: 0.5743, F1 Macro: 0.271\n",
      "Epoch 2/10, Train Loss: 0.2456, Accuracy: 0.9028, F1 Micro: 0.7215, F1 Macro: 0.5266\n",
      "Epoch 3/10, Train Loss: 0.201, Accuracy: 0.9124, F1 Micro: 0.7382, F1 Macro: 0.5669\n",
      "Epoch 4/10, Train Loss: 0.1661, Accuracy: 0.9168, F1 Micro: 0.7553, F1 Macro: 0.5906\n",
      "Epoch 5/10, Train Loss: 0.141, Accuracy: 0.9194, F1 Micro: 0.7666, F1 Macro: 0.6086\n",
      "Epoch 6/10, Train Loss: 0.1159, Accuracy: 0.9189, F1 Micro: 0.7689, F1 Macro: 0.6099\n",
      "Epoch 7/10, Train Loss: 0.0975, Accuracy: 0.9236, F1 Micro: 0.7787, F1 Macro: 0.6295\n",
      "Epoch 8/10, Train Loss: 0.0847, Accuracy: 0.9213, F1 Micro: 0.7732, F1 Macro: 0.6485\n",
      "Epoch 9/10, Train Loss: 0.0702, Accuracy: 0.922, F1 Micro: 0.771, F1 Macro: 0.649\n",
      "Epoch 10/10, Train Loss: 0.0622, Accuracy: 0.9224, F1 Micro: 0.7767, F1 Macro: 0.6615\n",
      "Best result for 9418 samples: F1 Micro: 0.7787\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.88      0.85      0.86      1190\n",
      "      Abusive       0.89      0.88      0.89      1018\n",
      "HS_Individual       0.76      0.73      0.75       768\n",
      "     HS_Group       0.78      0.64      0.70       422\n",
      "  HS_Religion       0.72      0.54      0.62       173\n",
      "      HS_Race       0.81      0.70      0.75       126\n",
      "  HS_Physical       1.00      0.02      0.03        60\n",
      "    HS_Gender       0.00      0.00      0.00        67\n",
      "     HS_Other       0.78      0.78      0.78       792\n",
      "      HS_Weak       0.75      0.71      0.73       725\n",
      "  HS_Moderate       0.71      0.55      0.62       352\n",
      "    HS_Strong       0.83      0.81      0.82       113\n",
      "\n",
      "    micro avg       0.81      0.75      0.78      5806\n",
      "    macro avg       0.74      0.60      0.63      5806\n",
      " weighted avg       0.80      0.75      0.77      5806\n",
      "  samples avg       0.46      0.44      0.43      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10536\n",
      "Threshold: 0.015363264083862306\n",
      "Samples above threshold: 112\n",
      "Acquired samples: 200\n",
      "Sampling duration: 6.7289228439331055 seconds\n",
      "\n",
      "Fold 5 - New train size: 9618\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 9618 samples...\n",
      "Epoch 1/10, Train Loss: 0.3702, Accuracy: 0.8769, F1 Micro: 0.5723, F1 Macro: 0.2682\n",
      "Epoch 2/10, Train Loss: 0.2458, Accuracy: 0.9028, F1 Micro: 0.7169, F1 Macro: 0.5388\n",
      "Epoch 3/10, Train Loss: 0.1997, Accuracy: 0.9113, F1 Micro: 0.7454, F1 Macro: 0.5569\n",
      "Epoch 4/10, Train Loss: 0.1663, Accuracy: 0.916, F1 Micro: 0.7662, F1 Macro: 0.6059\n",
      "Epoch 5/10, Train Loss: 0.1399, Accuracy: 0.9212, F1 Micro: 0.768, F1 Macro: 0.6164\n",
      "Epoch 6/10, Train Loss: 0.1163, Accuracy: 0.9195, F1 Micro: 0.7786, F1 Macro: 0.6272\n",
      "Epoch 7/10, Train Loss: 0.0933, Accuracy: 0.9216, F1 Micro: 0.7739, F1 Macro: 0.6386\n",
      "Epoch 8/10, Train Loss: 0.0827, Accuracy: 0.9202, F1 Micro: 0.7753, F1 Macro: 0.6427\n",
      "Epoch 9/10, Train Loss: 0.0722, Accuracy: 0.9225, F1 Micro: 0.7784, F1 Macro: 0.6644\n",
      "Epoch 10/10, Train Loss: 0.0603, Accuracy: 0.9232, F1 Micro: 0.7779, F1 Macro: 0.646\n",
      "Best result for 9618 samples: F1 Micro: 0.7786\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.89      0.86      1190\n",
      "      Abusive       0.87      0.91      0.89      1018\n",
      "HS_Individual       0.71      0.81      0.76       768\n",
      "     HS_Group       0.78      0.65      0.71       422\n",
      "  HS_Religion       0.73      0.53      0.61       173\n",
      "      HS_Race       0.83      0.69      0.75       126\n",
      "  HS_Physical       1.00      0.02      0.03        60\n",
      "    HS_Gender       0.00      0.00      0.00        67\n",
      "     HS_Other       0.71      0.82      0.76       792\n",
      "      HS_Weak       0.69      0.80      0.74       725\n",
      "  HS_Moderate       0.69      0.54      0.61       352\n",
      "    HS_Strong       0.90      0.73      0.80       113\n",
      "\n",
      "    micro avg       0.77      0.79      0.78      5806\n",
      "    macro avg       0.73      0.62      0.63      5806\n",
      " weighted avg       0.77      0.79      0.77      5806\n",
      "  samples avg       0.45      0.46      0.44      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10536\n",
      "Threshold: 0.012383997440338137\n",
      "Samples above threshold: 92\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.778926372528076 seconds\n",
      "\n",
      "Fold 5 - New train size: 9818\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 9818 samples...\n",
      "Epoch 1/10, Train Loss: 0.3689, Accuracy: 0.88, F1 Micro: 0.5947, F1 Macro: 0.2941\n",
      "Epoch 2/10, Train Loss: 0.2437, Accuracy: 0.9041, F1 Micro: 0.6972, F1 Macro: 0.4916\n",
      "Epoch 3/10, Train Loss: 0.1956, Accuracy: 0.9127, F1 Micro: 0.743, F1 Macro: 0.5787\n",
      "Epoch 4/10, Train Loss: 0.1666, Accuracy: 0.9178, F1 Micro: 0.7651, F1 Macro: 0.6085\n",
      "Epoch 5/10, Train Loss: 0.1354, Accuracy: 0.9209, F1 Micro: 0.774, F1 Macro: 0.6264\n",
      "Epoch 6/10, Train Loss: 0.1161, Accuracy: 0.9218, F1 Micro: 0.7698, F1 Macro: 0.632\n",
      "Epoch 7/10, Train Loss: 0.099, Accuracy: 0.9227, F1 Micro: 0.7749, F1 Macro: 0.6475\n",
      "Epoch 8/10, Train Loss: 0.081, Accuracy: 0.9233, F1 Micro: 0.7839, F1 Macro: 0.6767\n",
      "Epoch 9/10, Train Loss: 0.0665, Accuracy: 0.921, F1 Micro: 0.7782, F1 Macro: 0.6715\n",
      "Epoch 10/10, Train Loss: 0.0611, Accuracy: 0.9207, F1 Micro: 0.7846, F1 Macro: 0.6946\n",
      "Best result for 9818 samples: F1 Micro: 0.7846\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.83      0.91      0.87      1190\n",
      "      Abusive       0.88      0.92      0.90      1018\n",
      "HS_Individual       0.69      0.80      0.74       768\n",
      "     HS_Group       0.74      0.65      0.69       422\n",
      "  HS_Religion       0.68      0.61      0.64       173\n",
      "      HS_Race       0.82      0.70      0.76       126\n",
      "  HS_Physical       0.53      0.40      0.46        60\n",
      "    HS_Gender       1.00      0.18      0.30        67\n",
      "     HS_Other       0.77      0.83      0.80       792\n",
      "      HS_Weak       0.67      0.79      0.73       725\n",
      "  HS_Moderate       0.66      0.56      0.61       352\n",
      "    HS_Strong       0.86      0.83      0.85       113\n",
      "\n",
      "    micro avg       0.77      0.80      0.78      5806\n",
      "    macro avg       0.76      0.68      0.69      5806\n",
      " weighted avg       0.77      0.80      0.78      5806\n",
      "  samples avg       0.46      0.47      0.45      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10536\n",
      "Threshold: 0.004164725542068483\n",
      "Samples above threshold: 72\n",
      "Acquired samples: 200\n",
      "Sampling duration: 4.169554233551025 seconds\n",
      "\n",
      "Fold 5 - New train size: 10018\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 10018 samples...\n",
      "Epoch 1/10, Train Loss: 0.3725, Accuracy: 0.883, F1 Micro: 0.6186, F1 Macro: 0.3119\n",
      "Epoch 2/10, Train Loss: 0.2457, Accuracy: 0.903, F1 Micro: 0.7333, F1 Macro: 0.5458\n",
      "Epoch 3/10, Train Loss: 0.2034, Accuracy: 0.9089, F1 Micro: 0.753, F1 Macro: 0.5741\n",
      "Epoch 4/10, Train Loss: 0.1672, Accuracy: 0.9178, F1 Micro: 0.7654, F1 Macro: 0.6112\n",
      "Epoch 5/10, Train Loss: 0.1378, Accuracy: 0.9204, F1 Micro: 0.7761, F1 Macro: 0.6343\n",
      "Epoch 6/10, Train Loss: 0.1177, Accuracy: 0.9151, F1 Micro: 0.7558, F1 Macro: 0.6241\n",
      "Epoch 7/10, Train Loss: 0.0987, Accuracy: 0.9222, F1 Micro: 0.7792, F1 Macro: 0.652\n",
      "Epoch 8/10, Train Loss: 0.0825, Accuracy: 0.9223, F1 Micro: 0.7801, F1 Macro: 0.669\n",
      "Epoch 9/10, Train Loss: 0.069, Accuracy: 0.9196, F1 Micro: 0.7775, F1 Macro: 0.6815\n",
      "Epoch 10/10, Train Loss: 0.063, Accuracy: 0.9225, F1 Micro: 0.7832, F1 Macro: 0.6938\n",
      "Best result for 10018 samples: F1 Micro: 0.7832\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.85      0.89      0.87      1190\n",
      "      Abusive       0.89      0.91      0.90      1018\n",
      "HS_Individual       0.73      0.77      0.75       768\n",
      "     HS_Group       0.73      0.65      0.69       422\n",
      "  HS_Religion       0.77      0.51      0.61       173\n",
      "      HS_Race       0.74      0.74      0.74       126\n",
      "  HS_Physical       0.62      0.43      0.51        60\n",
      "    HS_Gender       0.88      0.21      0.34        67\n",
      "     HS_Other       0.77      0.82      0.79       792\n",
      "      HS_Weak       0.71      0.73      0.72       725\n",
      "  HS_Moderate       0.67      0.54      0.60       352\n",
      "    HS_Strong       0.83      0.80      0.81       113\n",
      "\n",
      "    micro avg       0.79      0.78      0.78      5806\n",
      "    macro avg       0.77      0.66      0.69      5806\n",
      " weighted avg       0.79      0.78      0.78      5806\n",
      "  samples avg       0.46      0.45      0.44      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10536\n",
      "Threshold: 0.0035541951656341557\n",
      "Samples above threshold: 52\n",
      "Acquired samples: 200\n",
      "Sampling duration: 3.0897231101989746 seconds\n",
      "\n",
      "Fold 5 - New train size: 10218\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 10218 samples...\n",
      "Epoch 1/10, Train Loss: 0.3754, Accuracy: 0.8795, F1 Micro: 0.6328, F1 Macro: 0.3052\n",
      "Epoch 2/10, Train Loss: 0.2454, Accuracy: 0.9031, F1 Micro: 0.7246, F1 Macro: 0.533\n",
      "Epoch 3/10, Train Loss: 0.2029, Accuracy: 0.9088, F1 Micro: 0.7528, F1 Macro: 0.5903\n",
      "Epoch 4/10, Train Loss: 0.1653, Accuracy: 0.9184, F1 Micro: 0.7715, F1 Macro: 0.6112\n",
      "Epoch 5/10, Train Loss: 0.1438, Accuracy: 0.9226, F1 Micro: 0.7822, F1 Macro: 0.6435\n",
      "Epoch 6/10, Train Loss: 0.1201, Accuracy: 0.9209, F1 Micro: 0.7746, F1 Macro: 0.6318\n",
      "Epoch 7/10, Train Loss: 0.0969, Accuracy: 0.9204, F1 Micro: 0.7827, F1 Macro: 0.6498\n",
      "Epoch 8/10, Train Loss: 0.0823, Accuracy: 0.9213, F1 Micro: 0.7803, F1 Macro: 0.6779\n",
      "Epoch 9/10, Train Loss: 0.074, Accuracy: 0.9227, F1 Micro: 0.7829, F1 Macro: 0.6923\n",
      "Epoch 10/10, Train Loss: 0.0606, Accuracy: 0.9219, F1 Micro: 0.7799, F1 Macro: 0.6961\n",
      "Best result for 10218 samples: F1 Micro: 0.7829\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.87      0.86      1190\n",
      "      Abusive       0.90      0.89      0.89      1018\n",
      "HS_Individual       0.73      0.78      0.75       768\n",
      "     HS_Group       0.76      0.63      0.69       422\n",
      "  HS_Religion       0.68      0.56      0.62       173\n",
      "      HS_Race       0.82      0.68      0.74       126\n",
      "  HS_Physical       0.69      0.37      0.48        60\n",
      "    HS_Gender       1.00      0.19      0.33        67\n",
      "     HS_Other       0.77      0.81      0.79       792\n",
      "      HS_Weak       0.70      0.76      0.73       725\n",
      "  HS_Moderate       0.68      0.55      0.61       352\n",
      "    HS_Strong       0.87      0.77      0.82       113\n",
      "\n",
      "    micro avg       0.79      0.77      0.78      5806\n",
      "    macro avg       0.79      0.65      0.69      5806\n",
      " weighted avg       0.79      0.77      0.78      5806\n",
      "  samples avg       0.45      0.45      0.44      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10536\n",
      "Threshold: 0.0029416918754577638\n",
      "Samples above threshold: 32\n",
      "Acquired samples: 200\n",
      "Sampling duration: 2.3070855140686035 seconds\n",
      "\n",
      "Fold 5 - New train size: 10418\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 10418 samples...\n",
      "Epoch 1/10, Train Loss: 0.3719, Accuracy: 0.8834, F1 Micro: 0.6162, F1 Macro: 0.2925\n",
      "Epoch 2/10, Train Loss: 0.2479, Accuracy: 0.9048, F1 Micro: 0.7132, F1 Macro: 0.5234\n",
      "Epoch 3/10, Train Loss: 0.197, Accuracy: 0.9152, F1 Micro: 0.7404, F1 Macro: 0.587\n",
      "Epoch 4/10, Train Loss: 0.1675, Accuracy: 0.9133, F1 Micro: 0.769, F1 Macro: 0.6258\n",
      "Epoch 5/10, Train Loss: 0.1402, Accuracy: 0.9213, F1 Micro: 0.7765, F1 Macro: 0.646\n",
      "Epoch 6/10, Train Loss: 0.1187, Accuracy: 0.9251, F1 Micro: 0.7775, F1 Macro: 0.6706\n",
      "Epoch 7/10, Train Loss: 0.0949, Accuracy: 0.9236, F1 Micro: 0.7844, F1 Macro: 0.6921\n",
      "Epoch 8/10, Train Loss: 0.0808, Accuracy: 0.9239, F1 Micro: 0.7867, F1 Macro: 0.7045\n",
      "Epoch 9/10, Train Loss: 0.0724, Accuracy: 0.9234, F1 Micro: 0.7852, F1 Macro: 0.7099\n",
      "Epoch 10/10, Train Loss: 0.0593, Accuracy: 0.9195, F1 Micro: 0.7814, F1 Macro: 0.7209\n",
      "Best result for 10418 samples: F1 Micro: 0.7867\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.86      0.88      0.87      1190\n",
      "      Abusive       0.90      0.89      0.89      1018\n",
      "HS_Individual       0.75      0.74      0.75       768\n",
      "     HS_Group       0.70      0.70      0.70       422\n",
      "  HS_Religion       0.65      0.71      0.68       173\n",
      "      HS_Race       0.78      0.75      0.77       126\n",
      "  HS_Physical       0.80      0.27      0.40        60\n",
      "    HS_Gender       0.90      0.28      0.43        67\n",
      "     HS_Other       0.80      0.80      0.80       792\n",
      "      HS_Weak       0.74      0.71      0.73       725\n",
      "  HS_Moderate       0.62      0.61      0.62       352\n",
      "    HS_Strong       0.86      0.80      0.83       113\n",
      "\n",
      "    micro avg       0.79      0.78      0.79      5806\n",
      "    macro avg       0.78      0.68      0.70      5806\n",
      " weighted avg       0.79      0.78      0.78      5806\n",
      "  samples avg       0.46      0.45      0.44      5806\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 10536\n",
      "Threshold: 0.002586477994918823\n",
      "Samples above threshold: 12\n",
      "Acquired samples: 118\n",
      "Sampling duration: 1.6632261276245117 seconds\n",
      "\n",
      "Fold 5 - New train size: 10536\n",
      "\n",
      "Launching training on 2 GPUs.\n",
      "Fold 5 - Training with 10536 samples...\n",
      "Epoch 1/10, Train Loss: 0.3732, Accuracy: 0.8835, F1 Micro: 0.6469, F1 Macro: 0.3438\n",
      "Epoch 2/10, Train Loss: 0.2506, Accuracy: 0.9059, F1 Micro: 0.7178, F1 Macro: 0.5172\n",
      "Epoch 3/10, Train Loss: 0.1995, Accuracy: 0.9148, F1 Micro: 0.7535, F1 Macro: 0.574\n",
      "Epoch 4/10, Train Loss: 0.1669, Accuracy: 0.9196, F1 Micro: 0.7585, F1 Macro: 0.605\n",
      "Epoch 5/10, Train Loss: 0.1401, Accuracy: 0.925, F1 Micro: 0.7817, F1 Macro: 0.6642\n",
      "Epoch 6/10, Train Loss: 0.1161, Accuracy: 0.9221, F1 Micro: 0.7788, F1 Macro: 0.6786\n",
      "Epoch 7/10, Train Loss: 0.0994, Accuracy: 0.9234, F1 Micro: 0.7825, F1 Macro: 0.7125\n",
      "Epoch 8/10, Train Loss: 0.0847, Accuracy: 0.924, F1 Micro: 0.7792, F1 Macro: 0.7141\n",
      "Epoch 9/10, Train Loss: 0.0688, Accuracy: 0.9253, F1 Micro: 0.784, F1 Macro: 0.7289\n",
      "Epoch 10/10, Train Loss: 0.0603, Accuracy: 0.9245, F1 Micro: 0.785, F1 Macro: 0.727\n",
      "Best result for 10536 samples: F1 Micro: 0.785\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           HS       0.87      0.86      0.87      1190\n",
      "      Abusive       0.89      0.90      0.89      1018\n",
      "HS_Individual       0.75      0.73      0.74       768\n",
      "     HS_Group       0.74      0.67      0.70       422\n",
      "  HS_Religion       0.68      0.60      0.63       173\n",
      "      HS_Race       0.82      0.72      0.77       126\n",
      "  HS_Physical       0.83      0.42      0.56        60\n",
      "    HS_Gender       0.71      0.55      0.62        67\n",
      "     HS_Other       0.82      0.76      0.79       792\n",
      "      HS_Weak       0.73      0.71      0.72       725\n",
      "  HS_Moderate       0.66      0.57      0.61       352\n",
      "    HS_Strong       0.85      0.79      0.82       113\n",
      "\n",
      "    micro avg       0.80      0.77      0.79      5806\n",
      "    macro avg       0.78      0.69      0.73      5806\n",
      " weighted avg       0.80      0.77      0.78      5806\n",
      "  samples avg       0.47      0.45      0.45      5806\n",
      "\n",
      "\n",
      "FOLD 5 COMPLETED in 6349.23 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "N_SPLITS = 5\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Prepare data for K-Fold\n",
    "label_columns = data.columns[1:]\n",
    "X = data['Tweet'].values\n",
    "y = data[label_columns].values\n",
    "kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_SEED)\n",
    "\n",
    "# Each element in these lists will be a list of metrics for one fold's learning curve\n",
    "all_fold_accuracies = []\n",
    "all_fold_f1_micros = []\n",
    "all_fold_f1_macros = []\n",
    "all_fold_data_used = []\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "    print(\"===============================================\")\n",
    "    print(f\"STARTING FOLD {fold + 1}/{N_SPLITS}\")\n",
    "    print(\"===============================================\")\n",
    "\n",
    "    X_train_fold, X_val_fold = X[train_index], X[val_index]\n",
    "    y_train_fold, y_val_fold = y[train_index], y[val_index]\n",
    "\n",
    "    # Shared resources for this fold's processes\n",
    "    accuracies = manager.list()\n",
    "    f1_micros = manager.list()\n",
    "    f1_macros = manager.list()\n",
    "    data_used = manager.list()\n",
    "    sampling_dur = manager.list()\n",
    "    \n",
    "    # Set seed for reproducibility within the fold\n",
    "    set_seed(RANDOM_SEED + fold)\n",
    "    \n",
    "    # Define the initial labeled pool from the current fold's training data\n",
    "    total_train_fold_size = len(X_train_fold) + len(X_val_fold)\n",
    "    initial_train_size = int(0.05 * total_train_fold_size)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train_fold)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train_fold))) - set(train_indices))\n",
    "    current_train_size = initial_train_size\n",
    "\n",
    "    # Adjust checkpoints based on the current fold's training size\n",
    "    checkpoints = [\n",
    "        # int(0.1 * total_train_fold_size)\n",
    "        int(0.5 * total_train_fold_size), \n",
    "        int(0.6 * total_train_fold_size),\n",
    "        int(0.7 * total_train_fold_size),\n",
    "        len(X_train_fold)\n",
    "    ]\n",
    "    \n",
    "    fold_start_time = time.time()\n",
    "    \n",
    "    while current_train_size < total_train_fold_size:\n",
    "        # 1. Train the model on the current labeled set\n",
    "        train_args = (\n",
    "            current_train_size, train_indices, (data_used, accuracies, f1_micros, f1_macros),\n",
    "            fold, RANDOM_SEED + fold, X_train_fold, y_train_fold, X_val_fold, y_val_fold, label_columns\n",
    "        )\n",
    "        notebook_launcher(train_model, train_args, num_processes=2)\n",
    "        \n",
    "        # Stop if we've reached the last checkpoint\n",
    "        if current_train_size >= checkpoints[-1]:\n",
    "            break\n",
    "\n",
    "        model = BertForSequenceClassification.from_pretrained(f'{filename}-fold-{fold + 1}-model')\n",
    "        \n",
    "        # 3. Perform query strategy to select new samples\n",
    "        new_samples_shared = manager.list()\n",
    "        X_pool = [X_train_fold[i] for i in remaining_indices]\n",
    "        sampling_args = (model, X_pool, train_indices, remaining_indices, sampling_dur, new_samples_shared, fold, X_train_fold, y_train_fold)\n",
    "        notebook_launcher(least_confidence_sampling, sampling_args, num_processes=2)\n",
    "        \n",
    "        # 4. Update the pools\n",
    "        newly_acquired_indices = list(new_samples_shared)\n",
    "        train_indices.extend(newly_acquired_indices)\n",
    "        remaining_indices = list(set(remaining_indices) - set(newly_acquired_indices))\n",
    "    \n",
    "        current_train_size = len(train_indices)\n",
    "        print(f\"\\nFold {fold + 1} - New train size: {current_train_size}\\n\")\n",
    "    \n",
    "    fold_end_time = time.time()\n",
    "    print(f\"\\nFOLD {fold + 1} COMPLETED in {fold_end_time - fold_start_time:.2f} seconds\")\n",
    "    \n",
    "    # Store the results for this fold\n",
    "    all_fold_data_used.append(list(data_used))\n",
    "    all_fold_accuracies.append(list(accuracies))\n",
    "    all_fold_f1_micros.append(list(f1_micros))\n",
    "    all_fold_f1_macros.append(list(f1_macros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bddf0a5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-29T11:03:47.874484Z",
     "iopub.status.busy": "2025-06-29T11:03:47.874016Z",
     "iopub.status.idle": "2025-06-29T11:03:48.684427Z",
     "shell.execute_reply": "2025-06-29T11:03:48.683748Z"
    },
    "papermill": {
     "duration": 1.103551,
     "end_time": "2025-06-29T11:03:48.686235",
     "exception": false,
     "start_time": "2025-06-29T11:03:47.582684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACCoAAAHqCAYAAADInz0eAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOzdd3yV5f3/8dfZ52QnJCHsLUuWAxwobgRHrVpX68DVVnF8bbWOVsWq1Noq1t0Wx6/iFrVqFbd11YULGbJ3EpKQdZKzr98fFzkQEiCBLML7+X3cj5Nzn/vc93WfxH4v7vt9Ph+HMcYgIiIiIiIiIiIiIiIiIiIi0gac7T0AERERERERERERERERERER2XMoqCAiIiIiIiIiIiIiIiIiIiJtRkEFERERERERERERERERERERaTMKKoiIiIiIiIiIiIiIiIiIiEibUVBBRERERERERERERERERERE2oyCCiIiIiIiIiIiIiIiIiIiItJmFFQQERERERERERERERERERGRNqOggoiIiIiIiIiIiIiIiIiIiLQZBRVERERERERERERERERERESkzSioICIi0gZWrFiBw+Hgscce2+G25513Hn379m31MYmIiIi0hebMg6Rj69u3L+edd94Ot3vsscdwOBysWLGi1cckIiIiIrIrmjN3bep8WESaRkEFkU7ogQcewOFwMG7cuPYeSocVj8fp3r07DoeD119/vb2Hs9saO3YsDoeDBx98sL2H0irqLqo3thxwwAHtPTwREZE9jua529a3b99tzltCoRAA1dXV3HTTTRx77LHk5OQ0Ozxw880343A4cDqdrF69usHrlZWVBAIBHA4HU6dObalTa1XXXHMNDoeD008/vb2H0mqa8rchIiIibUPz2W3TfLbllJeX4/f7cTgcLFiwoL2H0yrqwgWNLddee217D09Emsjd3gMQkZY3a9Ys+vbty+eff86SJUsYOHBgew+pw3n33XdZv349ffv2ZdasWUyaNKm9h7TbWbx4MV988UXyM/z1r3/d3kNqNWeeeSaTJ0+uty4vL6+dRiMiIrLn0jx3+0aPHs1vfvObBuu9Xi8AJSUl3HLLLfTu3ZtRo0bx/vvv79RxfD4fTz31FNdcc0299bNnz250+z59+lBbW4vH49mp47UWYwxPPfUUffv25ZVXXqGqqor09PT2Hlar2NHfhoiIiLQNzWe3r6POZ3c3zz33HA6Hg4KCAmbNmsWtt97a3kNqNbfccgv9+vWrt27vvfdup9GISHMpqCDSySxfvpxPPvmE2bNn88tf/pJZs2Zx0003tekYEokEkUgEv9/fpsdtjieeeIJ99tmHc889l+uvv55gMEhqamp7D6uBWCxGIpHokBcQn3jiCfLz8/nrX//KqaeeyooVK1qsXUFH+33ss88+/OIXv2jvYYiIiOzRNM/dsR49emx3ztKtWzfWr19PQUEBX375Jfvvv/9OHWfy5MmNXth98sknOe6443jhhRfqrXc4HC32mbXkPPH9999nzZo1vPvuu0ycOJHZs2dz7rnntsi+O9p8dkd/GyIiItL6NJ/dsY46n21tLf17eeKJJ5g8eTJ9+vThySefbLGggjGGUChEIBBokf21hEmTJrHffvu19zBEZCep9YNIJzNr1iyys7M57rjjOPXUU5k1a1bytWg0Sk5ODlOmTGnwvsrKSvx+P7/97W+T68LhMDfddBMDBw7E5/PRq1cvrrnmGsLhcL331pXCmjVrFsOHD8fn8/HGG28A8Je//IWDDjqILl26EAgE2HfffXn++ecbHL+2tpbLL7+c3Nxc0tPTOfHEE1m7di0Oh4Obb7653rZr167l/PPPp2vXrvh8PoYPH84jjzzS5M+otraWF198kTPOOIPTTjuN2tpaXn755Ua3ff3115kwYQLp6elkZGSw//778+STT9bb5rPPPmPy5MlkZ2eTmprKyJEjueeee5KvH3bYYRx22GEN9n3eeefVu7Ff12bgL3/5CzNmzGDAgAH4fD7mz59PJBLhxhtvZN999yUzM5PU1FQOOeQQ3nvvvQb7TSQS3HPPPYwYMQK/309eXh7HHnssX375JQATJkxg1KhRjZ7v4MGDmThx4o4+QsBO3E899VSOP/54MjMzG3wuTf18zjvvPNLS0li6dCmTJ08mPT2dn//854C9wPub3/yGXr164fP5GDx4MH/5y18wxtQ7xltvvcX48ePJysoiLS2NwYMHc/3119fb5t5772X48OGkpKSQnZ3Nfvvtt80xN9eyZcv42c9+Rk5ODikpKRxwwAG89tprTXrvSy+9xN57743f72fvvffmxRdfbHS7p59+mn333Tf5tzhixIh6n6OIiEhnp3nurvP5fBQUFOzyfs466yy++eYbFi5cmFxXWFjIu+++y1lnndVg+7p57tZleRcuXMhpp51GXl4egUCAwYMHc8MNNyRfryvNO3/+fM466yyys7MZP348YAO9f/zjH5Nz5r59+3L99dc3+B1uz6xZsxg2bBiHH344Rx11VL2/qS2tXbuWCy64gO7du+Pz+ejXrx+//vWviUQiwOaysx988AGXXHIJ+fn59OzZM/n+Bx54IPn30717dy699FLKy8vrHWPx4sWccsopFBQU4Pf76dmzJ2eccQYVFRXJbZoy591ZTZ13N+aHH37giCOOIBAI0LNnT2699VYSiUSD7b788ksmTpxIbm4ugUCAfv36cf7557fI+EVERHYHms/uuvaaz7bktVnY/u/l66+/ZtKkSWRkZJCWlsaRRx7J//73vyaf26pVq/jwww8544wzOOOMM5IBmcY88cQTjB07Nnm99NBDD+XNN99Mvt63b1+OP/545syZw3777UcgEODhhx8Gmn49dEfXZKuqqrjyyivp27cvPp+P/Px8jj76aObOndvkc96ed999l0MOOYTU1FSysrL4yU9+0qR2GMYYbr31Vnr27ElKSgqHH344P/zwQ4PtotEo06ZNY9CgQfj9frp06cL48eN56623WmT8Ip2dKiqIdDKzZs3i5JNPxuv1cuaZZ/Lggw/yxRdfsP/+++PxePjpT3/K7Nmzefjhh+t9S/+ll14iHA5zxhlnAHZCdeKJJ/LRRx9x8cUXM3ToUL7//nvuvvtufvzxR1566aV6x3333Xd59tlnmTp1Krm5uckb8Pfccw8nnngiP//5z4lEIjz99NP87Gc/49VXX+W4445Lvv+8887j2Wef5eyzz+aAAw7ggw8+qPd6naKiIg444IDkZC4vL4/XX3+dCy64gMrKSq688sodfkb//ve/qa6u5owzzqCgoIDDDjuMWbNmNZiEPvbYY5x//vkMHz6c6667jqysLL7++mveeOON5LZvvfUWxx9/PN26deOKK66goKCABQsW8Oqrr3LFFVc05VfWwKOPPkooFOLiiy/G5/ORk5NDZWUl//znPznzzDO56KKLqKqqYubMmUycOJHPP/+c0aNHJ99/wQUX8NhjjzFp0iQuvPBCYrEYH374If/73//Yb7/9OPvss7nooouYN29evTJYX3zxBT/++CO///3vdzjGzz77jCVLlvDoo4/i9Xo5+eSTmTVrVoMLpU39fGKxGBMnTmT8+PH85S9/ISUlBWMMJ554Iu+99x4XXHABo0ePZs6cOVx99dWsXbuWu+++G7AXRo8//nhGjhzJLbfcgs/nY8mSJXz88cfJ/f/jH//g8ssv59RTT+WKK64gFArx3Xff8dlnnzX6j4+t1dTUUFJSUm9dZmYmHo+HoqIiDjroIGpqarj88svp0qULjz/+OCeeeCLPP/88P/3pT7e53zfffJNTTjmFYcOGMX36dEpLS5kyZUq9C9t1n+OZZ57JkUceyR133AHAggUL+Pjjj3f670xERGR3o3nulTv8jKLRaIM5S0pKCikpKU38lJvm0EMPpWfPnjz55JPccsstADzzzDOkpaU1em6N+e677zjkkEPweDxcfPHF9O3bl6VLl/LKK69w22231dv2Zz/7GYMGDeL2229P3ji/8MILefzxxzn11FP5zW9+w2effcb06dNZsGDBNoOfWwqHw7zwwgvJ0sJnnnkmU6ZMobCwsN7F73Xr1jF27FjKy8u5+OKLGTJkCGvXruX555+npqam3t/aJZdcQl5eHjfeeCPBYBCwYYtp06Zx1FFH8etf/5pFixYl/3Y//vhjPB4PkUiEiRMnEg6HueyyyygoKGDt2rW8+uqrlJeXk5mZ2aQ57/Zs72+jqfPuxhQWFnL44YcTi8W49tprSU1N5e9//3uDb9kVFxdzzDHHkJeXx7XXXktWVhYrVqzoNOWVRUREmkLz2St3+Bl11PlsS16brdPY7+WHH37gkEMOISMjg2uuuQaPx8PDDz/MYYcdxgcffMC4ceN2eG5PPfUUqampHH/88QQCAQYMGMCsWbM46KCD6m03bdo0br75Zg466CBuueUWvF4vn332Ge+++y7HHHNMcrtFixZx5pln8stf/pKLLrqIwYMHN/l6aFOuyf7qV7/i+eefZ+rUqQwbNozS0lI++ugjFixYwD777LPD862oqGjwN5ObmwvA22+/zaRJk+jfvz8333wztbW13HvvvRx88MHMnTt3u9WBb7zxRm699VYmT57M5MmTmTt3Lsccc0wyrFzn5ptvZvr06Vx44YWMHTuWyspKvvzyS+bOncvRRx+9w/GL7PGMiHQaX375pQHMW2+9ZYwxJpFImJ49e5orrrgiuc2cOXMMYF555ZV67508ebLp379/8vm//vUv43Q6zYcfflhvu4ceesgA5uOPP06uA4zT6TQ//PBDgzHV1NTUex6JRMzee+9tjjjiiOS6r776ygDmyiuvrLfteeedZwBz0003JdddcMEFplu3bqakpKTetmeccYbJzMxscLzGHH/88ebggw9OPv/73/9u3G63KS4uTq4rLy836enpZty4caa2trbe+xOJhDHGmFgsZvr162f69OljNm7c2Og2xhgzYcIEM2HChAbjOPfcc02fPn2Sz5cvX24Ak5GRUW8sdccKh8P11m3cuNF07drVnH/++cl17777rgHM5Zdf3uB4dWMqLy83fr/f/O53v6v3+uWXX25SU1NNdXV1g/duberUqaZXr17Jfb755psGMF9//XW9MTfl8zn33HMNYK699tp627z00ksGMLfeemu99aeeeqpxOBxmyZIlxhhj7r77bgOYDRs2bHO8P/nJT8zw4cN3eF5bq/udNLa89957xhhjrrzySgPU+2+lqqrK9OvXz/Tt29fE4/F6+3r00UeT240ePdp069bNlJeXJ9fVfZZb/m1cccUVJiMjw8RisWafg4iISGegee6O57l9+vRpdM6y5TG29MUXXzSYm+zITTfdlJx3/fa3vzUDBw5Mvrb//vubKVOmGGPs53bppZcmX2tsHnTooYea9PR0s3LlynrH2HKeWHe8M888s94233zzjQHMhRdeWG/9b3/7WwOYd999d4fn8vzzzxvALF682BhjTGVlpfH7/ebuu++ut90555xjnE6n+eKLLxrso26sjz76qAHM+PHj683XiouLjdfrNcccc0xyTmiMMffdd58BzCOPPGKMMebrr782gHnuuee2Od6mzHm3ZUd/G02dd9ft69xzz00+r5sLf/bZZ/XOOzMz0wBm+fLlxhhjXnzxRQM0+jmKiIjsCTSf3b3nsy15bbZu/439Xk466STj9XrN0qVLk+vWrVtn0tPTzaGHHtqkcxwxYoT5+c9/nnx+/fXXm9zcXBONRpPrFi9ebJxOp/npT39ab5669TjrfidvvPFGvW2aej20KddkMzMz633WTVU3B29sqTN69GiTn59vSktLk+u+/fZb43Q6zTnnnNNgX3Vz17p5/HHHHVfv87j++usNUG8+PGrUKHPcccc1e/wiYqn1g0gnMmvWLLp27crhhx8O2BJSp59+Ok8//TTxeByAI444gtzcXJ555pnk+zZu3Mhbb73F6aefnlz33HPPMXToUIYMGUJJSUlyOeKIIwAalLWaMGECw4YNazCmLb9Js3HjRioqKjjkkEPqlW6qK2t1ySWX1HvvZZddVu+5MYYXXniBE044AWNMvXFNnDiRioqKHZaEKi0tZc6cOZx55pnJdaeccgoOh4Nnn302ue6tt96iqqqKa6+9tkFvMIfDAdgyXMuXL+fKK68kKyur0W12ximnnEJeXl69dS6XK5mkTiQSlJWVEYvF2G+//eqd8wsvvIDD4Wi0v13dmDIzM/nJT37CU089lfxGWjwe55lnnuGkk07aYS/dWCzGM888w+mnn57c5xFHHEF+fn69knXN/Xx+/etf13v+n//8B5fLxeWXX15v/W9+8xuMMbz++usAyX2//PLLjZaYrdtmzZo1fPHFF9s9t225+OKLeeutt+otde0z/vOf/zB27NhkGWKAtLQ0Lr74YlasWMH8+fMb3ef69ev55ptvOPfcc8nMzEyuP/rooxv8t5SVlUUwGFTJMBER2WNpnrvjeS7AuHHjGsxZzjnnnB2+b2ecddZZLFmyhC+++CL52JRKVQAbNmzgv//9L+effz69e/eu91pj88Rf/epX9Z7/5z//AeCqq66qt76uOkJTWnDNmjWL/fbbj4EDBwKQnp7OcccdV28+m0gkeOmllzjhhBMa7Xu79VgvuugiXC5X8vnbb79NJBLhyiuvxOl01tsuIyMjOc66ueCcOXOoqalpdLxNmfNuz/b+Npo6727Mf/7zHw444ADGjh2bXJeXl5ds5bb1+F999VWi0Wizxy8iIrK703x2957PtuS12Tpb/17i8ThvvvkmJ510Ev3790+u79atG2eddRYfffQRlZWV2z2n7777ju+//77ete8zzzyTkpIS5syZk1z30ksvkUgkuPHGG+vNUxsbZ79+/Rq0Cm7q9dCmXJPNysris88+Y926dds9t225//77G/zNwOZrr+eddx45OTnJ7UeOHMnRRx+d/DdFY+rm8Zdddlm9z6OxqiBZWVn88MMPLF68eKfGL7KnU1BBpJOIx+M8/fTTHH744SxfvpwlS5awZMkSxo0bR1FREe+88w4AbrebU045hZdffjnZs2z27NlEo9F6E97Fixfzww8/kJeXV2/Za6+9AFu6c0v9+vVrdFyvvvoqBxxwAH6/n5ycHPLy8njwwQfr9VpduXIlTqezwT7qLhrW2bBhA+Xl5fz9739vMK66/m1bj2trzzzzDNFolDFjxiQ/o7KyMsaNG1fvouTSpUsB6rVG2FpTttkZ2/osH3/8cUaOHJnsdZWXl8drr71W77NcunQp3bt3rzf5asw555yT7FcGdvJVVFTE2WefvcPxvfnmm2zYsIGxY8cmP8Ply5dz+OGH89RTTyUvnDbn83G73Q3aHaxcuZLu3buTnp5eb/3QoUOTrwOcfvrpHHzwwVx44YV07dqVM844g2effbbeBdzf/e53pKWlMXbsWAYNGsSll17a5DK5AIMGDeKoo46qt2RnZyfHMXjw4Abv2XqcW6tbP2jQoAavbb2/Sy65hL322otJkybRs2dPzj///OQ/FEVERDo7zXObNs8FW+J06znLlhc5W9KYMWMYMmQITz75JLNmzaKgoCB5cXxHli1bBjR9Hr3151f3uW79ORYUFJCVlbXN+Ved8vJy/vOf/zBhwoTk39OSJUs4+OCD+fLLL/nxxx8B+3uprKzcpXFCw7md1+ulf//+ydf79evHVVddxT//+U9yc3OZOHEi999/f72/pabMebdne38bTZ13N2blypVNms9OmDCBU045hWnTppGbm8tPfvITHn300QZ9tEVERDojzWc7x3y2Ja/NQsPfy4YNG6ipqdnmdcZEIsHq1au3u88nnniC1NRU+vfvn/w78/v99O3bt8G1b6fT2WiAZUfjhKZfD23KNdk///nPzJs3j169ejF27Fhuvvnm5L8XmmLs2LEN/ma2HMO2xllSUpJs19bY+UHD67Z5eXnJa8J1brnlFsrLy9lrr70YMWIEV199Nd99912Txy+yp3O39wBEpGW8++67rF+/nqeffpqnn366weuzZs1K9pY644wzePjhh3n99dc56aSTePbZZxkyZEjyG+Jgk6EjRozgrrvuavR4vXr1qvd86x6kAB9++CEnnngihx56KA888ADdunXD4/Hw6KOP8uSTTzb7HOsuwv3iF7/g3HPPbXSbkSNHbncfdROygw8+uNHXly1b1uKTX4fDkaxcsKW6tPTWGvssn3jiCc477zxOOukkrr76avLz83G5XEyfPj0ZCGiOiRMn0rVrV5544gkOPfRQnnjiCQoKCpITue2p+wxPO+20Rl//4IMPkunwpvL5fA3Su00VCAT473//y3vvvcdrr73GG2+8wTPPPMMRRxzBm2++icvlYujQoSxatIhXX32VN954gxdeeIEHHniAG2+8kWnTpu3UcdtSfn4+33zzDXPmzOH111/n9ddf59FHH+Wcc87h8ccfb+/hiYiItCrNc60dzXPbw1lnncWDDz5Ieno6p59++k7P53aksd8B7HwVs+eee45wOMxf//pX/vrXvzZ4fdasWTs1R9zWOJvir3/9K+eddx4vv/wyb775JpdffjnTp0/nf//7Hz179mzSnLcjczgcPP/88/zvf//jlVdeYc6cOZx//vn89a9/5X//+x9paWntPUQREZFWo/mstTvPZ1v62izs2tyxMcYYnnrqKYLBYKMBhOLiYqqrq5s979qVcTblmuxpp53GIYccwosvvsibb77JnXfeyR133MHs2bOZNGnSTh+7rRx66KEsXbo0OY//5z//yd13381DDz3EhRde2N7DE+nwFFQQ6SRmzZpFfn4+999/f4PXZs+ezYsvvshDDz1EIBDg0EMPpVu3bjzzzDOMHz+ed999lxtuuKHeewYMGMC3337LkUceudMXAF944QX8fj9z5szB5/Ml1z/66KP1tuvTpw+JRILly5fXSykuWbKk3nZ5eXmkp6cTj8ebdEN9a8uXL+eTTz5h6tSpTJgwod5riUSCs88+myeffJLf//73DBgwAIB58+Y1SAjX2XKb7Y0nOzu70RTojr7ptaXnn3+e/v37M3v27Hq/j63LiA0YMIA5c+ZQVla23eSuy+XirLPO4rHHHuOOO+7gpZdealCqtjHBYJCXX36Z008/nVNPPbXB65dffjmzZs3i8MMPb/Lnsy19+vTh7bffpqqqqt63uxYuXJh8vY7T6eTII4/kyCOP5K677uL222/nhhtu4L333kseOzU1ldNPP53TTz+dSCTCySefzG233cZ1113XoL1Hc8e5aNGiBusbG+fW7wMaLQvW2P68Xi8nnHACJ5xwAolEgksuuYSHH36YP/zhD9v8GxUREekMNM/tuM466yxuvPFG1q9fz7/+9a8mv68uGDxv3rydOm7d57p48eLkt7YAioqKKC8v3+b8q86sWbPYe++9Gy3J+/DDD/Pkk08ybdo08vLyyMjI2KVxgp3bbRmGjkQiLF++vMHvesSIEYwYMYLf//73fPLJJxx88ME89NBD3HrrrUDT5rw7O86mzrsbe29T57MABxxwAAcccAC33XYbTz75JD//+c95+umndRFXREQ6Nc1nO66mzmdb+tpsY/Ly8khJSdnmdUan09kghLKlDz74gDVr1nDLLbfUmyODbe1x8cUX89JLL/GLX/yCAQMGkEgkmD9/PqNHj27WOKF510Obck22W7duXHLJJVxyySUUFxezzz77cNttt+1SUGHLuXhj48zNzd1mC+Qtr9tuOY/fsGEDGzdubLB9Tk4OU6ZMYcqUKVRXV3PooYdy8803a44r0gRq/SDSCdTW1jJ79myOP/54Tj311AbL1KlTqaqq4t///jdgL3CdeuqpvPLKK/zrX/8iFovVKx8GNsm4du1a/vGPfzR6vG2VRdqSy+XC4XDUqxywYsUKXnrppXrb1fW4euCBB+qtv/feexvs75RTTuGFF15o9GLhhg0btjueukoA11xzTYPP6LTTTmPChAnJbY455hjS09OZPn06oVCo3n7qqiPss88+9OvXjxkzZlBeXt7oNmAnqAsXLqw3vm+//bZZrQfqAgRb7vezzz7j008/rbfdKaecgjGm0W+AbV3V4eyzz2bjxo388pe/pLq6ml/84hc7HMeLL75IMBjk0ksvbfRv7fjjj+eFF14gHA43+fPZlsmTJxOPx7nvvvvqrb/77rtxOBzJiWpZWVmD99ZNsOvK5JWWltZ73ev1MmzYMIwxu9wjd/LkyXz++ef1fhfBYJC///3v9O3bd5sl1Lp168bo0aN5/PHH65WIe+utt5J93OpsPX6n05lMoatcroiIdGaa51o7mue2lwEDBjBjxgymT5/O2LFjm/y+vLw8Dj30UB555BFWrVpV77WmzhMBZsyYUW993bcKjzvuuG2+d/Xq1fz3v//ltNNOa/RvasqUKSxZsoTPPvsMp9PJSSedxCuvvMKXX37ZYF87GutRRx2F1+vlb3/7W71tZ86cSUVFRXKclZWVxGKxeu8dMWIETqczOddrypx3ZzV13r2t9/7vf//j888/T67bsGFDvdLCYC+Ob/15tdT4RUREOjLNZ63dfT7bGtdmGzvGMcccw8svv8yKFSuS64uKinjyyScZP348GRkZ23x/XduHq6++usHf2UUXXcSgQYOSc7STTjoJp9PJLbfc0qCVWFPn4025Hrqja7LxeLzedVGwlWW7d+++y3PELa+9bnltet68ebz55pvJf1M05qijjsLj8XDvvffW+zy2/vcHNDzHtLQ0Bg4cqDmuSBOpooJIJ/Dvf/+bqqoqTjzxxEZfP+CAA8jLy2PWrFnJie3pp5/Ovffey0033cSIESMapCzPPvtsnn32WX71q1/x3nvvcfDBBxOPx1m4cCHPPvssc+bMYb/99tvuuI477jjuuusujj32WM466yyKi4u5//77GThwYL0+Tfvuuy+nnHIKM2bMoLS0lAMOOIAPPvgg2Rt2y5Tqn/70J9577z3GjRvHRRddxLBhwygrK2Pu3Lm8/fbbjV7AqzNr1ixGjx69zeTpiSeeyGWXXcbcuXPZZ599uPvuu7nwwgvZf//9Oeuss8jOzubbb7+lpqaGxx9/HKfTyYMPPsgJJ5zA6NGjmTJlCt26dWPhwoX88MMPzJkzB4Dzzz+fu+66i4kTJ3LBBRdQXFzMQw89xPDhw6msrNzuZ1jn+OOPZ/bs2fz0pz/luOOOY/ny5Tz00EMMGzaM6urq5HaHH344Z599Nn/7299YvHgxxx57LIlEgg8//JDDDz+cqVOnJrcdM2YMe++9N8899xxDhw5ln3322eE4Zs2aRZcuXTjooIO2+Rn+4x//4LXXXuPkk09u0uezLSeccAKHH344N9xwAytWrGDUqFG8+eabvPzyy1x55ZXJig233HIL//3vfznuuOPo06cPxcXFPPDAA/Ts2ZPx48cDNnhSUFDAwQcfTNeuXVmwYAH33Xcfxx13XINevM117bXX8tRTTzFp0iQuv/xycnJyePzxx1m+fDkvvPDCdksgT58+neOOO47x48dz/vnnU1ZWxr333svw4cPr/V4vvPBCysrKOOKII+jZsycrV67k3nvvZfTo0Q3+2xUREelMNM9t2jy3Oe677z7Ky8tZt24dAK+88gpr1qwB4LLLLiMzM7NZ+7viiit2ahx/+9vfGD9+PPvssw8XX3wx/fr1Y8WKFbz22mt88803233vqFGjOPfcc/n73/9OeXk5EyZM4PPPP+fxxx/npJNO2m4bsieffBJjzDb/piZPnozb7WbWrFmMGzeO22+/nTfffJMJEyZw8cUXM3ToUNavX89zzz3HRx99RFZW1jaPlZeXx3XXXce0adM49thjOfHEE1m0aBEPPPAA+++/fzIo/O677zJ16lR+9rOfsddeexGLxfjXv/6VvOAPTZvz7qymzrsbc8011/Cvf/2LY489liuuuILU1FT+/ve/06dPn3r/LTz++OM88MAD/PSnP2XAgAFUVVXxj3/8g4yMjO1eJBYREdndaT7bOeazrXFttjG33norb731FuPHj+eSSy7B7Xbz8MMPEw6H+fOf/7zN94XDYV544QWOPvrobVaOPfHEE7nnnnsoLi5m4MCB3HDDDfzxj3/kkEMO4eSTT8bn8/HFF1/QvXt3pk+fvt1xNvV66I6uyZaXl9OzZ09OPfVURo0aRVpaGm+//TZffPFFoy3amuvOO+9k0qRJHHjggVxwwQXU1tZy7733kpmZyc0337zN9+Xl5fHb3/6W6dOnc/zxxzN58mS+/vprXn/9dXJzc+ttO2zYMA477DD23XdfcnJy+PLLL3n++ed3+LsWkU2MiOz2TjjhBOP3+00wGNzmNuedd57xeDympKTEGGNMIpEwvXr1MoC59dZbG31PJBIxd9xxhxk+fLjx+XwmOzvb7LvvvmbatGmmoqIiuR1gLr300kb3MXPmTDNo0CDj8/nMkCFDzKOPPmpuuukms/X//ASDQXPppZeanJwck5aWZk466SSzaNEiA5g//elP9bYtKioyl156qenVq5fxeDymoKDAHHnkkebvf//7Ns//q6++MoD5wx/+sM1tVqxYYQDzf//3f8l1//73v81BBx1kAoGAycjIMGPHjjVPPfVUvfd99NFH5uijjzbp6ekmNTXVjBw50tx77731tnniiSdM//79jdfrNaNHjzZz5swx5557runTp09ym+XLlxvA3HnnnQ3GlkgkzO2332769OljfD6fGTNmjHn11Vcb7MMYY2KxmLnzzjvNkCFDjNfrNXl5eWbSpEnmq6++arDfP//5zwYwt99++zY/lzpFRUXG7Xabs88+e5vb1NTUmJSUFPPTn/60yZ/Pueeea1JTUxvdX1VVlfm///s/0717d+PxeMygQYPMnXfeaRKJRHKbd955x/zkJz8x3bt3N16v13Tv3t2ceeaZ5scff0xu8/DDD5tDDz3UdOnSxfh8PjNgwABz9dVX1/s7bsz2fidbWrp0qTn11FNNVlaW8fv9ZuzYsebVV19tdF+PPvpovfUvvPCCGTp0qPH5fGbYsGFm9uzZDX6vzz//vDnmmGNMfn6+8Xq9pnfv3uaXv/ylWb9+/XbHJSIisrvTPHfH89w6ffr0Mccdd1yTtgMaXZYvX77d99ad34YNG7a73daf27bmQfPmzTM//elPk3OowYMH15uvb+940WjUTJs2zfTr1894PB7Tq1cvc91115lQKLTdsY0YMcL07t17u9scdthhJj8/30SjUWOMMStXrjTnnHOOycvLMz6fz/Tv399ceumlJhwOG2OMefTRRw1gvvjii0b3d99995khQ4YYj8djunbtan7961+bjRs3Jl9ftmyZOf/8882AAQOM3+83OTk55vDDDzdvv/12cpumzHm3pSl/G02Zd9ft69xzz6237rvvvjMTJkwwfr/f9OjRw/zxj380M2fOrPc3NXfuXHPmmWea3r17G5/PZ/Lz883xxx9vvvzyyx2OX0REZHem+WznmM+29LXZ7f1e5s6dayZOnGjS0tJMSkqKOfzww80nn3yy3fG+8MILBjAzZ87c5jbvv/++Acw999yTXPfII4+YMWPGJP+GJkyYYN56663k69v7nTTleuiOrsmGw2Fz9dVXm1GjRiWvHY8aNco88MAD2z1fY3Y8B6/z9ttvm4MPPjh5ff+EE04w8+fPb3RfW/79xONxM23aNNOtWzcTCATMYYcdZubNm9dgPnzrrbeasWPHmqysLBMIBMyQIUPMbbfdZiKRyA7PQUSMcRjThDouIiLt4JtvvmHMmDE88cQT/PznP2/v4XRK99xzD//3f//HihUr6N27d3sPR0RERGSPoHmuiIiIiOzONJ8VEZGWsO161CIibai2trbBuhkzZuB0Ojn00EPbYUSdnzGGmTNnMmHCBIUURERERFqJ5rkiIiIisjvTfFZERFqLu70HICIC8Oc//5mvvvqKww8/HLfbzeuvv87rr7/OxRdfTK9evdp7eJ1KMBjk3//+N++99x7ff/89L7/8cnsPSURERKTT0jxXRERERHZnms+KiEhrUesHEekQ3nrrLaZNm8b8+fOprq6md+/enH322dxwww243cpUtaQVK1bQr18/srKyuOSSS7jtttvae0giIiIinZbmuSIiIiKyO9N8VkREWouCCiIiIiIiIiIiIiIiIiIiItJmnO09ABEREREREREREREREREREdlzKKggIiIiIiIiIiIiIiIiIiIibabTNBBKJBKsW7eO9PR0HA5Hew9HRERERFqRMYaqqiq6d++O09n5srea24qIiIjsOTS3FREREZHOojlz204TVFi3bh29evVq72GIiIiISBtavXo1PXv2bO9htDjNbUVERET2PJrbioiIiEhn0ZS5bacJKqSnpwP2pDMyMtp5NCIiIiLSmiorK+nVq1dyDtjZaG4rIiIisufQ3FZEREREOovmzG07TVChrmxYRkaGJrwiIiIie4iWKB17//33c+edd1JYWMioUaO49957GTt27Da3nzFjBg8++CCrVq0iNzeXU089lenTp+P3+3d6n1vT3FZERERkz9NZ2yJobisiIiKy52nK3LbzNT0TEREREWmiZ555hquuuoqbbrqJuXPnMmrUKCZOnEhxcXGj2z/55JNce+213HTTTSxYsICZM2fyzDPPcP311+/0PkVERERERERERET2NAoqiIiIiMge66677uKiiy5iypQpDBs2jIceeoiUlBQeeeSRRrf/5JNPOPjggznrrLPo27cvxxxzDGeeeSaff/75Tu9TREREREREREREZE+joIKIiIiI7JEikQhfffUVRx11VHKd0+nkqKOO4tNPP230PQcddBBfffVVMpiwbNky/vOf/zB58uSd3idAOBymsrKy3iIiIiIiIiIiIiLSWbnbewAiIiIiIu2hpKSEeDxO165d663v2rUrCxcubPQ9Z511FiUlJYwfPx5jDLFYjF/96lfJ1g87s0+A6dOnM23atF08IxEREREREREREZHdgyoqiIiIiIg00fvvv8/tt9/OAw88wNy5c5k9ezavvfYaf/zjH3dpv9dddx0VFRXJZfXq1S00YhEREREREREREZGORxUVRERERGSPlJubi8vloqioqN76oqIiCgoKGn3PH/7wB84++2wuvPBCAEaMGEEwGOTiiy/mhhtu2Kl9Avh8Pnw+3y6ekYiIiIiIiIiIiMjuQRUVRERERGSP5PV62XfffXnnnXeS6xKJBO+88w4HHnhgo++pqanB6aw/hXa5XAAYY3ZqnyIiIiIiIiIiIiJ7GlVUEBEREZE91lVXXcW5557Lfvvtx9ixY5kxYwbBYJApU6YAcM4559CjRw+mT58OwAknnMBdd93FmDFjGDduHEuWLOEPf/gDJ5xwQjKwsKN9ioiIiIiIiIiIiOzpdqqiwv3330/fvn3x+/2MGzeOzz//fJvbRqNRbrnlFgYMGIDf72fUqFG88cYb9bZ58MEHGTlyJBkZGWRkZHDggQfy+uuv78zQRERERESa7PTTT+cvf/kLN954I6NHj+abb77hjTfeoGvXrgCsWrWK9evXJ7f//e9/z29+8xt+//vfM2zYMC644AImTpzIww8/3OR9ioiIiIiIiIiIiOzpHMYY05w3PPPMM5xzzjk89NBDjBs3jhkzZvDcc8+xaNEi8vPzG2z/u9/9jieeeIJ//OMfDBkyhDlz5nDVVVfxySefMGbMGABeeeUVXC4XgwYNwhjD448/zp133snXX3/N8OHDmzSuyspKMjMzqaioICMjozmnJCIiIiK7mc4+9+vs5yciIiIim3X2uV9nPz8RERER2aw5c79mBxXGjRvH/vvvz3333QfYnru9evXisssu49prr22wfffu3bnhhhu49NJLk+tOOeUUAoEATzzxxDaPk5OTw5133skFF1zQpHFpwisiIiKy5+jsc7/Ofn4iIiIisllnn/t19vMTERERkc2aM/drVuuHSCTCV199xVFHHbV5B04nRx11FJ9++mmj7wmHw/j9/nrrAoEAH330UaPbx+Nxnn76aYLBIAceeOA2xxIOh6msrKy3iIiIiIiIiIiIiIiIiIiISMfWrKBCSUkJ8Xi8QX/drl27UlhY2Oh7Jk6cyF133cXixYtJJBK89dZbzJ49u16vX4Dvv/+etLQ0fD4fv/rVr3jxxRcZNmzYNscyffp0MjMzk0uvXr2acyoiIiIiIiIiIiIiIiIiIiLSDpoVVNgZ99xzD4MGDWLIkCF4vV6mTp3KlClTcDrrH3rw4MF88803fPbZZ/z617/m3HPPZf78+dvc73XXXUdFRUVyWb16dWufioiIiIiIiIiIiIiIiIiIiOyiZgUVcnNzcblcFBUV1VtfVFREQUFBo+/Jy8vjpZdeIhgMsnLlShYuXEhaWhr9+/evt53X62XgwIHsu+++TJ8+nVGjRnHPPfdscyw+n4+MjIx6i4iIiIiIiIiIiIiIiIiIiHRszQoqeL1e9t13X955553kukQiwTvvvMOBBx643ff6/X569OhBLBbjhRde4Cc/+cl2t08kEoTD4eYMT0RERETagTFQWmofRURERER2a4kohMvaexQiIiIiIrssYRIsLVva3sPYJndz33DVVVdx7rnnst9++zF27FhmzJhBMBhkypQpAJxzzjn06NGD6dOnA/DZZ5+xdu1aRo8ezdq1a7n55ptJJBJcc801yX1ed911TJo0id69e1NVVcWTTz7J+++/z5w5c1roNEVERESktRQWwsqVsPfekJbW3qMREREREdkJiTiECqF6iU3g5h4ALn97j0pEREREZKct37icDTUb6J7enYAn0N7DaaDZQYXTTz+dDRs2cOONN1JYWMjo0aN544036Nq1KwCrVq3C6dxcqCEUCvH73/+eZcuWkZaWxuTJk/nXv/5FVlZWcpvi4mLOOecc1q9fT2ZmJiNHjmTOnDkcffTRu36GIiIiItKqCguhogIcjvYeiYiIiIhIM5kEhIqhejmEioAEuFJVLkxEREREdmsJk6AoWEQwEsTldLX3cBrV7KACwNSpU5k6dWqjr73//vv1nk+YMIH58+dvd38zZ87cmWGIiIiISDsLhaCsTNdxRURERGQ3YwyESyC4AmrWgdMNgW629UMs2N6jExERERHZJSU1JZTUlBBwd7xKCnV2KqggIiIiIgJQUgIbN6rlg4iIiIjsBkwCYtUQrYTaIqhdZ9cH8sHptT8nou03PhERERGRFmCMYXXFamqjtQoqiIiIiEjnYwysWQNbdP0SEREREelY4iGIVEC0wrZ2iFVBPAwON/hywOVv7xGKiIiIiLSokpoS1lWto0ugC4aOWwpXl5VFREREZKeUl0NpKWRltfdIREREREQ2ScQgshGCK6H0Syj6L5R8ChULIF4LnkxI7Q0p3RuGFBIR+PFeWPlU+4y9jdx///307dsXv9/PuHHj+Pzzz7e57WGHHYbD4WiwHHfccW04YhERERFpKmMMqypWYTB4Xd72Hs52qaKCiIiIiOyU4mKIRm1QIRJp79GIiIiIyB7JJCAWhGgVRMogvME+T0TB5QN3KviywbGD72slIvDlZVD2lX2+732tP/Z28Mwzz3DVVVfx0EMPMW7cOGbMmMHEiRNZtGgR+fn5DbafPXs2kS0m+6WlpYwaNYqf/exnbTlsEREREWmistoy1letp0ugC/FEvL2Hs10KKoiIiIhIs4XDtu1Denp7j0REREREdhsmsePAwA73YSBeY4MJ0QoIFUOselM7Bwe408CXC05P0/eZiMI3124OKXQ/3u6rE7rrrru46KKLmDJlCgAPPfQQr732Go888gjXXnttg+1zcnLqPX/66adJSUlRUEFERESkA6qrphAnjt/tJxgJtveQtktBBREREZE9lDE7f/21pAQqK6FnT1VTEBEREZHtMAailRDaALVrbVDBnWYXlw+cvk2PXvuz09VwH7FaiFVBpBLCxTakEK8BnOAOgCcD/P6G72uKupBC8X/t8Uf9CTKH7nqgogOKRCJ89dVXXHfddcl1TqeTo446ik8//bRJ+5g5cyZnnHEGqamprTVMEREREdlJG0MbWVe1jtxAbnsPpUkUVBARERHZA8ViMG8euFwwcCAEAk1/rzGwdi14veDsfNdvRURERKQlxCMQLrHhhPAGW/HAnWZfi1ZCIgYY+9zpBofHVkFwp4ArBTybtg0V24BCvMY+dwU2tXPosutVDxIx+PZ6KP7ABiX2+StkjbKtIzqhkpIS4vE4Xbt2rbe+a9euLFy4cIfv//zzz5k3bx4zZ87c7nbhcJhwOJx8XllZuXMDFhEREZEmq6umEEvE8Lt3MsTbxhRUEBEREdnDGAOLF8Py5fbnsjIYOhQaaUnbqIoK2LABsrJadZgiIiIisrsxBqLlNlxQs8ZWPnB6wJu1/YoHiZitbJCI2HYO4ZJNQQZstQV3KviyW7bKQV1Ioeg9G1IY81fIPcBWb5BGzZw5kxEjRjB27Njtbjd9+nSmTZvWRqMSEREREYDyUDlrK9fSJdClvYfSZAoqiIiIiOxhli+HH3+E3Fx7vbi4GL74wlZW6N8fPDto51tUZNs97Gx1XRERERHpZOJhGy6oWbMpZBCx7RhSejQtXOB024VmlPnaFYkYfPd7KHrXVnIYcyfkHdg2x25Hubm5uFwuioqK6q0vKiqioKBgu+8NBoM8/fTT3HLLLTs8znXXXcdVV12VfF5ZWUmvXr12btAiIiIi0iSrK1cTS8QIeNpoTt0CFFQQERER2YOsXw8LFkB6OqSk2HUFBVBdDT/8ABs3wpAh266WEInAmjWQkdFmQxYRERGRnRUutW0WnF5w+sDl3fSzd9eqEyTiYGK2RUKoGGrW2uO4vLZ6gquDJVoTEQiuguplUL0cyr6Ajd/YkMI+d0LewVtsbNprlK3O6/Wy77778s4773DSSScBkEgkeOedd5g6dep23/vcc88RDof5xS9+scPj+Hw+fD5fSwxZRERERJqgrppCTiCnvYfSLAoqiIiIiOwhyspg3jxwuyEzs/5raWm2QkJhoW3tMHgw9OoFLlf97UpKoKoKevRou3GLiIiIyE4KbYDyb21IAWwbBocHXB5wBcCVAp60zeEFpwdMwlYcMHVLHGJhSGxa4qFN6xOb1sVs9YTUni3bmmFnxEMQXLkpkLAplFC9DGrX2vPYksMNY/4MeePrr4+Ugye9/c+llVx11VWce+657LfffowdO5YZM2YQDAaZMmUKAOeccw49evRg+vTp9d43c+ZMTjrpJLp02X1KCYuIiIjsKVZXrCYcC5Of2sTevh2EggoiIiIie4Dqavj+ewiFoHv3xrdxu6FnTygvh6+/ttUVBg2yIQawLYfXrrWtIZybrtvGYnD11RCPwyuvQGpqm5yOiIiIiDSVyw8pPe1kzsRsdYFEFCIVYEpsdQQSgAMcLvuz2aqqgMNpX3O4wemyPzs99oa+cwd9w+rEwxCrBm/2rocAErFNgYQlULXUPlYvs5UdtlURwZ0Gaf0hrR+k9oPcAyF9wFZjDNkARvogcHXOigCnn346GzZs4MYbb6SwsJDRo0fzxhtv0LVrVwBWrVqF01n/97No0SI++ugj3nzzzfYYsoiIiIhsx7qqdayqWLXbVVMABRVEREREOr1QyFZS2LjRBhF2JCvLtoVYscJWYRg6FLp1s5UWiovrt4X48kv49FMbcnBrZikiIiLScTkctprC9oIFidimQIKjZY5pjG2xsO5VWP82xIM27ODvWn8JFNR/7smwYzAJqC2sH0ioWgrBFTZ00RhP5haBhE2Paf3Bl7v98zLGtrFIGwCBbSR7O4mpU6dus9XD+++/32Dd4MGDMVuHV0RERESk3a2uWM33xd/jdrpJ9e5+3yDT5WQRERGRTiwWgwULYN06G1Jo6jVnr9e2figttWGEAQNsG4ho1LaIAEgk4L777M+TJ4Pa0IqIiIh0EPEIxGvARJv3PmcLXSqsWQNrX4N1/7FtF7ZkYnbd1uu35AqALw/CJfY8Gt0m1VZESBuw6XGgDSR4s3cuaBEute9NH9hyQQ0RERERkVZgjGFVxSq+L/oev9tPdiC7vYe0UxRUEBEREemkEgn48UdYvtxWRHC5mvd+hwNyc6G2FhYtskGE9PTNr7/5JixcaKsvnHlmy45dRERERJrAGNuuIF4DsRqIBSFSZn9OhGyLB0/6jvfTEmLVUPi2DShs/HrzelcKFBwJ3Y+D7FE2EBAqhFCRXWq3+DlUBJGNEK+FmlX2/Q73pqoIA2yIoO7RX9BygYJ4CBJhyBoB7pSW2aeIiIiISCswxrBs4zLmb5hPqieVTH9mew9ppymoICIiItJJrVgBixdDfr6tkLCzAgFbXaGqCjIy7LpwGO6/3/78i1/UbwchIiIiIi0sEd20hCEetjfWo5WbbuqHbCjBJMDhBKcfXH4bUGipCgnbYuJQ+gWsfRWK3rPjA8ABXfaHHsdD/uHgDmx+T6DALtsSD9kWDKFi8OVASu/WPQ9joLbIhh8C3VrvOCIiIiIiuyhhEiwuXczCkoVk+jJJ97VRKLmVKKggIiIi0gmtW2dbPmRk2KDBrnI6IXOLcO5zz8H69TYEcdpptiWEiIiIiDRTIg6JiG2HkIhsEUiI2KoCsVpbLSERs9uYmG3r4ACcHhtIcKeAKxsczSyftStq1sHq2ba1Q7h48/rUPtD9eOg+afthhO1x+SG1t13aQrgEfF3U8kFEREREOrR4Is6ikkX8WPYjOf4cUr2p293+neXv8Lu3f0fX1K6s+r9VbTTK5lFQQURERKSDikZh7VobEggEbIuFQMA+357SUpg3D9zuzRUQWlJFBcycaX/+1a/A71dQQURERKRZEjHb5qB6uW3XUBdCMGbzNg6XDSM43ZsWv22D4HC1zw11Y6DsC1j5DBR/CCTsek8GdJtoWztkDt+9bvbHN7XHyB6llg8iIiIi0mHFEjEWbFjAkrIl5KXkEfBs+5tpqypWcd8X9/Hu8ncB8Dg9bTXMZlNQQURERKQDqqmB+fNh1SobTHA4wOezoYDMTNtqYcvwgmfTfLOqyoYUIhHo1kqVax97zB5nwAA47jiFFERERESaLBG3FQiql9vWBi4fuNPB6doUQthBIrU9xGph3Wuw6lmoXrZ5fZex0OsUyD8EnLvQZ6y9JFs+DAL/TlZ/EBERERFpZZF4hPkb5rN843LyU/Pxu/2NblceKucfc//B8/OfJ27iOB1OJg+czC9G/qKNR9x0CiqIiIiIdDAbN9qwQUkJ9OhhKyMkEjZ8EArZtg4rV9ptPR4bXkhLg+xsW02hvNy+rzWsWwdPP21/vvxycLkUVBARERHZIZOwwYTgCntz3OWBQDdbKaGjqlkDq56DNf+GWJVd5wpAj+Oh92mQ1q99x7erwhvU8kFEREREOrRwLMy84nmsrFhJt7RueF0NA8KhWIin5z3No988SjAaBODgXgdz+djLKUgrIBwPt/Wwm6wD/2tIREREZM+zbh388IMNJPTsubnNg9NpAwn+rQKzkQiEwzbcUFhor7F269Z611offNAGE/bfHw46qHWOISIiItJhxGrBRMGVsnOhApOAcImtoFBbaPcRKGibgEJoA6yebY/lzQFv9uZHXza4UhtOGo2B0s9se4cNHwGbWlGk9LThhB4ngidt58YTD0Os2laNcLjt4tz0uLOT10Rdy4z4Fkti07LpZxJbtNRwbD4nlw8yBoN722VzRURERETaS220lnnF81hduZruad3xuBq2cNhYu5ELXrmAVRWrANiry15cOe5KxvYYC0AwEmzTMTeXggoiIiIiHUAiAcuXw4IFtkpC9+5Ne5/Xa5f09NYdH8DChfD66/bnK67QF89ERESkE4vVQs1aCC63N8KdPnCngTcL3Cm2skDd0tikyBgbUAiusAEFhwMCXaEt+8OufAqW/79tv+701g8veLOgYoE95zq5B0Lv0yHvoJ1rS5GIQrQCYjX2eJ4MwNj18bD9bBMxkuEBAIdriwCDc3MQIRHbFDxIbmhfd7qBuvd4bLUKh8d+1k63Pa7TDTjtvusWp8eet4iIiIhIBxOMBPmu+DsKqwrpkd4DdyNB51gixnXvXMeqilXkpuRy2djLmDRwEs6O2E5uGxRUEBEREdkF0ahtzbArN+0jEVi0CJYuhaystgkdNJcxcM899udJk2DIkPYdj4iIiEiriEegdh1UL7U32D2Z4M6wN9UjpVC73t4sdzrB6QeX395892ZuDi4kIhBcC7Vr7D79ufZm+c4KFcPGb6HsK9jw4aZ9mU1VAuoeN93AT/5sIFy6eR95h0CkDCLl9jFea8cZKrLLllwp0OME6P0zSOvb/PEmYhCthFjQBgK8WZA20LZZ8GTYcEEiZsMKJmof6xYTtSGRWA0kau1nXfe5On3g9m+qxODZxqOr+eMVEREREekgYokY66vWs7RsKeXhcnqk98C1jTnuvZ/fy5frvyTFk8IDkx+gf3b/Nh7trlNQQURERGQnrVtnAwapqbZNQ26urW7QHNXVttXD2rXQtWvD1g4dxaefwhdf2GoPv/51e49GREREpIUlYjaEUL3M3sj3pENK781pVNdWkzQTt6GGRNgGG2pW2ZBA3TedTMLemN/6fTti4lC1FMq/teGEjd9CaP2unduo6dDt6PrrYrUQ2QjRjRDeuCnEUGaDGd2OttUjmjvuaBVEq213BU8WZPbdFE7IbBggcG5q+8AO2i4YozJeIiIiItLpGWPYULOBpRuXUlRVRMAToEd6j21WR3hjyRvM+n4WADdNuGm3DCmAggoiIiIizRaP2zYNCxfaago1NTa0kJEBvXpBfr79eUfXVEtLYd482LgRevSw++poqqrgP/+B/7epavDppze9LYWIiIhIh5eI24oC1csgtAE8KZDSc8dtDhwucAdocKM9EQMSTaugYBK2vURo/eZQQsX3thJBPU7IGARZoyBrxKYqD6kkWx/ApkfHpnWOza+50yBQ0PDY7sCm8e/CxM4YiFXZ6gkGG+7IGAy+XFtFoZHytM2mkIKIiIiIdHIVoQqWly9ndcVqHDjolt6t0VYPdX4s/ZE//vePAEwZPYUj+x3ZVkNtcR3wcriIiIhIxxUO24DC8uWQnQ1pm75slkhAZaUNHvh8tjpCjx7QpYutQrAlY2wFhR9+sK0jevbsWNdgjYHvvoMXX4S33rLnDPacpkxp37GJiIiItAiTsMGE4HKoLQKXF1K67/rN9aa8P7IR1vwb1rwINWsavu5KsYGE7FGbwgl7bwomdCCJCNQWgjsd0gaALw98ObYFg4iIiIiI7FBttJaVFStZUb6CUDREXmoefvf2K7JVhCq4+q2rCcfDHNjzQH6176/aaLStQ0EFERERkSaqqrLhgnXroKDABhLqOJ2QlWWX2lq7zZo19nnPnrbKQnq6rcawbJkNO/j90K1bO51MIyorbfWE2bPtGOsMHAgnnwyTJtlzEBEREdltGQPhUgiuhNq1tjJCoKBlvv2/o+NunAurXoCi98BE7XqHB/x5NpiQNcqGE9IH2nF1VNFq+xmm9oPMweBOae8RiYiIiIi0KWMMRcEiXA4XAU8Av9u/3SoIW4rGo6yrWseSsiVUhCvoEuhCXkreDt8XT8S54d0bWFu1lh7pPbj18Ftxbd1ibTejoIKIiIhIE2zYYEMKFRU7btMQCNglHrfbf/stpKbaigRgqzHk5GyuxtCejLHje/FFePvtzdUTfD445hgbUNh7745V8UFERET2UPEwtsfAli0OaPx5Y5OXSDkEV9gqBiZhWxS4fA23a0mRClj3Kqx+0R67TuYw6HUKFByzqQXDbiK0AUzMBivS+sNufmFURERERGRnlNaW8vX6r4nEI3hdXrwuL6meVLICWaR4Ugi4bXgh4AkkAwwJk6A4WMyyjcsorC4k3ZtO74zeOJp44fXBLx/kf2v/h9/t5y9H/4VMf2ZrnmKbUFBBRERE9kiJBIRC9sZ8KGSXqipbVaBPH+jVy25nDKxaBfPn2/f06NH0m/Yulw0k5ORAMGj3Y4wNLPha+Zr49oRCsHIlfPUVvPRS/eoJgwZtrp7Q1CBFdbVtb+HSdWoRERFpaSYB4TJb/SBUbCdTsGlCVrfUPWwrvLBpiVVBPAL+XHBtv6Tqro3ZQPm3sHo2FL5t2ySAbenQ/VjodTJkDGm947eGRGxTq4c0W/Uh0IHKgomIiIiItCFjDCvLVxJNROmR3oNwPEwkHqEiXEFRsAhjDA6HA4/Lg8/lI9WTSoYvg9pYLWur1uJyuOiR3qPJFRgA3l72No99+xgAfzj0DwzqMqiVzq5tKaggIiIinVo8bsMH0ai9QV9ba59XV0MkYoMKiYTd1u22gYKCAvs8FoMff4TFi+1N+6ysnR9Haqpd2ooxUF5uqzesWFF/Wb9+8zV+sC0o6qonDB/evOoJdZ/t8OF2PyIiIiItIh6G8AYIrraPGPBkgcNpf2bTZMaw+bnZtNS9htn00qZ17jTwt0KbgkQMQoW2UsOGj6H0c6heuvn19L1s9YTux4K7DSeELSUegtoiSOluK0F4Mtp7RCIiIiIi7aakpoR1VevoEuiCw+HA7/bjd9e/MGqMIRKPEI6HkwEGp8NJbiAXn7t532BbWraUaR9MA+AXI37BxAETW+xc2puCCiIiItLpRCL2Jv3GjVBYaEMJ0ai9Ru10gtdrl9RUyM6uXwlgzRr7WFMDCxbYygP5+baVQ0e2ahV88okNVSxfbsddUbHt7TMyYMAAG1BoTvWELdXU2KDCiBHQs+fOj11EREQkKVppb4rXrLJtE9x+8OeD09O+44rV2KoONWsaLqFCMPH62zt90G2irZ6Q2cwk6LaYBESrIF5jK0I4fbZ1haMVy1pFyiFabcMWGXuBy9t6xxIRERER6eASJsHKipUADcIJW3I4HPjcvmaHErZWFa7it2/9ltpYLft335+pY6c2ul0sEWtWhYaOYvcbsYiIiEgjgkF7Y37DBigpseEEgJQUWwnB52v69eHaWpg71+6re3fb1qCjicXgm2/gww/tsmpVw20cDujWDfr2rb/062c/k125Xh4O28956FC7PxEREZGdlohDZFN7h9pCGwrwZkJqr00VFNpBtBKWPwEbv4HgSoiUbn97pxcCPSClp6060OcM8KTv+jiMgVgQohU2qOBJB28uJML2c4ps3BSScNjQQl14wdmMyW+jx01AqAgcHsgZDSnt+LsQEREREekg6qop5AZyW/1YCZPgD+/9gdWVqylIK+D2I25vNIxQHiqnPFROmjeN3JTWH1dLUlBBREREdkuJhP02f0UFFBXZ6gm1tbZiQnq6vUHv2skvlxUW2jYRPXva/XUU5eW2asKHH8Knn24OY4BtW7HPPjBq1OYwQu/erdOOIRazn1H//jBoUMt8QVBERET2QPEwhIqhZjWES+w6bxb489pvTJWLYNVzsO51GwbYkicDAj0hZVMgYcvFl9eyN/JjtTackIiAKxVSe4O/ALw5tqqBMbYlQ7zWLrEaW/0gVmVDFvEIYOyYvNngbkbLi0TEBkZ8uTZ04evScuclIiIiIrKbSpgEK8tX4sCxy5USmuIfc//BR6s/wuvycudRd5IdyG6wTSwRozJcyeAug1lbvZai6iK6pnVt9bG1FAUVREREZLdRU7O5WkJpqQ0qRCK2WkJ6OnTpsus3zTMyIB63lRTamzGwbNnmqgnff28DGnWys2H8eLuMG7dz7RuaK5GAtWuhVy8YNmznwyAiIiKyB4tU2HYJwTUQq7RtDNqzvUMiCoXvwKpnofy7zevTBkK3o6DLATYo4Mlo5XFE7GcTrwFXwH4mgW42nLB10MDhAHfALvX2Ed8cXojXQu16qFoCnrRNLSIc9tHh2Oq5E3CCiUJ4I6T2g8zBzQs4iIiIiIh0YhuCG1hfvZ68lNYPVr+/4n3+MfcfAFw//nqG5g1tdLviYDHd0rsxJG8I+Wn5fFf4HYXVhXRN7YpjN/h2mYIKIiIi0qHF41BWZr/Bv369DSm4XBAI2Bv1vhYOr2a08vXnpigrg9deg5dfhhUr6r+21142mHDIIW0fFDAG1q2Drl1h+HDwqkWxiIiINEe0CqqX2pvn8ZC98Z/Ss/1aCoSKYPVsWP2ibT0B9qZ91yOg92mQPbp1S0clYjaUEI/YUIHTY6sfZAyxVQzcac0/vtMFzjQbTAC7D1+uDWOYmH3c8mcSNtxA1LZ7AMgaAWn97b5ERERERISESbCifAVOnHhdrXtRdEX5Cm56/yYATht2GsfvdXyj21VHqnE5XQzKGYTb6SY/NZ8x3cbwbdG3rK9eT7e0bq06zpagoIKIiIh0SNXVsGEDrFlj2zoYA1lZkJPTOVsNxOPw2Wfw0kvwwQf2OdgwwP7722DC+PFQUNB+YywshMxMGDECUvTlOhEREWmqRAxq1kDVYogF7U14f377jMUYKPvSVk8o/i+YTZMuXx70Ohl6/hT8rdjXNR6CWLVt7eBw2CCBJx3SBoC/C3gyWza44cuxy7aYxKYlvimoYFRFQURERERkK8XB4mSlgta0tGwpl71xGcFokDEFY7jqwKsa3S5hEpTWljIsbxhdUja3auuS0oUxBWP4rug71latJcuf1arj3VUKKoiIiEiHEY3alg7r10NxMQSDkJpqv8Hv7oCzlrlzYdEiW+Vg8OCda72wfj38+992KSravH74cDjpJDj66LZp6bAj5eXg8diQQkeoOiEiIiK7iXCZDSjUrANvBqT2ap9xxKph7Wuw6nkILt+8Pnsf6HMa5B8GzlaYcJoExGrs8eMRcPvAnQGpA8CbBd7M9mt5ATYU4XCiS4QiIiIiIo2LJ+KsKF+B2+nG42q9ufv3Rd9zxZwrqAxX0i+rH3868k+4t/FvlA3BDeSl5NEvq1+D17ID2bayQuG3rKpYRX5qO4XEm0D/ChEREZF2ZQxUVm6unlBeDk6nrZ6Q24pfZttVL70Et98OicTmdb17w9ChdhkyxC6NhQyiUVs14eWX4X//s58B2ADA5Mnwk5/AoEFtchpNEovZ39GoUdCly463FxERESEehuAKqF5mWwykdG+ZIIAxEA/aNhLRKohWQmzLn6sbX1e7zlYzAHClQPfJ0PtUSB+462PaWiIC0WobUMCAOxX83cCfZ4MJ7vTOWSJMRERERKQTKg4WU1Rd1KrVFD5d/SlXv301oViIvfP3ZsbEGdushhCKhYiZGIO6DMLnbrwvcoYvgzHdxuDAQTgextRdgO5gFFQQERGRdlFbC2VlNpxQVmafp6dD9+7g6sDtcI2Bxx6D+++3z4cPt1UgCgth1Sq7zJmzefstwwv9+sEXX8Brr9l2FnX239+GEw4/HHyNzy3bVWEh9Oxpz0VERERku4yBUJGtohDasKnNw06WhzLG7qf4A9jwIdSsteEDEjt8a6NS+0Lvn0GP42zLhZYWq4ZQKbi8NoyQ0Qu82Tac4PK3/PFERERERKRVtUU1hTeXvsmN799ILBHjgB4H8Oej/0yKp/F2bMYYioPFDMgZsMPgRJo3jVEFo/ix9MdWrQSxKxRUEBERkTYTjdpQQnGxvfkdDNp2AhkZkN9xK1AlJRJw993w1FP2+ZQpcMkl9gtxGzfCwoUwf759XLBg2+EFsNUiTjjBBhR69mz7c2mq8nLw+22Fh47YfkNEREQ6kFgQqpbaSgpOt23z4HA2bx+JGGz8xoYTij+wlRAa4/SCJ90GAjwZNnjgyai/zpNm2yx40m1gIG1Ay1cyMAaiFRCpBHcKpA+CQAF4c8DZgdO3IiIiIiKyQ0XBIoqDxRSkFbTK/p+f/zx3fHwHBsPR/Y/mlsNu2W6ooKy2jAxfBgOyB+Bowr9t0n3p7Nt935YccovS5WYRERFpVfG4vdldUgJr10JVlb0+nJFhb9DvLlVvo1G4+ebNgYPf/AbOPHPz69nZcOCBdqlTF15YsMAuS5dC375w0klw0EEd/8b/li0fsrLaezQiIiLSYSXiNlBQ9aNtteDPb14FgVgQSj7dVDnhY7uPOk4f5I6D/AmQuTd4Mm0Aob0rFCRiECmHeI0NRWSNgEBXG4oQEREREZHdXiwRY0X5CjxOD+6WaGO3BWMMM7+eyUNfPQTAqUNP5eqDrsa1nbBzJB6hNlbLPt32IdWb2qLjaS8d/PK4iIiI7I6MsTe461o7lJfbwEJ6OnTr1rFbOzSmpgauuQb+9z879mnT4Nhjd/y+xsILuxO1fBAREZEdilRA1RKoWW0rCqT0aloSNVQCG/5rwwkln4OJbn7NkwX5h9hwQpdx4A602vCbLR6GyEYbVPDlQObQ5gczRERERESkwyuqttUUuqV1a9H9JkyCuz69i6d/eBqAi/a5iIv3uXiHFRKKg8X0zOhJj4weLTqe9qSggoiIiLQYY2D9etvqoKwMwmFISYG8PNviYXdUXg5XXAE//GBbIPz5z7YaQmenlg8iIiKyXYkoBFfZkEI8ZKsJOL3bf0+oCNb+x4YTKubVfy2lJ+QfZsMJ2SPB0cGSrbEaiJQBThtMSO0Nvjzb4kJERERERDqVWCLG8o3L8bl8LVpNIZaIMe2Daby+5HUAfnvgbzlj7zN2+L6KUAV+j5+BOQNxNre9Xgemf02JiIhIi4hGYckSWLwYnE5bTcDfwl8se+MNePppCIXA67X79/kaLnXr67ZxOGDwYOjSxS6pqU37ot/69TB1KqxcCZmZcM89sPfeLXtOLam62i55ebtWtUItH0RERGS7QhtsQCG03lY/8Oduf/tEFJY/AUv/CYnw5vWZw20wIX8CpPXveD3BTNy2oYhWgSsAqX0g0NNWUuhEFwdFRERERKS+wupCNtRsoHt69xbbZygW4ndv/46PV3+My+Hi5sNuZtLASTt8XywRozxczqiuo8j0Z7bYeDoCBRVERERkl1VWwoIFsHatvUmektKy+6+pgTvvhFdeaZn9+f2bQwtdukBu7uafu3WD/feHFSvgssuguBi6doX774e+fVvm+C3NGCgpse01MjNtu41u3WxQY2cUFkKPHmr5ICIiIluJ1UL1cgguBwwEeuy4okDp5zD/DgiutM+zRkL34yD/UPDntfqQmy0RhVg1RIP2uTsNMgbbig+ejPYdm4iIiIiItLpoPMryjcsJuAMtVk2hMlzJlXOu5Lui7/C5fNxx1B2M7z2+Se+taz/RO7PzXaxVUEFERER2mjGwbh0sXGi/yd+jR8u3CVi0CK6/3lY1cDjg5z+HAw6ASMS2lgiHbYWFup/r1tet++oryM+H0lK7BIP2tbVr7dKYo4+Gzz6zAYz+/eHee21YoSOKxWywIC0NRo+2FRAWLLBBi9zc5odG6lo+7LWXWj6IiIjIJiYBtYVQtRjCpbaCgjt1++8JFcPCu6HwLfvc2wWGXAHdJnW8ygnxEESrIV4DTg+40yFzCHizbcUI106mP0VEREREZLdTWF1ISU0JPdJ7bHObT1d/yidrPiFhEsQTceImTsIkks8TJlFv3eKyxaypXEO6N527J97N6ILRTRpLdaQap8PJoC6D8Lh2097K26HLzyIiIrJTIhHb6mHpUvvN/Z49W3b/xsCzz8KMGbatRF4e/PGPsN9+u7bf2trNoYXSUluJoO7nl16y27y16Xr6yJFw9922SkFHFApBURF07w7DhkHGpi/5jRgBgYANeUSjTR9/LAYVFZsDDyIiIrIHMwmIVkCkHGrX23YPLh+k9tp+24NEDFY+DUv+bm/844TeP4NBvwJPeluNfvuMgXhwUzghAm4/eDIhYy/76MkE5y700RIRERERkd1SNB5l2cZlpHhScG3j3wRzls7hhndvaPa+c1NyuW/SfQzMGdik7RMmQWltKcPyhpGbsoN2e7spBRVERESk2Soq7Lf2161rnVYP5eU2lPDBB/b5IYfATTe1zM3zQMCGKhoLVvj98PTT9ufx4+FPf7LrOqLyclvFYtAgGDy4fpsHt9uu8/th/nwbKslrQmXlwkL7uajlg4iIyB4qEbfhhHAZhNZDtHLTjfwUCOSDcweVBcq+sm0eqpfZ51kjYdjvbOuE9paIQSwIsSobVHClgL+rXbxZtsVDR6v0ICIiIiIibaqwupDS2lJ6pjf+rbzP137OTe/fBMBhfQ5jQM4AnA4nLocLp8Npf3a6GqzzuryM7z2enEBOk8dSUlNCl0AX+mb1bYlT65AUVBAREZEmq2v1sGCBbaHQGq0e5s6FP/zBVgrweOCKK+D009vmuvGQIfZx0iQbjOiIrQ+MsZ+Ny2UrH/TqBc5GvtTocEDfvjasMG+e/b0VFDS+Lajlg4iIyB4rEbNVEyIboXadDSeYOLgD4MvZcTgBIFwCi+6Bda/b554sGHwZ9Dhh+9UXWloiBonIpiUKibCdPAE43eAKQGp/27rCk2XPUUREREREOgVjDDXRGoLRIMFIkKpIFenedFK9qaR50wi4Azi2c5E5Eo+wbOMyUj2pjVZTWFS6iKvfuppYIsbR/Y/mtiNuw9lK/94JxUJEE1H26rIXfncH/SZdC9BlaBEREWmSulYPS5bYG9ot3eohHoeZM+Gf/4REwn6r//bbN4cH2sLxx9tKCh217UE0CuvXQ04ODB8OuU2o+FVQAD6fDSusWWPbRGwdRFDLBxERkT1MImrDCeFSCBVuCickwJ0K/jxwNrH3aSIGq56HJQ/aagU4oNfJMOgS8LZS76xEbHMIIRG1oQSTsK85XDZY4fKCNwc8GTaM4PTbthWuFPuaiIiIiIjs9sKxcDKUUBGuoLSmlNpYLaFoCAC30000EcXpcOJ3+0n1pJKbmkuGL4NUjw0vbBlIKKwupKy2jB7pPRoca23lWi5//XKC0SD7dtuXaYdNa7WQQsIkKA4W0z+7PwVpBa1yjI5CQQURERHZoS1bPeTn2/YJLamoyFZRmDvXPj/+eLjmmpZvKdEUHfVGfTAIJSXQpw8MHdq8zyY7G/bZx7aBWL0aunat39JCLR9ERET2APGIrZqQDCdU2fWeVNv+wNnMS0Qbv7VtHqp+tM8zhsHw30Hm8JYZrzE2jBAPQyJkxw9bhRGywZ1uz8Hps2GEulBCW1ZyEBERERGRVlcbrWVjaCPV4WrKasuoilRRG6slnojjcrgIeAKkedLIDeTWq5yQMAlCsRA10RoWlS4ikUjgdXkJeALkBHLI9mcT8ARYVtZ4NYWNtRu57PXLKK0tZVDOIP56zF/xtmIAuqi6iJxADoO6DNpuBYjOQEEFERER2SZjYO1aG1KoqWmdVg/vvGMrJ1RU2Jvv114Lkye37DFaUyJhlzp11YW39Qi2/cKWy46UlEA4bKsoDBiwc7+D1FQYNcpWV1i2zIYX0tLs566WDyIiIp1UPGQrJ4Q2QKgYYtV2vScNAgXNDyeADTss+husfWXTvjJg0KXQ6yQbItgZJmErI8RDdklEAQe4PDZ44OsKvmzbusHl3xRK8CuMICIiIiKyB1m+cTkLSxficrjwu/343X4yfBm4d/DvGqfDSYonhRTP5m9+ReIRaqI1rK1cy/KNy3E6ncQSMXpn1P8mV220livnXMmqylUUpBXwt2P/Rpo3rVXOD6A8VI7H5WF4/vB64+2sdDlaREREGojF7I3xFStg6dKWb/UQj8N//2vbPCxaZNcNHQq33bZ7fau/uhpKS8G7KUC7dcC17vmWj8bYYIMx9nMwZvP6Lbep+zkeh4wM2Hdf27ZhV0K0Xq8NOwQCsHAhhEK2UoNaPoiIiHQi8bCtmhDeYAMKsWp7Q9+dBinddiFMEIfVL8KP90NsUzWGHifC4MtsZYPm7Cce3hxKMHFsKGFT+CDQE7wZtk2DO8U+NtIfVkRERERE9iwJEnidXrqld9vlfXld3npVEeKJOAZTr51DLBHj2neu5YcNP5Dpy+S+SfeRl5q3y8fellAsRHWkmtEFo8lNaULP305AQQUREZE9iDE2hBCJQDRa/7G21lZNqKmx62IxexO7JVs9BIPw73/D00/bSg0ALheccAL87nfgaWI75I6guhrKy2Hvve1n1FgoobFHsEGFeLz+Y2M/1z0vKGi5IIHLBQMH2vDJ/Pm2SsbuFA4RERGRbYjVQu16CK6EaIUNJ3gyIKXHrlceqPgBfrgDKufb5+l7wbDfQfaopu/DJCBcBvGaTSGEAPgLtgolBFQlQURERERE2tzW7R6MMdz24W18vPpjfC4fd0+8m75ZfVvt+LFEjKJgEYO7DKZ35p5zsXanggr3338/d955J4WFhYwaNYp7772XsWPHNrptNBpl+vTpPP7446xdu5bBgwdzxx13cOyxxya3mT59OrNnz2bhwoUEAgEOOugg7rjjDgYPHrxzZyUiIiJEIrBhg62MsGUIIRazQYRo1N4Ir+N02qCA220f/X7IyWlaa4IdWbcOnnkGXnrJhhUAMjPh5JPhtNMgrxlB1HjcnpvP1zJj2xl1IYWhQ+1N//Yax85yOKBXL9v6wetVywcREZHdWiwINesguMoGFDzpux5OMHEonwcbPoINH0PVj3a9OxUG/Rp6ndq8thHRSghvBF8XyBoO3i6bWjd07n6rIiIiIiKye3rwywd55cdXcDqcTD9yOiO7jmy1YxljKKwupEd6DwZ1GYRjD/p3UrMvSz/zzDNcddVVPPTQQ4wbN44ZM2YwceJEFi1aRH5+foPtf//73/PEE0/wj3/8gyFDhjBnzhx++tOf8sknnzBmzBgAPvjgAy699FL2339/YrEY119/Pccccwzz588nNTV1189SRERkD2KMDSgsXmwfwX6Lvi6AUBdCcLtb9wa1MfDtt/DUU/Dee7YyAEDfvnDmmXDccXYczRGN2tBDaqo9N7fbVhpIacN2XXUhhSFDds+Qwpaym1GluTNrTgj3sMMO44MPPmiwfvLkybz22msAnHfeeTz++OP1Xp84cSJvvPFGyw9eRET2XNFKqFkLwdW2vYM3E1J77/zN/0g5lPzPhhNKPrWhhyQHdD8WBl8BvmaUII2HoLbYVkvIGgGpvWxAQUREREREpIN69odneeSbRwC4fvz1HNrn0FY93oaaDaT70hmWN6xeO4o9gcOYui7ITTNu3Dj2339/7rvvPgASiQS9evXisssu49prr22wfffu3bnhhhu49NJLk+tOOeUUAoEATzzxRKPH2LBhA/n5+XzwwQccemjTfvmVlZVkZmZSUVFBRkZGc05JRESk06ipgaVLYeVKe406L8+GFNpSLAZvvw1PPmlbC9QZNw7OOgsOPHDnbu7HYrZdRJ8+sNdeNjCwfj0UF9uKESkpkJFhKwS0lmAQNm60IYVBg3bvkMLurqXmfs888wznnHNOvRDuc889t80QbllZGZFIJPm8tLSUUaNG8c9//pPzzjsPsEGFoqIiHn300eR2Pp+P7GYkQzS3FRGRRhkD0XIIroHatRCvBW+2raKwM/uqWrypasJHtoICic2vu9Mh90DIHw+5B4E3q+n7TsQgvMEeI7UXpPW3bShEpFGdfe7X2c9PREREWl9NtIaHvnyIVeWrSPelE0vEiJs48UQ8+bj1uix/FqO7jmZo3lDcTawI9/ayt7nuneswGH6176+4cJ8LW/W8qsJVBKNB9u2+LwVpBa16rLbSnLlfs75HGYlE+Oqrr7juuuuS65xOJ0cddRSffvppo+8Jh8P4t/q6ZCAQ4KOPPtrmcSoqbGo/JyenOcMTERHZY8XjttLAjz9CRQXk50Mg0LZjKCyEf/8b/v73zeu8Xpg0yVZQGDhw5/ddd349e8Lee9u2D+np0K2bDSyUlsKaNfYxFrOvpae3bEhDIYXO6a677uKiiy5iypQpADz00EO89tprPPLII42GcLeenz799NOkpKTws5/9rN56n89HQUHn+MeFiIh0AMZAuNRWTwits0EAXzb4m9E/CyBWA6Wf23YOGz6GcHH919MGQt54G07I3Lt57R3qxhkpg2gQAgWQPgB8eWrxICIiIiIiu+SPH/yRP338p516r9/tZ2T+SEYXjGafbvuwd/7e+N0NK719tf4r/vDeHzAYTh5yMheMuWBXh71d4ViY8lA5I7qO6DQhheZq1r84S0pKiMfjdO3atd76rl27snDhwkbfM3HiRO666y4OPfRQBgwYwDvvvMPs2bOJb9kUewuJRIIrr7ySgw8+mL333nubYwmHw4TD4eTzysrK5pyKiIhIp1FebqsorF5tqwr03oWKv80VicAHH8DLL8Nnn9lr02DHcfbZcMopsKu5w0TCVlIoKIARI2xIYUtpaXbp1ct+Fhs22O3Xr7efQ1aWbRWxK4JBKCuDoUMVUuhMdiaEu7WZM2dyxhlnNGhX9v7775Ofn092djZHHHEEt956K126dGnR8YuIyB7AJCC0AWpWQW0hkABvF3A3I5EaXL2pasLHUPYVmOjm11x+yNnfhhPyDrbhgp0VrYZIKXiyoMu+EOje/KCDiIiIiIh0esYYIvEIwWiQeCKO2+nG7XTjcrqSPzsd9S/AFgYLAeiR3oMBOQNwOey2LocLl9OVfKxb53Q4WVe1jq8Lv6YiXMHn6z7n83WfA+B2uhmWO4wx3cYwpmAMowtGU1hdyG/e/A3RRJTD+hzG7w7+HY5WvMieMAkKg4X0z+5P36y+rXacjq7V/8V4zz33cNFFFzFkyBAcDgcDBgxgypQpPPLII41uf+mllzJv3rztVlwAmD59OtOmTWuNIYuIiOwWIhFYtcqGFEIheyPf42mbYy9ebMMJr79uKzjU2Wcfu5x/fsu0YDDGVlLIy7Mhhe1ViXA6bSgiJwf69bPBgsJCKCqy7SHS0mxriK2DDjuikELntTMh3C19/vnnzJs3j5kzZ9Zbf+yxx3LyySfTr18/li5dyvXXX8+kSZP49NNPcW2jzIdCuCIiUk8iBqHiTQGFInA4wdcFXE2YyCSiUDZ3U9WEj+w+thToYUMJeeMhZ9+m7XN74mEbpnD5IGMYpPZpXpBCREREREQ6JWMM4XiYUCxEbbSWUCxEVaSKilAFoViIcCxMzMRwOpwNggcepwev24vP7cPv8lMVrgLg6P5HM3Xs1CaPIWESLN+4nK8Lv04uxcFiviv+ju+Kv+Pxbx/HgQOf20coFmJU11HcesStuJyt2095ffV6uqZ2ZUjukFY/VkfWrKBCbm4uLpeLoqKieuuLioq2Wdo2Ly+Pl156iVAoRGlpKd27d+faa6+lf//+DbadOnUqr776Kv/973/p2bPndsdy3XXXcdVVVyWfV1ZW0qtXr+acjoiIyG7JGHvjfckSexM+Oxtyc1v/uNXV8MYbtr3D/Pmb1+fnwwkn2GUH/++72davtxURRo60QYOm8nptcKOgACorbUuI9ett64ZIxFZ8yMjYcZhCIQXZnpkzZzJixAjGjh1bb/0ZZ5yR/HnEiBGMHDmSAQMG8P7773PkkUc2ui+FcEVEBIB4BEJFEFxpWz043RDoCs4mpFFNAlY9D4sfhFjV5vUOF2SP2VQ1YbwNErTEN4MSMQiXgIlDSm9I7wferF3fr4iIiIiI7FaMMdREawhGg0TjUSLxCJXhSirCNpAQiUWIJqI4HA7cDjc+tw+vy0uGLwO30008ESdu4vUea2O1VEeqiZs4sUSMjbUbAfC4mvdNPafDyYCcAQzIGcCpw07FGJOstDB3/Vy+Lvya1ZWrCcVC9M/qz13H3NVoW4iWVFpTSsAdYFjesFY/VkfXrKCC1+tl33335Z133uGkk04CbKuGd955h6lTt59e8fv99OjRg2g0ygsvvMBpp52WfM0Yw2WXXcaLL77I+++/T79+/XY4Fp/Ph6+5X4kUERHZzdXU2AoKK1bYm+Y9e8I2vqDdIoyBuXNt9YR33oG6L3y73XDoofCTn8ABB7TOGAoLbaBg5EgbKthZGRl26dPHhhbKymyVhtJSiEZtW4iMjM3VKMrL7aPHo5BCZ7czIdw6wWCQp59+mltuuWWHx+nfvz+5ubksWbJkm0EFhXBFRPZw8ZANKFSvgHCZrUgQKGh664TqFTDvj1D+rX3u7QJ5B9lgQu44cDcj8bkjxkC0HKJV4MuH9AHg79p2vcdERERERKRdxRNxgtEg1ZFqKsOVlARLCEaDhGIhDLY3sMfpwevy4nf5yfRl4t7Ov21cThcuXLCda8ypXtt2dVdv7DscDnpk9KBHRg+O3+t4AEpqSlhYspCRXUeS4duFC9FNEIwECcfDjOk2huxAdqsea3fQ7NYPV111Feeeey777bcfY8eOZcaMGQSDQaZMmQLAOeecQ48ePZg+fToAn332GWvXrmX06NGsXbuWm2++mUQiwTXXXJPc56WXXsqTTz7Jyy+/THp6OoWFts9IZmYmge3VeBYREdlDxOP25vqPP9qb7Xl522+DsKuqquC552z1hDVrNq/v39+GEyZPtpUcWsuGDbbawahRLXccp9NWZ8jKgr59bcuK0lL7uW7YYD/j1FRbpQJsBQeFFDq3XQnhPvfcc4TDYX7xi1/s8Dhr1qyhtLSUbt26bXMbhXBFRPZQsRqoXQ/BFRCpAE8apPawVRCaIhGD5Y/BkplgouBKgb0uhd6nNn0fzRpvEEKl4MmAnH0g0L1p1R5ERERERGS3FY1HqY5UUx2pZmNoI6U1pdREa4jEIzidTgKuAKmeVLoEuuDYDQPMuSm5jO89vtWPE41HKaktYVjeMHqk92j14+0Omh1UOP3009mwYQM33ngjhYWFjB49mjfeeCPZ23fVqlU4t7iaHwqF+P3vf8+yZctIS0tj8uTJ/Otf/yIrKyu5zYMPPgjAYYcdVu9Yjz76KOedd17zz0pERKSTiEZtMGHZMli71lYY6NWr9b6wZoytnHDnnfYmPtib98ccYwMKw4e3/pfl6o47cmTrtbRwOm0AIjsb+vWrH1rIyIBYDIYMUUhhT9DcEG6dmTNnctJJJ9GlS5d666urq5k2bRqnnHIKBQUFLF26lGuuuYaBAwcyceLENjsvERHp4KLVULsWgqtsmwZPJqT2AkczJh4V820VharF9nnuQTD8eluJoSUZYys+REptKCFjMKT1BXdKyx5HRERERETanTEm2XahKlxFUbCI2mgtNdEaYokYbqebFE8K2f5sfO6W+9JNTbSGkpqSxpfaEhaVLGqxY7UHYwzrq9fTJ7MPA3MG7paBjtbQ7KACwNSpU7f5LbP333+/3vMJEyYwf8tG1o0wxuzMMERERDoVY2xrh+pqCAZt24GKCqittd/2LyjY3J6gNRQVwR13wH//a5/37g1TpsBRR7Vu9YYtlZfbcMbo0bApA9nqXC7IybFL//4wb579Xey1l0IKe4LmhnABFi1axEcffcSbb77ZYH8ul4vvvvuOxx9/nPLycrp3784xxxzDH//4R1VMEBERSMShdg1ULoZoJXizIKV385Kg8RAsfghWPAkkbMhh6G+g26SWS5TGQ7Z6QqwWMOAKQKAnpPUDX07LHENERERERNpdwiSoidbYNg6hSkpqS6iKVFEbqSVmYvhdflK9qeSn5m+3fUNjYokYG2s3UlpbSmltKWW1ZZTW2J8LqwuZVzyPgCdAaU0pwWiwSfvM8mdRHirH5/Lhc/twNifs3UaMMYTjYUKxEKFYiGgiCgZyAjkMyR3S7M+xM3OYTpISqKysJDMzk4qKCjJ2pZG1iIhIG4lEbCChutpWTSgpsaGEcNjeKPd6bUAgJQXcrTh3icfh+efhgQfseFwuOO88OP98aMv7qpWV9rMYNcqGJES2p7PP/Tr7+YmI7JEiG21AoXadbfHg3Yn+VqVfwLxbbTUGgG4TYehvd25fW0pEbBuKWDWYBLh84E4DX74NU3jSbVsJfetHpFV09rlfZz8/ERGR3Uk8EU+2cagIVVBSW0IwEiQcC4MDAu4AKZ4U/G7/dkMAsUSMdVXrWFWxijWVa1hVsYqiYBE10RobTKgppSJc0ayxBdwBclNy6y1dAl2SP7sdbkZ3G01trJZQLEQ4FsZgcODA7/bjd/vxuXx4XG3Xni6eiNuxbAomxBIxnA4nPrcPn8tHlj+LTH8mKZ4UMnwZpHg6f2W65sz9FNkQERFpA4nE5moJ1dW2zUBV1eZqCU6nDSWkp9t2B211DXjJErjtNvj+e/t85Ei4/noYOLBtjl+nLqwxYoRCCiIiItLJxCMQXAHVSyERhUA3aO43aKKVsOgeWPOyfe7vCsOug/yd7KOaiG2qmBC0P7u8NpiQNsCGHjwZ4E5tXisKERERERHpUBImkWzbEIwG2Vi7kfJQOTXRGiLxCE6HM3kD3Zfia9COIBqPsq5qHasrV9ulYnXy5/VV64mb+A7H4HK4yPJn0SWlC10CXcgJ5CQfcwI5pHpT6ZPZh7yUPFK9qdvd1+qK1RSkFdArsxe10VpqY7XURmupCldRHi6nJlJDVbiKmImBAa/LS4onhYAn0GJVDGKJmP08I0GiiSgupwuf20fAHaAgrSAZRqg7bkes+NCRKKggIiLSCmKxzRUCKipsG4eaGlstAWylgkAA8vNbt1rCtoTDMHMmPP64DUqkpsKll8Kpp7Z9u4PychvaGD4c+vVr22OLiIiItBpjIFQMVYvtoy8H/PnN30/hu7DgDgiX2ue9ToXBU22woMljiW+qmBC01RMcbhtESO0N3pxNwYQ0cLqaPz4RERERkT1UPBHH4XB0iJvRW4cSKkIVlIfKqY3VJisPGGPI8GWQ7c/G5/ZhjKG0tpQfS39kbdVa1lauZW3VWtZVrWNt1VoKqwu3e0y/20+vjF70zOhJ78zedEvrRqo3NRlG6BLoQqY/s8U/H6fDSao3tUGwIRKPUBOtSYYY6oIZRcEiEiaB1+kl1ZtKwB3A1cR/+9S1xghGgoTjYVxOF6meVHpm9qRLoEtyf363v0HQQ3ZMQQUREZEWFApBURGsWgUbN9pKCi6XDSVkZNiAQnvPV776ylZRWLXKPp8wAa65Brp2bdtxVFfbAEdKCgwbBgMGtP9nIyIiItIiYjVQtdRWUnA4IbUnOJoZAgiXwPw/Q9G79nlKb9j7D5AzZsfvNQmI19hxxEN2DK5U8HcDf5dNwYT05ld2EBERERERAIqDxSwsWYgxhuxANpm+zDb7Jn1TQgluhxu/20+6N53cQC4LSxbybdG3rKlckwwlrKteRygW2u6x6sIIvTJ72cdNP/fO6E1uSm6b3Jw3xhCKhXZYwcHr8uJ1ecnyZ9kV2Ta8UBWuoipSRUlNSTK8YIzB5/Ylf2d1v6+6YwWjQWqjtTgcDgKeALmpueSn5pPuTSfDl9Gm7SU6M/2LVEREpAVUVsL69bBmja2gkJpqb/y3R7WEbamshL/9DV56yT7v0sUGFI44om0DAjU1tvWFzwd77WVbPaSnt93xRURERFqNSUDtOqj8ESLltoKCO9DMfRhY+29YOANiVTbg0O8cGHAhuHw7fm+42LabcKWAtwv482wowZNhWzyIiIiIiMhOS5gEKzauYGGpDSn4XD5Wla8iZmI4cCTbAGT5s8j0bw4vbHkzfEei8SiReKTBEowGCUaChGIhwvFwvVBCwBNIhhLqwgPrqtbx8qKXmbN0DovLFjd6LAcOuqZ1pXt6d3qk97BLRo/k8y6BLu1SKSASjxCMBAnGgpiEIeAJ0D29O2neZlSWw4YXuqR0oUtKF/pm9SUcC1MVqaIqXEVxTXEy5GEwOBwOEokEAU+ADF8GA7IHkOHPIMOXgd/tb6Uz3bN1oNsnIiIiu5dEwlYEWLvWhhRqa23VhN69O1ZlAGPg7bfhL3+xAQGAk0+Gyy5r24BAKAQlJTa80b+//Zyystru+CIiIiKtKlIBVUugZg24/batQnMnhTVr4IfbofRz+zxjqK2ikLHXjt9r4lCz3gYSskbbVhMuXUwTEREREWkpoViIhSULWVG+gkxfJhm+jHqvG2MIx8OEYiHWVK5h+cblAPjcPvxuP1n+LLL8WaR4UvC7/UQTmwMJoVjI3piPBonGo0QTUaLxqK0iYMDhcOB2unE73XicngahhDpltWW8tewt5iydw3dF3yXXu51u+mf3Z2juUIbmDqVnRk96pPegIK2gQ1QHiCfiyQoRkXgEr8tLmjeNQemDyA5kk+HLIMWTssuhCZ/bh8/tIzcll37Z/QjFQlSFq6gMVxJNRJO/15Y4luyYggoiIiLNFI3Chg2wejUUF9vAQnY25OW198gaKiyEO+6ADz+0z/v2hRtugDFNqBjcUsJhG5BwOGw4oU8fyMlpu+OLiIiItKpEFIKrbEghHoJAPjibWbnAxGHFU7D4QUiEwemDQb+EPmc1rT1DPAy16yHQHbKG27CCiIiIiIi0mI21G1lQsoDC6kIKUgvwuRtWO3M4HPjd/nrfvt8yvLCuah0ry1eCAzxOD7FEDGNM8r0epwePy4PX5cXv9uNxenA5d9xCrjpSzfsr3ueNJW/wxbovki0SHDjYt9u+HDvwWA7veziZ/swW+jTqS5gECZMgnohjMBhj6j3WfQ5AvfXxRJxYIkY4HsbpdJLqTqV7ene6pHQhw5dBuje9See/K+p+X3mpHfDi/h5AQQUREZEmqq21wYQVK2DjRvB4bPsE3w4q8LY2Y6C62oYByso2L+vXwwsv2FYLbjdMmWIXbxtV/I1GbQWFRAK6d7chiS5dOla1CREREZFdEiqBqsUQWg+eLPDnNn8fVUtg3i1QMd8+z9kPht8Aqb2a9v5oNYTLIH2ArcCwo/YQIiIiIiLSZMYY1latZcGGBdTGaumZ3rNZN8+3FV6IJWK4ne6d/tZ+KBbi49Uf88aSN/h49cdE4pHka8PyhnHsgGM5uv/R9W7A11VvqBtDY6GCLR9jiRhggwh166gb7qYqDwaD0+HEiROn04nT4cThcODYtKGj7v82nafD4Ui+7nK7SHWmUpBWQKbfVjLwql3dHkVBBRERkR2oqLCVCVavhspKSE2Fbt3szf/WFonAN9/YEEJpqQ1IlJXV/7mszIYCtmXUKFtFoX//lhuXMY0viQTE4/ZzisehoAD69YPcXHA2rQWbiIiISMcXD0HVMgguB5OAQI+mVT7YUiICSx+BZY/aigruNBh8JfT8SdOTneESiEcga29I6w+t/G0jEREREZE9STQeZUnZEhaXLcbv8tMjvUeL7NfhcOxUu4WSmhLmrp/Lx6s/5v0V7xOMBpOv9cvqx8QBE5k4YCK9MuuHnsOxMKW1pRgMAXcgGRyoW5wOJw7so8vpSoYO6rZLcafgcXlwO92bt3E4cTlc9X6uey25/60egUbXyZ5LQQUREZFGJBI2ALBmja1MEApBZqZtXdBW86fycvjVr2DJkqZtn5pqWypsuYwcCZMm7VxIoKjIBiXqOBw2jFD38/aWrCwYMAC6dlVAQURERDoRY2yLharFECkFXy64U5u/n43fwrxbbdABIP8wGPY78Dex3KhJQG2hbRGRsw+ktMwFUxERERERsaoj1SzYsIDVlavJS8kjxZPS5mMorC7kq/Vf8fX6r5m7fi6rKlfVe70grSAZThiUM6jBjf+6gAJAt7Ru9M7qTaYvs17Vg7qfRdqDggoiIiJbiEZhwwZYtcq2eTDG3vDPz2/bcZSXwyWX2JBCRgYMHgzZ2bZ1Qna2HVPdz3WPfv8Od9tkJSW2RcTee9sWF3UBBKezfiChsefGQCAALn2hT0RERDoLk4BwKQRXQu1aGxBI6QWOZiYyE1FY/AAsfwIw4O0Cw66Grkc2PQ2biNkx+PIgczj4cpp9OiIiIiIism1F1UUs2LCAjaGN9Ejvgbu51dN2Ql2LiS2DCeuq19XbxoGDvbrsxT7d9uHIfkcysutInI38m2TLgEL39O70zuxNbkquAgnS4SioICIiAtTW2goCK1falgoeD+Tl2Zv1ba2yEi69FH780YYQHn4Y+vZtu+NXVEAsZltGFBS03XFFREREOpxEDMIbILgKQkWAw1ZRcO1EQrRmDXx7PVTMt897nGBbPXgzm76PWC2EiiG1D2QOBXfbf6tLRERERKSziifirChfwaLSRWCgV0avbd7crwhVsLx8OV6XF5/Lh8/tw+/2J597Xd7tBgOMMaysWLk5mFA4l+Jgcb1tXA4XQ3KHsE+3fdinYB9GF4wm3Ze+zX0qoCC7GwUVRERkj7dmDSxcaAMCaWnQvXv7VQOoqoKpU2HRIls14cEH2zakEAzaMYwerZCCiIiI7MHiEQgXQ/UKW0nB6bZtGZw7mWJd9wb8MB3iQfBkwN43QtfDmrePSDlEqyFjCGQMAmfze9qKiIiIiEjjQrEQC0sWsnzjcrL8WWT4MhrdrqSmhCe+e4LnFzxPKBba5v4cOPC6vPjdfnxuXzLM4HPZZWXFymSooI7b6WZ43vBkMGFk15Gkenfcai4UC1FaW4oDhwIKsltRUEFERPZoq1bB99/bCgq9eze94m5rqK6Gyy6D+fMhKwseeAD692+744fDtuXDsGH2sxARERHZ48RDUFtoWzyEy8AdgECBDSrsjFgtLPgzrH3FPs8eAyP/aPfZVMbY0AQOyBkNKe08aRURERER6WQ21m5k/ob5FAWLKEgtwOf2NdimOFjM//v2//HiwhcJx8MA5Kfm48BBOB4mHAsTjodJmAQABmPXx8MQbvy4XpeXEfkjksGEEV1H4Hc3vXrblgGFHuk96JPVhy6BLgooyG5DQQUREdkjGQMrVsC8eZCSYoMB7SkYhMsvt+PJzLQhhYED2+74sRgUFtpgxKBBuvYtIiIie5hYEGrW24BCtAI8aZDaAxy7UGar8kf49jq7T5ww4AK7NCf0YOJ2XJ4MyBoO/vydH4+IiIiIiNRjjGFN5RoWlCwgHAvTK6MXToez3jaF1YU89s1jvLzoZaKJKAAj8kdw4T4XclDPg+qFAowxxBIxwvEwoVgoGV6oewzFQsnneSl5DM8fjtfV/KptdQEFJ04FFGS3pqCCiIjscYyBZcvghx9sq4fMZrQFbg21tXDllfDdd5CeDvffD3vt1XbHTyRg3Tro0cNWU2ivthciIiIibS5SATXroGY1xKrBmwmpu1ixwBhY9SwsugcSEfDlw6g/Qs6+zdtPPGyrOwS62ZCCp/HSsyIiIiIi0nzReJTFpYtZsnEJAXeA7und672+tnItj337GK/8+AqxRAyAMQVjuHCfCxnbfWyjoQCHw4HH5cHj8pDmTWvR8cYSMSrDlVRHqvG6vAooSKegoIKIiOxRjIGlS21IITPTBgPaUyhkQwpff21DE/ffD0OGtO0Y1q+H3FzYe2/w7mTbZREREZHdhjEQ2Qg1a6B2HcRrwZsN/j67vu9IBcy7BYo/sM/zDoERN4E3q3n7iVbb1hPp/SFjKLgalp4VEREREZGdUxWuYmHJQlZXriYvJY8UT0rytVUVq3j0m0f5z+L/EDdxAPbvvj8X7nMh+3ZrZvh4FxljqI5UUxGuACDLn8WI/BHkpuaS6ctUQEF2ewoqiIjIHiORgCVLYMEC2+ohrWVDrc0WCsFVV8FXX0FqKtx3n61o0JaKi+2xR4ywjyIiIiKdlklAuBSCqyBUCIkY+LLBn9cy+y/7Gr77PYSKwOGBwVdAn9ObX50hXGqrKWTtDWn9walyVyIiIiIiO8sYk2y7EIqFqI3WsqJ8BRWhCnqk98C9qTXb8o3LeeSbR5izdA4JkwDgwJ4HcsGYCxhdMLpNx1wbraUiXEE0ESXNk8aAnAF0Te1KdiA7OV6RzkB/zSIiskdIJODHH2HhQsjObv+QQjgMV18Nn38OKSnwt7/ZigZtqbzcPu69tw1uiIiIiHRKiTiEizcFFIoAB/hywOVvmf2bOCydCUv+CSQgpTeMvh0ymlkmyyRsqwenD3L2gUD3XWtBISKyDffffz933nknhYWFjBo1invvvZexY8duc/vy8nJuuOEGZs+eTVlZGX369GHGjBlMnjy5DUctIiKyfbFELBlGqAsk1LVKCMfDRGKRZAuHgCdAz4yeOBwOlpQtYebXM3l72dsYDACH9D6EC8ZcwN75bXfBNpaIUR4qJxgNEnAHyE/Np3t6d7qkdMHvbqF/u4h0MAoqiIhIpxePw6JFdsnNtcGA9hSJwDXXwKefgt8P99wDo0a17RiqqyEYhNGjoWvXtj22iIiISJuIR2xAoXqFrVLgdNvqCc4W7HUVKoJv/wAb59rnPU6AoVeDu5kTzkTMtqHw5ULmcBukEBFpBc888wxXXXUVDz30EOPGjWPGjBlMnDiRRYsWkZ+f32D7SCTC0UcfTX5+Ps8//zw9evRg5cqVZCntLiIi7WDL6gjhmH0MRoJUhisJRoNE4hEi8QjGGBwOBx6nB5/bh9/lJ9OXWa8awcKShcz8eibvrXgvue7wvodzwZgLGJLbNr15EyZBVbiKqkgVDoeDbH82g3IGkZuaS7o3Xa0dpNNTUEFERDq1eNxWUfjxR8jLg0CgfccTjcK118LHH4PPBzNmwJgx239PdTW43TbU0BJCISgrs20mevVqmX2KiIiIdBjxkK1MEFwJ4TJwByBQYIMKLan4A/j+FohWgCsFhl8H3Sc1fz+xWggVQ2ofyBza/JCDiEgz3HXXXVx00UVMmTIFgIceeojXXnuNRx55hGuvvbbB9o888ghlZWV88skneDweAPr27duWQxYRkT1YdaSailAFoViIynAlleHKZHWEaCKKw+HAiROf24fX5SXDl4HX5cXpcG5zn/OK5zHz65l8uOpDABw4OKr/UVww5gIG5gxstXNJmATReJRoIko0HiUUCxFLxEj3pTMoZxD5aflk+7NxqfWb7EEUVPj/7N15eFx13f//Z2Yyk8kkmex70n0vXWgrBQX11mpF5Rbu+/aLuIAVcWPTikIByyJQWSwFRKso+hNvb7ndcAelbnCDlLYgdE3SvWn2ZSYzyazn/P74tIVKl2Rmsr8e1zUXc07mfD6f6XXRnpzzOu+3iIiMWfE47NgBDQ1QVpa+G/2prOfGG+HvfzchhbVrYcmSUx8TDpsWDU6nCV0UFKTWtiIeh5YWmDbNvBTKFRERkTEjHoLeJhNQiPnBlQs51ZCR5gt9iQjsehAOPG62fbNhwV2Qk0QCNNoNsaBpE+GbDg5XWpcqIvJ60WiUzZs3s2rVqmP7HA4Hy5Yt4/nnnz/hMb/+9a8555xzuPLKK/nVr35FaWkpH/7wh7n++utxOk/892skEiESiRzbDgQC6f0iIiIyptm2TVe4i8ZAI4eDh+mN9uLIcJDpyCTLeeLqCKezr3sfT+95mj/t+RO7u3YD4MhwsHzqcj6x8BNMLpyclnXHrBjRhGkxEU1EiSViWLYFQIbDVHhwO9y4nC5KckooyymjOLuYrMyslOcXGY0UVBARkTEpFoNt22Dv3pETUrj5ZvjLX8Dlgvvug6VLT39ceztMmGBehw+bV2cn+HyQnz+woIFlmeNra2HWLBN+EBERERn1on7oPQy9ByEeBHc+5EwYnERmcB/880boqTPbkz4KM64ceMDAtk1bCjKgcIGppqAEqYgMsvb2dhKJBOX/0v+vvLycnTt3nvCYPXv28Oc//5mPfOQj/P73v6ehoYHPfe5zxGIxbrnllhMes2bNGm677ba0r19ERMa2hJWgvbedQ4FDNAebiVtxCjwFlOSXJDXe0XDC03ufpqGz4dj+TEcm75n6Hj5x5ieYkD9hwONatkUkHqEv3kc4HiZhJwBTmSHTkYnbeSSIkFVCjisHr9uL2+kmy2mqPmRlZuFyuNTWQQQFFUREZAyKRl8LKVRUmOoFwykeh9Wr4emnTQuHe++Fc845/XHBILjdMGkSFBZCcbF539wMBw7AwYPg9ZoqC5mn+Rfdtk1IobQU5s4144qIiIiMarYNwT3QUw+JPnAXgmfi4MzVUw8Nj5h2D3bCzDXvVih9y8DHshOm8oMrDwrOAM8be8KLiIwUlmVRVlbGd77zHZxOJ4sXL6axsZF77733pEGFVatWsXLlymPbgUCAWvUdFBGRk4gmorSGWjngP0BbqA1HhoOi7CI8mQN/8mx/937+tOdPbNi7gfrO+mP7nRlOltYs5V1T3sXbJr4NX5avX+PZtk0kEaEvZkIJcTtOBhl4Mj14Mj1U5FaQ68491nriaBjB7XQriCDSDwoqiIjImBKJmJDCvn1QWTn8N+QTCbjtNvjjH00Fg7vvhnPP7d+xnZ0wY4YJKRyVl2detbXQ2gr795vgQmam+dzJQhmtraZlxLx5JtwgIiIiMqpZCRMeCOw0N/w9pemfI9oNh5+Ew7+BwK7X9vvmwKK14EniyS4rakIK2ZVQMBdc/btAKiKSDiUlJTidTlpaWo7b39LSQkVFxQmPqaysxOVyHdfmYfbs2TQ3NxONRnGf4JfurKwssob7iQERERnxQtEQzcFmDvgP0B3uPnbjfyAtHcCEE57e+zRP73n6hOGEZZOX8baJbyPfk3/KcY6GEsLxMOF4mFgiBoDH5SE7M5vSnFIKPAV4XV5y3DlkZ2YrjCCSIgUVRERkzAiHTUhh/36oqjItFk7n8GG46SYTKKiqMuGGf33l5CS3HsuCO+6AP/zBhBTWrIG3va1/x3Z3m2DBxJM8FOjxmHYQVVXQ1maqK7S0mDkLC49fc1cXOBwmpJB/6vNxERERkZEvEYXAdgjuhawSyExjCtOKQ/tz0PgbaH0G7LjZn5EJZedB9QVQei5kOAY+djwEkQ7ImwK+WeAc5t5kIjLuuN1uFi9ezIYNG7jwwgsBUzFhw4YNXHXVVSc85i1veQs//vGPsSwLh8P83VdXV0dlZeUJQwoiIiKnYts2/oifw4HDHOo5RDAaxOf2UeOrwTGAc+wD/gOmrcOep6nrrDu235nhZGn1UpZNOX04IRI3oYS+eB8xy4QSspxZeDI9VPuqXwsluHLIdmUPaH0i0j8KKoiIyJgQDsOrr5ob9tXVp2+FAKYlw003meMAtm8/8ed8vhMHGI6+fL43thS2LLjrLvjNb0xI4c474R3v6N93sSzw+2H+fBNWOJXMTLOGigpTgeHQIWhqgo4OE0pwOKC3F848E8pUVVhERERGu3gvdG+FvkPgqQBnmp7Y7WmAxt/C4T9AtOO1/b5ZUP1+qHwPuAuSHz/aZdaePwdyp4HDefpjREQGwcqVK7nssstYsmQJZ511FuvWrSMUCrFixQoALr30Uqqrq1mzZg0An/3sZ/nGN77Btddey9VXX019fT133XUX11xzzXB+DRERGWUs26K9t53GQCNNwSaiiSgFWQVM8E3od1WCY+GEvU9T13F8OOGs6rNYNmUZb5/49lOGE6KJKO297SSsBO5MN55MD5W5lRRmFx5XKcGp83WRIaGggoiIjHq9vSZs0NjY/5ACwLe/bY7LzYUbbjA3+puajn8FAq+9du068The7xvDC7t3w+9+Z4ICt90Gy5b1//t0dkJRkWnv0F8ZGVBcbF6TJ5u1HzwIwSDMng01Nf0fS0RERGREivqh+1WItEF2NQywJOwJx2t6ylRPCOx4bb+7ECrPh5oLIG96anPYNoRbIMMJhWeCt+aNCVcRkSF08cUX09bWxurVq2lubmbhwoU8+eSTlJeXA3DgwIFjlRMAamtreeqpp/jCF77A/Pnzqa6u5tprr+X6668frq8gIiKjSCwRozXUygH/Adp62wAo8hSR7cru1/GHAof4054/8ac9fzphOOGdk9/J2ye9nQJPwWnX0d7bjo1NRW4FNb4act25eF1ehRJEhlGGbdv2cC8iHQKBAPn5+fj9fnw+9XgUERkvQiF45RVzY34gIYVNm+CznzXXjr/2tZMHCUKhN4YXjr6am03lgpPJyIBbb4X3va//3yceN2MvXjywoMKJ9PWZgEVpqQlMiIwlY/3cb6x/PxGRAQu3mZBCvAeyq5JrvQCmtUPHP+DQb6D172CbEq9kOKH0PFM9ofTc1EMQAHYCepvAnQ/5c8FTmvqYIjImjfVzv7H+/URE5I36Yn20hFrY372frr4u3E43RdlFuJz96NULBCIBHtr4EL/c+ctj+5wZTt5U9SZTOaEf4QSAuBWnvbeduBWnIreCyYWTKfGWqI2DyCAayLmfKiqIiMioFQyakEJrq6kY4Oxn+LW7G1avNiGFD3zg1NUOcnJg2jTzOpFw2AQWmpvh8OHjKzF84APwzncO7Du1t5sWDZWVAzvuRLKzzUtERERkVOttNO0e7LippJBMRYLgHlM54fDvIfK6pGnedKi+AKrON5UU0sWKmpBCdiUUnAGuvPSNLSIiIiIyQvnDfpqCTRz0H6Qn2kOuK5eqvKp+Vy2wbZundj/F2n+spbOvE4Czqs/i3VPe3e9wAhwfUCjPLWdSwSTKcsoUUBAZYRRUEBGRUamnB/75T3Njv7q6/xUDbBu++lUTbpg4Ea67LrV1eDwwaZJ5pSoahUQCpkzpf2UIERERkTHLtiG4FwLbwZEFnoqBHR8LQNMfTUDBv+21/a58E0yovgB8M9O7ZoB4CMLtkDcFfLPBmZX+OURERERERgjLtujs6+RQ4BBNPU30xfsoyCpggm8CGQMIGTcGGvna/32N5w89D8CkgknceO6NLKpc1O8x4laczr5OookoZTllxwIKau8gMjLpNoiIiIw6gYAJKXR2DiykAPDzn8Pf/gYuF9x558iqONDWZr5PWdlwr0RERERkmFlxCNRBTz24feDqZ6lwOwHtL5hwQuvfTGUDONLa4S0mnFB6Ljj6V3J2wKJdEO+FgrmQOw10QVRERERExjDLttjaupX93fuxsCjyFFGWM7CLm3Erzn+/+t98Z/N3iCQiuBwuLj/zci5dcClup7tfYySsBJ19nYTjYUq8JUwpmkJ5TrkCCiIjnIIKIiIyqnR3m5BCd7e5qT+Qyr8NDXD//eb9VVfBrFmDscLk9Paa1hWTJg0seCEiIiIy5iQiENhhqilklUCm9/THBPdB42/h8O8g0vba/typr7V2yCoetCVj2xBugYxMKDwTvDXJtagQERERERlFGgON7OncQ2lOKZ5Mz4CP39q6lTufuZP6znoAllQuYdW5q5hYMLFfxyesBF3hLnpjvZR4Szij/AwqcivIdOj2p8hooP9TRURk1OjqMiGFQGDgIYVwGG66CSIRePOb4ZJLBm+dyWhvh2nToHgQr5+LiIiIjHjxXuh+FfoaIbsSHKd4gsq2oPF3cOiX0P3Ka/td+VC5/Ehrh1mDHxiwE9B7GNwFkH8GeEoGdz4RERERkRHAH/azs30nOe6cAYcUgtEgD7/4MD/b/jNsbPKz8vnC2V/gfdPf1692EZZt0dXXRSgWoii7iDmlc6jIrcDlHKTKaSIyKBRUEBGREc+2TVuEV181lQeqqgZ+vfmBB2D3bhMEuOWWkVW1IBAArxcm9i8oLCIiIjI2Rf0mpBBpg+xqONVTULYN29aYkAIADih9M1S/H8reeuqAQzolIhBuhuwqyJ8LrryhmVdEREREZBjFrTg723fSG+ulxlfT7+Ns2+bP+/7Mfc/dR1uvqYT2/unv5/Nnf54CT0G/ju8Kd9ET7aHIU8TMkplU5lX2u0WEiIwsCiqIiMiIZdvQ2QkHDkBjowknVFYOPKTwt7/BT39q3t9668iqWmDbplLE3Lng62frZREREZExJ9xmqiLEg0faJpwiVWrbUPfQkZBCBtRcCNM+PfSVDOJBCHdC3hTwzQZn1tDOLyIiIiIyTPZ27aWxp5HqvOp+H9McbObu/7ubZw48A8AE3wRWnbuKN1W/6bTH2raNP+LHH/FT4ClgUeUiKnMrycrUObjIaKaggoiIjEhdXbB/vwkoxONQUgKegbc5o7UVbr/dvP/IR+Ccc9K7zlR1dUF+PkyYMNwrERERERkmvY3QvRXsuKmkcLpU6u7vwt4fmvdzV0Htfwz+Gv9VpBMSYSiYC7lTweEc+jWIiIiIiAyDtlAbdR11FGcXk3mqKmhHxK04j297nPWb1tMX7yPTkcnHF3ycFQtXnDZo8PqAQn5WPgvLF1LlqxpwqwkRGZkUVBARkRGlu9tUUDh0CGIxU/0gOzu5sRIJWL0a/H6YOROuvDKtS01ZIgHBICxalPx3FBERERm1bAuCeyGwAxxZ4Kk4/TF7H4OGb5v3s1YOfUjBtiHcAhmZUHRm/4IVIiIiIiJjRDgeZmf7TgBy3bmn/fyOth3c+eydx45ZWL6QG8+7kSmFU057bNyK0xRsIteVy/yy+VT7qsl26SKqyFiioIKIiIwIgYCpoHDoEEQiJqDg9aY25g9/CJs2mUoMd94J7hHWqqyjw1SKqKoa7pWIiIiIDDErDoE66KkHdz648k5/zIGfwq4HzPvpn4VJHx7cNR5lWxDvNa0eEn2QVQL5Zwx9qwkRERERkWFk2zb1HfW09bZR66s95WdD0RDrN6/n8W2PY9kWee48rll6DR+Y+QEcp2rzdkQ4HqYl1EKtr5bZpbP7FYoQkdFHQQURERlWPT1w8KCpohAOQ1ERlJWlPu7WrbB+vXn/pS/BpEmpj5lOsRhEozB1Krhcw70aERERkSGUiJgqCsE9kFUGmf14KurQb2D73eb9lBUw9fLBX2M8ZAIK2JCZA55KE07IKjbbIiIiIiLjSGNPI3u69lCeU37KsMHf9v+Ne/7vHlpCLQAsn7qclWevpNhb3K95/GE/PdEeZhbPZEbxDFxOXTwVGasUVBARkWERDJrqCfv3Q2+vCSiUlqZv7JtuMq0V3vUu+Pd/P/XnOzpMRYfiYvD50rOG02lrg4oKKC8fmvlERERERoR4CLq3Ql8jZFeCox8lr5r+CFu/at5PvASmfy7963p91QQrataVmQv5E8BVYKo+ONUHV0RERETGp55ID7vad5GdmY0n88Tnxa2hVu597l7+su8vAFTnVXP9W67nzbVv7tcctm3TGmolIyODBRULmJA/oV/VF0Rk9FJQQUREhlQo9FpAIRg0AYWSNFfNvftuaGyEykq48cZTtw2Ox01QYsYMOHzYvMrLwelM75peLxw2a5oyZXDnERERERlRot0mpBBpg+xqcPTjkkTr3+CVrwAW1FwEs1ae+uRuIE5YNaECPKXgOtKOQhdGRURERGSci1txdrbvpCfSQ23+G1s+JKwEP9vxM7754jcJxUI4M5x8dP5HuWLRFScNNZxojuZgM74sH3PL5lKWk4aSuyIy4imoICIiQ6Kvz4QH9u417R4KC2HixPTP87vfwR/+YAIAd9wBeadpd3y0ssHcuVBTA7t2mVYUJSWQO0itz9rbzXdPd0BDREREZMQKt0H3K6ZigbemfwGA9n/ASzeAnYCq82HuqtRCCqqaICIiIiIyYPu793MwcJCq3Ko3/OxQ4BA3/fkmtrVtA+CMsjO46dybmF48vd/jh+NhWkItVOVVMbd0LnlZp7mgKyJjhoIKIiIyqKJRqK+H5mbw+6GgACZMSN+DcK938KCppgBwxRWwYMGpPx8Og2W9VtmgqAgWLzYhit27TcWHsjJwpPFBumAQsrJg0qTB+TMQERERGXF6D0H3NrDjppJCf06COrfAli+CHYPyd8AZtyRX3UBVE0REREREktbR20FdRx2FnkJcTtdxP7Ntm9V/Xc22tm3kuHK46qyr+I9Z/4HT0f8SsoFIAH/Ez7SiacwqmYXb2Y/WcCIyZiioICIigyYehy1bTJuHkpLBCygAxGJw002mjcOiRbBixemPaW83ayotfW2f2w2zZpnQwtHqCmVlkJ2d+hptGzo6zPgFBamPJyIiIjKi2RYE90JgBziyTECgP7q3wubPgxWB0rfAgjv71ybi6JyqmiAiIiIikrJIPMKOth0krAS+LN8bfv5C4wu80vIKWc4sfvwfP6baVz2g8dtCbSTsBPPK5jG5cDIOBYhFxh0FFUREZFBYlrnRf/iwaXPgcp3+mFSsXw/bt4PPB7ffbioknEowaEIJJ6tsUFZmxtq927zcbhO2SCVo4febMQej5YWIiIjIiGLFIVAHPfUmHODqZ/nWwC7YdDUkeqHoTbDwHnCc5kRSVRNERERERNLKtm0aOhto7W2l1ld7wp8/suURAP5j9n8MKKSQsBI0BZvIdeeysGwhFbn9DDSLyJijoIKIiKSdbcOePablQ3n54IcUNm6EH/7QvL/5Zqg4zbnt6ysbFBae/HMeD8yZ88bqCp4kHsKzLBNUWLAAcnIGfryIiIjIqJGImCoKwT2QVQaZ/SxNFdwDL14J8R4oWACLvg7OrFMfE24FOwGZeaqaICIiIiKSJk3BJnZ37abMW3bCSgcbD2/kny3/xO10c+n8S/s9biQeoTnUTGVuJXNK55DvyU/nskVklFFQQURE0u7QIdixw4QAkrmpPxBdXbB6tQkfXHQRvOMdpz/G74e8vP5VNsjIgMpKyM+HujrTxiI7G4qLB7bOzk5zTE3NwI4TERERGVXiIdO6oa8RsitN64X+CB2EFz8HsW7wzYHFD0Cm99THRLvNfwsXQnaVqiaIiIiIiKRBMBpkR9sOspxZZLveGDq2bZtHNh+ppjDrPyjNKX3DZ042bmdfJ1MKpzCrZBaeTIWLRcY7/RYvIiJp1doK27aZm/m5uYM7l23DbbdBeztMngxf/OLpjzla2WDKlIFVNvB6Yf58WLwYHA5TXSEW69+x8Tj09sLUqZB1mocCRUREREataDd0vgR9hyG7uv8hhb4mePGzEGmH3Kmw5EFwneZEMt4HsSDkzwFvjUIKIiIiIiJpkLAS7GrfRU+0h+LsEz+p9eLhF3m55WXcTjeXLbisX+O297bTE+lhXtk85pXNU0hBRABVVBARkTTq7oZXXzVhgFO1VEiXxx+HZ581rSXuvLN/1RtSqWzgcJjjjlZXOHjQVGYoKDj1ce3tph3F6VpSiIiIiIxK8ZAJGfQ0mPcDCQ6E20xIIdwM3gnwpm+Cu+DUx1gxiLRB3kxzjIiIiIiIpMX+7v0c9B+kIreCjIyMN/zctm0e2WKqKVw066LTVlOwbIumYBPeTC/zquZRlVc1KOsWkdFJQQUREUmLUMiEFEIhqK4e/Pnq6+HBB837a6+FGTNOf8zRygZz56ZW2SAvDxYuNIGHXbtMq4uKCsg8wb+qkQgkEqaCw4l+LiIiIjKqhdvAvx0iHaZVg3cAJ4LRLtPuofeQqcBw1rcg6zT9tWzLVGDwTgDfDNOnS0REREREUtbZ10l9Zz2+LB8up+uEn9l0eBMvNb+Ey+E6bTWFaCJKU7CJ8pxy5pbNpcBTMAirFpHRTLdMREQkZZEIbN0KHR1DE1IIh+HGGyEahXPPhYsv7t9xbW0mUFBZmfoanE6YNMlUU9i1CxoboajIhBj+dc6aGijtX6s2ERERkdHBtiB0AAI7zPucCQMLDcQC8OKVENoLWWWmkoKn/PTH9TVBVqlp+eDQJQ0RERERkXSIJqLsat9FNBGlxFtyws/8azWFspyyk44Xiobo6OtgcsFkZpXMItuVPSjrFpHRTb/Vi4hISuJx2LHD3KivrjbtEQbb2rWwd6+paHDLLf27Jh4Om5YUU6eakEG6FBTA4sVmLfX10NMD5eVmjt5e05Zi8uSh+XMRERERGRKJKAR2QXAPuHJP36rhX8VDsOka6KkDd5EJKfSnEkO4HZxeKDgDMnWhU0REREQkHWzbpqGjgaZgEzV5J++Xu7lpM1uat5y2mkJnXyfheJg5pXOYVjQNpyONF2NFZExRUEFERJJm2+bm/N69pkrBULQ2+POf4Re/MOGE22+HwsL+HdfeDhMmDE5lg8xMmDbNrOVoK4iSElNhYto0U2lBREREZEyIBUyrh95GyK4Ap2dgxyfCsPkL4N8KrnwTUsid1L957TgUzh94MEJERERERE6qOdjM7q7dlHpLTxkq+M6W7wBw4awLKc99YzU0y7ZoCbXgdro5s/JMqvOqyVCrNhE5BQUVREQkaXv3Ql2duSnvdg/+fM3NcMcd5v3HPgZLl/bvuGDQrG/SpMFtY1xcDEuWwJ49sHs35OSYOUVERETGhL5m8G+DWBC8NQNvvWBFYct10LUFMnNgyUOQN+30xyXCEPVDwTzITkMPLxERERERAUyLhl3tu3A5XHhd3pN+btPhTWxpMtUUPr7g42/4eSwR43DwMKXeUuaWzaUoW09uicjpJVWI+uGHH2bSpEl4PB6WLl3Kxo0bT/rZWCzG7bffztSpU/F4PCxYsIAnn3zyuM/8/e9/54ILLqCqqoqMjAyeeOKJZJYlIiJDqLERtm8Hnw+8Jz+HTZtEAlavhkAA5syBz362f8fZtqlsMGFC/6svpMLthlmz4E1vgjPOgLy8wZ9TREREZFBZCejZDZ2bTdjAW51ESCEOL98AHf8wVRgWPwD5c/p3XF8L5E6F3MnJrV9ERERERN7Asi3qOuroCndR4i055Wcf2fIIcOJqCn2xPpqCTUzMn8jiqsUKKYhIvw04qPD444+zcuVKbrnlFrZs2cKCBQtYvnw5ra2tJ/z8zTffzLe//W0eeughtm/fzmc+8xkuuugiXnrppWOfCYVCLFiwgIcffjj5byIiIkOmvR22bjU35X2+oZnz+9+HLVtMKOLOO8Hl6t9xfr8JCwx1ZYOyMqiqGto5RURERNIuEQb/q9D9qqmC4CkbeIkqOwGvfAVa/w4ONyy6HwoX9uM4G/qaIKcWfDMhI6lnLURERERE5AQOBQ6x37+fityKU7Zo2Ny0mc1Nm8l0ZHLZgsuO+5lt27T2tjKrZBYLKhacsiqDiMi/GvBv+WvXruWKK65gxYoVzJkzh/Xr1+P1enn00UdP+PnHHnuMG2+8kfe+971MmTKFz372s7z3ve/l61//+rHPnH/++dxxxx1cdNFFyX8TEREZEoEAvPoqxOOm1cFQ2LQJHjGhXb78Zait7d9xlmWCClOmmDYMIiIiIjIA0W7o3AI9e0xAwZVEqSjbgq13QPOfICMTzrwHit/Uv2P7msBdaCovOIegz5iIiIiIyDgRioao76jHm+nFfZpz7Uc2H6mmMPNCKnIrjh8nFiLXncvEgolkDrTqmoiMewMKKkSjUTZv3syyZcteG8DhYNmyZTz//PMnPCYSieDxeI7bl52dzbPPPpvEckVEZDj19ZmQQiAA5eWn/3w6PP00XHONaf3wnvfA+97X/2M7O02YoqZm8NYnIiIiMubYNvQeho5NEGmDnBpwZiU3zo57ofE3kOGEBXdC6bn9OzbSAY4sKDjDVHIQEREREZG0sG2bhs4GApHAads0bGnawqamTWQ6Mvn4wo+/4ef+iJ/ynHJVUhCRpAwoqNDe3k4ikaD8X+5OlZeX09zcfMJjli9fztq1a6mvr8eyLP70pz/xi1/8gqampuRXjQlABAKB414iIjJ4olHT7qG11bQ0GGjF34GybfjRj2DVKjP3W98KN9/c/3njcejthalTISuJ6+oiIiIi45IVh5466NwMJMBbY0IGA2XbsOtBOPBTIAPm3QoV7+zfsbEgJCJQMBeyhqiEl4iIiIjIONEcbGa/fz9lOWWnbPkA8MgWU03hAzM/8IZqCnErjm3bVOZVDtpaRWRsG/QGjw888ADTp09n1qxZuN1urrrqKlasWIHDkdrUa9asIT8//9irtr91wEVEZMASCdi5Ew4eNCGFFP8K79d8990H69aZa9wf/CDcey/8S4GeU2pvh4oK8xIRERGRfoj3Qder4N8Obh9klSQ/VsN3YN9j5v3cG6Hq/P4dl4hApBN8syC7Kvn5RURERETkDcLxMHUddbgcLjyZp77Y+lLTS7x4+EUyHZmsWLjiDT/3h/0UeApOW5VBRORkBnSrqaSkBKfTSUtLy3H7W1paqDjJnaDS0lKeeOIJQqEQ+/fvZ+fOneTm5jJlypTkVw2sWrUKv99/7HXw4MGUxhMRkROzbWhogN27TbuHzEFuNRYOw/XXw+OPm+3Pfx6+/GVwDuBBvkjEhB2mTBn89YqIiIiMCZFO6NwEvfsguxIyc5Mfa+8PYbd58opZX4Tai/p3nBWHcDPkTYbcKYNfwktEREREZJzZ07mHjr4OSrynDyUfrabw7zP+/Q3VFABCsRA1vhoyHboAKyLJGVBQwe12s3jxYjZs2HBsn2VZbNiwgXPOOeeUx3o8Hqqrq4nH4/z85z/nAx/4QHIrPiIrKwufz3fcS0RE0u/AAVNNobh4YBUNktHVBZ/5DPz1r+BywZo18NGPDvwadVsb1NZCWdmgLFNERERk7LBtCB2Ejhch6jetHhyu5Mfb/7+m5QPA9Cth0iX9X0dfs6mi4JsNjiTaTYiIiIiIyEm1hdrY272XkuwSHBmnvj34cvPLbDy88aTVFPpifXgyPZTmlA7WckVkHBhwzGnlypVcdtllLFmyhLPOOot169YRCoVYscL8RXXppZdSXV3NmjVrAHjhhRdobGxk4cKFNDY2cuutt2JZFl/+8pePjRkMBmloaDi2vXfvXl5++WWKioqYMGFCqt9RRESS1NwM27ZBbi7k5AzuXPv3w7XXwqFD4PPB178OZ5458HFCIRNymDRJD+GJiIiInJIVg0A99NSDKwc8KbR6ADj0K9hxj3k/9XKY+sYLmicVbgF3PuTPBWdWausQEREREZHjxBIx6jvrsW2bHPfpL/R+Z8t3ALhgxgVU5lW+4ef+iJ+ynDLy3HlpX6uIjB8DDipcfPHFtLW1sXr1apqbm1m4cCFPPvkk5eXlABw4cADH65qXh8Nhbr75Zvbs2UNubi7vfe97eeyxxygoKDj2mU2bNvFv//Zvx7ZXrlwJwGWXXcYPfvCDJL+aiIikorMTXn3VtFx43V/Zg+Kf/4SVK8Hvh+pqeOABEzRIRkcHzJgBhYVpXaKIiIjI2BIPgX+7qabgKYVMb2rjHX4Stt5h3k/8MEz7TP+PjXZDhtOEFFy60CkiIiIikm77u/fTHGymJq/mtJ99ufllNjZuxJnh5BMLP/GGn1u2RSwRo9pXTYaeFBORFCTVOOaqq67iqquuOuHP/vrXvx63/ba3vY3t27efcry3v/3t2LadzFJERGQQ9PSYkEI4DFVVgzvXhg2wejVEIjBnDtx/v2kzkYzublP9IdmQg4iIiMi4EG4zIYVoF3irIZWesj31sPN+6Nhotmv/A2Z9of+lreIh8ypcaAITIiIiIiKSVt3hbhq6Gij0FOLsR4u1R7Y8AsC/z/z3E1ZT6In0kJeVR3F2khdxRUSOOHUTGhERGXfCYdi6Fbq6oPKN56Fp9eMfww03mJDCeefBt7+dfEjBskxFhilTBr9NhYiMLQ8//DCTJk3C4/GwdOlSNm7ceNLPvv3tbycjI+MNr/e9733HPmPbNqtXr6ayspLs7GyWLVtGfX39UHwVEZFTsy0I7oPOTRAPgrcmtZBC42/h+Y+/FlKoeh/MuaH/IQUrCpEOyJsB3trk1yEiIiIiIieUsBLUd9QTSUTwZflO+/l/tvyTFxpfwJnhZMXCE7dyC0QCVPuqycpUyzYRSY2CCiIickwsBtu3Q3OzqaQwWJW7Egn4+tdh7Vqwbfiv/4J774Xs7OTH7Ow0IYea01cvExE55vHHH2flypXccsstbNmyhQULFrB8+XJaW1tP+Plf/OIXNDU1HXtt3boVp9PJBz/4wWOfueeee3jwwQdZv349L7zwAjk5OSxfvpxwODxUX0tE5I0SUejeBl3/BIcbsiuSP9lLREybh1dvBSsCxUth6Xdh3q2Q0c/LDHYCepvAOwnypg3eiaeIiIiIyDh2KHCIxkAjFTkV/fr8I5tNNYULZlxAVd4bS+1GE1GcDielXlVDE5HUKaggIiKAqUhQVwf79plKCs7TVwFLSjhsqij8z/+Y7Wuugeuvh8wUHuaLx6G3F6ZOhSwFeUVkANauXcsVV1zBihUrmDNnDuvXr8fr9fLoo4+e8PNFRUVUVFQce/3pT3/C6/UeCyrYts26deu4+eab+cAHPsD8+fP54Q9/yOHDh3niiSeG8JuJiLxOLABdW0ybBk8JuAuSH6v3ELzwCTj0BJAB0z4NSx4yrRsGEjboazJhiYLZqVV1EBERERGRE+qJ9FDfUU+uO5fMfpxzv9LyCv9o/Mcpqyn4w36KvcUUZheme7kiMg4pqCAiItg27Nljggrl5eByDc48XV3w2c/CX/5i5rjzTrj00tQfoGtvh4oK8xIR6a9oNMrmzZtZtmzZsX0Oh4Nly5bx/PPP92uM733ve3zoQx8i50jPmb1799Lc3HzcmPn5+SxdurTfY4qIpFVfM3Rsgr4W8FaD05P8WK1/h+c+BoFd4Mo3AYVpV/S/isJR4VbIzIX8uamtR0RERERETsiyLRo6GwjGgv0OFTyyxVRTeP+M91Ptq37Dz23bpi/eR3VeNY6B/g4gInICemxBREQ4dAh27ICiIvAM0rXigwdN9YSDB8Hng/vug0WLUh83EjHVIKZMSa0qg4iMP+3t7SQSCcrLy4/bX15ezs6dO097/MaNG9m6dSvf+973ju1rbm4+Nsa/jnn0ZycSiUSIRCLHtgOBQL++g4jISVkJCO2DwE4TJPBWJ58OteJQvx72/sBs558BC79mKiIMVNQP2GYMd35y6xERERERkVNq6mnigP8AZd6yfn3+1ZZXef7Q86esphCKhfC6vZR4S9K5VBEZxxR5EhEZ51pbYds2yM6G3NzBmeOVV2DFChNSqKqC730vPSEFgLY2qKmBsv6dc4uIpM33vvc95s2bx1lnnZXyWGvWrCE/P//Yq7a2Ng0rFJFxKxEG/6vQ/Spk5oCnLPmQQqQDNl31WkhhwsWw9JHkQgrxPoj1QN5syC4//edFRERERGTA+mJ91HfU48n0kJXZvz65R6spvG/6+6jx1ZzwM/6In4qcCnLcOWlbq4iMbwoqiIiMY93d8OqrpvVD4SC1FfvLX0y7h+5umD0bHn0UJk9Oz9ihkGkhMWlS6u0jRGT8KSkpwel00tLSctz+lpYWKk7TSyYUCvGTn/yEyy+//Lj9R48b6JirVq3C7/cfex08eHAgX0VE5DXRbujcAj17TEDBlZf8WJ0vwXMfgc5N4MyGBXfCnC+BI4k+YVbctHzImwa5E5Nfk4iIiIiInJRt2+zu3E1XuIvi7OJ+HbO1dSvPHXoOZ4aTT5z5iRN+Jm7FsW2bilz13hWR9FFQQURknAqFTEghFBqcagSxGDzwAHzpS6Y9w3nnwbe/DSVprAzW0QETJw5eyEJExja3283ixYvZsGHDsX2WZbFhwwbOOeecUx7705/+lEgkwkc/+tHj9k+ePJmKiorjxgwEArzwwgunHDMrKwufz3fcS0RkQGwbeg9DxyaItEFODTj79/TUCcfa+yN48TMQaYecyXDOD6FyeZLjWdDXCDkTwTfDtKIQEREREZG0aw21srd7L6XeUjL6+WTXd7Z8B4D3Tn/vSaspBCIBCjwFFHv7F34QEekPdfMWERmHIhHYutXc6K+uTv/4DQ1wyy2wa5fZfu97YfVqyEzjvzrd3aZVxUQ9kCciKVi5ciWXXXYZS5Ys4ayzzmLdunWEQiFWrDD9GC+99FKqq6tZs2bNccd973vf48ILL6S4+Phf0DMyMvj85z/PHXfcwfTp05k8eTJf+cpXqKqq4sILLxyqryUi440Vh+BuCNSB0w3eE19c7JdYELbeBi1/MduV74G5N0KmN/kx+5ohqxTyZydXjUFERERERE4rEo9Q31GPI8NBtiu7X8dsbd3KcwdNNYXLz7z8pJ8LRoPMK5tHpkO3FUUkffQ3iojIOBOPw44dcOgQ1NSAI40PtCUS8KMfwfr1pqJCfj7ccAO8613pmwPAssDvhwULTFhBRCRZF198MW1tbaxevZrm5mYWLlzIk08+SXm56Z1+4MABHP/yF+WuXbt49tln+eMf/3jCMb/85S8TCoX41Kc+RXd3N+eeey5PPvkkHo9n0L+PiIxD8T7w74TefZBVBJkpnBwF6uDl66H3IGRkwuwvQu1/pdZjK9IOTg8UnJFa2EFERERERE5pX/c+Wntbqcnrf3D5kS2PAKeuphCOh8nKzKI0pzQt6xQROSrDtm17uBeRDoFAgPz8fPx+v0rlioicRCRiQgp790JFBbjd6Rv7wAG49VZ45RWzfd55cNNN6W31cFR7O3g8cPbZkJVkRWMRGd3G+rnfWP9+IpImkQ7wbzdhgOzK1KoVHPoNbP8aWBHwVMDCr5lwQSpiPRAPQuEi8FalNpaIyBg21s/9xvr3ExEZCTr7Onnh0At4XV5y3f0LL29t3crHf/VxnBlOfvbBn1GbX3vCzzUHmynNKeVNVW/qdzsJERm/BnLup4oKIiLjhN8P27fD4cNQWZm+kIJlwc9+Bg8+COEw5OTAF78IF1yQ2sN3JxOPQ18fzJmjkIKIiIiMU1YcQvuhpwGsqGn1kJFkmaxEBHbcC4eeMNslb4b5t4O7ILU1JsIQ7Yb8MxRSEBEREREZRHErTl1HHXEr3u+QAsB3t3wXgPOnnX/SkIJlW0QTUarzqhVSEJG0U1BBRGQcaGoyIYVgEGprwelMz7jNzXD77bBxo9l+05tg9WoThBgs7e1QXj64c4iIiIiMWNFuCOyCvsPgygdPCuWreg+ZVg+BXUAGTPs0TP1E8qGHo6w49LVA3jTIm5LaWCIiIiIickoHug/Q1NNEVV7/A8IvNr7IswefxZnh5PIzLz/p53oiPfiyfBR7i9OxVBGR4yioICIyhiUSps3Dzp3gckFN/9uTnZJtw29/C/fdB6GQqWxwzTXwwQ+CI8Xr2qcSiZjvNGUKZOpfMBERERlPrDiEDkBPPVhhyK4CRwonRK1/h1dugXgPuApgwR1Qcnbq67Rt6D0M3mrwzUo99CAiIiIiIiflD/tp6GrAl+Ujs5+/H2xp2sLKP64E4H3T33fSagoAPdEephdNx5PpSct6RUReT7d5RETGqHDYBBT27oWiIsjtf9WvU2pvh7vugr//3WzPmwe33goTJ6Zn/FNpa4MJE6CsbPDnEhERERkxon7oqYPQIXCnWEXBikP9etj7A7OdPw8WroHsirQslXAzZBVB/lxwpqnXmIiIiIiIvIFlWzR0NtAX66PG178n1H5T9xvufOZO4lacOaVzuPqsq0/62VgihiPDQXluebqWLCJyHAUVRETGoO5u2LYNWlqgosJUPEiHp5+GNWvA7zcVGj79afjYx9LXSuJUQiEz56RJoHZoIiIiMi5YiSNVFOogEQZvilUUIu3wz5ugc7PZnvghmHktOFzpWW+kEzJcJqTgSlNKVkRERERETqgx0MihwCHKck7/VJdlW3zzxW/yg3/+AIB3Tn4nt739tlNWSvBH/BR6CinMLkzXkkVEjqOggojIGGLbcPgwbN8OfX2m1UM6QgR+P9xzDzz1lNmeMQNuvx2mTUt97P5IJEwlh5kzoVDnxSIiIjIeHFdFwQeeFHt4db4E/1xlwgpOL5xxM1S+Oz1rteKmhUQiDEVnplbxQURERERETisUDVHXUUd2Zjbu01Qy64v1sfqvq/nLvr8AcPmZl/PpxZ/GcZo2baFYiFkls077ORGRZCmoICIyRsTjsHs31NWB2w3V1ekZ99ln4Y47TFDA6YSPfxw++UlT3WCoNDVBZSVMnTp0c4qIiIgMCysBfYfAvwsSfeCtTK3igW3Dvh9B3TfATkDuFFh4D+ROSs96470QbjMtKXyzIDtNJ6EiIiIiInJCtm2zu2s3gUiAWl/tKT/bFmpj5R9XsqN9By6Hi5vfejPvm/6+084RiobIceVQ7C1O17JFRN5AQQURkTGgrw927oR9+6CoCHLTUGk3FIL774cnnjDbkybBrbfCGWekPvZAtLWZ7zNnDnhOXolMREREZPSLBSBQD70HwZWXehWFWBC23gYt5skpKt8Dc2+ETG/qawVTnSERgfzZkDsVTvMkl4iIiIiIpK452My+7n2U5ZSRcYoeuTvbd7LyjytpDbVS4Cngvnfdx8KKhf2aozvczYSCCeS61dJNRAaPggoiIqNcZ6dp9dDaaqoOuNNwfXjTJtPa4fBhyMiASy6Bz31u6IMCgYBp+7BwIeTnD+3cIiIiIkPmaBWFQJ2pUJBdkVoVBTBjvXy9CT1kuGD2F6H2P83JXcrrjUNfM2TmQtE8yK5Mz7giIiIiInJK4XiYuo46XA4XnsyTX6z9676/cvNfbiYcDzO5YDL3L7+fGl//gtAJK4FlW1TmVqZr2SIiJ6SggojIKGXb0NhoQgqRCNTWgiPFdmHhMDz8MPzP/5jtqiq45RZYvDj19SazFr8f5s2Dioqhn19ERERkSMR6TKig94CpopCTYhUFgEO/ge1fAysCngo4827In5v6uADxEITbwVttKim4fOkZV0RERERETmtP5x46+jpO2vLBtm0ee+UxHtr4EDY2S6uX8rV3fo28rLx+zxGIBCjwFFCUXZSuZYuInJCCCiIio1A8Dg0NUFcH2dkmUJCqrVtNKGH/frN90UXw+c9DTk7qYw9UPA4tLTBtGkyePPTzi4iIiAw624Leo1UUgkeqKKRYGisRhh33waEnzHbJm2H+7eAuSHW1RrjdhB/y50De1NSrPoiIiIiISL+1hdrY272XkuwSHBlvfGItloix5tk1/Lru1wB8cM4H+eI5XyTTMbBbgT3RHuaVzcPl1Pm+iAwuBRVEREaZ3l7YscMECkpKUg8SxGLwyCPwgx+AZZkxv/IVeMtb0rLcAbNtaG424YtZs1KvEiEiIiIy4sR6INAAvfvBlQs5J34aakB6D5lWD4FdQAZM/zRM+QSc4ALmgKnVg4iIiIjIsIolYjR0NmDbNjnuN14Q9of9fPnpL7O5aTOODAcrz17Jh8740IDnCcfDuJ1uSnJK0rFsEZFTUlBBRGQU6egwlQ86O82NfFeKodb6elNFoa7ObJ9/Plx3HeTnp77WZLW2gs8Hc+eCO8WHCkVERERGFNuC3kYTJogHIbs89SoKAK1/g1duMWO6CmDBHVBydurjglo9iIiIiIiMAPu799MUbKIm742t4vZ37+cLT32BA4ED5LhyuOudd/GW2uSeQusOd1OaU0p+1jBeIBaRcUNBBRGRUcC24eBBU0khFoOamtQqDcTj8Nhj8O1vm/f5+bBqFSxblr41J6O72zycN3cu5PW/bZqIiIjIyBcLQqAeeg9Apjc9VRSsONR/C/b+f2Y7fx4sXGPaSKTKtiHSAVZUrR5ERERERIZRd7ib3V27KfQU4nQ4j/vZpsOb+PLTXyYQCVCZW8n9y+9nWtG0pOaxbZtoIkpVXhUZqqAmIkNAQQURkREuFjOVD+rrTZuHkhSrbu3fD7feCq++arbf+la46SYoLk55qSkJh6GnBxYuhLKy4V2LiIiISNrYFvQdBv8uiPekr4pCuB1euQk6N5vtiZfAzGvSEyY42urBlQsFavUgIiIiIjJcElaC+o56wokwJd7jLww/sfMJ1jy7hoSdYF7ZPO57130Ue5O/yNsT7SHPnfeGeUREBouCCiIiI1goBNu3m2oKZWWQnZ3aeBs3wsqVJhSQkwNf+hK8733Df905HoeWFpg5EyZMGN61iIiIiKRNPAQ99RDcD5nZ4K1Jz4lX8wbYdifEAoADFtwJle9KfVx4XauHmiOtHlTmSkRERERkuBwKHKIx0EhlXuWxfQkrwTde/AaPvfIYAMunLmf1W1eTlZmV0lyBSIBpRdPwZHpSGkdEpL8UVBARGaHa2kxIoasLqqshM8W/sXftgi9/2YQUpk+H+++HijRUBU6VbUNTE9TWwowZqbW0EBERERkRjlZRCOwyYQJPOThTu2gIQLQbdtwLTU+Z7dypMP828M1KfWy1ehARERERGVF6Ij3Ud9ST684l02EuDvfGern5Lzfz9/1/B+DTiz/NJ8/8ZMqtGmKJGBkZGZTnlqe8bhGR/lJQQURkhLEsU0Fhxw5IJKAmDQ/e7dsHV10FwSAsWADf+Ebq1RnSpaUFCgth9mxw6Vq4iIiIjHbHVVHwgLc2PVUUWv4K29ZAtAMynDD5Mpj2yfS0kbDi0NdkqicUzgdPxfCX3BIRERERGccs26Khs4FgLEitrxaA5mAzK59aSV1nHW6nm1vedgvLpy5Py3z+iJ8iTxGFnsK0jCci0h8KKoiIjCDRKNTXQ0MD5OZCaWnqYzY1wZVXmsoMM2fCAw+MnJBCd7epFDF3rvm+IiIiIqOWbR+porATYn5zsz8tVRT8sOM+aPqD2c6dAvNugfy5qY8Nr7V6yKk1lRnU6kFEREREZNg19TRxwH+AMm8ZANvatrHyqZV09HVQlF3E19/1deaVz0vbfKFYiJklM3E6nGkbU0TkdBRUEBEZIXp6TKuHxkYoLwdPGlqBtbfD5z5nqhZMmmQqKYyUQEBvr6nwcOaZUFIy3KsRERERSUG890gVhX1HqihMSE9Fgta/w7Y7TUsGHDD5YzDtU+kJQNg2RNrBiqnVg4iIiIjICNIX66O+ox5PpoeszCye3vM0t/z1FiKJCFMLp7Ju+Toq8yrTNl8oGiLHlUOJVxdpRWRoKaggIjICtLaakEJ3N1RXmyoDqfL7TbuHgwehshIefti0WBgJYjFoa4NZs6C2drhXIyIiIpIk2zYtEwK7INYNnjJwpiFtGgvAjq/D4d+Z7ZxJMO9WKDgj9bHhX1o9LFCrBxERERGREcK2bXZ37qYr3EVNXg2PvvQo39z0TQDeUvsW7nzHneS60/skmj/ip8ZXk/ZxRUROxzHcCxARGc8sC/bsgU2bTIWBmpr0hBRCIbj2WtNCorgYvvlNU6VhJLAs045i4kSYMUPXxEVERGSUivdC96vQuQmsKHhr0xNSaHsWnr34SEghw1RRePOP0hdSiAehrxG81VB8FmRX6oRMRGScefjhh5k0aRIej4elS5eycePGk372Bz/4ARkZGce9POkoASkiIifUGmplX/c+8rPyufVvtx4LKVxyxiWsfffatIcJElYCy7bSWqFBRKS/VFFBRGQY2LZpe7BvH+zeDT4f5OenZ+xIBK67DrZuNWM+/PDIqlrQ3GxaPcyenZ5QhoiIiMiQsm0IN5sqCpFOyC5PUxWFIOz8OjT+xmx7J8C8W0zFg3Q4rtXDXMidolYPIiLj0OOPP87KlStZv349S5cuZd26dSxfvpxdu3ZRVlZ2wmN8Ph+7du06tp2hgJuIyKAIx8PUd9QTiAb4yl++wsstL+PMcPKlN3+J/5rzX4MyZ0+0h7ysPIqziwdlfBGRU9EtIhGRYbB/P+zcaaoolJdDuh5GiMfhhhvgxRfB64UHH4Rp09Izdjp0doLbDXPnmvWJiIiIjCrxPuhpgNBecLghZ0J6qhG0PQ/b7oBwC5ABkz4M0z+bngAEqNWDiIgcs3btWq644gpWrFgBwPr16/nd737Ho48+yg033HDCYzIyMqioqBjKZYqIjBuWbdEd7qazt5PGnkZebnmZe//vXhp7Gsl15/K1d36Ns2vOHrT5A5EAZ5SdgcupELOIDD0FFUREhpjfD3V15trwhDRd2wbTUuHWW+GZZyArC9auNYGAkSIUgnAYzjwTioqGezUiIiIiA3CsikLdkSoKZekJEcSDsHMdHHrCbHtrj1RRWJj62K+fI9JhxvbNMmEFEREZl6LRKJs3b2bVqlXH9jkcDpYtW8bzzz9/0uOCwSATJ07EsiwWLVrEXXfdxdyRdMFBRGSUsWyLQCRAR28Hh3sO4w/7iVtxdrTv4K5n7yIYDVKdV8265euYXDh50NYRjodxO92U5pQO2hwiIqeioIKIyBBKJExIoa8PamrSN65tw913w5NPgtNp3i9Zkr7xUxWNQkcHzJkD1dXDvRoRERGRfkhEINYD8R7oO2xu9jtckFObnqRp+z9g61ePVFEAJl4CM65MXxWFo60e7PiRVg9TwaFLACIi41l7ezuJRILy8vLj9peXl7Nz584THjNz5kweffRR5s+fj9/v57777uPNb34z27Zto+YkFzYikQiRSOTYdiAQSN+XEBEZpWzbJhAJ0BXu4nDPYbr6uogmonhdXoq9xfx575+55a+3kLATLCxfyH3vvo8CT0Fa549bcaKJKDErRiwRozPcyZTCKeRnpaknsYjIAOkqhYjIEDpwAA4dgqqq9I1p2/DQQ/Dzn5tr5l/9Kpx7bvrGT5VlQVMTTJ4MU6eqyrCIiIiMUImoCSXEeswN/mgXxHsBG5xZkFWcpioKIdj1ABz8hdnOroZ5q6FocepjH3Ws1YMP8hdCtsp1i4hIcs455xzOOeecY9tvfvObmT17Nt/+9rf56le/esJj1qxZw2233TZUSxQRGbFs26Yn2kNX35FwQriLSDyC1+Wl0FNIVmYWAI9ve5z7nrsPG5t/m/Rv3PmOO3E73QOe71gQIRE7FkaIW3HAtPHJdGTicrpwOVwUegupya+hPKecDF2wFZFhoqCCiMgQ6e421RR8PshM49++3/8+/PCH5v2NN8K7352+sZMRj5sWD0df8TiUl8OsWen93iIiIiIpseKvBRPCR4IJiRBYCcjMAmcOePMhw5m+OTtehFdvh3CT2Z7w/2DG1ZCZnb45jmv1MBtcuekbW0RERrWSkhKcTictLS3H7W9paaGion+hNpfLxZlnnklDQ8NJP7Nq1SpWrlx5bDsQCFBbW5vcokVERqFgNEhnX+exygnheBhPpof8rHw8Oa+Fn23b5pubvsn3X/4+AB+c80GuO+c6nI4T/w4St+LEErHjqiLE7Ti2bZPBkSBCpgki5Gflk+POIcedQ5YzC7fTjdvpJivTvHdkOIbkz0JE5FR0y0hEZAjE41Bfb27cp7Plw+OPwze/ad5//vNw0UXpG7s/bNt8p74+80okTOuJ7GzIzzdVFHJzoaDA7BMREREZNlbitWBCtNPczI+HTGsEhxsyveAqH5z2CPFeqHsIDvzUbGdXwRmroTiNvbrU6kFERE7D7XazePFiNmzYwIUXXgiAZVls2LCBq666ql9jJBIJXn31Vd773vee9DNZWVlkZWWlY8kiIqNGKBqiK9xFU08THX0d9MX6yHJmke/Jpyyn7A2fj1tx7nzmTn5T9xsAPrP4M3xi4SeIJCLEYiaMELfixK04NjYAmRlHKiI4XeRl5ZHrziXHlXMsfHA0kJCVmaUggoiMCrpqISIyBAaj5cNvfwv33mveX3EFfPSj6Rv7ZCIRE0gIhyEWM20cPB4TQqisNOGEnBzz0jUJERERGVa2ZaoLxHpMtYRImwkMJKLgdIHTC56ywb+Z37nZVFHoazTbtf8FM68xwYh0seLQexjc+Wr1ICIip7Ry5Uouu+wylixZwllnncW6desIhUKsWLECgEsvvZTq6mrWrFkDwO23387ZZ5/NtGnT6O7u5t5772X//v188pOfHM6vISIyIvTGeunq66Il2EJbXxu90V7cTje+LB+l3tKTHheOh1m1YRXPHHgGR4aDG8+9kQtnXcjhnsNkOjJxO93kZeWR48o5FkT41zDCyaouiIiMJgoqiIgMsu5uU00hPz99rQ/+8he4/Xbz/pJL4FOfSs+4r3e0hUNfnwkoWBa43SaUUFUFhYXg9ZpQgtdrQgsiIiIiw8a2XxdM6DbBhEQIEhHTviEzB7KKTPWEoRDvg7pvwIHHzbanAs74CpQsTfM8R1o95KjVg4iInN7FF19MW1sbq1evprm5mYULF/Lkk09SXl4OwIEDB3A4XnsKt6uriyuuuILm5mYKCwtZvHgxzz33HHPmzBmuryAiMqzC8TCdfZ20hlppDbUSioZwOVz4snwU+4rJOM1F0u5wNyufWskrra+Q5czirnfexdsmvo2eSA+ZjkwWViykNKeUTFVHE5FxIMO2bXu4F5EOgUCA/Px8/H4/Pp9vuJcjIgKYm/2bN0Nzc/paPvzjH/CFL5iKBhdcAF/5CjhSrORlWce3cLAsE6rIzjatG4qLzX+PVktwKrArIsNsrJ/7jfXvJ5IWtg2JXhNMiPkh3Gpu2sfD5uQoM8dUTXAOQ5mnzpdg623Qe8hs11wEs66FzDSGCGzbhDHsBORNV6sHEZFRbKyf+4317yciY18kHqErbConHA0nOB1OfFk+clw5pw0nHNUcbOaqP1zFvu59+LJ8rH33WhZWLCRuxWnsaWR+2XymFU8b5G8jIjK4BnLup6sYIiKD6MABOHw4fS0fXn4ZrrvOhBTe+U64+ebkQgona+Hg9ZpAhc/3WijBPUQPHYqIiIicVrwPYgHzirSZkEKiD8iAzGxw+Uw7h+GSCEPdw7D/J4ANnvIjVRTOTv884VZwFUD+LMiuTO/4IiIiIiLjXDQRpauv61jlhJ5oDw4c+LJ8VPuqcWQM7KJsQ2cDV//hatp62yjPKeeh8x9iSuEUAJpDzVTlVTGxYOJgfBURkRFLQQURkUHS1ZXelg87d8LnP2/CBW9+M9xxR3KVDdraIJEwoYTqaigoeC2UkJ2tFg4iIiIygiTCJowQ7zE35qP+I8EEwJl9pJ1D8cg4gel6GV69HXoPmO2aD8DML6S3FYNtQ7TDVI3InQx5MyDTm77xRURERETGMdu2aQo20dzTTFe4i55IDxmODHxuH9V5Aw8nHLWlaQsr/7iSYDTIlMIpPPSehyjPNS13/GE/HqeHmcUzcTld6fw6IiIjnoIKIiKDIB6HujoTKigpSX28ffvg6qshGIQzz4R77gFXEuetwaBZ2/z5JqSgFg4iIiIyoiSiJpQQC0C4zbR0iPcCNjg95qZ8VhEkeYFwUCTCUL8e9v03YENWGZxxE5S+Jf3zhFtMFYXiMyC7amQENERERERExoBoIkpDRwO7u3aTQQZel5eqvCqcjtQuoP5l71+46S83EU1EWVi+kLXL1+LLMqXQY4kY/oifBeULKMwuTMfXEBEZVRRUEBEZBPv3p6/lQ1MTXHmlqdAwaxbcf79p0zBQ8Th0dMDcuTBhQurrEhEREUmZFXtdxYQOiHZCIgS2Bc4sUzHBXTCyggmv1/0qvHorhPab7eoLYNZKcOWlb47jqihMgbzp5s9FRERERETSojvczY72HTT1NFHqLcXrSk/Vsp9t/xn3PHcPlm3xtolv48533Ikn87ULuy2hFmp8NWr5ICLjloIKIiJp1tUFDQ3pafnQ3g6f+xy0tMDkyfCNb0BuEtWDbdsEHmprYerU1NYkIiIikhZ9zRDYZaon2AlwuMwNeFcFOEb4r6qJCDR8G/b+CLAgqwTm3gxl56Z/nnALuHxQvASyK0duaENEREREZJSxbItDgUPsbN9JX7yPmryalCsogGkh8Z0t3+GRLY8AcNGsi7j+LdeT+brfc7r6uvC6vMwsmZmWOUVERqMRfvVHRGR0OdryIRJJveWD328qKRw8aNo0PPwwFBQkN1Z7O/h8MHt26uEJERERkZTYFgT3Q2C72faUjfxgwut1b4VXb4PQXrNd9V6YfZ0JE6TLcVUUJquKgoiIiIhImoXjYeo66tjTuYdcdy41eTVpGTduxbn7/+7mlzt/CcAVi67gU4s+Rcbr2rZFE1GCsSCLKhcdawMhIjIejaKrQSIiI1+6Wj6EQnDNNbB7twk8PPwwlJUlN1YwaAIUCxcmV41BREREJG2sGATqoKfBtEdw5w/3ivrPikLDI7Dn/8NUUSiGuTdC2dvSO89xVRQWQ3aVqiiIiIiIiKRRe287O9t20trbSnlO+XHtGFIRjoe56c838bf9fyODDK5/y/X815z/Ou4ztm3TEmphYv5EanzpCUeIiIxWCiqIiKRJVxfU15uqB6lULYhE4ItfhG3bTPuIhx+GmiTPWeNx6OiAuXOhoiL5NYmIiIikLN4L/m0QOgjZ5eBMz8XAIeHfDq/eCsE9ZrvyPaaKgrsgfXPYNkQ7Id6nKgoiIiIiIoMgYSXY172Puo46ElaCWl8tjjSFggORACufWsnLLS/jdrq549/u4B2T3/GGz3X0dZDnzmN68fS0zS0iMlopqCAikgaxGOzaBdEolJYmP048DjfcAJs2QU4OPPQQTJ2a3Fi2bao71NYmP4aIiIhIWkQ6TUgh0g7e6tHT6iHcAjvug5a/mG13EcxdBeX/lt55jlZRyFQVBRERERGRwRCKhqjrqGNf9z4KPAVpbbnQEmzh6ievZk+XaSOx9t1rWVS56A2fC8fDhONhllQtIdet0rciIqPk6pCIyMh2tOVDdXXyYyQScMst8MwzkJUF998Pc+YkP15bm6nuMHt2ahUeRERERFLS2wjd28CKgLdmdNyA72uGPd+HQ78GO2b2FZ8FC+4avCoK3kngmw4uXbAUEREREUmnlmALO9p20BXuoiK3ArfTnbax93Tt4eo/XE1LqIVSbykPnf8Q04qmveFzR1s+TC2cSlVein2DRUTGCN26EhFJUWcnNDRAYWHygQDbhq99DZ56CpxOuPtuWPTG0G2/BYMm+DB7NuTqWreIiIgMBysBwb0Q2AFON3hHwcW43kbY8wNo/A3YcbOvcBFMuwKKlkBGRvrmSkQg3AqZeaqiICIiIiIyCGKJGHu69tDQ2YAjw0Gtr5aMNJ7T/7Pln3zhqS8QiASYVDCJh97zEJV5lSf8bHtvO0WeIqYXT0/rGkRERjMFFUREUhCLQV1dai0fbBsefBB++UtwOOCOO+Dcc1NbU2cnzJ0LFRXJjyMiIiKStEQEArsguAfchSO/SkDoIOx5FA7/HuyE2Vf0Jpj2SShanP75Ip0Q7wXvRFVREBEREREZBIFIgF3tuzgYOEhxdnHaWy38bf/fuHHDjUQSEeaVzeP+5fdT4Ck44Wf7Yn1ErSgLShbgdXnTug4RkdEsqcc1Hn74YSZNmoTH42Hp0qVs3LjxpJ+NxWLcfvvtTJ06FY/Hw4IFC3jyySdTGlNEZKQ42vKhvDz5MR59FB57zLy/8UZ417uSH8u2obkZJkyAKVOSH0dEREQkabEe6HoJgg3gKRvZN+FD++GVW+DZ/zpSRSEBxWfD0u/CWd9Kf0jBippQBA4oWgRFC0b2n4+IiIiIyChj2zaNgUZebHyRwz2Hqc6rTntI4YmdT/ClP32JSCLCeRPO41vv+9ZJQwqWbdHa28rUwqlU5OqpMhGR1xtwRYXHH3+clStXsn79epYuXcq6detYvnw5u3btoqys7A2fv/nmm/nRj37EI488wqxZs3jqqae46KKLeO655zjzzDOTGlNEZCQ42vKhqCj5lg8/+Ql861vm/Re+ABdemNqa2tqgoABmzkx+TSIiIiJJC7eBfxtEuyG7Ghwj9IQkuAd2PwpNfwQss6/kzabFQ8G8wZkz0gnxkKooiIiIiIgMkkg8QkNnA7u7dpPlzKLGV5PW8W3b5nsvfY/1m9cDcMGMC7jpvJvIPMXvPa2hVkq9pUwtmqqWDyIi/yLDtm17IAcsXbqUN73pTXzjG98AwLIsamtrufrqq7nhhhve8PmqqipuuukmrrzyymP7/vM//5Ps7Gx+9KMfJTXmiQQCAfLz8/H7/fh8voF8JRGRAYvFYNMmaG+HqiTbLf/2t3Drreb9FVfApz+d2pqCQfNavFgtH0Rk7Bvr535j/fvJGGTb0HsQ/NtNVQJPOYzEi3A9DbD7e9D8NHDkV+HS80yLh/y5gzOnFYXeZnDlgW8meKshI6nihiIiMkaN9XO/sf79RGRk6OrrYmf7Tg73HKY8p5xsV3Zax09YCe57/j5+uv2nAKxYuILPLfncKcMHoWiInmgPb6p+E2U5eihXRMaHgZz7Dejxlmg0yubNm1m1atWxfQ6Hg2XLlvH888+f8JhIJILH4zluX3Z2Ns8++2zSYx4dNxKJHNsOBAID+SoiIinZt8+0WEgmpNDRAbfdBs89Z7YvuQQ+9anU1hOLmQoPZ5yhkIKIiIgMMStuAgA9dZDpBXfpcK/ojQJ1sPu70PLn1/aV/xtMuRzyZw3evEerKORMAt80E1YQEREREZG0sWyLg/6D7OzYSSQeodZXi9PhTOsckXiE1X9dzYa9G8gggy+e80U+dMaHTnlMwkrQ3tfOnNI5CimIiJzEgIIK7e3tJBIJyv+lGXt5eTk7d+484THLly9n7dq1vPWtb2Xq1Kls2LCBX/ziFyQSiaTHBFizZg233XbbQJYvIpIWHR2m5UNhYXLtFe6557WQwkUXwcqVqT1waNsmNDFhAkyenPw4IiIiIgOWCEP3DujdB1nFkJkz3Cs6nn+HCSi0/u21feXvhKmXg2/G4M1rRaGvBTJzoWgReGtURUFEREREJM36Yn3s6tjF/u795LpzKckrSfscwWiQlX9cyZamLbgcLm5/++28a+q7TntcS6iFitwKphROSfuaRETGikFvGPrAAw9wxRVXMGvWLDIyMpg6dSorVqzg0UcfTWncVatWsXLlymPbgUCA2traVJcrInJKsRjU1UE8DnlJPBD3zDOwYYMJJqxZA8uWpb6mtjYoKIBZs5ILToiIiIgkJeoH/zboawZvJTjcw72i13RvNQGFtmeP7MiAinfB1E9A3rTBnTvaBbEgeGtNGEJVFERERERE0q4t1MbO9p209bZRkVNBVmbWoMxxzZPXUN9ZT44rh6+/++ssqVpy2uN6Ij1kOjKZWTwTt3ME/Z4kIjLCDOiWVklJCU6nk5aWluP2t7S0UHGSWuOlpaU88cQThMNhOjo6qKqq4oYbbmDKlClJjwmQlZVFVlb6/+ERETmVffugqQmqqwd+bG8v3H23ef+xj6UnpBAMgmXB7NmQM8IeYBQREZExrK8ZurdBIgg5NZCR3tKqSet6xQQU2o+Ur8IBVcthyicgd5BLT1kx8+eSmWOqKGRXQ5pLzoqIiIiIjHcJK8G+7n3s6tiFbdvU+mpxDEL1sn3d+7j6D1fTFGyiOLuYB89/kJnFM097XNyK0xnuZF7ZPIq9xWlfl4jIWDKgv73dbjeLFy9mw4YNx/ZZlsWGDRs455xzTnmsx+OhurqaeDzOz3/+cz7wgQ+kPKaIyFA62vKhuDi5ygXr15sWDdXV8KlPpb6eWAw6O2HGDPiX7jkiIiIig8O2oGcvdG4GO3akpcEIuBnf+RK8+Dl44RMmpJDhhKr3w3k/hflfHfyQQrQL+ppMFYWSsyFngkIKIiIiIiJpFoqGeLn5ZV5peYXszGwqcisGJaSwtXUrl//6cpqCTUzwTeDRf3+0XyEFgOZQM1V5VUwqmJT2dYmIjDUDvtW2cuVKLrvsMpYsWcJZZ53FunXrCIVCrFixAoBLL72U6upq1qxZA8ALL7xAY2MjCxcupLGxkVtvvRXLsvjyl7/c7zFFRIZbNGpaPiQSkJs78ON37ICf/MS8v+EG8HhSW49tm8oOEybA5EG+7i4iIiICmIoBgTroaTDtDNz5w7se2zaBid2PmP+CCShUvx+mrDAhisFmxaCvBTK9R6oo1CigICIiIiKSZrZt0xJqYUfbDvwRP5W5lbicrrTP83Lzyzz2ymM8c+AZLNtiTukcHlj+AIXZhf063h/243F6mFk8c1DWJyIy1gw4qHDxxRfT1tbG6tWraW5uZuHChTz55JOUH3mc98CBAzgcryXYwuEwN998M3v27CE3N5f3vve9PPbYYxQUFPR7TBGR4bZ3rwkG1CRxvTsehzvvNC0ali+HdBSLaW2FwkKYNSu56g4iIiIiAxLvBf82CB0ETxlkZg/fWmwbOjaaFg9dL5l9GZlQfQFM+Th4k+jRlYxoN8R6TBUF33Rw+YZmXhERERGRcSSWiLG7azcNHQ1kOjKpyashIyMjrXM0B5t5cOOD/HH3H4/tO6fmHO5edjdel7ff6/RH/CwoX9DvYIOIyHiXYdu2PdyLSIdAIEB+fj5+vx+fTxeIRCR92tth40bIyUmumsJ//zfcfz/k5cHPfmZaR6QiGDSvJUvU8kFExq+xfu431r+fjDKRThNSiLRDdhU4hikladvQ/g9TQaH7FbMvwwW1F8LkyyC7YmjWcbSKgjMb8meqioKIiKRsrJ/7jfXvJyKDJxAJsKNtB409jZRkl5Djzknr+OF4mP/vn/8fP/znD4kkImSQwftnvJ93Tn4nZ9ecTeYAfvc5FDhEVV4ViyoX4dTvByIyjg3k3E/P4YqInEI0CvX1ybd8aG6G9evN+2uvTT2kEItBRwfMn6+QgoiIiAyB3kbo3gZWxLRSGIT+r6dl29D2fyag4N9m9jncUHMRTLnMVHgYKseqKNSAb4aqKIiIiIiIDALbtmnsaWRn205CsRDVedUDCg30Z/yndj/FQxsfoiXUAsCZFWfyxXO+yKySWQMer6uvC6/Ly8ySmQopiIgMgIIKIiKnkErLB9uGu++Gvj4480z4939PbS22bdYycSJMmpTaWCIiIiKnZCUguBcCO8DpBm/V0K/BtqH1b6bFQ2Cn2efIgtr/hMmXgqdk6NZixaGv2VRRKDpTVRRERERERAZJJB6hobOBhs4GsjOzqfElcWH2FLa1bePrz3+dV1pMlbaK3AquPetalk1ZllRLiWgiSjAWZFHlInxZCjKLiAyEggoiIifR3g67d5sqCM4krkNv2ADPPAOZmXDjjeBI8QHE1lYoKoJZs8yYIiIiIoMiEYHALgjuAXchuJIoK5UK24KWv5qAQk+d2ef0wIQPwqSPQlaKJaoGKh6CcBt4a8E3E9z5Qzu/iIiIiMg40dnXyc72nTQHmynPKceT6Unb2O297Xxj4zf4bf1vAfBkevj4go/z0fkfTXoe27ZpCbUwMX9i2gMVIiLjgW51iYicQDQKdXVgWcm1fAgG4b77zPsVK2Dy5NTW09NjHiqcPRty0tuKTUREROQ1sR7TXqHvMHgqwJk1dHPbCWj+swkoBHebfU4vTPh/MPkjJjQxlGwbIm1mXflzIW8qOFxDuwYRERERkXEgYSU4GDjIrvZdRBNRavJq0tZCIRKP8OOtP+b7L3+f3lgvAOdPO5+rz7qaspzU2sh19HWQ585jevF0HMPRJk9EZJRTUEFE5AT27oXm5uRaPgB84xumIsOECfDxj6e2llgMurpg3jwoG8IWzCIiIjLOhNtMSCHaDdnVkMYesKdkJ6DpT7D7exDaa/Zl5sDED8HES8BdMDTreD0ralo9uAvBNwuyK4Z+DSIiIiIi40BnXye7O3dzKHAIX5aPEm96WrzZts2f9/2ZB194kMaeRgDOKDuDL579ReaVz0t5/HA8TDgeZnHVYnLdQ1yFTkRkjFBQQUTkX7S1QUND8i0fXnkFfv5z8/7GGyErhQcRbRuammDixNSrMoiIiIickG1D70HwbzehAW8NJNGbdcCsODQ9ZQIKvQfMvsw8mHSJCSm4hqm/a9RvXjmTIH+GCU2IiIiIiEhaReIR9nXvY0/XHqJWlMrcSlzO9FQwq+uo4+vPf53NTZsBKPWWcvVZV/Oeae9JS+WDoy0fphZOpSqvKuXxRETGKwUVRERe52jLB9tOruVDPA533mmOv+ACWLIktfW0tkJREcycmVxoQkREROSUrDj0NEBPHWR6wV06NPOGW+DFz0Fov9l2+WDSh2HCh8A1TE8j2ZZZV4YTChdAzkRIU7lZERERERExbNumOdhMQ2cDbb1tFGcXU+ZOTxnZrr4uvrnpm/xq16+wbIssZxYfnf9RLltwGV6XNy1zALT3tlPkKVLLBxGRFCmoICLyOnv2QEtL8i0fHnsMdu+GggK49trU1tLTYwIPs2dDjh7kExERkXRLhKF7B/Tug6zioasc0LMbNl9jQgEA06+EiR+EzGEsl5oIQ18LeMogf7b58xARERERkbTqifSwu2s3B/wHcDlc1Ppq03KjP5aI8fi2x/nuS98lGA0CsGzyMq5Zek3aKx70xfqIWlEWlCxIa/hBRGQ8UlBBROSItjYTMki25cOhQ/Dd75r3K1easEKyolHo6oJ586AsPYFiERERkddE/eDfBn3N4K0Eh3to5u16GTZ/AeI9prXCkocgu3Jo5j6ZSCfEeyFvOvimg9MzvOsRERERERlj4lacQ4FD1HfUE4wGKcspw5OZ+nm3bds8e+BZ7n/hfg74TTu5mcUz+eI5X2RR5aKUx/9Xlm3R2tvKzOKZVORWpH18EZHxRkEFEREgEoFdu8z7ZFo+2DbcdZcZZ+lSOP/85Ndi29DcDJMmweTJyY8jIiIickJ9zdC9DRJByKkxrQ6GQvOf4ZWbwYpCwXxYtBbcBUMz94lYcfNnkemFokXgrYGMjOFbj4iIiIjIGNTe205DZwOHew6Tn5XPhPwJaRl3T9ce7v/H/Tx/6HkAirKL+NySz3HBjAtwDlILt9ZQK6XeUqYWTSVDvzuIiKRMzXNERIC9e6G1FUqTbMv8hz/Axo2QlQWrVqV2jbulBYqKYObM5Co7iIjIwDz88MNMmjQJj8fD0qVL2bhx4yk/393dzZVXXkllZSVZWVnMmDGD3//+98d+fuutt5KRkXHca9asWYP9NUROz7agZw90bgY7duTG/BCdbOz/X3j5ehNSKHsbvOmbwxtSiIegtxGyy6H4LMipVUhBRERERCSN+mJ9bG/dzguHXqAt1EZ1XjUFnoKUx/WH/dz73L1c8vNLeP7Q82Q6MvnY/I/xi//3Cy6cdeGghRRC0RAAM0tmpqUahIiIqKKCiMixlg8lJckFA7q7Ye1a8/6Tn4SamuTX0tNjrpHPng1etTgTERl0jz/+OCtXrmT9+vUsXbqUdevWsXz5cnbt2kXZCXrvRKNR3vWud1FWVsbPfvYzqqur2b9/PwX/0u9n7ty5PP3008e2MzN12i3DzIpBoA56GsCVB+78oZnXtqH+m7Dn+2a79j9hzpeHLiBxovVE2sGOQ/4cyJsKDtfwrEVEREREZAyybIumnibqO+rpCHdQml1Kjjsn5XHjVpxf7PgF3978bfwRPwBvm/g2Pr/089Tm16Y8/qkkrATtfe3MKZ1DWY769IqIpIuumIrIuPb6lg85SZ4vP/CACStMnQof+1jya4lGoasL5s+HE9wbExGRQbB27VquuOIKVqxYAcD69ev53e9+x6OPPsoNN9zwhs8/+uijdHZ28txzz+FymZubkyZNesPnMjMzqahQv0oZIeK94N8GoYPgKYPM7KGZ14rD1jvg8G/N9vTPwJTLh69ygRWDviZwFUD+QvCUq4qCiIiIiEga+cN+9nTt4YD/AJ5MDxN8E3BkpF7Y+x+H/sHaf6xlT9ceAKYUTuGL53yRpdVLUx67P1pCLVTkVjClcMqQzCciMl4oqCAi49qePabVwoQkW6Nt2gS/+Y25xn3TTZDsA7O2DU1NMHkynOB+l4iIDIJoNMrmzZtZtWrVsX0Oh4Nly5bx/PPPn/CYX//615xzzjlceeWV/OpXv6K0tJQPf/jDXH/99ThfV5anvr6eqqoqPB4P55xzDmvWrGFCsv/YiKQi0mlCCpF28FaDY4h+BYz3mlYP7c+b6glzb4SaDwzN3CcSC0CkG3ImQP4syEz9iS4RERERETFiiRgH/Ado6GqgL9pHWU4ZWZlZKY97wH+AdS+s4+/7/w5AflY+n1nyGS6adRGZQ/S7TU+kB6fDyYziGbid7iGZU0RkvFBQQUTGrdZWE1QoLQVHEsHeSATuusu8/8//NJUQktXSAsXFMHNmcu0nRERk4Nrb20kkEpSXlx+3v7y8nJ07d57wmD179vDnP/+Zj3zkI/z+97+noaGBz33uc8RiMW655RYAli5dyg9+8ANmzpxJU1MTt912G+eddx5bt24lLy/vhONGIhEikcix7UAgkKZvKeNabyN0bwMrAt4aSMOTTP0S6YDNn4fADnB6YOHXoPTcoZn7X9kWhFtMWKJwPuRMgkHqWSsiIiIiMt7Ytk1bbxsNnQ00B5spyCqgJL8k5XGD0SDfe+l7/M/W/yFuxXFmOPngnA9yxaIryPcMURs7TLuJznAn88rmUeJN/XuJiMjxFFQQkXEpEoG6OvM+2ZYP3/8+HDgAJSVw1VXJryUQMBUZ5swBrzf5cUREZPBZlkVZWRnf+c53cDqdLF68mMbGRu69995jQYXzzz//2Ofnz5/P0qVLmThxIv/7v//L5ZdffsJx16xZw2233TYk30HGASsBwb1HggJu8FYN3dyhg7D5aug9ZFosLF4HBWcM3fyvlwhDXwt4SsE3Gzy6sCgiIiIiki69sV72dO5hX/c+MjIyqMmrwZliKDhhJfhN3W/45qZv0tnXCcA5Neew8uyVTC6cnI5lD0hLqIWqvComFUwa8rlFRMYDBRVEZFzavdtUVKitTe74PXvgBz8w76+7DnJzkxsnGoXublONobQ0uTFERCQ5JSUlOJ1OWlpajtvf0tJCRUXFCY+prKzE5XId1+Zh9uzZNDc3E41GcbvfWAayoKCAGTNm0NDQcNK1rFq1ipUrVx7bDgQC1Cb7j5SMb4kIBHZBcA+4C8GV5ElKMvzbTCWFaBdkV8OSh0yrheEQ7YJYCPKmgW+GqewgIiIiIiIpS1gJDvccpq6jDn/ET5m3jGxXdsrjbmnawn3P30ddh3m6bEL+BFaevZK31L6FjIyMlMcfKH/YT5Yzi5nFM3E5XUM+v4jIeDBEtT9FREaOoy0fSkqSa/lgWablQzwO550H73xncuuwbWhuhkmTzEtERIaW2+1m8eLFbNiw4dg+y7LYsGED55xzzgmPectb3kJDQwOWZR3bV1dXR2Vl5QlDCgDBYJDdu3dTWVl50rVkZWXh8/mOe4kMWKwHul6CYAN4yoY2pND2f7Dx0yYg4JsFZz86PCEFK26qOVgWFC0y1RwUUhARERERSYuuvi62NG1hc9NmElaCCb4JaQkpfO+l7/Gp336Kuo46ct25fOHsL/D4fz7OuRPOHZaQQiwRwx/xM71oOoXZhUM+v4jIeKGKCiIyrkQisGuXabWQbMuHX/0KXn4ZsrPh+uvNWAPV12cCE8XFMHMmONUqWURkWKxcuZLLLruMJUuWcNZZZ7Fu3TpCoRArVqwA4NJLL6W6upo1a9YA8NnPfpZvfOMbXHvttVx99dXU19dz1113cc011xwb87rrruOCCy5g4sSJHD58mFtuuQWn08kll1wyLN9Rxolwm6loEO021QwcQ/ir3qHfwLY7wE5A8dlw5t2QmeSJViriIQi3m1YXvlngLhj6NYiIiIiIjEHRRJT93fvZ3bWbSDxCRU5F2qoM/Per/823Nn0LgPMmnMfqt64elnCAbdsEo0H8ET9xK86E/AlMKBimCnEiIuOEggoiMm7Ytqmk0NaWfMuH9nZ48EHz/jOfgZNUBj/tOlpbYcYMsw6vN7m1iIhI6i6++GLa2tpYvXo1zc3NLFy4kCeffJLy8nIADhw4gON15Xdqa2t56qmn+MIXvsD8+fOprq7m2muv5frrrz/2mUOHDnHJJZfQ0dFBaWkp5557Lv/4xz8oVY8fGQy2Db0Hwb/dBAW8NcmlKJOde8+jUG8uKlL1XjjjK+AY4rKotg2RdrBikD8HcqeA88QVTkREREREpP9s26Yl1EJ9Rz1tvW0UeYoo9abvd9sfvfIj1r2wDoBPLPwEn13y2SGvoBC34nSHuwnFQuS6c5laNJXi7GIKswvJHMoAuIjIOJRh27Y93ItIh0AgQH5+Pn6/X6VyReSEGhthyxbIz0++msKNN8If/wizZsEPfgCZSZyrtrdDVhacfTZ4VIlYRCQpY/3cb6x/P0kDK25uzvc2mlYHrhxwD+FTR3YCtt8LB39mtid/HGZcOXQhiaOsGPQ1g8sH+bPBUzH0axAREUnRWD/3G+vfT2SsCkaD7O7czX7/fjIzMinxluB0pK8s7A//+UMe3GieCPvkmZ/k04s/PaQhhb5YH13hLizbosBTwMSCiZR6S8lxD0N1OBGRMWQg536Kg4nIuNDVBdu3m4BAsiGF554zIQWHA26+ObmQQixm2j7MnauQgoiIiCQhHjJtHkL7IdoFGU7wlIBzCE8sEmH4583Q+lcgA2ZfBxMvHrr5j4r1QKQLciaAbya4cod+DSIiIiIiY0zcitMYaKS+o56eaA9lOWV4MtP7+8YPXv4B33jxGwBcsegKPr3402kd/2Qs2yIQCRCIBMjKzKIqr4pqXzUl3hJVTxARGQb6m1dExrxw2IQU+vqgujq5Mfr64GtfM+8/9CFTUSEZra1QVQWVlckdLyIiIuOQbZlQQu9h6GuCeNBUUMiuhKG+mBb1w5aV0P1PcLhh/u1QsWxo12BbEG41lRMK50POJEjjk10iIiIiIuNVR28HDZ0NHO45TJ47j1pfbdqrHHz/5e/z8IsPA/CpRZ/iU4s/ldbxTySaiNLV10UkEcGX5WNO6RwqcivwZfmGvNWEiIi8RkEFERnTEgnYuRNaWqC2NvlxvvMdOHwYKirgM59JboxQCJxOmDrV/FdERETklBJRiLRB70FTRcG2wF0AWUXD096grxk2XQ2hvZCZC4vWQtGioV1DIgx9raaKhG+2+a+IiIiIiKQkHA+zr3sfe7r2kLASVOVVDUqFgUdfepRvbvomAJ9Z/Bk+ueiTaZ/j9YLRIN3hbhwZDkq8JdTm11LqLSUrM2tQ5xURkf5RUEFExrR9+8yrosK0bEjGrl3w4x+b99dfD17vwMewbejogJkzobg4uXWIiIjIOBELQF+LCShE/ZCZZW7IO9zDt6aeeth0jQlOeMph8QOQN21o1xDtglgI8qZA3gzIzB7a+UVERERExhjLtmgONlPfUU9HXwfF2cXkugenpdp3t3yX9ZvXA/DZJZ/l8jMvH5R5ElaC7nA3wViQHHcOUwqnUJlXSVF2EY6MJC8Qi4jIoFBQQUTGrJYWU02hoACykgzJJhJw553mv+98J5x3XnLjdHWBzweTJiV3vIiIiIxxVgKiHRBqhEgzxPvAnQ85NTDcF9M6NsFLX4R4CHKnwOIHIbti6Oa34hBuBkc2FJ0J3hHwZyIiIiIiMsoFIgF2d+7mgP8AWc4san21g3Yj/5Etj/Dtzd8G4Mo3XcmKhSvSPkc4Hqarr4uEnaDAU8C0ommU5ZYNWvBCRERSp6CCiIxJPT2wfbupopCXl/w4P/2pGScnB667Lrkx4nEIBmHx4uSqMYiIiMgYFu+DSCuEDkKkw9yAdxeAp2y4V2Y0/RFeuQXsGBQugkX3gcs3dPPHe03bi+xKyJ9t/mxERERERMY527axsY973999CStBc7CZ/f799EZ7KcspG9RWCN/e/G0e2fIIAFe96So+vvDjaRvbtm0CkQD+iB+3001FXgXVedWUeEtwOV1pm0dERAaHggoiMubEYiZc4PdDTU3y47S0wDdNyzSuvhpKS5Mbp7UVKiuhqir5tYiIiMgYYtsQ64beJuhrhFgPZOaYKgWD0Ac2aft+DDvXmvfl74D5XwXnEPVytW0T3LAi4Jtl2kw4h7H1hYiIiIjIKcQSMQ4GDh6rSPD6oACYFguWbWFjY1lH/mtbWFhg88afYWFb9rHP2faRfScJIxx1bB+vfQ6b4z5nY9Mb7aUwu5Da/NpB+zOxbZvvbPnOsZDC1WddzWULLkvL2LFEjO5wN73xXvKz8pldOpuK3Arys/LJyMhIyxwiIjL4RtBVMBGR1Nk21NXBoUMmpJDKeem990JvL8yfD//xH8mN0ddn1jB1KmTqb1wREZHxzYqZ6gB9jRBuNdvufMiZkNpJS7rZFux6CPY9ZrYn/D+Y/UXIcA7N/FbMhDjcPiicD56KkfXnIyIiIiLyOpZtsbV1K7s7d5PpyIQMwAYyIIMMbNs+dvM8g4wTvn/99qn2A8cdD+DIcAxoLIAyb9mg3tC3bZv1m9fzvZe+B8C1S6/lY/M/lvK4oWiIrkgXGWRQ4i1hrm8upTmleDI9KY8tIiJDT7fNRGRMOXQIGhqgvDy1YMBf/2peTifceKNpITFQtg1tbTBtGpSUJL8WERERGeViQQi3QO9BiHaDw2VaGDhH4MU0Kwav3gZNT5rtGVfB5MuGLigQ64Folwlv+GaCS/1kRURERGRk29O5h/3+/VTmVeqGOSak8M1N3+T7L38fgM8v/Twfnf/RpMdLWAn8ET890R5yXDlMyp9EVV4VRdlFOB1DFKYWEZFBoaCCiIwZnZ2m5UNODmRnJz9OMAj33GPeX3qpCRokw++HvDyYMkUPAYqIiIw7tmVaF/Qdhr5miIfAlQfeqqGrTDBQ8SC89GXo2GjWeMZqqH7f0MxtW6bKREYG5M+D3Ekjqw2GiIiIiMgJNAYa2dm+k0JPoUIKmJDCwy8+zA/++QMAVp69kg/P+3BSY4XjYbrD3cSsGAVZBSwoX0BZThl5WXlpXLGIiAwnXfkRkTGhrw+2bYNoFKqqUhvrW9+C1lbTOuLyy5MbIx6HQADOPNMEJ0RERGScSIRNe4fegxBpB2xTPcEzwssrhdth8zXQUwfObFh4D5SeMzRzJyImzJFVDPlzwFM6NPOKiIiIiKSgo7eDrW1bcTvd5LpVCcy2bR7a+BA/fOWHAFx3znV86IwPDXiMnmgPgUiATEcmpTml1PhqKPWW4nK6BmPZIiIyjBRUEJFRL5GAnTuhvd2EC1KxdSv87/+a96tWgSfJIHR7u2k/UV2d2npERERkFLBtiPlNe4fQIYgHTFsHT5lp8zDSBfeZkELfYXAXweIHIH/20Mwd7TatMfKmQN5MyEyhLJaIiIiIyBDpifSwtXUrsXiMyrzK4V7OsLNtmwc3PshjrzwGwJfe/CUunnvxgMYIRAJ0hbvwuX1ML5pOZV4lBZ4CMlSqVkRkzFJQQURGvT17YN8+qKgAhyP5ceJxuOsuc6/h/PNh6dLkxgmHwbJMywjXKLg3ISIiIkmy4qZqQm8jRFpMZQCXD7w1kJHCSclQ6noFtnzBBC28tbDkIbP+oRA+UnGiaKGZe7T8mYmIiIjIuBaJR9jWto2uvi5qfEN07jyC2bbNuhfW8d+v/jcAX37zl/l/c//fgMaIxCP4I37mlM5hYv5Esl0KMIuIjAcKKojIqNbUBLt2QVERuN2pjfXjH0NdHeTnw8qVyY/T1gaTJ0OpqhaLiIiMTfGQae8Q2m8qAmQ4IKso+VJMw6X1b/DyjWBFTMuFxQ+Au3Bo5g63Ag4oXADZegJNREREREaHhJVgR/sODvccpiavZtw/7W/bNvf/435+vPXHANzwlhv4rzn/NaAxLNuiOdTMlMIpzCiegUMBZhGRcUNBBREZtQIB2L4dMjMhN8U2cI2N8O1vm/fXXguFSV6j7+4GrxemTIFx/nuKiIjI2GJbEO2C3sPQ1wTxILhyILsCHKPw16qDv4RtawALSt8CC742dG0X+prB4YaC+ZBdPjRzioiIiIikyLZt6jvr2du1l8rcSpwO53AvaVjZts3af6zlf7b+DwCrzl3Ff87+zwGP0xpqpTi7mJnFMxVSEBEZZ0bhFTUREYhGTUghGISaFCus2TbcfTdEIrB4MVxwQXLjJBLg98OCBZCXl9qaREREZIRIRCHSBr0HTRUF2wJ3gamgMBpTibYNDd+B3Y+Y7ep/h7k3Dl3Yoq8ZHFmmkoJH5adEREREZPQ44D/ArvZdlHhLcDtTLO06ytm2zX3P38fj2x4H4KbzbuKiWRcNeJyeSA8ZGRnMKZ2jdg8iIuOQggoiMupYlmn3cPgwVFenPt4f/wjPPQcuF6xalfw9h/Z2KCuD2trU1yQiIiLDLBaAvhYTUIj6wemGrGJwZg33ypJnxWH71+DQE2Z76idh2qeHJnBh26YSRaYXCheaP0sRERERkVGiJdjC9rbt5Lpz8bq8w72cYWXbNvc8dw8/3f5TMsjgpvNu4sJZFw54nFgiRle4i3ll8yjNUYhZRGQ8UlBBREadgwdhzx4oLzdtH1IRCMDXv27ef+ITMGlScuNEIhCPw7Rp4B7fgWoREZHRy0pAtANCjRBphngfuPMhpwZGewnSeB/880ZoewZwwJzrYcLAy7Imxbah7zBk5plKCllFQzOviIiIiEgadIe72dq6FYACT8HwLmaYWbbFPf93Dz/b8TMyyODmt97MB2Z+YMDj2LZNc6iZCfkTmFQ4Kf0LFRGRUUFBBREZVdrbYccOyM0Fjyf18R56CDo7TUDhssuSH6e1FSZONOEJERERGWXifRBphdBBiHSYCgPuQvCUDffK0iPaDZs/D/6tpu3Cgjuh/O1DM7dtQ18juApMSMFdMDTzioiIiIikQW+sl60tWwnGgtTkpdh/dpSzbIu7/+9ufr7j52SQweq3reaCGcn10G3vbceX5WNmyUwyh6oNnYiIjDj6F0BERo1QCLZtg0QCStNQDeyll+CXvzTvb7op+UoIgQBkZ8OUKaOzVbWIiMi4ZNsQ64beJnMjPdYDmTmQXQFj6UJZbyNsuhp6D4DLB4vWmtYLQ8G2oPewCScULjTVKURERERERolYIsb21u209bZR41NIYc2za/jlzl+SQQa3vO0W3j/j/UmNFYqGiFkxFpQsINedm+aViojIaDKGrsCJyFgWj8POnab6QW1t6uNFo3DXXeb9hRfCmWcmN45lQVcXzJ8P+br2LiIiMrJZCbDCEPWbcEK4Fey4uYGfM2HsJQ4DO2HTtaadhacCljwEuZOHZm7bMiGJrBJTScGVNzTzioiIiIikgWVb7GrfxYHAAarzqnGM9lZwKbBsi7ueuYsndj2BI8PBrW+7lfdOf29SY8WtOO197cwpnUNFbkWaVyoiIqONggoiMuLZNuzeDfv3Q1VVeu4h/PCHsHcvFBXBNdckP05HBxQXpyc8ISIiImliJSDRB4nwkf/2mfYH8SBYUbPf4TJP+jvT0EtqJGr/B7z0ZUj0Qt50WPwgeNJQkqo/7ISppOApg4L54NJTUiIiIiIyuuzt2ktDVwPlOeXjujWBZVvc8fc7+HXdr3FkOLjt7bdx/rTzkx6vOdhMVV4VUwunkjHWguIiIjJg4/dfWBEZNQ4fhro6KCkBlyv18fbvh0cfNe9XrgSfL7lxolGIREw1hays1NclIiIiA/SGQELvkUBCCKwIJKKABRkOcLjBkWWe7M8qNvvGqsO/h1dvM4GBoiVw5n1DFxaw4qZahacSCuebdhoiIiIiIqNIY6CRHW07KMgqwJM5RoPN/ZCwEtzxzB38pu43ODIc3P7223nPtPckPV5nXydel5fZJbNxOdNwkVdEREY9BRVEZETr7oYdO8Dthpw0XOe2bVizxoQMzjkHli9PfqzWVqipgQpVKRMRERlcSQUSfJDlHtuBhH9l27D3h1D3kNmueDfMv9X8mQwFK27aPXiroWAeZHqHZl4RERERkTTp6O1gW9s23E43eVnjt31Zwkrw1b9/ld/W/xZHhoOv/ttXWT41+Qup4XiY3lgviyoXke9R/1wRETEUVBCRESsSMSGFUMgEAtLht7+FTZtMBYQbbki+jUQwaMaYOhUc4+j+h4iIyKCy4q8LI4RNECHm/5dAgm3+AXdkmRvw4zGQcCK2BTvXwv6fmO1JH4GZ1w7dn8vRkEJOLeSfAZnZQzOviIiIiEiaBKNBtrZuJRqPUplXOdzLGTYJK8Htf7+d39X/DmeGk6/+21d599R3pzReS6iF6UXTqfGl6SKviIiMCQoqiMiIZFmwcyc0NaUvpNDeDuvWmfef+hRUVye/to4OmDsXCgrSszYREZFx5aSBhCBYUQUSBioRgVdvgeanzfbMz8Pkjw7d/FYM+g5DzkQoOAOc6oklIiIiIqNLJB5ha+tWuvq6xvXN9ISV4Na/3cofGv6AM8PJne+4k2VTlqU0ZmtvK+U55cwonkFGsk+NiYjImKSrfCIyIu3bB3v3Qnk5OJ2pjxcMwjXXgN8PM2bARz6S/FidnVBUBBMnpr4uERGRMc2KQywI4TYIHQT/Tmh/AVr/Bm3PQNtz0LkZenZBtAvIMIEEb7V5Mt9bA55ScOeD06OQwonEemDT1SakkJEJ8+8Y4pBCFHoPg3eyQgoiIiKjxMMPP8ykSZPweDwsXbqUjRs39uu4n/zkJ2RkZHDhhRcO7gJFhljCSrCjfQeHew5TlVc1bm+mx604t/z1lmMhhbveeVfKIYXucDeZjkxmlcwiK1O/K4iIyPFUUUFERpzWVlNNIT8fPJ7Ux+vpgSuvhLo6M+btt0Nmkn/7xWLQ12eqKaRjbSIiImOCFX+tOkKiD+K9EOs+0rLhBBUSnFlHKiRkJd+HabyzYtD2LNR/C4J7wJkDi+6F4rOGbg2JCPQ1Q94U8M0Bp3vo5hYREZGkPP7446xcuZL169ezdOlS1q1bx/Lly9m1axdlZWUnPW7fvn1cd911nHfeeUO4WpHBZ9s29Z317O3aS2VuJU5HGp6YGoWOhhSe2v0Uzgwna965hndMfkdKY0biEQKRAAsrFlLsLU7TSkVEZCxRUEFERpRgELZvN+99vtTH8/vhqqtgxw4TUvjWt2DatOTHa201LSMqx2+bOhERGc8USBh+PQ3Q+Bs4/PsjVSiArGJY/CD4Zg7dOhJhCLdA3lTInwMO19DNLSIiIklbu3YtV1xxBStWrABg/fr1/O53v+PRRx/lhhtuOOExiUSCj3zkI9x2220888wzdHd3D+GKRQbXAf8BdrXvoji7GPc4Dd7GrThf+ctX+NOeP+HMcHL3srt5+6S3pzSmbdu0hFqYVDCJiQUqSysiIiemoIKIjBixmAkUdHVBbW3q43V3w+c+ZyopFBamHlIIhUwlhqlT09OOQkREZMQ6ZSAhAokYrwUSPOZJelc+ZLkVSBgMsR5oegoafw3+7a/tzyqGqvfBxEtMi4yhkghDuBVyp0P+bHDo10oREZHRIBqNsnnzZlatWnVsn8PhYNmyZTz//PMnPe7222+nrKyMyy+/nGeeeWYolioyJFqCLWxv206uO5ccd85wL2dYxK04N//5Zp7e+zSZjsz/v707j4+qPvv//5qZzJZ938MaIOybQEGrrWIR/XK7dLHVW1GrthValbqAVdR6F7RaSqtWbO+qba3W9u6irbgVxV9dKktFRZF9JwtZJzOZfc7vjyOBSBASkkwmeT8fj3mQOXNm5prjYC7mvOf6cO9Z9550SAGg2ldNtjubEbkjsGoJPxEROQZ9oiQivYJhwNatsHevObHgZM9xHBlSyM42QwpDh55cfbW1UFFhPp6IiEifE26Gln0QbjpOICFTgYSeYMSgfj3sew6qXzX/ewBYbJB/OpT8F+RO7/mQQKQFArWQPhzSK6CfjsYVERFJRLW1tUSjUQoKCtpsLygo4OOPP273Pm+88Qa//vWv2bBhwwk/TzAYJBgMtl73eDydqlekOzUFmthYsxGATFdmfIuJk0gswg9e/QGrdq4iyZrEj2f+mNMHnn7Sj+sNeQEYmTeSZHvyST+eiIj0XQoqiEivsH8/bNsGeXnm1IKT0dAA3/mO+Xg5OWZIYciQk3vM+npz6YjBg0/ucURERHqtUCM0fQhJaQokxJO/Evb/w1zewX/g8PbUIWY4ofhccMYpNRnxQbAeMiogbbhCCiIiIn1cc3Mzl112Gb/61a/Izc094fstXbqUu+++uxsrEzk5/rCfjTUb8Ya9lKaVxrucuIjEIixatYjXdr2G3WrnxzN/zOcHfr5LHrfeX8+Y/DHkp+R3QaUiItKXKaggInHX0AAffQRuNySfZMi2rs4MKezYAbm5sGIFDBp0co8ZiUBLC0yaZNYoIiLSZ1mSwHXiH0JLF4kGofo1M5xQtwYwzO1JKVB0DpT+F6SPim9oJOKFYKO51EPaMND4VhERkYSTm5uLzWajurq6zfbq6moKCwuP2n/79u3s2rWLOXPmtG6LxWIAJCUlsXnzZoa2M75y0aJFLFiwoPW6x+OhrCvW+BTpAuFomI8OfkSNr4bS9P4ZUghHw9z26m2tIYX7z76f0wacdtKPaxgGlc2VlKaXnZZeKQAAcLJJREFUMjhL3/YSEZHj69SnSw8//DCDBg3C5XIxbdo01qxZ85n7L1++nBEjRuB2uykrK+PGG28kEAi03t7c3MwNN9zAwIEDcbvdzJgxg7Vr13amNBFJMH4/fPghBIMnv6RCbS18+9tmSCEvDx599ORDCgA1NVBYCMXFJ/9YIiIiIoC5rlTTJvjoPnjtHHj/dqh7BzAgewqMuwe++BKMXgQZo+MbUgg3fxJSGKWQgoiISAJzOBxMnjyZVatWtW6LxWKsWrWK6dOnH7V/RUUFH3zwARs2bGi9/Nd//Rdf/OIX2bBhwzHDB06nk/T09DYXkd4gZsTYUreF3U27KU4rxtrP+tqYEWNX4y7mvTCP13a9hsPm4Cdf+kmXhBQA6vx1pDnTqMitIKmnl6gTEZGE1OHfFs888wwLFixgxYoVTJs2jeXLlzNr1iw2b95Mfv7Ro3yeeuopFi5cyGOPPcaMGTPYsmULV1xxBRaLhWXLlgFw9dVXs3HjRn73u99RXFzMk08+ycyZM/noo48oKSk5+VcpIr1SNAqbN5tBgJMN1h8KKezaBfn55iSFAQNOvsaWFrBaobz85JekEBERESHUCAdegP3PQfPWw9tdBebSDiX/D5J70b+Bwh4zqJA5xlx+QkuBiIiIJLQFCxYwd+5cTjnlFKZOncry5cvx+XxceeWVAFx++eWUlJSwdOlSXC4XY8aMaXP/zMxMgKO2iySCnQ072Vq/lYKUgj59Ij0Si7DPs4+dDTvZ2WhedjTsYFfjLoLRIABJ1iR+cvZPmF52dEipM1rCLQSjQcYWjCXNmdYljykiIn1fh38bL1u2jGuuuaa1eV2xYgXPP/88jz32GAsXLjxq/7feeotTTz2VSy65BIBBgwbxjW98g3feeQcAv9/Pn//8Z5599llOP/10AO666y7+/ve/88gjj/A///M/nX5xItK77dxpXoqKzDBAZ9XUmCGFPXugoMCcpFDaBZPbDMMMQAwbZi4jISIiItIpsQjU/Rv2/R1qXgcjYm63OiD/C+bSDjlTwGKLa5lHCTVCxAcZYyB1sEIKIiIifcDFF1/MwYMHWbx4MVVVVUyYMIEXX3yRgoICAPbs2YP1ZD6kEemlDjQfYNPBTWQ6M3ElueJdTpcIRUPsadrDjoYdZiChYSc7Gnewp2kPkVik3fvYrXYGZw1m/pT5XRZSiMQiHGw5yMjckRSlFnXJY4qISP/QoaBCKBRi/fr1LFq0qHWb1Wpl5syZvP322+3eZ8aMGTz55JOsWbOGqVOnsmPHDlauXMlll10GQCQSIRqN4nK1bQ7cbjdvvPFGR1+PiCSIqipzmkJWFjgcnX+c6mozpLB3rxl4WLECumoQS2MjpKXBYC2pJiIiIp3h2wP7/w77/wHBg4e3p480wwlFs8DeS0chhxoh6oes8ZA8QCEFERGRPmT+/PnMnz+/3dtWr179mfd94oknur4gkW5W11LHxpqN2G32hPy2vz/sZ1fjrjbTEXY27mSfZx8xI9bufVxJLgZnDmZQ5iCGZA1hcOZgBmcOpiS9pMunSVT5qihOK2Zo9lAs+neDiIh0QId+I9XW1hKNRlsTtocUFBTw8ccft3ufSy65hNraWk477TQMwyASifDtb3+b2267DYC0tDSmT5/OPffcw8iRIykoKODpp5/m7bffpry8/Ji1BINBgsFg63WPx9ORlyIicdTcDB9+aE5RSDuJfxtUVcG3vgX790NxsRlSKC7umhojEbPOSZMgJaVrHlNERET6gUgLVK0yl3ZoePfwdnsGFJ8LJXMgfXj86jsRwXqIhSBzHKR0wVpaIiIiIiJx4g152VizkVAkRFFa7/62vzfkbZ2K0LpsQ8NODngPHPM+qY5UhmQOORxIyDIDCYWphVgt3T8dpcHfgDvJTUVuBQ7bSXwbTURE+qVuX4hp9erVLFmyhF/84hdMmzaNbdu2cf3113PPPfdwxx13APC73/2Oq666ipKSEmw2G5MmTeIb3/gG69evP+bjLl26lLvvvru7yxeRLhYKwUcfgdd7cpMPKivNSQr795uP8+ijUFjYdXXW1pqP11XTGURERKQPMwxofN8MJ1S+AtGWT26wQu7nzOkJ+aebSz30dsFaMGKfTFLogrW0RERERETiJBgJsrFmIw3+BkrTe09v2xhoZEfDjsNLNnwSSDjYcvCY98lyZZlTET4JIgzOGsyQzCHkJufGbYpBIBLAF/YxqWgSma7MuNQgIiKJrUNBhdzcXGw2G9XV1W22V1dXU3iMM4R33HEHl112GVdffTUAY8eOxefzce211/KDH/wAq9XK0KFDef311/H5fHg8HoqKirj44osZMmTIMWtZtGgRCxYsaL3u8XgoKyvryMsRkR5mGLB16+FwQWd76P37zZBCZSWUlpqTFLoypBAIQCwGQ4dCUrfHuURERCRhBWrhwD/M5R18uw9vTy6Dkv+CkvPAlR+/+joq8MkHo5njIbmLxlSJiIiIiMRBNBZlU+0mDjQfoCStpMdP5huGQW1L7VHTEXY07qAx0HjM++Wn5JvTETIPT0cYnDmYLHdWzxV/AmJGjGpfNeXZ5ZSk65teIiLSOR06BedwOJg8eTKrVq3iggsuACAWi7Fq1apjrmvW0tKC1dp2xJDNZgPMX9ZHSklJISUlhYaGBl566SV+/OMfH7MWp9OJ0+nsSPkiEmd798K2bVBQ0PkAwL59ZkihqgoGDDBDCvld/Pl/TY0ZUsjL69rHFRERkT4gFoaDb8C+56D2LTCi5nabCwrPNgMKWRM6n8iMl0A1YDMnKbi7MAEqIiIiItLDDMNgW/02djTsoDClkCRr938TadPBTazcthJfyNc6JcEb8h5z/5K0ksPLNWQenpKQ6kjt9lq7QpW3ivzkfIbnDO+RJSZERKRv6vBv6AULFjB37lxOOeUUpk6dyvLly/H5fFx55ZUAXH755ZSUlLB06VIA5syZw7Jly5g4cWLr0g933HEHc+bMaQ0svPTSSxiGwYgRI9i2bRs333wzFRUVrY8pIomvrg42bYLUVHC5OvcYe/eaIYXqahg40AwpdHWYoLHRrHHIkMQ7vyAiIiLdqHmbOTnhwEoINRzenjnOXNqh8GxISolffSfDX2UuS5E1PrEmQIiIiIiItGOvZy+b6zaT687FmdS9X3Y0DIPfvPcbHlr70FG32Sw2StJL2kxHGJI1hIEZA3Hb3d1aV3dqCjRht9kZmTcSV1InP+gVERGhE0GFiy++mIMHD7J48WKqqqqYMGECL774IgUFBQDs2bOnzQSF22+/HYvFwu23387+/fvJy8tjzpw5/OhHP2rdp6mpiUWLFrFv3z6ys7P58pe/zI9+9CPsdnsXvEQRibeWFvjoIwiHITe3c4+xZ48ZUqipgUGDzJBCZx/rWKJRaGqCCRPMsIKIiIj0c2EvVL4E+5+Dpg8Pb3fmQPF55vSE1EFxK++kGQYEqsDqhqxx4NI4KRERERFJbDW+Gj6s+ZAUewopju4NEoejYZa+sZTntjwHQG5yLhdVXNQ6HWFAxgAcNke31tDTQtEQnqCHcQXjyEnOiXc5IiKS4CzGp9dfSFAej4eMjAyamppIT0+Pdzki8olIBN5/H3bvhtJSsHZiEtiuXWZIobbWnHTwyCOQ0w19cFUVZGTAtGmgnJSISO/W13u/uLw+316oXw8pZT3zfL2VETOPw77noPpViAXN7RYb5J9uhhNyp0MPjI/tVoYB/kpISjaXqnDqQ0YREZF4UW8r0jWaAk2sO7COYCRIQWpBtz/XLf+8hfWV67FarCz43AIuHn0xlj48otUwDPZ49jA4czDjCsZhs9riXZKIiPRCHen9EvzTNRHp7bZvN0MKRUWdCyns3GmGFOrqYOhQM6SQnd31dQYC5kSF8nKFFERERPolfyXs/4e5vIP/wOHtqUPMcELxueDshiYkHgzDfI32dHO5B0dWvCsSERERETkp/rCfjTUb8Ya9lKSWdOtz7Wnaww0v3sAezx6S7cksOXMJpw04rVufszeo8dWQ485hRO4IhRRERKRLKKggIt3mwAHYssUMFnTm5P/27XDddWZIYdgw+MUvIKubPkc/eNBcUqKge8PWIiIi0ptEg1Cz2pyeULcG+GTYXFIKFM0yAwoZo6EvfSvKiEHLAXBkfhJSyIx3RSIiIiIiJyUcDfPRwY+o8dVQml7arVMN1h1Yxy3/vAVP0ENhaiHLZy2nPLu8256vt/CGvBgYVORWkGxPjnc5IiLSRyioICJdLhQyT/xv2gQOB6Smdvwxtm2D73wHGhpg+HAzpJCZ2eWlAuDxgNttLivRl85DiIiISDsMAzwfw/7n4MCLEGk+fFv2FCj9Lyj4Ithc8auxuxwKKTizzZCCXaOXRURERCSxxYwYW+q2sLtpN8WpxVgtnRjpeoKe3fwsS/61hKgRZUz+GB44+wFyk3O77fl6i0gsQp2/jjH5Y7p9SQ0REelfFFQQkZNmGODzQVMT1NaaF6/XXOqhuLjjj7dlizlJobERKirg4YchI6PLywYgFjPDEOPGgZZJFBER6eMaN8JH95pBhUNcBebkhJL/B8ndOyI2rowo+PaDK++TkEJavCsSERERETlpOxt2srV+KwUpBdht3bOea8yI8dCah/jt+78F4OwhZ3PnGXfiSuqD4eZPMQyDyuZKytLLGJI1JN7liIhIH6Oggoh0SiRiTiJoaoLqajNU4PeDzQZpaVBUZP7cUZs3myGFpiYYNQoeeqh7AwS1tZCXB2Vl3fccIiIiEmexCGz/X9jxuHnC3uqA/C+Y0xNypoClj6+vakShZT+4CyBzHNg7Me5KRERERKSXOdB8gI9rPybTmdltoQF/2M/i1Yt5bddrAFw98WqunXxtt05u6E3q/HWkOdOoyK0gyarTSSIi0rX0m0VETpjfbwYI6uvNcILXC9EouFzm8g65uSe3dMLHH5shBY8HRo82Qwpp3fhlv1DIvJSXg9PZfc8jIiIiceTdCe8vBs8m83rRLBh5Mzgy41pWj4lFwH8AXIXmJIUkrScrIiIiIomv3l/PxpqNJFmTSHN2zweINb4aFry8gI9rP8ZutbP4jMXMLp/dLc/VG7WEWwhFQ4wtGNttx1hERPo3BRVE5JhiMWhuNsMJNTVmQKGlxQwjpKaakwjsXTRR7aOPYN488/nGjoUHHzSfozvV1EBpKRRoaTUREZG+x4jB7j/ClgchFgR7OoxaCEVfindlPScWMScpJJeYkxSS3PGuSERERETkpHlDXj6o/oBgJEhxWifWnT0BH9d+zI0v3cjBloNkujJ54OwHmFA4oVueqzeKxqIcbDlIRU4FRalF8S5HRET6KAUVRKSNUMgMJjQ2QlWVOd0gFAKHwwwOZGWBtYsnm23cCPPnmxMaxo2Dn/+8+0MKXq85RWHo0K5/PSIiIhJn/irY+EOoW2Nez/kcjF0Mrvz41tWTYmFoOQApZZA5Fmx9f/1cEREREen7gpEgH9Z8SL2/nrL07lnLdfWu1dz+2u0EIgGGZA5h2axllKaXdstz9VZVviqKUosozynHcjIjdEVERD6Dggoi/ZxhgM9nhhNqa82L12tuT042gwnduSzCBx+YIQWfDyZMgJ/9DFJSuu/5wJwUUVdnLi+Rmdm9zyUiIiI9yDCg8kX46D6IeMHqhIoboOwrJ7c+VaKJhc3lHlIGQuYYsGmNKxERERFJfNFYlE21m9jfvJ+StJIuP4FuGAa/e/93PLjmQQwMPlfyOe6deS+pjm7+RlUv0+BvwJXkYmTeSBw2R7zLERGRPkxBBZF+KBIxJyU0NZlTE5qawO+HpCRzkkFREdhs3V/He+/B975nhhQmTYLly81wRHerr4ecHBg4sPufS0RERHpIqBE+uheq/mlezxgNY++G1EHxrKrnxULQUgkpgyFzNOiDRRERERHpAwzDYFv9NnY27KQwpZAka9ee2ghHw9z75r08u/lZAL4y8ivcNOOmLn+e3i4QCeANeZlUPIlMV2a8yxERkT6uf/2WFenH/H4zkFBfD9XV5tSESATcbjOckJfXs/Vs2GCGFFpaYPJkM6Tg7oFlk8NhCARgzBhwaQKyiIhI33DwLXOph2AtWGww9GoYciX0sw8ViQbNZS/ShphBDas93hWJiIiIiHSJvZ69bK7bTI47B2dS104Mawo0ces/b2Vd5TqsFisLPreAi0df3O+WPIgZMap91ZRnl/e7pS5ERCQ++tkndyL9RywGzc1mOKGmxgwotLSYU49TUyE/35ygEA//+Q9cf70ZnpgyBX76054JDQQC5gSJgQPNqREiIiKS4CJ+2Pwz2Pt/5vWUQTDuh5AxKq5lxUU0AIFqSCuHjJEKKYiIiIhIn1Hjq+Gjgx+RYk8hxdG1a8buadrDDS/dwJ6mPSTbk1ly5hJOG3Balz5Hoqj2VpOfnM/wnOFYLdZ4lyMiIv2AggoifUgoZAYTGhuhstIMKoRC4HCY4YTs7Pgvz7xuHdxwgxkamDoVli3r/pCCYUBdHQSDMHw4DBsGVvXaIiIiia3xA3j/TmjZY14f+HUYPh9s/XBkUsQPgRpIG/ZJSEH/zBMRERGRvqEp0MQH1R8Qi8XITM7s0sded2Adt/zzFjxBD4WphSyftZzy7PIufY5E4Ql6sFltVORV4Erqh/+mEhGRuNAnWCIJzDDA5zODCbW15sl4r9fcnpwMWVng7NpJaCdlzRq48UYzMDB9Otx/f/eHFEIhc4pCejqMHWtOUoh3WENEREROQiwC238F2x8HYuAqgDGLIXdavCvreUYUws3mJX0EpFeA1RbvqkREREREuoQ/7OfDgx/iDXspSS3p0sd+bvNzLHljCZFYhDH5Y3jg7AfITc7t0udIFKFoiMZAI+MLxvfbYyAiIvGhoIJIgolEzKkJTU3mCfimJnMJBbvdnJpQVAS2Xvj59L//Dd//vhlSOPVU+PGPuz9E0dhoTpUYNMicopCa2r3PJyIiIt3MuwPeXwyej83rRefAqFvAnh7funqSETscTgCwp0HGaEgdopCCiIiIiPQZ4WiYjw5+RLW3mtL0Uixd9M2jmBHjoTUP8dv3fwvA2UPO5s4z7uy3UwQMw6DKW8WgzEEMzBwY73JERKSfUVBBJEFEIrB/P+zcCR4PRKPgdkNaGuTnx7u6z/b222ZIIRSCz38e7rvPXI6iu0QiZojD7YaJE6G0tHeGN0REROQEGTHY/QfY8hDEQmYwYdQiKDo73pX1DCMGER+EPebPSWmQVg6uPHBkgdUe7wpFRERERLpMzIixpW4Lu5t2U5xajNXSNWu4+sN+Fq9ezGu7XgPg6olXc+3ka7vs8RPRwZaDZLmyGJ4zHJuCzyIi0sMUVBDp5WIxqK6GHTugpsZc0qGgAJIS5G/vm2/CzTebIYXTT4d77+3ekEJzM9TXQ0kJjBgBmZnd91wiIiLSA/xV8MHdUL/WvJ473VzqwZUX37q6m2FA1Achj7nEQ1IKpAw0l7pwZIGtF63vJSIiIiLShXY17GJb/TYKUgqw27omlHvQd5AbX76Rj2s/xm61s/iMxcwun90lj52ovCEvMSPGyLyRpDhS4l2OiIj0QwlyqlOk/zEMqK01JyhUVppLOxQXJ05AAeBf/4JbboFwGL74RViyxHwd3eFQoMNqhbFjzeUeuuu5REREpAcYBlS+AB/9GCJesLlgxA1Q9mXoorGvvVKkxZycEAuBLQXcpeAuAGe2eQxERERERPqwA80H2FS7iXRnepctx/Bx7ccseHkBNb4aMl2ZPHD2A0wonNAlj52oIrEIdf46RueNpiC1IN7liIhIP5VApzxF+o/GRti1C/btM68XFCTeSffXX4dbbzWXYTjzTDOk0F0hi5YWOHjQXAKjogJyc7vneURERKSHhBrhw6VQvcq8njEGxv0QUgbEtaxuE/FDxAORgDk5wVUA7kJwZENScryrExERERHpNtFYFH/Ejz/sxxf2sbVuK0nWJNKd6V3y+Kt3reb2124nEAkwJHMIy2YtozS9tEseO5FVeasoSy9jSNaQeJciIiL9mIIKIr2I1wu7d8OePeZSCbm54EqwL84FAvDoo/C735nXZ86E//mf7gkpHJo6EQqZyzyUl4NTU5BFREQS28E3YeMPIVgHFhuUXwODrwBrH/unSzQA4WaItoDNDY4cyCgywwn21HhXJyIiIiLS5YKRIP6In5ZwCy2hFhqDjXiCHoKRIKFoiJgRI9meTG7yyX8LyTAMnvzgSX7+zs8xMPhcyee4d+a9pDr6d68diASobakl1ZHKiNwRXba0hoiISGf0sU/7RBJTIGBOT9ixA3w+yMkxpwMkklAI/vpXeOwxqKszt512WveFFIJBc6mHrCwYPx4KC/v2FGgREZE+L9ICm5fD3r+Y11MGwbh7IGNkPKvqWrEQhDzma7U5zFBCxkhwZEFSmpoZEREREekTjpyS4I/4aQ420+BvwB/xE4wECcfCWC1W7FY7riQX6c50nDYnli7qh8PRMPe+eS/Pbn4WgK+M/Ao3zbiJpL4Wfj4BhmG0/jcIRoM4k5zkJucyJGtIl02tEBER6az+95tZpBcJh+HAAdi+3VzuITMTBiTYRONIBFauhF/9CiorzW3FxXDttTB7NthsXf+c9fXmcg+DB8Pw4ZCsicgiInISHn74Ye6//36qqqoYP348Dz74IFOnTj3m/o2NjfzgBz/gL3/5C/X19QwcOJDly5dz7rnndvox+72G9+GDxdDyybpXA78Bw+eBLcFGS7UnFobwJ+EEaxLYMyF9+CeTE9IVThARERGRhHZoSoI/bE5KaAyYUxICkQChaAjDMLBarLiSXDiTnKQ707s1MNAUaOLWf97Kusp1WC1WFnxuARePvrjLQhCJIGbE8IV8NIeaicQi5pSKlFwKUwvJdGWS5kjrV8dDRER6LwUVROIgGoWqKnOCQm0tpKaaAYVE6g9jMXj1VXjkEXO5CjCXqrj6ajj/fLB3w9SwSMQ8bsnJMGkSlJSA1dr1zyMiIv3HM888w4IFC1ixYgXTpk1j+fLlzJo1i82bN5PfznijUCjE2WefTX5+Pv/3f/9HSUkJu3fvJjMzs9OP2a/FwrDtV7DjCSAGrgIYeyfkJHioIxaBSDOEvWCxgj0DMoaAK8f82aIGRkREREQSS8yItU5IaAm34A16aQw24gv5CEaCRIwIGOCwOVoDCV05JeFE7Gnaww0v3cCepj0k25NZcuYSThtwWo89fzxFYhG8IS/esBcMSLGnUJZRRl5yHpmuTFIcKfEuUURE5CgWwzCMeBfRFTweDxkZGTQ1NZGerpFF0jsZBhw8aAYUqqvB4TCXeeiOqQPdxTDgzTfhF7+ALVvMbRkZcMUV8NWvgqubvvjo8UBDA5SVwYgRoL/mIiL9W1f1ftOmTWPKlCk89NBDAMRiMcrKyvjud7/LwoULj9p/xYoV3H///Xz88cfYj5HK6+hjticuva1vL9Svh5Synnk+7w54/w7wbDavF8+GkbeAPa1nnr+rGVEIHwonWMxpCe4icOaaUxSsCdTwiYiISI/q659r9vXX1xeFoiFawi2twYRGfyNNwSaC0SDBSJCYEcNmseFMcuJKcuFKcsV9WYX1leu55ZVbaAo2UZhayPJZyynPLo9rTd0tFA3RHGymJdKCxWIhzZFGYUohOck5ZLgycCX1gQl1IiKScDrS+2migkgPqa83Jw/s3WtOASgshKQE+xu4fj08/DC8/755PSUFLrkELr3UnArRHaJRM9Rht8P48TBwYOIdNxER6Z1CoRDr169n0aJFrdusViszZ87k7bffbvc+zz33HNOnT2fevHk8++yz5OXlcckll3Drrbdis9k69Zj9jhGD3U/DlochFjInDIxeBIUz411ZxxkxiHjNpR0MwJ4KacPAlQeOLHOpBxERERGRXurIKQn+sJ/mYDONwUZaQi0Eo0FC0RAWLNhtdlxJLtIcaeS4c7D2sglhz21+jiVvLCESizAmfwwPnP0Aucm58S6rW/jDfrwhL/6IH4fNQZozjcFZg8lyZ5HhzMBu64YxtyIiIt1En5yJdDOPxwwo7NljLl2QlwdOZ7yr6pgPPzQnKLzzjnnd6YSvfQ3mzoUjJl13OZ/PXBqjqAiGDzenT4iIiHSV2tpaotEoBQUFbbYXFBTw8ccft3ufHTt28Oqrr3LppZeycuVKtm3bxnXXXUc4HObOO+/s1GMCBINBgsFg63WPx3MSr6wX81fBB3dB/Trzeu4MGLMYXAn0IaJhQMQH4SYzqJCUBqlDwflJOMHmiHeFIiIiIiJHCUVDbZZuaAo00RRsIhAJEIwEMTCwYGmdkJDqSO31J71jRoyH1z7Mb977DQBnDzmbO8+4s09NEjAMA1/YhzfkJRQN4UpykeXKoiKtgkxXJunO9F4XHBERETlRCiqIdJOWFnN6wq5d5s+5uZCcHO+qOmb7dlixAl57zbxus8GFF8I3v2kGLrpLLGYukRGLwahRMGSIuUyGiIhIvMViMfLz8/nlL3+JzWZj8uTJ7N+/n/vvv58777yz04+7dOlS7r777i6stJcxDDjwPGy63zzJb3PBiBug7MvmMgm9nWFA1Gcu7RANm5MTUgaCKx8c2WBLsBSqiIiIiPRZMSNGIBJoXbrBF/bR6G/EG/ISjAYJR8NgAbvVnJKQak/tlVMSjscf9rN49WJe22V+cHn1xKu5dvK1Cfc62hONRfGGvDSHmjEMg2RHMoWpheSn5JPpyiTVkYolEf4dJSIichwKKoh0sVAI9u2DnTuhqQmys82QQiLZtw8efRRefNH8XN5qhdmz4ZproLS0e587EDCXesjJgYoK+NQXUkVERLpMbm4uNpuN6urqNturq6spLCxs9z5FRUXY7XZsNlvrtpEjR1JVVUUoFOrUYwIsWrSIBQsWtF73eDyUlZV15mX1PqFG+PBHUP1J8jFjLIy7G1IGxLWsExJpMZd1iAXBlgKuEnAXmJMTktzxrk5ERERE+rlILIIv5GtduqEp2ERTwJySEIgGiMViWC1WXEkunDZnQkxJOBEHfQdZ8PICNtVuwm61s/iMxcwunx3vsk5KOBrGG/LiC/sASHWkMiRrCLnJuWS6MnHb9e8PERHpexRUEOkikQhUVZlTCOrrIS0NBgxIjC8JHlJTA//7v/DssxCNmtvOPBO+/W1zqkF3MgzzuPn9UF4Ow4aBW/23iIh0I4fDweTJk1m1ahUXXHABYE5MWLVqFfPnz2/3PqeeeipPPfWU+YGf1fymzpYtWygqKsLxyfifjj4mgNPpxJloa0OdiJo3YOM9EKoDiw3Kr4XBc8Hai/8ZEg2YyzpEgmYYwZUP7qJPwgkp8a5ORERERPqxQyezm0PNNPgbqPPX4Q/7j5qSkGJPIdud3SemC3zax7Ufs+DlBdT4ash0ZfLA2Q8woXBCvMvqlEAkgDfkpSXcQpI1iXRnOiMyRpDtzibTlYlDy8qJiEgf14s/IRRJDLGYeYJ/504zqJCcbE4dsCbQvwMaGuCJJ+BPfzInQgDMmAHf+Q6MHNn9zx8Om8cuLQ0mT4bi4sQ6fiIikrgWLFjA3LlzOeWUU5g6dSrLly/H5/Nx5ZVXAnD55ZdTUlLC0qVLAfjOd77DQw89xPXXX893v/tdtm7dypIlS/je9753wo/ZL0Ra4OOfwr6/mtdTh8DYH0JGRXzrOpZo0JycEPWbyzg4siGj2PzTnhrv6kRERESknwpFQ2YwIdhMvb+een89LeEWIrEIdqsdt91Ntju735zQXr1rNbe/djuBSIAhmUNYNmsZpendPP61CxmGgT/ipznYTDAaxJnkJN2RTnl2OVnuLDKcGdistuM/kIiISB+hoIJIJx2aALBrF+zfDzabeYI9KYH+Vnm98OST8NRT0NJibpswAebNg4kTe6aGxkbweMzpE8OHm2EFERGRnnLxxRdz8OBBFi9eTFVVFRMmTODFF1+k4JO1h/bs2dM6OQGgrKyMl156iRtvvJFx48ZRUlLC9ddfz6233nrCj9nnNbwHH9wJLfvM6wMvgeHXgc0V37o+LRYywwnhFrA5zIkJ6RXgzIaktMQaiyUiIiIifUIwEqQ51Iw35KW2pZamQBO+sI9YLIbdZifZnkx+Sj5JvXlCWTcwDIMnP3iSn7/zcwwMPlfyOe6deS+pjt4fKo4ZMXwhH82hZiKxCMn2ZHJTcilIKSDTlUm6Mx2L/u0hIiL9lMUwDCPeRXQFj8dDRkYGTU1NpKenx7sc6eOamsyAwr595hIJeXngSKDgst8PzzwDv/2tGRIAqKiA666D6dN75nP5SASqq8HpNAMKAwaYYQ8REZET0dd7v7i8Pt9eqF8PKWWdu38sDNt+CTt+A8TAVQBj74KcKV1Z5cmLBiBQA1Y72DPAXQzOHLCnQx8cjSsiIiK9n3rb/isQCdAcNIMJB1sO0hRooiXSgmEY2K12UuwpuO3ufhdMOFI4GubeN+/l2c3PAvCVkV/hphk39epjEolF8Ia8eMNeMCDFnkJuSi55yXlkujJJcWhJORER6bs60vv13t/mIr2Qzwd795ohhUAAcnPB7Y53VScuFIK//hUeewzq6sxtgwfDt78NZ57Zc18c9HrN5y8uhhEjICurZ55XREREuknzNnh/MTRvMa8XnwsjbwZ7LxuVFAubIYXUYZBcDI5MhRNEREREpEccGvvvDXnxBDzU+mvxBD34w34Mw8Bhc5DiSNH4/yM0BZq49Z+3sq5yHVaLlQWfW8DFoy/ulRMIIrFIa9DEYrGQ5khjWNYwcpJzyHBl4ErqZRPmREREegEFFUROQDBoTk/YuROamyE725yikCgiEVi5En71K6isNLeVlMA118Ds2T03ySAWg5oa8+fRo2HIELDbe+a5RUREpBsYMdj1FGz9hbmUgj0DRt8GhWfFu7KjGTHwV0LyAMiogF78DSwRERERSXyGYdASbjGDCUEPB1sO0hxqxh/ygwVcNhduu5ssVxZWhWePsqdpDze8dAN7mvaQbE9myZlLOG3AafEu6yjRWJSGQAO+sI9sdzaDswaT5c4iw5mB3aYPPkVERD6LPp0T+QzhsHlif8cOqK+HjAwoK0ucJYtjMVi1ClasgN27zW25uXD11XD++T0bEggEzKUe8vLMZSYSKeghIiIi7fBXwgd3mctFAOSdCqPvAFduXMs6Jn8lOPMgY6RCCiIiIiLS5QzDwBf20RxsNoMJvoP4wj78ET8Y4La7cSe5yU7PVjDhONZXrueWV26hKdhEYWohy2ctpzy7PN5ltREzYjT4G/CGveS4cxiZN5Ki1CKFE0RERDpAn9CJtCMWM0+q79hhTgBITjYDCtYE+TeEYcCbb8IvfgFbPpnAnJEBV1wBX/0quHpw0phhmMs8BIMwbJh56cnnFxERkS5mGHDgedh0P0R8YHNDxY1QemHvTXMGa8GWDJmjISk53tWIiIiISB8QM2L4Qj6aQ4eDCd6Ql2AkiMViwZXkIsWeQo47p1cuVdBbPbf5OZa8sYRILMKY/DE8cPYD5Cb3njB0zIjRGGjEG/KS5cpicu5kitKKcNgc8S5NREQk4SioIHIEw4DaWnOJh8pKc+JAcTEkJdDflPXr4eGH4f33zespKXDppXDJJZCa2rO1hEJQVWWGJMaOhaKi3nv+QkRERE5AqAE+XALVr5nXM8fB2LshpSy+dX2WcDPEIpA9DhxZ8a5GRERERBJUNBZtnZjQFGjiYIs5MSEUDWGxWHDb3KQ703EmOxVM6ITGQCO/ee83/O793wFw9pCzufOMO3El9Y5vPBmGQWOgEU/IQ5Yri4lFEylKLcKZ5Ix3aSIiIgkrgU6/inSvhgZzeYR9+8zrBQU9uzTCyfrwQ3OCwjvvmNedTvja12DuXMjM7Pl6PB5oaoJBg2D4cDMwISIiIgms5l+w8X8gVAcWG5R/CwZf3ruXUYgGINQImWPBXRTvakREREQkgURiEbwhL96QlwZ/A7UttbSEWwhFQ1gtVlLsKWQ4M3rNifRE0xJu4T+V/2HdgXWsObCGLXVbWm+7euLVXDv52l6xRIZhGDQFm2gKNpHhzGBCwQRK0ksUUBAREekCvfhTRZGe4fWaAYU9e8wJALm5ibU0wbZtsGIFrF5tXrfZ4KKL4KqrIC+v5+sxDDh40Fw+Y/RoGDo0cZbMEBERkXZEfPDxT2Hf38zrqUNg3A8hvSKuZR1XLAKBakgth9TB8a5GRERERHq5cDTcGkyo99dT56/DH/YTioawWWykOFLIcmXpBHUnhaIhPqj5wAwm7F/DxpqNRI1om32GZg3lmxO/yZeGfilOVR726YDC+ILxlKSXKJgiIiLShRRUkH4rEIC9e81lHnw+yMmB/Px4V3Xi9u2DRx+FF180wwFWK8yeDddcA6Wl8akpHDaXesjMhJEjzakUIiIiksAaNsD7d4J/v3l94CUwfB7YevmHs4YB/kpwl5iBil7wTSwRERER6V1C0RDekJfmYDMNgQbqWsxgQjgWxm6147a7yXHnYLcl0MjVXiQai7K5bjNrD6xl7f61vFv1LsFosM0+JWklTCmewpSSKZxSdAo5yTlxqvYwwzDwBD00BhtJd6QzLn8cJekluO3ueJcmIiLS5yioIP2KYYDfb37jf/t2aGw0T6oPGBDvyk5cdTX8+tfw7LMQ/SR0fOaZ8O1vw5Ah8avL64X6evNYjhgBqanxq0VEREROUiwMWx+Fnb8FYuAqgLF3Q84p8a7sxASqwZEFGaPB5oh3NSIiIiLSCwQjQTOYEGqmrqWOxkAjvrCPaCyKw+bAneQmLyWPpN68tFkvZhgGu5t2s2b/GtYeWMv6yvV4gp42++S4czil+BSmFE9haslUitOK41Rt+zxBDw2BBtIcaYzNH0tJegnJ9uR4lyUiItJnqeuSPi8QAI/HvBw8aP7p80FamnlS3WKJd4UnpqUFfv5zeO45c4kKgBkz4DvfMacXxMuRSz2MGQODB0OS/s8iIiKSuJq3wfuLofmTNWKLz4ORN4M9QVKIoQawJJkhhUSpWURERES6XCASoDnYjDfk5WDLQTwBD76ID8MwsFvtpNhTKEgpUDDhJFR5q1h7YC1r9q9h3YF1HGw52Ob2FHsKk4snM7V4KlOKpzAkawiWXvhhbHOwmfpAPamOVEbnjaY0vZQUR0q8yxIREenz1IVJnxMKmWGE5mbzBHpjozlFwTDA5YKUFHOZh17YE7fLMMzlHX7+c/P1AIwfD/Pnw8SJ8a1NSz2IiIj0IUYU9v0Ndj0FRhjsGTD6Nig8K96VnbiIDyItkDURXLnxrkZERERE4uRA8wE+qvkIX9gMJjhsDlIcKRQ5i7BZbfEuL2E1BhpZd2Bd69SEvZ69bW532pyMLxjPlJIpTCmeQkVuRa8OgnhDXur99SQ7khmVN4rS9FJSHQo7i4iI9JTe2yWInKBI5HAwoa7OXH7A5zO/4e90msGErCywJuDSxJs2wf33w/vvm9dLSsyAwsyZ8Q9aHLnUQ0WFeZxFREQkQXl3wZtfh7p3zOt5p8KYO8CZQCf7YyEI1kH6SEgujXc1IiIiIhJH4WgYT8hDaVqpggknoSXcwn8q/8PaA2tZu38tW+q3tLndZrExKm8UU4rNYMK4gnE4k5xxqvbEtQYU7MmMyBlBWUYZac60eJclIiLS7yioIAknGjVDCc3N5ony2lpzWYRIBBwO84R5YWFiLz9QXw+/+AU8++zhSRBXXQWXXmqGL+LJMKCmxvxTSz2IiIj0ER8vM0MKVheMXAClF8Y/FdkRRhRaKiFlMKSVJ1btIiIiItItrFgVUuigUDTEBzUfsHb/WtYcWMOHNR8SNaJt9inPLm8NJkwqmpRQEwh8IR/1gXpcSS6G5wxnQMYABRRERETiSKcXpdeLxcxv7zc3Q0ODufxBS4u5xIPdDsnJkJ/fN06WRyLwzDPwq1+ZrxngnHPgu9/tHcsqhMNQWWlOqNBSDyIiIn3I+CXQshcKvwS5U+NdTcf5K8FdCJkjoRePlhURERER6U2isSib6za3LuWwoWoDwWiwzT4laSVmMKFkCqcUnUJOck6cqu28lnALdS11OJOclGeVMyBzAOnO9HiXJSIi0u/pUzzpdQzDXLqhuRmamqC62rweDILNZk5MyM42pyf0JW+/DT/5CezaZV6vqICbboIJE+JZ1WFa6kFERKQPs6fC5J9D/fp4V9JxgYNgS4WM0WBzxbsaEREREZFeyzAMdjXuYs2BNaw7sI51B9bRHGpus0+OO4dTik9hSvEUppZMpTitOE7Vnjx/2E+dvw67zc7Q7KEMyBhAhisj3mWJiIjIJxRUkF6hpcUMJng8ZjDB64VAwJzam5wMGRnm8gd90d69sGwZ/Otf5vWsLJg3D+bMMYMZ8aalHkRERKTXCnvMZR+yJoBDHziKiIiIiHxalbeqdWLC2gNrqW2pbXN7ij2FycWTmVo8lSnFUxiSNQRLgi+ldiigkGRNYlDmIAZmDiTTlRnvskRERORTdLpR4iIQMIMJzc3mSfCmJnMbmIGE1FTIze3bywu3tMBjj8Hvf28uqWCzwde+BtdeC2m9ZGk0LfUgIiIivVY0ACEPZI41l30QEREREREa/A2sO7CudWrCXs/eNrc7bU7GF4xnSskUphRPoSK3gqQ+snxaIBKg1l9LkiWJgZkDGZgxkCx3VrzLEhERkWPoGx1InPj9UFdnfrv8WBcxhUKHgwkHD0Jjo3mi3jDMYEJysrmcg9Ua70q7XywGL7wADz4ItZ8EmD/3Ofj+981pBb2FlnoQERGRXisWAX81pI+A1EHxrkZEREREJG58IR/vVr1rTkzYv5Yt9Vva3G6z2BiVN4opxWYwYVzBOJxJzjhV2z0CkQB1/jqsWBmQPoCBmQPJcmUl/GQIERGRvk6n0k9CfT2sX2+ebAfzG/FJSeafh352Os2Ly2X+2V6YwW4//HNf6Z0ikcPBhLo681j5fOZJeofDPOmdkdE7ljboSR9+CA88AB98YF4vKYEFC+D003vPf3st9SAiIiK9mmGA/wCklEH6cLD0g6SriIiIiMgRGgONvLz9ZV7e/jIf1HxA1Ii2ub08u7w1mDCpaBKpjtQ4Vdq9gpEgdf46AErSShiUOYhsd7YCCiIiIglCpx9PkmFAWZn5ZzR6+BKJmGPzAwHz52jUPElvsRwONlitbcMNSUnmSfwjww2fDjJ8+tJbTvRHo+Y38A8FE+rqzIkJ4bD5mpKTzWUD+usJ77o6ePhh+Pvfzf/+bjdcdRVccon537q30FIPIiIi0uv5K8GRDRmjwGqPdzUiIiIiIj0iEAnwr93/YuW2lby196024YSStBIzmFAyhVOKTiEnOSeOlXa/UDREbUstBgYlaSUMzBxIjjtHAQUREZEE009PG3c9i6Xjyz0cGWw4FG7wes1lEQ5ta+85Dk1sOBRucLkOXz4damgv5NAVYjFzQkJzMzQ0mEsYeL3mEg9JSWYwITfXfP7+LByGZ56BX/3KPF4As2fDd78L+fnxre3TtNSDiIiI9HrBerA6IXMMJKlZEREREZG+LWbE+E/lf1i5dSWrdq7CF/a13laRW8G55edyxsAzKEkviWOVPScUDVHXUkeMGEWpRQzKHERucq4CCiIiIglKQYU4OhQ2OFGHpjZEIoenNASD5uSCQ9sP7ffp5zgUajhyOYpDl8+a2GC3H54C0dJiBhMaG+HgQfPEdiBgPnZyMmRnm9MTxPTmm7BsGezebV4fORJuvhnGjYtvXZ+mpR5EREQkIUS8EA1A9kRw9u1viImIiIhI/7a9fjsvbHuBF7a9QLWvunV7YWohs8tnM7t8NkOyhsSxwp4Vjoap89cRiUUoTC1kcNZgcpNzsWoZOBERkYSm05EJpDNTGw4FGo6c2vDp5SiOfHyLpe1yFDabGT4wDHMiQEuLuWSF2w3p6b1vKkBvsGcP/PSn8K9/mdezs2HePJgzxzx2vYmWehAREZGEEA1CoN6cpODuH98WExEREZH+pballhe3vcjKbSvZUreldXuqI5WZg2cye9hsJhZO7Fcn5yOxCLUttURiEQpSCxiUOYj8lPx+dQxERET6sk4FFR5++GHuv/9+qqqqGD9+PA8++CBTp0495v7Lly/nkUceYc+ePeTm5vKVr3yFpUuX4nK5AIhGo9x11108+eSTVFVVUVxczBVXXMHtt9+usU0nqaPBhlisbbghEjEDCoZhLgWQk2OGGeRoPh/8+tfw1FPmcbPZ4Otfh2uugdTUeFd3NC31ICIiIgnBiIK/CtKGQOoQNaMiIiIi0me0hFt4bddrvLD1BdYcWEPMML9VZrPYOHXAqZxbfi6fH/B5nEnOOFfasyKxCHUtdYRjYfJT8hmcNZi85Dxs1g6MJxYREZFer8NBhWeeeYYFCxawYsUKpk2bxvLly5k1axabN28mv52v1z/11FMsXLiQxx57jBkzZrBlyxauuOIKLBYLy5YtA+C+++7jkUce4Te/+Q2jR49m3bp1XHnllWRkZPC9733v5F+lnDCrVcs3dFQsBitXwoMPQl2duW3GDFiwAAYNimtp7dJSDyIiIpIwDANaKsFdBOkjQR9MioiIiEiCi8QirN2/lpXbVvLartcIRAKtt43LH8fsYbM5e8jZZLoy41dknERiEer99QSjQTOgkDmY/JR8BRRERET6qA6fnly2bBnXXHMNV155JQArVqzg+eef57HHHmPhwoVH7f/WW29x6qmncskllwAwaNAgvvGNb/DOO++02ef888/nvPPOa93n6aefZs2aNZ16USI9ZeNGeOAB80+A0lL4/vfhtNN655f9tNSDiIiIJJRgDdjTIHM02PrXt8hEREREpO8wDIPNdZtZuXUlL21/iTp/XettZellzC6fzbnDzqU0vTSOVcZHJBahOdiML+zDYrGQ485hcJYZUEiy6ttVIiIifVmHftOHQiHWr1/PokWLWrdZrVZmzpzJ22+/3e59ZsyYwZNPPsmaNWuYOnUqO3bsYOXKlVx22WVt9vnlL3/Jli1bGD58OO+99x5vvPFG68QFkd6mthYefhj+/nfzenIyXHUVXHJJ751IoaUeREREJKGEGgELZI4Be3q8qxERERER6bDK5kpe3P4iL2x9gR2NO1q3Zzgz+NLQL3Fu+bmMyR/T75Y/jsQieENemoPNWKwWMp2ZVGRUkJOcQ5YrSxMURERE+okOBRVqa2uJRqMUfOpr2AUFBXz88cft3ueSSy6htraW0047DcMwiEQifPvb3+a2225r3WfhwoV4PB4qKiqw2WxEo1F+9KMfcemllx6zlmAwSDAYbL3u8Xg68lJEOiUchqefhl//Gnw+c9t558H8+ZCXF9/ajkVLPYiIiEjCifgh7IXsCeA6enk5EREREZHeqjnYzKqdq1i5bSX/qfxP63aHzcHpA07n3GHnMr10OnabPY5V9rxoLEpzqBlvyAtAujOdirwKcpNzyXRlanqCiIhIP9Ttv/1Xr17NkiVL+MUvfsG0adPYtm0b119/Pffccw933HEHAH/84x/5/e9/z1NPPcXo0aPZsGEDN9xwA8XFxcydO7fdx126dCl33313d5cv0uqNN2DZMtizx7w+ahTcfDOMHRvfuj6LlnoQERGRhBMLQ6AG0isgeUC8qxEREREROa5wNMxb+95i5daV/GvPvwhFQ623TS6azOzy2cwcMpNUR2ocq+x50VjUnJwQagYgzZnGsOxh5KXkkenK7HdhDREREWmrQ0GF3NxcbDYb1dXVbbZXV1dTWFjY7n3uuOMOLrvsMq6++moAxo4di8/n49prr+UHP/gBVquVm2++mYULF/L1r3+9dZ/du3ezdOnSYwYVFi1axIIFC1qvezweysrKOvJyRE7I7t1mQOHNN83rOTkwbx78v/8HVmt8a/ssXi/U1cHAgVrqQURERBKEEQN/JaQMhPRh0M9G4IqIiIhI4jAMgw9qPuCFbS/w8vaXaQo2td42JHMI5w47l3PKz6Ewtf3PzfuqmBGjOdhMc7gZDEh1pDIsexi5KblkubIUThAREZFWHQoqOBwOJk+ezKpVq7jgggsAiMVirFq1ivnz57d7n5aWFqyfOptrs5lrTBmG8Zn7xGKxY9bidDpxOp0dKV+kQ7xec4mHp5+GSMRcLuEb34BvfhNSe3H4+cilHsaO1VIPIiIikkD8VeDMg4yRYNUHmCIiIiLS++xt2svKbSt5YdsL7PPsa92e487hnPJzmF0+mxE5I7D0o9BtzIi1Tk4wDINURypDs4aSl5xHljsLh80R7xJFRESkF+rw6csFCxYwd+5cTjnlFKZOncry5cvx+XxceeWVAFx++eWUlJSwdOlSAObMmcOyZcuYOHFi69IPd9xxB3PmzGkNLMyZM4cf/ehHDBgwgNGjR/Puu++ybNkyrrrqqi58qSInJhaD55+Hhx4yJxIAnHoqLFhgTifozbTUg4iIiCSsYC3YXJA5GpKS412NiIiISJ/18MMPc//991NVVcX48eN58MEHmTp1arv7/uUvf2HJkiVs27aNcDjMsGHD+P73v89ll13Ww1XHV2OgkZe3v8wL217gg5oPWre7klx8cdAXOW/YeZxSfApJ1v7zbaGYEcMX8uEJeogRI9WeyuDMweSl5JHlysKZpC8ZioiIyGfrcOd08cUXc/DgQRYvXkxVVRUTJkzgxRdfpOCTM6J79uxpMx3h9ttvx2KxcPvtt7N//37y8vJagwmHPPjgg9xxxx1cd9111NTUUFxczLe+9S0WL17cBS9R5MRt3Aj33w8ffmheHzDADCicdlp86zoRWupBREREEla4GWJhyJoEjqx4VyMiIiLSZz3zzDMsWLCAFStWMG3aNJYvX86sWbPYvHkz+fn5R+2fnZ3ND37wAyoqKnA4HPzjH//gyiuvJD8/n1mzZsXhFfScQCTAG3ve4Pmtz/PW3reIGlEArBYr00qmMbt8Nl8Y9AWS7f0nZGsYBr6wGU6IxqKkOFIYmDmQ/JR8stxZuJJc8S5RREREEojFOLT+QoLzeDxkZGTQ1NREenp6jzzn/v2wdi2UlfXI00k3qq2FBx80JymAeZL/m980l3qw9/Kpw0cu9TB8uJZ6EBGR/iEevV9Pisvr8+2F+vWQ0sPNbTQAgRrIGAvp5T373CIiIiK9QE/2ftOmTWPKlCk89NBDgLmsb1lZGd/97ndZuHDhCT3GpEmTOO+887jnnntOaP949La7G3fzbuW7lGV0rLeNGTH+U/kfXtj2Av/c8U98YV/rbSNyRnDusHOZNXQWucm5XV1yr3VkOCESi5DqSCUvJY/8lHyy3dkKJ4iIiEgbHen9dDpT+rVQCJ56Ch57DFpazG1z5sC8eZCbAP/e0FIPIiIiktBiEQhUQ2o5pA2JdzUiIiIifVooFGL9+vUsWrSodZvVamXmzJm8/fbbx72/YRi8+uqrbN68mfvuu++Y+wWDQYLBYOt1j8dzcoX3gB0NO1i5dSUvbHuBal916/aClALOHXYu5ww9h6HZQ+NYYc8yDIOWcAueoIdwLEyKI4XS9FIKUgvIcmXhtrvjXaKIiIj0AQoqSL9kGPDGG7BsGezda24bPRpuvhnGjIlvbSdKSz2IiIhIQjMM8FeCuwTSK8BiPf59RERERKTTamtriUajrUv4HlJQUMDHH398zPs1NTVRUlJCMBjEZrPxi1/8grPPPvuY+y9dupS77767y+ruLrUttby0/SVWbl3J5rrNrdtT7CnMHDKTc4edy8TCiVj7UZ96KJwQjAZJcaRQlFZEYWohWe6sfrXEhYiIiPQMBRWk39m5E376U3jrLfN6Tg5897tw7rlgTYB/dxy51MO4cTBokJZ6EBERkQQUqAZHFmSMBpsj3tWIiIiIyDGkpaWxYcMGvF4vq1atYsGCBQwZMoQvfOEL7e6/aNEiFixY0Hrd4/FQ1kvWzm0Jt7B612pWbl3JmgNriBkxAGwWG6cOOJVzy8/ltAGn9avlDA6FE0LREMn2ZApSC8xwgiuLFIe+GSUiIiLdR6c3O6mqCl57DZqazHH7Dn222qscOpm/c+fhy65dsGMHNDaa+yQlwSWXwDe/mTjTCEIh872XnW1OUdBSDyIiIpKQQg1gsZkhBXtqvKsRERER6Rdyc3Ox2WxUV1e32V5dXU1hYeEx72e1WikvLwdgwoQJbNq0iaVLlx4zqOB0OnE6nV1W98mKxCKs3b+WldtWsnrXavwRf+ttY/PHcu6wczl7yNlkujLjV2QP84f9rZMT3HY3eSl5FKUWkeXOItWh/lxERER6hoIKnfTqq3DZZebPFgvk5UFxsXkpKTEvh67n5YHNFt96+6poFA4cMIMIO3aYYYRDoQSfr/37WCxw2mlw440wYEBPVtt5hgH19dDSYtaspR5EREQkYUVazEvWBHDlxrsaERERkX7D4XAwefJkVq1axQUXXABALBZj1apVzJ8//4QfJxaLEQwGu6nKrmEYBjsadvCnj/7ES9tfos5f13pbaXops8tnc275uZRl9I5JDz0hEAngCXoIRAK4klzkJOdQlFZElssMJ1gslniXKCIiIv2MggqdlJQEI0bA7t0QCJjf3q+pgQ0b2t+3qKhteOHQzyUlkJFhnjyXYwuFYM+ew0GEQ6GE3bvN29pjs0FZGQwe3PYycCC43T1Z/cnx+833VmYmTJ5svm8UfBEREZGEFAtDsBbSR0Jy//lQWERERKS3WLBgAXPnzuWUU05h6tSpLF++HJ/Px5VXXgnA5ZdfTklJCUuXLgVg6dKlnHLKKQwdOpRgMMjKlSv53e9+xyOPPBLPl/GZfvfe77jn/7uHrfVbW7dlODP40tAvMbt8NmPzx/abk/KBSIDmYDMtkRZcSS6y3dkUpRaR7c5WOEFERETiTkGFTvra1+DUU2HNGkhNNb/Vv3+/+eehn/fvN8f0RyKwd695aU9KyuEAQ3sTGRLppPrJamlpOxVhxw7z5/37zekJ7XE6zfDBpwMJZWVgt/dk9V0rGoWDB81pCsOHw5AhkJwc76pEREREOsmIQcsBSBkMaeVK6oqIiIjEwcUXX8zBgwdZvHgxVVVVTJgwgRdffJGCT9YX3bNnD1artXV/n8/Hddddx759+3C73VRUVPDkk09y8cUXx+slHFdtSy1b67dit9o5feDpnDvsXGaUzsBuS+APCjsgGAnSHGrGF/bhtDnJdmdTkVZBtjubNEeawgkiIiLSa1gMwzDiXURX8Hg8ZGRk0NTURHp6eo885/79sHateUL8WCIR82TzoRDDp/+srT3+82RnHzvEUFhoTmxINI2NhwMJR16qqo59n5QU82T9oEFmEOHQz0VFfW/CQFOTeSkogPJyc/kQ/RtCRETksHj0fj0pLq/Ptxfq10NKN006aNkHjlzIngRJ/SiJKyIiInIc6m27VrW3mic2PEFpWikVeRXd/ny9QSgawhP00BJuwWFzkOXOojitmCxXFunOdIUTREREpMd0pPdLwFPcieXQsg9FRe3fHgiYJ+f37Ws7jeHQn14v1Nebl40bj76/zWaezP70RIZDf+bkxO8Et2GYQYxDUxEOTUjYtct8PceSnX14KsKgQWYgYfBgyM3t+yfrQyFzmQeXC8aNgwEDEnsqhIiIiAgAgYNgS4XMMQopiIiIiEi3Kkgt4Otjvs67le/Gu5RuZRgGTcEmPEEPDpuDDGcGw3OGk+U2wwlWi/X4DyIiIiISRwoqxJnLZZ6MHzSo/ds9nmMvK1FZaZ7YPrS9PU7nsZeVKCkxl604WdGoWcunpyPs3Ak+37HvV1h49HINgwZBZubJ15RoDAPq6szgSmmpOUUhIyPeVYmIiIh0gbAHjChkTQCHGhwRERERkZMRM2I0+Bvwhr1kODMYmz+WnOQcMlwZCieIiIhIQlFQoZdLTzcvFe1MKYvFzJPbx1pWoqYGgsHDoYFjPf6xlpUoKjKDDoeEw7B37+GpCIced/du83naY7WaJ96PXKrhUCAhOfkkD04f0dJiLg+SlQWjR5vH3qp/U4iIiEhfEA1AyAOZY8FdGO9qREREREQSVjQWpSHQQEu4hSxXFpNyJ1GYWogryRXv0kREREQ6RUGFBGa1Ql6eeZkw4ejbw2Gorj72shKNjebEBo8HPv64/efIyzMDCx6PGVKIRtvfz+GAgQMPBxEOhRIGDDBvk6NFImZAwWKBESPMY+bWJGQRERHpK2IR8FdD2jBIHRTvakREREREElIkFqHeX08wEiQ7OZuReSMpTC3EYdOHriIiIpLYFFTow+x2c5pBaWn7t7e0HL2sxJGhBr/fPJF+8ODh+yQnmwGEQ0GEIUPMYEJxMdhsPfGq+obGRmhqMkMg5eVmIERERESkzzAM8FdCShmkjwCNoBURERER6ZBwNEydv45ILEJuci6DCgaRn5KP3WaPd2kiIiIiXUJBhX4sOdk8SV5efvRthmGeTN+/HyorIS3NDCTk55sTAKRzgkFzSY7kZHMKRlmZGSgRERER6VMCVeDIgoxRoG96iYiIiIicsGAkSL2/nqgRpSC1gIEZA8lPycdm1bfEREREpG9RUEHaZbFAVpZ5GTMm3tUkPsOAujoIBMwlMoYOhfT0eFclIiIi0g2C9WCxQ+YYSEqJdzUiIiIiIgkhEAlQ56/DgoXC1EIGZAwgLyUPq6aTiYiISB+loIJIN/P5oLYWsrPN0EdREVj17wsRERHpiyJeiPohexI4c+JdjYiIiIhIr+cP+6nz15FkTaI0vZSy9DJyknMUUBAREZE+T0EFkW4SiZjLPFitUFFhLp3hdse7KhEREZFuEgtBoB4yR4G7JN7ViIiIiIj0at6QlwZ/A44kBwMzB1KWXka2OxuL1t0VERGRfkJBBZFu0NgIHg8UFsKwYZCbG++KRERERLqREYWWSkgbAqnl5jpiIiIiIiJylOZgMw2BBtx2N0Ozh1KWUUamKzPeZYmIiIj0OAUVRLpQMAjV1ZCaChMmQFkZJOlvmYiIiPRlhmGGFNxFkF4BVlu8KxIRERER6VUMw8AT9NAUbCLFkcKInBGUZpSS7kyPd2kiIiIicaNTqCJdIBaDujozqDBoEJSXQ1pavKsSERER6QHBGrCnQeZosLniXY2IiIiISK9hGAZNwSaagk2kO9IZnT+a4rRiUh2p8S5NREREJO4UVBA5SV6vGVLIyYFx48zlHqzWeFclIiIi0gNCjeafmWPArm+DiYiIiIgAxIwYjYFGmkPNZDgzGF8wnqK0IpLtyfEuTURERKTXUFBBpJMiEaipAZsNRo0yJym49CVCERER6S8ifgh7IWs8uPLjXY2IiIiISNxFY1EaAg20hFvIcmUxqWgShamFuJL0oaGIiIjIpymoINIJjY3g8UBREQwbZk5TEBEREek3YhEI1ED6CEgZGO9qRERERETiKhKLUO+vJxgJkuXOYmTeSApTC3HYHPEuTURERKTXUlBBpAMCATh4EFJTYeJEKC2FJP0tEhERkf7EiIF/vxlQSB8OFku8KxIRERERiYtwNEydv45ILEJuci4DCwZSkFKA3WaPd2kiIiIivZ5OsYqcgFgMamshHDaXeBg6FNLS4l2ViIiISBz4q8CZBxkjwaoPYEVERESk/wlFQ9S11BE1ouSn5jMoYxB5KXkkWfVxu4iIiMiJUud0kgzDvOiLZH2X12uGFHJzYfhwKCzUf28RERHpp4K1YHNB5hhISo53NSIiIiIiPSoQCVDnr8OChcLUQgZkDCA3OReb1Rbv0kREREQSjoIKJ8FqheRk2LfPDCskJYHTaV5cLi0JkOgiEaiuBrsdxowxJyk4nfGuSkRERCROwl6IhSFrEjiy4l2NiIiIiEiP8Yf91PnrSLImUZJWwoCMAeQk52C1WONdmoiIiEjC0qn0k1BYCKmp4Pebl+ZmaGw8/HMkYu5nt5vBhUMhBqv6117NMMz/js3NUFwMw4ZBdna8qxIRERGJo2gQQg2QMQaSi+NdjYiIiIhIj/CGvDT4G3AkORiYOZCy9DKy3dlYNG5VRERE5KQpqHASLBZISzMvRwoGD4cX/H5oajIvPh/U1UEsZoYVjgwvOBzxeQ3SViAANTWQng6TJkFpKdg0uU1ERET6s1gEAlWQWg6pg+NdjYiIiIhIt2sONtMQaMBtdzM0eyhlGWVkujLjXZaIiIhIn6KgQjc4FD7IzDy8LRYzT4K3tJjhBZ/P/Na+zwf19RAOm/sduXyE06nlI3pKLAYHD0I0CkOHwpAh5rQMERERkX7NMMBfCe5iSB8BWntXRERERPoowzDwBD00BZtIdiQzImcEpRmlpDvT412aiIiISJ+k0+A9xGqF5GTzcqRwuO30BY/HDDAEAuaf0ag5ueHI8ILTaW6TruH1mpMu8vLMZR4KCnR8RURERAAIVIMjEzJGg80Z72pERERERLqcYRg0BZtoCjaR7khnVN4oStJLSHXoW0wiIiIi3cka7wL6O7vdXGagoAAGDYJx4+Dzn4fTT4fTToOpU2H0aMjNNff3eGD/fti71/yzttY80X5oIoOcuHAY9u0zAyKjR5vHurBQIQUREZH+5uGHH2bQoEG4XC6mTZvGmjVrjrnvE088gcViaXNxuVxt9rniiiuO2uecc87p7pfR9UKNYLGZIQV72nF3FxERERFJJDEjRr2/nj2ePQCMLxjPjAEzGJE7QiEFERERkR6giQq9kMUCLpd5OVI02nb6gtdrTl1oaYHmZvPEu8Vihh9crsPTF6yKo7SKxcyLx2Mev9JSKC+HrKx4VyYiIiLx8Mwzz7BgwQJWrFjBtGnTWL58ObNmzWLz5s3k5+e3e5/09HQ2b97cet3STsrxnHPO4fHHH2+97nQm2DSCSAuEvZA9EVx58a5GRERERKTLRGNRGgINtIRbyHJlMaloEoWphbiSXMe/s4iIiIh0GQUVEojNBqmp5uVIoZAZVjgUYGhqMi8+n7mkgWEcvXyEw5GYkwMMwwxsRKNm4ODIPw/9HItBJGLuC+brPPLnpCQzyDF5MpSUmMdVRERE+qdly5ZxzTXXcOWVVwKwYsUKnn/+eR577DEWLlzY7n0sFguFhYWf+bhOp/O4+/RasTAED0L6KEgui3c1IiIiIiJdIhKLUO+vJxgJkuXOYmTeSApTC3HYHPEuTURERKRfUlChD3A4zEtm5uFtsRgEAofDCz6fOX3h0BSGUMg8eW+3tw0wJHXzO+JQ0ODIQMGhnz8dOjgULjj0J5hBA5vNnBJhsx3+2W6HlBTzONjth4/JoX0OXZKSzD+dzqMnVoiIiEj/EgqFWL9+PYsWLWrdZrVamTlzJm+//fYx7+f1ehk4cCCxWIxJkyaxZMkSRo8e3Waf1atXk5+fT1ZWFmeeeSb/8z//Q05OzjEfMxgMEgwGW697PJ6TeGUnIwYtByBlMKSVJ2ayVURERETkCOFomDp/HZFYhNzkXAYWDKQgpQC7zR7v0kRERET6NQUV+iirFZKTzcuRIhEzuHBoAoPHY05fODSJIRo193M4Dp/Mdzrbfkbd3hSDY005+DSLxazNajVDA4d+ttnA7W4bMjgyaHAoYHCs65qKICIiIh1VW1tLNBqloKCgzfaCggI+/vjjdu8zYsQIHnvsMcaNG0dTUxMPPPAAM2bM4MMPP6S0tBQwl3246KKLGDx4MNu3b+e2225j9uzZvP3229iO0bQsXbqUu+++u2tfYGfEwuAuhYwKsOqfCiIiIiKSuKJGlMrmSqJGlPzUfAZlDCIvJY8k9bkiIiIivYK6sn4mKQnS0szLIYYBweDh6QstLWZoweOB5maorW071eDT0wwO/ex0Hp7QcGTQ4Hghg0OBBX1hT0RERHq76dOnM3369NbrM2bMYOTIkTz66KPcc889AHz9619vvX3s2LGMGzeOoUOHsnr1as4666x2H3fRokUsWLCg9brH46GsLA7LLrgKIXM0JLl7/rlFRERERLqQK8lFfko+AzIGkJuci82qbzqJiIiI9CYKKggWizk5weWCrKzD26NRc/mIlhYIhw9PQThW6EBBAxEREUkkubm52Gw2qqur22yvrq6msLDwhB7DbrczceJEtm3bdsx9hgwZQm5uLtu2bTtmUMHpdOJ0Ok+8+O7gzAV7Gjgy41uHiIiIiMhJyk/J53OlnyPLnYXVYo13OSIiIiLSDnVpckw2G6SkQF4eFBdDYSHk5pphhvR08zan0wwrKKQgIiIiicbhcDB58mRWrVrVui0Wi7Fq1ao2UxM+SzQa5YMPPqCoqOiY++zbt4+6urrP3KdXSHIrpCAiIiIifYLb7iYnOUchBREREZFeTJ2aiIiIiPRbCxYs4Fe/+hW/+c1v2LRpE9/5znfw+XxceeWVAFx++eUsWrSodf8f/vCHvPzyy+zYsYP//Oc//Pd//ze7d+/m6quvBsDr9XLzzTfz73//m127drFq1SrOP/98ysvLmTVrVlxeo4iIiIiIiIiIiEhvo6UfRERERKTfuvjiizl48CCLFy+mqqqKCRMm8OKLL1JQUADAnj17sFoPZ3sbGhq45pprqKqqIisri8mTJ/PWW28xatQoAGw2G++//z6/+c1vaGxspLi4mC996Uvcc8898V/aQURERERERERERKSXsBiGYcS7iK7g8XjIyMigqamJ9PT0eJcjIiIiIt2or/d+ff31iYiIiMhhfb336+uvT0REREQO60jvp6UfREREREREREREREREREREpMcoqCAiIiIiIiIiIiIiIiIiIiI9RkEFERERERERERERERERERER6TEKKoiIiIiIiIiIiIiIiIiIiEiPUVBBREREREREREREREREREREeoyCCiIiIiIiIiIiIiIiIiIiItJjFFQQERERERERERERERERERGRHqOggoiIiIiIiIiIiIiIiIiIiPQYBRVERERERERERERERERERESkxyioICIiIiIiIiIiIiIiIiIiIj1GQQURERERERERERERERERERHpMQoqiIiIiIiIiIiIiIiIiIiISI9JincBXcUwDAA8Hk+cKxERERGR7nao5zvUA/Y16m1FRERE+g/1tiIiIiLSV3Skt+0zQYXm5mYAysrK4lyJiIiIiPSU5uZmMjIy4l1Gl1NvKyIiItL/qLcVERERkb7iRHpbi9FHorqxWIwDBw6QlpaGxWKJdzlx5fF4KCsrY+/evaSnp8e7nISh49ZxOmado+PWcTpmnaPj1jk6bh0Xj2NmGAbNzc0UFxdjtfa91czU2x6mv5Odo+PWcTpmnaPj1nE6Zp2j49ZxOmado96266m3PUx/LztHx63jdMw6R8et43TMOkfHreN0zDqnt/e2fWaigtVqpbS0NN5l9Crp6en6y9oJOm4dp2PWOTpuHadj1jk6bp2j49ZxPX3M+uK3zQ5Rb3s0/Z3sHB23jtMx6xwdt47TMescHbeO0zHrHPW2XUe97dH097JzdNw6Tsesc3TcOk7HrHN03DpOx6xzemtv2/ciuiIiIiIiIiIiIiIiIiIiItJrKaggIiIiIiIiIiIiIiIiIiIiPUZBhT7I6XRy55134nQ6411KQtFx6zgds87Rces4HbPO0XHrHB23jtMxk+6k91fn6Lh1nI5Z5+i4dZyOWefouHWcjlnn6LhJd9L7q3N03DpOx6xzdNw6Tsesc3TcOk7HrHN6+3GzGIZhxLsIERERERERERERERERERER6R80UUFERERERERERERERERERER6jIIKIiIiIiIiIiIiIiIiIiIi0mMUVBAREREREREREREREREREZEeo6BCAvv//r//jzlz5lBcXIzFYuFvf/tbm9sNw2Dx4sUUFRXhdruZOXMmW7dujU+xvcTSpUuZMmUKaWlp5Ofnc8EFF7B58+Y2+wQCAebNm0dOTg6pqal8+ctfprq6Ok4V9w6PPPII48aNIz09nfT0dKZPn84LL7zQeruO2fHde++9WCwWbrjhhtZtOm5Hu+uuu7BYLG0uFRUVrbfrmLVv//79/Pd//zc5OTm43W7Gjh3LunXrWm/X74OjDRo06Kj3msViYd68eYDea+2JRqPccccdDB48GLfbzdChQ7nnnnswDKN1H73X5GSot+049bado9725Km3PTHqbTtHvW3HqbftOPW20t3U23acetvOUW978tTbnhj1tp2j3rbj1Nt2XCL3tgoqJDCfz8f48eN5+OGH2739xz/+MT//+c9ZsWIF77zzDikpKcyaNYtAINDDlfYer7/+OvPmzePf//43r7zyCuFwmC996Uv4fL7WfW688Ub+/ve/86c//YnXX3+dAwcOcNFFF8Wx6vgrLS3l3nvvZf369axbt44zzzyT888/nw8//BDQMTuetWvX8uijjzJu3Lg223Xc2jd69GgqKytbL2+88UbrbTpmR2toaODUU0/Fbrfzwgsv8NFHH/GTn/yErKys1n30++Boa9eubfM+e+WVVwD46le/Cui91p777ruPRx55hIceeohNmzZx33338eMf/5gHH3ywdR+91+RkqLftOPW2naPe9uSot+0Y9bYdo962c9Tbdpx6W+lu6m07Tr1t56i3PTnqbTtGvW3HqLftHPW2HZfQva0hfQJg/PWvf229HovFjMLCQuP+++9v3dbY2Gg4nU7j6aefjkOFvVNNTY0BGK+//rphGOYxstvtxp/+9KfWfTZt2mQAxttvvx2vMnulrKws43//9391zI6jubnZGDZsmPHKK68YZ5xxhnH99dcbhqH32rHceeedxvjx49u9Tcesfbfeeqtx2mmnHfN2/T44Mddff70xdOhQIxaL6b12DOedd55x1VVXtdl20UUXGZdeeqlhGHqvSddSb9s56m07T73tiVFv2zHqbTtOvW3XUG97fOptpSept+0c9badp972xKi37Rj1th2n3rZrqLc9vkTubTVRoY/auXMnVVVVzJw5s3VbRkYG06ZN4+23345jZb1LU1MTANnZ2QCsX7+ecDjc5rhVVFQwYMAAHbdPRKNR/vCHP+Dz+Zg+fbqO2XHMmzeP8847r83xAb3XPsvWrVspLi5myJAhXHrppezZswfQMTuW5557jlNOOYWvfvWr5OfnM3HiRH71q1+13q7fB8cXCoV48sknueqqq7BYLHqvHcOMGTNYtWoVW7ZsAeC9997jjTfeYPbs2YDea9K99P46MeptO069bceot+049bYdo9725Km3PTHqbSWe9P46MeptO069bceot+049bYdo9725Km3PTGJ3NsmxfXZpdtUVVUBUFBQ0GZ7QUFB6239XSwW44YbbuDUU09lzJgxgHncHA4HmZmZbfbVcYMPPviA6dOnEwgESE1N5a9//SujRo1iw4YNOmbH8Ic//IH//Oc/rF279qjb9F5r37Rp03jiiScYMWIElZWV3H333Xz+859n48aNOmbHsGPHDh555BEWLFjAbbfdxtq1a/ne976Hw+Fg7ty5+n1wAv72t7/R2NjIFVdcAejv57EsXLgQj8dDRUUFNpuNaDTKj370Iy699FJAvYd0L72/jk+9bceot+049bYdp96249Tbnjz1tidGva3Ek95fx6fetmPU23acetuOU2/bceptT5562xOTyL2tggrSb82bN4+NGze2WUdJjm3EiBFs2LCBpqYm/u///o+5c+fy+uuvx7usXmvv3r1cf/31vPLKK7hcrniXkzAOJfwAxo0bx7Rp0xg4cCB//OMfcbvdcays94rFYpxyyiksWbIEgIkTJ7Jx40ZWrFjB3Llz41xdYvj1r3/N7NmzKS4ujncpvdof//hHfv/73/PUU08xevRoNmzYwA033EBxcbHeayK9gHrbjlFv2zHqbTtHvW3Hqbc9eeptT4x6W5HeTb1tx6i37Rj1tp2j3rbj1NuePPW2JyaRe1st/dBHFRYWAlBdXd1me3V1dett/dn8+fP5xz/+wWuvvUZpaWnr9sLCQkKhEI2NjW3213EDh8NBeXk5kydPZunSpYwfP56f/exnOmbHsH79empqapg0aRJJSUkkJSXx+uuv8/Of/5ykpCQKCgp03E5AZmYmw4cPZ9u2bXqvHUNRURGjRo1qs23kyJGto9f0++Cz7d69m3/+859cffXVrdv0XmvfzTffzMKFC/n617/O2LFjueyyy7jxxhtZunQpoPeadC+9vz6betuOU2/bMeptu4Z62+NTb3ty1NueOPW2Ek96f3029bYdp962Y9Tbdg31tsen3vbkqLc9cYnc2yqo0EcNHjyYwsJCVq1a1brN4/HwzjvvMH369DhWFl+GYTB//nz++te/8uqrrzJ48OA2t0+ePBm73d7muG3evJk9e/b06+PWnlgsRjAY1DE7hrPOOosPPviADRs2tF5OOeUULr300tafddyOz+v1sn37doqKivReO4ZTTz2VzZs3t9m2ZcsWBg4cCOj3wfE8/vjj5Ofnc95557Vu03utfS0tLVitbVtHm81GLBYD9F6T7qX3V/vU23Yd9bafTb1t11Bve3zqbU+OetsTp95W4knvr/apt+066m0/m3rbrqHe9vjU254c9bYnLqF7W0MSVnNzs/Huu+8a7777rgEYy5YtM959911j9+7dhmEYxr333mtkZmYazz77rPH+++8b559/vjF48GDD7/fHufL4+c53vmNkZGQYq1evNiorK1svLS0trft8+9vfNgYMGGC8+uqrxrp164zp06cb06dPj2PV8bdw4ULj9ddfN3bu3Gm8//77xsKFCw2LxWK8/PLLhmHomJ2oM844w7j++utbr+u4He373/++sXr1amPnzp3Gm2++acycOdPIzc01ampqDMPQMWvPmjVrjKSkJONHP/qRsXXrVuP3v/+9kZycbDz55JOt++j3Qfui0agxYMAA49Zbbz3qNr3XjjZ37lyjpKTE+Mc//mHs3LnT+Mtf/mLk5uYat9xyS+s+eq/JyVBv23HqbTtHvW3XUG97fOptO069beept+0Y9bbS3dTbdpx6285Rb9s11Nsen3rbjlNv23nqbTsmkXtbBRUS2GuvvWYAR13mzp1rGIZhxGIx44477jAKCgoMp9NpnHXWWcbmzZvjW3SctXe8AOPxxx9v3cfv9xvXXXedkZWVZSQnJxsXXnihUVlZGb+ie4GrrrrKGDhwoOFwOIy8vDzjrLPOam12DUPH7ER9uuHVcTvaxRdfbBQVFRkOh8MoKSkxLr74YmPbtm2tt+uYte/vf/+7MWbMGMPpdBoVFRXGL3/5yza36/dB+1566SUDaPdY6L12NI/HY1x//fXGgAEDDJfLZQwZMsT4wQ9+YASDwdZ99F6Tk6HetuPU23aOetuuod72+NTbdo56285Rb9sx6m2lu6m37Tj1tp2j3rZrqLc9PvW2naPetnPU23ZMIve2FsMwjG4c2CAiIiIiIiIiIiIiIiIiIiLSynr8XURERERERERERERERERERES6hoIKIiIiIiIiIiIiIiIiIiIi0mMUVBAREREREREREREREREREZEeo6CCiIiIiIiIiIiIiIiIiIiI9BgFFURERERERERERERERERERKTHKKggIiIiIiIiIiIiIiIiIiIiPUZBBREREREREREREREREREREekxCiqIiIiIiIiIiIiIiIiIiIhIj1FQQUSkj7vrrrsoKCjAYrHwt7/97YTus3r1aiwWC42Njd1aW28yaNAgli9fHu8yREREROQzqLc9MeptRURERHo/9bYnRr2tSN+loIKI9LgrrrgCi8WCxWLB4XBQXl7OD3/4QyKRSLxLO66ONI29waZNm7j77rt59NFHqaysZPbs2d32XF/4whe44YYbuu3xRURERHoj9bY9R72tiIiISPdSb9tz1NuKiEBSvAsQkf7pnHPO4fHHHycYDLJy5UrmzZuH3W5n0aJFHX6saDSKxWLBalX26tO2b98OwPnnn4/FYolzNSIiIiJ9k3rbnqHeVkRERKT7qbftGeptRUQ0UUFE4sTpdFJYWMjAgQP5zne+w8yZM3nuuecACAaD3HTTTZSUlJCSksK0adNYvXp1632feOIJMjMzee655xg1ahROp5M9e/YQDAa59dZbKSsrw+l0Ul5ezq9//evW+23cuJHZs2eTmppKQUEBl112GbW1ta23f+ELX+B73/set9xyC9nZ2RQWFnLXXXe13j5o0CAALrzwQiwWS+v17du3c/7551NQUEBqaipTpkzhn//8Z5vXW1lZyXnnnYfb7Wbw4ME89dRTR42samxs5OqrryYvL4/09HTOPPNM3nvvvc88jh988AFnnnkmbrebnJwcrr32WrxeL2CODpszZw4AVqv1MxvelStXMnz4cNxuN1/84hfZtWtXm9vr6ur4xje+QUlJCcnJyYwdO5ann3669fYrrriC119/nZ/97Getqetdu3YRjUb55je/yeDBg3G73YwYMYKf/exnn/maDv33PdLf/va3NvW/9957fPGLXyQtLY309HQmT57MunXrWm9/4403+PznP4/b7aasrIzvfe97+Hy+1ttramqYM2dO63+P3//+959Zk4iIiMhnUW+r3vZY1NuKiIhIolFvq972WNTbikhXU1BBRHoFt9tNKBQCYP78+bz99tv84Q9/4P333+erX/0q55xzDlu3bm3dv6Wlhfvuu4///d//5cMPPyQ/P5/LL7+cp59+mp///Ods2rSJRx99lNTUVMBsJs8880wmTpzIunXrePHFF6muruZrX/tamzp+85vfkJKSwjvvvMOPf/xjfvjDH/LKK68AsHbtWgAef/xxKisrW697vV7OPfdcVq1axbvvvss555zDnDlz2LNnT+vjXn755Rw4cIDVq1fz5z//mV/+8pfU1NS0ee6vfvWr1NTU8MILL7B+/XomTZrEWWedRX19fbvHzOfzMWvWLLKysli7di1/+tOf+Oc//8n8+fMBuOmmm3j88ccBs+GurKxs93H27t3LRRddxJw5c9iwYQNXX301CxcubLNPIBBg8uTJPP/882zcuJFrr72Wyy67jDVr1gDws5/9jOnTp3PNNde0PldZWRmxWIzS0lL+9Kc/8dFHH7F48WJuu+02/vjHP7Zby4m69NJLKS0tZe3ataxfv56FCxdit9sB8x8g55xzDl/+8pd5//33eeaZZ3jjjTdajwuYDfrevXt57bXX+L//+z9+8YtfHPXfQ0RERKSz1Nuqt+0I9bYiIiLSm6m3VW/bEeptRaRDDBGRHjZ37lzj/PPPNwzDMGKxmPHKK68YTqfTuOmmm4zdu3cbNpvN2L9/f5v7nHXWWcaiRYsMwzCMxx9/3ACMDRs2tN6+efNmAzBeeeWVdp/znnvuMb70pS+12bZ3714DMDZv3mwYhmGcccYZxmmnndZmnylTphi33npr63XA+Otf/3rc1zh69GjjwQcfNAzDMDZt2mQAxtq1a1tv37p1qwEYP/3pTw3DMIx//etfRnp6uhEIBNo8ztChQ41HH3203ef45S9/aWRlZRler7d12/PPP29YrVajqqrKMAzD+Otf/2oc73/1ixYtMkaNGtVm26233moARkNDwzHvd9555xnf//73W6+fccYZxvXXX/+Zz2UYhjFv3jzjy1/+8jFvf/zxx42MjIw22z79OtLS0ownnnii3ft/85vfNK699to22/71r38ZVqvV8Pv9re+VNWvWtN5+6L/Rof8eIiIiIidKva16W/W2IiIi0leot1Vvq95WRHpSUrcnIURE2vGPf/yD1NRUwuEwsViMSy65hLvuuovVq1cTjUYZPnx4m/2DwSA5OTmt1x0OB+PGjWu9vmHDBmw2G2eccUa7z/fee+/x2muvtSZ1j7R9+/bW5zvyMQGKioqOm9j0er3cddddPP/881RWVhKJRPD7/a3J3M2bN5OUlMSkSZNa71NeXk5WVlab+rxeb5vXCOD3+1vXK/u0TZs2MX78eFJSUlq3nXrqqcRiMTZv3kxBQcFn1n3k40ybNq3NtunTp7e5Ho1GWbJkCX/84x/Zv38/oVCIYDBIcnLycR//4Ycf5rHHHmPPnj34/X5CoRATJkw4odqOZcGCBVx99dX87ne/Y+bMmXz1q19l6NChgHks33///TZjwQzDIBaLsXPnTrZs2UJSUhKTJ09uvb2iouKosWUiIiIiJ0q9rXrbk6HeVkRERHoT9bbqbU+GelsR6QgFFUQkLr74xS/yyCOP4HA4KC4uJinJ/N+R1+vFZrOxfv16bDZbm/sc2ay63e42a1+53e7PfD6v18ucOXO47777jrqtqKio9edDY6gOsVgsxGKxz3zsm266iVdeeYUHHniA8vJy3G43X/nKV1pHop0Ir9dLUVFRmzXdDukNjdj999/Pz372M5YvX87YsWNJSUnhhhtuOO5r/MMf/sBNN93ET37yE6ZPn05aWhr3338/77zzzjHvY7VaMQyjzbZwONzm+l133cUll1zC888/zwsvvMCdd97JH/7wBy688EK8Xi/f+ta3+N73vnfUYw8YMIAtW7Z04JWLiIiIHJ9626PrU29rUm8rIiIiiUa97dH1qbc1qbcVka6moIKIxEVKSgrl5eVHbZ84cSLRaJSamho+//nPn/DjjR07llgsxuuvv87MmTOPun3SpEn8+c9/ZtCgQa3NdWfY7Xai0WibbW+++SZXXHEFF154IWA2r7t27Wq9fcSIEUQiEd59993WNOi2bdtoaGhoU19VVRVJSUkMGjTohGoZOXIkTzzxBD6frzWd++abb2K1WhkxYsQJv6aRI0fy3HPPtdn273//+6jXeP755/Pf//3fAMRiMbZs2cKoUaNa93E4HO0emxkzZnDddde1bjtW0viQvLw8mpub27yuDRs2HLXf8OHDGT58ODfeeCPf+MY3ePzxx7nwwguZNGkSH330UbvvLzBTuJFIhPXr1zNlyhTATE83NjZ+Zl0iIiIix6LeVr3tsai3FRERkUSj3la97bGotxWRrmaNdwEiIkcaPnw4l156KZdffjl/+ctf2LlzJ2vWrGHp0qU8//zzx7zfoEGDmDt3LldddRV/+9vf2LlzJ6tXr+aPf/wjAPPmzaO+vp5vfOMbrF27lu3bt/PSSy9x5ZVXHtWkfZZBgwaxatUqqqqqWhvWYcOG8Ze//IUNGzbw3nvvcckll7RJ81ZUVDBz5kyuvfZa1qxZw7vvvsu1117bJl08c+ZMpk+fzgUXXMDLL7/Mrl27eOutt/jBD37AunXr2q3l0ksvxeVyMXfuXDZu3Mhrr73Gd7/7XS677LITHh8G8O1vf5utW7dy8803s3nzZp566imeeOKJNvsMGzaMV155hbfeeotNmzbxrW99i+rq6qOOzTvvvMOuXbuora0lFosxbNgw1q1bx0svvcSWLVu44447WLt27WfWM23aNJKTk7ntttvYvn37UfX4/X7mz5/P6tWr2b17N2+++SZr165l5MiRANx666289dZbzJ8/nw0bNrB161aeffZZ5s+fD5j/ADnnnHP41re+xTvvvMP69eu5+uqrj5vuFhEREeko9bbqbdXbioiISF+h3la9rXpbEelqCiqISK/z+OOPc/nll/P973+fESNGcMEFF7B27VoGDBjwmfd75JFH+MpXvsJ1111HRUUF11xzDT6fD4Di4mLefPNNotEoX/rSlxg7diw33HADmZmZWK0n/r/Cn/zkJ7zyyiuUlZUxceJEAJYtW0ZWVhYzZsxgzpw5zJo1q826ZgC//e1vKSgo4PTTT+fCCy/kmmuuIS0tDZfLBZijylauXMnpp5/OlVdeyfDhw/n617/O7t27j9m8Jicn89JLL1FfX8+UKVP4yle+wllnncVDDz10wq8HzLFaf/7zn/nb3/7G+PHjWbFiBUuWLGmzz+23386kSZOYNWsWX/jCFygsLOSCCy5os89NN92EzWZj1KhR5OXlsWfPHr71rW9x0UUXcfHFFzNt2jTq6urapHTbk52dzZNPPsnKlSsZO3YsTz/9NHfddVfr7Tabjbq6Oi6//HKGDx/O1772NWbPns3dd98NmOvVvf7662zZsoXPf/7zTJw4kcWLF1NcXNz6GI8//jjFxcWcccYZXHTRRVx77bXk5+d36LiJiIiInAj1tupt1duKiIhIX6HeVr2telsR6UoW49MLyoiISLfbt28fZWVl/POf/+Sss86KdzkiIiIiIp2m3lZERERE+gr1tiIiPUdBBRGRHvDqq6/i9XoZO3YslZWV3HLLLezfv58tW7Zgt9vjXZ6IiIiIyAlTbysiIiIifYV6WxGR+EmKdwEiIv1BOBzmtttuY8eOHaSlpTFjxgx+//vfq9kVERERkYSj3lZERERE+gr1tiIi8aOJCiIiIiIiIiIiIiIiIiIiItJjrPEuQERERERERERERERERERERPoPBRVERERERERERERERERERESkxyioICIiIiIiIiIiIiIiIiIiIj1GQQURERERERERERERERERERHpMQoqiIiIiIiIiIiIiIiIiIiISI9RUEFERERERERERERERERERER6jIIKIiIiIiIiIiIiIiIiIiIi0mMUVBAREREREREREREREREREZEeo6CCiIiIiIiIiIiIiIiIiIiI9Jj/HzV2ZV8dFUSaAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "common_data_points = sorted(list(set(point for fold_points in all_fold_data_used for point in fold_points)))\n",
    "\n",
    "# Interpolate metrics for each fold to the common data points\n",
    "avg_accuracies = []\n",
    "avg_f1_micros = []\n",
    "avg_f1_macros = []\n",
    "std_accuracies = []\n",
    "std_f1_micros = []\n",
    "std_f1_macros = []\n",
    "\n",
    "for point in common_data_points:\n",
    "    point_accuracies = []\n",
    "    point_f1_micros = []\n",
    "    point_f1_macros = []\n",
    "    for i in range(N_SPLITS):\n",
    "        sorted_indices = np.argsort(all_fold_data_used[i])\n",
    "        sorted_data = np.array(all_fold_data_used[i])[sorted_indices]\n",
    "        \n",
    "        sorted_acc = np.array(all_fold_accuracies[i])[sorted_indices]\n",
    "        sorted_f1m = np.array(all_fold_f1_micros[i])[sorted_indices]\n",
    "        sorted_f1ma = np.array(all_fold_f1_macros[i])[sorted_indices]\n",
    "        \n",
    "        # Use interpolation to estimate the metric value at the common 'point'\n",
    "        point_accuracies.append(np.interp(point, sorted_data, sorted_acc))\n",
    "        point_f1_micros.append(np.interp(point, sorted_data, sorted_f1m))\n",
    "        point_f1_macros.append(np.interp(point, sorted_data, sorted_f1ma))\n",
    "    \n",
    "    avg_accuracies.append(np.mean(point_accuracies))\n",
    "    avg_f1_micros.append(np.mean(point_f1_micros))\n",
    "    avg_f1_macros.append(np.mean(point_f1_macros))\n",
    "    \n",
    "    std_accuracies.append(np.std(point_accuracies))\n",
    "    std_f1_micros.append(np.std(point_f1_micros))\n",
    "    std_f1_macros.append(np.std(point_f1_macros))\n",
    "\n",
    "# Convert to numpy arrays for easier plotting\n",
    "avg_accuracies = np.array(avg_accuracies)\n",
    "avg_f1_micros = np.array(avg_f1_micros)\n",
    "avg_f1_macros = np.array(avg_f1_macros)\n",
    "std_accuracies = np.array(std_accuracies)\n",
    "std_f1_micros = np.array(std_f1_micros)\n",
    "std_f1_macros = np.array(std_f1_macros)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "data_used_percent = [round(data / len(X) * 100, 1) for data in common_data_points]\n",
    "\n",
    "# Plot for Accuracy\n",
    "axs[0].plot(data_used_percent, avg_accuracies, label=\"Avg Accuracy\", color=\"blue\")\n",
    "axs[0].fill_between(data_used_percent, avg_accuracies - std_accuracies, avg_accuracies + std_accuracies, color='blue', alpha=0.2)\n",
    "axs[0].set_xlabel(\"Percentage of data used\")\n",
    "axs[0].set_title(\"Average Accuracy Across Folds\")\n",
    "\n",
    "# Plot for F1 Micro\n",
    "axs[1].plot(data_used_percent, avg_f1_micros, label=\"Avg F1 Micro\", color=\"orange\")\n",
    "axs[1].fill_between(data_used_percent, avg_f1_micros - std_f1_micros, avg_f1_micros + std_f1_micros, color='orange', alpha=0.2)\n",
    "axs[1].set_xlabel(\"Percentage of data used\")\n",
    "axs[1].set_title(\"Average F1 Micro Across Folds\")\n",
    "\n",
    "# Plot for F1 Macro\n",
    "axs[2].plot(data_used_percent, avg_f1_macros, label=\"Avg F1 Macro\", color=\"green\")\n",
    "axs[2].fill_between(data_used_percent, avg_f1_macros - std_f1_macros, avg_f1_macros + std_f1_macros, color='green', alpha=0.2)\n",
    "axs[2].set_xlabel(\"Percentage of data used\")\n",
    "axs[2].set_title(\"Average F1 Macro Across Folds\")\n",
    "\n",
    "# Adjust layout and show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "for i in range(N_SPLITS):\n",
    "    result = pd.DataFrame({\n",
    "        'Data Used': all_fold_data_used[i],\n",
    "        'Accuracy': all_fold_accuracies[i],\n",
    "        'F1 Micro': all_fold_f1_micros[i],\n",
    "        'F1 Macro': all_fold_f1_macros[i],\n",
    "    })\n",
    "\n",
    "    result.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7380256,
     "sourceId": 11756058,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 31575.162194,
   "end_time": "2025-06-29T11:03:53.802794",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-29T02:17:38.640600",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "07fdf800e2734bb5a5c73070b3dea60b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "0b11e85feebf4e289b87b59b6bc73e56": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0c6cb7fb42744f3aa24d386227e1ba00": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0cae55cdc0144ebe8631545b953c4bc6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "1ab8d7bea41a44bfae3639e01559c695": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "211d33920ab5445488129448cff10fe8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "238f7e231c3e46b4a6f649c52244f298": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "26a0e2755dc2489aa34b81959d551345": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c70233c61db04602809d3ac7e0571aa7",
       "placeholder": "",
       "style": "IPY_MODEL_ed35f3107a3e40908f87eea6f5b70e06",
       "value": "229k/?[00:00&lt;00:00,6.18MB/s]"
      }
     },
     "28ee904f54e44e5ab7e690522f108147": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_07fdf800e2734bb5a5c73070b3dea60b",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f5058bac238d43818a37af251af9117d",
       "value": 1.0
      }
     },
     "308f68b0d93a468883c8af35ae7a52d6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_56029dcc76c34350baf29331160cf667",
        "IPY_MODEL_d5a5641eaed147debbfdf6ac9705393d",
        "IPY_MODEL_fde87d7baa0e4e4797f788e55b9045ff"
       ],
       "layout": "IPY_MODEL_fc13bb3968654e11b743ff2b397f6d0c"
      }
     },
     "367dcaf548c247fd9c9f1c9ffd624ce9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "39a7003b50a44c5cb3fde2a9a8f2e7aa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3dc97d75dfb64dc3ab59126dcae465f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3e8f2e57c3504da8b280d635fe2e831e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9c4513c8762344e0a66dc3f04ab0f55f",
       "max": 112.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_49cdd1dc439b4ecab1e28ac5f4c8da69",
       "value": 112.0
      }
     },
     "43b1f99fcfb94b35953f45f3029f8fa1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_de5f34071bdf40dfb9d3d17c5f3b4ad8",
       "placeholder": "",
       "style": "IPY_MODEL_69696a7b07c843259c6a4fb69e390b92",
       "value": "tokenizer_config.json:100%"
      }
     },
     "453dea9f6fa945f5a160ea69ced4a3a9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "49cdd1dc439b4ecab1e28ac5f4c8da69": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "51c43fc119ac443484cbce3b922da28a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e3c033cae242416cbceac6e4ec620376",
       "placeholder": "",
       "style": "IPY_MODEL_cfb8a271cab442e3a7366c877c42e1ed",
       "value": "112/112[00:00&lt;00:00,12.5kB/s]"
      }
     },
     "52fd0bba0c5c420fafb6c7cf8b93cb78": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "56029dcc76c34350baf29331160cf667": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0b11e85feebf4e289b87b59b6bc73e56",
       "placeholder": "",
       "style": "IPY_MODEL_367dcaf548c247fd9c9f1c9ffd624ce9",
       "value": "pytorch_model.bin:100%"
      }
     },
     "5921fb2fa1eb412fa390cf2ddfe8d2ac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "69696a7b07c843259c6a4fb69e390b92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6acaf229ee9345c583f7821c99210c89": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e24107ac3862456c961504437ba2ff1b",
        "IPY_MODEL_3e8f2e57c3504da8b280d635fe2e831e",
        "IPY_MODEL_51c43fc119ac443484cbce3b922da28a"
       ],
       "layout": "IPY_MODEL_453dea9f6fa945f5a160ea69ced4a3a9"
      }
     },
     "7dee2f8d4ff545df8b2000d8bbec8317": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_211d33920ab5445488129448cff10fe8",
       "placeholder": "",
       "style": "IPY_MODEL_5921fb2fa1eb412fa390cf2ddfe8d2ac",
       "value": "2.00/2.00[00:00&lt;00:00,172B/s]"
      }
     },
     "8758214e129e45a4a2e39ec65389bfd6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8bb8fafb7c8d4bbc98ef08d5f4e4e212": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1ab8d7bea41a44bfae3639e01559c695",
       "placeholder": "",
       "style": "IPY_MODEL_f125e22050d74ac28611939263140233",
       "value": "config.json:"
      }
     },
     "944fdfb7e9674c43a52fa3eca80c6928": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9c17db2735e845b88c399b626c7a7eaa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9c4513c8762344e0a66dc3f04ab0f55f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a39e85883c7f431fb383706d87671bc4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0cae55cdc0144ebe8631545b953c4bc6",
       "max": 1.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3dc97d75dfb64dc3ab59126dcae465f3",
       "value": 1.0
      }
     },
     "a506fd1310054c7aa971b40a7d734fb9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b946fa452f274193b144bc02faf40999": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f6b374818fd94be78f38646724c64958",
        "IPY_MODEL_28ee904f54e44e5ab7e690522f108147",
        "IPY_MODEL_26a0e2755dc2489aa34b81959d551345"
       ],
       "layout": "IPY_MODEL_52fd0bba0c5c420fafb6c7cf8b93cb78"
      }
     },
     "baaee55cb95749ccb4b72b3c6b74e469": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "bb47bee69251431e9a2db410e1d20b3c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "bd29833f54ce4840a2c164fa826b69f6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c2d7bb277ef3428fa9778ce4108bbc2d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_43b1f99fcfb94b35953f45f3029f8fa1",
        "IPY_MODEL_f1fbfd15f793457a93b0bcfc109002c4",
        "IPY_MODEL_7dee2f8d4ff545df8b2000d8bbec8317"
       ],
       "layout": "IPY_MODEL_bd29833f54ce4840a2c164fa826b69f6"
      }
     },
     "c70233c61db04602809d3ac7e0571aa7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cfb8a271cab442e3a7366c877c42e1ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d4ba8c91bd1842d9af72fc128cd3060f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d5a5641eaed147debbfdf6ac9705393d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f4a24bf434cc46c6bc810844cd961a7b",
       "max": 497810400.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_baaee55cb95749ccb4b72b3c6b74e469",
       "value": 497810400.0
      }
     },
     "d6590c9a66004bb6a42f4ee482c4ad5a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d88b9cb18fcf4ff08cba5246953c0866": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8bb8fafb7c8d4bbc98ef08d5f4e4e212",
        "IPY_MODEL_a39e85883c7f431fb383706d87671bc4",
        "IPY_MODEL_ed28bc7411744f11b273a199264f3629"
       ],
       "layout": "IPY_MODEL_d6590c9a66004bb6a42f4ee482c4ad5a"
      }
     },
     "de5f34071bdf40dfb9d3d17c5f3b4ad8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e24107ac3862456c961504437ba2ff1b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8758214e129e45a4a2e39ec65389bfd6",
       "placeholder": "",
       "style": "IPY_MODEL_bb47bee69251431e9a2db410e1d20b3c",
       "value": "special_tokens_map.json:100%"
      }
     },
     "e3c033cae242416cbceac6e4ec620376": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ed28bc7411744f11b273a199264f3629": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_39a7003b50a44c5cb3fde2a9a8f2e7aa",
       "placeholder": "",
       "style": "IPY_MODEL_a506fd1310054c7aa971b40a7d734fb9",
       "value": "1.53k/?[00:00&lt;00:00,126kB/s]"
      }
     },
     "ed35f3107a3e40908f87eea6f5b70e06": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f125e22050d74ac28611939263140233": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f1fbfd15f793457a93b0bcfc109002c4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d4ba8c91bd1842d9af72fc128cd3060f",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_238f7e231c3e46b4a6f649c52244f298",
       "value": 2.0
      }
     },
     "f4a24bf434cc46c6bc810844cd961a7b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f5058bac238d43818a37af251af9117d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f6b374818fd94be78f38646724c64958": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_944fdfb7e9674c43a52fa3eca80c6928",
       "placeholder": "",
       "style": "IPY_MODEL_f752150058fc4daf8527b263405e831f",
       "value": "vocab.txt:"
      }
     },
     "f752150058fc4daf8527b263405e831f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "fc13bb3968654e11b743ff2b397f6d0c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fde87d7baa0e4e4797f788e55b9045ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0c6cb7fb42744f3aa24d386227e1ba00",
       "placeholder": "",
       "style": "IPY_MODEL_9c17db2735e845b88c399b626c7a7eaa",
       "value": "498M/498M[00:02&lt;00:00,249MB/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
