{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f54c09d",
   "metadata": {
    "papermill": {
     "duration": 0.015224,
     "end_time": "2025-03-31T04:34:56.921038",
     "exception": false,
     "start_time": "2025-03-31T04:34:56.905814",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "453f2183",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:34:56.949107Z",
     "iopub.status.busy": "2025-03-31T04:34:56.948779Z",
     "iopub.status.idle": "2025-03-31T04:35:28.999104Z",
     "shell.execute_reply": "2025-03-31T04:35:28.998440Z"
    },
    "papermill": {
     "duration": 32.065201,
     "end_time": "2025-03-31T04:35:29.000623",
     "exception": false,
     "start_time": "2025-03-31T04:34:56.935422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746b3aa3",
   "metadata": {
    "papermill": {
     "duration": 0.011111,
     "end_time": "2025-03-31T04:35:29.023422",
     "exception": false,
     "start_time": "2025-03-31T04:35:29.012311",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "538a9dde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:35:29.046226Z",
     "iopub.status.busy": "2025-03-31T04:35:29.045732Z",
     "iopub.status.idle": "2025-03-31T04:35:29.049258Z",
     "shell.execute_reply": "2025-03-31T04:35:29.048478Z"
    },
    "papermill": {
     "duration": 0.016204,
     "end_time": "2025-03-31T04:35:29.050453",
     "exception": false,
     "start_time": "2025-03-31T04:35:29.034249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cc000aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:35:29.073078Z",
     "iopub.status.busy": "2025-03-31T04:35:29.072850Z",
     "iopub.status.idle": "2025-03-31T04:35:29.076616Z",
     "shell.execute_reply": "2025-03-31T04:35:29.075852Z"
    },
    "papermill": {
     "duration": 0.016361,
     "end_time": "2025-03-31T04:35:29.077869",
     "exception": false,
     "start_time": "2025-03-31T04:35:29.061508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/working/results') == False:\n",
    "    os.mkdir('/kaggle/working/results')\n",
    "\n",
    "if os.path.exists('/kaggle/working/acquired_data') == False:\n",
    "    os.mkdir('/kaggle/working/acquired_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7db0312e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:35:29.100690Z",
     "iopub.status.busy": "2025-03-31T04:35:29.100449Z",
     "iopub.status.idle": "2025-03-31T04:35:29.113187Z",
     "shell.execute_reply": "2025-03-31T04:35:29.112411Z"
    },
    "papermill": {
     "duration": 0.025315,
     "end_time": "2025-03-31T04:35:29.114386",
     "exception": false,
     "start_time": "2025-03-31T04:35:29.089071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79a2682",
   "metadata": {
    "papermill": {
     "duration": 0.010687,
     "end_time": "2025-03-31T04:35:29.135963",
     "exception": false,
     "start_time": "2025-03-31T04:35:29.125276",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "308a77b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:35:29.158401Z",
     "iopub.status.busy": "2025-03-31T04:35:29.158171Z",
     "iopub.status.idle": "2025-03-31T04:35:29.221933Z",
     "shell.execute_reply": "2025-03-31T04:35:29.220537Z"
    },
    "papermill": {
     "duration": 0.076711,
     "end_time": "2025-03-31T04:35:29.223506",
     "exception": false,
     "start_time": "2025-03-31T04:35:29.146795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Shared resources\n",
    "aspect_accuracies = manager.list()\n",
    "aspect_f1_micros = manager.list()\n",
    "aspect_f1_macros = manager.list()\n",
    "sentiment_accuracies = manager.list()\n",
    "sentiment_f1_micros = manager.list()\n",
    "sentiment_f1_macros = manager.list()\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "farthest_point = manager.Value(\"s\", \"test\")\n",
    "\n",
    "# Non shared resources\n",
    "filename = 'hoasa-coreset'\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "sequence_length = 48\n",
    "\n",
    "aspect_list = ['ac', 'air_panas', 'bau', 'general', 'kebersihan', 'linen', 'service', 'sunrise_meal', 'tv', 'wifi']\n",
    "aspect_mapping = {'ac': 0, 'air_panas': 1, 'bau': 2, 'general': 3, 'kebersihan': 4, 'linen': 5, 'service': 6, 'sunrise_meal': 7, 'tv': 8, 'wifi': 9}\n",
    "label_mapping = {\"neg\": 0, \"neut\": 1, 'neg_pos': 1, 'pos': 2}\n",
    "ignored_keys = ['labels', 'ori_text', 'ori_label', 'ori_indices', 'aspect']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596dc078",
   "metadata": {
    "papermill": {
     "duration": 0.01079,
     "end_time": "2025-03-31T04:35:29.245407",
     "exception": false,
     "start_time": "2025-03-31T04:35:29.234617",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30366667",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:35:29.268263Z",
     "iopub.status.busy": "2025-03-31T04:35:29.267964Z",
     "iopub.status.idle": "2025-03-31T04:35:29.354010Z",
     "shell.execute_reply": "2025-03-31T04:35:29.353233Z"
    },
    "papermill": {
     "duration": 0.099129,
     "end_time": "2025-03-31T04:35:29.355314",
     "exception": false,
     "start_time": "2025-03-31T04:35:29.256185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>ac</th>\n",
       "      <th>air_panas</th>\n",
       "      <th>bau</th>\n",
       "      <th>general</th>\n",
       "      <th>kebersihan</th>\n",
       "      <th>linen</th>\n",
       "      <th>service</th>\n",
       "      <th>sunrise_meal</th>\n",
       "      <th>tv</th>\n",
       "      <th>wifi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kebersihan kurang...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sangat mengecewakan... hotel bad image, kebers...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tempat nyaman bersih tapi tv terlalu tinggi ti...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>pos</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>semuanya bagus sesuai profile,dan harga promo ...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>pos</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tempat tidur sangat keras, bantal besar dan ke...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review    ac air_panas   bau  \\\n",
       "0                               kebersihan kurang...  neut      neut  neut   \n",
       "1  sangat mengecewakan... hotel bad image, kebers...  neut      neut  neut   \n",
       "2  Tempat nyaman bersih tapi tv terlalu tinggi ti...  neut      neut  neut   \n",
       "3  semuanya bagus sesuai profile,dan harga promo ...  neut       neg  neut   \n",
       "4  Tempat tidur sangat keras, bantal besar dan ke...   neg       neg  neut   \n",
       "\n",
       "  general kebersihan linen service sunrise_meal    tv  wifi  \n",
       "0    neut        neg  neut    neut         neut  neut  neut  \n",
       "1    neut        neg  neut    neut         neut  neut  neut  \n",
       "2    neut        pos  neut    neut         neut   neg  neut  \n",
       "3     pos       neut  neut    neut         neut  neut  neut  \n",
       "4    neut       neut   neg    neut         neut  neut  neut  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/hoasa-dataset/train_preprocess.csv', encoding='latin-1')\n",
    "val_data = pd.read_csv('/kaggle/input/hoasa-dataset/valid_preprocess.csv', encoding='latin-1')\n",
    "test_data = pd.read_csv('/kaggle/input/hoasa-dataset/test_preprocess.csv', encoding='latin-1')\n",
    "\n",
    "data = pd.concat([train_data, val_data, test_data], ignore_index=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9995a543",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:35:29.378683Z",
     "iopub.status.busy": "2025-03-31T04:35:29.378476Z",
     "iopub.status.idle": "2025-03-31T04:35:29.388051Z",
     "shell.execute_reply": "2025-03-31T04:35:29.387483Z"
    },
    "papermill": {
     "duration": 0.022765,
     "end_time": "2025-03-31T04:35:29.389332",
     "exception": false,
     "start_time": "2025-03-31T04:35:29.366567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c9ca124",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:35:29.412538Z",
     "iopub.status.busy": "2025-03-31T04:35:29.412320Z",
     "iopub.status.idle": "2025-03-31T04:35:29.425027Z",
     "shell.execute_reply": "2025-03-31T04:35:29.424300Z"
    },
    "papermill": {
     "duration": 0.026031,
     "end_time": "2025-03-31T04:35:29.426481",
     "exception": false,
     "start_time": "2025-03-31T04:35:29.400450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2283,) (2283, 10)\n",
      "(571,) (571, 10)\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_data.columns[1:]\n",
    "val_labels = val_data.columns[1:]\n",
    "\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['review'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['review'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b411ed",
   "metadata": {
    "papermill": {
     "duration": 0.01084,
     "end_time": "2025-03-31T04:35:29.448402",
     "exception": false,
     "start_time": "2025-03-31T04:35:29.437562",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BUILD DATASET & DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07b81b01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:35:29.471446Z",
     "iopub.status.busy": "2025-03-31T04:35:29.471202Z",
     "iopub.status.idle": "2025-03-31T04:35:29.477282Z",
     "shell.execute_reply": "2025-03-31T04:35:29.476610Z"
    },
    "papermill": {
     "duration": 0.01897,
     "end_time": "2025-03-31T04:35:29.478608",
     "exception": false,
     "start_time": "2025-03-31T04:35:29.459638",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AspectDetectionDataset(Dataset):\n",
    "    def __init__(self, texts, labels, label_mapping, tokenizer, max_length=sequence_length, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        \n",
    "        original_labels = [self.label_mapping[label] for label in self.labels[idx]]\n",
    "        encoded_labels = [1 if label == 1 else 0 for label in original_labels]\n",
    "        \n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['ori_indices'] = idx\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(original_labels, dtype=torch.float)\n",
    "        item['labels'] = torch.tensor(encoded_labels, dtype=torch.float if self.use_float else torch.long)\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ad2a782",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:35:29.501358Z",
     "iopub.status.busy": "2025-03-31T04:35:29.501145Z",
     "iopub.status.idle": "2025-03-31T04:35:29.508028Z",
     "shell.execute_reply": "2025-03-31T04:35:29.507373Z"
    },
    "papermill": {
     "duration": 0.019532,
     "end_time": "2025-03-31T04:35:29.509148",
     "exception": false,
     "start_time": "2025-03-31T04:35:29.489616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentAnalysisDataset(Dataset):\n",
    "    def __init__(self, texts, labels, aspects, indices, label_mapping, tokenizer, max_length=96, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.aspects = aspects\n",
    "        self.indices = indices\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = aspect_token + ' ' + self.aspects[idx] + ' ' + review_token + ' ' + self.texts[idx] \n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "\n",
    "        if isinstance(self.labels[idx], str):\n",
    "            self.labels[idx] = self.label_mapping[self.labels[idx]]\n",
    "        elif torch.is_tensor(self.labels[idx]):\n",
    "            self.labels[idx] = int(self.labels[idx].item())\n",
    "\n",
    "        encoded_label = 1 if self.labels[idx] == 2 else self.labels[idx]\n",
    "        one_hot_label = F.one_hot(torch.tensor(encoded_label, dtype=torch.long), num_classes=2).float()\n",
    "\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['aspect'] = self.aspects[idx]\n",
    "        item['labels'] = one_hot_label\n",
    "        item['ori_indices'] = self.indices[idx]\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f19102ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:35:29.531909Z",
     "iopub.status.busy": "2025-03-31T04:35:29.531709Z",
     "iopub.status.idle": "2025-03-31T04:35:30.570265Z",
     "shell.execute_reply": "2025-03-31T04:35:30.569600Z"
    },
    "papermill": {
     "duration": 1.051513,
     "end_time": "2025-03-31T04:35:30.571639",
     "exception": false,
     "start_time": "2025-03-31T04:35:29.520126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45258ecd8313421e8649d081091e664a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c7a26b070941d996e32a51e8b1fd03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09bd513f5ff043eea3a6357d405fdc57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962c997ba74a4db4a273e83cafa8c0fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "review_token = '[REVIEW]'\n",
    "aspect_token = '[ASPECT]'\n",
    "special_tokens_dict = {'additional_special_tokens': [review_token, aspect_token]}\n",
    "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "379febf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:35:30.604633Z",
     "iopub.status.busy": "2025-03-31T04:35:30.604367Z",
     "iopub.status.idle": "2025-03-31T04:35:30.608888Z",
     "shell.execute_reply": "2025-03-31T04:35:30.608043Z"
    },
    "papermill": {
     "duration": 0.020074,
     "end_time": "2025-03-31T04:35:30.610269",
     "exception": false,
     "start_time": "2025-03-31T04:35:30.590195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_aspect_dataset(X_train, y_train, X_val, y_val, sequence_length, num_workers=4):\n",
    "    train_dataset = AspectDetectionDataset(X_train, y_train, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = AspectDetectionDataset(X_val, y_val, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "507708bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:35:30.634288Z",
     "iopub.status.busy": "2025-03-31T04:35:30.634023Z",
     "iopub.status.idle": "2025-03-31T04:35:30.643470Z",
     "shell.execute_reply": "2025-03-31T04:35:30.642835Z"
    },
    "papermill": {
     "duration": 0.022742,
     "end_time": "2025-03-31T04:35:30.644649",
     "exception": false,
     "start_time": "2025-03-31T04:35:30.621907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_sentiment_dataset(device, train_dataset, val_dataset, aspect_detection_model, tokenizer, max_length=sequence_length):\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    aspect_detection_model.to(device)\n",
    "    aspect_detection_model.eval()\n",
    "\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    train_aspects = []\n",
    "    train_indices = []\n",
    "\n",
    "    val_data = []\n",
    "    val_labels = []\n",
    "    val_aspects = []\n",
    "    val_indices = []\n",
    "\n",
    "    # Transform train set\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        train_aspects.append(aspect_list[j])\n",
    "                        train_data.append(batch['ori_text'][i])\n",
    "                        train_labels.append(batch['ori_label'][i][j])\n",
    "                        train_indices.append(batch['ori_indices'][i])\n",
    "            \n",
    "        # Transform validation set\n",
    "        for batch in val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        val_aspects.append(aspect_list[j])\n",
    "                        val_data.append(batch['ori_text'][i])\n",
    "                        val_labels.append(batch['ori_label'][i][j])\n",
    "                        val_indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    train_dataset = SentimentAnalysisDataset(train_data, train_labels, train_aspects, train_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "    val_dataset = SentimentAnalysisDataset(val_data, val_labels, val_aspects, val_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb67b83f",
   "metadata": {
    "papermill": {
     "duration": 0.011344,
     "end_time": "2025-03-31T04:35:30.667616",
     "exception": false,
     "start_time": "2025-03-31T04:35:30.656272",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d87641e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:35:30.691437Z",
     "iopub.status.busy": "2025-03-31T04:35:30.691200Z",
     "iopub.status.idle": "2025-03-31T04:35:30.694734Z",
     "shell.execute_reply": "2025-03-31T04:35:30.694129Z"
    },
    "papermill": {
     "duration": 0.016875,
     "end_time": "2025-03-31T04:35:30.695887",
     "exception": false,
     "start_time": "2025-03-31T04:35:30.679012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "315f98f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:35:30.719776Z",
     "iopub.status.busy": "2025-03-31T04:35:30.719575Z",
     "iopub.status.idle": "2025-03-31T04:35:30.724019Z",
     "shell.execute_reply": "2025-03-31T04:35:30.723418Z"
    },
    "papermill": {
     "duration": 0.018183,
     "end_time": "2025-03-31T04:35:30.725671",
     "exception": false,
     "start_time": "2025-03-31T04:35:30.707488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p, label, classes):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        labels=label,\n",
    "        target_names=classes,\n",
    "        zero_division=0\n",
    "    ) \n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b8b2b55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:35:30.750395Z",
     "iopub.status.busy": "2025-03-31T04:35:30.750148Z",
     "iopub.status.idle": "2025-03-31T04:35:30.756288Z",
     "shell.execute_reply": "2025-03-31T04:35:30.755526Z"
    },
    "papermill": {
     "duration": 0.019481,
     "end_time": "2025-03-31T04:35:30.757486",
     "exception": false,
     "start_time": "2025-03-31T04:35:30.738005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics_overall(p, classes):\n",
    "    preds = torch.tensor(p.predictions)\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Ensure it's in the correct shape\n",
    "    if preds.shape != labels.shape:\n",
    "        raise ValueError(\"Shape mismatch: predictions and labels must have the same shape.\")\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Compute per-label (column-wise) precision, recall, F1\n",
    "    precision_list, recall_list, f1_micro_list, f1_macro_list = [], [], [], []\n",
    "    \n",
    "    for i in range(labels.shape[1]):  # Loop through each column (multi-output)\n",
    "        prec, rec, f1_micro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='micro', zero_division=0\n",
    "        )\n",
    "        _, _, f1_macro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='macro', zero_division=0\n",
    "        )\n",
    "\n",
    "        precision_list.append(prec)\n",
    "        recall_list.append(rec)\n",
    "        f1_micro_list.append(f1_micro)\n",
    "        f1_macro_list.append(f1_macro)\n",
    "\n",
    "    # Compute average metrics across all outputs\n",
    "    precision = sum(precision_list) / len(precision_list)\n",
    "    recall = sum(recall_list) / len(recall_list)\n",
    "    f1_micro = sum(f1_micro_list) / len(f1_micro_list)\n",
    "    f1_macro = sum(f1_macro_list) / len(f1_macro_list)\n",
    "\n",
    "    # Generate classification report per output\n",
    "    reports = [classification_report(labels[:, i], preds[:, i], target_names=classes, zero_division=0) for i in range(labels.shape[1])]\n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'reports': reports  # Returns list of reports, one for each output label\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dad9404b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:35:30.781332Z",
     "iopub.status.busy": "2025-03-31T04:35:30.781081Z",
     "iopub.status.idle": "2025-03-31T04:35:30.806899Z",
     "shell.execute_reply": "2025-03-31T04:35:30.806145Z"
    },
    "papermill": {
     "duration": 0.039332,
     "end_time": "2025-03-31T04:35:30.808236",
     "exception": false,
     "start_time": "2025-03-31T04:35:30.768904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, aspect_metrics, sentiment_metrics, metrics, trials, seed):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=len(train_labels),\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    )\n",
    "\n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in aspect_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    aspect_optimizer = torch.optim.AdamW(aspect_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Define DataLoaders\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    aspect_train_loader, aspect_val_loader, aspect_train_dataset, aspect_val_dataset = build_aspect_dataset(current_X_train, current_y_train, X_val, y_val, sequence_length)\n",
    "\n",
    "    # Prepare everything with Accelerator\n",
    "    aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader = accelerator.prepare(\n",
    "        aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader\n",
    "    )\n",
    "\n",
    "    aspect_result = None\n",
    "    start_time = time.time()\n",
    "\n",
    "    # ASPECT DETECTION\n",
    "    accelerator.print(\"ASPECT DETECTION\")\n",
    "    for epoch in range(epochs):\n",
    "        aspect_model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in aspect_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            aspect_optimizer.zero_grad()\n",
    "            outputs = aspect_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            aspect_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        aspect_model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in aspect_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = aspect_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}),\n",
    "            None,\n",
    "            aspect_list,\n",
    "        )\n",
    "\n",
    "        if aspect_result is None or result['f1_micro'] >= aspect_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(aspect_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'{filename}-aspect-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "            aspect_result = result\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(aspect_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    accelerator.print(f\"\\nAspect detection accuracy: {round(aspect_result['accuracy'], 4)}, F1 Micro: {round(aspect_result['f1_micro'], 4)}, F1 Macro: {round(aspect_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(aspect_result['report'])\n",
    "\n",
    "    best_aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{trials + 1}-model')\n",
    "    best_aspect_model = accelerator.prepare(best_aspect_model)\n",
    "\n",
    "    # SENTIMENT ANALYSIS ON NON NEUTRAL ASPECTS\n",
    "    accelerator.print(\"--------------------------------------------------\")\n",
    "    accelerator.print(\"SENTIMENT ANALYSIS\")\n",
    "\n",
    "    sentiment_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=2,\n",
    "    )\n",
    "    sentiment_optimizer = torch.optim.AdamW(sentiment_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "\n",
    "    for name, param in sentiment_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    sentiment_train_loader, sentiment_val_loader, sentiment_train_dataset, sentiment_val_dataset = build_sentiment_dataset(\n",
    "        device, aspect_train_dataset, aspect_val_dataset, best_aspect_model, tokenizer, max_length=sequence_length\n",
    "    )\n",
    "    sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader = accelerator.prepare(\n",
    "        sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader\n",
    "    )\n",
    "    sentiment_result = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        sentiment_model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch in sentiment_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            sentiment_optimizer.zero_grad()\n",
    "            outputs = sentiment_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            sentiment_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        sentiment_model.eval()\n",
    "        sentiment_val_outputs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in sentiment_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                \n",
    "                outputs = sentiment_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                for i in range(len(preds)):\n",
    "                    val_output = {\n",
    "                        'label': batch['labels'][i],\n",
    "                        'aspect': batch['aspect'][i],\n",
    "                        'ori_indices': batch['ori_indices'][i],\n",
    "                        'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                    }\n",
    "                    sentiment_val_outputs.append(val_output)\n",
    "\n",
    "        sentiment_val_outputs = accelerator.gather_for_metrics(sentiment_val_outputs)\n",
    "        unique_val_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_val_outputs}\n",
    "        sentiment_val_outputs = list(unique_val_outputs.values())\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': [item['pred'] for item in sentiment_val_outputs], 'label_ids': [np.argmax(item['label'].cpu().numpy()) for item in sentiment_val_outputs]}),\n",
    "            [0, 1],\n",
    "            ['negative', 'positive']\n",
    "        )\n",
    "\n",
    "        if sentiment_result is None or result['f1_micro'] >= sentiment_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            sentiment_result = result\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(sentiment_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                 f'{filename}-sentiment-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(sentiment_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "\n",
    "    accelerator.print(f\"\\nSentiment analysis accuracy: {round(sentiment_result['accuracy'], 4)}, F1 Micro: {round(sentiment_result['f1_micro'], 4)}, F1 Macro: {round(sentiment_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(sentiment_result['report'])\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    best_sentiment_model = BertForSequenceClassification.from_pretrained( f'{filename}-sentiment-{trials + 1}-model')\n",
    "    best_sentiment_model = accelerator.prepare(best_sentiment_model)\n",
    "\n",
    "    # Compute overall metrics\n",
    "    aspect_labels = []\n",
    "    aspect_indices = []\n",
    "    aspect_preds = []\n",
    "\n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = []\n",
    "    \n",
    "    best_aspect_model.eval()\n",
    "    best_sentiment_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in aspect_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = best_aspect_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            aspect_indices.append(accelerator.gather(batch['ori_indices']))\n",
    "            aspect_labels.append(accelerator.gather(batch['ori_label']))\n",
    "            aspect_preds.append(accelerator.gather(preds))\n",
    "\n",
    "        aspect_indices = torch.cat(aspect_indices).cpu().numpy()\n",
    "        aspect_labels = torch.cat(aspect_labels).cpu().numpy()\n",
    "        aspect_preds = torch.cat(aspect_preds).cpu().numpy()\n",
    "\n",
    "        accelerator.wait_for_everyone()\n",
    "        aspect_outputs = [\n",
    "            {'ori_indices': aspect_indices[i], \n",
    "             'ori_labels': aspect_labels[i], \n",
    "             'pred': aspect_preds[i]}\n",
    "            for i in range(len(aspect_preds))\n",
    "        ]\n",
    "        aspect_outputs = {x['ori_indices'].item(): x for x in aspect_outputs}\n",
    "    \n",
    "        for batch in sentiment_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = best_sentiment_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "    \n",
    "            for i in range(len(preds)):\n",
    "                output = {\n",
    "                    'aspect': batch['aspect'][i],\n",
    "                    'ori_indices': batch['ori_indices'][i],\n",
    "                    'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                }\n",
    "                sentiment_outputs.append(output)\n",
    "\n",
    "        sentiment_outputs = accelerator.gather_for_metrics(sentiment_outputs)\n",
    "        sentiment_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_outputs}\n",
    "\n",
    "    # Replcae non neutral aspect to its predicted sentiment\n",
    "    accelerator.wait_for_everyone()\n",
    "    if accelerator.is_main_process:\n",
    "        i = -1\n",
    "        for (ori_index, aspect), value in sentiment_outputs.items():\n",
    "            aspect = aspect_mapping[aspect]\n",
    "            aspect_outputs[ori_index]['pred'][aspect] = 2 if value['pred'] == 1.0 else value['pred']\n",
    "\n",
    "        result = compute_metrics_overall(\n",
    "            type('EvalOutput', (object,), {'predictions': [output['pred'] for output in aspect_outputs.values()], 'label_ids': [output['ori_labels'] for output in aspect_outputs.values()]}),\n",
    "            ['negative', 'neutral', 'positive'],\n",
    "        )\n",
    "\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        accelerator.print(f\"Iteration {current_train_size}: Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        for i in range(len(train_labels)):\n",
    "            accelerator.print(f\"Aspect {aspect_list[i]} report:\")\n",
    "            accelerator.print(result['reports'][i])\n",
    "       \n",
    "        \n",
    "        aspect_metrics[0].append(aspect_result['accuracy'])\n",
    "        aspect_metrics[1].append(aspect_result['f1_micro'])\n",
    "        aspect_metrics[2].append(aspect_result['f1_macro'])\n",
    "        sentiment_metrics[0].append(sentiment_result['accuracy'])\n",
    "        sentiment_metrics[1].append(sentiment_result['f1_micro'])\n",
    "        sentiment_metrics[2].append(sentiment_result['f1_macro'])\n",
    "        metrics[0].append(current_train_size)\n",
    "        metrics[1].append(result['accuracy'])\n",
    "        metrics[2].append(result['f1_micro'])\n",
    "        metrics[3].append(result['f1_macro'])\n",
    "        \n",
    "    accelerator.print(f\"Total train time: {duration} s\")\n",
    "    accelerator.end_training()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c27643",
   "metadata": {
    "papermill": {
     "duration": 0.011386,
     "end_time": "2025-03-31T04:35:30.831200",
     "exception": false,
     "start_time": "2025-03-31T04:35:30.819814",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PLOT THE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df46306c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:35:30.854989Z",
     "iopub.status.busy": "2025-03-31T04:35:30.854762Z",
     "iopub.status.idle": "2025-03-31T04:35:30.859849Z",
     "shell.execute_reply": "2025-03-31T04:35:30.859114Z"
    },
    "papermill": {
     "duration": 0.018474,
     "end_time": "2025-03-31T04:35:30.861034",
     "exception": false,
     "start_time": "2025-03-31T04:35:30.842560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04dd9bd",
   "metadata": {
    "papermill": {
     "duration": 0.01129,
     "end_time": "2025-03-31T04:35:30.883743",
     "exception": false,
     "start_time": "2025-03-31T04:35:30.872453",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QUERY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6d88d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:35:30.907679Z",
     "iopub.status.busy": "2025-03-31T04:35:30.907464Z",
     "iopub.status.idle": "2025-03-31T04:35:30.923705Z",
     "shell.execute_reply": "2025-03-31T04:35:30.922904Z"
    },
    "papermill": {
     "duration": 0.029619,
     "end_time": "2025-03-31T04:35:30.924934",
     "exception": false,
     "start_time": "2025-03-31T04:35:30.895315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def coreset_sampling(aspect_model, sentiment_model, farthest_point, X_pool, train_indices, remaining_indices, sampling_dur, new_samples, trials, n_samples=min_increment):\n",
    "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model.to(device)\n",
    "    aspect_model.eval()\n",
    "    sentiment_model.to(device)\n",
    "    sentiment_model.eval()\n",
    "\n",
    "    farthest_data = farthest_point.value\n",
    "    if farthest_data is not None:\n",
    "        X_pool.append(farthest_data)\n",
    "        \n",
    "    current_train_size = len(train_indices)\n",
    "    aspect_dataset = AspectDetectionDataset(\n",
    "        X_pool,\n",
    "        [['neut' for i in range(len(train_labels))] for x in range(len(X_pool))], \n",
    "        label_mapping, \n",
    "        tokenizer, \n",
    "        max_length=sequence_length\n",
    "    )\n",
    "    aspect_loader = DataLoader(\n",
    "        aspect_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = {}\n",
    "\n",
    "    aspects = []\n",
    "    data = []\n",
    "    labels = []\n",
    "    indices = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Pass through aspect detction model\n",
    "    for batch in aspect_loader:\n",
    "        token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "        input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "        attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = aspect_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).logits\n",
    "            embeddings = aspect_model.base_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "\n",
    "        for i in range(len(outputs)):\n",
    "            aspect_outputs[batch['ori_indices'][i].item()] = embeddings.last_hidden_state[i].mean(dim=1).cpu().numpy()\n",
    "            \n",
    "            for j in range(len(outputs[i])):\n",
    "                if int(outputs[i][j].round()) != 1:\n",
    "                    aspects.append(aspect_list[j])\n",
    "                    data.append(batch['ori_text'][i])\n",
    "                    labels.append(batch['ori_label'][i][j])\n",
    "                    indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    if len(data) > 0:\n",
    "        sentiment_dataset = SentimentAnalysisDataset(data, labels, aspects, indices, label_mapping, tokenizer, max_length=sequence_length)\n",
    "        sentiment_loader = torch.utils.data.DataLoader(\n",
    "            sentiment_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4,\n",
    "        )\n",
    "    \n",
    "        # Pass through sentiment analysis model\n",
    "        for batch in sentiment_loader:\n",
    "            token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "            input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "            attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                outputs = sentiment_model.base_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "    \n",
    "            for i in range(len(outputs.last_hidden_state)):\n",
    "                ori_index = batch['ori_indices'][i].item()\n",
    "                if ori_index in sentiment_outputs.keys():\n",
    "                    sentiment_outputs[ori_index].append(outputs.last_hidden_state[i].mean(dim=1).cpu().numpy())\n",
    "                else:\n",
    "                    sentiment_outputs[ori_index] = [outputs.last_hidden_state[i].mean(dim=1).cpu().numpy()]\n",
    "\n",
    "    for key, val in sentiment_outputs.items():\n",
    "        sentiment_outputs[key] = np.mean(val, axis=0)\n",
    "\n",
    "    if accelerator.is_main_process:\n",
    "        aspect_outputs = dict(sorted(aspect_outputs.items()))\n",
    "\n",
    "        if len(data) > 0:\n",
    "            for key, val in sentiment_outputs.items():\n",
    "                aspect_outputs[key] = np.mean([val, aspect_outputs[key]], axis=0)\n",
    "\n",
    "        embeddings = np.array(list(aspect_outputs.values()))\n",
    "        distance_matrix = pairwise_distances(embeddings)\n",
    "        selected_indices = distance_matrix.shape[0] - 1 if farthest_data is not None else 0\n",
    "\n",
    "        # Calculate the minimum distance from selected points to all other points\n",
    "        min_distances = distance_matrix[selected_indices]\n",
    "\n",
    "        sorted_dist = np.argsort(min_distances)\n",
    "        sorted_dist = sorted_dist[::-1]\n",
    "        farthest_point.value = aspect_dataset[sorted_dist[0]]['ori_text']\n",
    "\n",
    "        threshold = np.percentile(min_distances, 90)\n",
    "        candidates = np.where(min_distances >= threshold)[0]  # Select the point farthest from the current set\n",
    "        num_of_candidates = len(candidates)\n",
    "    \n",
    "        # Check nearest checkpoint\n",
    "        nearest_cp = 0\n",
    "        for cp in checkpoints:\n",
    "            if cp > current_train_size:\n",
    "                nearest_cp = cp\n",
    "                break\n",
    "                \n",
    "        # Determine number of maximum samples to be acquired\n",
    "        if num_of_candidates <= n_samples and n_samples < nearest_cp - current_train_size:\n",
    "            selected_indices = sorted_dist[:n_samples]\n",
    "        elif num_of_candidates > n_samples and num_of_candidates < nearest_cp - current_train_size:\n",
    "             selected_indices = sorted_dist[:max(n_samples, min(math.ceil(0.1*len(sorted_dist)), num_of_candidates))]\n",
    "        else:\n",
    "            selected_indices = sorted_dist[:nearest_cp - current_train_size]\n",
    "            \n",
    "            temp = train_indices.copy()\n",
    "            temp.extend([remaining_indices[i] for i in selected_indices])\n",
    "            \n",
    "            # Save acquired data up to checkpoint\n",
    "            acquired_data = pd.DataFrame({\n",
    "                'processed_text': [X_train[i] for i in temp],\n",
    "                'ac': [y_train[i][0] for i in temp],\n",
    "                'air_panas': [y_train[i][1] for i in temp],\n",
    "                'bau': [y_train[i][2] for i in temp],\n",
    "                'general': [y_train[i][3] for i in temp],\n",
    "                'kebersihan': [y_train[i][4] for i in temp],\n",
    "                'linen': [y_train[i][5] for i in temp],\n",
    "                'service': [y_train[i][6] for i in temp],\n",
    "                'sunrise_meal': [y_train[i][7] for i in temp],\n",
    "                'tv': [y_train[i][8] for i in temp],\n",
    "                'wifi': [y_train[i][9] for i in temp],\n",
    "            })\n",
    "            acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "\n",
    "        end_time = time.time() \n",
    "        duration = end_time - start_time\n",
    "\n",
    "        sampling_dur.append(duration)\n",
    "        for i in selected_indices:\n",
    "            new_samples.append(remaining_indices[i])\n",
    "        \n",
    "        print(\"Nearest checkpoint:\", nearest_cp)\n",
    "        print(\"Threshold:\", threshold)\n",
    "        print(\"Acquired samples:\", len(selected_indices))\n",
    "        print(f\"Sampling duration: {duration} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc14e283",
   "metadata": {
    "papermill": {
     "duration": 0.011215,
     "end_time": "2025-03-31T04:35:30.947651",
     "exception": false,
     "start_time": "2025-03-31T04:35:30.936436",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "255c0ab8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:35:30.971265Z",
     "iopub.status.busy": "2025-03-31T04:35:30.971044Z",
     "iopub.status.idle": "2025-03-31T04:35:30.980106Z",
     "shell.execute_reply": "2025-03-31T04:35:30.979508Z"
    },
    "papermill": {
     "duration": 0.022368,
     "end_time": "2025-03-31T04:35:30.981392",
     "exception": false,
     "start_time": "2025-03-31T04:35:30.959024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i):\n",
    "    aspect_accuracies = manager.list()\n",
    "    aspect_f1_micros = manager.list()\n",
    "    aspect_f1_macros = manager.list()\n",
    "    sentiment_accuracies = manager.list()\n",
    "    sentiment_f1_micros = manager.list()\n",
    "    sentiment_f1_macros = manager.list()\n",
    "    accuracies = manager.list()\n",
    "    f1_micros = manager.list()\n",
    "    f1_macros = manager.list()\n",
    "    data_used = manager.list()\n",
    "    sampling_dur = manager.list()\n",
    "    new_samples = manager.list()\n",
    "\n",
    "    set_seed(seed)\n",
    "    \n",
    "    print(\"===============================================\")\n",
    "    print(\"TRIAL {}\".format(i+1))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        # Train the model\n",
    "        args = (\n",
    "            current_train_size, \n",
    "            train_indices, \n",
    "            (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "            (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "            (data_used, accuracies, f1_micros, f1_macros), \n",
    "            i,\n",
    "            seed\n",
    "        )\n",
    "        notebook_launcher(train_model, args, num_processes=2)\n",
    "\n",
    "        aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{i+1}-model')\n",
    "        sentiment_model = BertForSequenceClassification.from_pretrained(f'{filename}-sentiment-{i+1}-model')\n",
    "    \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples = manager.list()\n",
    "        sampling_args = (\n",
    "            aspect_model, \n",
    "            sentiment_model, \n",
    "            farthest_point,\n",
    "            [X_train[i] for i in remaining_indices], \n",
    "            train_indices, \n",
    "            remaining_indices, \n",
    "            sampling_dur, \n",
    "            new_samples, \n",
    "            i\n",
    "        )\n",
    "        notebook_launcher(coreset_sampling, sampling_args, num_processes=2)\n",
    "        new_samples = list(new_samples)\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    args = (\n",
    "        current_train_size, \n",
    "        train_indices, \n",
    "        (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "        (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "        (data_used, accuracies, f1_micros, f1_macros), \n",
    "        i,\n",
    "        seed\n",
    "    )\n",
    "    notebook_launcher(train_model, args, num_processes=2)\n",
    "    data_used, accuracies, f1_micros, f1_macros, sampling_dur = list(data_used), list(accuracies), list(f1_micros), list(f1_macros), list(sampling_dur)\n",
    "    aspect_accuracies, aspect_f1_micros, aspect_f1_macros = list(aspect_accuracies), list(aspect_f1_micros), list(aspect_f1_macros)\n",
    "    sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros = list(sentiment_accuracies), list(sentiment_f1_micros), list(sentiment_f1_macros)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    # print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Aspect Accuracy': aspect_accuracies,\n",
    "        'Aspect F1 Micro': aspect_f1_micros,\n",
    "        'Aspect F1 Macro': aspect_f1_macros,\n",
    "        'Sentiment Accuracy': sentiment_accuracies,\n",
    "        'Sentiment F1 Micro': sentiment_f1_micros,\n",
    "        'Sentiment F1 Macro': sentiment_f1_macros,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    \n",
    "    sampling_dur.insert(0, 0)\n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    results.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c60e30d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:35:31.005395Z",
     "iopub.status.busy": "2025-03-31T04:35:31.005189Z",
     "iopub.status.idle": "2025-03-31T04:35:31.008100Z",
     "shell.execute_reply": "2025-03-31T04:35:31.007492Z"
    },
    "papermill": {
     "duration": 0.01599,
     "end_time": "2025-03-31T04:35:31.009257",
     "exception": false,
     "start_time": "2025-03-31T04:35:30.993267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [50, 81, 14, 3, 94]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9a92ce",
   "metadata": {
    "papermill": {
     "duration": 0.011252,
     "end_time": "2025-03-31T04:35:31.031942",
     "exception": false,
     "start_time": "2025-03-31T04:35:31.020690",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e624308c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:35:31.055745Z",
     "iopub.status.busy": "2025-03-31T04:35:31.055548Z",
     "iopub.status.idle": "2025-03-31T06:55:43.997247Z",
     "shell.execute_reply": "2025-03-31T06:55:43.996404Z"
    },
    "papermill": {
     "duration": 8412.9554,
     "end_time": "2025-03-31T06:55:43.998837",
     "exception": false,
     "start_time": "2025-03-31T04:35:31.043437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 1\n",
      "Random seed: 50\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c7ab7169f2404c84a96f3d6311261e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5865, Accuracy: 0.7995, F1 Micro: 0.8876, F1 Macro: 0.8805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4747, Accuracy: 0.801, F1 Micro: 0.8892, F1 Macro: 0.8841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4337, Accuracy: 0.8007, F1 Micro: 0.8893, F1 Macro: 0.8848\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.425, Accuracy: 0.8033, F1 Micro: 0.8905, F1 Macro: 0.8856\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4065, Accuracy: 0.8064, F1 Micro: 0.8916, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4121, Accuracy: 0.8101, F1 Micro: 0.8933, F1 Macro: 0.8874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3857, Accuracy: 0.8177, F1 Micro: 0.8971, F1 Macro: 0.8914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3725, Accuracy: 0.8321, F1 Micro: 0.9044, F1 Macro: 0.8994\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3428, Accuracy: 0.841, F1 Micro: 0.9088, F1 Macro: 0.9042\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3197, Accuracy: 0.8507, F1 Micro: 0.9137, F1 Macro: 0.9092\n",
      "\n",
      "Aspect detection accuracy: 0.8507, F1 Micro: 0.9137, F1 Macro: 0.9092\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.84      1.00      0.91       462\n",
      "   air_panas       0.84      1.00      0.91       480\n",
      "         bau       0.86      1.00      0.93       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.80      0.85      0.83       317\n",
      "       linen       0.71      0.99      0.83       392\n",
      "     service       0.88      0.97      0.93       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.90      1.00      0.95       516\n",
      "        wifi       0.86      1.00      0.93       498\n",
      "\n",
      "   micro avg       0.85      0.99      0.91      4614\n",
      "   macro avg       0.85      0.98      0.91      4614\n",
      "weighted avg       0.85      0.99      0.91      4614\n",
      " samples avg       0.85      0.99      0.91      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6014, Accuracy: 0.6293, F1 Micro: 0.6293, F1 Macro: 0.3862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5503, Accuracy: 0.6293, F1 Micro: 0.6293, F1 Macro: 0.3862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4934, Accuracy: 0.6293, F1 Micro: 0.6293, F1 Macro: 0.3862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3898, Accuracy: 0.6878, F1 Micro: 0.6878, F1 Macro: 0.5444\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3441, Accuracy: 0.7488, F1 Micro: 0.7488, F1 Macro: 0.6959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2311, Accuracy: 0.7634, F1 Micro: 0.7634, F1 Macro: 0.719\n",
      "Epoch 7/10, Train Loss: 0.181, Accuracy: 0.7439, F1 Micro: 0.7439, F1 Macro: 0.6915\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2402, Accuracy: 0.7756, F1 Micro: 0.7756, F1 Macro: 0.7399\n",
      "Epoch 9/10, Train Loss: 0.1526, Accuracy: 0.7512, F1 Micro: 0.7512, F1 Macro: 0.6996\n",
      "Epoch 10/10, Train Loss: 0.1164, Accuracy: 0.7537, F1 Micro: 0.7537, F1 Macro: 0.7047\n",
      "\n",
      "Sentiment analysis accuracy: 0.7756, F1 Micro: 0.7756, F1 Macro: 0.7399\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.91      0.84       258\n",
      "    positive       0.78      0.55      0.64       152\n",
      "\n",
      "    accuracy                           0.78       410\n",
      "   macro avg       0.78      0.73      0.74       410\n",
      "weighted avg       0.78      0.78      0.76       410\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 142: Accuracy: 0.8419, F1 Micro: 0.8419, F1 Macro: 0.4131\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.27      0.42        97\n",
      "     neutral       0.84      1.00      0.91       459\n",
      "    positive       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.59      0.42      0.44       571\n",
      "weighted avg       0.84      0.85      0.81       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.01      0.02        86\n",
      "     neutral       0.83      1.00      0.91       475\n",
      "    positive       1.00      0.10      0.18        10\n",
      "\n",
      "    accuracy                           0.84       571\n",
      "   macro avg       0.94      0.37      0.37       571\n",
      "weighted avg       0.86      0.84      0.76       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        78\n",
      "     neutral       0.86      1.00      0.92       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.74      0.86      0.80       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.69      0.71       200\n",
      "     neutral       0.80      0.85      0.83       315\n",
      "    positive       0.43      0.38      0.40        56\n",
      "\n",
      "    accuracy                           0.75       571\n",
      "   macro avg       0.66      0.64      0.65       571\n",
      "weighted avg       0.74      0.75      0.75       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.18      0.30       162\n",
      "     neutral       0.71      0.99      0.83       387\n",
      "    positive       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.72       571\n",
      "   macro avg       0.52      0.39      0.37       571\n",
      "weighted avg       0.72      0.72      0.64       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.48      0.59        85\n",
      "     neutral       0.88      0.98      0.93       418\n",
      "    positive       0.76      0.62      0.68        68\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.80      0.69      0.73       571\n",
      "weighted avg       0.85      0.86      0.85       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.89      1.00      0.94       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.30      0.33      0.31       571\n",
      "weighted avg       0.80      0.89      0.85       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        74\n",
      "     neutral       0.87      1.00      0.93       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.80       571\n",
      "\n",
      "Total train time: 81.4811270236969 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.006963421870023012\n",
      "Acquired samples: 215\n",
      "Sampling duration: 51.95136117935181 seconds\n",
      "New train size: 357\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5657, Accuracy: 0.8062, F1 Micro: 0.8911, F1 Macro: 0.8843\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5232, Accuracy: 0.8142, F1 Micro: 0.8955, F1 Macro: 0.8905\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5029, Accuracy: 0.8319, F1 Micro: 0.9027, F1 Macro: 0.8952\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4491, Accuracy: 0.8422, F1 Micro: 0.9091, F1 Macro: 0.903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4193, Accuracy: 0.8646, F1 Micro: 0.921, F1 Macro: 0.9158\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.362, Accuracy: 0.8911, F1 Micro: 0.9353, F1 Macro: 0.9306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3234, Accuracy: 0.8984, F1 Micro: 0.9393, F1 Macro: 0.9354\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2718, Accuracy: 0.9087, F1 Micro: 0.9449, F1 Macro: 0.9412\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2524, Accuracy: 0.9208, F1 Micro: 0.9519, F1 Macro: 0.948\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2125, Accuracy: 0.926, F1 Micro: 0.9551, F1 Macro: 0.9512\n",
      "\n",
      "Aspect detection accuracy: 0.926, F1 Micro: 0.9551, F1 Macro: 0.9512\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.93      1.00      0.96       480\n",
      "         bau       0.92      0.99      0.95       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.88      0.85      0.87       317\n",
      "       linen       0.82      0.99      0.90       392\n",
      "     service       0.96      0.96      0.96       423\n",
      "sunrise_meal       0.95      1.00      0.97       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.93      0.98      0.96      4614\n",
      "   macro avg       0.93      0.98      0.95      4614\n",
      "weighted avg       0.93      0.98      0.96      4614\n",
      " samples avg       0.93      0.98      0.95      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5896, Accuracy: 0.7203, F1 Micro: 0.7203, F1 Macro: 0.434\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4363, Accuracy: 0.8165, F1 Micro: 0.8165, F1 Macro: 0.7526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3608, Accuracy: 0.8381, F1 Micro: 0.8381, F1 Macro: 0.7685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2914, Accuracy: 0.8562, F1 Micro: 0.8562, F1 Macro: 0.8026\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2406, Accuracy: 0.8709, F1 Micro: 0.8709, F1 Macro: 0.8285\n",
      "Epoch 6/10, Train Loss: 0.1783, Accuracy: 0.8652, F1 Micro: 0.8652, F1 Macro: 0.8087\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1747, Accuracy: 0.8743, F1 Micro: 0.8743, F1 Macro: 0.8258\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.11, Accuracy: 0.8845, F1 Micro: 0.8845, F1 Macro: 0.8479\n",
      "Epoch 9/10, Train Loss: 0.1309, Accuracy: 0.8652, F1 Micro: 0.8652, F1 Macro: 0.808\n",
      "Epoch 10/10, Train Loss: 0.082, Accuracy: 0.88, F1 Micro: 0.88, F1 Macro: 0.8391\n",
      "\n",
      "Sentiment analysis accuracy: 0.8845, F1 Micro: 0.8845, F1 Macro: 0.8479\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.92       632\n",
      "    positive       0.87      0.69      0.77       251\n",
      "\n",
      "    accuracy                           0.88       883\n",
      "   macro avg       0.88      0.83      0.85       883\n",
      "weighted avg       0.88      0.88      0.88       883\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 357: Accuracy: 0.9193, F1 Micro: 0.9193, F1 Macro: 0.7346\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.91      0.93        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.87      0.87      0.87        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.60      0.74        86\n",
      "     neutral       0.93      1.00      0.96       475\n",
      "    positive       0.50      0.40      0.44        10\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.79      0.67      0.71       571\n",
      "weighted avg       0.93      0.93      0.92       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.49      0.63        78\n",
      "     neutral       0.92      0.99      0.95       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.60      0.49      0.53       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       1.00      0.03      0.06        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.62      0.34      0.33       571\n",
      "weighted avg       0.88      0.87      0.82       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.78      0.79       200\n",
      "     neutral       0.88      0.85      0.87       315\n",
      "    positive       0.73      0.95      0.82        56\n",
      "\n",
      "    accuracy                           0.84       571\n",
      "   macro avg       0.80      0.86      0.83       571\n",
      "weighted avg       0.84      0.84      0.84       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.57      0.70       162\n",
      "     neutral       0.82      0.99      0.90       387\n",
      "    positive       0.57      0.18      0.28        22\n",
      "\n",
      "    accuracy                           0.84       571\n",
      "   macro avg       0.77      0.58      0.63       571\n",
      "weighted avg       0.84      0.84      0.82       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.76      0.78        85\n",
      "     neutral       0.95      0.96      0.96       418\n",
      "    positive       0.84      0.87      0.86        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.87      0.86      0.87       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.17      0.29        29\n",
      "     neutral       0.95      1.00      0.97       525\n",
      "    positive       0.85      0.65      0.73        17\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.88      0.61      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.85      0.90        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.95      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.89      0.93        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.96      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 130.0022256374359 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.008915056660771371\n",
      "Acquired samples: 193\n",
      "Sampling duration: 57.724971771240234 seconds\n",
      "New train size: 550\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5227, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4471, Accuracy: 0.829, F1 Micro: 0.9017, F1 Macro: 0.8962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4188, Accuracy: 0.8552, F1 Micro: 0.916, F1 Macro: 0.9115\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.354, Accuracy: 0.8807, F1 Micro: 0.9297, F1 Macro: 0.9251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2972, Accuracy: 0.9012, F1 Micro: 0.9411, F1 Macro: 0.9376\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2497, Accuracy: 0.9167, F1 Micro: 0.9497, F1 Macro: 0.9466\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2176, Accuracy: 0.9241, F1 Micro: 0.9541, F1 Macro: 0.9511\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1878, Accuracy: 0.9365, F1 Micro: 0.9612, F1 Macro: 0.958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1627, Accuracy: 0.9401, F1 Micro: 0.9633, F1 Macro: 0.96\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1421, Accuracy: 0.9422, F1 Micro: 0.9646, F1 Macro: 0.9612\n",
      "\n",
      "Aspect detection accuracy: 0.9422, F1 Micro: 0.9646, F1 Macro: 0.9612\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.96      0.99      0.97       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.90      0.99      0.94       500\n",
      "  kebersihan       0.90      0.88      0.89       317\n",
      "       linen       0.87      0.98      0.92       392\n",
      "     service       0.94      0.97      0.96       423\n",
      "sunrise_meal       0.95      1.00      0.97       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.95      0.98      0.96      4614\n",
      "   macro avg       0.95      0.98      0.96      4614\n",
      "weighted avg       0.95      0.98      0.96      4614\n",
      " samples avg       0.95      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5328, Accuracy: 0.8035, F1 Micro: 0.8035, F1 Macro: 0.7257\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3269, Accuracy: 0.849, F1 Micro: 0.849, F1 Macro: 0.7936\n",
      "Epoch 3/10, Train Loss: 0.2422, Accuracy: 0.8418, F1 Micro: 0.8418, F1 Macro: 0.7645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2215, Accuracy: 0.8728, F1 Micro: 0.8728, F1 Macro: 0.8274\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1867, Accuracy: 0.8862, F1 Micro: 0.8862, F1 Macro: 0.8493\n",
      "Epoch 6/10, Train Loss: 0.1195, Accuracy: 0.8738, F1 Micro: 0.8738, F1 Macro: 0.8228\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1312, Accuracy: 0.8935, F1 Micro: 0.8935, F1 Macro: 0.8598\n",
      "Epoch 8/10, Train Loss: 0.1021, Accuracy: 0.8842, F1 Micro: 0.8842, F1 Macro: 0.8388\n",
      "Epoch 9/10, Train Loss: 0.0758, Accuracy: 0.8811, F1 Micro: 0.8811, F1 Macro: 0.8347\n",
      "Epoch 10/10, Train Loss: 0.0518, Accuracy: 0.8842, F1 Micro: 0.8842, F1 Macro: 0.8448\n",
      "\n",
      "Sentiment analysis accuracy: 0.8935, F1 Micro: 0.8935, F1 Macro: 0.8598\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93       698\n",
      "    positive       0.87      0.72      0.79       269\n",
      "\n",
      "    accuracy                           0.89       967\n",
      "   macro avg       0.89      0.84      0.86       967\n",
      "weighted avg       0.89      0.89      0.89       967\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 550: Accuracy: 0.9349, F1 Micro: 0.9349, F1 Macro: 0.7674\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.89      0.92        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.96      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.74      0.83        86\n",
      "     neutral       0.96      0.99      0.97       475\n",
      "    positive       0.40      0.40      0.40        10\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.77      0.71      0.73       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.74      0.79        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.57      0.59       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.90      0.99      0.94       496\n",
      "    positive       0.84      0.31      0.45        68\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.58      0.43      0.47       571\n",
      "weighted avg       0.88      0.90      0.87       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83       200\n",
      "     neutral       0.90      0.88      0.89       315\n",
      "    positive       0.79      0.93      0.85        56\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.84      0.88      0.86       571\n",
      "weighted avg       0.87      0.87      0.87       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.70      0.79       162\n",
      "     neutral       0.87      0.98      0.92       387\n",
      "    positive       0.62      0.23      0.33        22\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.80      0.64      0.68       571\n",
      "weighted avg       0.87      0.87      0.86       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.72      0.79        85\n",
      "     neutral       0.94      0.98      0.96       418\n",
      "    positive       0.86      0.88      0.87        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.90      0.86      0.87       571\n",
      "weighted avg       0.93      0.93      0.92       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.17      0.29        29\n",
      "     neutral       0.95      1.00      0.97       525\n",
      "    positive       0.80      0.71      0.75        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.63      0.67       571\n",
      "weighted avg       0.95      0.95      0.93       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.91      0.93        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       0.75      1.00      0.86         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.90      0.97      0.93       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.90      0.98      0.93       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 154.71610951423645 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.006838974868878723\n",
      "Acquired samples: 174\n",
      "Sampling duration: 54.44733023643494 seconds\n",
      "New train size: 724\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5227, Accuracy: 0.8099, F1 Micro: 0.8933, F1 Macro: 0.8876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4668, Accuracy: 0.8441, F1 Micro: 0.9094, F1 Macro: 0.9031\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4017, Accuracy: 0.8847, F1 Micro: 0.9316, F1 Macro: 0.9268\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3207, Accuracy: 0.9083, F1 Micro: 0.9452, F1 Macro: 0.9428\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2603, Accuracy: 0.926, F1 Micro: 0.9552, F1 Macro: 0.9524\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.217, Accuracy: 0.9351, F1 Micro: 0.9604, F1 Macro: 0.9575\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1882, Accuracy: 0.9411, F1 Micro: 0.964, F1 Macro: 0.961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1664, Accuracy: 0.9434, F1 Micro: 0.9653, F1 Macro: 0.9623\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1466, Accuracy: 0.947, F1 Micro: 0.9674, F1 Macro: 0.9642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1273, Accuracy: 0.9479, F1 Micro: 0.9679, F1 Macro: 0.9647\n",
      "\n",
      "Aspect detection accuracy: 0.9479, F1 Micro: 0.9679, F1 Macro: 0.9647\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.95      1.00      0.97       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.92      0.99      0.95       500\n",
      "  kebersihan       0.91      0.89      0.90       317\n",
      "       linen       0.89      0.96      0.92       392\n",
      "     service       0.95      0.98      0.97       423\n",
      "sunrise_meal       0.96      1.00      0.98       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      4614\n",
      "   macro avg       0.95      0.98      0.96      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.95      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4953, Accuracy: 0.825, F1 Micro: 0.825, F1 Macro: 0.7773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3501, Accuracy: 0.8559, F1 Micro: 0.8559, F1 Macro: 0.8041\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2456, Accuracy: 0.8638, F1 Micro: 0.8638, F1 Macro: 0.809\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1877, Accuracy: 0.8877, F1 Micro: 0.8877, F1 Macro: 0.8591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1516, Accuracy: 0.8917, F1 Micro: 0.8917, F1 Macro: 0.8567\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0945, Accuracy: 0.8936, F1 Micro: 0.8936, F1 Macro: 0.8614\n",
      "Epoch 7/10, Train Loss: 0.0746, Accuracy: 0.8767, F1 Micro: 0.8767, F1 Macro: 0.8294\n",
      "Epoch 8/10, Train Loss: 0.0494, Accuracy: 0.8877, F1 Micro: 0.8877, F1 Macro: 0.8537\n",
      "Epoch 9/10, Train Loss: 0.0208, Accuracy: 0.8777, F1 Micro: 0.8777, F1 Macro: 0.8434\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0289, Accuracy: 0.8946, F1 Micro: 0.8946, F1 Macro: 0.8612\n",
      "\n",
      "Sentiment analysis accuracy: 0.8946, F1 Micro: 0.8946, F1 Macro: 0.8612\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93       714\n",
      "    positive       0.92      0.70      0.79       292\n",
      "\n",
      "    accuracy                           0.89      1006\n",
      "   macro avg       0.90      0.84      0.86      1006\n",
      "weighted avg       0.90      0.89      0.89      1006\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 724: Accuracy: 0.9415, F1 Micro: 0.9415, F1 Macro: 0.81\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.72      0.82        86\n",
      "     neutral       0.95      1.00      0.97       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.86      0.71      0.77       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.78      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.92      0.99      0.95       496\n",
      "    positive       0.81      0.44      0.57        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.58      0.48      0.51       571\n",
      "weighted avg       0.89      0.91      0.89       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.85      0.85       200\n",
      "     neutral       0.92      0.89      0.90       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.88      0.90      0.89       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.75      0.79       162\n",
      "     neutral       0.89      0.96      0.92       387\n",
      "    positive       0.62      0.23      0.33        22\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.79      0.65      0.68       571\n",
      "weighted avg       0.86      0.87      0.86       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        85\n",
      "     neutral       0.95      0.98      0.97       418\n",
      "    positive       0.91      0.91      0.91        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.88      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.21      0.32        29\n",
      "     neutral       0.96      1.00      0.98       525\n",
      "    positive       0.76      0.76      0.76        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.80      0.66      0.69       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.95      0.96        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 186.12340426445007 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.005790745932608843\n",
      "Acquired samples: 156\n",
      "Sampling duration: 49.442925453186035 seconds\n",
      "New train size: 880\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4991, Accuracy: 0.8106, F1 Micro: 0.894, F1 Macro: 0.8891\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4204, Accuracy: 0.8682, F1 Micro: 0.9223, F1 Macro: 0.9156\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3333, Accuracy: 0.8969, F1 Micro: 0.9388, F1 Macro: 0.9363\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2721, Accuracy: 0.9285, F1 Micro: 0.9565, F1 Macro: 0.9536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2146, Accuracy: 0.9377, F1 Micro: 0.9619, F1 Macro: 0.9591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1836, Accuracy: 0.9429, F1 Micro: 0.9651, F1 Macro: 0.9627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1554, Accuracy: 0.9455, F1 Micro: 0.9666, F1 Macro: 0.9639\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1301, Accuracy: 0.949, F1 Micro: 0.9685, F1 Macro: 0.9654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1158, Accuracy: 0.9502, F1 Micro: 0.9693, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.103, Accuracy: 0.9505, F1 Micro: 0.9695, F1 Macro: 0.9667\n",
      "\n",
      "Aspect detection accuracy: 0.9505, F1 Micro: 0.9695, F1 Macro: 0.9667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.96      1.00      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.93      0.98      0.96       500\n",
      "  kebersihan       0.93      0.90      0.92       317\n",
      "       linen       0.87      0.97      0.92       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.95      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4887, Accuracy: 0.8549, F1 Micro: 0.8549, F1 Macro: 0.8019\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3149, Accuracy: 0.8707, F1 Micro: 0.8707, F1 Macro: 0.8299\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.191, Accuracy: 0.8855, F1 Micro: 0.8855, F1 Macro: 0.848\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1808, Accuracy: 0.8944, F1 Micro: 0.8944, F1 Macro: 0.8625\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1092, Accuracy: 0.8973, F1 Micro: 0.8973, F1 Macro: 0.8658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0713, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.874\n",
      "Epoch 7/10, Train Loss: 0.0571, Accuracy: 0.9013, F1 Micro: 0.9013, F1 Macro: 0.8746\n",
      "Epoch 8/10, Train Loss: 0.0397, Accuracy: 0.8944, F1 Micro: 0.8944, F1 Macro: 0.8618\n",
      "Epoch 9/10, Train Loss: 0.0417, Accuracy: 0.9013, F1 Micro: 0.9013, F1 Macro: 0.871\n",
      "Epoch 10/10, Train Loss: 0.0358, Accuracy: 0.9013, F1 Micro: 0.9013, F1 Macro: 0.8725\n",
      "\n",
      "Sentiment analysis accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93       716\n",
      "    positive       0.92      0.73      0.81       297\n",
      "\n",
      "    accuracy                           0.90      1013\n",
      "   macro avg       0.91      0.85      0.87      1013\n",
      "weighted avg       0.90      0.90      0.90      1013\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 880: Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.7983\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.76      0.84        86\n",
      "     neutral       0.96      1.00      0.98       475\n",
      "    positive       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.89      0.78      0.83       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.74      0.78        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.57      0.58       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.98      0.96       496\n",
      "    positive       0.83      0.56      0.67        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.59      0.51      0.54       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.88      0.86       200\n",
      "     neutral       0.93      0.90      0.92       315\n",
      "    positive       0.88      0.91      0.89        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.89      0.90      0.89       571\n",
      "weighted avg       0.90      0.89      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.69      0.77       162\n",
      "     neutral       0.87      0.97      0.92       387\n",
      "    positive       0.40      0.18      0.25        22\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.72      0.61      0.65       571\n",
      "weighted avg       0.85      0.86      0.85       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.78      0.83        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.89      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.21      0.34        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.90      0.72      0.71       571\n",
      "weighted avg       0.96      0.96      0.94       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 204.79570150375366 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.004750775545835495\n",
      "Acquired samples: 141\n",
      "Sampling duration: 45.208348751068115 seconds\n",
      "New train size: 1021\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5017, Accuracy: 0.8231, F1 Micro: 0.8992, F1 Macro: 0.8926\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4161, Accuracy: 0.8753, F1 Micro: 0.9261, F1 Macro: 0.9202\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3109, Accuracy: 0.9016, F1 Micro: 0.9412, F1 Macro: 0.9382\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2486, Accuracy: 0.9342, F1 Micro: 0.9598, F1 Macro: 0.9568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2025, Accuracy: 0.9405, F1 Micro: 0.9636, F1 Macro: 0.9607\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1655, Accuracy: 0.949, F1 Micro: 0.9686, F1 Macro: 0.9662\n",
      "Epoch 7/10, Train Loss: 0.146, Accuracy: 0.9472, F1 Micro: 0.9677, F1 Macro: 0.9656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1263, Accuracy: 0.9517, F1 Micro: 0.9702, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1091, Accuracy: 0.9576, F1 Micro: 0.9737, F1 Macro: 0.9711\n",
      "Epoch 10/10, Train Loss: 0.0959, Accuracy: 0.9531, F1 Micro: 0.9711, F1 Macro: 0.9684\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9737, F1 Macro: 0.9711\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.94      0.91      0.92       317\n",
      "       linen       0.91      0.96      0.94       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4546, Accuracy: 0.8482, F1 Micro: 0.8482, F1 Macro: 0.8043\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2711, Accuracy: 0.8696, F1 Micro: 0.8696, F1 Macro: 0.8309\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2021, Accuracy: 0.8752, F1 Micro: 0.8752, F1 Macro: 0.8487\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1772, Accuracy: 0.8966, F1 Micro: 0.8966, F1 Macro: 0.8667\n",
      "Epoch 5/10, Train Loss: 0.091, Accuracy: 0.8892, F1 Micro: 0.8892, F1 Macro: 0.8544\n",
      "Epoch 6/10, Train Loss: 0.0893, Accuracy: 0.8957, F1 Micro: 0.8957, F1 Macro: 0.8647\n",
      "Epoch 7/10, Train Loss: 0.0605, Accuracy: 0.8939, F1 Micro: 0.8939, F1 Macro: 0.8633\n",
      "Epoch 8/10, Train Loss: 0.0485, Accuracy: 0.8939, F1 Micro: 0.8939, F1 Macro: 0.8636\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0335, Accuracy: 0.8985, F1 Micro: 0.8985, F1 Macro: 0.8709\n",
      "Epoch 10/10, Train Loss: 0.0198, Accuracy: 0.8948, F1 Micro: 0.8948, F1 Macro: 0.8637\n",
      "\n",
      "Sentiment analysis accuracy: 0.8985, F1 Micro: 0.8985, F1 Macro: 0.8709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93       754\n",
      "    positive       0.91      0.73      0.81       320\n",
      "\n",
      "    accuracy                           0.90      1074\n",
      "   macro avg       0.90      0.85      0.87      1074\n",
      "weighted avg       0.90      0.90      0.90      1074\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1021: Accuracy: 0.951, F1 Micro: 0.951, F1 Macro: 0.8483\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.81      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.79      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.83      0.66      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.55      0.57       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.87       200\n",
      "     neutral       0.93      0.91      0.92       315\n",
      "    positive       0.85      0.95      0.90        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.91      0.90       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.79      0.82       162\n",
      "     neutral       0.91      0.96      0.94       387\n",
      "    positive       0.64      0.41      0.50        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.80      0.72      0.75       571\n",
      "weighted avg       0.88      0.89      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.80      0.85        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.90      0.93      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.90      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.41      0.56        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.78      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.97      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 228.46276664733887 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0042040348052978516\n",
      "Acquired samples: 127\n",
      "Sampling duration: 40.54556941986084 seconds\n",
      "New train size: 1148\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4956, Accuracy: 0.821, F1 Micro: 0.8985, F1 Macro: 0.8927\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3765, Accuracy: 0.8851, F1 Micro: 0.9323, F1 Macro: 0.9289\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2838, Accuracy: 0.9205, F1 Micro: 0.952, F1 Macro: 0.9499\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2231, Accuracy: 0.9342, F1 Micro: 0.96, F1 Macro: 0.958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1822, Accuracy: 0.9484, F1 Micro: 0.9683, F1 Macro: 0.9659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1554, Accuracy: 0.9503, F1 Micro: 0.9694, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1327, Accuracy: 0.9561, F1 Micro: 0.9727, F1 Macro: 0.9699\n",
      "Epoch 8/10, Train Loss: 0.1148, Accuracy: 0.955, F1 Micro: 0.9722, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.093, Accuracy: 0.9595, F1 Micro: 0.975, F1 Macro: 0.9727\n",
      "Epoch 10/10, Train Loss: 0.0855, Accuracy: 0.9573, F1 Micro: 0.9736, F1 Macro: 0.971\n",
      "\n",
      "Aspect detection accuracy: 0.9595, F1 Micro: 0.975, F1 Macro: 0.9727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.95      0.91      0.93       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       0.99      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.433, Accuracy: 0.7905, F1 Micro: 0.7905, F1 Macro: 0.7666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2568, Accuracy: 0.8787, F1 Micro: 0.8787, F1 Macro: 0.8426\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1951, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.8722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1324, Accuracy: 0.9052, F1 Micro: 0.9052, F1 Macro: 0.8773\n",
      "Epoch 5/10, Train Loss: 0.0966, Accuracy: 0.8948, F1 Micro: 0.8948, F1 Macro: 0.8578\n",
      "Epoch 6/10, Train Loss: 0.0696, Accuracy: 0.8948, F1 Micro: 0.8948, F1 Macro: 0.8582\n",
      "Epoch 7/10, Train Loss: 0.0479, Accuracy: 0.89, F1 Micro: 0.89, F1 Macro: 0.85\n",
      "Epoch 8/10, Train Loss: 0.0404, Accuracy: 0.891, F1 Micro: 0.891, F1 Macro: 0.8534\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0414, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8784\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0239, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.877\n",
      "\n",
      "Sentiment analysis accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.877\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       752\n",
      "    positive       0.93      0.73      0.82       303\n",
      "\n",
      "    accuracy                           0.91      1055\n",
      "   macro avg       0.91      0.85      0.88      1055\n",
      "weighted avg       0.91      0.91      0.90      1055\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1148: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.8257\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.83      0.88        86\n",
      "     neutral       0.97      1.00      0.98       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.92      0.77      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.79      0.80        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.59      0.59       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.89      0.60      0.72        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.61      0.53      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.91      0.89       200\n",
      "     neutral       0.95      0.91      0.93       315\n",
      "    positive       0.88      0.91      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.91      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.80      0.84       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       0.69      0.41      0.51        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.83      0.73      0.77       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.79      0.84        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.90      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.38      0.52        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.87      0.75      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.96      0.97        74\n",
      "     neutral       0.99      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 233.7001166343689 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0023173416266217828\n",
      "Acquired samples: 114\n",
      "Sampling duration: 36.92839789390564 seconds\n",
      "New train size: 1262\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4919, Accuracy: 0.8347, F1 Micro: 0.9051, F1 Macro: 0.899\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3737, Accuracy: 0.891, F1 Micro: 0.9355, F1 Macro: 0.9325\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2697, Accuracy: 0.9302, F1 Micro: 0.9576, F1 Macro: 0.9552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2091, Accuracy: 0.9408, F1 Micro: 0.9639, F1 Macro: 0.9613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.175, Accuracy: 0.9458, F1 Micro: 0.9669, F1 Macro: 0.9644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1502, Accuracy: 0.9526, F1 Micro: 0.9707, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1248, Accuracy: 0.9571, F1 Micro: 0.9735, F1 Macro: 0.9711\n",
      "Epoch 8/10, Train Loss: 0.107, Accuracy: 0.9569, F1 Micro: 0.9734, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0933, Accuracy: 0.9582, F1 Micro: 0.9741, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0837, Accuracy: 0.9599, F1 Micro: 0.9751, F1 Macro: 0.9725\n",
      "\n",
      "Aspect detection accuracy: 0.9599, F1 Micro: 0.9751, F1 Macro: 0.9725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.96      0.90      0.93       317\n",
      "       linen       0.91      0.98      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.99       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4035, Accuracy: 0.8601, F1 Micro: 0.8601, F1 Macro: 0.8218\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2812, Accuracy: 0.8795, F1 Micro: 0.8795, F1 Macro: 0.8421\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.177, Accuracy: 0.8897, F1 Micro: 0.8897, F1 Macro: 0.8563\n",
      "Epoch 4/10, Train Loss: 0.1367, Accuracy: 0.8814, F1 Micro: 0.8814, F1 Macro: 0.8435\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.09, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0565, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8815\n",
      "Epoch 7/10, Train Loss: 0.0501, Accuracy: 0.899, F1 Micro: 0.899, F1 Macro: 0.8702\n",
      "Epoch 8/10, Train Loss: 0.0535, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8763\n",
      "Epoch 9/10, Train Loss: 0.0354, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8723\n",
      "Epoch 10/10, Train Loss: 0.0227, Accuracy: 0.899, F1 Micro: 0.899, F1 Macro: 0.8687\n",
      "\n",
      "Sentiment analysis accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8815\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.93       758\n",
      "    positive       0.90      0.77      0.83       321\n",
      "\n",
      "    accuracy                           0.91      1079\n",
      "   macro avg       0.90      0.87      0.88      1079\n",
      "weighted avg       0.91      0.91      0.90      1079\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1262: Accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.8449\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.60      0.60      0.60        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.83      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.76      0.80        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.14      0.20         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.71      0.61      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.91      0.89       200\n",
      "     neutral       0.96      0.90      0.92       315\n",
      "    positive       0.82      0.98      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.93      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.74      0.81       162\n",
      "     neutral       0.90      0.98      0.94       387\n",
      "    positive       0.61      0.50      0.55        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.80      0.74      0.77       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.82      0.85        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.92      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.38      0.52        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.77      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       0.80      0.67      0.73         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.86      0.89       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.96      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 255.5189929008484 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.002766927471384406\n",
      "Acquired samples: 103\n",
      "Sampling duration: 33.64441227912903 seconds\n",
      "New train size: 1365\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4784, Accuracy: 0.8337, F1 Micro: 0.904, F1 Macro: 0.8956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3617, Accuracy: 0.9005, F1 Micro: 0.941, F1 Macro: 0.9389\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2595, Accuracy: 0.9304, F1 Micro: 0.9578, F1 Macro: 0.9556\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2057, Accuracy: 0.9405, F1 Micro: 0.9637, F1 Macro: 0.9615\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1647, Accuracy: 0.9507, F1 Micro: 0.9697, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1374, Accuracy: 0.9583, F1 Micro: 0.9742, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1207, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1037, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.085, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9749\n",
      "Epoch 10/10, Train Loss: 0.076, Accuracy: 0.9604, F1 Micro: 0.9754, F1 Macro: 0.973\n",
      "\n",
      "Aspect detection accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4129, Accuracy: 0.8483, F1 Micro: 0.8483, F1 Macro: 0.7836\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2536, Accuracy: 0.8915, F1 Micro: 0.8915, F1 Macro: 0.8598\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1764, Accuracy: 0.898, F1 Micro: 0.898, F1 Macro: 0.8694\n",
      "Epoch 4/10, Train Loss: 0.1279, Accuracy: 0.8952, F1 Micro: 0.8952, F1 Macro: 0.8651\n",
      "Epoch 5/10, Train Loss: 0.0896, Accuracy: 0.8888, F1 Micro: 0.8888, F1 Macro: 0.8485\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0711, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8771\n",
      "Epoch 7/10, Train Loss: 0.0483, Accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0331, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8785\n",
      "Epoch 9/10, Train Loss: 0.0403, Accuracy: 0.8998, F1 Micro: 0.8998, F1 Macro: 0.8703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0228, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8822\n",
      "\n",
      "Sentiment analysis accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8822\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       773\n",
      "    positive       0.94      0.73      0.83       315\n",
      "\n",
      "    accuracy                           0.91      1088\n",
      "   macro avg       0.92      0.86      0.88      1088\n",
      "weighted avg       0.91      0.91      0.91      1088\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1365: Accuracy: 0.9567, F1 Micro: 0.9567, F1 Macro: 0.8429\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.89        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.57      0.40      0.47        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.76      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.79      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.61      0.59      0.60       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.85      0.65      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.93      0.59      0.65       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.90      0.88       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.91      0.91      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.77      0.45      0.57        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.76      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.84      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.89      0.96      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 272.8935146331787 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.003236520243808627\n",
      "Acquired samples: 62\n",
      "Sampling duration: 30.582130670547485 seconds\n",
      "New train size: 1427\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4787, Accuracy: 0.8377, F1 Micro: 0.9071, F1 Macro: 0.9032\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3479, Accuracy: 0.9069, F1 Micro: 0.9442, F1 Macro: 0.9411\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2447, Accuracy: 0.9363, F1 Micro: 0.9612, F1 Macro: 0.9592\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.196, Accuracy: 0.9464, F1 Micro: 0.9672, F1 Macro: 0.9648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1613, Accuracy: 0.949, F1 Micro: 0.9687, F1 Macro: 0.9659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1383, Accuracy: 0.9556, F1 Micro: 0.9726, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1113, Accuracy: 0.9557, F1 Micro: 0.9728, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1028, Accuracy: 0.959, F1 Micro: 0.9747, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0859, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.975\n",
      "Epoch 10/10, Train Loss: 0.0727, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9734\n",
      "\n",
      "Aspect detection accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.409, Accuracy: 0.8644, F1 Micro: 0.8644, F1 Macro: 0.823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2594, Accuracy: 0.8812, F1 Micro: 0.8812, F1 Macro: 0.8382\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1665, Accuracy: 0.9006, F1 Micro: 0.9006, F1 Macro: 0.8722\n",
      "Epoch 4/10, Train Loss: 0.1205, Accuracy: 0.8979, F1 Micro: 0.8979, F1 Macro: 0.8651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0945, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0639, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.8907\n",
      "Epoch 7/10, Train Loss: 0.0466, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.8869\n",
      "Epoch 8/10, Train Loss: 0.0363, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8773\n",
      "Epoch 9/10, Train Loss: 0.0365, Accuracy: 0.909, F1 Micro: 0.909, F1 Macro: 0.8815\n",
      "Epoch 10/10, Train Loss: 0.0177, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.8877\n",
      "\n",
      "Sentiment analysis accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.8907\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       766\n",
      "    positive       0.92      0.77      0.84       311\n",
      "\n",
      "    accuracy                           0.91      1077\n",
      "   macro avg       0.92      0.87      0.89      1077\n",
      "weighted avg       0.91      0.91      0.91      1077\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1427: Accuracy: 0.9571, F1 Micro: 0.9571, F1 Macro: 0.8545\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.98      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.82      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.77      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.85      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.58       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88       200\n",
      "     neutral       0.92      0.93      0.93       315\n",
      "    positive       0.89      0.98      0.93        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.83      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.68      0.59      0.63        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.83      0.79      0.81       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.90      0.94      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.41      0.56        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.78      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 281.2371115684509 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.0023391118273139\n",
      "Acquired samples: 86\n",
      "Sampling duration: 28.43354845046997 seconds\n",
      "New train size: 1513\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4796, Accuracy: 0.8311, F1 Micro: 0.9035, F1 Macro: 0.8978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3331, Accuracy: 0.9116, F1 Micro: 0.9472, F1 Macro: 0.9449\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2364, Accuracy: 0.9413, F1 Micro: 0.9642, F1 Macro: 0.9621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1913, Accuracy: 0.9502, F1 Micro: 0.9695, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1538, Accuracy: 0.9566, F1 Micro: 0.9732, F1 Macro: 0.9709\n",
      "Epoch 6/10, Train Loss: 0.1315, Accuracy: 0.9559, F1 Micro: 0.9729, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1097, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.098, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0785, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.975\n",
      "Epoch 10/10, Train Loss: 0.0686, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9743\n",
      "\n",
      "Aspect detection accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.93      0.96      0.94       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4302, Accuracy: 0.845, F1 Micro: 0.845, F1 Macro: 0.7752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2499, Accuracy: 0.8736, F1 Micro: 0.8736, F1 Macro: 0.8278\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1761, Accuracy: 0.9041, F1 Micro: 0.9041, F1 Macro: 0.8748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1346, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0883, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8882\n",
      "Epoch 6/10, Train Loss: 0.0612, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.8777\n",
      "Epoch 7/10, Train Loss: 0.0484, Accuracy: 0.9041, F1 Micro: 0.9041, F1 Macro: 0.8779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0525, Accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.8908\n",
      "Epoch 9/10, Train Loss: 0.0286, Accuracy: 0.9133, F1 Micro: 0.9133, F1 Macro: 0.8871\n",
      "Epoch 10/10, Train Loss: 0.0198, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.882\n",
      "\n",
      "Sentiment analysis accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.8908\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       775\n",
      "    positive       0.93      0.76      0.84       309\n",
      "\n",
      "    accuracy                           0.92      1084\n",
      "   macro avg       0.92      0.87      0.89      1084\n",
      "weighted avg       0.92      0.92      0.91      1084\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1513: Accuracy: 0.958, F1 Micro: 0.958, F1 Macro: 0.8461\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.87      0.88       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.81      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.61      0.60      0.60       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.68      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.60      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.89       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.90      0.96      0.93        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.83      0.85       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.67      0.45      0.54        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.82      0.75      0.78       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.41      0.56        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.78      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 291.3546485900879 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.002412556204944849\n",
      "Acquired samples: 78\n",
      "Sampling duration: 25.562933206558228 seconds\n",
      "New train size: 1591\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4747, Accuracy: 0.8587, F1 Micro: 0.9182, F1 Macro: 0.9136\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3257, Accuracy: 0.9227, F1 Micro: 0.9533, F1 Macro: 0.9506\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2309, Accuracy: 0.9443, F1 Micro: 0.966, F1 Macro: 0.9638\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1863, Accuracy: 0.9514, F1 Micro: 0.9701, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1534, Accuracy: 0.9563, F1 Micro: 0.9731, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1302, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "Epoch 7/10, Train Loss: 0.1055, Accuracy: 0.9585, F1 Micro: 0.9744, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0924, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9757\n",
      "Epoch 9/10, Train Loss: 0.0788, Accuracy: 0.9641, F1 Micro: 0.9776, F1 Macro: 0.9751\n",
      "Epoch 10/10, Train Loss: 0.067, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9742\n",
      "\n",
      "Aspect detection accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3869, Accuracy: 0.8601, F1 Micro: 0.8601, F1 Macro: 0.807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2201, Accuracy: 0.9002, F1 Micro: 0.9002, F1 Macro: 0.8717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1484, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.8929\n",
      "Epoch 4/10, Train Loss: 0.1114, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0928, Accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.8924\n",
      "Epoch 6/10, Train Loss: 0.0595, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.8932\n",
      "Epoch 7/10, Train Loss: 0.0476, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.8829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0349, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.8989\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0224, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.8975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0202, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.8989\n",
      "\n",
      "Sentiment analysis accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.8989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       763\n",
      "    positive       0.94      0.78      0.85       309\n",
      "\n",
      "    accuracy                           0.92      1072\n",
      "   macro avg       0.93      0.88      0.90      1072\n",
      "weighted avg       0.92      0.92      0.92      1072\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1591: Accuracy: 0.9581, F1 Micro: 0.9581, F1 Macro: 0.85\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.88      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.76      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.78      0.82        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.76      0.81        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.58      0.59       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.89      0.98      0.93        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.84      0.86       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.79      0.50      0.61        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.77      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.88      0.94      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.59      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.78      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.82      0.87       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 304.6536440849304 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.003208952071145177\n",
      "Acquired samples: 70\n",
      "Sampling duration: 23.39919090270996 seconds\n",
      "New train size: 1661\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4687, Accuracy: 0.8587, F1 Micro: 0.9177, F1 Macro: 0.9127\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3209, Accuracy: 0.9262, F1 Micro: 0.9554, F1 Macro: 0.9532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2263, Accuracy: 0.9415, F1 Micro: 0.9644, F1 Macro: 0.9621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1731, Accuracy: 0.9524, F1 Micro: 0.9708, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.145, Accuracy: 0.9582, F1 Micro: 0.9741, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.124, Accuracy: 0.9611, F1 Micro: 0.976, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1036, Accuracy: 0.962, F1 Micro: 0.9765, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0885, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0748, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0653, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9758\n",
      "\n",
      "Aspect detection accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.93      0.94      0.93       317\n",
      "       linen       0.93      0.98      0.96       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3915, Accuracy: 0.8678, F1 Micro: 0.8678, F1 Macro: 0.8252\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2209, Accuracy: 0.8976, F1 Micro: 0.8976, F1 Macro: 0.8646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1701, Accuracy: 0.9078, F1 Micro: 0.9078, F1 Macro: 0.8771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1195, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8846\n",
      "Epoch 5/10, Train Loss: 0.0701, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0573, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8835\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0403, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8821\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0466, Accuracy: 0.9162, F1 Micro: 0.9162, F1 Macro: 0.8884\n",
      "Epoch 9/10, Train Loss: 0.0264, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.8876\n",
      "Epoch 10/10, Train Loss: 0.0258, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8724\n",
      "\n",
      "Sentiment analysis accuracy: 0.9162, F1 Micro: 0.9162, F1 Macro: 0.8884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.99      0.94       771\n",
      "    positive       0.95      0.74      0.83       303\n",
      "\n",
      "    accuracy                           0.92      1074\n",
      "   macro avg       0.93      0.86      0.89      1074\n",
      "weighted avg       0.92      0.92      0.91      1074\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1661: Accuracy: 0.958, F1 Micro: 0.958, F1 Macro: 0.8475\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.92      0.93        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.85      0.81      0.83       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.83      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.77      0.83       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.84      0.63      0.72        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.54      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.87      0.89       200\n",
      "     neutral       0.93      0.94      0.93       315\n",
      "    positive       0.92      0.98      0.95        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.85       162\n",
      "     neutral       0.93      0.98      0.95       387\n",
      "    positive       1.00      0.23      0.37        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.93      0.68      0.73       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.88      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.52      0.64        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 318.86311626434326 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.0024360311683267353\n",
      "Acquired samples: 51\n",
      "Sampling duration: 21.086299657821655 seconds\n",
      "New train size: 1712\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4664, Accuracy: 0.8566, F1 Micro: 0.917, F1 Macro: 0.9124\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3133, Accuracy: 0.9267, F1 Micro: 0.9558, F1 Macro: 0.9537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2233, Accuracy: 0.9446, F1 Micro: 0.9661, F1 Macro: 0.9638\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1764, Accuracy: 0.9533, F1 Micro: 0.9713, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1427, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9737\n",
      "Epoch 6/10, Train Loss: 0.1171, Accuracy: 0.9592, F1 Micro: 0.9748, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1015, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9757\n",
      "Epoch 8/10, Train Loss: 0.0853, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9746\n",
      "Epoch 9/10, Train Loss: 0.0727, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.975\n",
      "Epoch 10/10, Train Loss: 0.0635, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9751\n",
      "\n",
      "Aspect detection accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4024, Accuracy: 0.8604, F1 Micro: 0.8604, F1 Macro: 0.8271\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2348, Accuracy: 0.8937, F1 Micro: 0.8937, F1 Macro: 0.8678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1746, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1209, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.094, Accuracy: 0.9159, F1 Micro: 0.9159, F1 Macro: 0.8892\n",
      "Epoch 6/10, Train Loss: 0.0594, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0421, Accuracy: 0.9159, F1 Micro: 0.9159, F1 Macro: 0.8925\n",
      "Epoch 8/10, Train Loss: 0.0456, Accuracy: 0.914, F1 Micro: 0.914, F1 Macro: 0.8868\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0243, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.8911\n",
      "Epoch 10/10, Train Loss: 0.026, Accuracy: 0.914, F1 Micro: 0.914, F1 Macro: 0.886\n",
      "\n",
      "Sentiment analysis accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.8911\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.99      0.94       775\n",
      "    positive       0.95      0.75      0.84       307\n",
      "\n",
      "    accuracy                           0.92      1082\n",
      "   macro avg       0.93      0.87      0.89      1082\n",
      "weighted avg       0.92      0.92      0.91      1082\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1712: Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.8631\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.77      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.79      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.61      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.89      0.98      0.93        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.88      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.75      0.79       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.95      0.90      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.87      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 316.7966606616974 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.0022255396004766223\n",
      "Acquired samples: 58\n",
      "Sampling duration: 19.29153323173523 seconds\n",
      "New train size: 1770\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4585, Accuracy: 0.8696, F1 Micro: 0.9237, F1 Macro: 0.9193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3084, Accuracy: 0.9314, F1 Micro: 0.9585, F1 Macro: 0.9565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2168, Accuracy: 0.9477, F1 Micro: 0.968, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1702, Accuracy: 0.9566, F1 Micro: 0.9732, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1396, Accuracy: 0.9613, F1 Micro: 0.9761, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1166, Accuracy: 0.9616, F1 Micro: 0.9763, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0976, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.976\n",
      "Epoch 8/10, Train Loss: 0.0827, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9747\n",
      "Epoch 9/10, Train Loss: 0.0717, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9744\n",
      "Epoch 10/10, Train Loss: 0.0606, Accuracy: 0.9639, F1 Micro: 0.9775, F1 Macro: 0.975\n",
      "\n",
      "Aspect detection accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.92      0.94      0.93       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3913, Accuracy: 0.8752, F1 Micro: 0.8752, F1 Macro: 0.834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2289, Accuracy: 0.8909, F1 Micro: 0.8909, F1 Macro: 0.8518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1521, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8851\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1219, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0878, Accuracy: 0.9131, F1 Micro: 0.9131, F1 Macro: 0.8865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0681, Accuracy: 0.9131, F1 Micro: 0.9131, F1 Macro: 0.8893\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0453, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.8937\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0366, Accuracy: 0.9187, F1 Micro: 0.9187, F1 Macro: 0.895\n",
      "Epoch 9/10, Train Loss: 0.032, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.8934\n",
      "Epoch 10/10, Train Loss: 0.0198, Accuracy: 0.9168, F1 Micro: 0.9168, F1 Macro: 0.8928\n",
      "\n",
      "Sentiment analysis accuracy: 0.9187, F1 Micro: 0.9187, F1 Macro: 0.895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.94       773\n",
      "    positive       0.93      0.78      0.85       309\n",
      "\n",
      "    accuracy                           0.92      1082\n",
      "   macro avg       0.92      0.88      0.89      1082\n",
      "weighted avg       0.92      0.92      0.92      1082\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1770: Accuracy: 0.9595, F1 Micro: 0.9595, F1 Macro: 0.8805\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.90      0.94        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.78      0.70      0.74        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.92      0.87      0.89       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.83      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.77      0.83       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.62      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.84      0.88       200\n",
      "     neutral       0.92      0.94      0.93       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.71      0.45      0.56        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.84      0.76      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.82      0.84        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.90      0.93      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.62      0.73        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.80      0.94      0.86        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.85      0.86       571\n",
      "weighted avg       0.98      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 329.1094346046448 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.0018744586152024568\n",
      "Acquired samples: 52\n",
      "Sampling duration: 17.45881676673889 seconds\n",
      "New train size: 1822\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4637, Accuracy: 0.8642, F1 Micro: 0.9212, F1 Macro: 0.9172\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3016, Accuracy: 0.9271, F1 Micro: 0.9559, F1 Macro: 0.9535\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2138, Accuracy: 0.9431, F1 Micro: 0.9653, F1 Macro: 0.9631\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1684, Accuracy: 0.951, F1 Micro: 0.9699, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1361, Accuracy: 0.958, F1 Micro: 0.974, F1 Macro: 0.9717\n",
      "Epoch 6/10, Train Loss: 0.1138, Accuracy: 0.9578, F1 Micro: 0.974, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0979, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0806, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9759\n",
      "Epoch 9/10, Train Loss: 0.0688, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9757\n",
      "Epoch 10/10, Train Loss: 0.06, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9754\n",
      "\n",
      "Aspect detection accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.94      0.91      0.93       317\n",
      "       linen       0.94      0.97      0.96       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3738, Accuracy: 0.8719, F1 Micro: 0.8719, F1 Macro: 0.8248\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2359, Accuracy: 0.9058, F1 Micro: 0.9058, F1 Macro: 0.8768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.149, Accuracy: 0.9067, F1 Micro: 0.9067, F1 Macro: 0.8792\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1154, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8815\n",
      "Epoch 5/10, Train Loss: 0.0714, Accuracy: 0.9085, F1 Micro: 0.9085, F1 Macro: 0.8805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0513, Accuracy: 0.9131, F1 Micro: 0.9131, F1 Macro: 0.8858\n",
      "Epoch 7/10, Train Loss: 0.0545, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8842\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0291, Accuracy: 0.914, F1 Micro: 0.914, F1 Macro: 0.8866\n",
      "Epoch 9/10, Train Loss: 0.0325, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8853\n",
      "Epoch 10/10, Train Loss: 0.022, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8789\n",
      "\n",
      "Sentiment analysis accuracy: 0.914, F1 Micro: 0.914, F1 Macro: 0.8866\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       782\n",
      "    positive       0.94      0.74      0.83       311\n",
      "\n",
      "    accuracy                           0.91      1093\n",
      "   macro avg       0.92      0.86      0.89      1093\n",
      "weighted avg       0.92      0.91      0.91      1093\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1822: Accuracy: 0.9594, F1 Micro: 0.9594, F1 Macro: 0.8632\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.92      0.94        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.81      0.85       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.81      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.85      0.66      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.55      0.57       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.90      0.88       200\n",
      "     neutral       0.94      0.91      0.93       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88       162\n",
      "     neutral       0.94      0.97      0.96       387\n",
      "    positive       0.79      0.50      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.87      0.78      0.82       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.87      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.95      0.93      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.62      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 332.685099363327 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.002794771920889616\n",
      "Acquired samples: 50\n",
      "Sampling duration: 15.752938508987427 seconds\n",
      "New train size: 1872\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4487, Accuracy: 0.867, F1 Micro: 0.9224, F1 Macro: 0.9173\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2935, Accuracy: 0.9306, F1 Micro: 0.9579, F1 Macro: 0.9554\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2065, Accuracy: 0.9431, F1 Micro: 0.9652, F1 Macro: 0.9631\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1695, Accuracy: 0.9536, F1 Micro: 0.9715, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1339, Accuracy: 0.9585, F1 Micro: 0.9744, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1133, Accuracy: 0.9599, F1 Micro: 0.9751, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0952, Accuracy: 0.9604, F1 Micro: 0.9754, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0813, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9753\n",
      "Epoch 9/10, Train Loss: 0.0673, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9743\n",
      "Epoch 10/10, Train Loss: 0.0564, Accuracy: 0.962, F1 Micro: 0.9763, F1 Macro: 0.9736\n",
      "\n",
      "Aspect detection accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.94      0.93       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3819, Accuracy: 0.8717, F1 Micro: 0.8717, F1 Macro: 0.8269\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2142, Accuracy: 0.8946, F1 Micro: 0.8946, F1 Macro: 0.863\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1502, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8775\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1121, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8876\n",
      "Epoch 5/10, Train Loss: 0.0873, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8807\n",
      "Epoch 6/10, Train Loss: 0.0639, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.886\n",
      "Epoch 7/10, Train Loss: 0.0383, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8836\n",
      "Epoch 8/10, Train Loss: 0.0314, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0292, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8863\n",
      "Epoch 10/10, Train Loss: 0.0226, Accuracy: 0.9047, F1 Micro: 0.9047, F1 Macro: 0.8748\n",
      "\n",
      "Sentiment analysis accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8863\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       775\n",
      "    positive       0.95      0.74      0.83       316\n",
      "\n",
      "    accuracy                           0.91      1091\n",
      "   macro avg       0.93      0.86      0.89      1091\n",
      "weighted avg       0.92      0.91      0.91      1091\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1872: Accuracy: 0.9581, F1 Micro: 0.9581, F1 Macro: 0.8553\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.81      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.75      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.58      0.59       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.89       200\n",
      "     neutral       0.93      0.94      0.93       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86       162\n",
      "     neutral       0.92      0.97      0.95       387\n",
      "    positive       1.00      0.36      0.53        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.93      0.73      0.78       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.87      0.87        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.90      0.94      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.69      0.74        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 334.8993921279907 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.0016503374092280865\n",
      "Acquired samples: 50\n",
      "Sampling duration: 14.078689575195312 seconds\n",
      "New train size: 1922\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4537, Accuracy: 0.8707, F1 Micro: 0.9244, F1 Macro: 0.9202\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2888, Accuracy: 0.9361, F1 Micro: 0.9611, F1 Macro: 0.959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2086, Accuracy: 0.9474, F1 Micro: 0.9677, F1 Macro: 0.9649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1624, Accuracy: 0.955, F1 Micro: 0.9723, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1341, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1086, Accuracy: 0.9622, F1 Micro: 0.9766, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0917, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9761\n",
      "Epoch 8/10, Train Loss: 0.0744, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9745\n",
      "Epoch 9/10, Train Loss: 0.0635, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9748\n",
      "Epoch 10/10, Train Loss: 0.0567, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9741\n",
      "\n",
      "Aspect detection accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3874, Accuracy: 0.8549, F1 Micro: 0.8549, F1 Macro: 0.7955\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2042, Accuracy: 0.8965, F1 Micro: 0.8965, F1 Macro: 0.8638\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1513, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.8827\n",
      "Epoch 4/10, Train Loss: 0.09, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.8812\n",
      "Epoch 5/10, Train Loss: 0.0865, Accuracy: 0.9011, F1 Micro: 0.9011, F1 Macro: 0.8721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0626, Accuracy: 0.9159, F1 Micro: 0.9159, F1 Macro: 0.892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0437, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.8927\n",
      "Epoch 8/10, Train Loss: 0.0361, Accuracy: 0.914, F1 Micro: 0.914, F1 Macro: 0.8899\n",
      "Epoch 9/10, Train Loss: 0.0225, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8836\n",
      "Epoch 10/10, Train Loss: 0.0275, Accuracy: 0.914, F1 Micro: 0.914, F1 Macro: 0.8878\n",
      "\n",
      "Sentiment analysis accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.8927\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       773\n",
      "    positive       0.94      0.76      0.84       309\n",
      "\n",
      "    accuracy                           0.92      1082\n",
      "   macro avg       0.93      0.87      0.89      1082\n",
      "weighted avg       0.92      0.92      0.91      1082\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1922: Accuracy: 0.9588, F1 Micro: 0.9588, F1 Macro: 0.8655\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.77      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.61      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89       200\n",
      "     neutral       0.93      0.94      0.94       315\n",
      "    positive       0.86      0.96      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.89      0.36      0.52        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.73      0.78       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.62      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.97      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 341.8394169807434 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.002369301393628121\n",
      "Acquired samples: 50\n",
      "Sampling duration: 13.024586915969849 seconds\n",
      "New train size: 1972\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4533, Accuracy: 0.8741, F1 Micro: 0.9256, F1 Macro: 0.9194\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2824, Accuracy: 0.9345, F1 Micro: 0.9603, F1 Macro: 0.9581\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2008, Accuracy: 0.9484, F1 Micro: 0.9683, F1 Macro: 0.966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1575, Accuracy: 0.9559, F1 Micro: 0.9728, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1279, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.975\n",
      "Epoch 6/10, Train Loss: 0.109, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.974\n",
      "Epoch 7/10, Train Loss: 0.0895, Accuracy: 0.9615, F1 Micro: 0.9762, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0743, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.064, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.976\n",
      "Epoch 10/10, Train Loss: 0.0525, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.91      0.98      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3648, Accuracy: 0.8778, F1 Micro: 0.8778, F1 Macro: 0.8399\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2132, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1391, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8919\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0985, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0839, Accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.8976\n",
      "Epoch 6/10, Train Loss: 0.0677, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.8889\n",
      "Epoch 7/10, Train Loss: 0.0434, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8919\n",
      "Epoch 8/10, Train Loss: 0.043, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8854\n",
      "Epoch 9/10, Train Loss: 0.0225, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.8901\n",
      "Epoch 10/10, Train Loss: 0.0309, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.8887\n",
      "\n",
      "Sentiment analysis accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.8976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       773\n",
      "    positive       0.93      0.78      0.85       315\n",
      "\n",
      "    accuracy                           0.92      1088\n",
      "   macro avg       0.92      0.88      0.90      1088\n",
      "weighted avg       0.92      0.92      0.92      1088\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1972: Accuracy: 0.9594, F1 Micro: 0.9594, F1 Macro: 0.871\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.90      0.93        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.81      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.84      0.79      0.82        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.64      0.68       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.80      0.85       162\n",
      "     neutral       0.91      0.98      0.94       387\n",
      "    positive       0.79      0.50      0.61        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.76      0.80       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.89      0.94      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 348.2137711048126 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.0018950439873151482\n",
      "Acquired samples: 25\n",
      "Sampling duration: 11.02154803276062 seconds\n",
      "New train size: 1997\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4493, Accuracy: 0.8741, F1 Micro: 0.9264, F1 Macro: 0.9231\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2762, Accuracy: 0.9352, F1 Micro: 0.9604, F1 Macro: 0.9576\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1973, Accuracy: 0.9521, F1 Micro: 0.9706, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.157, Accuracy: 0.9566, F1 Micro: 0.9733, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.128, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1069, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0874, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9748\n",
      "Epoch 8/10, Train Loss: 0.0748, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0613, Accuracy: 0.9639, F1 Micro: 0.9775, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.053, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9759\n",
      "\n",
      "Aspect detection accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3473, Accuracy: 0.8703, F1 Micro: 0.8703, F1 Macro: 0.829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2211, Accuracy: 0.9034, F1 Micro: 0.9034, F1 Macro: 0.8753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1536, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8792\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0929, Accuracy: 0.9089, F1 Micro: 0.9089, F1 Macro: 0.8805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0729, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.8875\n",
      "Epoch 6/10, Train Loss: 0.0533, Accuracy: 0.9034, F1 Micro: 0.9034, F1 Macro: 0.8724\n",
      "Epoch 7/10, Train Loss: 0.0519, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8792\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0338, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.888\n",
      "Epoch 9/10, Train Loss: 0.0252, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8853\n",
      "Epoch 10/10, Train Loss: 0.0203, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8824\n",
      "\n",
      "Sentiment analysis accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       775\n",
      "    positive       0.94      0.75      0.83       312\n",
      "\n",
      "    accuracy                           0.91      1087\n",
      "   macro avg       0.92      0.86      0.89      1087\n",
      "weighted avg       0.92      0.91      0.91      1087\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1997: Accuracy: 0.9587, F1 Micro: 0.9587, F1 Macro: 0.8669\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.92      0.80      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.85      0.84        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.77      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.61      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.89       200\n",
      "     neutral       0.93      0.94      0.94       315\n",
      "    positive       0.85      0.95      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.89      0.36      0.52        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.73      0.78       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.48      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 357.90166997909546 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.0014199410798028111\n",
      "Acquired samples: 50\n",
      "Sampling duration: 10.218830108642578 seconds\n",
      "New train size: 2047\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4444, Accuracy: 0.878, F1 Micro: 0.9283, F1 Macro: 0.9245\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2734, Accuracy: 0.9358, F1 Micro: 0.9608, F1 Macro: 0.9585\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1912, Accuracy: 0.9516, F1 Micro: 0.9703, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1495, Accuracy: 0.9547, F1 Micro: 0.9721, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.127, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.103, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9751\n",
      "Epoch 7/10, Train Loss: 0.0871, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9754\n",
      "Epoch 8/10, Train Loss: 0.073, Accuracy: 0.962, F1 Micro: 0.9765, F1 Macro: 0.9742\n",
      "Epoch 9/10, Train Loss: 0.064, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0535, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.95      0.91      0.93       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3529, Accuracy: 0.8691, F1 Micro: 0.8691, F1 Macro: 0.8278\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1936, Accuracy: 0.8926, F1 Micro: 0.8926, F1 Macro: 0.8606\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1278, Accuracy: 0.9016, F1 Micro: 0.9016, F1 Macro: 0.8745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0995, Accuracy: 0.9052, F1 Micro: 0.9052, F1 Macro: 0.8783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0685, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0533, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8812\n",
      "Epoch 7/10, Train Loss: 0.0347, Accuracy: 0.8998, F1 Micro: 0.8998, F1 Macro: 0.8688\n",
      "Epoch 8/10, Train Loss: 0.036, Accuracy: 0.898, F1 Micro: 0.898, F1 Macro: 0.8676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0329, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8798\n",
      "Epoch 10/10, Train Loss: 0.0235, Accuracy: 0.9025, F1 Micro: 0.9025, F1 Macro: 0.8713\n",
      "\n",
      "Sentiment analysis accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.99      0.94       787\n",
      "    positive       0.95      0.72      0.82       321\n",
      "\n",
      "    accuracy                           0.91      1108\n",
      "   macro avg       0.93      0.85      0.88      1108\n",
      "weighted avg       0.91      0.91      0.90      1108\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2047: Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.8544\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.92      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.85      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.77      0.83       571\n",
      "weighted avg       0.96      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.84      0.68      0.75        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.55      0.57       571\n",
      "weighted avg       0.92      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.92      0.90       200\n",
      "     neutral       0.95      0.91      0.93       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.87      0.86       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       1.00      0.32      0.48        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.93      0.72      0.77       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.87      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 357.88877844810486 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.001762383384630084\n",
      "Acquired samples: 50\n",
      "Sampling duration: 8.526890754699707 seconds\n",
      "New train size: 2097\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4358, Accuracy: 0.8839, F1 Micro: 0.9317, F1 Macro: 0.9287\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2597, Accuracy: 0.9349, F1 Micro: 0.9604, F1 Macro: 0.958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1889, Accuracy: 0.9497, F1 Micro: 0.9691, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1507, Accuracy: 0.958, F1 Micro: 0.9741, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1162, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1012, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.086, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9757\n",
      "Epoch 8/10, Train Loss: 0.0711, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9743\n",
      "Epoch 9/10, Train Loss: 0.0582, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9747\n",
      "Epoch 10/10, Train Loss: 0.0499, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.975\n",
      "\n",
      "Aspect detection accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.93      0.94      0.93       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3769, Accuracy: 0.8708, F1 Micro: 0.8708, F1 Macro: 0.8307\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2036, Accuracy: 0.8954, F1 Micro: 0.8954, F1 Macro: 0.8607\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1482, Accuracy: 0.9072, F1 Micro: 0.9072, F1 Macro: 0.8797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1103, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8845\n",
      "Epoch 5/10, Train Loss: 0.0863, Accuracy: 0.9063, F1 Micro: 0.9063, F1 Macro: 0.8767\n",
      "Epoch 6/10, Train Loss: 0.0648, Accuracy: 0.9081, F1 Micro: 0.9081, F1 Macro: 0.8783\n",
      "Epoch 7/10, Train Loss: 0.0461, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8812\n",
      "Epoch 8/10, Train Loss: 0.0448, Accuracy: 0.9072, F1 Micro: 0.9072, F1 Macro: 0.8808\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0158, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.8847\n",
      "Epoch 10/10, Train Loss: 0.025, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8834\n",
      "\n",
      "Sentiment analysis accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.8847\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       781\n",
      "    positive       0.94      0.74      0.83       318\n",
      "\n",
      "    accuracy                           0.91      1099\n",
      "   macro avg       0.92      0.86      0.88      1099\n",
      "weighted avg       0.91      0.91      0.91      1099\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2097: Accuracy: 0.9588, F1 Micro: 0.9588, F1 Macro: 0.8679\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.80      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.85      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.77      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.61      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.89       200\n",
      "     neutral       0.93      0.94      0.93       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.88      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.85      0.50      0.63        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.78      0.82       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.96      0.94      0.95        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.59      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 364.4540729522705 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.0020125440787523985\n",
      "Acquired samples: 50\n",
      "Sampling duration: 6.8541083335876465 seconds\n",
      "New train size: 2147\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4333, Accuracy: 0.8859, F1 Micro: 0.9323, F1 Macro: 0.9277\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2588, Accuracy: 0.9394, F1 Micro: 0.9631, F1 Macro: 0.9609\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1833, Accuracy: 0.9531, F1 Micro: 0.9711, F1 Macro: 0.9687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1439, Accuracy: 0.9592, F1 Micro: 0.9748, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1178, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1024, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0829, Accuracy: 0.9653, F1 Micro: 0.9785, F1 Macro: 0.9767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0698, Accuracy: 0.9668, F1 Micro: 0.9794, F1 Macro: 0.9774\n",
      "Epoch 9/10, Train Loss: 0.0582, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9758\n",
      "Epoch 10/10, Train Loss: 0.0511, Accuracy: 0.9663, F1 Micro: 0.9791, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.9668, F1 Micro: 0.9794, F1 Macro: 0.9774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.94      0.95      0.94       317\n",
      "       linen       0.94      0.97      0.96       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3561, Accuracy: 0.8629, F1 Micro: 0.8629, F1 Macro: 0.8194\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1986, Accuracy: 0.8974, F1 Micro: 0.8974, F1 Macro: 0.8682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1439, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8858\n",
      "Epoch 4/10, Train Loss: 0.1066, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.8855\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0738, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8921\n",
      "Epoch 6/10, Train Loss: 0.0511, Accuracy: 0.9092, F1 Micro: 0.9092, F1 Macro: 0.8866\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0473, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8937\n",
      "Epoch 8/10, Train Loss: 0.0339, Accuracy: 0.9155, F1 Micro: 0.9155, F1 Macro: 0.8915\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0299, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.8951\n",
      "Epoch 10/10, Train Loss: 0.0273, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8747\n",
      "\n",
      "Sentiment analysis accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.8951\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       779\n",
      "    positive       0.94      0.77      0.85       322\n",
      "\n",
      "    accuracy                           0.92      1101\n",
      "   macro avg       0.93      0.87      0.90      1101\n",
      "weighted avg       0.92      0.92      0.92      1101\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2147: Accuracy: 0.9613, F1 Micro: 0.9613, F1 Macro: 0.8897\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.86      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.85      0.87       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.84      0.78      0.81        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.63      0.68       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.88      0.90       200\n",
      "     neutral       0.94      0.95      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.87       162\n",
      "     neutral       0.94      0.97      0.96       387\n",
      "    positive       1.00      0.45      0.62        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.94      0.77      0.82       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.89      0.87        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.94      0.96      0.95        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.94      0.93       571\n",
      "weighted avg       0.96      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.83      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 379.7973792552948 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.0014985638204962014\n",
      "Acquired samples: 50\n",
      "Sampling duration: 5.309431552886963 seconds\n",
      "New train size: 2197\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4295, Accuracy: 0.8875, F1 Micro: 0.9334, F1 Macro: 0.9296\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2555, Accuracy: 0.937, F1 Micro: 0.9617, F1 Macro: 0.9596\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1887, Accuracy: 0.9535, F1 Micro: 0.9714, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1456, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.118, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0948, Accuracy: 0.9646, F1 Micro: 0.9781, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0801, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.976\n",
      "Epoch 8/10, Train Loss: 0.0673, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9741\n",
      "Epoch 9/10, Train Loss: 0.0572, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0498, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.93      0.99      0.96       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3442, Accuracy: 0.8638, F1 Micro: 0.8638, F1 Macro: 0.8089\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2028, Accuracy: 0.8953, F1 Micro: 0.8953, F1 Macro: 0.857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.138, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0841, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8839\n",
      "Epoch 5/10, Train Loss: 0.0768, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0532, Accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.8847\n",
      "Epoch 7/10, Train Loss: 0.0349, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8839\n",
      "Epoch 8/10, Train Loss: 0.0323, Accuracy: 0.9092, F1 Micro: 0.9092, F1 Macro: 0.8778\n",
      "Epoch 9/10, Train Loss: 0.0348, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0271, Accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.8864\n",
      "\n",
      "Sentiment analysis accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.8864\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       777\n",
      "    positive       0.92      0.75      0.83       302\n",
      "\n",
      "    accuracy                           0.91      1079\n",
      "   macro avg       0.92      0.87      0.89      1079\n",
      "weighted avg       0.91      0.91      0.91      1079\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2197: Accuracy: 0.9581, F1 Micro: 0.9581, F1 Macro: 0.8772\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.88      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.87      0.83      0.85       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.81      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.93      0.99      0.96       496\n",
      "    positive       0.84      0.56      0.67        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.93      0.56      0.63       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.69      0.50      0.58        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.83      0.77      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.97      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 379.3137540817261 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.00163489633705467\n",
      "Acquired samples: 50\n",
      "Sampling duration: 3.724790096282959 seconds\n",
      "New train size: 2247\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4321, Accuracy: 0.8866, F1 Micro: 0.9334, F1 Macro: 0.9303\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2542, Accuracy: 0.9403, F1 Micro: 0.9635, F1 Macro: 0.9611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1829, Accuracy: 0.9557, F1 Micro: 0.9726, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1416, Accuracy: 0.959, F1 Micro: 0.9747, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1123, Accuracy: 0.9651, F1 Micro: 0.9784, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0962, Accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9763\n",
      "Epoch 7/10, Train Loss: 0.0806, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0666, Accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.9764\n",
      "Epoch 9/10, Train Loss: 0.0547, Accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9761\n",
      "Epoch 10/10, Train Loss: 0.0469, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.9764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.93      0.92      0.93       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3452, Accuracy: 0.8723, F1 Micro: 0.8723, F1 Macro: 0.8309\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1894, Accuracy: 0.8942, F1 Micro: 0.8942, F1 Macro: 0.8582\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1288, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8789\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0946, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0723, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.8937\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.054, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.8946\n",
      "Epoch 7/10, Train Loss: 0.036, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8781\n",
      "Epoch 8/10, Train Loss: 0.0354, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8867\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0339, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.8953\n",
      "Epoch 10/10, Train Loss: 0.0217, Accuracy: 0.9133, F1 Micro: 0.9133, F1 Macro: 0.8892\n",
      "\n",
      "Sentiment analysis accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.8953\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       777\n",
      "    positive       0.95      0.76      0.85       319\n",
      "\n",
      "    accuracy                           0.92      1096\n",
      "   macro avg       0.93      0.87      0.90      1096\n",
      "weighted avg       0.92      0.92      0.92      1096\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2247: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.8787\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.88      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.85      0.81      0.83        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.77      0.64      0.67       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.88       200\n",
      "     neutral       0.93      0.92      0.93       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.76      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.96      0.94      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.82      0.76        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.87      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 382.6130747795105 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.002324844943359494\n",
      "Acquired samples: 36\n",
      "Sampling duration: 2.1599607467651367 seconds\n",
      "New train size: 2283\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4322, Accuracy: 0.8903, F1 Micro: 0.9352, F1 Macro: 0.9325\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.25, Accuracy: 0.9372, F1 Micro: 0.9618, F1 Macro: 0.9596\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1736, Accuracy: 0.9523, F1 Micro: 0.9708, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1402, Accuracy: 0.9578, F1 Micro: 0.974, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1128, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.974\n",
      "Epoch 6/10, Train Loss: 0.0941, Accuracy: 0.9594, F1 Micro: 0.9748, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0796, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0624, Accuracy: 0.9667, F1 Micro: 0.9793, F1 Macro: 0.9773\n",
      "Epoch 9/10, Train Loss: 0.0554, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9761\n",
      "Epoch 10/10, Train Loss: 0.0459, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9759\n",
      "\n",
      "Aspect detection accuracy: 0.9667, F1 Micro: 0.9793, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3463, Accuracy: 0.8682, F1 Micro: 0.8682, F1 Macro: 0.8364\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1862, Accuracy: 0.9009, F1 Micro: 0.9009, F1 Macro: 0.8714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.129, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8821\n",
      "Epoch 4/10, Train Loss: 0.0937, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8814\n",
      "Epoch 5/10, Train Loss: 0.0698, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0632, Accuracy: 0.9191, F1 Micro: 0.9191, F1 Macro: 0.8957\n",
      "Epoch 7/10, Train Loss: 0.0392, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8821\n",
      "Epoch 8/10, Train Loss: 0.0373, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.8874\n",
      "Epoch 9/10, Train Loss: 0.0268, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8782\n",
      "Epoch 10/10, Train Loss: 0.0359, Accuracy: 0.9182, F1 Micro: 0.9182, F1 Macro: 0.8951\n",
      "\n",
      "Sentiment analysis accuracy: 0.9191, F1 Micro: 0.9191, F1 Macro: 0.8957\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       779\n",
      "    positive       0.95      0.76      0.85       321\n",
      "\n",
      "    accuracy                           0.92      1100\n",
      "   macro avg       0.93      0.87      0.90      1100\n",
      "weighted avg       0.92      0.92      0.92      1100\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2283: Accuracy: 0.9611, F1 Micro: 0.9611, F1 Macro: 0.8861\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.91      0.91        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.84      0.78      0.81        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.63      0.68       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.87      0.90       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.85      0.95      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       1.00      0.45      0.62        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.93      0.76      0.81       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.89      0.87        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.94      0.97      0.96        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.94      0.93       571\n",
      "weighted avg       0.96      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.62      0.73        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.80      0.94      0.86        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.85      0.86       571\n",
      "weighted avg       0.98      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 392.59438920021057 s\n",
      "Total runtime: 8411.907177448273 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c23032",
   "metadata": {
    "papermill": {
     "duration": 0.178326,
     "end_time": "2025-03-31T06:55:44.363161",
     "exception": false,
     "start_time": "2025-03-31T06:55:44.184835",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cbe21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 2\n",
      "Random seed: 81\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6de2982f2a3455f920ec15c29a317d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6846, Accuracy: 0.7771, F1 Micro: 0.873, F1 Macro: 0.8661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5356, Accuracy: 0.8012, F1 Micro: 0.8896, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4856, Accuracy: 0.8019, F1 Micro: 0.8899, F1 Macro: 0.8853\n",
      "Epoch 4/10, Train Loss: 0.4451, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Epoch 5/10, Train Loss: 0.447, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4104, Accuracy: 0.8038, F1 Micro: 0.8908, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4062, Accuracy: 0.8099, F1 Micro: 0.893, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4023, Accuracy: 0.8189, F1 Micro: 0.8974, F1 Macro: 0.8906\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3668, Accuracy: 0.8349, F1 Micro: 0.9047, F1 Macro: 0.8978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3363, Accuracy: 0.8422, F1 Micro: 0.9091, F1 Macro: 0.9034\n",
      "\n",
      "Aspect detection accuracy: 0.8422, F1 Micro: 0.9091, F1 Macro: 0.9034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.80      1.00      0.89       462\n",
      "   air_panas       0.83      1.00      0.91       480\n",
      "         bau       0.86      1.00      0.93       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.66      0.86      0.75       317\n",
      "       linen       0.73      0.99      0.84       392\n",
      "     service       0.92      0.96      0.94       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.90      1.00      0.95       516\n",
      "        wifi       0.91      1.00      0.95       498\n",
      "\n",
      "   micro avg       0.84      0.99      0.91      4614\n",
      "   macro avg       0.84      0.98      0.90      4614\n",
      "weighted avg       0.85      0.99      0.91      4614\n",
      " samples avg       0.84      0.99      0.91      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6158, Accuracy: 0.6141, F1 Micro: 0.6141, F1 Macro: 0.3805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4961, Accuracy: 0.6141, F1 Micro: 0.6141, F1 Macro: 0.3805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4198, Accuracy: 0.6141, F1 Micro: 0.6141, F1 Macro: 0.3805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4426, Accuracy: 0.6141, F1 Micro: 0.6141, F1 Macro: 0.3805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3147, Accuracy: 0.7391, F1 Micro: 0.7391, F1 Macro: 0.6783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2361, Accuracy: 0.7636, F1 Micro: 0.7636, F1 Macro: 0.7349\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2395, Accuracy: 0.7663, F1 Micro: 0.7663, F1 Macro: 0.7452\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2328, Accuracy: 0.7935, F1 Micro: 0.7935, F1 Macro: 0.781\n",
      "Epoch 9/10, Train Loss: 0.1405, Accuracy: 0.7799, F1 Micro: 0.7799, F1 Macro: 0.7604\n",
      "Epoch 10/10, Train Loss: 0.0903, Accuracy: 0.7745, F1 Micro: 0.7745, F1 Macro: 0.7461\n",
      "\n",
      "Sentiment analysis accuracy: 0.7935, F1 Micro: 0.7935, F1 Macro: 0.781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.84      0.83       226\n",
      "    positive       0.74      0.72      0.73       142\n",
      "\n",
      "    accuracy                           0.79       368\n",
      "   macro avg       0.78      0.78      0.78       368\n",
      "weighted avg       0.79      0.79      0.79       368\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 142: Accuracy: 0.8343, F1 Micro: 0.8343, F1 Macro: 0.4065\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        97\n",
      "     neutral       0.80      1.00      0.89       459\n",
      "    positive       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.80       571\n",
      "   macro avg       0.27      0.33      0.30       571\n",
      "weighted avg       0.65      0.80      0.72       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        86\n",
      "     neutral       0.83      1.00      0.91       475\n",
      "    positive       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.28      0.33      0.30       571\n",
      "weighted avg       0.69      0.83      0.76       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.03      0.05        78\n",
      "     neutral       0.86      1.00      0.93       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.51      0.34      0.32       571\n",
      "weighted avg       0.83      0.86      0.80       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.36      0.49       200\n",
      "     neutral       0.66      0.86      0.75       315\n",
      "    positive       0.27      0.32      0.30        56\n",
      "\n",
      "    accuracy                           0.63       571\n",
      "   macro avg       0.56      0.51      0.51       571\n",
      "weighted avg       0.65      0.63      0.61       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.23      0.37       162\n",
      "     neutral       0.72      0.99      0.84       387\n",
      "    positive       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.74       571\n",
      "   macro avg       0.55      0.41      0.40       571\n",
      "weighted avg       0.75      0.74      0.67       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.61      0.71        85\n",
      "     neutral       0.92      0.96      0.94       418\n",
      "    positive       0.72      0.75      0.73        68\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.83      0.78      0.79       571\n",
      "weighted avg       0.88      0.89      0.88       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.89      1.00      0.94       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.30      0.33      0.31       571\n",
      "weighted avg       0.80      0.89      0.85       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.36      0.52        74\n",
      "     neutral       0.91      1.00      0.95       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.61      0.45      0.49       571\n",
      "weighted avg       0.91      0.91      0.89       571\n",
      "\n",
      "Total train time: 79.88755536079407 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.007074228813871742\n",
      "Acquired samples: 215\n",
      "Sampling duration: 53.64547395706177 seconds\n",
      "New train size: 357\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6158, Accuracy: 0.8024, F1 Micro: 0.8846, F1 Macro: 0.861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5176, Accuracy: 0.8132, F1 Micro: 0.8935, F1 Macro: 0.8853\n",
      "Epoch 3/10, Train Loss: 0.5032, Accuracy: 0.8146, F1 Micro: 0.8925, F1 Macro: 0.8795\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4852, Accuracy: 0.829, F1 Micro: 0.9009, F1 Macro: 0.8911\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4176, Accuracy: 0.8589, F1 Micro: 0.9168, F1 Macro: 0.9088\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3618, Accuracy: 0.8825, F1 Micro: 0.9289, F1 Macro: 0.9192\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3209, Accuracy: 0.8913, F1 Micro: 0.9349, F1 Macro: 0.9281\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2752, Accuracy: 0.9092, F1 Micro: 0.9447, F1 Macro: 0.9375\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2407, Accuracy: 0.9149, F1 Micro: 0.9483, F1 Macro: 0.9428\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2316, Accuracy: 0.9243, F1 Micro: 0.954, F1 Macro: 0.9501\n",
      "\n",
      "Aspect detection accuracy: 0.9243, F1 Micro: 0.954, F1 Macro: 0.9501\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.97      0.99      0.98       462\n",
      "   air_panas       0.95      0.99      0.97       480\n",
      "         bau       0.91      0.98      0.95       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.86      0.86      0.86       317\n",
      "       linen       0.85      0.97      0.90       392\n",
      "     service       0.96      0.97      0.96       423\n",
      "sunrise_meal       0.95      1.00      0.97       530\n",
      "          tv       0.97      1.00      0.99       516\n",
      "        wifi       0.99      0.99      0.99       498\n",
      "\n",
      "   micro avg       0.93      0.98      0.95      4614\n",
      "   macro avg       0.93      0.98      0.95      4614\n",
      "weighted avg       0.93      0.98      0.95      4614\n",
      " samples avg       0.93      0.98      0.95      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6404, Accuracy: 0.7698, F1 Micro: 0.7698, F1 Macro: 0.6271\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4736, Accuracy: 0.8183, F1 Micro: 0.8183, F1 Macro: 0.7524\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3604, Accuracy: 0.851, F1 Micro: 0.851, F1 Macro: 0.8084\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2721, Accuracy: 0.8623, F1 Micro: 0.8623, F1 Macro: 0.8133\n",
      "Epoch 5/10, Train Loss: 0.2497, Accuracy: 0.8589, F1 Micro: 0.8589, F1 Macro: 0.8027\n",
      "Epoch 6/10, Train Loss: 0.1899, Accuracy: 0.8612, F1 Micro: 0.8612, F1 Macro: 0.8096\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1505, Accuracy: 0.8713, F1 Micro: 0.8713, F1 Macro: 0.8302\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1228, Accuracy: 0.8725, F1 Micro: 0.8725, F1 Macro: 0.8284\n",
      "Epoch 9/10, Train Loss: 0.1052, Accuracy: 0.8691, F1 Micro: 0.8691, F1 Macro: 0.8184\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0624, Accuracy: 0.877, F1 Micro: 0.877, F1 Macro: 0.8308\n",
      "\n",
      "Sentiment analysis accuracy: 0.877, F1 Micro: 0.877, F1 Macro: 0.8308\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.97      0.92       637\n",
      "    positive       0.90      0.63      0.74       249\n",
      "\n",
      "    accuracy                           0.88       886\n",
      "   macro avg       0.89      0.80      0.83       886\n",
      "weighted avg       0.88      0.88      0.87       886\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 357: Accuracy: 0.9187, F1 Micro: 0.9187, F1 Macro: 0.7264\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.87      0.91        97\n",
      "     neutral       0.97      0.99      0.98       459\n",
      "    positive       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.95      0.91      0.93       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.72      0.80        86\n",
      "     neutral       0.95      0.99      0.97       475\n",
      "    positive       0.80      0.40      0.53        10\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.88      0.70      0.77       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.44      0.57        78\n",
      "     neutral       0.91      0.98      0.95       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.57      0.47      0.50       571\n",
      "weighted avg       0.90      0.91      0.89       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.79      0.80       200\n",
      "     neutral       0.86      0.86      0.86       315\n",
      "    positive       0.80      0.86      0.83        56\n",
      "\n",
      "    accuracy                           0.84       571\n",
      "   macro avg       0.82      0.84      0.83       571\n",
      "weighted avg       0.84      0.84      0.84       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.65      0.74       162\n",
      "     neutral       0.84      0.97      0.90       387\n",
      "    positive       0.75      0.14      0.23        22\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.82      0.59      0.62       571\n",
      "weighted avg       0.85      0.85      0.83       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.75      0.81        85\n",
      "     neutral       0.96      0.97      0.96       418\n",
      "    positive       0.85      0.90      0.87        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.89      0.87      0.88       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.10      0.18        29\n",
      "     neutral       0.95      1.00      0.97       525\n",
      "    positive       0.77      0.59      0.67        17\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.77      0.56      0.60       571\n",
      "weighted avg       0.92      0.94      0.92       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      0.80      0.88        54\n",
      "     neutral       0.97      1.00      0.99       511\n",
      "    positive       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.98      0.76      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        74\n",
      "     neutral       0.99      0.99      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.98      0.97      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 139.40799140930176 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.009121236205101014\n",
      "Acquired samples: 193\n",
      "Sampling duration: 63.75147747993469 seconds\n",
      "New train size: 550\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5583, Accuracy: 0.8014, F1 Micro: 0.8857, F1 Macro: 0.8654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4678, Accuracy: 0.8094, F1 Micro: 0.8899, F1 Macro: 0.8756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4274, Accuracy: 0.8276, F1 Micro: 0.8999, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3626, Accuracy: 0.8661, F1 Micro: 0.9201, F1 Macro: 0.9112\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3091, Accuracy: 0.8941, F1 Micro: 0.9367, F1 Macro: 0.9325\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.251, Accuracy: 0.9177, F1 Micro: 0.9501, F1 Macro: 0.9473\n",
      "Epoch 7/10, Train Loss: 0.2252, Accuracy: 0.917, F1 Micro: 0.95, F1 Macro: 0.9476\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2014, Accuracy: 0.9328, F1 Micro: 0.9591, F1 Macro: 0.9569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1709, Accuracy: 0.9403, F1 Micro: 0.9634, F1 Macro: 0.9608\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1449, Accuracy: 0.9432, F1 Micro: 0.9653, F1 Macro: 0.9631\n",
      "\n",
      "Aspect detection accuracy: 0.9432, F1 Micro: 0.9653, F1 Macro: 0.9631\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.97      1.00      0.98       462\n",
      "   air_panas       0.96      0.99      0.97       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.89      0.99      0.94       500\n",
      "  kebersihan       0.88      0.95      0.91       317\n",
      "       linen       0.90      0.96      0.93       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.94      1.00      0.97       530\n",
      "          tv       0.98      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      4614\n",
      "   macro avg       0.94      0.98      0.96      4614\n",
      "weighted avg       0.95      0.98      0.97      4614\n",
      " samples avg       0.95      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5449, Accuracy: 0.8185, F1 Micro: 0.8185, F1 Macro: 0.7554\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3743, Accuracy: 0.8468, F1 Micro: 0.8468, F1 Macro: 0.7699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2749, Accuracy: 0.8636, F1 Micro: 0.8636, F1 Macro: 0.8251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2275, Accuracy: 0.8772, F1 Micro: 0.8772, F1 Macro: 0.8285\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.161, Accuracy: 0.8835, F1 Micro: 0.8835, F1 Macro: 0.8378\n",
      "Epoch 6/10, Train Loss: 0.1341, Accuracy: 0.8793, F1 Micro: 0.8793, F1 Macro: 0.8345\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1046, Accuracy: 0.8856, F1 Micro: 0.8856, F1 Macro: 0.8382\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0701, Accuracy: 0.8993, F1 Micro: 0.8993, F1 Macro: 0.8595\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0777, Accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.8641\n",
      "Epoch 10/10, Train Loss: 0.0847, Accuracy: 0.8814, F1 Micro: 0.8814, F1 Macro: 0.8317\n",
      "\n",
      "Sentiment analysis accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.8641\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.94       701\n",
      "    positive       0.91      0.70      0.79       252\n",
      "\n",
      "    accuracy                           0.90       953\n",
      "   macro avg       0.90      0.84      0.86       953\n",
      "weighted avg       0.90      0.90      0.90       953\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 550: Accuracy: 0.9368, F1 Micro: 0.9368, F1 Macro: 0.763\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.87      0.91        97\n",
      "     neutral       0.97      1.00      0.98       459\n",
      "    positive       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.96      0.91      0.93       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.78      0.84        86\n",
      "     neutral       0.96      0.99      0.97       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.86      0.76      0.80       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.76      0.80        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.58      0.59       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.89      0.99      0.94       496\n",
      "    positive       0.72      0.19      0.30        68\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.54      0.39      0.41       571\n",
      "weighted avg       0.86      0.88      0.85       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.80      0.85       200\n",
      "     neutral       0.88      0.95      0.91       315\n",
      "    positive       0.88      0.91      0.89        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.89      0.88      0.88       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.79      0.83       162\n",
      "     neutral       0.90      0.97      0.93       387\n",
      "    positive       0.75      0.27      0.40        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.84      0.68      0.72       571\n",
      "weighted avg       0.89      0.89      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.80      0.83        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.86      0.90      0.88        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.89      0.89       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.10      0.18        29\n",
      "     neutral       0.94      1.00      0.97       525\n",
      "    positive       0.73      0.47      0.57        17\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.76      0.52      0.57       571\n",
      "weighted avg       0.92      0.94      0.92       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.83      0.88        54\n",
      "     neutral       0.98      1.00      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.97      0.83      0.89       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.95      0.96        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.98      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 163.54698419570923 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.007865283824503421\n",
      "Acquired samples: 174\n",
      "Sampling duration: 60.468610525131226 seconds\n",
      "New train size: 724\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.566, Accuracy: 0.8017, F1 Micro: 0.8899, F1 Macro: 0.8854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4787, Accuracy: 0.8198, F1 Micro: 0.8973, F1 Macro: 0.8894\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4179, Accuracy: 0.8753, F1 Micro: 0.9263, F1 Macro: 0.9196\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3387, Accuracy: 0.9045, F1 Micro: 0.9426, F1 Macro: 0.9376\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.275, Accuracy: 0.9243, F1 Micro: 0.9541, F1 Macro: 0.9512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2327, Accuracy: 0.9365, F1 Micro: 0.9613, F1 Macro: 0.9592\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2063, Accuracy: 0.9389, F1 Micro: 0.9629, F1 Macro: 0.9608\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1806, Accuracy: 0.9458, F1 Micro: 0.9668, F1 Macro: 0.9649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1556, Accuracy: 0.9481, F1 Micro: 0.9681, F1 Macro: 0.9661\n",
      "Epoch 10/10, Train Loss: 0.1404, Accuracy: 0.945, F1 Micro: 0.9662, F1 Macro: 0.9636\n",
      "\n",
      "Aspect detection accuracy: 0.9481, F1 Micro: 0.9681, F1 Macro: 0.9661\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.96      0.99      0.97       480\n",
      "         bau       0.96      0.97      0.97       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.92      0.92      0.92       317\n",
      "       linen       0.91      0.97      0.94       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      4614\n",
      "   macro avg       0.95      0.98      0.97      4614\n",
      "weighted avg       0.95      0.98      0.97      4614\n",
      " samples avg       0.95      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5022, Accuracy: 0.8284, F1 Micro: 0.8284, F1 Macro: 0.7635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3357, Accuracy: 0.8711, F1 Micro: 0.8711, F1 Macro: 0.8174\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2413, Accuracy: 0.8751, F1 Micro: 0.8751, F1 Macro: 0.8215\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1982, Accuracy: 0.8822, F1 Micro: 0.8822, F1 Macro: 0.8303\n",
      "Epoch 5/10, Train Loss: 0.1185, Accuracy: 0.8812, F1 Micro: 0.8812, F1 Macro: 0.828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1051, Accuracy: 0.8924, F1 Micro: 0.8924, F1 Macro: 0.8492\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0683, Accuracy: 0.8944, F1 Micro: 0.8944, F1 Macro: 0.8551\n",
      "Epoch 8/10, Train Loss: 0.0598, Accuracy: 0.8924, F1 Micro: 0.8924, F1 Macro: 0.8519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0439, Accuracy: 0.8954, F1 Micro: 0.8954, F1 Macro: 0.8542\n",
      "Epoch 10/10, Train Loss: 0.0349, Accuracy: 0.8944, F1 Micro: 0.8944, F1 Macro: 0.8525\n",
      "\n",
      "Sentiment analysis accuracy: 0.8954, F1 Micro: 0.8954, F1 Macro: 0.8542\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93       730\n",
      "    positive       0.87      0.70      0.78       255\n",
      "\n",
      "    accuracy                           0.90       985\n",
      "   macro avg       0.89      0.83      0.85       985\n",
      "weighted avg       0.89      0.90      0.89       985\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 724: Accuracy: 0.941, F1 Micro: 0.941, F1 Macro: 0.7985\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.93      0.94        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.92      0.80      0.86        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.91      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.78      0.84        86\n",
      "     neutral       0.96      0.99      0.97       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.86      0.76      0.80       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.77      0.79        78\n",
      "     neutral       0.96      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.75      0.81       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       1.00      0.01      0.03        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.62      0.34      0.32       571\n",
      "weighted avg       0.87      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.84      0.86       200\n",
      "     neutral       0.92      0.92      0.92       315\n",
      "    positive       0.84      0.95      0.89        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.88      0.90      0.89       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.79      0.84       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.79      0.50      0.61        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.86      0.75      0.80       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.82        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.83      0.94      0.88        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.89      0.89       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.21      0.34        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.90      0.72      0.71       571\n",
      "weighted avg       0.96      0.96      0.94       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.91      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.96      0.96        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.87      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 181.84226822853088 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.006066473526880146\n",
      "Acquired samples: 156\n",
      "Sampling duration: 55.207499980926514 seconds\n",
      "New train size: 880\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5399, Accuracy: 0.8012, F1 Micro: 0.8896, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4451, Accuracy: 0.8337, F1 Micro: 0.9041, F1 Macro: 0.8954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3617, Accuracy: 0.8905, F1 Micro: 0.935, F1 Macro: 0.9309\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2838, Accuracy: 0.9226, F1 Micro: 0.9532, F1 Macro: 0.9501\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.231, Accuracy: 0.9354, F1 Micro: 0.9607, F1 Macro: 0.9586\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1907, Accuracy: 0.9453, F1 Micro: 0.9665, F1 Macro: 0.9643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1674, Accuracy: 0.9509, F1 Micro: 0.9697, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1483, Accuracy: 0.9531, F1 Micro: 0.9711, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1272, Accuracy: 0.9543, F1 Micro: 0.9718, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1072, Accuracy: 0.9554, F1 Micro: 0.9724, F1 Macro: 0.9699\n",
      "\n",
      "Aspect detection accuracy: 0.9554, F1 Micro: 0.9724, F1 Macro: 0.9699\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.93      0.98      0.96       500\n",
      "  kebersihan       0.94      0.91      0.93       317\n",
      "       linen       0.88      0.98      0.93       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      0.99      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4707, Accuracy: 0.8483, F1 Micro: 0.8483, F1 Macro: 0.8103\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.282, Accuracy: 0.854, F1 Micro: 0.854, F1 Macro: 0.8004\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.232, Accuracy: 0.876, F1 Micro: 0.876, F1 Macro: 0.8333\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1345, Accuracy: 0.8969, F1 Micro: 0.8969, F1 Macro: 0.864\n",
      "Epoch 5/10, Train Loss: 0.1379, Accuracy: 0.8903, F1 Micro: 0.8903, F1 Macro: 0.8564\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0681, Accuracy: 0.8989, F1 Micro: 0.8989, F1 Macro: 0.8687\n",
      "Epoch 7/10, Train Loss: 0.0544, Accuracy: 0.8979, F1 Micro: 0.8979, F1 Macro: 0.867\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0436, Accuracy: 0.8989, F1 Micro: 0.8989, F1 Macro: 0.8671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0256, Accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0182, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.877\n",
      "\n",
      "Sentiment analysis accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.877\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.94       746\n",
      "    positive       0.92      0.74      0.82       302\n",
      "\n",
      "    accuracy                           0.91      1048\n",
      "   macro avg       0.91      0.85      0.88      1048\n",
      "weighted avg       0.91      0.91      0.90      1048\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 880: Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.828\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.60      0.60      0.60        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.81      0.82       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.79      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.98      0.96       496\n",
      "    positive       0.83      0.57      0.68        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.59      0.52      0.55       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.89      0.88       200\n",
      "     neutral       0.94      0.91      0.92       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.73      0.81       162\n",
      "     neutral       0.88      0.98      0.93       387\n",
      "    positive       0.71      0.45      0.56        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.84      0.72      0.77       571\n",
      "weighted avg       0.89      0.89      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.84      0.86        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.94      0.90      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.90      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.41      0.55        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.76      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.97      0.96        74\n",
      "     neutral       1.00      0.99      1.00       494\n",
      "    positive       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.87      0.88      0.87       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 208.46132898330688 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0049381364136934286\n",
      "Acquired samples: 141\n",
      "Sampling duration: 51.05970501899719 seconds\n",
      "New train size: 1021\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5239, Accuracy: 0.8076, F1 Micro: 0.8915, F1 Macro: 0.8838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4286, Accuracy: 0.8642, F1 Micro: 0.9201, F1 Macro: 0.9127\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3213, Accuracy: 0.9149, F1 Micro: 0.9486, F1 Macro: 0.9447\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2496, Accuracy: 0.9345, F1 Micro: 0.9601, F1 Macro: 0.9578\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2057, Accuracy: 0.9443, F1 Micro: 0.9658, F1 Macro: 0.9636\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1757, Accuracy: 0.9502, F1 Micro: 0.9693, F1 Macro: 0.967\n",
      "Epoch 7/10, Train Loss: 0.1458, Accuracy: 0.949, F1 Micro: 0.9687, F1 Macro: 0.9663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1275, Accuracy: 0.9556, F1 Micro: 0.9725, F1 Macro: 0.97\n",
      "Epoch 9/10, Train Loss: 0.1106, Accuracy: 0.9509, F1 Micro: 0.9697, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0992, Accuracy: 0.9564, F1 Micro: 0.9729, F1 Macro: 0.9704\n",
      "\n",
      "Aspect detection accuracy: 0.9564, F1 Micro: 0.9729, F1 Macro: 0.9704\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.98      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.93      0.98      0.96       500\n",
      "  kebersihan       0.93      0.92      0.93       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.97      0.96      0.96       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      0.99      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.97      0.97      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4406, Accuracy: 0.8247, F1 Micro: 0.8247, F1 Macro: 0.7617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2644, Accuracy: 0.8483, F1 Micro: 0.8483, F1 Macro: 0.8065\n",
      "Epoch 3/10, Train Loss: 0.1986, Accuracy: 0.8411, F1 Micro: 0.8411, F1 Macro: 0.7806\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.148, Accuracy: 0.8738, F1 Micro: 0.8738, F1 Macro: 0.8357\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0964, Accuracy: 0.8847, F1 Micro: 0.8847, F1 Macro: 0.8525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0774, Accuracy: 0.8892, F1 Micro: 0.8892, F1 Macro: 0.8603\n",
      "Epoch 7/10, Train Loss: 0.077, Accuracy: 0.8837, F1 Micro: 0.8837, F1 Macro: 0.8515\n",
      "Epoch 8/10, Train Loss: 0.0581, Accuracy: 0.8828, F1 Micro: 0.8828, F1 Macro: 0.8511\n",
      "Epoch 9/10, Train Loss: 0.0386, Accuracy: 0.8847, F1 Micro: 0.8847, F1 Macro: 0.8556\n",
      "Epoch 10/10, Train Loss: 0.0293, Accuracy: 0.881, F1 Micro: 0.881, F1 Macro: 0.8472\n",
      "\n",
      "Sentiment analysis accuracy: 0.8892, F1 Micro: 0.8892, F1 Macro: 0.8603\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.92       766\n",
      "    positive       0.90      0.71      0.80       335\n",
      "\n",
      "    accuracy                           0.89      1101\n",
      "   macro avg       0.89      0.84      0.86      1101\n",
      "weighted avg       0.89      0.89      0.89      1101\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1021: Accuracy: 0.9496, F1 Micro: 0.9496, F1 Macro: 0.8424\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.90      0.88        86\n",
      "     neutral       0.98      0.98      0.98       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.80      0.79      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.82      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.76      0.81       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.98      0.96       496\n",
      "    positive       0.82      0.60      0.69        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.58      0.53      0.55       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88       200\n",
      "     neutral       0.93      0.92      0.93       315\n",
      "    positive       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.80      0.84       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       0.68      0.59      0.63        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.83      0.78      0.81       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.80      0.81        85\n",
      "     neutral       0.97      0.96      0.96       418\n",
      "    positive       0.86      0.94      0.90        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.88      0.90      0.89       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.45      0.58        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.68      0.88      0.77        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.78      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.99      0.97        74\n",
      "     neutral       1.00      0.99      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 222.15040373802185 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.004426493309438229\n",
      "Acquired samples: 127\n",
      "Sampling duration: 45.448999643325806 seconds\n",
      "New train size: 1148\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5127, Accuracy: 0.8038, F1 Micro: 0.8909, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4103, Accuracy: 0.8847, F1 Micro: 0.9318, F1 Macro: 0.9262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2987, Accuracy: 0.9148, F1 Micro: 0.9484, F1 Macro: 0.9441\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.232, Accuracy: 0.941, F1 Micro: 0.9639, F1 Macro: 0.9615\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1905, Accuracy: 0.9481, F1 Micro: 0.9681, F1 Macro: 0.9654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.155, Accuracy: 0.9536, F1 Micro: 0.9713, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1344, Accuracy: 0.9556, F1 Micro: 0.9726, F1 Macro: 0.9699\n",
      "Epoch 8/10, Train Loss: 0.1083, Accuracy: 0.9536, F1 Micro: 0.9715, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.099, Accuracy: 0.9595, F1 Micro: 0.975, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0863, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9739\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9739\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.97      0.96       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4209, Accuracy: 0.8512, F1 Micro: 0.8512, F1 Macro: 0.8098\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2303, Accuracy: 0.8771, F1 Micro: 0.8771, F1 Macro: 0.8439\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1896, Accuracy: 0.8845, F1 Micro: 0.8845, F1 Macro: 0.8513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1411, Accuracy: 0.8965, F1 Micro: 0.8965, F1 Macro: 0.8722\n",
      "Epoch 5/10, Train Loss: 0.1078, Accuracy: 0.8937, F1 Micro: 0.8937, F1 Macro: 0.8641\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0761, Accuracy: 0.9039, F1 Micro: 0.9039, F1 Macro: 0.8788\n",
      "Epoch 7/10, Train Loss: 0.0347, Accuracy: 0.903, F1 Micro: 0.903, F1 Macro: 0.8786\n",
      "Epoch 8/10, Train Loss: 0.0336, Accuracy: 0.9011, F1 Micro: 0.9011, F1 Macro: 0.8749\n",
      "Epoch 9/10, Train Loss: 0.033, Accuracy: 0.8965, F1 Micro: 0.8965, F1 Macro: 0.8663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0316, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8799\n",
      "\n",
      "Sentiment analysis accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93       757\n",
      "    positive       0.92      0.75      0.83       325\n",
      "\n",
      "    accuracy                           0.90      1082\n",
      "   macro avg       0.91      0.86      0.88      1082\n",
      "weighted avg       0.91      0.90      0.90      1082\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1148: Accuracy: 0.9539, F1 Micro: 0.9539, F1 Macro: 0.8464\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.93      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.78      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.74      0.80        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.74      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.97      0.96       496\n",
      "    positive       0.81      0.76      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.58      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.89       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.83      0.96      0.89        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84       162\n",
      "     neutral       0.92      0.96      0.94       387\n",
      "    positive       0.86      0.55      0.67        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.88      0.77      0.81       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.82      0.83        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.80      0.67      0.73         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.86      0.88       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 242.93848276138306 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.003208631882444024\n",
      "Acquired samples: 114\n",
      "Sampling duration: 41.51809287071228 seconds\n",
      "New train size: 1262\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5106, Accuracy: 0.8019, F1 Micro: 0.89, F1 Macro: 0.8856\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3828, Accuracy: 0.8872, F1 Micro: 0.9328, F1 Macro: 0.9272\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2762, Accuracy: 0.9286, F1 Micro: 0.9568, F1 Macro: 0.9542\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2098, Accuracy: 0.9422, F1 Micro: 0.9646, F1 Macro: 0.9623\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1775, Accuracy: 0.9509, F1 Micro: 0.9698, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1465, Accuracy: 0.9557, F1 Micro: 0.9726, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1207, Accuracy: 0.9571, F1 Micro: 0.9735, F1 Macro: 0.9709\n",
      "Epoch 8/10, Train Loss: 0.108, Accuracy: 0.9557, F1 Micro: 0.9726, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0888, Accuracy: 0.9592, F1 Micro: 0.9748, F1 Macro: 0.9722\n",
      "Epoch 10/10, Train Loss: 0.0787, Accuracy: 0.959, F1 Micro: 0.9746, F1 Macro: 0.972\n",
      "\n",
      "Aspect detection accuracy: 0.9592, F1 Micro: 0.9748, F1 Macro: 0.9722\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.88      0.96      0.92       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3848, Accuracy: 0.8514, F1 Micro: 0.8514, F1 Macro: 0.7941\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2269, Accuracy: 0.8829, F1 Micro: 0.8829, F1 Macro: 0.8476\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1603, Accuracy: 0.8952, F1 Micro: 0.8952, F1 Macro: 0.8612\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1239, Accuracy: 0.901, F1 Micro: 0.901, F1 Macro: 0.8719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0885, Accuracy: 0.9029, F1 Micro: 0.9029, F1 Macro: 0.875\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0523, Accuracy: 0.9067, F1 Micro: 0.9067, F1 Macro: 0.8778\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0546, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0508, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8831\n",
      "Epoch 9/10, Train Loss: 0.0295, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0449, Accuracy: 0.9095, F1 Micro: 0.9095, F1 Macro: 0.8847\n",
      "\n",
      "Sentiment analysis accuracy: 0.9095, F1 Micro: 0.9095, F1 Macro: 0.8847\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       747\n",
      "    positive       0.90      0.77      0.83       303\n",
      "\n",
      "    accuracy                           0.91      1050\n",
      "   macro avg       0.91      0.87      0.88      1050\n",
      "weighted avg       0.91      0.91      0.91      1050\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1262: Accuracy: 0.9518, F1 Micro: 0.9518, F1 Macro: 0.8469\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.95      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.81      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.78      0.82        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.82      0.66      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.55      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.79      0.86       200\n",
      "     neutral       0.88      0.96      0.92       315\n",
      "    positive       0.86      0.88      0.87        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.89      0.88      0.88       571\n",
      "weighted avg       0.90      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       0.79      0.50      0.61        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.76      0.80       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.80      0.83        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.88      0.94      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.41      0.57        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.63      1.00      0.77        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.78       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 257.7833375930786 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0036075943382456897\n",
      "Acquired samples: 103\n",
      "Sampling duration: 37.48617672920227 seconds\n",
      "New train size: 1365\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5055, Accuracy: 0.8056, F1 Micro: 0.8898, F1 Macro: 0.8798\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3774, Accuracy: 0.8965, F1 Micro: 0.9384, F1 Macro: 0.9335\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2578, Accuracy: 0.934, F1 Micro: 0.9599, F1 Macro: 0.9575\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2066, Accuracy: 0.9481, F1 Micro: 0.9681, F1 Macro: 0.9656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.164, Accuracy: 0.9491, F1 Micro: 0.9688, F1 Macro: 0.9664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1382, Accuracy: 0.9575, F1 Micro: 0.9737, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1169, Accuracy: 0.9601, F1 Micro: 0.9752, F1 Macro: 0.9728\n",
      "Epoch 8/10, Train Loss: 0.1011, Accuracy: 0.9568, F1 Micro: 0.9733, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0855, Accuracy: 0.9602, F1 Micro: 0.9753, F1 Macro: 0.9728\n",
      "Epoch 10/10, Train Loss: 0.0776, Accuracy: 0.9576, F1 Micro: 0.9738, F1 Macro: 0.9712\n",
      "\n",
      "Aspect detection accuracy: 0.9602, F1 Micro: 0.9753, F1 Macro: 0.9728\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.94      0.91      0.93       317\n",
      "       linen       0.91      0.97      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3962, Accuracy: 0.8455, F1 Micro: 0.8455, F1 Macro: 0.791\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2525, Accuracy: 0.877, F1 Micro: 0.877, F1 Macro: 0.8392\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1666, Accuracy: 0.8844, F1 Micro: 0.8844, F1 Macro: 0.8489\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1361, Accuracy: 0.8973, F1 Micro: 0.8973, F1 Macro: 0.867\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0802, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8758\n",
      "Epoch 6/10, Train Loss: 0.0591, Accuracy: 0.8899, F1 Micro: 0.8899, F1 Macro: 0.8551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.065, Accuracy: 0.9056, F1 Micro: 0.9056, F1 Macro: 0.879\n",
      "Epoch 8/10, Train Loss: 0.0361, Accuracy: 0.901, F1 Micro: 0.901, F1 Macro: 0.8762\n",
      "Epoch 9/10, Train Loss: 0.033, Accuracy: 0.8982, F1 Micro: 0.8982, F1 Macro: 0.8668\n",
      "Epoch 10/10, Train Loss: 0.0346, Accuracy: 0.8918, F1 Micro: 0.8918, F1 Macro: 0.8617\n",
      "\n",
      "Sentiment analysis accuracy: 0.9056, F1 Micro: 0.9056, F1 Macro: 0.879\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       762\n",
      "    positive       0.93      0.74      0.82       319\n",
      "\n",
      "    accuracy                           0.91      1081\n",
      "   macro avg       0.91      0.86      0.88      1081\n",
      "weighted avg       0.91      0.91      0.90      1081\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1365: Accuracy: 0.9536, F1 Micro: 0.9536, F1 Macro: 0.8547\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.93      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.84      0.87        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.57      0.40      0.47        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.74      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.79      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.85      0.65      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.54      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.89      0.88       200\n",
      "     neutral       0.94      0.91      0.93       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.93      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.78      0.84       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.67      0.55      0.60        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.83      0.77      0.79       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.84      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.55      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 266.76620602607727 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0034175293520092966\n",
      "Acquired samples: 62\n",
      "Sampling duration: 33.80435276031494 seconds\n",
      "New train size: 1427\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4937, Accuracy: 0.8057, F1 Micro: 0.8918, F1 Macro: 0.8873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3594, Accuracy: 0.8977, F1 Micro: 0.939, F1 Macro: 0.9341\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2555, Accuracy: 0.9354, F1 Micro: 0.9607, F1 Macro: 0.9585\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1976, Accuracy: 0.9458, F1 Micro: 0.9668, F1 Macro: 0.9644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.157, Accuracy: 0.9521, F1 Micro: 0.9705, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1349, Accuracy: 0.9528, F1 Micro: 0.9709, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1141, Accuracy: 0.9595, F1 Micro: 0.9749, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0972, Accuracy: 0.9595, F1 Micro: 0.9749, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0818, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0746, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9744\n",
      "\n",
      "Aspect detection accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.93      0.96      0.94       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3877, Accuracy: 0.8565, F1 Micro: 0.8565, F1 Macro: 0.8148\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2151, Accuracy: 0.8638, F1 Micro: 0.8638, F1 Macro: 0.8138\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.158, Accuracy: 0.8885, F1 Micro: 0.8885, F1 Macro: 0.8546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1143, Accuracy: 0.8976, F1 Micro: 0.8976, F1 Macro: 0.8665\n",
      "Epoch 5/10, Train Loss: 0.0843, Accuracy: 0.8903, F1 Micro: 0.8903, F1 Macro: 0.8536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0702, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8684\n",
      "Epoch 7/10, Train Loss: 0.0529, Accuracy: 0.8995, F1 Micro: 0.8995, F1 Macro: 0.8686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0398, Accuracy: 0.9013, F1 Micro: 0.9013, F1 Macro: 0.8744\n",
      "Epoch 9/10, Train Loss: 0.0337, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8694\n",
      "Epoch 10/10, Train Loss: 0.0308, Accuracy: 0.8985, F1 Micro: 0.8985, F1 Macro: 0.8676\n",
      "\n",
      "Sentiment analysis accuracy: 0.9013, F1 Micro: 0.9013, F1 Macro: 0.8744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93       773\n",
      "    positive       0.90      0.75      0.82       321\n",
      "\n",
      "    accuracy                           0.90      1094\n",
      "   macro avg       0.90      0.86      0.87      1094\n",
      "weighted avg       0.90      0.90      0.90      1094\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1427: Accuracy: 0.955, F1 Micro: 0.955, F1 Macro: 0.8695\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.91      0.93        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.79      1.00      0.88        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.97      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.87      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.64      0.70      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.86      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.85      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.83      0.66      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.93      0.60      0.65       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89       200\n",
      "     neutral       0.93      0.94      0.94       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.82      0.84       162\n",
      "     neutral       0.93      0.96      0.94       387\n",
      "    positive       0.69      0.41      0.51        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.83      0.73      0.77       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.84      0.83        85\n",
      "     neutral       0.97      0.96      0.97       418\n",
      "    positive       0.90      0.94      0.92        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.91      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.45      0.59        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.67      0.94      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.80      0.79       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 281.23896288871765 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.002653496479615569\n",
      "Acquired samples: 86\n",
      "Sampling duration: 31.31895422935486 seconds\n",
      "New train size: 1513\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4982, Accuracy: 0.816, F1 Micro: 0.8963, F1 Macro: 0.8903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3548, Accuracy: 0.9076, F1 Micro: 0.9444, F1 Macro: 0.9394\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2458, Accuracy: 0.9418, F1 Micro: 0.9644, F1 Macro: 0.962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1864, Accuracy: 0.9507, F1 Micro: 0.9697, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.152, Accuracy: 0.9521, F1 Micro: 0.9704, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1282, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9736\n",
      "Epoch 7/10, Train Loss: 0.1091, Accuracy: 0.9587, F1 Micro: 0.9744, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0979, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9742\n",
      "Epoch 9/10, Train Loss: 0.0813, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9733\n",
      "Epoch 10/10, Train Loss: 0.0679, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9738\n",
      "\n",
      "Aspect detection accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3871, Accuracy: 0.8585, F1 Micro: 0.8585, F1 Macro: 0.8103\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2193, Accuracy: 0.8851, F1 Micro: 0.8851, F1 Macro: 0.856\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1603, Accuracy: 0.8925, F1 Micro: 0.8925, F1 Macro: 0.8598\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1175, Accuracy: 0.9026, F1 Micro: 0.9026, F1 Macro: 0.876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0926, Accuracy: 0.9026, F1 Micro: 0.9026, F1 Macro: 0.876\n",
      "Epoch 6/10, Train Loss: 0.0727, Accuracy: 0.8989, F1 Micro: 0.8989, F1 Macro: 0.8732\n",
      "Epoch 7/10, Train Loss: 0.0497, Accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8733\n",
      "Epoch 8/10, Train Loss: 0.043, Accuracy: 0.9007, F1 Micro: 0.9007, F1 Macro: 0.8744\n",
      "Epoch 9/10, Train Loss: 0.0498, Accuracy: 0.8952, F1 Micro: 0.8952, F1 Macro: 0.8686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0355, Accuracy: 0.9026, F1 Micro: 0.9026, F1 Macro: 0.8734\n",
      "\n",
      "Sentiment analysis accuracy: 0.9026, F1 Micro: 0.9026, F1 Macro: 0.8734\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93       766\n",
      "    positive       0.94      0.71      0.81       322\n",
      "\n",
      "    accuracy                           0.90      1088\n",
      "   macro avg       0.92      0.85      0.87      1088\n",
      "weighted avg       0.91      0.90      0.90      1088\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1513: Accuracy: 0.9553, F1 Micro: 0.9553, F1 Macro: 0.8485\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.79      0.81       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.78      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.86      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.57      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.83      0.84       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.88      0.32      0.47        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.71      0.75       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.59      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 285.4992084503174 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.002392746740952134\n",
      "Acquired samples: 78\n",
      "Sampling duration: 28.673948764801025 seconds\n",
      "New train size: 1591\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4952, Accuracy: 0.8132, F1 Micro: 0.8951, F1 Macro: 0.8898\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3383, Accuracy: 0.9184, F1 Micro: 0.9507, F1 Macro: 0.9469\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2412, Accuracy: 0.9432, F1 Micro: 0.9653, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1853, Accuracy: 0.9488, F1 Micro: 0.9685, F1 Macro: 0.9656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1533, Accuracy: 0.9563, F1 Micro: 0.973, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1258, Accuracy: 0.9595, F1 Micro: 0.975, F1 Macro: 0.9728\n",
      "Epoch 7/10, Train Loss: 0.1072, Accuracy: 0.9589, F1 Micro: 0.9746, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0913, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.974\n",
      "Epoch 9/10, Train Loss: 0.0808, Accuracy: 0.9594, F1 Micro: 0.9748, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0667, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9745\n",
      "\n",
      "Aspect detection accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.94      0.93       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3877, Accuracy: 0.832, F1 Micro: 0.832, F1 Macro: 0.7628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2315, Accuracy: 0.8733, F1 Micro: 0.8733, F1 Macro: 0.8301\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.149, Accuracy: 0.899, F1 Micro: 0.899, F1 Macro: 0.871\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0981, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8812\n",
      "Epoch 5/10, Train Loss: 0.0896, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8702\n",
      "Epoch 6/10, Train Loss: 0.0759, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8751\n",
      "Epoch 7/10, Train Loss: 0.0465, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8742\n",
      "Epoch 8/10, Train Loss: 0.039, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8753\n",
      "Epoch 9/10, Train Loss: 0.0302, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8781\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.017, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8841\n",
      "\n",
      "Sentiment analysis accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8841\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.94       768\n",
      "    positive       0.92      0.75      0.83       321\n",
      "\n",
      "    accuracy                           0.91      1089\n",
      "   macro avg       0.91      0.86      0.88      1089\n",
      "weighted avg       0.91      0.91      0.91      1089\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1591: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.8612\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.82      0.80      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.83      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.80      0.72      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.57      0.58       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.88       200\n",
      "     neutral       0.93      0.94      0.93       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.81      0.85       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       0.80      0.55      0.65        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.78      0.81       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.95      0.91      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.41      0.56        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.65      0.88      0.75        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.76      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 311.37069964408875 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.0026232610456645494\n",
      "Acquired samples: 70\n",
      "Sampling duration: 26.187652587890625 seconds\n",
      "New train size: 1661\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4919, Accuracy: 0.8314, F1 Micro: 0.9026, F1 Macro: 0.8937\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3371, Accuracy: 0.9229, F1 Micro: 0.9533, F1 Macro: 0.9495\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2346, Accuracy: 0.9441, F1 Micro: 0.9658, F1 Macro: 0.9638\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1905, Accuracy: 0.9528, F1 Micro: 0.9709, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1523, Accuracy: 0.9563, F1 Micro: 0.973, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1298, Accuracy: 0.9583, F1 Micro: 0.9743, F1 Macro: 0.9725\n",
      "Epoch 7/10, Train Loss: 0.1084, Accuracy: 0.9582, F1 Micro: 0.9742, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0902, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.081, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0679, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "\n",
      "Aspect detection accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.91      0.98      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4107, Accuracy: 0.8687, F1 Micro: 0.8687, F1 Macro: 0.8262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2428, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8826\n",
      "Epoch 3/10, Train Loss: 0.1679, Accuracy: 0.8957, F1 Micro: 0.8957, F1 Macro: 0.8615\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.106, Accuracy: 0.9078, F1 Micro: 0.9078, F1 Macro: 0.8803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.081, Accuracy: 0.9153, F1 Micro: 0.9153, F1 Macro: 0.891\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0473, Accuracy: 0.9162, F1 Micro: 0.9162, F1 Macro: 0.8925\n",
      "Epoch 7/10, Train Loss: 0.0402, Accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.8894\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0299, Accuracy: 0.9181, F1 Micro: 0.9181, F1 Macro: 0.8947\n",
      "Epoch 9/10, Train Loss: 0.0461, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8803\n",
      "Epoch 10/10, Train Loss: 0.0436, Accuracy: 0.9153, F1 Micro: 0.9153, F1 Macro: 0.8905\n",
      "\n",
      "Sentiment analysis accuracy: 0.9181, F1 Micro: 0.9181, F1 Macro: 0.8947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       764\n",
      "    positive       0.93      0.77      0.85       310\n",
      "\n",
      "    accuracy                           0.92      1074\n",
      "   macro avg       0.92      0.88      0.89      1074\n",
      "weighted avg       0.92      0.92      0.92      1074\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1661: Accuracy: 0.958, F1 Micro: 0.958, F1 Macro: 0.8624\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.75      0.81       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.40      0.29      0.33         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.85      0.75      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.74      0.67      0.70       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89       200\n",
      "     neutral       0.93      0.93      0.93       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.80      0.84       162\n",
      "     neutral       0.91      0.98      0.95       387\n",
      "    positive       0.80      0.36      0.50        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.71      0.76       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.94      0.96      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.94      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.82      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.88      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 319.382479429245 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.0022708812262862924\n",
      "Acquired samples: 51\n",
      "Sampling duration: 23.48244595527649 seconds\n",
      "New train size: 1712\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4943, Accuracy: 0.826, F1 Micro: 0.9013, F1 Macro: 0.8953\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3278, Accuracy: 0.9278, F1 Micro: 0.9562, F1 Macro: 0.9532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2352, Accuracy: 0.9477, F1 Micro: 0.9679, F1 Macro: 0.9657\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.183, Accuracy: 0.9523, F1 Micro: 0.9705, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1525, Accuracy: 0.9587, F1 Micro: 0.9744, F1 Macro: 0.9719\n",
      "Epoch 6/10, Train Loss: 0.1272, Accuracy: 0.9578, F1 Micro: 0.974, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1072, Accuracy: 0.9595, F1 Micro: 0.975, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0892, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0764, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0641, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.93      0.98      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.99       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3809, Accuracy: 0.868, F1 Micro: 0.868, F1 Macro: 0.823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2317, Accuracy: 0.9021, F1 Micro: 0.9021, F1 Macro: 0.8724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1672, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.8891\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1248, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.8891\n",
      "Epoch 5/10, Train Loss: 0.0865, Accuracy: 0.9086, F1 Micro: 0.9086, F1 Macro: 0.8798\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0638, Accuracy: 0.9169, F1 Micro: 0.9169, F1 Macro: 0.8914\n",
      "Epoch 7/10, Train Loss: 0.0513, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.8878\n",
      "Epoch 8/10, Train Loss: 0.0377, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.8878\n",
      "Epoch 9/10, Train Loss: 0.0407, Accuracy: 0.9123, F1 Micro: 0.9123, F1 Macro: 0.8875\n",
      "Epoch 10/10, Train Loss: 0.0159, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8887\n",
      "\n",
      "Sentiment analysis accuracy: 0.9169, F1 Micro: 0.9169, F1 Macro: 0.8914\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.99      0.94       770\n",
      "    positive       0.96      0.75      0.84       313\n",
      "\n",
      "    accuracy                           0.92      1083\n",
      "   macro avg       0.93      0.87      0.89      1083\n",
      "weighted avg       0.92      0.92      0.91      1083\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1712: Accuracy: 0.9588, F1 Micro: 0.9588, F1 Macro: 0.8616\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.86      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.78      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.82      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.88      0.76      0.82        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.78      0.63      0.67       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.91      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.83      0.87       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.74      0.79       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.95      0.93      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.52      0.61        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.79      0.65      0.71        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.72      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 331.98410630226135 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.002936054370366037\n",
      "Acquired samples: 58\n",
      "Sampling duration: 21.639638900756836 seconds\n",
      "New train size: 1770\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4808, Accuracy: 0.8465, F1 Micro: 0.911, F1 Macro: 0.9032\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3195, Accuracy: 0.9293, F1 Micro: 0.9569, F1 Macro: 0.954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2235, Accuracy: 0.9438, F1 Micro: 0.9656, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1823, Accuracy: 0.9526, F1 Micro: 0.9708, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1435, Accuracy: 0.9536, F1 Micro: 0.9715, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1187, Accuracy: 0.9613, F1 Micro: 0.9761, F1 Macro: 0.9742\n",
      "Epoch 7/10, Train Loss: 0.1025, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0857, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9753\n",
      "Epoch 9/10, Train Loss: 0.0754, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0624, Accuracy: 0.9644, F1 Micro: 0.978, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.9644, F1 Micro: 0.978, F1 Macro: 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.92      0.98      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.99      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.99      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3504, Accuracy: 0.8723, F1 Micro: 0.8723, F1 Macro: 0.8244\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2384, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1669, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.8932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.12, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.8989\n",
      "Epoch 5/10, Train Loss: 0.0806, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.8936\n",
      "Epoch 6/10, Train Loss: 0.0724, Accuracy: 0.9215, F1 Micro: 0.9215, F1 Macro: 0.8991\n",
      "Epoch 7/10, Train Loss: 0.0581, Accuracy: 0.9196, F1 Micro: 0.9196, F1 Macro: 0.8964\n",
      "Epoch 8/10, Train Loss: 0.0388, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.8909\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0298, Accuracy: 0.9253, F1 Micro: 0.9253, F1 Macro: 0.9023\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0279, Accuracy: 0.9262, F1 Micro: 0.9262, F1 Macro: 0.9037\n",
      "\n",
      "Sentiment analysis accuracy: 0.9262, F1 Micro: 0.9262, F1 Macro: 0.9037\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       758\n",
      "    positive       0.95      0.78      0.86       299\n",
      "\n",
      "    accuracy                           0.93      1057\n",
      "   macro avg       0.93      0.88      0.90      1057\n",
      "weighted avg       0.93      0.93      0.92      1057\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1770: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.8659\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.97      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.82      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.57      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.87      0.89       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.81      0.85       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       0.86      0.27      0.41        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.69      0.74       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.81      0.86        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.92      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 330.59721326828003 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.002865209523588419\n",
      "Acquired samples: 52\n",
      "Sampling duration: 19.676509857177734 seconds\n",
      "New train size: 1822\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.488, Accuracy: 0.8411, F1 Micro: 0.9085, F1 Macro: 0.9023\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3189, Accuracy: 0.9274, F1 Micro: 0.9561, F1 Macro: 0.9532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.221, Accuracy: 0.9413, F1 Micro: 0.9642, F1 Macro: 0.9618\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1739, Accuracy: 0.9524, F1 Micro: 0.9707, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1461, Accuracy: 0.9573, F1 Micro: 0.9736, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1214, Accuracy: 0.9595, F1 Micro: 0.975, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.103, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0869, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0723, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9756\n",
      "Epoch 10/10, Train Loss: 0.0622, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.92      0.95      0.93       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3838, Accuracy: 0.8675, F1 Micro: 0.8675, F1 Macro: 0.8251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1947, Accuracy: 0.8983, F1 Micro: 0.8983, F1 Macro: 0.8643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1424, Accuracy: 0.9123, F1 Micro: 0.9123, F1 Macro: 0.8839\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.104, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.8859\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0742, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0645, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.8935\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0521, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.8941\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0293, Accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9044\n",
      "Epoch 9/10, Train Loss: 0.0263, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.892\n",
      "Epoch 10/10, Train Loss: 0.0254, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.8945\n",
      "\n",
      "Sentiment analysis accuracy: 0.9272, F1 Micro: 0.9272, F1 Macro: 0.9044\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       771\n",
      "    positive       0.95      0.78      0.86       301\n",
      "\n",
      "    accuracy                           0.93      1072\n",
      "   macro avg       0.94      0.88      0.90      1072\n",
      "weighted avg       0.93      0.93      0.92      1072\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1822: Accuracy: 0.9595, F1 Micro: 0.9595, F1 Macro: 0.8831\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.78      0.81        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.84      0.62      0.71        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.93      0.58      0.64       571\n",
      "weighted avg       0.93      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.89       200\n",
      "     neutral       0.92      0.95      0.93       315\n",
      "    positive       0.89      0.98      0.93        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.88       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.85      0.50      0.63        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.78      0.82       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.94      0.96      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.62      0.73        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.83      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 340.8505549430847 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.0022083516931161286\n",
      "Acquired samples: 50\n",
      "Sampling duration: 17.449869632720947 seconds\n",
      "New train size: 1872\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4757, Accuracy: 0.8479, F1 Micro: 0.912, F1 Macro: 0.9051\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3061, Accuracy: 0.9236, F1 Micro: 0.9539, F1 Macro: 0.951\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2168, Accuracy: 0.946, F1 Micro: 0.9669, F1 Macro: 0.9646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1708, Accuracy: 0.9528, F1 Micro: 0.971, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1421, Accuracy: 0.9569, F1 Micro: 0.9735, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1151, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.975\n",
      "Epoch 7/10, Train Loss: 0.096, Accuracy: 0.9618, F1 Micro: 0.9764, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0814, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9755\n",
      "Epoch 9/10, Train Loss: 0.0675, Accuracy: 0.9616, F1 Micro: 0.9763, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0604, Accuracy: 0.9655, F1 Micro: 0.9786, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.9655, F1 Micro: 0.9786, F1 Macro: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3694, Accuracy: 0.8574, F1 Micro: 0.8574, F1 Macro: 0.8177\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2301, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1545, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1147, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.8901\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0789, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.8875\n",
      "Epoch 6/10, Train Loss: 0.0628, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0372, Accuracy: 0.9204, F1 Micro: 0.9204, F1 Macro: 0.8984\n",
      "Epoch 8/10, Train Loss: 0.0365, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.8908\n",
      "Epoch 9/10, Train Loss: 0.0354, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0256, Accuracy: 0.9204, F1 Micro: 0.9204, F1 Macro: 0.8968\n",
      "\n",
      "Sentiment analysis accuracy: 0.9204, F1 Micro: 0.9204, F1 Macro: 0.8968\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       770\n",
      "    positive       0.94      0.77      0.85       310\n",
      "\n",
      "    accuracy                           0.92      1080\n",
      "   macro avg       0.93      0.88      0.90      1080\n",
      "weighted avg       0.92      0.92      0.92      1080\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1872: Accuracy: 0.9595, F1 Micro: 0.9595, F1 Macro: 0.861\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.97      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.87      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.81      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.57      0.59       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.87      0.89       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.64      0.41      0.50        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.82      0.75      0.77       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.84      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.80      0.94      0.86        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.84      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 341.02781319618225 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.0025970188202336436\n",
      "Acquired samples: 50\n",
      "Sampling duration: 15.57163119316101 seconds\n",
      "New train size: 1922\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4736, Accuracy: 0.8707, F1 Micro: 0.9239, F1 Macro: 0.9177\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3002, Accuracy: 0.9293, F1 Micro: 0.957, F1 Macro: 0.9536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2187, Accuracy: 0.9477, F1 Micro: 0.9679, F1 Macro: 0.9656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1647, Accuracy: 0.9519, F1 Micro: 0.9705, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1375, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1139, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0905, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0788, Accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0702, Accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.9766\n",
      "Epoch 10/10, Train Loss: 0.0567, Accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.91      0.98      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.357, Accuracy: 0.8699, F1 Micro: 0.8699, F1 Macro: 0.8374\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2231, Accuracy: 0.9041, F1 Micro: 0.9041, F1 Macro: 0.8751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1516, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8908\n",
      "Epoch 4/10, Train Loss: 0.1134, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0745, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.8931\n",
      "Epoch 6/10, Train Loss: 0.0724, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.89\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0597, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.8985\n",
      "Epoch 8/10, Train Loss: 0.0371, Accuracy: 0.9207, F1 Micro: 0.9207, F1 Macro: 0.8979\n",
      "Epoch 9/10, Train Loss: 0.0326, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.885\n",
      "Epoch 10/10, Train Loss: 0.033, Accuracy: 0.9197, F1 Micro: 0.9197, F1 Macro: 0.8968\n",
      "\n",
      "Sentiment analysis accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.8985\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       771\n",
      "    positive       0.95      0.77      0.85       313\n",
      "\n",
      "    accuracy                           0.92      1084\n",
      "   macro avg       0.93      0.88      0.90      1084\n",
      "weighted avg       0.92      0.92      0.92      1084\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1922: Accuracy: 0.9604, F1 Micro: 0.9604, F1 Macro: 0.8773\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.81      0.84        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.87      0.79      0.83        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.78      0.64      0.68       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.89      0.98      0.93        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.80      0.84       162\n",
      "     neutral       0.91      0.98      0.94       387\n",
      "    positive       0.73      0.36      0.48        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.84      0.71      0.76       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.87      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.96      0.94      0.95        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.62      0.73        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.83      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 358.47558426856995 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.0019065051805228\n",
      "Acquired samples: 50\n",
      "Sampling duration: 14.651275157928467 seconds\n",
      "New train size: 1972\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4761, Accuracy: 0.8523, F1 Micro: 0.9145, F1 Macro: 0.9085\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2984, Accuracy: 0.9307, F1 Micro: 0.958, F1 Macro: 0.9557\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2134, Accuracy: 0.9465, F1 Micro: 0.9673, F1 Macro: 0.9652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1621, Accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1346, Accuracy: 0.9592, F1 Micro: 0.9749, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1108, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9751\n",
      "Epoch 7/10, Train Loss: 0.0949, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0827, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.069, Accuracy: 0.967, F1 Micro: 0.9795, F1 Macro: 0.9774\n",
      "Epoch 10/10, Train Loss: 0.0573, Accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.967, F1 Micro: 0.9795, F1 Macro: 0.9774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.95      0.97      0.96       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.363, Accuracy: 0.8769, F1 Micro: 0.8769, F1 Macro: 0.8423\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2043, Accuracy: 0.9061, F1 Micro: 0.9061, F1 Macro: 0.8792\n",
      "Epoch 3/10, Train Loss: 0.1364, Accuracy: 0.9043, F1 Micro: 0.9043, F1 Macro: 0.8743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0878, Accuracy: 0.9207, F1 Micro: 0.9207, F1 Macro: 0.8984\n",
      "Epoch 5/10, Train Loss: 0.077, Accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.8876\n",
      "Epoch 6/10, Train Loss: 0.0647, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.893\n",
      "Epoch 7/10, Train Loss: 0.0452, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.883\n",
      "Epoch 8/10, Train Loss: 0.045, Accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.8873\n",
      "Epoch 9/10, Train Loss: 0.0362, Accuracy: 0.9152, F1 Micro: 0.9152, F1 Macro: 0.8904\n",
      "Epoch 10/10, Train Loss: 0.0306, Accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.8889\n",
      "\n",
      "Sentiment analysis accuracy: 0.9207, F1 Micro: 0.9207, F1 Macro: 0.8984\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.95       782\n",
      "    positive       0.93      0.79      0.85       315\n",
      "\n",
      "    accuracy                           0.92      1097\n",
      "   macro avg       0.92      0.88      0.90      1097\n",
      "weighted avg       0.92      0.92      0.92      1097\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1972: Accuracy: 0.9611, F1 Micro: 0.9611, F1 Macro: 0.8748\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.88      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.60      0.60      0.60        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.83      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.84        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.88      0.72      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.57      0.59       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.88      0.90       200\n",
      "     neutral       0.93      0.94      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.90       162\n",
      "     neutral       0.94      0.97      0.96       387\n",
      "    positive       0.69      0.50      0.58        22\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.85      0.78      0.81       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.85        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.90      0.97      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.83      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 368.36013436317444 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.0022086119977757336\n",
      "Acquired samples: 25\n",
      "Sampling duration: 12.285639762878418 seconds\n",
      "New train size: 1997\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.478, Accuracy: 0.8813, F1 Micro: 0.9293, F1 Macro: 0.9214\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2955, Accuracy: 0.938, F1 Micro: 0.962, F1 Macro: 0.959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2023, Accuracy: 0.9434, F1 Micro: 0.9655, F1 Macro: 0.9632\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1622, Accuracy: 0.9516, F1 Micro: 0.9703, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1336, Accuracy: 0.9592, F1 Micro: 0.9747, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1101, Accuracy: 0.9597, F1 Micro: 0.9752, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0934, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0768, Accuracy: 0.9653, F1 Micro: 0.9785, F1 Macro: 0.9765\n",
      "Epoch 9/10, Train Loss: 0.0666, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "Epoch 10/10, Train Loss: 0.0581, Accuracy: 0.9618, F1 Micro: 0.9764, F1 Macro: 0.9744\n",
      "\n",
      "Aspect detection accuracy: 0.9653, F1 Micro: 0.9785, F1 Macro: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3418, Accuracy: 0.8504, F1 Micro: 0.8504, F1 Macro: 0.8213\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2101, Accuracy: 0.904, F1 Micro: 0.904, F1 Macro: 0.877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1325, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.8825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1056, Accuracy: 0.9178, F1 Micro: 0.9178, F1 Macro: 0.8914\n",
      "Epoch 5/10, Train Loss: 0.0853, Accuracy: 0.9141, F1 Micro: 0.9141, F1 Macro: 0.8884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0638, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.8978\n",
      "Epoch 7/10, Train Loss: 0.0564, Accuracy: 0.9178, F1 Micro: 0.9178, F1 Macro: 0.8919\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0413, Accuracy: 0.9243, F1 Micro: 0.9243, F1 Macro: 0.9026\n",
      "Epoch 9/10, Train Loss: 0.0227, Accuracy: 0.9215, F1 Micro: 0.9215, F1 Macro: 0.8985\n",
      "Epoch 10/10, Train Loss: 0.0242, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8884\n",
      "\n",
      "Sentiment analysis accuracy: 0.9243, F1 Micro: 0.9243, F1 Macro: 0.9026\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       774\n",
      "    positive       0.93      0.79      0.86       309\n",
      "\n",
      "    accuracy                           0.92      1083\n",
      "   macro avg       0.93      0.88      0.90      1083\n",
      "weighted avg       0.92      0.92      0.92      1083\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1997: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.8766\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.83      0.86       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.82      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.82      0.93      0.86       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.82      0.69      0.75        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.76      0.60      0.65       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.87      0.89       200\n",
      "     neutral       0.93      0.94      0.94       315\n",
      "    positive       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.88       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.73      0.50      0.59        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.86      0.78      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.96      0.96      0.96        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.45      0.59        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.80      0.80       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 363.30977869033813 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.0021777112036943437\n",
      "Acquired samples: 50\n",
      "Sampling duration: 11.254270553588867 seconds\n",
      "New train size: 2047\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4659, Accuracy: 0.8682, F1 Micro: 0.9225, F1 Macro: 0.9158\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2956, Accuracy: 0.9344, F1 Micro: 0.9601, F1 Macro: 0.9578\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2046, Accuracy: 0.951, F1 Micro: 0.9699, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1628, Accuracy: 0.9561, F1 Micro: 0.9729, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1312, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1158, Accuracy: 0.9618, F1 Micro: 0.9764, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0971, Accuracy: 0.9622, F1 Micro: 0.9766, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0787, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0678, Accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9769\n",
      "Epoch 10/10, Train Loss: 0.0589, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9791, F1 Macro: 0.9769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.98      0.98       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.95      0.95      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.98      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.98      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3519, Accuracy: 0.8602, F1 Micro: 0.8602, F1 Macro: 0.8123\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2054, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.87\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1384, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.882\n",
      "Epoch 4/10, Train Loss: 0.1005, Accuracy: 0.8978, F1 Micro: 0.8978, F1 Macro: 0.8641\n",
      "Epoch 5/10, Train Loss: 0.0773, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.877\n",
      "Epoch 6/10, Train Loss: 0.0702, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.8815\n",
      "Epoch 7/10, Train Loss: 0.0483, Accuracy: 0.905, F1 Micro: 0.905, F1 Macro: 0.8782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0384, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8853\n",
      "Epoch 9/10, Train Loss: 0.0403, Accuracy: 0.9014, F1 Micro: 0.9014, F1 Macro: 0.8762\n",
      "Epoch 10/10, Train Loss: 0.0283, Accuracy: 0.905, F1 Micro: 0.905, F1 Macro: 0.8787\n",
      "\n",
      "Sentiment analysis accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8853\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       792\n",
      "    positive       0.93      0.75      0.83       324\n",
      "\n",
      "    accuracy                           0.91      1116\n",
      "   macro avg       0.92      0.86      0.89      1116\n",
      "weighted avg       0.91      0.91      0.91      1116\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2047: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.8818\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        78\n",
      "     neutral       0.98      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.62      0.66       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.90      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.94      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86       162\n",
      "     neutral       0.95      0.96      0.95       387\n",
      "    positive       0.47      0.41      0.44        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.76      0.74      0.75       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.87      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.69      0.77        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 361.52166962623596 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.002063847426325083\n",
      "Acquired samples: 50\n",
      "Sampling duration: 9.415579080581665 seconds\n",
      "New train size: 2097\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4638, Accuracy: 0.8764, F1 Micro: 0.9276, F1 Macro: 0.9226\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2828, Accuracy: 0.9361, F1 Micro: 0.9611, F1 Macro: 0.9586\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1993, Accuracy: 0.9514, F1 Micro: 0.9701, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1597, Accuracy: 0.9573, F1 Micro: 0.9737, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1299, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1056, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0896, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0747, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0653, Accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9768\n",
      "Epoch 10/10, Train Loss: 0.0532, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3545, Accuracy: 0.8558, F1 Micro: 0.8558, F1 Macro: 0.8023\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2161, Accuracy: 0.903, F1 Micro: 0.903, F1 Macro: 0.8755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1336, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.8822\n",
      "Epoch 4/10, Train Loss: 0.0978, Accuracy: 0.903, F1 Micro: 0.903, F1 Macro: 0.8736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.068, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.8799\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0554, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.8859\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0392, Accuracy: 0.9166, F1 Micro: 0.9166, F1 Macro: 0.8936\n",
      "Epoch 8/10, Train Loss: 0.027, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.8893\n",
      "Epoch 9/10, Train Loss: 0.0303, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.8838\n",
      "Epoch 10/10, Train Loss: 0.0181, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.8901\n",
      "\n",
      "Sentiment analysis accuracy: 0.9166, F1 Micro: 0.9166, F1 Macro: 0.8936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       780\n",
      "    positive       0.93      0.77      0.84       323\n",
      "\n",
      "    accuracy                           0.92      1103\n",
      "   macro avg       0.92      0.87      0.89      1103\n",
      "weighted avg       0.92      0.92      0.91      1103\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2097: Accuracy: 0.9602, F1 Micro: 0.9602, F1 Macro: 0.8781\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.86      0.89        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.78      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.83      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.76      0.81        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.58      0.59       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.67      0.55      0.60        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.83      0.79      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.84      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.83      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 370.8089621067047 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.0033891851082444194\n",
      "Acquired samples: 50\n",
      "Sampling duration: 7.597778558731079 seconds\n",
      "New train size: 2147\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4656, Accuracy: 0.8722, F1 Micro: 0.9251, F1 Macro: 0.9194\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.276, Accuracy: 0.9366, F1 Micro: 0.9614, F1 Macro: 0.9592\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1945, Accuracy: 0.946, F1 Micro: 0.967, F1 Macro: 0.9647\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.156, Accuracy: 0.9509, F1 Micro: 0.9698, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1215, Accuracy: 0.9564, F1 Micro: 0.9731, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.105, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0868, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0702, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0626, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0528, Accuracy: 0.9653, F1 Micro: 0.9785, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.9653, F1 Micro: 0.9785, F1 Macro: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.91      0.98      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.99      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3378, Accuracy: 0.8783, F1 Micro: 0.8783, F1 Macro: 0.8423\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2076, Accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8777\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1354, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.8952\n",
      "Epoch 4/10, Train Loss: 0.0921, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.8925\n",
      "Epoch 5/10, Train Loss: 0.0817, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.8861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0551, Accuracy: 0.9223, F1 Micro: 0.9223, F1 Macro: 0.8978\n",
      "Epoch 7/10, Train Loss: 0.0466, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.8967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0319, Accuracy: 0.9223, F1 Micro: 0.9223, F1 Macro: 0.8992\n",
      "Epoch 9/10, Train Loss: 0.0253, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.8984\n",
      "Epoch 10/10, Train Loss: 0.0238, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.8876\n",
      "\n",
      "Sentiment analysis accuracy: 0.9223, F1 Micro: 0.9223, F1 Macro: 0.8992\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.95       768\n",
      "    positive       0.92      0.79      0.85       300\n",
      "\n",
      "    accuracy                           0.92      1068\n",
      "   macro avg       0.92      0.88      0.90      1068\n",
      "weighted avg       0.92      0.92      0.92      1068\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2147: Accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.8662\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.78      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.92      0.93       571\n",
      "weighted avg       0.95      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.88      0.68      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.60      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.80      0.85       162\n",
      "     neutral       0.91      0.98      0.95       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.73      0.78       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.80      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.86      0.96      0.90        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.59      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.97      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 379.2584295272827 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.0012778593692928553\n",
      "Acquired samples: 50\n",
      "Sampling duration: 5.976361513137817 seconds\n",
      "New train size: 2197\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.451, Accuracy: 0.8842, F1 Micro: 0.9314, F1 Macro: 0.9255\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.268, Accuracy: 0.9415, F1 Micro: 0.9642, F1 Macro: 0.9619\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1859, Accuracy: 0.9486, F1 Micro: 0.9685, F1 Macro: 0.9664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1537, Accuracy: 0.9557, F1 Micro: 0.9727, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1258, Accuracy: 0.9559, F1 Micro: 0.9728, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1041, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9749\n",
      "Epoch 7/10, Train Loss: 0.0849, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0725, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0603, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9762\n",
      "Epoch 10/10, Train Loss: 0.0511, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.93      0.98      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.346, Accuracy: 0.8492, F1 Micro: 0.8492, F1 Macro: 0.8193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2059, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1294, Accuracy: 0.9095, F1 Micro: 0.9095, F1 Macro: 0.8819\n",
      "Epoch 4/10, Train Loss: 0.1007, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.8776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0747, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0578, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.8989\n",
      "Epoch 7/10, Train Loss: 0.045, Accuracy: 0.9095, F1 Micro: 0.9095, F1 Macro: 0.8843\n",
      "Epoch 8/10, Train Loss: 0.0357, Accuracy: 0.915, F1 Micro: 0.915, F1 Macro: 0.8898\n",
      "Epoch 9/10, Train Loss: 0.0314, Accuracy: 0.9159, F1 Micro: 0.9159, F1 Macro: 0.8928\n",
      "Epoch 10/10, Train Loss: 0.0258, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8843\n",
      "\n",
      "Sentiment analysis accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.8989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       775\n",
      "    positive       0.93      0.79      0.85       319\n",
      "\n",
      "    accuracy                           0.92      1094\n",
      "   macro avg       0.92      0.88      0.90      1094\n",
      "weighted avg       0.92      0.92      0.92      1094\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2197: Accuracy: 0.9597, F1 Micro: 0.9597, F1 Macro: 0.8894\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.79      1.00      0.88        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.92      0.97      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.86      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.55      0.60      0.57        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.82      0.82      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.29      0.40         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.87      0.79      0.83        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.83      0.69      0.73       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89       200\n",
      "     neutral       0.93      0.93      0.93       315\n",
      "    positive       0.83      0.96      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.91       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.92      0.76      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.62      0.73        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.83      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 379.4197852611542 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.0015273577068001033\n",
      "Acquired samples: 50\n",
      "Sampling duration: 3.9984920024871826 seconds\n",
      "New train size: 2247\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4502, Accuracy: 0.8832, F1 Micro: 0.9307, F1 Macro: 0.9243\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2698, Accuracy: 0.9392, F1 Micro: 0.963, F1 Macro: 0.9603\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1882, Accuracy: 0.9486, F1 Micro: 0.9686, F1 Macro: 0.9667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.153, Accuracy: 0.9526, F1 Micro: 0.9709, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1219, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1017, Accuracy: 0.9646, F1 Micro: 0.9781, F1 Macro: 0.9761\n",
      "Epoch 7/10, Train Loss: 0.0835, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9745\n",
      "Epoch 8/10, Train Loss: 0.0707, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0601, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0503, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9764\n",
      "\n",
      "Aspect detection accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3515, Accuracy: 0.8628, F1 Micro: 0.8628, F1 Macro: 0.8255\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1913, Accuracy: 0.8847, F1 Micro: 0.8847, F1 Macro: 0.8435\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1252, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8802\n",
      "Epoch 4/10, Train Loss: 0.1079, Accuracy: 0.9085, F1 Micro: 0.9085, F1 Macro: 0.8834\n",
      "Epoch 5/10, Train Loss: 0.0693, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.056, Accuracy: 0.9131, F1 Micro: 0.9131, F1 Macro: 0.8866\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0361, Accuracy: 0.914, F1 Micro: 0.914, F1 Macro: 0.8879\n",
      "Epoch 8/10, Train Loss: 0.0407, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8786\n",
      "Epoch 9/10, Train Loss: 0.0213, Accuracy: 0.9131, F1 Micro: 0.9131, F1 Macro: 0.8869\n",
      "Epoch 10/10, Train Loss: 0.0205, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.885\n",
      "\n",
      "Sentiment analysis accuracy: 0.914, F1 Micro: 0.914, F1 Macro: 0.8879\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       781\n",
      "    positive       0.93      0.76      0.83       312\n",
      "\n",
      "    accuracy                           0.91      1093\n",
      "   macro avg       0.92      0.87      0.89      1093\n",
      "weighted avg       0.92      0.91      0.91      1093\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2247: Accuracy: 0.9594, F1 Micro: 0.9594, F1 Macro: 0.8833\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.97      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.86      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.81       571\n",
      "weighted avg       0.96      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.85      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.86      0.63      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.93      0.59      0.65       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.84      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.73      0.50      0.59        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.85      0.77      0.80       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.94      0.96      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.83      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 384.6878752708435 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.0012709985254332422\n",
      "Acquired samples: 36\n",
      "Sampling duration: 2.193781614303589 seconds\n",
      "New train size: 2283\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.448, Accuracy: 0.8863, F1 Micro: 0.9329, F1 Macro: 0.9283\n",
      "Higher F1 achieved, saving model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 0.265, Accuracy: 0.9384, F1 Micro: 0.9625, F1 Macro: 0.9599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1805, Accuracy: 0.9512, F1 Micro: 0.9701, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1446, Accuracy: 0.9559, F1 Micro: 0.9728, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.117, Accuracy: 0.9615, F1 Micro: 0.9762, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0978, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0837, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0709, Accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9767\n",
      "Epoch 9/10, Train Loss: 0.0585, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9758\n",
      "Epoch 10/10, Train Loss: 0.0497, Accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.96      0.92      0.94       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3612, Accuracy: 0.8638, F1 Micro: 0.8638, F1 Macro: 0.8152\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2116, Accuracy: 0.8857, F1 Micro: 0.8857, F1 Macro: 0.8454\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.135, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0983, Accuracy: 0.9095, F1 Micro: 0.9095, F1 Macro: 0.879\n",
      "Epoch 5/10, Train Loss: 0.0674, Accuracy: 0.9086, F1 Micro: 0.9086, F1 Macro: 0.8808\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0535, Accuracy: 0.9095, F1 Micro: 0.9095, F1 Macro: 0.883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0385, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8848\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0391, Accuracy: 0.9141, F1 Micro: 0.9141, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0326, Accuracy: 0.9168, F1 Micro: 0.9168, F1 Macro: 0.8907\n",
      "Epoch 10/10, Train Loss: 0.023, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.8834\n",
      "\n",
      "Sentiment analysis accuracy: 0.9168, F1 Micro: 0.9168, F1 Macro: 0.8907\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       785\n",
      "    positive       0.94      0.76      0.84       309\n",
      "\n",
      "    accuracy                           0.92      1094\n",
      "   macro avg       0.92      0.87      0.89      1094\n",
      "weighted avg       0.92      0.92      0.91      1094\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2283: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.8854\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.94        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.84      0.86       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.89      0.62      0.73        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.58      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.91      0.91       200\n",
      "     neutral       0.96      0.92      0.94       315\n",
      "    positive       0.83      0.98      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.94      0.92       571\n",
      "weighted avg       0.93      0.92      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.75      0.55      0.63        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.86      0.79      0.82       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.84      0.85        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.91      0.91      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.83      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 392.5757451057434 s\n",
      "Total runtime: 8551.809144496918 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabb7ddd",
   "metadata": {
    "papermill": {
     "duration": 0.181438,
     "end_time": "2025-03-31T06:55:45.164760",
     "exception": false,
     "start_time": "2025-03-31T06:55:44.983322",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45e74eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 3\n",
      "Random seed: 14\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba27d7514b2406993863ba48b6363d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6341, Accuracy: 0.7974, F1 Micro: 0.8859, F1 Macro: 0.8768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5134, Accuracy: 0.8014, F1 Micro: 0.8897, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4829, Accuracy: 0.8017, F1 Micro: 0.8897, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4632, Accuracy: 0.8045, F1 Micro: 0.8906, F1 Macro: 0.8847\n",
      "Epoch 5/10, Train Loss: 0.4642, Accuracy: 0.8047, F1 Micro: 0.8903, F1 Macro: 0.8835\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4501, Accuracy: 0.8075, F1 Micro: 0.891, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.451, Accuracy: 0.8149, F1 Micro: 0.8947, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4034, Accuracy: 0.8273, F1 Micro: 0.9007, F1 Macro: 0.892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3957, Accuracy: 0.8345, F1 Micro: 0.9041, F1 Macro: 0.8954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3562, Accuracy: 0.8448, F1 Micro: 0.9097, F1 Macro: 0.9016\n",
      "\n",
      "Aspect detection accuracy: 0.8448, F1 Micro: 0.9097, F1 Macro: 0.9016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.83      1.00      0.90       462\n",
      "   air_panas       0.83      1.00      0.91       480\n",
      "         bau       0.86      1.00      0.93       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.70      0.75      0.73       317\n",
      "       linen       0.77      0.94      0.85       392\n",
      "     service       0.90      0.98      0.94       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.90      1.00      0.95       516\n",
      "        wifi       0.88      1.00      0.94       498\n",
      "\n",
      "   micro avg       0.85      0.98      0.91      4614\n",
      "   macro avg       0.85      0.97      0.90      4614\n",
      "weighted avg       0.85      0.98      0.91      4614\n",
      " samples avg       0.85      0.97      0.91      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7316, Accuracy: 0.5412, F1 Micro: 0.5412, F1 Macro: 0.3512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.612, Accuracy: 0.5412, F1 Micro: 0.5412, F1 Macro: 0.3512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5437, Accuracy: 0.5645, F1 Micro: 0.5645, F1 Macro: 0.4185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5596, Accuracy: 0.5751, F1 Micro: 0.5751, F1 Macro: 0.4522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4998, Accuracy: 0.5877, F1 Micro: 0.5877, F1 Macro: 0.5659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.478, Accuracy: 0.6025, F1 Micro: 0.6025, F1 Macro: 0.5626\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3806, Accuracy: 0.666, F1 Micro: 0.666, F1 Macro: 0.6564\n",
      "Epoch 8/10, Train Loss: 0.3522, Accuracy: 0.6195, F1 Micro: 0.6195, F1 Macro: 0.5823\n",
      "Epoch 9/10, Train Loss: 0.3548, Accuracy: 0.6575, F1 Micro: 0.6575, F1 Macro: 0.6482\n",
      "Epoch 10/10, Train Loss: 0.3088, Accuracy: 0.6237, F1 Micro: 0.6237, F1 Macro: 0.6009\n",
      "\n",
      "Sentiment analysis accuracy: 0.666, F1 Micro: 0.666, F1 Macro: 0.6564\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.77      0.71       256\n",
      "    positive       0.67      0.54      0.60       217\n",
      "\n",
      "    accuracy                           0.67       473\n",
      "   macro avg       0.67      0.66      0.66       473\n",
      "weighted avg       0.67      0.67      0.66       473\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 142: Accuracy: 0.8285, F1 Micro: 0.8285, F1 Macro: 0.4061\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.16      0.28        97\n",
      "     neutral       0.83      1.00      0.91       459\n",
      "    positive       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.61      0.39      0.40       571\n",
      "weighted avg       0.83      0.83      0.78       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        86\n",
      "     neutral       0.83      1.00      0.91       475\n",
      "    positive       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.28      0.33      0.30       571\n",
      "weighted avg       0.69      0.83      0.76       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        78\n",
      "     neutral       0.86      1.00      0.92       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.74      0.86      0.80       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.43      0.50       200\n",
      "     neutral       0.70      0.75      0.73       315\n",
      "    positive       0.28      0.45      0.34        56\n",
      "\n",
      "    accuracy                           0.61       571\n",
      "   macro avg       0.53      0.54      0.52       571\n",
      "weighted avg       0.62      0.61      0.61       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.30      0.42       162\n",
      "     neutral       0.76      0.94      0.84       387\n",
      "    positive       0.17      0.18      0.18        22\n",
      "\n",
      "    accuracy                           0.73       571\n",
      "   macro avg       0.54      0.47      0.48       571\n",
      "weighted avg       0.72      0.73      0.70       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.41      0.51        85\n",
      "     neutral       0.90      0.98      0.93       418\n",
      "    positive       0.72      0.68      0.70        68\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.76      0.69      0.71       571\n",
      "weighted avg       0.84      0.86      0.84       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.89      1.00      0.94       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.30      0.33      0.31       571\n",
      "weighted avg       0.80      0.89      0.85       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.24        74\n",
      "     neutral       0.88      1.00      0.94       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.63      0.38      0.39       571\n",
      "weighted avg       0.89      0.88      0.84       571\n",
      "\n",
      "Total train time: 83.44769215583801 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.004959636321291328\n",
      "Acquired samples: 215\n",
      "Sampling duration: 58.641945600509644 seconds\n",
      "New train size: 357\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5769, Accuracy: 0.7766, F1 Micro: 0.8704, F1 Macro: 0.8476\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.514, Accuracy: 0.8146, F1 Micro: 0.8935, F1 Macro: 0.8854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4706, Accuracy: 0.8175, F1 Micro: 0.8966, F1 Macro: 0.8906\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4465, Accuracy: 0.83, F1 Micro: 0.903, F1 Macro: 0.8977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4282, Accuracy: 0.8399, F1 Micro: 0.9082, F1 Macro: 0.9031\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3909, Accuracy: 0.8726, F1 Micro: 0.9249, F1 Macro: 0.9188\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3454, Accuracy: 0.8918, F1 Micro: 0.9356, F1 Macro: 0.9306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2891, Accuracy: 0.9024, F1 Micro: 0.9414, F1 Macro: 0.9367\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2512, Accuracy: 0.9116, F1 Micro: 0.9467, F1 Macro: 0.9429\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2292, Accuracy: 0.9212, F1 Micro: 0.9524, F1 Macro: 0.9489\n",
      "\n",
      "Aspect detection accuracy: 0.9212, F1 Micro: 0.9524, F1 Macro: 0.9489\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.98       462\n",
      "   air_panas       0.94      0.99      0.96       480\n",
      "         bau       0.87      1.00      0.93       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.84      0.90      0.87       317\n",
      "       linen       0.84      0.97      0.90       392\n",
      "     service       0.95      0.97      0.96       423\n",
      "sunrise_meal       0.96      0.99      0.98       530\n",
      "          tv       0.98      0.99      0.99       516\n",
      "        wifi       0.99      0.99      0.99       498\n",
      "\n",
      "   micro avg       0.92      0.98      0.95      4614\n",
      "   macro avg       0.92      0.98      0.95      4614\n",
      "weighted avg       0.93      0.98      0.95      4614\n",
      " samples avg       0.92      0.98      0.95      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6506, Accuracy: 0.7157, F1 Micro: 0.7157, F1 Macro: 0.4171\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5591, Accuracy: 0.8112, F1 Micro: 0.8112, F1 Macro: 0.7227\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3827, Accuracy: 0.8507, F1 Micro: 0.8507, F1 Macro: 0.795\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3439, Accuracy: 0.8519, F1 Micro: 0.8519, F1 Macro: 0.811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.249, Accuracy: 0.8578, F1 Micro: 0.8578, F1 Macro: 0.8028\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1974, Accuracy: 0.8769, F1 Micro: 0.8769, F1 Macro: 0.8371\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.134, Accuracy: 0.8817, F1 Micro: 0.8817, F1 Macro: 0.8453\n",
      "Epoch 8/10, Train Loss: 0.1171, Accuracy: 0.8769, F1 Micro: 0.8769, F1 Macro: 0.8366\n",
      "Epoch 9/10, Train Loss: 0.104, Accuracy: 0.8769, F1 Micro: 0.8769, F1 Macro: 0.8311\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0659, Accuracy: 0.8829, F1 Micro: 0.8829, F1 Macro: 0.8447\n",
      "\n",
      "Sentiment analysis accuracy: 0.8829, F1 Micro: 0.8829, F1 Macro: 0.8447\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92       599\n",
      "    positive       0.88      0.68      0.77       238\n",
      "\n",
      "    accuracy                           0.88       837\n",
      "   macro avg       0.88      0.82      0.84       837\n",
      "weighted avg       0.88      0.88      0.88       837\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 357: Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.7154\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.88      0.91        97\n",
      "     neutral       0.98      0.99      0.98       459\n",
      "    positive       0.87      0.87      0.87        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.65      0.76        86\n",
      "     neutral       0.94      0.99      0.96       475\n",
      "    positive       0.50      0.30      0.37        10\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.78      0.65      0.70       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.09      0.16        78\n",
      "     neutral       0.87      1.00      0.93       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.55      0.36      0.36       571\n",
      "weighted avg       0.85      0.87      0.82       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.67      0.03      0.06        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.51      0.34      0.33       571\n",
      "weighted avg       0.84      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.72      0.78       200\n",
      "     neutral       0.84      0.90      0.87       315\n",
      "    positive       0.77      0.84      0.80        56\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.82      0.82      0.82       571\n",
      "weighted avg       0.83      0.83      0.83       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.61      0.71       162\n",
      "     neutral       0.83      0.97      0.90       387\n",
      "    positive       0.75      0.14      0.23        22\n",
      "\n",
      "    accuracy                           0.84       571\n",
      "   macro avg       0.81      0.57      0.61       571\n",
      "weighted avg       0.84      0.84      0.82       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.74      0.79        85\n",
      "     neutral       0.95      0.97      0.96       418\n",
      "    positive       0.86      0.90      0.88        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.88      0.87      0.88       571\n",
      "weighted avg       0.92      0.93      0.93       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.31      0.44        29\n",
      "     neutral       0.96      0.99      0.98       525\n",
      "    positive       0.75      0.71      0.73        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.82      0.67      0.71       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.87      0.90        54\n",
      "     neutral       0.98      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.97      0.84      0.90       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.89      0.92        74\n",
      "     neutral       0.99      0.99      0.99       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.96      0.92       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 132.87312769889832 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.009701472334563732\n",
      "Acquired samples: 193\n",
      "Sampling duration: 63.482770919799805 seconds\n",
      "New train size: 550\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5347, Accuracy: 0.8036, F1 Micro: 0.8908, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4526, Accuracy: 0.8137, F1 Micro: 0.894, F1 Macro: 0.8874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4123, Accuracy: 0.8328, F1 Micro: 0.9048, F1 Macro: 0.8998\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3646, Accuracy: 0.8714, F1 Micro: 0.9248, F1 Macro: 0.92\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3118, Accuracy: 0.9005, F1 Micro: 0.9406, F1 Macro: 0.9362\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2606, Accuracy: 0.9076, F1 Micro: 0.9448, F1 Macro: 0.9412\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2302, Accuracy: 0.9273, F1 Micro: 0.9558, F1 Macro: 0.9523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1988, Accuracy: 0.9354, F1 Micro: 0.9605, F1 Macro: 0.9571\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1616, Accuracy: 0.9401, F1 Micro: 0.9634, F1 Macro: 0.96\n",
      "Epoch 10/10, Train Loss: 0.1505, Accuracy: 0.9396, F1 Micro: 0.9631, F1 Macro: 0.9597\n",
      "\n",
      "Aspect detection accuracy: 0.9401, F1 Micro: 0.9634, F1 Macro: 0.96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.95      0.99      0.97       480\n",
      "         bau       0.95      0.98      0.97       496\n",
      "     general       0.88      1.00      0.93       500\n",
      "  kebersihan       0.85      0.91      0.88       317\n",
      "       linen       0.90      0.96      0.93       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.96      1.00      0.98       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.99      0.99      0.99       498\n",
      "\n",
      "   micro avg       0.94      0.98      0.96      4614\n",
      "   macro avg       0.94      0.98      0.96      4614\n",
      "weighted avg       0.95      0.98      0.96      4614\n",
      " samples avg       0.94      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5534, Accuracy: 0.7756, F1 Micro: 0.7756, F1 Macro: 0.5987\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4042, Accuracy: 0.8272, F1 Micro: 0.8272, F1 Macro: 0.7313\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.32, Accuracy: 0.8672, F1 Micro: 0.8672, F1 Macro: 0.8148\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2567, Accuracy: 0.8746, F1 Micro: 0.8746, F1 Macro: 0.83\n",
      "Epoch 5/10, Train Loss: 0.1945, Accuracy: 0.8493, F1 Micro: 0.8493, F1 Macro: 0.7739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1609, Accuracy: 0.8767, F1 Micro: 0.8767, F1 Macro: 0.8266\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1068, Accuracy: 0.8799, F1 Micro: 0.8799, F1 Macro: 0.8275\n",
      "Epoch 8/10, Train Loss: 0.0936, Accuracy: 0.8788, F1 Micro: 0.8788, F1 Macro: 0.8285\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.082, Accuracy: 0.8883, F1 Micro: 0.8883, F1 Macro: 0.8447\n",
      "Epoch 10/10, Train Loss: 0.0558, Accuracy: 0.8799, F1 Micro: 0.8799, F1 Macro: 0.8324\n",
      "\n",
      "Sentiment analysis accuracy: 0.8883, F1 Micro: 0.8883, F1 Macro: 0.8447\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.97      0.93       691\n",
      "    positive       0.90      0.66      0.76       258\n",
      "\n",
      "    accuracy                           0.89       949\n",
      "   macro avg       0.89      0.82      0.84       949\n",
      "weighted avg       0.89      0.89      0.88       949\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 550: Accuracy: 0.9329, F1 Micro: 0.9329, F1 Macro: 0.7795\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.90      0.93        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.96      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.70      0.78        86\n",
      "     neutral       0.95      0.99      0.97       475\n",
      "    positive       0.60      0.30      0.40        10\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.81      0.66      0.72       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.71      0.78        78\n",
      "     neutral       0.95      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.73      0.80       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.88      1.00      0.93       496\n",
      "    positive       0.88      0.10      0.18        68\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.58      0.37      0.37       571\n",
      "weighted avg       0.87      0.88      0.83       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.75      0.80       200\n",
      "     neutral       0.85      0.90      0.88       315\n",
      "    positive       0.84      0.93      0.88        56\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.85      0.86      0.85       571\n",
      "weighted avg       0.85      0.85      0.85       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.80      0.82       162\n",
      "     neutral       0.90      0.96      0.93       387\n",
      "    positive       0.75      0.14      0.23        22\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.83      0.63      0.66       571\n",
      "weighted avg       0.88      0.88      0.87       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.76      0.81        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.87      0.87      0.87        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.89      0.87      0.88       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.28      0.41        29\n",
      "     neutral       0.96      1.00      0.98       525\n",
      "    positive       0.75      0.71      0.73        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.84      0.66      0.71       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.98      0.86      0.91       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.95      0.95        74\n",
      "     neutral       0.99      0.99      0.99       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.90      0.98      0.93       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 155.57780385017395 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.008348324615508319\n",
      "Acquired samples: 174\n",
      "Sampling duration: 61.490214586257935 seconds\n",
      "New train size: 724\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5324, Accuracy: 0.808, F1 Micro: 0.8928, F1 Macro: 0.8883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4583, Accuracy: 0.8226, F1 Micro: 0.8993, F1 Macro: 0.8946\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4124, Accuracy: 0.87, F1 Micro: 0.9238, F1 Macro: 0.9186\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3408, Accuracy: 0.8957, F1 Micro: 0.9381, F1 Macro: 0.9342\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2929, Accuracy: 0.9208, F1 Micro: 0.9519, F1 Macro: 0.948\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2374, Accuracy: 0.9332, F1 Micro: 0.9593, F1 Macro: 0.9565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2057, Accuracy: 0.9377, F1 Micro: 0.9619, F1 Macro: 0.9584\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1826, Accuracy: 0.9411, F1 Micro: 0.9641, F1 Macro: 0.9612\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1515, Accuracy: 0.9448, F1 Micro: 0.9661, F1 Macro: 0.963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1313, Accuracy: 0.9481, F1 Micro: 0.9681, F1 Macro: 0.9649\n",
      "\n",
      "Aspect detection accuracy: 0.9481, F1 Micro: 0.9681, F1 Macro: 0.9649\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.96      0.99      0.98       480\n",
      "         bau       0.95      0.99      0.97       496\n",
      "     general       0.91      0.99      0.95       500\n",
      "  kebersihan       0.88      0.91      0.90       317\n",
      "       linen       0.88      0.97      0.92       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      4614\n",
      "   macro avg       0.95      0.98      0.96      4614\n",
      "weighted avg       0.95      0.98      0.97      4614\n",
      " samples avg       0.95      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5417, Accuracy: 0.797, F1 Micro: 0.797, F1 Macro: 0.7638\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3816, Accuracy: 0.8711, F1 Micro: 0.8711, F1 Macro: 0.8343\n",
      "Epoch 3/10, Train Loss: 0.2783, Accuracy: 0.867, F1 Micro: 0.867, F1 Macro: 0.8162\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1983, Accuracy: 0.8883, F1 Micro: 0.8883, F1 Macro: 0.8534\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2086, Accuracy: 0.8893, F1 Micro: 0.8893, F1 Macro: 0.8578\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1183, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8709\n",
      "Epoch 7/10, Train Loss: 0.071, Accuracy: 0.8924, F1 Micro: 0.8924, F1 Macro: 0.8645\n",
      "Epoch 8/10, Train Loss: 0.0659, Accuracy: 0.8995, F1 Micro: 0.8995, F1 Macro: 0.8695\n",
      "Epoch 9/10, Train Loss: 0.0571, Accuracy: 0.8934, F1 Micro: 0.8934, F1 Macro: 0.8568\n",
      "Epoch 10/10, Train Loss: 0.0414, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.8676\n",
      "\n",
      "Sentiment analysis accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93       708\n",
      "    positive       0.89      0.74      0.81       277\n",
      "\n",
      "    accuracy                           0.90       985\n",
      "   macro avg       0.90      0.85      0.87       985\n",
      "weighted avg       0.90      0.90      0.90       985\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 724: Accuracy: 0.9406, F1 Micro: 0.9406, F1 Macro: 0.8106\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.98      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.77      0.84        86\n",
      "     neutral       0.96      0.99      0.98       475\n",
      "    positive       0.50      0.40      0.44        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.80      0.72      0.75       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.68      0.77        78\n",
      "     neutral       0.95      0.99      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.95      0.72      0.80       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.91      0.99      0.95       496\n",
      "    positive       0.86      0.35      0.50        68\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.59      0.45      0.48       571\n",
      "weighted avg       0.89      0.90      0.88       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.79      0.83       200\n",
      "     neutral       0.88      0.91      0.90       315\n",
      "    positive       0.83      0.95      0.88        56\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.86      0.88      0.87       571\n",
      "weighted avg       0.87      0.87      0.87       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.73      0.79       162\n",
      "     neutral       0.88      0.97      0.92       387\n",
      "    positive       0.71      0.23      0.34        22\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.82      0.64      0.69       571\n",
      "weighted avg       0.87      0.87      0.86       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.75      0.83        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.86      0.94      0.90        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.89      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.41      0.56        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.82      0.76        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.75      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.95      0.96        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.98      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 179.72118210792542 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.007184798922389747\n",
      "Acquired samples: 156\n",
      "Sampling duration: 57.16083216667175 seconds\n",
      "New train size: 880\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5196, Accuracy: 0.8076, F1 Micro: 0.8926, F1 Macro: 0.8882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4267, Accuracy: 0.8434, F1 Micro: 0.9099, F1 Macro: 0.9051\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3518, Accuracy: 0.8946, F1 Micro: 0.9367, F1 Macro: 0.9308\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2771, Accuracy: 0.9085, F1 Micro: 0.9454, F1 Macro: 0.9416\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2283, Accuracy: 0.9316, F1 Micro: 0.9584, F1 Macro: 0.9549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1944, Accuracy: 0.9391, F1 Micro: 0.9629, F1 Macro: 0.9597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1671, Accuracy: 0.9474, F1 Micro: 0.9677, F1 Macro: 0.9646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1392, Accuracy: 0.9502, F1 Micro: 0.9694, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1252, Accuracy: 0.9505, F1 Micro: 0.9695, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1068, Accuracy: 0.9536, F1 Micro: 0.9713, F1 Macro: 0.968\n",
      "\n",
      "Aspect detection accuracy: 0.9536, F1 Micro: 0.9713, F1 Macro: 0.968\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.97      0.96       500\n",
      "  kebersihan       0.88      0.92      0.90       317\n",
      "       linen       0.92      0.94      0.93       392\n",
      "     service       0.95      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5401, Accuracy: 0.8346, F1 Micro: 0.8346, F1 Macro: 0.8013\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3328, Accuracy: 0.8733, F1 Micro: 0.8733, F1 Macro: 0.8438\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2467, Accuracy: 0.8837, F1 Micro: 0.8837, F1 Macro: 0.8562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1792, Accuracy: 0.8904, F1 Micro: 0.8904, F1 Macro: 0.8642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1326, Accuracy: 0.8922, F1 Micro: 0.8922, F1 Macro: 0.8663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0845, Accuracy: 0.8951, F1 Micro: 0.8951, F1 Macro: 0.8718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0725, Accuracy: 0.8951, F1 Micro: 0.8951, F1 Macro: 0.8683\n",
      "Epoch 8/10, Train Loss: 0.0728, Accuracy: 0.8904, F1 Micro: 0.8904, F1 Macro: 0.861\n",
      "Epoch 9/10, Train Loss: 0.0339, Accuracy: 0.8922, F1 Micro: 0.8922, F1 Macro: 0.864\n",
      "Epoch 10/10, Train Loss: 0.0367, Accuracy: 0.8875, F1 Micro: 0.8875, F1 Macro: 0.856\n",
      "\n",
      "Sentiment analysis accuracy: 0.8951, F1 Micro: 0.8951, F1 Macro: 0.8683\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93       733\n",
      "    positive       0.92      0.72      0.81       325\n",
      "\n",
      "    accuracy                           0.90      1058\n",
      "   macro avg       0.90      0.85      0.87      1058\n",
      "weighted avg       0.90      0.90      0.89      1058\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 880: Accuracy: 0.9457, F1 Micro: 0.9457, F1 Macro: 0.8194\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.90      0.78      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.76      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.97      0.96       496\n",
      "    positive       0.75      0.72      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.57      0.56      0.57       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.79      0.83       200\n",
      "     neutral       0.88      0.92      0.90       315\n",
      "    positive       0.85      0.91      0.88        56\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.87      0.87      0.87       571\n",
      "weighted avg       0.87      0.87      0.87       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.81      0.81       162\n",
      "     neutral       0.92      0.95      0.93       387\n",
      "    positive       0.54      0.32      0.40        22\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.76      0.69      0.72       571\n",
      "weighted avg       0.88      0.88      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.76      0.84        85\n",
      "     neutral       0.95      0.99      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.89      0.91       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.41      0.53        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.68      0.76      0.72        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.80      0.72      0.75       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.33      0.50         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.76      0.81       571\n",
      "weighted avg       0.99      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 205.69451665878296 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0047507295850664375\n",
      "Acquired samples: 141\n",
      "Sampling duration: 51.96614170074463 seconds\n",
      "New train size: 1021\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5106, Accuracy: 0.8021, F1 Micro: 0.89, F1 Macro: 0.8854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4175, Accuracy: 0.8642, F1 Micro: 0.9203, F1 Macro: 0.9137\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3397, Accuracy: 0.8974, F1 Micro: 0.9388, F1 Macro: 0.9344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2699, Accuracy: 0.933, F1 Micro: 0.959, F1 Macro: 0.9552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2235, Accuracy: 0.942, F1 Micro: 0.9644, F1 Macro: 0.9617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1836, Accuracy: 0.9436, F1 Micro: 0.9655, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1645, Accuracy: 0.9462, F1 Micro: 0.9669, F1 Macro: 0.9638\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.135, Accuracy: 0.9524, F1 Micro: 0.9707, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1197, Accuracy: 0.9535, F1 Micro: 0.9713, F1 Macro: 0.9683\n",
      "Epoch 10/10, Train Loss: 0.1032, Accuracy: 0.9521, F1 Micro: 0.9705, F1 Macro: 0.9676\n",
      "\n",
      "Aspect detection accuracy: 0.9535, F1 Micro: 0.9713, F1 Macro: 0.9683\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.96      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.93      0.98      0.96       500\n",
      "  kebersihan       0.91      0.91      0.91       317\n",
      "       linen       0.91      0.97      0.94       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.472, Accuracy: 0.837, F1 Micro: 0.837, F1 Macro: 0.7811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3043, Accuracy: 0.8648, F1 Micro: 0.8648, F1 Macro: 0.8355\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2299, Accuracy: 0.8859, F1 Micro: 0.8859, F1 Macro: 0.8533\n",
      "Epoch 4/10, Train Loss: 0.1641, Accuracy: 0.8802, F1 Micro: 0.8802, F1 Macro: 0.8389\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1245, Accuracy: 0.8945, F1 Micro: 0.8945, F1 Macro: 0.8642\n",
      "Epoch 6/10, Train Loss: 0.0872, Accuracy: 0.8859, F1 Micro: 0.8859, F1 Macro: 0.8474\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0687, Accuracy: 0.9032, F1 Micro: 0.9032, F1 Macro: 0.8734\n",
      "Epoch 8/10, Train Loss: 0.0518, Accuracy: 0.8965, F1 Micro: 0.8965, F1 Macro: 0.8637\n",
      "Epoch 9/10, Train Loss: 0.0348, Accuracy: 0.9003, F1 Micro: 0.9003, F1 Macro: 0.8701\n",
      "Epoch 10/10, Train Loss: 0.0368, Accuracy: 0.8945, F1 Micro: 0.8945, F1 Macro: 0.8616\n",
      "\n",
      "Sentiment analysis accuracy: 0.9032, F1 Micro: 0.9032, F1 Macro: 0.8734\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93       738\n",
      "    positive       0.94      0.71      0.81       305\n",
      "\n",
      "    accuracy                           0.90      1043\n",
      "   macro avg       0.92      0.85      0.87      1043\n",
      "weighted avg       0.91      0.90      0.90      1043\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1021: Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.8449\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.79      0.85        86\n",
      "     neutral       0.96      0.99      0.98       475\n",
      "    positive       0.80      0.40      0.53        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.89      0.73      0.79       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.78      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.14      0.20         7\n",
      "     neutral       0.93      0.98      0.96       496\n",
      "    positive       0.84      0.53      0.65        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.70      0.55      0.60       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.84      0.85       200\n",
      "     neutral       0.91      0.90      0.91       315\n",
      "    positive       0.87      0.93      0.90        56\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.88      0.89      0.88       571\n",
      "weighted avg       0.88      0.88      0.88       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.78      0.83       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.64      0.41      0.50        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.81      0.72      0.76       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.95      0.91      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.48      0.61        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.77      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.95      0.96        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 227.03755140304565 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0035521372687071563\n",
      "Acquired samples: 127\n",
      "Sampling duration: 46.95641565322876 seconds\n",
      "New train size: 1148\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4989, Accuracy: 0.8057, F1 Micro: 0.8915, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4025, Accuracy: 0.8811, F1 Micro: 0.9301, F1 Macro: 0.9258\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3118, Accuracy: 0.9134, F1 Micro: 0.9479, F1 Macro: 0.9445\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2406, Accuracy: 0.9354, F1 Micro: 0.9607, F1 Macro: 0.9579\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2045, Accuracy: 0.9458, F1 Micro: 0.9667, F1 Macro: 0.9639\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1732, Accuracy: 0.9477, F1 Micro: 0.968, F1 Macro: 0.9652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1358, Accuracy: 0.9514, F1 Micro: 0.9701, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.12, Accuracy: 0.9536, F1 Micro: 0.9715, F1 Macro: 0.9687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1044, Accuracy: 0.9543, F1 Micro: 0.9718, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0894, Accuracy: 0.9592, F1 Micro: 0.9748, F1 Macro: 0.9721\n",
      "\n",
      "Aspect detection accuracy: 0.9592, F1 Micro: 0.9748, F1 Macro: 0.9721\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.90      0.93      0.92       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4445, Accuracy: 0.8384, F1 Micro: 0.8384, F1 Macro: 0.7693\n",
      "Epoch 2/10, Train Loss: 0.2867, Accuracy: 0.8261, F1 Micro: 0.8261, F1 Macro: 0.736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2102, Accuracy: 0.8904, F1 Micro: 0.8904, F1 Macro: 0.8536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1655, Accuracy: 0.896, F1 Micro: 0.896, F1 Macro: 0.8626\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1169, Accuracy: 0.8998, F1 Micro: 0.8998, F1 Macro: 0.8716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0799, Accuracy: 0.8998, F1 Micro: 0.8998, F1 Macro: 0.871\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0628, Accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.8807\n",
      "Epoch 8/10, Train Loss: 0.0485, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0291, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.884\n",
      "Epoch 10/10, Train Loss: 0.0367, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8799\n",
      "\n",
      "Sentiment analysis accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       753\n",
      "    positive       0.94      0.74      0.83       305\n",
      "\n",
      "    accuracy                           0.91      1058\n",
      "   macro avg       0.92      0.86      0.88      1058\n",
      "weighted avg       0.91      0.91      0.91      1058\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1148: Accuracy: 0.9531, F1 Micro: 0.9531, F1 Macro: 0.853\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.94      0.93        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.92      0.73      0.81        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.89      0.91       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.84      0.88        86\n",
      "     neutral       0.97      1.00      0.98       475\n",
      "    positive       0.80      0.40      0.53        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.90      0.74      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.78      0.82        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.84      0.63      0.72        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.93      0.59      0.64       571\n",
      "weighted avg       0.93      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86       200\n",
      "     neutral       0.90      0.93      0.92       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.89      0.90      0.89       571\n",
      "weighted avg       0.90      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.80      0.55      0.65        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.87      0.79      0.82       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.84      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.91      0.92        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.97      0.86      0.90       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 244.2654619216919 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0027509547071531415\n",
      "Acquired samples: 114\n",
      "Sampling duration: 42.993669748306274 seconds\n",
      "New train size: 1262\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4959, Accuracy: 0.8188, F1 Micro: 0.8968, F1 Macro: 0.8888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3936, Accuracy: 0.8894, F1 Micro: 0.9343, F1 Macro: 0.9295\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2959, Accuracy: 0.9212, F1 Micro: 0.9526, F1 Macro: 0.9493\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2238, Accuracy: 0.9396, F1 Micro: 0.9629, F1 Macro: 0.9601\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1808, Accuracy: 0.9488, F1 Micro: 0.9685, F1 Macro: 0.9657\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1626, Accuracy: 0.9554, F1 Micro: 0.9724, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1312, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1146, Accuracy: 0.959, F1 Micro: 0.9746, F1 Macro: 0.9722\n",
      "Epoch 9/10, Train Loss: 0.0941, Accuracy: 0.9585, F1 Micro: 0.9743, F1 Macro: 0.9718\n",
      "Epoch 10/10, Train Loss: 0.084, Accuracy: 0.9575, F1 Micro: 0.9738, F1 Macro: 0.9712\n",
      "\n",
      "Aspect detection accuracy: 0.959, F1 Micro: 0.9746, F1 Macro: 0.9722\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.93      0.99      0.96       500\n",
      "  kebersihan       0.93      0.91      0.92       317\n",
      "       linen       0.92      0.98      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4699, Accuracy: 0.8346, F1 Micro: 0.8346, F1 Macro: 0.8006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2795, Accuracy: 0.8828, F1 Micro: 0.8828, F1 Macro: 0.8477\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1923, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1437, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.8873\n",
      "Epoch 5/10, Train Loss: 0.0998, Accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8746\n",
      "Epoch 6/10, Train Loss: 0.085, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8832\n",
      "Epoch 7/10, Train Loss: 0.0579, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8777\n",
      "Epoch 8/10, Train Loss: 0.0509, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8751\n",
      "Epoch 9/10, Train Loss: 0.046, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8755\n",
      "Epoch 10/10, Train Loss: 0.0215, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8747\n",
      "\n",
      "Sentiment analysis accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.8873\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       756\n",
      "    positive       0.92      0.76      0.83       302\n",
      "\n",
      "    accuracy                           0.91      1058\n",
      "   macro avg       0.92      0.87      0.89      1058\n",
      "weighted avg       0.91      0.91      0.91      1058\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1262: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.8478\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.83      0.88        86\n",
      "     neutral       0.97      1.00      0.98       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.91      0.77      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.82      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.99      0.96       496\n",
      "    positive       0.86      0.56      0.68        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.60      0.52      0.55       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88       200\n",
      "     neutral       0.93      0.91      0.92       315\n",
      "    positive       0.80      0.95      0.87        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.87      0.91      0.89       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.80      0.85       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       0.79      0.50      0.61        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.76      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.90      0.94      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.45      0.59        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.68      0.88      0.77        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.78      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.97      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 251.32853841781616 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.003024667338468134\n",
      "Acquired samples: 103\n",
      "Sampling duration: 38.436182260513306 seconds\n",
      "New train size: 1365\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4909, Accuracy: 0.8203, F1 Micro: 0.8987, F1 Macro: 0.8938\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.376, Accuracy: 0.8981, F1 Micro: 0.9394, F1 Macro: 0.9355\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2771, Accuracy: 0.9309, F1 Micro: 0.9579, F1 Macro: 0.9549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2173, Accuracy: 0.9448, F1 Micro: 0.9662, F1 Macro: 0.9637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1721, Accuracy: 0.9505, F1 Micro: 0.9695, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1503, Accuracy: 0.958, F1 Micro: 0.9739, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.124, Accuracy: 0.9597, F1 Micro: 0.975, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1062, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0886, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0768, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9742\n",
      "\n",
      "Aspect detection accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.92      0.98      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4392, Accuracy: 0.8359, F1 Micro: 0.8359, F1 Macro: 0.8077\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2503, Accuracy: 0.8863, F1 Micro: 0.8863, F1 Macro: 0.8575\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1626, Accuracy: 0.901, F1 Micro: 0.901, F1 Macro: 0.8723\n",
      "Epoch 4/10, Train Loss: 0.1283, Accuracy: 0.8992, F1 Micro: 0.8992, F1 Macro: 0.8733\n",
      "Epoch 5/10, Train Loss: 0.0885, Accuracy: 0.8983, F1 Micro: 0.8983, F1 Macro: 0.8681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.063, Accuracy: 0.9056, F1 Micro: 0.9056, F1 Macro: 0.8789\n",
      "Epoch 7/10, Train Loss: 0.05, Accuracy: 0.9019, F1 Micro: 0.9019, F1 Macro: 0.8731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0353, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8849\n",
      "Epoch 9/10, Train Loss: 0.0425, Accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0275, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.893\n",
      "\n",
      "Sentiment analysis accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.893\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       766\n",
      "    positive       0.92      0.78      0.84       325\n",
      "\n",
      "    accuracy                           0.91      1091\n",
      "   macro avg       0.92      0.88      0.89      1091\n",
      "weighted avg       0.92      0.91      0.91      1091\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1365: Accuracy: 0.9566, F1 Micro: 0.9566, F1 Macro: 0.8666\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.88      0.90        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.86      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.81      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.83      0.74      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.62      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.88       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.80      0.85       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       0.75      0.55      0.63        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.77      0.81       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.87      0.96      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.83      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.96      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.60      1.00      0.75         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.86      0.99      0.90       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 273.80911898612976 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0022099203430116176\n",
      "Acquired samples: 62\n",
      "Sampling duration: 35.136056900024414 seconds\n",
      "New train size: 1427\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.492, Accuracy: 0.8191, F1 Micro: 0.8975, F1 Macro: 0.8909\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3788, Accuracy: 0.9016, F1 Micro: 0.941, F1 Macro: 0.9364\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2726, Accuracy: 0.933, F1 Micro: 0.9591, F1 Macro: 0.9562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.211, Accuracy: 0.9469, F1 Micro: 0.9674, F1 Macro: 0.9645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.174, Accuracy: 0.9542, F1 Micro: 0.9717, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1424, Accuracy: 0.9566, F1 Micro: 0.9732, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1195, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1003, Accuracy: 0.9611, F1 Micro: 0.9758, F1 Macro: 0.9733\n",
      "Epoch 9/10, Train Loss: 0.0859, Accuracy: 0.9604, F1 Micro: 0.9754, F1 Macro: 0.973\n",
      "Epoch 10/10, Train Loss: 0.0764, Accuracy: 0.9606, F1 Micro: 0.9755, F1 Macro: 0.9733\n",
      "\n",
      "Aspect detection accuracy: 0.9611, F1 Micro: 0.9758, F1 Macro: 0.9733\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.96      0.89      0.92       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4197, Accuracy: 0.8509, F1 Micro: 0.8509, F1 Macro: 0.8136\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2443, Accuracy: 0.8845, F1 Micro: 0.8845, F1 Macro: 0.8505\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1833, Accuracy: 0.8955, F1 Micro: 0.8955, F1 Macro: 0.8646\n",
      "Epoch 4/10, Train Loss: 0.1177, Accuracy: 0.89, F1 Micro: 0.89, F1 Macro: 0.8594\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1116, Accuracy: 0.8973, F1 Micro: 0.8973, F1 Macro: 0.8676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0885, Accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.8704\n",
      "Epoch 7/10, Train Loss: 0.0606, Accuracy: 0.8982, F1 Micro: 0.8982, F1 Macro: 0.8668\n",
      "Epoch 8/10, Train Loss: 0.0394, Accuracy: 0.8918, F1 Micro: 0.8918, F1 Macro: 0.8626\n",
      "Epoch 9/10, Train Loss: 0.0611, Accuracy: 0.8873, F1 Micro: 0.8873, F1 Macro: 0.8493\n",
      "Epoch 10/10, Train Loss: 0.0309, Accuracy: 0.8945, F1 Micro: 0.8945, F1 Macro: 0.8654\n",
      "\n",
      "Sentiment analysis accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.8704\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93       777\n",
      "    positive       0.92      0.72      0.81       323\n",
      "\n",
      "    accuracy                           0.90      1100\n",
      "   macro avg       0.91      0.85      0.87      1100\n",
      "weighted avg       0.90      0.90      0.90      1100\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1427: Accuracy: 0.955, F1 Micro: 0.955, F1 Macro: 0.852\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.90      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.83      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.81      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.87      0.66      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.55      0.57       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.92      0.89       200\n",
      "     neutral       0.96      0.89      0.92       315\n",
      "    positive       0.89      0.98      0.93        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.73      0.50      0.59        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.85      0.77      0.81       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.80      0.84        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.89      0.93      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.90      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.45      0.57        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.67      0.71      0.69        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.80      0.72      0.75       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 274.33013701438904 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.0022152436431497335\n",
      "Acquired samples: 86\n",
      "Sampling duration: 32.41700744628906 seconds\n",
      "New train size: 1513\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4919, Accuracy: 0.8238, F1 Micro: 0.9005, F1 Macro: 0.8965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3637, Accuracy: 0.9094, F1 Micro: 0.9453, F1 Macro: 0.9409\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2528, Accuracy: 0.9372, F1 Micro: 0.9618, F1 Macro: 0.9595\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1981, Accuracy: 0.947, F1 Micro: 0.9675, F1 Macro: 0.9648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1618, Accuracy: 0.9552, F1 Micro: 0.9723, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1335, Accuracy: 0.9595, F1 Micro: 0.9749, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.114, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0987, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.974\n",
      "Epoch 9/10, Train Loss: 0.0822, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0726, Accuracy: 0.962, F1 Micro: 0.9765, F1 Macro: 0.9743\n",
      "\n",
      "Aspect detection accuracy: 0.962, F1 Micro: 0.9765, F1 Macro: 0.9743\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.93      0.98      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4399, Accuracy: 0.8645, F1 Micro: 0.8645, F1 Macro: 0.8242\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2365, Accuracy: 0.8975, F1 Micro: 0.8975, F1 Macro: 0.8668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1675, Accuracy: 0.9078, F1 Micro: 0.9078, F1 Macro: 0.8787\n",
      "Epoch 4/10, Train Loss: 0.1303, Accuracy: 0.904, F1 Micro: 0.904, F1 Macro: 0.8718\n",
      "Epoch 5/10, Train Loss: 0.0814, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.868\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0632, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.049, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.8813\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0351, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.8839\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0302, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.8861\n",
      "Epoch 10/10, Train Loss: 0.0204, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8836\n",
      "\n",
      "Sentiment analysis accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.8861\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       766\n",
      "    positive       0.92      0.76      0.83       297\n",
      "\n",
      "    accuracy                           0.91      1063\n",
      "   macro avg       0.92      0.87      0.89      1063\n",
      "weighted avg       0.91      0.91      0.91      1063\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1513: Accuracy: 0.9559, F1 Micro: 0.9559, F1 Macro: 0.8451\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.91      0.80      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.81      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.87      0.60      0.71        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.53      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.83      0.86       162\n",
      "     neutral       0.93      0.98      0.95       387\n",
      "    positive       0.77      0.45      0.57        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.86      0.75      0.80       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.82      0.87        85\n",
      "     neutral       0.96      0.99      0.98       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.31      0.46        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.62      0.88      0.73        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.73      0.73       571\n",
      "weighted avg       0.96      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.98      0.86      0.91       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 293.4050238132477 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.0023545052390545607\n",
      "Acquired samples: 78\n",
      "Sampling duration: 29.568399906158447 seconds\n",
      "New train size: 1591\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4776, Accuracy: 0.8382, F1 Micro: 0.9073, F1 Macro: 0.902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3508, Accuracy: 0.9123, F1 Micro: 0.947, F1 Macro: 0.943\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2368, Accuracy: 0.9398, F1 Micro: 0.9633, F1 Macro: 0.9608\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.194, Accuracy: 0.9517, F1 Micro: 0.9703, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1591, Accuracy: 0.9573, F1 Micro: 0.9735, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1295, Accuracy: 0.9576, F1 Micro: 0.9738, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1108, Accuracy: 0.9585, F1 Micro: 0.9744, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0907, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0801, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9754\n",
      "Epoch 10/10, Train Loss: 0.0685, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9742\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4084, Accuracy: 0.8562, F1 Micro: 0.8562, F1 Macro: 0.7974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2463, Accuracy: 0.8898, F1 Micro: 0.8898, F1 Macro: 0.8539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.161, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.127, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8845\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0741, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.8858\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0491, Accuracy: 0.9141, F1 Micro: 0.9141, F1 Macro: 0.8875\n",
      "Epoch 7/10, Train Loss: 0.0543, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8842\n",
      "Epoch 8/10, Train Loss: 0.0362, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0287, Accuracy: 0.9169, F1 Micro: 0.9169, F1 Macro: 0.8897\n",
      "Epoch 10/10, Train Loss: 0.035, Accuracy: 0.9085, F1 Micro: 0.9085, F1 Macro: 0.8784\n",
      "\n",
      "Sentiment analysis accuracy: 0.9169, F1 Micro: 0.9169, F1 Macro: 0.8897\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       769\n",
      "    positive       0.95      0.75      0.83       302\n",
      "\n",
      "    accuracy                           0.92      1071\n",
      "   macro avg       0.93      0.86      0.89      1071\n",
      "weighted avg       0.92      0.92      0.91      1071\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1591: Accuracy: 0.958, F1 Micro: 0.958, F1 Macro: 0.8605\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.91      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.91      0.80      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.78      0.82        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.86      0.63      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.54      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.89       200\n",
      "     neutral       0.93      0.94      0.94       315\n",
      "    positive       0.89      0.98      0.93        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.75      0.79       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.84      0.85        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.93      0.91      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.62      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.97      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 307.05525064468384 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.001766243693418801\n",
      "Acquired samples: 70\n",
      "Sampling duration: 26.708749055862427 seconds\n",
      "New train size: 1661\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4784, Accuracy: 0.8368, F1 Micro: 0.9066, F1 Macro: 0.9014\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3398, Accuracy: 0.917, F1 Micro: 0.9499, F1 Macro: 0.9466\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2399, Accuracy: 0.9377, F1 Micro: 0.962, F1 Macro: 0.9593\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1824, Accuracy: 0.9507, F1 Micro: 0.9697, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1545, Accuracy: 0.9595, F1 Micro: 0.9749, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1276, Accuracy: 0.9618, F1 Micro: 0.9764, F1 Macro: 0.9741\n",
      "Epoch 7/10, Train Loss: 0.1094, Accuracy: 0.9608, F1 Micro: 0.9756, F1 Macro: 0.973\n",
      "Epoch 8/10, Train Loss: 0.091, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9736\n",
      "Epoch 9/10, Train Loss: 0.0773, Accuracy: 0.9599, F1 Micro: 0.9752, F1 Macro: 0.9729\n",
      "Epoch 10/10, Train Loss: 0.068, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9738\n",
      "\n",
      "Aspect detection accuracy: 0.9618, F1 Micro: 0.9764, F1 Macro: 0.9741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.92      0.94      0.93       317\n",
      "       linen       0.92      0.98      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4301, Accuracy: 0.8691, F1 Micro: 0.8691, F1 Macro: 0.829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2411, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.8871\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1653, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.8916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.133, Accuracy: 0.9156, F1 Micro: 0.9156, F1 Macro: 0.8891\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0872, Accuracy: 0.9165, F1 Micro: 0.9165, F1 Macro: 0.8902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0732, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.8994\n",
      "Epoch 7/10, Train Loss: 0.0508, Accuracy: 0.9175, F1 Micro: 0.9175, F1 Macro: 0.8936\n",
      "Epoch 8/10, Train Loss: 0.046, Accuracy: 0.9175, F1 Micro: 0.9175, F1 Macro: 0.8926\n",
      "Epoch 9/10, Train Loss: 0.0415, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.8877\n",
      "Epoch 10/10, Train Loss: 0.026, Accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.8953\n",
      "\n",
      "Sentiment analysis accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.8994\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       753\n",
      "    positive       0.94      0.78      0.85       301\n",
      "\n",
      "    accuracy                           0.92      1054\n",
      "   macro avg       0.93      0.88      0.90      1054\n",
      "weighted avg       0.92      0.92      0.92      1054\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1661: Accuracy: 0.956, F1 Micro: 0.956, F1 Macro: 0.8554\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.85      0.89        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.78      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.79      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.56      0.57       571\n",
      "weighted avg       0.92      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.84      0.88       200\n",
      "     neutral       0.92      0.94      0.93       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.83      0.87       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.74      0.79       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.82      0.85        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.95      0.97        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.98      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 300.13938760757446 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.0023119742516428234\n",
      "Acquired samples: 51\n",
      "Sampling duration: 23.798953533172607 seconds\n",
      "New train size: 1712\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4791, Accuracy: 0.8417, F1 Micro: 0.9082, F1 Macro: 0.8993\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3393, Accuracy: 0.9191, F1 Micro: 0.951, F1 Macro: 0.9471\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.24, Accuracy: 0.9418, F1 Micro: 0.9644, F1 Macro: 0.962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1843, Accuracy: 0.9523, F1 Micro: 0.9706, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1555, Accuracy: 0.9592, F1 Micro: 0.9748, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1253, Accuracy: 0.9599, F1 Micro: 0.9751, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1053, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9735\n",
      "Epoch 8/10, Train Loss: 0.0864, Accuracy: 0.9599, F1 Micro: 0.9752, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0759, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0639, Accuracy: 0.9634, F1 Micro: 0.9772, F1 Macro: 0.9751\n",
      "\n",
      "Aspect detection accuracy: 0.9634, F1 Micro: 0.9772, F1 Macro: 0.9751\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.93      0.98      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4234, Accuracy: 0.8622, F1 Micro: 0.8622, F1 Macro: 0.8251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2278, Accuracy: 0.8951, F1 Micro: 0.8951, F1 Macro: 0.8671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1461, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1232, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8835\n",
      "Epoch 5/10, Train Loss: 0.0645, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8778\n",
      "Epoch 6/10, Train Loss: 0.056, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0528, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8872\n",
      "Epoch 8/10, Train Loss: 0.0437, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8835\n",
      "Epoch 9/10, Train Loss: 0.0141, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8799\n",
      "Epoch 10/10, Train Loss: 0.0385, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8756\n",
      "\n",
      "Sentiment analysis accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8872\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       774\n",
      "    positive       0.94      0.75      0.83       322\n",
      "\n",
      "    accuracy                           0.91      1096\n",
      "   macro avg       0.92      0.86      0.89      1096\n",
      "weighted avg       0.91      0.91      0.91      1096\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1712: Accuracy: 0.958, F1 Micro: 0.958, F1 Macro: 0.8724\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.89        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.79      0.82       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.83      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.80      0.75      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.58      0.58      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.89       200\n",
      "     neutral       0.93      0.94      0.94       315\n",
      "    positive       0.90      0.98      0.94        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.76      0.80       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 318.4396708011627 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.001591447996906936\n",
      "Acquired samples: 58\n",
      "Sampling duration: 22.188555479049683 seconds\n",
      "New train size: 1770\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4764, Accuracy: 0.8431, F1 Micro: 0.91, F1 Macro: 0.9047\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3266, Accuracy: 0.9189, F1 Micro: 0.9505, F1 Macro: 0.9456\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2296, Accuracy: 0.9448, F1 Micro: 0.9662, F1 Macro: 0.9638\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1802, Accuracy: 0.9509, F1 Micro: 0.9698, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1493, Accuracy: 0.958, F1 Micro: 0.974, F1 Macro: 0.9714\n",
      "Epoch 6/10, Train Loss: 0.1229, Accuracy: 0.9566, F1 Micro: 0.9732, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1016, Accuracy: 0.9599, F1 Micro: 0.9751, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0878, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9741\n",
      "Epoch 9/10, Train Loss: 0.0741, Accuracy: 0.9618, F1 Micro: 0.9762, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0647, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9752\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.94      0.93      0.93       317\n",
      "       linen       0.94      0.97      0.96       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4258, Accuracy: 0.8524, F1 Micro: 0.8524, F1 Macro: 0.8166\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2424, Accuracy: 0.8992, F1 Micro: 0.8992, F1 Macro: 0.87\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1781, Accuracy: 0.901, F1 Micro: 0.901, F1 Macro: 0.8753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1155, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8771\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.076, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0617, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.8903\n",
      "Epoch 7/10, Train Loss: 0.0609, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8778\n",
      "Epoch 8/10, Train Loss: 0.0319, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.8718\n",
      "Epoch 9/10, Train Loss: 0.0249, Accuracy: 0.9056, F1 Micro: 0.9056, F1 Macro: 0.8753\n",
      "Epoch 10/10, Train Loss: 0.0216, Accuracy: 0.901, F1 Micro: 0.901, F1 Macro: 0.8709\n",
      "\n",
      "Sentiment analysis accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.8903\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       776\n",
      "    positive       0.94      0.75      0.84       315\n",
      "\n",
      "    accuracy                           0.92      1091\n",
      "   macro avg       0.93      0.87      0.89      1091\n",
      "weighted avg       0.92      0.92      0.91      1091\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1770: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.8786\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.83      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.85      0.68      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.60      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.89      0.98      0.93        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.88       162\n",
      "     neutral       0.94      0.98      0.96       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.92      0.77      0.82       571\n",
      "weighted avg       0.93      0.93      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.88      0.86        85\n",
      "     neutral       0.97      0.96      0.97       418\n",
      "    positive       0.93      0.91      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.41      0.56        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.67      0.82      0.74        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.74      0.76       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.96      0.97        74\n",
      "     neutral       0.99      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 334.8152320384979 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.0018342332798056305\n",
      "Acquired samples: 52\n",
      "Sampling duration: 20.142498016357422 seconds\n",
      "New train size: 1822\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4767, Accuracy: 0.8523, F1 Micro: 0.9145, F1 Macro: 0.9089\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3153, Accuracy: 0.922, F1 Micro: 0.953, F1 Macro: 0.9496\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2238, Accuracy: 0.9465, F1 Micro: 0.9672, F1 Macro: 0.965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1786, Accuracy: 0.9524, F1 Micro: 0.9707, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.144, Accuracy: 0.9589, F1 Micro: 0.9746, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1175, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9742\n",
      "Epoch 7/10, Train Loss: 0.0999, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9742\n",
      "Epoch 8/10, Train Loss: 0.0862, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0726, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0606, Accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9764\n",
      "\n",
      "Aspect detection accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.92      0.93       317\n",
      "       linen       0.93      0.98      0.96       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4105, Accuracy: 0.8601, F1 Micro: 0.8601, F1 Macro: 0.8225\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2412, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.8744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1516, Accuracy: 0.9092, F1 Micro: 0.9092, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1114, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.8824\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0744, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.8914\n",
      "Epoch 6/10, Train Loss: 0.0576, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8824\n",
      "Epoch 7/10, Train Loss: 0.0372, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.8848\n",
      "Epoch 8/10, Train Loss: 0.0283, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0363, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.024, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8911\n",
      "\n",
      "Sentiment analysis accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8911\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       783\n",
      "    positive       0.95      0.75      0.84       318\n",
      "\n",
      "    accuracy                           0.92      1101\n",
      "   macro avg       0.93      0.87      0.89      1101\n",
      "weighted avg       0.92      0.92      0.91      1101\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1822: Accuracy: 0.9604, F1 Micro: 0.9604, F1 Macro: 0.8921\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.91      0.93        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.78      0.70      0.74        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.87      0.89       571\n",
      "weighted avg       0.97      0.98      0.98       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.83      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.29      0.40         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.85      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.82      0.67      0.72       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.91      0.90       200\n",
      "     neutral       0.95      0.92      0.93       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.88       162\n",
      "     neutral       0.93      0.98      0.95       387\n",
      "    positive       1.00      0.41      0.58        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.94      0.75      0.80       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 336.42217922210693 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.0019832329824566843\n",
      "Acquired samples: 50\n",
      "Sampling duration: 18.40799069404602 seconds\n",
      "New train size: 1872\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4654, Accuracy: 0.8595, F1 Micro: 0.9177, F1 Macro: 0.9105\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3128, Accuracy: 0.9278, F1 Micro: 0.9561, F1 Macro: 0.953\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2176, Accuracy: 0.9434, F1 Micro: 0.9654, F1 Macro: 0.963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1784, Accuracy: 0.9542, F1 Micro: 0.9717, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1389, Accuracy: 0.9597, F1 Micro: 0.975, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1131, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0958, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9739\n",
      "Epoch 8/10, Train Loss: 0.0815, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9737\n",
      "Epoch 9/10, Train Loss: 0.0704, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.058, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9754\n",
      "\n",
      "Aspect detection accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.92      0.93      0.93       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3895, Accuracy: 0.848, F1 Micro: 0.848, F1 Macro: 0.7865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.215, Accuracy: 0.8999, F1 Micro: 0.8999, F1 Macro: 0.8691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1516, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8772\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1021, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.8894\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.083, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.8902\n",
      "Epoch 6/10, Train Loss: 0.0639, Accuracy: 0.9081, F1 Micro: 0.9081, F1 Macro: 0.8848\n",
      "Epoch 7/10, Train Loss: 0.0466, Accuracy: 0.9063, F1 Micro: 0.9063, F1 Macro: 0.8784\n",
      "Epoch 8/10, Train Loss: 0.039, Accuracy: 0.9072, F1 Micro: 0.9072, F1 Macro: 0.8813\n",
      "Epoch 9/10, Train Loss: 0.0261, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8782\n",
      "Epoch 10/10, Train Loss: 0.0245, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8862\n",
      "\n",
      "Sentiment analysis accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.8902\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       774\n",
      "    positive       0.95      0.75      0.84       325\n",
      "\n",
      "    accuracy                           0.91      1099\n",
      "   macro avg       0.93      0.87      0.89      1099\n",
      "weighted avg       0.92      0.91      0.91      1099\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1872: Accuracy: 0.9588, F1 Micro: 0.9588, F1 Macro: 0.8822\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.98      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.87      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.55      0.60      0.57        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.82      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.82      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.25      0.14      0.18         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.85      0.75      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.69      0.62      0.65       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88       200\n",
      "     neutral       0.92      0.93      0.93       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       1.00      0.50      0.67        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.94      0.78      0.83       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.62      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.71      0.73        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.77      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 342.67991065979004 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.002425098326057196\n",
      "Acquired samples: 50\n",
      "Sampling duration: 16.22691297531128 seconds\n",
      "New train size: 1922\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4686, Accuracy: 0.862, F1 Micro: 0.9192, F1 Macro: 0.9128\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3047, Accuracy: 0.9276, F1 Micro: 0.9559, F1 Macro: 0.9526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2178, Accuracy: 0.9474, F1 Micro: 0.9677, F1 Macro: 0.9654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1671, Accuracy: 0.9542, F1 Micro: 0.9718, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1385, Accuracy: 0.9594, F1 Micro: 0.9749, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1151, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0965, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0823, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0674, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9756\n",
      "Epoch 10/10, Train Loss: 0.0598, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9743\n",
      "\n",
      "Aspect detection accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.93      0.93       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3929, Accuracy: 0.856, F1 Micro: 0.856, F1 Macro: 0.8217\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2313, Accuracy: 0.8861, F1 Micro: 0.8861, F1 Macro: 0.8482\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1569, Accuracy: 0.9061, F1 Micro: 0.9061, F1 Macro: 0.8797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1198, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.102, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8793\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0699, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0485, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0448, Accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.8891\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0244, Accuracy: 0.9152, F1 Micro: 0.9152, F1 Macro: 0.8899\n",
      "Epoch 10/10, Train Loss: 0.0234, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8818\n",
      "\n",
      "Sentiment analysis accuracy: 0.9152, F1 Micro: 0.9152, F1 Macro: 0.8899\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       780\n",
      "    positive       0.94      0.75      0.84       317\n",
      "\n",
      "    accuracy                           0.92      1097\n",
      "   macro avg       0.92      0.87      0.89      1097\n",
      "weighted avg       0.92      0.92      0.91      1097\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1922: Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.8783\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.77      0.61      0.66       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.89       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.89      0.98      0.93        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.71      0.45      0.56        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.84      0.76      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.72      0.76      0.74        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.78      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 351.7183439731598 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.0020313594723120345\n",
      "Acquired samples: 50\n",
      "Sampling duration: 14.931052207946777 seconds\n",
      "New train size: 1972\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4612, Accuracy: 0.859, F1 Micro: 0.9177, F1 Macro: 0.912\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3014, Accuracy: 0.9321, F1 Micro: 0.9586, F1 Macro: 0.9562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2108, Accuracy: 0.9455, F1 Micro: 0.9667, F1 Macro: 0.9642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.164, Accuracy: 0.9523, F1 Micro: 0.9707, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.134, Accuracy: 0.9595, F1 Micro: 0.9749, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1132, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0966, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0814, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0665, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9756\n",
      "Epoch 10/10, Train Loss: 0.0577, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.975\n",
      "\n",
      "Aspect detection accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.93      0.98      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3849, Accuracy: 0.851, F1 Micro: 0.851, F1 Macro: 0.7814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1991, Accuracy: 0.9078, F1 Micro: 0.9078, F1 Macro: 0.88\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1496, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.8881\n",
      "Epoch 4/10, Train Loss: 0.1054, Accuracy: 0.9078, F1 Micro: 0.9078, F1 Macro: 0.8849\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0764, Accuracy: 0.9209, F1 Micro: 0.9209, F1 Macro: 0.8979\n",
      "Epoch 6/10, Train Loss: 0.0491, Accuracy: 0.9171, F1 Micro: 0.9171, F1 Macro: 0.8921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0539, Accuracy: 0.9218, F1 Micro: 0.9218, F1 Macro: 0.8978\n",
      "Epoch 8/10, Train Loss: 0.0348, Accuracy: 0.9171, F1 Micro: 0.9171, F1 Macro: 0.8921\n",
      "Epoch 9/10, Train Loss: 0.0219, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.8862\n",
      "Epoch 10/10, Train Loss: 0.0226, Accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.8955\n",
      "\n",
      "Sentiment analysis accuracy: 0.9218, F1 Micro: 0.9218, F1 Macro: 0.8978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       768\n",
      "    positive       0.95      0.77      0.85       306\n",
      "\n",
      "    accuracy                           0.92      1074\n",
      "   macro avg       0.93      0.88      0.90      1074\n",
      "weighted avg       0.92      0.92      0.92      1074\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1972: Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.882\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.97      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.92      0.79      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.89      0.69      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.78      0.61      0.66       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88       200\n",
      "     neutral       0.93      0.93      0.93       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.84      0.87       162\n",
      "     neutral       0.93      0.98      0.95       387\n",
      "    positive       0.92      0.55      0.69        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.92      0.79      0.84       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.89      0.94      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 354.72769045829773 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.001532389025669545\n",
      "Acquired samples: 25\n",
      "Sampling duration: 12.506279230117798 seconds\n",
      "New train size: 1997\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.464, Accuracy: 0.8663, F1 Micro: 0.922, F1 Macro: 0.917\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2954, Accuracy: 0.9358, F1 Micro: 0.9608, F1 Macro: 0.9584\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2047, Accuracy: 0.9453, F1 Micro: 0.9665, F1 Macro: 0.9643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.162, Accuracy: 0.9505, F1 Micro: 0.9695, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1325, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1077, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9745\n",
      "Epoch 7/10, Train Loss: 0.091, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0762, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0619, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9758\n",
      "Epoch 10/10, Train Loss: 0.054, Accuracy: 0.9622, F1 Micro: 0.9766, F1 Macro: 0.9744\n",
      "\n",
      "Aspect detection accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.94      0.97      0.96       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3671, Accuracy: 0.8776, F1 Micro: 0.8776, F1 Macro: 0.834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2099, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1454, Accuracy: 0.9063, F1 Micro: 0.9063, F1 Macro: 0.8754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0978, Accuracy: 0.91, F1 Micro: 0.91, F1 Macro: 0.8803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0709, Accuracy: 0.91, F1 Micro: 0.91, F1 Macro: 0.8803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.06, Accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.8905\n",
      "Epoch 7/10, Train Loss: 0.0381, Accuracy: 0.91, F1 Micro: 0.91, F1 Macro: 0.8803\n",
      "Epoch 8/10, Train Loss: 0.031, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.8828\n",
      "Epoch 9/10, Train Loss: 0.0307, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8847\n",
      "Epoch 10/10, Train Loss: 0.0312, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.8863\n",
      "\n",
      "Sentiment analysis accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.8905\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       777\n",
      "    positive       0.94      0.75      0.84       301\n",
      "\n",
      "    accuracy                           0.92      1078\n",
      "   macro avg       0.92      0.87      0.89      1078\n",
      "weighted avg       0.92      0.92      0.91      1078\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1997: Accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.8518\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.81      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.86      0.62      0.72        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.53      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.89       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88       162\n",
      "     neutral       0.94      0.97      0.96       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.77      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.82      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.97      0.81      0.86       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 351.03999972343445 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.001673074415884912\n",
      "Acquired samples: 50\n",
      "Sampling duration: 11.679076910018921 seconds\n",
      "New train size: 2047\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4556, Accuracy: 0.8682, F1 Micro: 0.9227, F1 Macro: 0.916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2897, Accuracy: 0.93, F1 Micro: 0.9575, F1 Macro: 0.9552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2037, Accuracy: 0.9477, F1 Micro: 0.968, F1 Macro: 0.9657\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1619, Accuracy: 0.9545, F1 Micro: 0.9719, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1349, Accuracy: 0.9585, F1 Micro: 0.9744, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1103, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0929, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0747, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9754\n",
      "Epoch 9/10, Train Loss: 0.0635, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.055, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9756\n",
      "\n",
      "Aspect detection accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.97      0.97       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.384, Accuracy: 0.8697, F1 Micro: 0.8697, F1 Macro: 0.8294\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.193, Accuracy: 0.905, F1 Micro: 0.905, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1344, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8887\n",
      "Epoch 4/10, Train Loss: 0.1064, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8895\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0872, Accuracy: 0.9149, F1 Micro: 0.9149, F1 Macro: 0.8913\n",
      "Epoch 6/10, Train Loss: 0.0528, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8879\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0437, Accuracy: 0.9158, F1 Micro: 0.9158, F1 Macro: 0.8939\n",
      "Epoch 8/10, Train Loss: 0.0298, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8818\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0306, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.8951\n",
      "Epoch 10/10, Train Loss: 0.0201, Accuracy: 0.9086, F1 Micro: 0.9086, F1 Macro: 0.8816\n",
      "\n",
      "Sentiment analysis accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.8951\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       777\n",
      "    positive       0.95      0.77      0.85       328\n",
      "\n",
      "    accuracy                           0.92      1105\n",
      "   macro avg       0.93      0.87      0.90      1105\n",
      "weighted avg       0.92      0.92      0.91      1105\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2047: Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.8756\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.79      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44         7\n",
      "     neutral       0.96      0.97      0.97       496\n",
      "    positive       0.79      0.79      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.68      0.74       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.88       200\n",
      "     neutral       0.93      0.93      0.93       315\n",
      "    positive       0.85      0.93      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.91      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.77      0.45      0.57        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.86      0.76      0.80       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.88        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.94      0.96      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.62      0.73        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.83      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 359.7421700954437 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.001606802036985755\n",
      "Acquired samples: 50\n",
      "Sampling duration: 9.74364447593689 seconds\n",
      "New train size: 2097\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4591, Accuracy: 0.8733, F1 Micro: 0.9258, F1 Macro: 0.9205\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2844, Accuracy: 0.9354, F1 Micro: 0.9606, F1 Macro: 0.9583\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1983, Accuracy: 0.951, F1 Micro: 0.97, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1596, Accuracy: 0.9582, F1 Micro: 0.9741, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1251, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1113, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9748\n",
      "Epoch 7/10, Train Loss: 0.0887, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9737\n",
      "Epoch 8/10, Train Loss: 0.0724, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.062, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0529, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "\n",
      "Aspect detection accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      0.99      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.393, Accuracy: 0.8594, F1 Micro: 0.8594, F1 Macro: 0.8074\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2033, Accuracy: 0.8824, F1 Micro: 0.8824, F1 Macro: 0.8424\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1453, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.8885\n",
      "Epoch 4/10, Train Loss: 0.0977, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8833\n",
      "Epoch 5/10, Train Loss: 0.0711, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8782\n",
      "Epoch 6/10, Train Loss: 0.0415, Accuracy: 0.9072, F1 Micro: 0.9072, F1 Macro: 0.8814\n",
      "Epoch 7/10, Train Loss: 0.0466, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8869\n",
      "Epoch 8/10, Train Loss: 0.033, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8849\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.028, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8907\n",
      "Epoch 10/10, Train Loss: 0.0164, Accuracy: 0.9081, F1 Micro: 0.9081, F1 Macro: 0.8814\n",
      "\n",
      "Sentiment analysis accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8907\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       776\n",
      "    positive       0.93      0.77      0.84       312\n",
      "\n",
      "    accuracy                           0.92      1088\n",
      "   macro avg       0.92      0.87      0.89      1088\n",
      "weighted avg       0.92      0.92      0.91      1088\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2097: Accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.8793\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.79      1.00      0.88        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.92      0.97      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.88      0.93        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.86      0.87       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.81      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.87      0.66      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.60      0.65       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89       200\n",
      "     neutral       0.93      0.93      0.93       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.86       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.74      0.78       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.84      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      0.99      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      1.00      0.95       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 364.927775144577 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.0016688071424141528\n",
      "Acquired samples: 50\n",
      "Sampling duration: 7.891338586807251 seconds\n",
      "New train size: 2147\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4456, Accuracy: 0.8727, F1 Micro: 0.925, F1 Macro: 0.919\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2734, Accuracy: 0.9297, F1 Micro: 0.9575, F1 Macro: 0.9549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1939, Accuracy: 0.9486, F1 Micro: 0.9685, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1561, Accuracy: 0.9521, F1 Micro: 0.9704, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1276, Accuracy: 0.9595, F1 Micro: 0.975, F1 Macro: 0.9726\n",
      "Epoch 6/10, Train Loss: 0.103, Accuracy: 0.9594, F1 Micro: 0.9749, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0863, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9737\n",
      "Epoch 8/10, Train Loss: 0.074, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0605, Accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9763\n",
      "Epoch 10/10, Train Loss: 0.0522, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9756\n",
      "\n",
      "Aspect detection accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.97      0.96       500\n",
      "  kebersihan       0.95      0.92      0.93       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3702, Accuracy: 0.8478, F1 Micro: 0.8478, F1 Macro: 0.8203\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2162, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8813\n",
      "Epoch 3/10, Train Loss: 0.1351, Accuracy: 0.9067, F1 Micro: 0.9067, F1 Macro: 0.8783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1015, Accuracy: 0.9121, F1 Micro: 0.9121, F1 Macro: 0.8872\n",
      "Epoch 5/10, Train Loss: 0.0682, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.058, Accuracy: 0.9158, F1 Micro: 0.9158, F1 Macro: 0.8926\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0403, Accuracy: 0.9185, F1 Micro: 0.9185, F1 Macro: 0.8943\n",
      "Epoch 8/10, Train Loss: 0.0311, Accuracy: 0.9149, F1 Micro: 0.9149, F1 Macro: 0.8915\n",
      "Epoch 9/10, Train Loss: 0.0355, Accuracy: 0.9121, F1 Micro: 0.9121, F1 Macro: 0.8877\n",
      "Epoch 10/10, Train Loss: 0.0225, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.8892\n",
      "\n",
      "Sentiment analysis accuracy: 0.9185, F1 Micro: 0.9185, F1 Macro: 0.8943\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.99      0.94       780\n",
      "    positive       0.96      0.75      0.84       324\n",
      "\n",
      "    accuracy                           0.92      1104\n",
      "   macro avg       0.93      0.87      0.89      1104\n",
      "weighted avg       0.92      0.92      0.92      1104\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2147: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.8749\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.76      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.81      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.40      0.29      0.33         7\n",
      "     neutral       0.96      0.97      0.96       496\n",
      "    positive       0.80      0.76      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.72      0.67      0.69       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.91      0.90       200\n",
      "     neutral       0.95      0.92      0.93       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87       162\n",
      "     neutral       0.94      0.97      0.96       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.76      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.69      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.84      0.86       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 375.8669035434723 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.001275705941952765\n",
      "Acquired samples: 50\n",
      "Sampling duration: 5.933987140655518 seconds\n",
      "New train size: 2197\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.437, Accuracy: 0.883, F1 Micro: 0.9311, F1 Macro: 0.9265\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.27, Accuracy: 0.9387, F1 Micro: 0.9626, F1 Macro: 0.9603\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1906, Accuracy: 0.9503, F1 Micro: 0.9693, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1512, Accuracy: 0.959, F1 Micro: 0.9747, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1227, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9746\n",
      "Epoch 6/10, Train Loss: 0.1008, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9743\n",
      "Epoch 7/10, Train Loss: 0.0813, Accuracy: 0.9622, F1 Micro: 0.9766, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.072, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0592, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0489, Accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.95      0.95      0.95       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.98      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.359, Accuracy: 0.8633, F1 Micro: 0.8633, F1 Macro: 0.8333\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.198, Accuracy: 0.8984, F1 Micro: 0.8984, F1 Macro: 0.8704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1312, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.8952\n",
      "Epoch 4/10, Train Loss: 0.099, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.8921\n",
      "Epoch 5/10, Train Loss: 0.0776, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.8856\n",
      "Epoch 6/10, Train Loss: 0.0481, Accuracy: 0.9092, F1 Micro: 0.9092, F1 Macro: 0.8821\n",
      "Epoch 7/10, Train Loss: 0.0349, Accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.8823\n",
      "Epoch 8/10, Train Loss: 0.0237, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8811\n",
      "Epoch 9/10, Train Loss: 0.0331, Accuracy: 0.9056, F1 Micro: 0.9056, F1 Macro: 0.8785\n",
      "Epoch 10/10, Train Loss: 0.0237, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8878\n",
      "\n",
      "Sentiment analysis accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.8952\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.94       786\n",
      "    positive       0.92      0.78      0.85       326\n",
      "\n",
      "    accuracy                           0.92      1112\n",
      "   macro avg       0.92      0.88      0.90      1112\n",
      "weighted avg       0.92      0.92      0.92      1112\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2197: Accuracy: 0.9597, F1 Micro: 0.9597, F1 Macro: 0.8816\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.92      0.94        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.87      0.88       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.84        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.83      0.72      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.61      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.89      0.90       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.83      0.96      0.89        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87       162\n",
      "     neutral       0.95      0.96      0.95       387\n",
      "    positive       0.65      0.50      0.56        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.82      0.78      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.88      0.96      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.83      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.91      0.99      0.95       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 373.01130175590515 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.0016591341234743595\n",
      "Acquired samples: 50\n",
      "Sampling duration: 4.127646207809448 seconds\n",
      "New train size: 2247\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4412, Accuracy: 0.8852, F1 Micro: 0.9319, F1 Macro: 0.9271\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2619, Accuracy: 0.9312, F1 Micro: 0.9583, F1 Macro: 0.956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1889, Accuracy: 0.9528, F1 Micro: 0.9709, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1483, Accuracy: 0.9587, F1 Micro: 0.9744, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1156, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0975, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.083, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9757\n",
      "Epoch 8/10, Train Loss: 0.0673, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0554, Accuracy: 0.9667, F1 Micro: 0.9793, F1 Macro: 0.9772\n",
      "Epoch 10/10, Train Loss: 0.0481, Accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9764\n",
      "\n",
      "Aspect detection accuracy: 0.9667, F1 Micro: 0.9793, F1 Macro: 0.9772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.94      0.97      0.96       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3579, Accuracy: 0.8812, F1 Micro: 0.8812, F1 Macro: 0.848\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1952, Accuracy: 0.8894, F1 Micro: 0.8894, F1 Macro: 0.8519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1219, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8851\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0873, Accuracy: 0.9166, F1 Micro: 0.9166, F1 Macro: 0.8933\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0812, Accuracy: 0.9184, F1 Micro: 0.9184, F1 Macro: 0.8945\n",
      "Epoch 6/10, Train Loss: 0.0476, Accuracy: 0.9075, F1 Micro: 0.9075, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0448, Accuracy: 0.922, F1 Micro: 0.922, F1 Macro: 0.9003\n",
      "Epoch 8/10, Train Loss: 0.0333, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8809\n",
      "Epoch 9/10, Train Loss: 0.0219, Accuracy: 0.9175, F1 Micro: 0.9175, F1 Macro: 0.8935\n",
      "Epoch 10/10, Train Loss: 0.018, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8893\n",
      "\n",
      "Sentiment analysis accuracy: 0.922, F1 Micro: 0.922, F1 Macro: 0.9003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       782\n",
      "    positive       0.94      0.78      0.85       321\n",
      "\n",
      "    accuracy                           0.92      1103\n",
      "   macro avg       0.93      0.88      0.90      1103\n",
      "weighted avg       0.92      0.92      0.92      1103\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2247: Accuracy: 0.9616, F1 Micro: 0.9616, F1 Macro: 0.8956\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.92      0.92        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.92      0.80      0.85       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.81      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.82      0.78      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.68      0.74       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89       162\n",
      "     neutral       0.94      0.97      0.96       387\n",
      "    positive       0.81      0.59      0.68        22\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.89      0.81      0.84       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.84      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.82      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 384.5681803226471 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.0010906811803579328\n",
      "Acquired samples: 36\n",
      "Sampling duration: 2.262880325317383 seconds\n",
      "New train size: 2283\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4315, Accuracy: 0.8856, F1 Micro: 0.932, F1 Macro: 0.9266\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2615, Accuracy: 0.9358, F1 Micro: 0.9609, F1 Macro: 0.9587\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1774, Accuracy: 0.9483, F1 Micro: 0.9683, F1 Macro: 0.9662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1476, Accuracy: 0.9578, F1 Micro: 0.9738, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1225, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9746\n",
      "Epoch 6/10, Train Loss: 0.0968, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.082, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0678, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0569, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.045, Accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9769\n",
      "\n",
      "Aspect detection accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.98      0.98      0.98       496\n",
      "     general       0.96      0.97      0.97       500\n",
      "  kebersihan       0.94      0.95      0.95       317\n",
      "       linen       0.91      0.98      0.94       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3471, Accuracy: 0.8769, F1 Micro: 0.8769, F1 Macro: 0.8335\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1908, Accuracy: 0.8954, F1 Micro: 0.8954, F1 Macro: 0.8723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1446, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.8932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1054, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.8941\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0675, Accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.8974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0564, Accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.8957\n",
      "Epoch 7/10, Train Loss: 0.0479, Accuracy: 0.9185, F1 Micro: 0.9185, F1 Macro: 0.8947\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0352, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.8992\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0255, Accuracy: 0.9241, F1 Micro: 0.9241, F1 Macro: 0.9018\n",
      "Epoch 10/10, Train Loss: 0.0181, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9008\n",
      "\n",
      "Sentiment analysis accuracy: 0.9241, F1 Micro: 0.9241, F1 Macro: 0.9018\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       772\n",
      "    positive       0.94      0.79      0.86       308\n",
      "\n",
      "    accuracy                           0.92      1080\n",
      "   macro avg       0.93      0.88      0.90      1080\n",
      "weighted avg       0.92      0.92      0.92      1080\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2283: Accuracy: 0.9594, F1 Micro: 0.9594, F1 Macro: 0.8684\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        78\n",
      "     neutral       0.98      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.96      0.97      0.96       496\n",
      "    positive       0.79      0.78      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.63      0.67       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.89      0.90       200\n",
      "     neutral       0.94      0.95      0.95       315\n",
      "    positive       0.85      0.95      0.90        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.79      0.84       162\n",
      "     neutral       0.91      0.98      0.94       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.73      0.78       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.94      0.96      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.59      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.71      0.71        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.76      0.79       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.98      0.81      0.87       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 392.1692683696747 s\n",
      "Total runtime: 8476.265299797058 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47314397",
   "metadata": {
    "papermill": {
     "duration": 0.180554,
     "end_time": "2025-03-31T06:55:45.895347",
     "exception": false,
     "start_time": "2025-03-31T06:55:45.714793",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ab9d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 4\n",
      "Random seed: 3\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6072, Accuracy: 0.7955, F1 Micro: 0.8818, F1 Macro: 0.8546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4916, Accuracy: 0.8016, F1 Micro: 0.8877, F1 Macro: 0.8774\n",
      "Epoch 3/10, Train Loss: 0.453, Accuracy: 0.8024, F1 Micro: 0.8857, F1 Macro: 0.8609\n",
      "Epoch 4/10, Train Loss: 0.4515, Accuracy: 0.8021, F1 Micro: 0.8849, F1 Macro: 0.8543\n",
      "Epoch 5/10, Train Loss: 0.417, Accuracy: 0.8047, F1 Micro: 0.8868, F1 Macro: 0.862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4402, Accuracy: 0.8092, F1 Micro: 0.8902, F1 Macro: 0.874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3799, Accuracy: 0.8141, F1 Micro: 0.8937, F1 Macro: 0.8828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3851, Accuracy: 0.8252, F1 Micro: 0.899, F1 Macro: 0.8873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3532, Accuracy: 0.8361, F1 Micro: 0.9044, F1 Macro: 0.8918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3254, Accuracy: 0.8502, F1 Micro: 0.9121, F1 Macro: 0.9018\n",
      "\n",
      "Aspect detection accuracy: 0.8502, F1 Micro: 0.9121, F1 Macro: 0.9018\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.86      1.00      0.93       462\n",
      "   air_panas       0.90      0.99      0.94       480\n",
      "         bau       0.87      1.00      0.93       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.77      0.66      0.71       317\n",
      "       linen       0.74      0.98      0.84       392\n",
      "     service       0.82      0.98      0.89       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.90      1.00      0.95       516\n",
      "        wifi       0.89      1.00      0.94       498\n",
      "\n",
      "   micro avg       0.86      0.97      0.91      4614\n",
      "   macro avg       0.85      0.96      0.90      4614\n",
      "weighted avg       0.86      0.97      0.91      4614\n",
      " samples avg       0.86      0.97      0.91      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5988, Accuracy: 0.6204, F1 Micro: 0.6204, F1 Macro: 0.3829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5281, Accuracy: 0.6204, F1 Micro: 0.6204, F1 Macro: 0.3829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4888, Accuracy: 0.6259, F1 Micro: 0.6259, F1 Macro: 0.4027\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3707, Accuracy: 0.6861, F1 Micro: 0.6861, F1 Macro: 0.5752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3492, Accuracy: 0.7336, F1 Micro: 0.7336, F1 Macro: 0.6917\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2739, Accuracy: 0.7372, F1 Micro: 0.7372, F1 Macro: 0.7005\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3739, Accuracy: 0.7409, F1 Micro: 0.7409, F1 Macro: 0.7103\n",
      "Epoch 8/10, Train Loss: 0.2974, Accuracy: 0.7281, F1 Micro: 0.7281, F1 Macro: 0.6718\n",
      "Epoch 9/10, Train Loss: 0.18, Accuracy: 0.7372, F1 Micro: 0.7372, F1 Macro: 0.703\n",
      "Epoch 10/10, Train Loss: 0.1429, Accuracy: 0.7281, F1 Micro: 0.7281, F1 Macro: 0.6706\n",
      "\n",
      "Sentiment analysis accuracy: 0.7409, F1 Micro: 0.7409, F1 Macro: 0.7103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.86      0.80       340\n",
      "    positive       0.70      0.55      0.62       208\n",
      "\n",
      "    accuracy                           0.74       548\n",
      "   macro avg       0.73      0.70      0.71       548\n",
      "weighted avg       0.74      0.74      0.73       548\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 142: Accuracy: 0.8385, F1 Micro: 0.8385, F1 Macro: 0.4347\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.36      0.51        97\n",
      "     neutral       0.87      1.00      0.93       459\n",
      "    positive       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.58      0.45      0.48       571\n",
      "weighted avg       0.84      0.86      0.83       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.43      0.56        86\n",
      "     neutral       0.90      0.99      0.94       475\n",
      "    positive       0.20      0.10      0.13        10\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.63      0.51      0.54       571\n",
      "weighted avg       0.87      0.89      0.87       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.12      0.20        78\n",
      "     neutral       0.87      1.00      0.93       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.59      0.37      0.38       571\n",
      "weighted avg       0.87      0.87      0.83       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.65      0.65       200\n",
      "     neutral       0.77      0.66      0.71       315\n",
      "    positive       0.26      0.48      0.34        56\n",
      "\n",
      "    accuracy                           0.64       571\n",
      "   macro avg       0.56      0.60      0.57       571\n",
      "weighted avg       0.68      0.64      0.65       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.30      0.44       162\n",
      "     neutral       0.74      0.98      0.84       387\n",
      "    positive       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.75       571\n",
      "   macro avg       0.53      0.43      0.43       571\n",
      "weighted avg       0.74      0.75      0.70       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.18      0.29        85\n",
      "     neutral       0.81      0.98      0.89       418\n",
      "    positive       0.60      0.44      0.51        68\n",
      "\n",
      "    accuracy                           0.80       571\n",
      "   macro avg       0.77      0.53      0.56       571\n",
      "weighted avg       0.80      0.80      0.76       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.89      1.00      0.94       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.30      0.33      0.31       571\n",
      "weighted avg       0.80      0.89      0.85       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.24      0.39        74\n",
      "     neutral       0.89      1.00      0.94       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.61      0.41      0.44       571\n",
      "weighted avg       0.90      0.89      0.87       571\n",
      "\n",
      "Total train time: 81.06794238090515 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.006908668205142022\n",
      "Acquired samples: 215\n",
      "Sampling duration: 51.64927053451538 seconds\n",
      "New train size: 357\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5577, Accuracy: 0.7917, F1 Micro: 0.8777, F1 Macro: 0.819\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5208, Accuracy: 0.8062, F1 Micro: 0.886, F1 Macro: 0.8525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5078, Accuracy: 0.8198, F1 Micro: 0.8945, F1 Macro: 0.8752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4489, Accuracy: 0.8441, F1 Micro: 0.9096, F1 Macro: 0.9036\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4062, Accuracy: 0.8691, F1 Micro: 0.9219, F1 Macro: 0.9134\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.36, Accuracy: 0.8913, F1 Micro: 0.935, F1 Macro: 0.9288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3041, Accuracy: 0.8991, F1 Micro: 0.9393, F1 Macro: 0.9333\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2578, Accuracy: 0.9095, F1 Micro: 0.9455, F1 Macro: 0.9408\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2292, Accuracy: 0.9177, F1 Micro: 0.95, F1 Macro: 0.9448\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.21, Accuracy: 0.9227, F1 Micro: 0.9529, F1 Macro: 0.9483\n",
      "\n",
      "Aspect detection accuracy: 0.9227, F1 Micro: 0.9529, F1 Macro: 0.9483\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.98       462\n",
      "   air_panas       0.95      0.99      0.97       480\n",
      "         bau       0.95      0.97      0.96       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.85      0.84      0.84       317\n",
      "       linen       0.82      0.98      0.89       392\n",
      "     service       0.95      0.96      0.95       423\n",
      "sunrise_meal       0.96      0.99      0.98       530\n",
      "          tv       0.96      1.00      0.98       516\n",
      "        wifi       0.99      0.99      0.99       498\n",
      "\n",
      "   micro avg       0.93      0.98      0.95      4614\n",
      "   macro avg       0.93      0.97      0.95      4614\n",
      "weighted avg       0.93      0.98      0.95      4614\n",
      " samples avg       0.93      0.97      0.95      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5851, Accuracy: 0.7843, F1 Micro: 0.7843, F1 Macro: 0.6752\n",
      "Epoch 2/10, Train Loss: 0.484, Accuracy: 0.7778, F1 Micro: 0.7778, F1 Macro: 0.7453\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4089, Accuracy: 0.8279, F1 Micro: 0.8279, F1 Macro: 0.7601\n",
      "Epoch 4/10, Train Loss: 0.2643, Accuracy: 0.8268, F1 Micro: 0.8268, F1 Macro: 0.7533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2618, Accuracy: 0.8475, F1 Micro: 0.8475, F1 Macro: 0.7998\n",
      "Epoch 6/10, Train Loss: 0.1735, Accuracy: 0.8453, F1 Micro: 0.8453, F1 Macro: 0.7935\n",
      "Epoch 7/10, Train Loss: 0.207, Accuracy: 0.8268, F1 Micro: 0.8268, F1 Macro: 0.7463\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1363, Accuracy: 0.8475, F1 Micro: 0.8475, F1 Macro: 0.7846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1211, Accuracy: 0.8486, F1 Micro: 0.8486, F1 Macro: 0.7945\n",
      "Epoch 10/10, Train Loss: 0.07, Accuracy: 0.842, F1 Micro: 0.842, F1 Macro: 0.778\n",
      "\n",
      "Sentiment analysis accuracy: 0.8486, F1 Micro: 0.8486, F1 Macro: 0.7945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.96      0.90       648\n",
      "    positive       0.87      0.57      0.69       270\n",
      "\n",
      "    accuracy                           0.85       918\n",
      "   macro avg       0.86      0.77      0.79       918\n",
      "weighted avg       0.85      0.85      0.84       918\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 357: Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.7025\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.89      0.91        97\n",
      "     neutral       0.98      0.99      0.98       459\n",
      "    positive       0.75      0.80      0.77        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.89      0.89       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.77      0.82        86\n",
      "     neutral       0.95      0.99      0.97       475\n",
      "    positive       0.60      0.30      0.40        10\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.81      0.68      0.73       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.71      0.73        78\n",
      "     neutral       0.95      0.97      0.96       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.57      0.56      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.50      0.01      0.03        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.46      0.34      0.32       571\n",
      "weighted avg       0.82      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.74      0.75       200\n",
      "     neutral       0.85      0.84      0.85       315\n",
      "    positive       0.71      0.79      0.75        56\n",
      "\n",
      "    accuracy                           0.80       571\n",
      "   macro avg       0.77      0.79      0.78       571\n",
      "weighted avg       0.80      0.80      0.80       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.57      0.70       162\n",
      "     neutral       0.82      0.98      0.89       387\n",
      "    positive       0.50      0.05      0.08        22\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.73      0.53      0.56       571\n",
      "weighted avg       0.83      0.83      0.81       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.76      0.81        85\n",
      "     neutral       0.95      0.96      0.95       418\n",
      "    positive       0.84      0.85      0.85        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.86      0.87       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.58      0.24      0.34        29\n",
      "     neutral       0.96      0.99      0.98       525\n",
      "    positive       0.67      0.59      0.62        17\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.74      0.61      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.65      0.76        54\n",
      "     neutral       0.96      1.00      0.98       511\n",
      "    positive       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.96      0.71      0.80       571\n",
      "weighted avg       0.96      0.96      0.95       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.93      0.94        74\n",
      "     neutral       0.99      0.99      0.99       494\n",
      "    positive       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.87      0.86      0.87       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 129.215482711792 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.009808465838432312\n",
      "Acquired samples: 193\n",
      "Sampling duration: 58.38590693473816 seconds\n",
      "New train size: 550\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5182, Accuracy: 0.8026, F1 Micro: 0.8861, F1 Macro: 0.864\n",
      "Epoch 2/10, Train Loss: 0.4514, Accuracy: 0.8056, F1 Micro: 0.8845, F1 Macro: 0.8468\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.404, Accuracy: 0.8431, F1 Micro: 0.9084, F1 Macro: 0.8996\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3385, Accuracy: 0.8693, F1 Micro: 0.9228, F1 Macro: 0.9161\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2818, Accuracy: 0.9068, F1 Micro: 0.9441, F1 Macro: 0.9404\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2432, Accuracy: 0.9248, F1 Micro: 0.9542, F1 Macro: 0.9511\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.196, Accuracy: 0.9285, F1 Micro: 0.9566, F1 Macro: 0.954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1763, Accuracy: 0.9326, F1 Micro: 0.9589, F1 Macro: 0.9564\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1531, Accuracy: 0.9349, F1 Micro: 0.9603, F1 Macro: 0.9575\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1346, Accuracy: 0.9441, F1 Micro: 0.9657, F1 Macro: 0.963\n",
      "\n",
      "Aspect detection accuracy: 0.9441, F1 Micro: 0.9657, F1 Macro: 0.963\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.90      0.99      0.94       500\n",
      "  kebersihan       0.88      0.93      0.91       317\n",
      "       linen       0.92      0.94      0.93       392\n",
      "     service       0.93      0.99      0.96       423\n",
      "sunrise_meal       0.96      1.00      0.98       530\n",
      "          tv       0.97      1.00      0.98       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      4614\n",
      "   macro avg       0.95      0.98      0.96      4614\n",
      "weighted avg       0.95      0.98      0.97      4614\n",
      " samples avg       0.95      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5415, Accuracy: 0.7856, F1 Micro: 0.7856, F1 Macro: 0.6658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3712, Accuracy: 0.8455, F1 Micro: 0.8455, F1 Macro: 0.7775\n",
      "Epoch 3/10, Train Loss: 0.2603, Accuracy: 0.8364, F1 Micro: 0.8364, F1 Macro: 0.7706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2208, Accuracy: 0.8628, F1 Micro: 0.8628, F1 Macro: 0.8058\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.186, Accuracy: 0.877, F1 Micro: 0.877, F1 Macro: 0.8354\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1386, Accuracy: 0.8811, F1 Micro: 0.8811, F1 Macro: 0.8381\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0953, Accuracy: 0.8902, F1 Micro: 0.8902, F1 Macro: 0.8516\n",
      "Epoch 8/10, Train Loss: 0.0773, Accuracy: 0.8821, F1 Micro: 0.8821, F1 Macro: 0.8406\n",
      "Epoch 9/10, Train Loss: 0.1009, Accuracy: 0.873, F1 Micro: 0.873, F1 Macro: 0.8179\n",
      "Epoch 10/10, Train Loss: 0.0661, Accuracy: 0.8821, F1 Micro: 0.8821, F1 Macro: 0.8359\n",
      "\n",
      "Sentiment analysis accuracy: 0.8902, F1 Micro: 0.8902, F1 Macro: 0.8516\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93       710\n",
      "    positive       0.90      0.68      0.78       274\n",
      "\n",
      "    accuracy                           0.89       984\n",
      "   macro avg       0.89      0.83      0.85       984\n",
      "weighted avg       0.89      0.89      0.89       984\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 550: Accuracy: 0.937, F1 Micro: 0.937, F1 Macro: 0.7631\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.90      0.93        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.79      1.00      0.88        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.91      0.96      0.93       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.57      0.40      0.47        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.81      0.74      0.77       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.76      0.80        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.60      0.58      0.59       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.90      0.99      0.94       496\n",
      "    positive       0.79      0.28      0.41        68\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.56      0.42      0.45       571\n",
      "weighted avg       0.87      0.89      0.87       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.78      0.83       200\n",
      "     neutral       0.88      0.93      0.91       315\n",
      "    positive       0.85      0.93      0.89        56\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.87      0.88      0.87       571\n",
      "weighted avg       0.88      0.88      0.88       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83       162\n",
      "     neutral       0.92      0.94      0.93       387\n",
      "    positive       0.42      0.23      0.29        22\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.72      0.67      0.69       571\n",
      "weighted avg       0.88      0.88      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.73      0.82        85\n",
      "     neutral       0.93      0.99      0.96       418\n",
      "    positive       0.97      0.88      0.92        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.87      0.90       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.24      0.35        29\n",
      "     neutral       0.96      1.00      0.98       525\n",
      "    positive       0.69      0.65      0.67        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.76      0.63      0.67       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.74      0.82        54\n",
      "     neutral       0.97      1.00      0.98       511\n",
      "    positive       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.97      0.75      0.82       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.95      0.96        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.98      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 155.0571985244751 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0070693155750632284\n",
      "Acquired samples: 174\n",
      "Sampling duration: 54.7974591255188 seconds\n",
      "New train size: 724\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5092, Accuracy: 0.8113, F1 Micro: 0.8937, F1 Macro: 0.8877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4449, Accuracy: 0.8361, F1 Micro: 0.9044, F1 Macro: 0.8956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3754, Accuracy: 0.8813, F1 Micro: 0.9298, F1 Macro: 0.9249\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3014, Accuracy: 0.9095, F1 Micro: 0.9456, F1 Macro: 0.9418\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2379, Accuracy: 0.9312, F1 Micro: 0.9581, F1 Macro: 0.9555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2025, Accuracy: 0.9375, F1 Micro: 0.9618, F1 Macro: 0.959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1693, Accuracy: 0.9396, F1 Micro: 0.963, F1 Macro: 0.9598\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1546, Accuracy: 0.9439, F1 Micro: 0.9655, F1 Macro: 0.9631\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1314, Accuracy: 0.9464, F1 Micro: 0.9671, F1 Macro: 0.9641\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1122, Accuracy: 0.9488, F1 Micro: 0.9685, F1 Macro: 0.9658\n",
      "\n",
      "Aspect detection accuracy: 0.9488, F1 Micro: 0.9685, F1 Macro: 0.9658\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.95      1.00      0.97       480\n",
      "         bau       0.96      0.97      0.97       496\n",
      "     general       0.91      0.99      0.95       500\n",
      "  kebersihan       0.92      0.91      0.91       317\n",
      "       linen       0.89      0.97      0.93       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.96      1.00      0.98       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.95      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.95      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5169, Accuracy: 0.8185, F1 Micro: 0.8185, F1 Macro: 0.7632\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3065, Accuracy: 0.8641, F1 Micro: 0.8641, F1 Macro: 0.8244\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.256, Accuracy: 0.8869, F1 Micro: 0.8869, F1 Macro: 0.8523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1992, Accuracy: 0.8909, F1 Micro: 0.8909, F1 Macro: 0.8609\n",
      "Epoch 5/10, Train Loss: 0.1418, Accuracy: 0.875, F1 Micro: 0.875, F1 Macro: 0.8252\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0895, Accuracy: 0.8929, F1 Micro: 0.8929, F1 Macro: 0.8548\n",
      "Epoch 7/10, Train Loss: 0.0816, Accuracy: 0.881, F1 Micro: 0.881, F1 Macro: 0.8345\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0697, Accuracy: 0.8968, F1 Micro: 0.8968, F1 Macro: 0.8632\n",
      "Epoch 9/10, Train Loss: 0.0371, Accuracy: 0.8938, F1 Micro: 0.8938, F1 Macro: 0.8571\n",
      "Epoch 10/10, Train Loss: 0.0419, Accuracy: 0.8958, F1 Micro: 0.8958, F1 Macro: 0.8617\n",
      "\n",
      "Sentiment analysis accuracy: 0.8968, F1 Micro: 0.8968, F1 Macro: 0.8632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93       721\n",
      "    positive       0.91      0.70      0.80       287\n",
      "\n",
      "    accuracy                           0.90      1008\n",
      "   macro avg       0.90      0.84      0.86      1008\n",
      "weighted avg       0.90      0.90      0.89      1008\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 724: Accuracy: 0.942, F1 Micro: 0.942, F1 Macro: 0.7819\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.74      0.83        86\n",
      "     neutral       0.95      1.00      0.97       475\n",
      "    positive       0.75      0.30      0.43        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.88      0.68      0.74       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.76      0.78        78\n",
      "     neutral       0.96      0.97      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.58      0.58       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.91      0.99      0.95       496\n",
      "    positive       0.90      0.41      0.57        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.61      0.47      0.51       571\n",
      "weighted avg       0.90      0.91      0.89       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.84      0.85       200\n",
      "     neutral       0.92      0.91      0.91       315\n",
      "    positive       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.87      0.90      0.89       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.75      0.81       162\n",
      "     neutral       0.89      0.97      0.93       387\n",
      "    positive       0.67      0.27      0.39        22\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.81      0.67      0.71       571\n",
      "weighted avg       0.88      0.88      0.87       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.82      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.86      0.94      0.90        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.31      0.42        29\n",
      "     neutral       0.96      1.00      0.98       525\n",
      "    positive       0.71      0.59      0.65        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.77      0.63      0.68       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.91      0.92        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.97      0.86      0.90       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.96      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 179.52103996276855 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.007447527069598436\n",
      "Acquired samples: 156\n",
      "Sampling duration: 51.345064878463745 seconds\n",
      "New train size: 880\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4976, Accuracy: 0.8135, F1 Micro: 0.8948, F1 Macro: 0.8885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4168, Accuracy: 0.8549, F1 Micro: 0.916, F1 Macro: 0.9112\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3169, Accuracy: 0.9054, F1 Micro: 0.9434, F1 Macro: 0.9396\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.245, Accuracy: 0.9347, F1 Micro: 0.9602, F1 Macro: 0.9578\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2059, Accuracy: 0.9405, F1 Micro: 0.9637, F1 Macro: 0.9614\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1674, Accuracy: 0.945, F1 Micro: 0.9663, F1 Macro: 0.9641\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1418, Accuracy: 0.9464, F1 Micro: 0.9671, F1 Macro: 0.9644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1343, Accuracy: 0.9512, F1 Micro: 0.9699, F1 Macro: 0.9672\n",
      "Epoch 9/10, Train Loss: 0.1149, Accuracy: 0.9509, F1 Micro: 0.9698, F1 Macro: 0.9672\n",
      "Epoch 10/10, Train Loss: 0.0966, Accuracy: 0.9503, F1 Micro: 0.9695, F1 Macro: 0.9669\n",
      "\n",
      "Aspect detection accuracy: 0.9512, F1 Micro: 0.9699, F1 Macro: 0.9672\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.96      0.99      0.98       480\n",
      "         bau       0.96      0.99      0.98       496\n",
      "     general       0.91      0.99      0.95       500\n",
      "  kebersihan       0.93      0.91      0.92       317\n",
      "       linen       0.93      0.94      0.93       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.98      1.00      0.99       516\n",
      "        wifi       1.00      0.99      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4955, Accuracy: 0.8354, F1 Micro: 0.8354, F1 Macro: 0.7848\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3232, Accuracy: 0.8606, F1 Micro: 0.8606, F1 Macro: 0.8005\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2595, Accuracy: 0.8896, F1 Micro: 0.8896, F1 Macro: 0.852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1796, Accuracy: 0.8945, F1 Micro: 0.8945, F1 Macro: 0.8594\n",
      "Epoch 5/10, Train Loss: 0.1762, Accuracy: 0.8906, F1 Micro: 0.8906, F1 Macro: 0.8499\n",
      "Epoch 6/10, Train Loss: 0.1291, Accuracy: 0.8906, F1 Micro: 0.8906, F1 Macro: 0.8503\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0915, Accuracy: 0.9022, F1 Micro: 0.9022, F1 Macro: 0.871\n",
      "Epoch 8/10, Train Loss: 0.0821, Accuracy: 0.8867, F1 Micro: 0.8867, F1 Macro: 0.8419\n",
      "Epoch 9/10, Train Loss: 0.0638, Accuracy: 0.8935, F1 Micro: 0.8935, F1 Macro: 0.8529\n",
      "Epoch 10/10, Train Loss: 0.0451, Accuracy: 0.8935, F1 Micro: 0.8935, F1 Macro: 0.8545\n",
      "\n",
      "Sentiment analysis accuracy: 0.9022, F1 Micro: 0.9022, F1 Macro: 0.871\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93       743\n",
      "    positive       0.90      0.73      0.81       290\n",
      "\n",
      "    accuracy                           0.90      1033\n",
      "   macro avg       0.90      0.85      0.87      1033\n",
      "weighted avg       0.90      0.90      0.90      1033\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 880: Accuracy: 0.9455, F1 Micro: 0.9455, F1 Macro: 0.8219\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.78      0.85        86\n",
      "     neutral       0.96      0.99      0.98       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.86      0.79      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.78      0.84        78\n",
      "     neutral       0.96      0.99      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.76      0.83       571\n",
      "weighted avg       0.96      0.96      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.91      0.99      0.95       496\n",
      "    positive       0.81      0.38      0.52        68\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.57      0.46      0.49       571\n",
      "weighted avg       0.89      0.90      0.88       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86       200\n",
      "     neutral       0.93      0.90      0.91       315\n",
      "    positive       0.83      0.96      0.89        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.87      0.91      0.89       571\n",
      "weighted avg       0.90      0.89      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.83      0.84       162\n",
      "     neutral       0.93      0.94      0.93       387\n",
      "    positive       0.55      0.50      0.52        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.77      0.76      0.76       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.82      0.87        85\n",
      "     neutral       0.96      0.99      0.97       418\n",
      "    positive       0.95      0.91      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.91      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.34      0.48        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.71      0.71      0.71        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.81      0.68      0.72       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.85      0.90        54\n",
      "     neutral       0.98      1.00      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.98      0.84      0.90       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.97      0.97        74\n",
      "     neutral       1.00      0.99      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.90      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 197.8123598098755 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.005273764207959175\n",
      "Acquired samples: 141\n",
      "Sampling duration: 45.92233324050903 seconds\n",
      "New train size: 1021\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4887, Accuracy: 0.8106, F1 Micro: 0.8935, F1 Macro: 0.8875\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4048, Accuracy: 0.8755, F1 Micro: 0.9265, F1 Macro: 0.9208\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3075, Accuracy: 0.9187, F1 Micro: 0.9508, F1 Macro: 0.9474\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2381, Accuracy: 0.9377, F1 Micro: 0.962, F1 Macro: 0.9597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1935, Accuracy: 0.9444, F1 Micro: 0.9659, F1 Macro: 0.9632\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1643, Accuracy: 0.9455, F1 Micro: 0.9666, F1 Macro: 0.9641\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1434, Accuracy: 0.9484, F1 Micro: 0.9683, F1 Macro: 0.9659\n",
      "Epoch 8/10, Train Loss: 0.1262, Accuracy: 0.9484, F1 Micro: 0.9682, F1 Macro: 0.9657\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1051, Accuracy: 0.9526, F1 Micro: 0.9707, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0953, Accuracy: 0.9547, F1 Micro: 0.972, F1 Macro: 0.9692\n",
      "\n",
      "Aspect detection accuracy: 0.9547, F1 Micro: 0.972, F1 Macro: 0.9692\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.92      0.99      0.95       500\n",
      "  kebersihan       0.90      0.93      0.92       317\n",
      "       linen       0.93      0.94      0.94       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      0.99      0.99       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4601, Accuracy: 0.8382, F1 Micro: 0.8382, F1 Macro: 0.7788\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2908, Accuracy: 0.8562, F1 Micro: 0.8562, F1 Macro: 0.8009\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.208, Accuracy: 0.8874, F1 Micro: 0.8874, F1 Macro: 0.8511\n",
      "Epoch 4/10, Train Loss: 0.1395, Accuracy: 0.8798, F1 Micro: 0.8798, F1 Macro: 0.8357\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1268, Accuracy: 0.8903, F1 Micro: 0.8903, F1 Macro: 0.8554\n",
      "Epoch 6/10, Train Loss: 0.1087, Accuracy: 0.877, F1 Micro: 0.877, F1 Macro: 0.8297\n",
      "Epoch 7/10, Train Loss: 0.0689, Accuracy: 0.8884, F1 Micro: 0.8884, F1 Macro: 0.8529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0627, Accuracy: 0.8912, F1 Micro: 0.8912, F1 Macro: 0.8539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0366, Accuracy: 0.895, F1 Micro: 0.895, F1 Macro: 0.8618\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0266, Accuracy: 0.8959, F1 Micro: 0.8959, F1 Macro: 0.8604\n",
      "\n",
      "Sentiment analysis accuracy: 0.8959, F1 Micro: 0.8959, F1 Macro: 0.8604\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.98      0.93       752\n",
      "    positive       0.95      0.68      0.79       305\n",
      "\n",
      "    accuracy                           0.90      1057\n",
      "   macro avg       0.91      0.83      0.86      1057\n",
      "weighted avg       0.90      0.90      0.89      1057\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1021: Accuracy: 0.9483, F1 Micro: 0.9483, F1 Macro: 0.8333\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.88      0.90        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.87      0.79      0.82       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.78      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.75      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.92      0.99      0.95       496\n",
      "    positive       0.87      0.49      0.62        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.60      0.49      0.53       571\n",
      "weighted avg       0.90      0.92      0.90       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.83      0.86       200\n",
      "     neutral       0.90      0.93      0.92       315\n",
      "    positive       0.90      0.95      0.92        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.90      0.90      0.90       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.85      0.83       162\n",
      "     neutral       0.93      0.94      0.94       387\n",
      "    positive       0.78      0.32      0.45        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.84      0.70      0.74       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.84      0.88        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.90      0.88      0.89        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.90      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.52      0.60        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.71      0.73        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.74      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.97      0.86      0.91       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.97      0.96        74\n",
      "     neutral       1.00      0.99      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 223.279935836792 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.00469110794365406\n",
      "Acquired samples: 127\n",
      "Sampling duration: 42.508955001831055 seconds\n",
      "New train size: 1148\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4873, Accuracy: 0.8156, F1 Micro: 0.8954, F1 Macro: 0.8881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3851, Accuracy: 0.8939, F1 Micro: 0.9366, F1 Macro: 0.9306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2786, Accuracy: 0.9266, F1 Micro: 0.9556, F1 Macro: 0.9529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2117, Accuracy: 0.942, F1 Micro: 0.9645, F1 Macro: 0.9622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1758, Accuracy: 0.9455, F1 Micro: 0.9665, F1 Macro: 0.9642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1504, Accuracy: 0.9488, F1 Micro: 0.9685, F1 Macro: 0.9664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.133, Accuracy: 0.9498, F1 Micro: 0.9691, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1112, Accuracy: 0.9514, F1 Micro: 0.97, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.097, Accuracy: 0.9552, F1 Micro: 0.9723, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0826, Accuracy: 0.9573, F1 Micro: 0.9735, F1 Macro: 0.9708\n",
      "\n",
      "Aspect detection accuracy: 0.9573, F1 Micro: 0.9735, F1 Macro: 0.9708\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.98      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.92      0.92      0.92       317\n",
      "       linen       0.90      0.96      0.93       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      0.99      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      0.99      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4345, Accuracy: 0.8538, F1 Micro: 0.8538, F1 Macro: 0.8115\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2789, Accuracy: 0.8557, F1 Micro: 0.8557, F1 Macro: 0.8071\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1736, Accuracy: 0.8911, F1 Micro: 0.8911, F1 Macro: 0.8637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1528, Accuracy: 0.8911, F1 Micro: 0.8911, F1 Macro: 0.8575\n",
      "Epoch 5/10, Train Loss: 0.1065, Accuracy: 0.8901, F1 Micro: 0.8901, F1 Macro: 0.8603\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0798, Accuracy: 0.8957, F1 Micro: 0.8957, F1 Macro: 0.8677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0653, Accuracy: 0.8966, F1 Micro: 0.8966, F1 Macro: 0.8679\n",
      "Epoch 8/10, Train Loss: 0.0499, Accuracy: 0.8939, F1 Micro: 0.8939, F1 Macro: 0.8671\n",
      "Epoch 9/10, Train Loss: 0.0453, Accuracy: 0.8957, F1 Micro: 0.8957, F1 Macro: 0.8686\n",
      "Epoch 10/10, Train Loss: 0.0294, Accuracy: 0.8892, F1 Micro: 0.8892, F1 Macro: 0.8561\n",
      "\n",
      "Sentiment analysis accuracy: 0.8966, F1 Micro: 0.8966, F1 Macro: 0.8679\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93       753\n",
      "    positive       0.92      0.72      0.81       321\n",
      "\n",
      "    accuracy                           0.90      1074\n",
      "   macro avg       0.90      0.85      0.87      1074\n",
      "weighted avg       0.90      0.90      0.89      1074\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1148: Accuracy: 0.9504, F1 Micro: 0.9504, F1 Macro: 0.8405\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        86\n",
      "     neutral       0.98      0.98      0.98       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.79      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.77      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.58       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87       200\n",
      "     neutral       0.92      0.92      0.92       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.90      0.91      0.90       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.77      0.81       162\n",
      "     neutral       0.90      0.96      0.93       387\n",
      "    positive       0.55      0.27      0.36        22\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.77      0.67      0.70       571\n",
      "weighted avg       0.87      0.88      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.82      0.84        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.48      0.61        29\n",
      "     neutral       0.98      0.99      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.81      0.81       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.99      0.97        74\n",
      "     neutral       1.00      0.99      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 245.03443121910095 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.00458193477243185\n",
      "Acquired samples: 114\n",
      "Sampling duration: 38.0894136428833 seconds\n",
      "New train size: 1262\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4882, Accuracy: 0.8123, F1 Micro: 0.895, F1 Macro: 0.8903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.357, Accuracy: 0.9059, F1 Micro: 0.9436, F1 Macro: 0.9397\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2559, Accuracy: 0.933, F1 Micro: 0.9592, F1 Macro: 0.9567\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2003, Accuracy: 0.9448, F1 Micro: 0.9662, F1 Macro: 0.9639\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1672, Accuracy: 0.9455, F1 Micro: 0.9667, F1 Macro: 0.9643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1425, Accuracy: 0.9533, F1 Micro: 0.9711, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1201, Accuracy: 0.9578, F1 Micro: 0.9738, F1 Macro: 0.9714\n",
      "Epoch 8/10, Train Loss: 0.1017, Accuracy: 0.955, F1 Micro: 0.9723, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0856, Accuracy: 0.958, F1 Micro: 0.974, F1 Macro: 0.971\n",
      "Epoch 10/10, Train Loss: 0.0769, Accuracy: 0.9563, F1 Micro: 0.973, F1 Macro: 0.9702\n",
      "\n",
      "Aspect detection accuracy: 0.958, F1 Micro: 0.974, F1 Macro: 0.971\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.91      0.92      0.91       317\n",
      "       linen       0.91      0.96      0.94       392\n",
      "     service       0.96      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4428, Accuracy: 0.8416, F1 Micro: 0.8416, F1 Macro: 0.7848\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2579, Accuracy: 0.8816, F1 Micro: 0.8816, F1 Macro: 0.8488\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1945, Accuracy: 0.8919, F1 Micro: 0.8919, F1 Macro: 0.8579\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1499, Accuracy: 0.9012, F1 Micro: 0.9012, F1 Macro: 0.8753\n",
      "Epoch 5/10, Train Loss: 0.1082, Accuracy: 0.8928, F1 Micro: 0.8928, F1 Macro: 0.8676\n",
      "Epoch 6/10, Train Loss: 0.1008, Accuracy: 0.8975, F1 Micro: 0.8975, F1 Macro: 0.8695\n",
      "Epoch 7/10, Train Loss: 0.0706, Accuracy: 0.8956, F1 Micro: 0.8956, F1 Macro: 0.865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0624, Accuracy: 0.9012, F1 Micro: 0.9012, F1 Macro: 0.8725\n",
      "Epoch 9/10, Train Loss: 0.0429, Accuracy: 0.8863, F1 Micro: 0.8863, F1 Macro: 0.8498\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0408, Accuracy: 0.904, F1 Micro: 0.904, F1 Macro: 0.8779\n",
      "\n",
      "Sentiment analysis accuracy: 0.904, F1 Micro: 0.904, F1 Macro: 0.8779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93       753\n",
      "    positive       0.92      0.74      0.82       320\n",
      "\n",
      "    accuracy                           0.90      1073\n",
      "   macro avg       0.91      0.86      0.88      1073\n",
      "weighted avg       0.91      0.90      0.90      1073\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1262: Accuracy: 0.9518, F1 Micro: 0.9518, F1 Macro: 0.8528\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.98      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.86      0.89        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.82      0.84       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.81      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.57       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.83      0.85       200\n",
      "     neutral       0.91      0.92      0.91       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.88      0.90      0.89       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84       162\n",
      "     neutral       0.91      0.96      0.94       387\n",
      "    positive       0.75      0.41      0.53        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.84      0.73      0.77       571\n",
      "weighted avg       0.89      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.80      0.84        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.89      0.93      0.91        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.90      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.48      0.64        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      1.00      0.85        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.83      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.99      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.88      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 252.56736516952515 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.004401474166661501\n",
      "Acquired samples: 103\n",
      "Sampling duration: 34.73066258430481 seconds\n",
      "New train size: 1365\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4772, Accuracy: 0.8231, F1 Micro: 0.8993, F1 Macro: 0.8928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3542, Accuracy: 0.9125, F1 Micro: 0.9472, F1 Macro: 0.9432\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2399, Accuracy: 0.9377, F1 Micro: 0.9618, F1 Macro: 0.9595\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1947, Accuracy: 0.9446, F1 Micro: 0.9661, F1 Macro: 0.9642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1627, Accuracy: 0.9498, F1 Micro: 0.9692, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.135, Accuracy: 0.9531, F1 Micro: 0.9711, F1 Macro: 0.969\n",
      "Epoch 7/10, Train Loss: 0.1157, Accuracy: 0.9493, F1 Micro: 0.9689, F1 Macro: 0.9662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0995, Accuracy: 0.9561, F1 Micro: 0.9728, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0846, Accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9711\n",
      "Epoch 10/10, Train Loss: 0.0742, Accuracy: 0.9568, F1 Micro: 0.9733, F1 Macro: 0.9708\n",
      "\n",
      "Aspect detection accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9711\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.91      0.92      0.92       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4173, Accuracy: 0.8302, F1 Micro: 0.8302, F1 Macro: 0.7619\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2689, Accuracy: 0.8621, F1 Micro: 0.8621, F1 Macro: 0.8138\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1982, Accuracy: 0.8865, F1 Micro: 0.8865, F1 Macro: 0.8487\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1374, Accuracy: 0.8874, F1 Micro: 0.8874, F1 Macro: 0.8547\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0997, Accuracy: 0.8959, F1 Micro: 0.8959, F1 Macro: 0.8635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0845, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0587, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8697\n",
      "Epoch 8/10, Train Loss: 0.0358, Accuracy: 0.8968, F1 Micro: 0.8968, F1 Macro: 0.8646\n",
      "Epoch 9/10, Train Loss: 0.0378, Accuracy: 0.8874, F1 Micro: 0.8874, F1 Macro: 0.8505\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0336, Accuracy: 0.9006, F1 Micro: 0.9006, F1 Macro: 0.8704\n",
      "\n",
      "Sentiment analysis accuracy: 0.9006, F1 Micro: 0.9006, F1 Macro: 0.8704\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93       752\n",
      "    positive       0.94      0.71      0.81       314\n",
      "\n",
      "    accuracy                           0.90      1066\n",
      "   macro avg       0.91      0.85      0.87      1066\n",
      "weighted avg       0.90      0.90      0.90      1066\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1365: Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.8338\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.85      0.90        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.64      0.70      0.67        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.85      0.85       571\n",
      "weighted avg       0.97      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.79      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.88      0.65      0.75        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.61      0.54      0.57       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.84      0.85       200\n",
      "     neutral       0.91      0.92      0.92       315\n",
      "    positive       0.89      0.89      0.89        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.89      0.89      0.89       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.81      0.84       162\n",
      "     neutral       0.91      0.96      0.94       387\n",
      "    positive       0.60      0.27      0.37        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.79      0.68      0.72       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.88      0.87        85\n",
      "     neutral       0.97      0.96      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.45      0.54        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.71      0.71        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.79      0.72      0.74       571\n",
      "weighted avg       0.95      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.96      0.97        74\n",
      "     neutral       0.99      1.00      1.00       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.87      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 268.25197744369507 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0030597240664064886\n",
      "Acquired samples: 62\n",
      "Sampling duration: 31.337403297424316 seconds\n",
      "New train size: 1427\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4789, Accuracy: 0.8205, F1 Micro: 0.899, F1 Macro: 0.8948\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3365, Accuracy: 0.9214, F1 Micro: 0.9523, F1 Macro: 0.9487\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2316, Accuracy: 0.9418, F1 Micro: 0.9644, F1 Macro: 0.9622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1828, Accuracy: 0.9464, F1 Micro: 0.9672, F1 Macro: 0.9649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1535, Accuracy: 0.9521, F1 Micro: 0.9705, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1349, Accuracy: 0.9559, F1 Micro: 0.9727, F1 Macro: 0.9702\n",
      "Epoch 7/10, Train Loss: 0.1073, Accuracy: 0.9524, F1 Micro: 0.9707, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0932, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9727\n",
      "Epoch 9/10, Train Loss: 0.0826, Accuracy: 0.959, F1 Micro: 0.9746, F1 Macro: 0.972\n",
      "Epoch 10/10, Train Loss: 0.0704, Accuracy: 0.958, F1 Micro: 0.974, F1 Macro: 0.9716\n",
      "\n",
      "Aspect detection accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9727\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.93      0.99      0.96       500\n",
      "  kebersihan       0.94      0.91      0.93       317\n",
      "       linen       0.93      0.96      0.94       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4244, Accuracy: 0.844, F1 Micro: 0.844, F1 Macro: 0.786\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.258, Accuracy: 0.8866, F1 Micro: 0.8866, F1 Macro: 0.8501\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.174, Accuracy: 0.9026, F1 Micro: 0.9026, F1 Macro: 0.8724\n",
      "Epoch 4/10, Train Loss: 0.11, Accuracy: 0.8904, F1 Micro: 0.8904, F1 Macro: 0.8506\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0932, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8714\n",
      "Epoch 6/10, Train Loss: 0.0705, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.866\n",
      "Epoch 7/10, Train Loss: 0.053, Accuracy: 0.8951, F1 Micro: 0.8951, F1 Macro: 0.8576\n",
      "Epoch 8/10, Train Loss: 0.0412, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0339, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.874\n",
      "Epoch 10/10, Train Loss: 0.0166, Accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8707\n",
      "\n",
      "Sentiment analysis accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       763\n",
      "    positive       0.93      0.72      0.81       295\n",
      "\n",
      "    accuracy                           0.91      1058\n",
      "   macro avg       0.92      0.85      0.87      1058\n",
      "weighted avg       0.91      0.91      0.90      1058\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1427: Accuracy: 0.9532, F1 Micro: 0.9532, F1 Macro: 0.8314\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.84      0.87        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.78      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.76      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.92      0.99      0.96       496\n",
      "    positive       0.90      0.51      0.65        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.61      0.50      0.54       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.89      0.88       200\n",
      "     neutral       0.94      0.91      0.93       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86       162\n",
      "     neutral       0.93      0.96      0.94       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.74      0.78       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.84      0.87        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.45      0.55        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.71      0.71        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.80      0.72      0.75       571\n",
      "weighted avg       0.95      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      1.00      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.89      0.93       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 269.96677446365356 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.003462738962844014\n",
      "Acquired samples: 86\n",
      "Sampling duration: 29.308510065078735 seconds\n",
      "New train size: 1513\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4668, Accuracy: 0.8267, F1 Micro: 0.9021, F1 Macro: 0.8973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3221, Accuracy: 0.9283, F1 Micro: 0.9562, F1 Macro: 0.9529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2232, Accuracy: 0.9422, F1 Micro: 0.9647, F1 Macro: 0.9623\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1792, Accuracy: 0.9465, F1 Micro: 0.9672, F1 Macro: 0.9649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1466, Accuracy: 0.954, F1 Micro: 0.9716, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.13, Accuracy: 0.9568, F1 Micro: 0.9733, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1042, Accuracy: 0.9576, F1 Micro: 0.9738, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0892, Accuracy: 0.9601, F1 Micro: 0.9752, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0777, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9739\n",
      "Epoch 10/10, Train Loss: 0.0665, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9738\n",
      "\n",
      "Aspect detection accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9739\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4216, Accuracy: 0.848, F1 Micro: 0.848, F1 Macro: 0.7859\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2256, Accuracy: 0.899, F1 Micro: 0.899, F1 Macro: 0.8693\n",
      "Epoch 3/10, Train Loss: 0.1547, Accuracy: 0.8943, F1 Micro: 0.8943, F1 Macro: 0.8592\n",
      "Epoch 4/10, Train Loss: 0.1024, Accuracy: 0.8981, F1 Micro: 0.8981, F1 Macro: 0.8655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0793, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8813\n",
      "Epoch 6/10, Train Loss: 0.0789, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8748\n",
      "Epoch 7/10, Train Loss: 0.0491, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8784\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0433, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.8848\n",
      "Epoch 9/10, Train Loss: 0.0347, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8842\n",
      "Epoch 10/10, Train Loss: 0.0345, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8821\n",
      "\n",
      "Sentiment analysis accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.8848\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       767\n",
      "    positive       0.95      0.74      0.83       312\n",
      "\n",
      "    accuracy                           0.91      1079\n",
      "   macro avg       0.92      0.86      0.88      1079\n",
      "weighted avg       0.91      0.91      0.91      1079\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1513: Accuracy: 0.9564, F1 Micro: 0.9564, F1 Macro: 0.8673\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.87      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.85      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.81      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.83      0.93      0.87       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.85      0.66      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.76      0.60      0.64       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88       200\n",
      "     neutral       0.93      0.93      0.93       315\n",
      "    positive       0.90      0.93      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.91      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.83      0.85       162\n",
      "     neutral       0.92      0.96      0.94       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.74      0.78       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.88      0.93       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 287.36807084083557 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.002948351902887225\n",
      "Acquired samples: 78\n",
      "Sampling duration: 26.65811800956726 seconds\n",
      "New train size: 1591\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4684, Accuracy: 0.8385, F1 Micro: 0.9076, F1 Macro: 0.9021\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3289, Accuracy: 0.9267, F1 Micro: 0.9553, F1 Macro: 0.9514\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2215, Accuracy: 0.9432, F1 Micro: 0.9653, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1773, Accuracy: 0.9458, F1 Micro: 0.9669, F1 Macro: 0.9645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1465, Accuracy: 0.9517, F1 Micro: 0.9702, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1253, Accuracy: 0.9554, F1 Micro: 0.9726, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1051, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.089, Accuracy: 0.9615, F1 Micro: 0.976, F1 Macro: 0.9735\n",
      "Epoch 9/10, Train Loss: 0.0748, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0654, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.93      0.94      0.93       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.97      0.99      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.412, Accuracy: 0.7831, F1 Micro: 0.7831, F1 Macro: 0.6262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2523, Accuracy: 0.8948, F1 Micro: 0.8948, F1 Macro: 0.86\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1496, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.8856\n",
      "Epoch 4/10, Train Loss: 0.118, Accuracy: 0.9089, F1 Micro: 0.9089, F1 Macro: 0.8807\n",
      "Epoch 5/10, Train Loss: 0.0909, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8815\n",
      "Epoch 6/10, Train Loss: 0.0574, Accuracy: 0.8977, F1 Micro: 0.8977, F1 Macro: 0.8705\n",
      "Epoch 7/10, Train Loss: 0.0456, Accuracy: 0.9089, F1 Micro: 0.9089, F1 Macro: 0.8789\n",
      "Epoch 8/10, Train Loss: 0.0368, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8802\n",
      "Epoch 9/10, Train Loss: 0.0282, Accuracy: 0.9033, F1 Micro: 0.9033, F1 Macro: 0.8748\n",
      "Epoch 10/10, Train Loss: 0.026, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8775\n",
      "\n",
      "Sentiment analysis accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.8856\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       765\n",
      "    positive       0.90      0.77      0.83       300\n",
      "\n",
      "    accuracy                           0.91      1065\n",
      "   macro avg       0.91      0.87      0.89      1065\n",
      "weighted avg       0.91      0.91      0.91      1065\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1591: Accuracy: 0.9557, F1 Micro: 0.9557, F1 Macro: 0.8559\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.79      1.00      0.88        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.92      0.97      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.84      0.88        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.60      0.60      0.60        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.81      0.82       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.79      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.88      0.63      0.74        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.77      0.59      0.64       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.87      0.89       200\n",
      "     neutral       0.93      0.94      0.93       315\n",
      "    positive       0.85      0.95      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.84      0.86       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.60      0.41      0.49        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.80      0.74      0.76       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.85      0.89        85\n",
      "     neutral       0.97      0.99      0.98       418\n",
      "    positive       0.94      0.96      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.48      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.89      0.91        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.60      0.50      0.55         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.84      0.79      0.82       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 299.8951108455658 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.0024290592409670357\n",
      "Acquired samples: 70\n",
      "Sampling duration: 23.875110149383545 seconds\n",
      "New train size: 1661\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4625, Accuracy: 0.8438, F1 Micro: 0.91, F1 Macro: 0.9041\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3122, Accuracy: 0.9295, F1 Micro: 0.9571, F1 Macro: 0.9539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2149, Accuracy: 0.9457, F1 Micro: 0.9666, F1 Macro: 0.9644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1742, Accuracy: 0.9509, F1 Micro: 0.9698, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1487, Accuracy: 0.9566, F1 Micro: 0.9731, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1218, Accuracy: 0.9592, F1 Micro: 0.9748, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1036, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9737\n",
      "Epoch 8/10, Train Loss: 0.0883, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0704, Accuracy: 0.9613, F1 Micro: 0.9761, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0629, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.92      0.95      0.93       317\n",
      "       linen       0.93      0.96      0.94       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3947, Accuracy: 0.8706, F1 Micro: 0.8706, F1 Macro: 0.8279\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2245, Accuracy: 0.8966, F1 Micro: 0.8966, F1 Macro: 0.8615\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1409, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8824\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0958, Accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.8851\n",
      "Epoch 5/10, Train Loss: 0.0759, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8778\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.054, Accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.8884\n",
      "Epoch 7/10, Train Loss: 0.0483, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8801\n",
      "Epoch 8/10, Train Loss: 0.032, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8808\n",
      "Epoch 9/10, Train Loss: 0.0395, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8859\n",
      "Epoch 10/10, Train Loss: 0.0227, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8857\n",
      "\n",
      "Sentiment analysis accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.8884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       768\n",
      "    positive       0.93      0.76      0.83       306\n",
      "\n",
      "    accuracy                           0.91      1074\n",
      "   macro avg       0.92      0.87      0.89      1074\n",
      "weighted avg       0.92      0.91      0.91      1074\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1661: Accuracy: 0.9567, F1 Micro: 0.9567, F1 Macro: 0.8633\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.91      0.79      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.79      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.86      0.63      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.93      0.59      0.65       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89       200\n",
      "     neutral       0.92      0.95      0.93       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.85       162\n",
      "     neutral       0.93      0.96      0.94       387\n",
      "    positive       0.59      0.45      0.51        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.79      0.75      0.77       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.92      0.97      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.52      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.78      0.80       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.87      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      1.00      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.89      0.93       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 306.2196342945099 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.002759893937036395\n",
      "Acquired samples: 51\n",
      "Sampling duration: 21.690382957458496 seconds\n",
      "New train size: 1712\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4629, Accuracy: 0.8528, F1 Micro: 0.915, F1 Macro: 0.9099\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3054, Accuracy: 0.9302, F1 Micro: 0.9576, F1 Macro: 0.9552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2088, Accuracy: 0.9464, F1 Micro: 0.9672, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1725, Accuracy: 0.9497, F1 Micro: 0.9691, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1431, Accuracy: 0.9554, F1 Micro: 0.9725, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.117, Accuracy: 0.9578, F1 Micro: 0.974, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0971, Accuracy: 0.9592, F1 Micro: 0.9748, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0825, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0704, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0607, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9763\n",
      "\n",
      "Aspect detection accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.93      0.96      0.94       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3843, Accuracy: 0.8598, F1 Micro: 0.8598, F1 Macro: 0.812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2074, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.8763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.151, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8849\n",
      "Epoch 4/10, Train Loss: 0.1055, Accuracy: 0.9047, F1 Micro: 0.9047, F1 Macro: 0.8765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.069, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8839\n",
      "Epoch 6/10, Train Loss: 0.0509, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8804\n",
      "Epoch 7/10, Train Loss: 0.0324, Accuracy: 0.8992, F1 Micro: 0.8992, F1 Macro: 0.8656\n",
      "Epoch 8/10, Train Loss: 0.0314, Accuracy: 0.8955, F1 Micro: 0.8955, F1 Macro: 0.8687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0344, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8844\n",
      "Epoch 10/10, Train Loss: 0.0234, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8836\n",
      "\n",
      "Sentiment analysis accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8844\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       774\n",
      "    positive       0.94      0.74      0.83       317\n",
      "\n",
      "    accuracy                           0.91      1091\n",
      "   macro avg       0.92      0.86      0.88      1091\n",
      "weighted avg       0.91      0.91      0.91      1091\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1712: Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.8738\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.79      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.62      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.89       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.85       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       1.00      0.41      0.58        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.93      0.74      0.79       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.99      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.88      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 317.3459165096283 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.0019271595869213344\n",
      "Acquired samples: 58\n",
      "Sampling duration: 19.90328884124756 seconds\n",
      "New train size: 1770\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4552, Accuracy: 0.8689, F1 Micro: 0.9232, F1 Macro: 0.9176\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3003, Accuracy: 0.9269, F1 Micro: 0.9556, F1 Macro: 0.9527\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2081, Accuracy: 0.9405, F1 Micro: 0.9637, F1 Macro: 0.9612\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1668, Accuracy: 0.9503, F1 Micro: 0.9696, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1367, Accuracy: 0.9563, F1 Micro: 0.973, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1144, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9743\n",
      "Epoch 7/10, Train Loss: 0.0965, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0819, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0707, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9749\n",
      "Epoch 10/10, Train Loss: 0.0576, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9747\n",
      "\n",
      "Aspect detection accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3737, Accuracy: 0.8567, F1 Micro: 0.8567, F1 Macro: 0.81\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2253, Accuracy: 0.8967, F1 Micro: 0.8967, F1 Macro: 0.8688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1561, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.8875\n",
      "Epoch 4/10, Train Loss: 0.099, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0812, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.8928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0625, Accuracy: 0.9191, F1 Micro: 0.9191, F1 Macro: 0.8956\n",
      "Epoch 7/10, Train Loss: 0.0373, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8828\n",
      "Epoch 8/10, Train Loss: 0.0295, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8817\n",
      "Epoch 9/10, Train Loss: 0.0316, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8811\n",
      "Epoch 10/10, Train Loss: 0.0247, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8754\n",
      "\n",
      "Sentiment analysis accuracy: 0.9191, F1 Micro: 0.9191, F1 Macro: 0.8956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       761\n",
      "    positive       0.95      0.76      0.85       314\n",
      "\n",
      "    accuracy                           0.92      1075\n",
      "   macro avg       0.93      0.87      0.90      1075\n",
      "weighted avg       0.92      0.92      0.92      1075\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1770: Accuracy: 0.958, F1 Micro: 0.958, F1 Macro: 0.871\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.85      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.77      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.88      0.72      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.57      0.59       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.87      0.89       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.90      0.96      0.93        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.82      0.85       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.75      0.80       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.88      0.85        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.93      0.97      0.95        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.66      0.73        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.97      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 321.0330579280853 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.0028589200926944615\n",
      "Acquired samples: 52\n",
      "Sampling duration: 18.14451789855957 seconds\n",
      "New train size: 1822\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4594, Accuracy: 0.8655, F1 Micro: 0.9216, F1 Macro: 0.9166\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2886, Accuracy: 0.9337, F1 Micro: 0.9596, F1 Macro: 0.9573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2006, Accuracy: 0.9458, F1 Micro: 0.9669, F1 Macro: 0.9647\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.166, Accuracy: 0.9524, F1 Micro: 0.9707, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1365, Accuracy: 0.9568, F1 Micro: 0.9734, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1121, Accuracy: 0.9592, F1 Micro: 0.9747, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0968, Accuracy: 0.9595, F1 Micro: 0.975, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0811, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0688, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0587, Accuracy: 0.9651, F1 Micro: 0.9784, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9651, F1 Micro: 0.9784, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.98      0.98       496\n",
      "     general       0.96      0.99      0.97       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3754, Accuracy: 0.8657, F1 Micro: 0.8657, F1 Macro: 0.8309\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2314, Accuracy: 0.9058, F1 Micro: 0.9058, F1 Macro: 0.8761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1575, Accuracy: 0.9086, F1 Micro: 0.9086, F1 Macro: 0.8784\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.098, Accuracy: 0.9095, F1 Micro: 0.9095, F1 Macro: 0.8824\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0829, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8894\n",
      "Epoch 6/10, Train Loss: 0.0655, Accuracy: 0.9058, F1 Micro: 0.9058, F1 Macro: 0.8745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0529, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.8927\n",
      "Epoch 8/10, Train Loss: 0.0288, Accuracy: 0.9095, F1 Micro: 0.9095, F1 Macro: 0.8815\n",
      "Epoch 9/10, Train Loss: 0.0411, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.8856\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0323, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.8942\n",
      "\n",
      "Sentiment analysis accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.8942\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       767\n",
      "    positive       0.94      0.77      0.84       305\n",
      "\n",
      "    accuracy                           0.92      1072\n",
      "   macro avg       0.92      0.87      0.89      1072\n",
      "weighted avg       0.92      0.92      0.92      1072\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1822: Accuracy: 0.9588, F1 Micro: 0.9588, F1 Macro: 0.8603\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.87      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86        78\n",
      "     neutral       0.98      0.98      0.98       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.78      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.96      0.99      0.97       496\n",
      "    positive       0.88      0.75      0.81        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.63      0.68       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.87      0.89       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.90      0.96      0.93        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.85       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       0.86      0.27      0.41        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.69      0.74       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.48      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.79      0.80       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 338.58569622039795 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.0030462051508948207\n",
      "Acquired samples: 50\n",
      "Sampling duration: 16.226937532424927 seconds\n",
      "New train size: 1872\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4433, Accuracy: 0.876, F1 Micro: 0.9268, F1 Macro: 0.9205\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2843, Accuracy: 0.9335, F1 Micro: 0.9596, F1 Macro: 0.9572\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1986, Accuracy: 0.9472, F1 Micro: 0.9676, F1 Macro: 0.9652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1637, Accuracy: 0.9509, F1 Micro: 0.9699, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1331, Accuracy: 0.9594, F1 Micro: 0.9748, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1112, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9741\n",
      "Epoch 7/10, Train Loss: 0.094, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0756, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9747\n",
      "Epoch 9/10, Train Loss: 0.0661, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0573, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9756\n",
      "\n",
      "Aspect detection accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4054, Accuracy: 0.8743, F1 Micro: 0.8743, F1 Macro: 0.8301\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2419, Accuracy: 0.9039, F1 Micro: 0.9039, F1 Macro: 0.8744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1394, Accuracy: 0.9131, F1 Micro: 0.9131, F1 Macro: 0.8893\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1061, Accuracy: 0.9159, F1 Micro: 0.9159, F1 Macro: 0.8905\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0648, Accuracy: 0.9159, F1 Micro: 0.9159, F1 Macro: 0.8915\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0617, Accuracy: 0.9159, F1 Micro: 0.9159, F1 Macro: 0.8895\n",
      "Epoch 7/10, Train Loss: 0.0418, Accuracy: 0.914, F1 Micro: 0.914, F1 Macro: 0.8876\n",
      "Epoch 8/10, Train Loss: 0.044, Accuracy: 0.914, F1 Micro: 0.914, F1 Macro: 0.8878\n",
      "Epoch 9/10, Train Loss: 0.0258, Accuracy: 0.915, F1 Micro: 0.915, F1 Macro: 0.8892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0325, Accuracy: 0.9187, F1 Micro: 0.9187, F1 Macro: 0.8952\n",
      "\n",
      "Sentiment analysis accuracy: 0.9187, F1 Micro: 0.9187, F1 Macro: 0.8952\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.94       773\n",
      "    positive       0.92      0.78      0.85       309\n",
      "\n",
      "    accuracy                           0.92      1082\n",
      "   macro avg       0.92      0.88      0.90      1082\n",
      "weighted avg       0.92      0.92      0.92      1082\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1872: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.8512\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.88      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.78      0.82        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.61      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.90       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.84      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.81      0.59      0.68        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.89        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.94      0.96      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.48      0.61        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.68      0.88      0.77        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.79      0.79       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.75      0.50      0.60         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.81      0.85       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 338.1980450153351 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.002667278121225536\n",
      "Acquired samples: 50\n",
      "Sampling duration: 14.579085350036621 seconds\n",
      "New train size: 1922\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4531, Accuracy: 0.8786, F1 Micro: 0.9282, F1 Macro: 0.9217\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2757, Accuracy: 0.9352, F1 Micro: 0.9604, F1 Macro: 0.9575\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1998, Accuracy: 0.9493, F1 Micro: 0.969, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1548, Accuracy: 0.9543, F1 Micro: 0.9718, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1256, Accuracy: 0.9604, F1 Micro: 0.9756, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1054, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0871, Accuracy: 0.9639, F1 Micro: 0.9775, F1 Macro: 0.9753\n",
      "Epoch 8/10, Train Loss: 0.0745, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0605, Accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9762\n",
      "Epoch 10/10, Train Loss: 0.0541, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.94      0.95      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3791, Accuracy: 0.8782, F1 Micro: 0.8782, F1 Macro: 0.8403\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2234, Accuracy: 0.9018, F1 Micro: 0.9018, F1 Macro: 0.8712\n",
      "Epoch 3/10, Train Loss: 0.131, Accuracy: 0.8918, F1 Micro: 0.8918, F1 Macro: 0.8563\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.106, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.089, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.8853\n",
      "Epoch 6/10, Train Loss: 0.0499, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8821\n",
      "Epoch 7/10, Train Loss: 0.0471, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8776\n",
      "Epoch 8/10, Train Loss: 0.0325, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8861\n",
      "Epoch 9/10, Train Loss: 0.0379, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0337, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8921\n",
      "\n",
      "Sentiment analysis accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8921\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       781\n",
      "    positive       0.94      0.76      0.84       319\n",
      "\n",
      "    accuracy                           0.92      1100\n",
      "   macro avg       0.92      0.87      0.89      1100\n",
      "weighted avg       0.92      0.92      0.91      1100\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1922: Accuracy: 0.9602, F1 Micro: 0.9602, F1 Macro: 0.884\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.87      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.83      0.85        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.14      0.20         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.89      0.72      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.73      0.62      0.65       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86       162\n",
      "     neutral       0.94      0.95      0.94       387\n",
      "    positive       0.63      0.55      0.59        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.81      0.78      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.83      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 342.1702299118042 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.0020839456235989934\n",
      "Acquired samples: 50\n",
      "Sampling duration: 13.40099287033081 seconds\n",
      "New train size: 1972\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4454, Accuracy: 0.8814, F1 Micro: 0.93, F1 Macro: 0.9244\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2722, Accuracy: 0.9411, F1 Micro: 0.964, F1 Macro: 0.962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.196, Accuracy: 0.9465, F1 Micro: 0.9673, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1587, Accuracy: 0.953, F1 Micro: 0.9711, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1325, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9748\n",
      "Epoch 6/10, Train Loss: 0.1051, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9747\n",
      "Epoch 7/10, Train Loss: 0.0881, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0717, Accuracy: 0.9648, F1 Micro: 0.9782, F1 Macro: 0.9761\n",
      "Epoch 9/10, Train Loss: 0.0626, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9759\n",
      "Epoch 10/10, Train Loss: 0.0542, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "\n",
      "Aspect detection accuracy: 0.9648, F1 Micro: 0.9782, F1 Macro: 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3949, Accuracy: 0.8688, F1 Micro: 0.8688, F1 Macro: 0.8237\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.232, Accuracy: 0.9014, F1 Micro: 0.9014, F1 Macro: 0.8689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1514, Accuracy: 0.9209, F1 Micro: 0.9209, F1 Macro: 0.898\n",
      "Epoch 4/10, Train Loss: 0.1056, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8912\n",
      "Epoch 5/10, Train Loss: 0.0858, Accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.8966\n",
      "Epoch 6/10, Train Loss: 0.0557, Accuracy: 0.9181, F1 Micro: 0.9181, F1 Macro: 0.8947\n",
      "Epoch 7/10, Train Loss: 0.0641, Accuracy: 0.9172, F1 Micro: 0.9172, F1 Macro: 0.8934\n",
      "Epoch 8/10, Train Loss: 0.0506, Accuracy: 0.9172, F1 Micro: 0.9172, F1 Macro: 0.8953\n",
      "Epoch 9/10, Train Loss: 0.0387, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8892\n",
      "Epoch 10/10, Train Loss: 0.0384, Accuracy: 0.9191, F1 Micro: 0.9191, F1 Macro: 0.8943\n",
      "\n",
      "Sentiment analysis accuracy: 0.9209, F1 Micro: 0.9209, F1 Macro: 0.898\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       767\n",
      "    positive       0.93      0.78      0.85       308\n",
      "\n",
      "    accuracy                           0.92      1075\n",
      "   macro avg       0.93      0.88      0.90      1075\n",
      "weighted avg       0.92      0.92      0.92      1075\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1972: Accuracy: 0.9588, F1 Micro: 0.9588, F1 Macro: 0.8675\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.78      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.57      0.59       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.88      0.90       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.83      0.85       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       1.00      0.41      0.58        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.93      0.74      0.79       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.84      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.88      0.96      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.82      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 338.6675217151642 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.002124825469218195\n",
      "Acquired samples: 25\n",
      "Sampling duration: 11.147892951965332 seconds\n",
      "New train size: 1997\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4519, Accuracy: 0.8804, F1 Micro: 0.9294, F1 Macro: 0.9237\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.275, Accuracy: 0.9406, F1 Micro: 0.9636, F1 Macro: 0.9613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.188, Accuracy: 0.9491, F1 Micro: 0.9688, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1531, Accuracy: 0.9538, F1 Micro: 0.9716, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1281, Accuracy: 0.9599, F1 Micro: 0.9752, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1051, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0907, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0748, Accuracy: 0.9641, F1 Micro: 0.9776, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0628, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0511, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9758\n",
      "\n",
      "Aspect detection accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.94      0.95      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3761, Accuracy: 0.8705, F1 Micro: 0.8705, F1 Macro: 0.8315\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1972, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.8854\n",
      "Epoch 3/10, Train Loss: 0.1374, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1012, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.8851\n",
      "Epoch 5/10, Train Loss: 0.0833, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0616, Accuracy: 0.9155, F1 Micro: 0.9155, F1 Macro: 0.8894\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0483, Accuracy: 0.9155, F1 Micro: 0.9155, F1 Macro: 0.8909\n",
      "Epoch 8/10, Train Loss: 0.0345, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8814\n",
      "Epoch 9/10, Train Loss: 0.0362, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.886\n",
      "Epoch 10/10, Train Loss: 0.0164, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.8901\n",
      "\n",
      "Sentiment analysis accuracy: 0.9155, F1 Micro: 0.9155, F1 Macro: 0.8909\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       774\n",
      "    positive       0.93      0.76      0.84       315\n",
      "\n",
      "    accuracy                           0.92      1089\n",
      "   macro avg       0.92      0.87      0.89      1089\n",
      "weighted avg       0.92      0.92      0.91      1089\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1997: Accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.8665\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.87      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.79      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.81      0.71      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.56      0.57       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.90      0.96      0.93        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.88      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.79      0.50      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.86      0.78      0.81       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.94      0.96      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.78      0.81       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 357.94565653800964 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.0018916038097813725\n",
      "Acquired samples: 50\n",
      "Sampling duration: 10.453207015991211 seconds\n",
      "New train size: 2047\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4471, Accuracy: 0.8826, F1 Micro: 0.9309, F1 Macro: 0.9258\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2685, Accuracy: 0.9344, F1 Micro: 0.9602, F1 Macro: 0.9583\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1917, Accuracy: 0.9519, F1 Micro: 0.9705, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1499, Accuracy: 0.9575, F1 Micro: 0.9738, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1279, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1058, Accuracy: 0.9648, F1 Micro: 0.9782, F1 Macro: 0.976\n",
      "Epoch 7/10, Train Loss: 0.0857, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0715, Accuracy: 0.9661, F1 Micro: 0.979, F1 Macro: 0.977\n",
      "Epoch 9/10, Train Loss: 0.0609, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.975\n",
      "Epoch 10/10, Train Loss: 0.0511, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.9661, F1 Micro: 0.979, F1 Macro: 0.977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.94      0.97      0.96       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3712, Accuracy: 0.875, F1 Micro: 0.875, F1 Macro: 0.8398\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2077, Accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1492, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8879\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0959, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.8949\n",
      "Epoch 5/10, Train Loss: 0.0681, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8859\n",
      "Epoch 6/10, Train Loss: 0.0565, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8929\n",
      "Epoch 7/10, Train Loss: 0.0396, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.8886\n",
      "Epoch 8/10, Train Loss: 0.0401, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8929\n",
      "Epoch 9/10, Train Loss: 0.0267, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.8886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0253, Accuracy: 0.9182, F1 Micro: 0.9182, F1 Macro: 0.8943\n",
      "\n",
      "Sentiment analysis accuracy: 0.9182, F1 Micro: 0.9182, F1 Macro: 0.8943\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       775\n",
      "    positive       0.93      0.77      0.84       313\n",
      "\n",
      "    accuracy                           0.92      1088\n",
      "   macro avg       0.92      0.87      0.89      1088\n",
      "weighted avg       0.92      0.92      0.92      1088\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2047: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.8824\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.90      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.86      0.87       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.79      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.62      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.87      0.89       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.89      0.98      0.93        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.87       162\n",
      "     neutral       0.94      0.97      0.96       387\n",
      "    positive       0.88      0.32      0.47        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.72      0.76       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.81      0.85        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.88      0.96      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.80      0.94      0.86        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.84      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 353.32052206993103 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.0019997751340270044\n",
      "Acquired samples: 50\n",
      "Sampling duration: 8.840047121047974 seconds\n",
      "New train size: 2097\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4446, Accuracy: 0.8875, F1 Micro: 0.9331, F1 Macro: 0.9271\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2647, Accuracy: 0.9403, F1 Micro: 0.9636, F1 Macro: 0.9613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1961, Accuracy: 0.9505, F1 Micro: 0.9697, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1492, Accuracy: 0.9563, F1 Micro: 0.9731, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1243, Accuracy: 0.9608, F1 Micro: 0.9758, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.103, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9756\n",
      "Epoch 7/10, Train Loss: 0.0904, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0733, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0601, Accuracy: 0.9661, F1 Micro: 0.9789, F1 Macro: 0.9767\n",
      "Epoch 10/10, Train Loss: 0.0524, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9764\n",
      "\n",
      "Aspect detection accuracy: 0.9661, F1 Micro: 0.9789, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.98      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3658, Accuracy: 0.8611, F1 Micro: 0.8611, F1 Macro: 0.8209\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2084, Accuracy: 0.897, F1 Micro: 0.897, F1 Macro: 0.8712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.135, Accuracy: 0.8987, F1 Micro: 0.8987, F1 Macro: 0.8724\n",
      "Epoch 4/10, Train Loss: 0.1069, Accuracy: 0.8898, F1 Micro: 0.8898, F1 Macro: 0.8622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0822, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.881\n",
      "Epoch 6/10, Train Loss: 0.0651, Accuracy: 0.905, F1 Micro: 0.905, F1 Macro: 0.8792\n",
      "Epoch 7/10, Train Loss: 0.047, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8767\n",
      "Epoch 8/10, Train Loss: 0.0359, Accuracy: 0.905, F1 Micro: 0.905, F1 Macro: 0.8804\n",
      "Epoch 9/10, Train Loss: 0.0306, Accuracy: 0.8987, F1 Micro: 0.8987, F1 Macro: 0.8697\n",
      "Epoch 10/10, Train Loss: 0.0238, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8732\n",
      "\n",
      "Sentiment analysis accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.881\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       787\n",
      "    positive       0.94      0.74      0.82       329\n",
      "\n",
      "    accuracy                           0.91      1116\n",
      "   macro avg       0.92      0.86      0.88      1116\n",
      "weighted avg       0.91      0.91      0.90      1116\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2097: Accuracy: 0.9595, F1 Micro: 0.9595, F1 Macro: 0.8721\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.92      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.84        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.14      0.20         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.84      0.76      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.71      0.63      0.66       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.88      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.86      0.96      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.88      0.86       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.78      0.32      0.45        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.85      0.72      0.75       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.87      0.86        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.90      0.97      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.62      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 363.38609433174133 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.0019451936008408667\n",
      "Acquired samples: 50\n",
      "Sampling duration: 7.061577081680298 seconds\n",
      "New train size: 2147\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4335, Accuracy: 0.8905, F1 Micro: 0.935, F1 Macro: 0.9304\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2574, Accuracy: 0.942, F1 Micro: 0.9645, F1 Macro: 0.9623\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.182, Accuracy: 0.9495, F1 Micro: 0.969, F1 Macro: 0.9667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.148, Accuracy: 0.9517, F1 Micro: 0.9704, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1217, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0979, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0848, Accuracy: 0.9646, F1 Micro: 0.9781, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0684, Accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9768\n",
      "Epoch 9/10, Train Loss: 0.0574, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9763\n",
      "Epoch 10/10, Train Loss: 0.0476, Accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9768\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.92      0.96      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3464, Accuracy: 0.8719, F1 Micro: 0.8719, F1 Macro: 0.838\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1852, Accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.8928\n",
      "Epoch 3/10, Train Loss: 0.1364, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.8884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0831, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.8958\n",
      "Epoch 5/10, Train Loss: 0.0572, Accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.8914\n",
      "Epoch 6/10, Train Loss: 0.062, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.8963\n",
      "Epoch 7/10, Train Loss: 0.0458, Accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.8919\n",
      "Epoch 8/10, Train Loss: 0.0276, Accuracy: 0.9152, F1 Micro: 0.9152, F1 Macro: 0.892\n",
      "Epoch 9/10, Train Loss: 0.0234, Accuracy: 0.9171, F1 Micro: 0.9171, F1 Macro: 0.8927\n",
      "Epoch 10/10, Train Loss: 0.028, Accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.8926\n",
      "\n",
      "Sentiment analysis accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.8958\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.94       772\n",
      "    positive       0.93      0.78      0.85       313\n",
      "\n",
      "    accuracy                           0.92      1085\n",
      "   macro avg       0.92      0.88      0.90      1085\n",
      "weighted avg       0.92      0.92      0.92      1085\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2147: Accuracy: 0.9595, F1 Micro: 0.9595, F1 Macro: 0.8767\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.82      0.75      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.76      0.62      0.66       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.85      0.89       200\n",
      "     neutral       0.92      0.96      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.84      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.79      0.50      0.61        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.77      0.81       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.48      0.60        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.82      0.76        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.77      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 365.28723216056824 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.0019338001962751151\n",
      "Acquired samples: 50\n",
      "Sampling duration: 5.381765365600586 seconds\n",
      "New train size: 2197\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4292, Accuracy: 0.8941, F1 Micro: 0.9369, F1 Macro: 0.932\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2523, Accuracy: 0.9434, F1 Micro: 0.9654, F1 Macro: 0.9634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1772, Accuracy: 0.9516, F1 Micro: 0.9702, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1481, Accuracy: 0.9587, F1 Micro: 0.9745, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1174, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0993, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0804, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9761\n",
      "Epoch 8/10, Train Loss: 0.0651, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9756\n",
      "Epoch 9/10, Train Loss: 0.0556, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0474, Accuracy: 0.9668, F1 Micro: 0.9794, F1 Macro: 0.9773\n",
      "\n",
      "Aspect detection accuracy: 0.9668, F1 Micro: 0.9794, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3619, Accuracy: 0.8679, F1 Micro: 0.8679, F1 Macro: 0.8268\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.215, Accuracy: 0.9053, F1 Micro: 0.9053, F1 Macro: 0.8787\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1378, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8815\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.097, Accuracy: 0.9162, F1 Micro: 0.9162, F1 Macro: 0.8913\n",
      "Epoch 5/10, Train Loss: 0.0645, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.8888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0614, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.8942\n",
      "Epoch 7/10, Train Loss: 0.0383, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.8896\n",
      "Epoch 8/10, Train Loss: 0.034, Accuracy: 0.9153, F1 Micro: 0.9153, F1 Macro: 0.8879\n",
      "Epoch 9/10, Train Loss: 0.0278, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8863\n",
      "Epoch 10/10, Train Loss: 0.0242, Accuracy: 0.9162, F1 Micro: 0.9162, F1 Macro: 0.8895\n",
      "\n",
      "Sentiment analysis accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.8942\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       785\n",
      "    positive       0.94      0.76      0.84       313\n",
      "\n",
      "    accuracy                           0.92      1098\n",
      "   macro avg       0.93      0.87      0.89      1098\n",
      "weighted avg       0.92      0.92      0.92      1098\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2197: Accuracy: 0.9613, F1 Micro: 0.9613, F1 Macro: 0.8894\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.82      0.80      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.79      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.29      0.40         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.82      0.66      0.71       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.79      0.50      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.87      0.78      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.94      0.96      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.83      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 392.5878393650055 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.0013162630842998625\n",
      "Acquired samples: 50\n",
      "Sampling duration: 3.8023438453674316 seconds\n",
      "New train size: 2247\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4345, Accuracy: 0.891, F1 Micro: 0.9351, F1 Macro: 0.9299\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2507, Accuracy: 0.945, F1 Micro: 0.9663, F1 Macro: 0.9642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1837, Accuracy: 0.9491, F1 Micro: 0.9689, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.144, Accuracy: 0.9587, F1 Micro: 0.9745, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1159, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9751\n",
      "Epoch 6/10, Train Loss: 0.0971, Accuracy: 0.9622, F1 Micro: 0.9766, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0766, Accuracy: 0.9663, F1 Micro: 0.979, F1 Macro: 0.977\n",
      "Epoch 8/10, Train Loss: 0.0642, Accuracy: 0.962, F1 Micro: 0.9765, F1 Macro: 0.9747\n",
      "Epoch 9/10, Train Loss: 0.058, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9752\n",
      "Epoch 10/10, Train Loss: 0.047, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "\n",
      "Aspect detection accuracy: 0.9663, F1 Micro: 0.979, F1 Macro: 0.977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.98       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.96      0.92      0.94       317\n",
      "       linen       0.95      0.96      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.98      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.98      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.38, Accuracy: 0.8697, F1 Micro: 0.8697, F1 Macro: 0.8374\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2094, Accuracy: 0.903, F1 Micro: 0.903, F1 Macro: 0.876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1447, Accuracy: 0.903, F1 Micro: 0.903, F1 Macro: 0.8744\n",
      "Epoch 4/10, Train Loss: 0.1127, Accuracy: 0.8958, F1 Micro: 0.8958, F1 Macro: 0.8613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0925, Accuracy: 0.9075, F1 Micro: 0.9075, F1 Macro: 0.8801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0643, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8837\n",
      "Epoch 7/10, Train Loss: 0.0497, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8803\n",
      "Epoch 8/10, Train Loss: 0.043, Accuracy: 0.9075, F1 Micro: 0.9075, F1 Macro: 0.879\n",
      "Epoch 9/10, Train Loss: 0.0299, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.8777\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0222, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8829\n",
      "\n",
      "Sentiment analysis accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8829\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       793\n",
      "    positive       0.95      0.73      0.83       320\n",
      "\n",
      "    accuracy                           0.91      1113\n",
      "   macro avg       0.92      0.86      0.88      1113\n",
      "weighted avg       0.91      0.91      0.91      1113\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2247: Accuracy: 0.9602, F1 Micro: 0.9602, F1 Macro: 0.8657\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.85        78\n",
      "     neutral       0.98      0.97      0.98       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.94      0.88       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.83      0.65      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.54      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.92      0.91       200\n",
      "     neutral       0.96      0.92      0.94       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.88      0.87       162\n",
      "     neutral       0.95      0.96      0.95       387\n",
      "    positive       0.75      0.41      0.53        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.85      0.75      0.78       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87        85\n",
      "     neutral       0.97      0.99      0.98       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.66      0.73        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 380.836797952652 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.002020435128360987\n",
      "Acquired samples: 36\n",
      "Sampling duration: 2.148585796356201 seconds\n",
      "New train size: 2283\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4293, Accuracy: 0.8939, F1 Micro: 0.9366, F1 Macro: 0.9305\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2486, Accuracy: 0.945, F1 Micro: 0.9663, F1 Macro: 0.964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1745, Accuracy: 0.9521, F1 Micro: 0.9705, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1396, Accuracy: 0.9571, F1 Micro: 0.9735, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1162, Accuracy: 0.958, F1 Micro: 0.9741, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0979, Accuracy: 0.962, F1 Micro: 0.9765, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0807, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0663, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0559, Accuracy: 0.9661, F1 Micro: 0.979, F1 Macro: 0.9769\n",
      "Epoch 10/10, Train Loss: 0.046, Accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.9661, F1 Micro: 0.979, F1 Macro: 0.9769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.98      0.98      0.98       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3285, Accuracy: 0.8645, F1 Micro: 0.8645, F1 Macro: 0.8146\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1843, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.8861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1341, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.8869\n",
      "Epoch 4/10, Train Loss: 0.0846, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.8868\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0712, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8916\n",
      "Epoch 6/10, Train Loss: 0.0504, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.889\n",
      "Epoch 7/10, Train Loss: 0.0378, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.89\n",
      "Epoch 8/10, Train Loss: 0.0289, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8816\n",
      "Epoch 9/10, Train Loss: 0.0333, Accuracy: 0.9155, F1 Micro: 0.9155, F1 Macro: 0.8898\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0176, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8911\n",
      "\n",
      "Sentiment analysis accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8911\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       784\n",
      "    positive       0.94      0.76      0.84       316\n",
      "\n",
      "    accuracy                           0.92      1100\n",
      "   macro avg       0.92      0.87      0.89      1100\n",
      "weighted avg       0.92      0.92      0.91      1100\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2283: Accuracy: 0.9602, F1 Micro: 0.9602, F1 Macro: 0.8671\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        78\n",
      "     neutral       0.98      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.57      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.80      0.36      0.50        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.73      0.77       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.90      0.97      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.92      0.94      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.69      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 394.0883529186249 s\n",
      "Total runtime: 8340.565621376038 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1af26ae",
   "metadata": {
    "papermill": {
     "duration": 0.188871,
     "end_time": "2025-03-31T06:55:46.631461",
     "exception": false,
     "start_time": "2025-03-31T06:55:46.442590",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba48b582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 5\n",
      "Random seed: 94\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ed4707d28b4473b1c5593c20e4195a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6222, Accuracy: 0.7984, F1 Micro: 0.8875, F1 Macro: 0.8819\n",
      "Epoch 2/10, Train Loss: 0.4944, Accuracy: 0.7981, F1 Micro: 0.8873, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4566, Accuracy: 0.7997, F1 Micro: 0.8881, F1 Macro: 0.8821\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4288, Accuracy: 0.8017, F1 Micro: 0.8893, F1 Macro: 0.8836\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4243, Accuracy: 0.804, F1 Micro: 0.8907, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4161, Accuracy: 0.8135, F1 Micro: 0.8944, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4005, Accuracy: 0.8179, F1 Micro: 0.8965, F1 Macro: 0.8903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3794, Accuracy: 0.8247, F1 Micro: 0.9001, F1 Macro: 0.8939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3213, Accuracy: 0.8417, F1 Micro: 0.9083, F1 Macro: 0.9019\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3264, Accuracy: 0.8519, F1 Micro: 0.9131, F1 Macro: 0.9062\n",
      "\n",
      "Aspect detection accuracy: 0.8519, F1 Micro: 0.9131, F1 Macro: 0.9062\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.88      1.00      0.94       462\n",
      "   air_panas       0.83      1.00      0.91       480\n",
      "         bau       0.87      0.98      0.92       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.78      0.78      0.78       317\n",
      "       linen       0.79      0.92      0.85       392\n",
      "     service       0.87      0.96      0.91       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.90      1.00      0.95       516\n",
      "        wifi       0.86      1.00      0.93       498\n",
      "\n",
      "   micro avg       0.86      0.97      0.91      4614\n",
      "   macro avg       0.86      0.96      0.91      4614\n",
      "weighted avg       0.86      0.97      0.91      4614\n",
      " samples avg       0.86      0.97      0.91      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5506, Accuracy: 0.6036, F1 Micro: 0.6036, F1 Macro: 0.3764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4796, Accuracy: 0.6036, F1 Micro: 0.6036, F1 Macro: 0.3764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4879, Accuracy: 0.6036, F1 Micro: 0.6036, F1 Macro: 0.3764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4287, Accuracy: 0.6036, F1 Micro: 0.6036, F1 Macro: 0.3764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3515, Accuracy: 0.6036, F1 Micro: 0.6036, F1 Macro: 0.3849\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3279, Accuracy: 0.7, F1 Micro: 0.7, F1 Macro: 0.6242\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2793, Accuracy: 0.7073, F1 Micro: 0.7073, F1 Macro: 0.6432\n",
      "Epoch 8/10, Train Loss: 0.202, Accuracy: 0.6873, F1 Micro: 0.6873, F1 Macro: 0.6008\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2003, Accuracy: 0.7309, F1 Micro: 0.7309, F1 Macro: 0.6829\n",
      "Epoch 10/10, Train Loss: 0.1315, Accuracy: 0.7109, F1 Micro: 0.7109, F1 Macro: 0.649\n",
      "\n",
      "Sentiment analysis accuracy: 0.7309, F1 Micro: 0.7309, F1 Macro: 0.6829\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.93      0.81       332\n",
      "    positive       0.80      0.43      0.56       218\n",
      "\n",
      "    accuracy                           0.73       550\n",
      "   macro avg       0.75      0.68      0.68       550\n",
      "weighted avg       0.75      0.73      0.71       550\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 142: Accuracy: 0.8433, F1 Micro: 0.8433, F1 Macro: 0.4292\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.46      0.61        97\n",
      "     neutral       0.88      1.00      0.94       459\n",
      "    positive       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.59      0.49      0.51       571\n",
      "weighted avg       0.86      0.88      0.86       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        86\n",
      "     neutral       0.83      1.00      0.91       475\n",
      "    positive       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.28      0.33      0.30       571\n",
      "weighted avg       0.69      0.83      0.76       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.35      0.08      0.13        78\n",
      "     neutral       0.87      0.98      0.92       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.41      0.35      0.35       571\n",
      "weighted avg       0.79      0.85      0.81       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.69      0.71       200\n",
      "     neutral       0.78      0.77      0.78       315\n",
      "    positive       0.39      0.46      0.42        56\n",
      "\n",
      "    accuracy                           0.71       571\n",
      "   macro avg       0.63      0.64      0.64       571\n",
      "weighted avg       0.72      0.71      0.72       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.48      0.56       162\n",
      "     neutral       0.78      0.92      0.85       387\n",
      "    positive       0.50      0.09      0.15        22\n",
      "\n",
      "    accuracy                           0.76       571\n",
      "   macro avg       0.66      0.50      0.52       571\n",
      "weighted avg       0.75      0.76      0.74       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.49      0.57        85\n",
      "     neutral       0.87      0.96      0.91       418\n",
      "    positive       0.83      0.56      0.67        68\n",
      "\n",
      "    accuracy                           0.84       571\n",
      "   macro avg       0.79      0.67      0.72       571\n",
      "weighted avg       0.83      0.84      0.83       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.89      1.00      0.94       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.30      0.33      0.31       571\n",
      "weighted avg       0.80      0.89      0.85       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        74\n",
      "     neutral       0.87      1.00      0.93       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.80       571\n",
      "\n",
      "Total train time: 89.86634707450867 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.007094677537679672\n",
      "Acquired samples: 215\n",
      "Sampling duration: 51.79585289955139 seconds\n",
      "New train size: 357\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6002, Accuracy: 0.7967, F1 Micro: 0.881, F1 Macro: 0.8397\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.537, Accuracy: 0.8132, F1 Micro: 0.8919, F1 Macro: 0.8749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5149, Accuracy: 0.8236, F1 Micro: 0.8993, F1 Macro: 0.8929\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4569, Accuracy: 0.8372, F1 Micro: 0.9059, F1 Macro: 0.8984\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4382, Accuracy: 0.8545, F1 Micro: 0.9145, F1 Macro: 0.907\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3739, Accuracy: 0.8661, F1 Micro: 0.9211, F1 Macro: 0.9151\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3296, Accuracy: 0.8925, F1 Micro: 0.9361, F1 Macro: 0.9311\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2898, Accuracy: 0.9076, F1 Micro: 0.9444, F1 Macro: 0.9399\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2539, Accuracy: 0.9184, F1 Micro: 0.9505, F1 Macro: 0.9461\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2171, Accuracy: 0.9222, F1 Micro: 0.9523, F1 Macro: 0.947\n",
      "\n",
      "Aspect detection accuracy: 0.9222, F1 Micro: 0.9523, F1 Macro: 0.947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.97      0.99      0.98       462\n",
      "   air_panas       0.92      0.99      0.95       480\n",
      "         bau       0.94      0.97      0.96       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.92      0.78      0.85       317\n",
      "       linen       0.86      0.95      0.91       392\n",
      "     service       0.95      0.94      0.95       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.97      1.00      0.98       516\n",
      "        wifi       0.97      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.94      0.97      0.95      4614\n",
      "   macro avg       0.94      0.96      0.95      4614\n",
      "weighted avg       0.94      0.97      0.95      4614\n",
      " samples avg       0.94      0.97      0.95      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6189, Accuracy: 0.7631, F1 Micro: 0.7631, F1 Macro: 0.696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4266, Accuracy: 0.799, F1 Micro: 0.799, F1 Macro: 0.7357\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3739, Accuracy: 0.8185, F1 Micro: 0.8185, F1 Macro: 0.7659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3222, Accuracy: 0.8308, F1 Micro: 0.8308, F1 Macro: 0.7829\n",
      "Epoch 5/10, Train Loss: 0.2309, Accuracy: 0.8031, F1 Micro: 0.8031, F1 Macro: 0.7252\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2208, Accuracy: 0.8369, F1 Micro: 0.8369, F1 Macro: 0.7971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1537, Accuracy: 0.841, F1 Micro: 0.841, F1 Macro: 0.8004\n",
      "Epoch 8/10, Train Loss: 0.1076, Accuracy: 0.8062, F1 Micro: 0.8062, F1 Macro: 0.7315\n",
      "Epoch 9/10, Train Loss: 0.1142, Accuracy: 0.8379, F1 Micro: 0.8379, F1 Macro: 0.7928\n",
      "Epoch 10/10, Train Loss: 0.119, Accuracy: 0.8297, F1 Micro: 0.8297, F1 Macro: 0.7762\n",
      "\n",
      "Sentiment analysis accuracy: 0.841, F1 Micro: 0.841, F1 Macro: 0.8004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.95      0.89       661\n",
      "    positive       0.86      0.61      0.71       314\n",
      "\n",
      "    accuracy                           0.84       975\n",
      "   macro avg       0.85      0.78      0.80       975\n",
      "weighted avg       0.84      0.84      0.83       975\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 357: Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.7419\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.85      0.90        97\n",
      "     neutral       0.98      0.99      0.98       459\n",
      "    positive       0.74      0.93      0.82        15\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.89      0.92      0.90       571\n",
      "weighted avg       0.97      0.96      0.96       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.56      0.68        86\n",
      "     neutral       0.92      0.99      0.95       475\n",
      "    positive       0.40      0.20      0.27        10\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.73      0.58      0.63       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.65      0.70        78\n",
      "     neutral       0.94      0.97      0.95       491\n",
      "    positive       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.74      0.71      0.72       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.86      0.80       200\n",
      "     neutral       0.92      0.78      0.85       315\n",
      "    positive       0.68      0.91      0.78        56\n",
      "\n",
      "    accuracy                           0.82       571\n",
      "   macro avg       0.78      0.85      0.81       571\n",
      "weighted avg       0.84      0.82      0.82       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.68      0.75       162\n",
      "     neutral       0.86      0.96      0.91       387\n",
      "    positive       0.75      0.27      0.40        22\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.81      0.64      0.68       571\n",
      "weighted avg       0.85      0.85      0.84       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.71      0.77        85\n",
      "     neutral       0.95      0.94      0.95       418\n",
      "    positive       0.72      0.90      0.80        68\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.84      0.85      0.84       571\n",
      "weighted avg       0.91      0.90      0.90       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.28      0.41        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.72      0.76      0.74        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.83      0.68      0.71       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.72      0.82        54\n",
      "     neutral       0.97      1.00      0.98       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.97      0.85      0.90       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.81      0.88        74\n",
      "     neutral       0.97      1.00      0.98       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.94      0.91       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Total train time: 134.57021617889404 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.010502824187278747\n",
      "Acquired samples: 193\n",
      "Sampling duration: 56.83982801437378 seconds\n",
      "New train size: 550\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5421, Accuracy: 0.8007, F1 Micro: 0.8893, F1 Macro: 0.8848\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4652, Accuracy: 0.8161, F1 Micro: 0.8958, F1 Macro: 0.8893\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4174, Accuracy: 0.8578, F1 Micro: 0.9174, F1 Macro: 0.9123\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3441, Accuracy: 0.875, F1 Micro: 0.9257, F1 Macro: 0.9188\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2892, Accuracy: 0.8962, F1 Micro: 0.9377, F1 Macro: 0.9327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2369, Accuracy: 0.9113, F1 Micro: 0.9465, F1 Macro: 0.9425\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2084, Accuracy: 0.9198, F1 Micro: 0.9515, F1 Macro: 0.9488\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.188, Accuracy: 0.9299, F1 Micro: 0.9574, F1 Macro: 0.9542\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1538, Accuracy: 0.9359, F1 Micro: 0.9609, F1 Macro: 0.9579\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1367, Accuracy: 0.938, F1 Micro: 0.9621, F1 Macro: 0.9588\n",
      "\n",
      "Aspect detection accuracy: 0.938, F1 Micro: 0.9621, F1 Macro: 0.9588\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.91      1.00      0.95       480\n",
      "         bau       0.94      0.99      0.96       496\n",
      "     general       0.92      0.99      0.95       500\n",
      "  kebersihan       0.87      0.92      0.89       317\n",
      "       linen       0.87      0.96      0.92       392\n",
      "     service       0.94      0.97      0.96       423\n",
      "sunrise_meal       0.97      0.99      0.98       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.99      0.99      0.99       498\n",
      "\n",
      "   micro avg       0.94      0.98      0.96      4614\n",
      "   macro avg       0.94      0.98      0.96      4614\n",
      "weighted avg       0.94      0.98      0.96      4614\n",
      " samples avg       0.94      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5654, Accuracy: 0.8162, F1 Micro: 0.8162, F1 Macro: 0.7395\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3696, Accuracy: 0.8536, F1 Micro: 0.8536, F1 Macro: 0.8011\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2639, Accuracy: 0.8654, F1 Micro: 0.8654, F1 Macro: 0.8195\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2045, Accuracy: 0.8729, F1 Micro: 0.8729, F1 Macro: 0.8321\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1504, Accuracy: 0.8857, F1 Micro: 0.8857, F1 Macro: 0.8515\n",
      "Epoch 6/10, Train Loss: 0.1437, Accuracy: 0.8814, F1 Micro: 0.8814, F1 Macro: 0.8407\n",
      "Epoch 7/10, Train Loss: 0.0996, Accuracy: 0.8835, F1 Micro: 0.8835, F1 Macro: 0.8445\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0537, Accuracy: 0.8868, F1 Micro: 0.8868, F1 Macro: 0.8486\n",
      "Epoch 9/10, Train Loss: 0.062, Accuracy: 0.8729, F1 Micro: 0.8729, F1 Macro: 0.8251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.054, Accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8751\n",
      "\n",
      "Sentiment analysis accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8751\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93       661\n",
      "    positive       0.90      0.75      0.82       275\n",
      "\n",
      "    accuracy                           0.90       936\n",
      "   macro avg       0.90      0.86      0.88       936\n",
      "weighted avg       0.90      0.90      0.90       936\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 550: Accuracy: 0.9315, F1 Micro: 0.9315, F1 Macro: 0.7873\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.90      0.93        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.71      1.00      0.83        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.96      0.92       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.51      0.67        86\n",
      "     neutral       0.91      1.00      0.95       475\n",
      "    positive       0.67      0.20      0.31        10\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.84      0.57      0.64       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.62      0.72        78\n",
      "     neutral       0.94      0.99      0.96       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.94      0.70      0.78       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.92      0.99      0.95       496\n",
      "    positive       0.86      0.44      0.58        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.59      0.48      0.51       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.80      0.84       200\n",
      "     neutral       0.87      0.92      0.89       315\n",
      "    positive       0.84      0.82      0.83        56\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.86      0.85      0.85       571\n",
      "weighted avg       0.87      0.87      0.87       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.70      0.78       162\n",
      "     neutral       0.87      0.96      0.92       387\n",
      "    positive       0.67      0.36      0.47        22\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.80      0.68      0.72       571\n",
      "weighted avg       0.86      0.87      0.86       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.73      0.80        85\n",
      "     neutral       0.94      0.97      0.96       418\n",
      "    positive       0.88      0.90      0.89        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.90      0.87      0.88       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.31      0.44        29\n",
      "     neutral       0.97      0.99      0.98       525\n",
      "    positive       0.67      0.82      0.74        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.80      0.71      0.72       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.83      0.89        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       0.75      1.00      0.86         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.94      0.91       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.93      0.94        74\n",
      "     neutral       0.99      0.99      0.99       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.97      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 157.83175539970398 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.007164334133267403\n",
      "Acquired samples: 174\n",
      "Sampling duration: 58.106494665145874 seconds\n",
      "New train size: 724\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5359, Accuracy: 0.8023, F1 Micro: 0.8852, F1 Macro: 0.8571\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.445, Accuracy: 0.8293, F1 Micro: 0.9016, F1 Macro: 0.8926\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3924, Accuracy: 0.8776, F1 Micro: 0.9272, F1 Macro: 0.9215\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3213, Accuracy: 0.9106, F1 Micro: 0.9462, F1 Macro: 0.9416\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2487, Accuracy: 0.9297, F1 Micro: 0.9573, F1 Macro: 0.9537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2044, Accuracy: 0.938, F1 Micro: 0.9621, F1 Macro: 0.9591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1854, Accuracy: 0.9406, F1 Micro: 0.9638, F1 Macro: 0.9612\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1593, Accuracy: 0.9434, F1 Micro: 0.9654, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1399, Accuracy: 0.9458, F1 Micro: 0.9669, F1 Macro: 0.9645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1246, Accuracy: 0.9509, F1 Micro: 0.9698, F1 Macro: 0.9671\n",
      "\n",
      "Aspect detection accuracy: 0.9509, F1 Micro: 0.9698, F1 Macro: 0.9671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.96      1.00      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.92      0.99      0.95       500\n",
      "  kebersihan       0.88      0.94      0.91       317\n",
      "       linen       0.89      0.97      0.93       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.95      0.99      0.97      4614\n",
      "   macro avg       0.95      0.98      0.97      4614\n",
      "weighted avg       0.96      0.99      0.97      4614\n",
      " samples avg       0.95      0.99      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4906, Accuracy: 0.8193, F1 Micro: 0.8193, F1 Macro: 0.7176\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3149, Accuracy: 0.869, F1 Micro: 0.869, F1 Macro: 0.8211\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2267, Accuracy: 0.8832, F1 Micro: 0.8832, F1 Macro: 0.8473\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.194, Accuracy: 0.8954, F1 Micro: 0.8954, F1 Macro: 0.8607\n",
      "Epoch 5/10, Train Loss: 0.1409, Accuracy: 0.8904, F1 Micro: 0.8904, F1 Macro: 0.8478\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0948, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0723, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0592, Accuracy: 0.9086, F1 Micro: 0.9086, F1 Macro: 0.8794\n",
      "Epoch 9/10, Train Loss: 0.0594, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8666\n",
      "Epoch 10/10, Train Loss: 0.0414, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8709\n",
      "\n",
      "Sentiment analysis accuracy: 0.9086, F1 Micro: 0.9086, F1 Macro: 0.8794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       711\n",
      "    positive       0.91      0.75      0.82       274\n",
      "\n",
      "    accuracy                           0.91       985\n",
      "   macro avg       0.91      0.86      0.88       985\n",
      "weighted avg       0.91      0.91      0.91       985\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 724: Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.8217\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.91      0.93        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.81      0.87      0.84        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.79      0.86        86\n",
      "     neutral       0.96      1.00      0.98       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.85      0.73      0.78       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.77      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.92      0.99      0.95       496\n",
      "    positive       0.91      0.44      0.59        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.61      0.48      0.52       571\n",
      "weighted avg       0.90      0.92      0.90       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.79      0.84       200\n",
      "     neutral       0.88      0.94      0.91       315\n",
      "    positive       0.84      0.91      0.87        56\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.87      0.88      0.87       571\n",
      "weighted avg       0.89      0.88      0.88       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.73      0.79       162\n",
      "     neutral       0.89      0.97      0.93       387\n",
      "    positive       0.47      0.32      0.38        22\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.74      0.67      0.70       571\n",
      "weighted avg       0.87      0.87      0.87       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.78      0.84        85\n",
      "     neutral       0.96      0.99      0.97       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.90      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.91      0.92        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.97      0.91      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.90      0.97      0.93       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 174.30433201789856 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.005500901676714422\n",
      "Acquired samples: 156\n",
      "Sampling duration: 55.63730263710022 seconds\n",
      "New train size: 880\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.514, Accuracy: 0.8062, F1 Micro: 0.8901, F1 Macro: 0.88\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4217, Accuracy: 0.8618, F1 Micro: 0.9188, F1 Macro: 0.9119\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3358, Accuracy: 0.8941, F1 Micro: 0.9369, F1 Macro: 0.9321\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2553, Accuracy: 0.926, F1 Micro: 0.9551, F1 Macro: 0.9515\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2091, Accuracy: 0.9375, F1 Micro: 0.962, F1 Macro: 0.9591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1788, Accuracy: 0.9413, F1 Micro: 0.9642, F1 Macro: 0.9613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1482, Accuracy: 0.9526, F1 Micro: 0.9707, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1296, Accuracy: 0.9542, F1 Micro: 0.9718, F1 Macro: 0.9691\n",
      "Epoch 9/10, Train Loss: 0.1125, Accuracy: 0.954, F1 Micro: 0.9717, F1 Macro: 0.9687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1004, Accuracy: 0.9575, F1 Micro: 0.9737, F1 Macro: 0.9709\n",
      "\n",
      "Aspect detection accuracy: 0.9575, F1 Micro: 0.9737, F1 Macro: 0.9709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.92      0.92      0.92       317\n",
      "       linen       0.90      0.97      0.93       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4677, Accuracy: 0.8243, F1 Micro: 0.8243, F1 Macro: 0.7602\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2725, Accuracy: 0.8577, F1 Micro: 0.8577, F1 Macro: 0.824\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1845, Accuracy: 0.8921, F1 Micro: 0.8921, F1 Macro: 0.8571\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1604, Accuracy: 0.9007, F1 Micro: 0.9007, F1 Macro: 0.8709\n",
      "Epoch 5/10, Train Loss: 0.1251, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0774, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.875\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.062, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.877\n",
      "Epoch 8/10, Train Loss: 0.0527, Accuracy: 0.8978, F1 Micro: 0.8978, F1 Macro: 0.8706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0696, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8766\n",
      "Epoch 10/10, Train Loss: 0.027, Accuracy: 0.9016, F1 Micro: 0.9016, F1 Macro: 0.8701\n",
      "\n",
      "Sentiment analysis accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       742\n",
      "    positive       0.94      0.72      0.82       305\n",
      "\n",
      "    accuracy                           0.91      1047\n",
      "   macro avg       0.92      0.85      0.88      1047\n",
      "weighted avg       0.91      0.91      0.90      1047\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 880: Accuracy: 0.9503, F1 Micro: 0.9503, F1 Macro: 0.8319\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.80      0.80      0.80        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.84      0.88        86\n",
      "     neutral       0.97      1.00      0.98       475\n",
      "    positive       0.75      0.30      0.43        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.88      0.71      0.76       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.74      0.79        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.74      0.81       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.87       200\n",
      "     neutral       0.91      0.92      0.92       315\n",
      "    positive       0.83      0.89      0.86        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.88      0.89      0.88       571\n",
      "weighted avg       0.90      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.78      0.82       162\n",
      "     neutral       0.90      0.97      0.93       387\n",
      "    positive       0.69      0.41      0.51        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.82      0.72      0.76       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.81      0.85        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.66      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.85      0.65      0.73        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.77      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.94      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.96      0.97        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 192.3501899242401 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.006325059290975332\n",
      "Acquired samples: 141\n",
      "Sampling duration: 50.62042260169983 seconds\n",
      "New train size: 1021\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5135, Accuracy: 0.8024, F1 Micro: 0.8901, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4165, Accuracy: 0.8611, F1 Micro: 0.918, F1 Macro: 0.9078\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3109, Accuracy: 0.9141, F1 Micro: 0.9481, F1 Macro: 0.9427\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2385, Accuracy: 0.9366, F1 Micro: 0.9613, F1 Macro: 0.958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1908, Accuracy: 0.946, F1 Micro: 0.967, F1 Macro: 0.9645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1637, Accuracy: 0.9493, F1 Micro: 0.9688, F1 Macro: 0.9656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1439, Accuracy: 0.9542, F1 Micro: 0.9718, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1194, Accuracy: 0.9568, F1 Micro: 0.9733, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.104, Accuracy: 0.9571, F1 Micro: 0.9736, F1 Macro: 0.9711\n",
      "Epoch 10/10, Train Loss: 0.0901, Accuracy: 0.9563, F1 Micro: 0.973, F1 Macro: 0.9699\n",
      "\n",
      "Aspect detection accuracy: 0.9571, F1 Micro: 0.9736, F1 Macro: 0.9711\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.98       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.95      0.98      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.91      0.94      0.93       317\n",
      "       linen       0.89      0.98      0.93       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.99      0.97      4614\n",
      " samples avg       0.96      0.99      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4351, Accuracy: 0.8574, F1 Micro: 0.8574, F1 Macro: 0.8032\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2803, Accuracy: 0.8712, F1 Micro: 0.8712, F1 Macro: 0.8256\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1962, Accuracy: 0.883, F1 Micro: 0.883, F1 Macro: 0.8375\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1445, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1055, Accuracy: 0.9086, F1 Micro: 0.9086, F1 Macro: 0.8812\n",
      "Epoch 6/10, Train Loss: 0.0859, Accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0866, Accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.8904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0399, Accuracy: 0.9184, F1 Micro: 0.9184, F1 Macro: 0.8937\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0392, Accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.8943\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0387, Accuracy: 0.9223, F1 Micro: 0.9223, F1 Macro: 0.8983\n",
      "\n",
      "Sentiment analysis accuracy: 0.9223, F1 Micro: 0.9223, F1 Macro: 0.8983\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       729\n",
      "    positive       0.94      0.77      0.85       288\n",
      "\n",
      "    accuracy                           0.92      1017\n",
      "   macro avg       0.93      0.88      0.90      1017\n",
      "weighted avg       0.92      0.92      0.92      1017\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1021: Accuracy: 0.9515, F1 Micro: 0.9515, F1 Macro: 0.8413\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.90      0.93        97\n",
      "     neutral       0.98      0.99      0.98       459\n",
      "    positive       0.86      0.80      0.83        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.93      0.90      0.91       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.87      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.76      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.71      0.77        78\n",
      "     neutral       0.95      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.73      0.80       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.88      0.68      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.55      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.83      0.87       200\n",
      "     neutral       0.91      0.94      0.93       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.91      0.90       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.75      0.82       162\n",
      "     neutral       0.89      0.98      0.93       387\n",
      "    positive       0.71      0.45      0.56        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.84      0.73      0.77       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.94      0.90      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.62      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.79      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.97      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.96      0.96        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.87      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 212.84762024879456 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.004996964801102876\n",
      "Acquired samples: 127\n",
      "Sampling duration: 46.214025020599365 seconds\n",
      "New train size: 1148\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5084, Accuracy: 0.8083, F1 Micro: 0.8918, F1 Macro: 0.8839\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.403, Accuracy: 0.8813, F1 Micro: 0.9292, F1 Macro: 0.9219\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.299, Accuracy: 0.9227, F1 Micro: 0.9533, F1 Macro: 0.95\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2225, Accuracy: 0.9451, F1 Micro: 0.9664, F1 Macro: 0.9635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1803, Accuracy: 0.9545, F1 Micro: 0.9719, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.15, Accuracy: 0.9568, F1 Micro: 0.9733, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1254, Accuracy: 0.9569, F1 Micro: 0.9735, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1111, Accuracy: 0.9589, F1 Micro: 0.9746, F1 Macro: 0.9719\n",
      "Epoch 9/10, Train Loss: 0.0924, Accuracy: 0.959, F1 Micro: 0.9746, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0855, Accuracy: 0.9594, F1 Micro: 0.9748, F1 Macro: 0.9718\n",
      "\n",
      "Aspect detection accuracy: 0.9594, F1 Micro: 0.9748, F1 Macro: 0.9718\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.92      0.91      0.92       317\n",
      "       linen       0.93      0.95      0.94       392\n",
      "     service       0.96      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4444, Accuracy: 0.8295, F1 Micro: 0.8295, F1 Macro: 0.7627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2423, Accuracy: 0.8653, F1 Micro: 0.8653, F1 Macro: 0.8207\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1935, Accuracy: 0.8891, F1 Micro: 0.8891, F1 Macro: 0.8584\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1095, Accuracy: 0.8891, F1 Micro: 0.8891, F1 Macro: 0.8596\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.102, Accuracy: 0.8918, F1 Micro: 0.8918, F1 Macro: 0.8641\n",
      "Epoch 6/10, Train Loss: 0.0825, Accuracy: 0.8909, F1 Micro: 0.8909, F1 Macro: 0.8595\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0518, Accuracy: 0.8973, F1 Micro: 0.8973, F1 Macro: 0.8693\n",
      "Epoch 8/10, Train Loss: 0.0561, Accuracy: 0.8937, F1 Micro: 0.8937, F1 Macro: 0.8672\n",
      "Epoch 9/10, Train Loss: 0.0343, Accuracy: 0.8946, F1 Micro: 0.8946, F1 Macro: 0.8639\n",
      "Epoch 10/10, Train Loss: 0.0317, Accuracy: 0.8882, F1 Micro: 0.8882, F1 Macro: 0.8535\n",
      "\n",
      "Sentiment analysis accuracy: 0.8973, F1 Micro: 0.8973, F1 Macro: 0.8693\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93       763\n",
      "    positive       0.92      0.72      0.81       328\n",
      "\n",
      "    accuracy                           0.90      1091\n",
      "   macro avg       0.90      0.85      0.87      1091\n",
      "weighted avg       0.90      0.90      0.89      1091\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1148: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.8515\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.75      1.00      0.86        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.97      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.79      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.82      0.92      0.86       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86       200\n",
      "     neutral       0.92      0.91      0.92       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.91      0.90       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.81      0.84       162\n",
      "     neutral       0.93      0.95      0.94       387\n",
      "    positive       0.55      0.50      0.52        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.78      0.76      0.77       571\n",
      "weighted avg       0.89      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.84      0.84        85\n",
      "     neutral       0.96      0.97      0.97       418\n",
      "    positive       0.92      0.90      0.91        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.90      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.72      0.76      0.74        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.78      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.96      0.97        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 224.58983063697815 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0034005235647782683\n",
      "Acquired samples: 114\n",
      "Sampling duration: 41.42838716506958 seconds\n",
      "New train size: 1262\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5072, Accuracy: 0.8149, F1 Micro: 0.8953, F1 Macro: 0.888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3887, Accuracy: 0.9014, F1 Micro: 0.9405, F1 Macro: 0.9343\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2771, Accuracy: 0.9314, F1 Micro: 0.9583, F1 Macro: 0.9549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2095, Accuracy: 0.9448, F1 Micro: 0.9662, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1699, Accuracy: 0.9543, F1 Micro: 0.9718, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1395, Accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9712\n",
      "Epoch 7/10, Train Loss: 0.1219, Accuracy: 0.9569, F1 Micro: 0.9732, F1 Macro: 0.9695\n",
      "Epoch 8/10, Train Loss: 0.1054, Accuracy: 0.9569, F1 Micro: 0.9734, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.089, Accuracy: 0.9594, F1 Micro: 0.9748, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0803, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9732\n",
      "\n",
      "Aspect detection accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9732\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.92      0.93      0.92       317\n",
      "       linen       0.93      0.95      0.94       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4279, Accuracy: 0.8529, F1 Micro: 0.8529, F1 Macro: 0.8091\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2545, Accuracy: 0.8742, F1 Micro: 0.8742, F1 Macro: 0.8365\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1661, Accuracy: 0.8816, F1 Micro: 0.8816, F1 Macro: 0.8472\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.128, Accuracy: 0.8964, F1 Micro: 0.8964, F1 Macro: 0.865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0838, Accuracy: 0.901, F1 Micro: 0.901, F1 Macro: 0.8709\n",
      "Epoch 6/10, Train Loss: 0.0746, Accuracy: 0.8918, F1 Micro: 0.8918, F1 Macro: 0.8611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0644, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.875\n",
      "Epoch 8/10, Train Loss: 0.0332, Accuracy: 0.8825, F1 Micro: 0.8825, F1 Macro: 0.8403\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0418, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8795\n",
      "Epoch 10/10, Train Loss: 0.0298, Accuracy: 0.901, F1 Micro: 0.901, F1 Macro: 0.8746\n",
      "\n",
      "Sentiment analysis accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8795\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       762\n",
      "    positive       0.94      0.73      0.82       319\n",
      "\n",
      "    accuracy                           0.91      1081\n",
      "   macro avg       0.92      0.86      0.88      1081\n",
      "weighted avg       0.91      0.91      0.90      1081\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1262: Accuracy: 0.9545, F1 Micro: 0.9545, F1 Macro: 0.8603\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.75      0.30      0.43        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.72      0.77       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.78      0.81        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.89      0.69      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.56      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.84      0.87       200\n",
      "     neutral       0.92      0.93      0.92       315\n",
      "    positive       0.86      0.96      0.91        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.91      0.90       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86       162\n",
      "     neutral       0.93      0.95      0.94       387\n",
      "    positive       0.67      0.45      0.54        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.82      0.76      0.78       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.84      0.84        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.87      0.91      0.89        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.90      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.96      0.97        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 240.07640671730042 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0033212443348020313\n",
      "Acquired samples: 103\n",
      "Sampling duration: 37.728453397750854 seconds\n",
      "New train size: 1365\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4937, Accuracy: 0.8198, F1 Micro: 0.8975, F1 Macro: 0.8899\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3694, Accuracy: 0.8977, F1 Micro: 0.9392, F1 Macro: 0.9351\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2603, Accuracy: 0.9373, F1 Micro: 0.9619, F1 Macro: 0.9593\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2025, Accuracy: 0.9524, F1 Micro: 0.9707, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1589, Accuracy: 0.955, F1 Micro: 0.9723, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.137, Accuracy: 0.9589, F1 Micro: 0.9746, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1152, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9728\n",
      "Epoch 8/10, Train Loss: 0.0968, Accuracy: 0.9568, F1 Micro: 0.9732, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0848, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.073, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9747\n",
      "\n",
      "Aspect detection accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.92      0.94      0.93       317\n",
      "       linen       0.94      0.95      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4321, Accuracy: 0.85, F1 Micro: 0.85, F1 Macro: 0.8019\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.24, Accuracy: 0.8813, F1 Micro: 0.8813, F1 Macro: 0.8526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1841, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1144, Accuracy: 0.8997, F1 Micro: 0.8997, F1 Macro: 0.8694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0826, Accuracy: 0.9016, F1 Micro: 0.9016, F1 Macro: 0.8743\n",
      "Epoch 6/10, Train Loss: 0.0688, Accuracy: 0.9006, F1 Micro: 0.9006, F1 Macro: 0.8689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0616, Accuracy: 0.9043, F1 Micro: 0.9043, F1 Macro: 0.88\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0416, Accuracy: 0.9043, F1 Micro: 0.9043, F1 Macro: 0.8752\n",
      "Epoch 9/10, Train Loss: 0.0358, Accuracy: 0.9006, F1 Micro: 0.9006, F1 Macro: 0.8704\n",
      "Epoch 10/10, Train Loss: 0.0283, Accuracy: 0.8997, F1 Micro: 0.8997, F1 Macro: 0.8723\n",
      "\n",
      "Sentiment analysis accuracy: 0.9043, F1 Micro: 0.9043, F1 Macro: 0.8752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.94       768\n",
      "    positive       0.94      0.72      0.81       319\n",
      "\n",
      "    accuracy                           0.90      1087\n",
      "   macro avg       0.92      0.85      0.88      1087\n",
      "weighted avg       0.91      0.90      0.90      1087\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1365: Accuracy: 0.9562, F1 Micro: 0.9562, F1 Macro: 0.8598\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.93      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.76      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.76      0.80        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.86      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.57      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.84      0.88       200\n",
      "     neutral       0.92      0.94      0.93       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.88      0.86       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       1.00      0.32      0.48        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.92      0.72      0.76       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.66      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.80      0.71      0.75        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 253.34855437278748 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Threshold: 0.0031382167246192696\n",
      "Acquired samples: 62\n",
      "Sampling duration: 33.9397988319397 seconds\n",
      "New train size: 1427\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4854, Accuracy: 0.8267, F1 Micro: 0.9001, F1 Macro: 0.8902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3583, Accuracy: 0.9078, F1 Micro: 0.9446, F1 Macro: 0.9402\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.248, Accuracy: 0.9406, F1 Micro: 0.9638, F1 Macro: 0.9612\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.189, Accuracy: 0.9465, F1 Micro: 0.9673, F1 Macro: 0.9649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1559, Accuracy: 0.9533, F1 Micro: 0.9713, F1 Macro: 0.9687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1298, Accuracy: 0.9569, F1 Micro: 0.9734, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1086, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.097, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9736\n",
      "Epoch 9/10, Train Loss: 0.0812, Accuracy: 0.9608, F1 Micro: 0.9758, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0703, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9738\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9738\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.93      0.95      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4335, Accuracy: 0.859, F1 Micro: 0.859, F1 Macro: 0.8149\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2407, Accuracy: 0.885, F1 Micro: 0.885, F1 Macro: 0.8457\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.169, Accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1165, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8868\n",
      "Epoch 5/10, Train Loss: 0.0816, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8761\n",
      "Epoch 6/10, Train Loss: 0.0941, Accuracy: 0.9072, F1 Micro: 0.9072, F1 Macro: 0.8794\n",
      "Epoch 7/10, Train Loss: 0.0433, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8767\n",
      "Epoch 8/10, Train Loss: 0.0399, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8765\n",
      "Epoch 9/10, Train Loss: 0.0336, Accuracy: 0.9063, F1 Micro: 0.9063, F1 Macro: 0.8794\n",
      "Epoch 10/10, Train Loss: 0.0383, Accuracy: 0.91, F1 Micro: 0.91, F1 Macro: 0.8834\n",
      "\n",
      "Sentiment analysis accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8868\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       765\n",
      "    positive       0.92      0.76      0.83       313\n",
      "\n",
      "    accuracy                           0.91      1078\n",
      "   macro avg       0.92      0.87      0.89      1078\n",
      "weighted avg       0.91      0.91      0.91      1078\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1427: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.8496\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.73      0.79        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.74      0.81       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.82      0.69      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.56      0.57       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.89       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86       162\n",
      "     neutral       0.93      0.95      0.94       387\n",
      "    positive       0.71      0.55      0.62        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.83      0.78      0.80       571\n",
      "weighted avg       0.90      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.84      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.88      0.94      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.52      0.62        29\n",
      "     neutral       0.97      1.00      0.99       525\n",
      "    positive       0.79      0.65      0.71        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.72      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.96      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 253.93019342422485 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.002593502216041088\n",
      "Acquired samples: 86\n",
      "Sampling duration: 31.733232259750366 seconds\n",
      "New train size: 1513\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4833, Accuracy: 0.8262, F1 Micro: 0.9018, F1 Macro: 0.8973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3496, Accuracy: 0.9101, F1 Micro: 0.9461, F1 Macro: 0.9426\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2328, Accuracy: 0.9425, F1 Micro: 0.9649, F1 Macro: 0.9625\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.182, Accuracy: 0.9528, F1 Micro: 0.9709, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1479, Accuracy: 0.9561, F1 Micro: 0.9729, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1245, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1029, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0882, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0786, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9752\n",
      "Epoch 10/10, Train Loss: 0.0656, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9736\n",
      "\n",
      "Aspect detection accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.94      0.95      0.94       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4054, Accuracy: 0.8385, F1 Micro: 0.8385, F1 Macro: 0.7954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2374, Accuracy: 0.8695, F1 Micro: 0.8695, F1 Macro: 0.8262\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1789, Accuracy: 0.8859, F1 Micro: 0.8859, F1 Macro: 0.8582\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1366, Accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.873\n",
      "Epoch 5/10, Train Loss: 0.1106, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.87\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0906, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0616, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8797\n",
      "Epoch 8/10, Train Loss: 0.0483, Accuracy: 0.9033, F1 Micro: 0.9033, F1 Macro: 0.8763\n",
      "Epoch 9/10, Train Loss: 0.033, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.8748\n",
      "Epoch 10/10, Train Loss: 0.0508, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8751\n",
      "\n",
      "Sentiment analysis accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.94       774\n",
      "    positive       0.92      0.75      0.82       322\n",
      "\n",
      "    accuracy                           0.91      1096\n",
      "   macro avg       0.91      0.86      0.88      1096\n",
      "weighted avg       0.91      0.91      0.90      1096\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1513: Accuracy: 0.9571, F1 Micro: 0.9571, F1 Macro: 0.8687\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.88      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.82      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.57      0.59       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.88       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.90      0.95      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.84      0.85       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.61      0.50      0.55        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.80      0.77      0.78       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.83      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 271.85885548591614 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.0031925782095640898\n",
      "Acquired samples: 78\n",
      "Sampling duration: 28.61773991584778 seconds\n",
      "New train size: 1591\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4833, Accuracy: 0.8283, F1 Micro: 0.9026, F1 Macro: 0.8971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3386, Accuracy: 0.9163, F1 Micro: 0.9498, F1 Macro: 0.9472\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2355, Accuracy: 0.9465, F1 Micro: 0.9672, F1 Macro: 0.9647\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1875, Accuracy: 0.9493, F1 Micro: 0.9689, F1 Macro: 0.9663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1479, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1264, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9735\n",
      "Epoch 7/10, Train Loss: 0.1075, Accuracy: 0.9595, F1 Micro: 0.975, F1 Macro: 0.9724\n",
      "Epoch 8/10, Train Loss: 0.0929, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9729\n",
      "Epoch 9/10, Train Loss: 0.0746, Accuracy: 0.9611, F1 Micro: 0.9758, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0673, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9742\n",
      "\n",
      "Aspect detection accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.92      0.93       317\n",
      "       linen       0.93      0.96      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4036, Accuracy: 0.8551, F1 Micro: 0.8551, F1 Macro: 0.8143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2474, Accuracy: 0.8797, F1 Micro: 0.8797, F1 Macro: 0.8399\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1894, Accuracy: 0.887, F1 Micro: 0.887, F1 Macro: 0.854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1243, Accuracy: 0.9034, F1 Micro: 0.9034, F1 Macro: 0.8741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1083, Accuracy: 0.9061, F1 Micro: 0.9061, F1 Macro: 0.8784\n",
      "Epoch 6/10, Train Loss: 0.066, Accuracy: 0.9025, F1 Micro: 0.9025, F1 Macro: 0.8728\n",
      "Epoch 7/10, Train Loss: 0.0618, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8698\n",
      "Epoch 8/10, Train Loss: 0.0563, Accuracy: 0.9043, F1 Micro: 0.9043, F1 Macro: 0.876\n",
      "Epoch 9/10, Train Loss: 0.0462, Accuracy: 0.8943, F1 Micro: 0.8943, F1 Macro: 0.8609\n",
      "Epoch 10/10, Train Loss: 0.0348, Accuracy: 0.8943, F1 Micro: 0.8943, F1 Macro: 0.8606\n",
      "\n",
      "Sentiment analysis accuracy: 0.9061, F1 Micro: 0.9061, F1 Macro: 0.8784\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       774\n",
      "    positive       0.94      0.73      0.82       323\n",
      "\n",
      "    accuracy                           0.91      1097\n",
      "   macro avg       0.92      0.85      0.88      1097\n",
      "weighted avg       0.91      0.91      0.90      1097\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1591: Accuracy: 0.9566, F1 Micro: 0.9566, F1 Macro: 0.8725\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.79      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.62      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89       200\n",
      "     neutral       0.95      0.92      0.93       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.84      0.84       162\n",
      "     neutral       0.93      0.96      0.94       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.87      0.74      0.78       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.91      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.82      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 273.57840371131897 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.004184608906507493\n",
      "Acquired samples: 70\n",
      "Sampling duration: 26.158042907714844 seconds\n",
      "New train size: 1661\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.476, Accuracy: 0.838, F1 Micro: 0.9071, F1 Macro: 0.901\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3281, Accuracy: 0.9259, F1 Micro: 0.955, F1 Macro: 0.9517\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2242, Accuracy: 0.9472, F1 Micro: 0.9676, F1 Macro: 0.965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1749, Accuracy: 0.9536, F1 Micro: 0.9714, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1434, Accuracy: 0.9556, F1 Micro: 0.9727, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1196, Accuracy: 0.959, F1 Micro: 0.9747, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0988, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0838, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9743\n",
      "Epoch 9/10, Train Loss: 0.0711, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9732\n",
      "Epoch 10/10, Train Loss: 0.0655, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9737\n",
      "\n",
      "Aspect detection accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9743\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.91      0.95      0.93       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3711, Accuracy: 0.8679, F1 Micro: 0.8679, F1 Macro: 0.8331\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2375, Accuracy: 0.8868, F1 Micro: 0.8868, F1 Macro: 0.8467\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1512, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.8876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1137, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.8873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0838, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.8953\n",
      "Epoch 6/10, Train Loss: 0.0581, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.8884\n",
      "Epoch 7/10, Train Loss: 0.0497, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.8954\n",
      "Epoch 8/10, Train Loss: 0.0359, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.891\n",
      "Epoch 9/10, Train Loss: 0.0372, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.8947\n",
      "Epoch 10/10, Train Loss: 0.034, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.8912\n",
      "\n",
      "Sentiment analysis accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.8953\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       756\n",
      "    positive       0.95      0.76      0.84       304\n",
      "\n",
      "    accuracy                           0.92      1060\n",
      "   macro avg       0.93      0.87      0.90      1060\n",
      "weighted avg       0.92      0.92      0.92      1060\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1661: Accuracy: 0.9567, F1 Micro: 0.9567, F1 Macro: 0.8741\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.87      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.76      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.91      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.62      0.66       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.84      0.87       200\n",
      "     neutral       0.91      0.95      0.93       315\n",
      "    positive       0.87      0.93      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.91      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.83      0.85       162\n",
      "     neutral       0.92      0.96      0.94       387\n",
      "    positive       0.92      0.50      0.65        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.77      0.81       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.94      0.91      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.66      0.73        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.81      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.96      0.96        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.87      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 279.8447666168213 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Threshold: 0.0024866833351552486\n",
      "Acquired samples: 51\n",
      "Sampling duration: 22.74165964126587 seconds\n",
      "New train size: 1712\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4729, Accuracy: 0.85, F1 Micro: 0.9134, F1 Macro: 0.9079\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3182, Accuracy: 0.9295, F1 Micro: 0.9571, F1 Macro: 0.9537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2199, Accuracy: 0.9477, F1 Micro: 0.9679, F1 Macro: 0.9654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1716, Accuracy: 0.9557, F1 Micro: 0.9727, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1403, Accuracy: 0.9575, F1 Micro: 0.9738, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1219, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9735\n",
      "Epoch 7/10, Train Loss: 0.1007, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0845, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9751\n",
      "Epoch 9/10, Train Loss: 0.0695, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0621, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9752\n",
      "\n",
      "Aspect detection accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.92      0.93       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4001, Accuracy: 0.8658, F1 Micro: 0.8658, F1 Macro: 0.8263\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.208, Accuracy: 0.8932, F1 Micro: 0.8932, F1 Macro: 0.8595\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1502, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8777\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0997, Accuracy: 0.9078, F1 Micro: 0.9078, F1 Macro: 0.8806\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0791, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.8869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0623, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.8843\n",
      "Epoch 7/10, Train Loss: 0.0486, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8791\n",
      "Epoch 8/10, Train Loss: 0.0381, Accuracy: 0.8959, F1 Micro: 0.8959, F1 Macro: 0.872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0404, Accuracy: 0.9169, F1 Micro: 0.9169, F1 Macro: 0.8922\n",
      "Epoch 10/10, Train Loss: 0.0099, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8922\n",
      "\n",
      "Sentiment analysis accuracy: 0.9169, F1 Micro: 0.9169, F1 Macro: 0.8922\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.99      0.94       775\n",
      "    positive       0.96      0.75      0.84       320\n",
      "\n",
      "    accuracy                           0.92      1095\n",
      "   macro avg       0.93      0.87      0.89      1095\n",
      "weighted avg       0.92      0.92      0.91      1095\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1712: Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.8849\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.80      0.84       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.79      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.62      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88       200\n",
      "     neutral       0.93      0.92      0.93       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.87      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.76      0.81       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.66      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 294.8033661842346 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.0034357117488980292\n",
      "Acquired samples: 58\n",
      "Sampling duration: 19.796300172805786 seconds\n",
      "New train size: 1770\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4648, Accuracy: 0.8498, F1 Micro: 0.9115, F1 Macro: 0.9023\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.318, Accuracy: 0.925, F1 Micro: 0.9544, F1 Macro: 0.9505\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2131, Accuracy: 0.946, F1 Micro: 0.967, F1 Macro: 0.9648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1702, Accuracy: 0.9543, F1 Micro: 0.972, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1366, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9735\n",
      "Epoch 6/10, Train Loss: 0.1156, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9735\n",
      "Epoch 7/10, Train Loss: 0.0983, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.084, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0687, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0628, Accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.94      0.93      0.93       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3694, Accuracy: 0.8688, F1 Micro: 0.8688, F1 Macro: 0.8268\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2284, Accuracy: 0.8963, F1 Micro: 0.8963, F1 Macro: 0.8624\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1472, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1063, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8863\n",
      "Epoch 5/10, Train Loss: 0.0928, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0636, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.893\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0373, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.8911\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0488, Accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.895\n",
      "Epoch 9/10, Train Loss: 0.0324, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.8894\n",
      "Epoch 10/10, Train Loss: 0.0285, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.887\n",
      "\n",
      "Sentiment analysis accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.94       775\n",
      "    positive       0.92      0.79      0.85       315\n",
      "\n",
      "    accuracy                           0.92      1090\n",
      "   macro avg       0.92      0.88      0.89      1090\n",
      "weighted avg       0.92      0.92      0.92      1090\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1770: Accuracy: 0.9594, F1 Micro: 0.9594, F1 Macro: 0.8769\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.85      0.80      0.83       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.79      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.83      0.78      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.63      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.89       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.83      0.86       162\n",
      "     neutral       0.92      0.97      0.95       387\n",
      "    positive       0.73      0.50      0.59        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.85      0.77      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.81      0.85        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.82      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.91      0.99      0.95       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 299.89915227890015 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.0023180793505162\n",
      "Acquired samples: 52\n",
      "Sampling duration: 17.827144145965576 seconds\n",
      "New train size: 1822\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4796, Accuracy: 0.8486, F1 Micro: 0.9121, F1 Macro: 0.9046\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.313, Accuracy: 0.9269, F1 Micro: 0.9557, F1 Macro: 0.9528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2118, Accuracy: 0.9462, F1 Micro: 0.967, F1 Macro: 0.9649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1704, Accuracy: 0.9543, F1 Micro: 0.9718, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1366, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1153, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9745\n",
      "Epoch 7/10, Train Loss: 0.1004, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0822, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.975\n",
      "Epoch 9/10, Train Loss: 0.0704, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9751\n",
      "Epoch 10/10, Train Loss: 0.0599, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9746\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.91      0.98      0.94       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3763, Accuracy: 0.865, F1 Micro: 0.865, F1 Macro: 0.8177\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2135, Accuracy: 0.9013, F1 Micro: 0.9013, F1 Macro: 0.8751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1475, Accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.8835\n",
      "Epoch 4/10, Train Loss: 0.1292, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8858\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0966, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8878\n",
      "Epoch 6/10, Train Loss: 0.0736, Accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.8859\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0608, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8865\n",
      "Epoch 8/10, Train Loss: 0.0458, Accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.8866\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0393, Accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.8884\n",
      "Epoch 10/10, Train Loss: 0.0444, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8824\n",
      "\n",
      "Sentiment analysis accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.8884\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       767\n",
      "    positive       0.93      0.76      0.83       307\n",
      "\n",
      "    accuracy                           0.91      1074\n",
      "   macro avg       0.92      0.87      0.89      1074\n",
      "weighted avg       0.92      0.91      0.91      1074\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1822: Accuracy: 0.9573, F1 Micro: 0.9573, F1 Macro: 0.878\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.86      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.86      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.94       571\n",
      "weighted avg       0.96      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.62      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.88       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.84      0.95      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.80      0.84       162\n",
      "     neutral       0.91      0.98      0.94       387\n",
      "    positive       0.78      0.32      0.45        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.86      0.70      0.75       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.81      0.86        85\n",
      "     neutral       0.96      0.99      0.97       418\n",
      "    positive       0.94      0.91      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.90      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.59      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.72      0.76      0.74        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.78      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 294.5394265651703 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.0027171282330527903\n",
      "Acquired samples: 50\n",
      "Sampling duration: 16.65543532371521 seconds\n",
      "New train size: 1872\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4657, Accuracy: 0.8566, F1 Micro: 0.9174, F1 Macro: 0.9134\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2989, Accuracy: 0.9335, F1 Micro: 0.9595, F1 Macro: 0.9569\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2141, Accuracy: 0.9465, F1 Micro: 0.9673, F1 Macro: 0.9652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.166, Accuracy: 0.9545, F1 Micro: 0.972, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1337, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1089, Accuracy: 0.9611, F1 Micro: 0.976, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0961, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0777, Accuracy: 0.9665, F1 Micro: 0.9792, F1 Macro: 0.9769\n",
      "Epoch 9/10, Train Loss: 0.0709, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9755\n",
      "Epoch 10/10, Train Loss: 0.0586, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9758\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9792, F1 Macro: 0.9769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3569, Accuracy: 0.867, F1 Micro: 0.867, F1 Macro: 0.8204\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2121, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8799\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1557, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8855\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0995, Accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.8926\n",
      "Epoch 5/10, Train Loss: 0.0758, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8844\n",
      "Epoch 6/10, Train Loss: 0.0678, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8873\n",
      "Epoch 7/10, Train Loss: 0.0464, Accuracy: 0.9165, F1 Micro: 0.9165, F1 Macro: 0.892\n",
      "Epoch 8/10, Train Loss: 0.0429, Accuracy: 0.9156, F1 Micro: 0.9156, F1 Macro: 0.8912\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0319, Accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.8933\n",
      "Epoch 10/10, Train Loss: 0.026, Accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.8871\n",
      "\n",
      "Sentiment analysis accuracy: 0.9174, F1 Micro: 0.9174, F1 Macro: 0.8933\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       778\n",
      "    positive       0.93      0.77      0.84       312\n",
      "\n",
      "    accuracy                           0.92      1090\n",
      "   macro avg       0.92      0.87      0.89      1090\n",
      "weighted avg       0.92      0.92      0.92      1090\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1872: Accuracy: 0.9608, F1 Micro: 0.9608, F1 Macro: 0.8853\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.81      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.89      0.74      0.81        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.62      0.68       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.90       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.80      0.55      0.65        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.87      0.79      0.82       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.52      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.94      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.82      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.96      0.96        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 303.8802843093872 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.0021521040238440038\n",
      "Acquired samples: 50\n",
      "Sampling duration: 14.25416111946106 seconds\n",
      "New train size: 1922\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4678, Accuracy: 0.854, F1 Micro: 0.9158, F1 Macro: 0.9118\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2959, Accuracy: 0.9321, F1 Micro: 0.9586, F1 Macro: 0.9549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2071, Accuracy: 0.9467, F1 Micro: 0.9674, F1 Macro: 0.965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1638, Accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1345, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9736\n",
      "Epoch 6/10, Train Loss: 0.1071, Accuracy: 0.9585, F1 Micro: 0.9744, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0946, Accuracy: 0.9634, F1 Micro: 0.9772, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.079, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0677, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0561, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9759\n",
      "\n",
      "Aspect detection accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.375, Accuracy: 0.8673, F1 Micro: 0.8673, F1 Macro: 0.8347\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2105, Accuracy: 0.8891, F1 Micro: 0.8891, F1 Macro: 0.8518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1578, Accuracy: 0.8955, F1 Micro: 0.8955, F1 Macro: 0.8684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1233, Accuracy: 0.9018, F1 Micro: 0.9018, F1 Macro: 0.8712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0859, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8837\n",
      "Epoch 6/10, Train Loss: 0.0653, Accuracy: 0.9018, F1 Micro: 0.9018, F1 Macro: 0.8749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0594, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8863\n",
      "Epoch 8/10, Train Loss: 0.038, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0349, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8873\n",
      "Epoch 10/10, Train Loss: 0.0296, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8749\n",
      "\n",
      "Sentiment analysis accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8873\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       777\n",
      "    positive       0.93      0.76      0.83       323\n",
      "\n",
      "    accuracy                           0.91      1100\n",
      "   macro avg       0.92      0.87      0.89      1100\n",
      "weighted avg       0.91      0.91      0.91      1100\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1922: Accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.8782\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.62      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89       200\n",
      "     neutral       0.93      0.94      0.94       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.85       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.75      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.83      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 319.89155888557434 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.0018618632457219066\n",
      "Acquired samples: 50\n",
      "Sampling duration: 13.35463261604309 seconds\n",
      "New train size: 1972\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4652, Accuracy: 0.8609, F1 Micro: 0.9192, F1 Macro: 0.9147\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2937, Accuracy: 0.9377, F1 Micro: 0.9619, F1 Macro: 0.9593\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2034, Accuracy: 0.9451, F1 Micro: 0.9665, F1 Macro: 0.9643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1614, Accuracy: 0.9578, F1 Micro: 0.9738, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1286, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1084, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0919, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0784, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0654, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "Epoch 10/10, Train Loss: 0.0559, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9757\n",
      "\n",
      "Aspect detection accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3737, Accuracy: 0.8669, F1 Micro: 0.8669, F1 Macro: 0.8182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2226, Accuracy: 0.8808, F1 Micro: 0.8808, F1 Macro: 0.8343\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.149, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.8793\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1082, Accuracy: 0.9131, F1 Micro: 0.9131, F1 Macro: 0.8854\n",
      "Epoch 5/10, Train Loss: 0.0938, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8843\n",
      "Epoch 6/10, Train Loss: 0.0632, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.883\n",
      "Epoch 7/10, Train Loss: 0.036, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0437, Accuracy: 0.915, F1 Micro: 0.915, F1 Macro: 0.8881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0325, Accuracy: 0.915, F1 Micro: 0.915, F1 Macro: 0.8865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0359, Accuracy: 0.915, F1 Micro: 0.915, F1 Macro: 0.8873\n",
      "\n",
      "Sentiment analysis accuracy: 0.915, F1 Micro: 0.915, F1 Macro: 0.8873\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       778\n",
      "    positive       0.94      0.75      0.83       304\n",
      "\n",
      "    accuracy                           0.91      1082\n",
      "   macro avg       0.92      0.86      0.89      1082\n",
      "weighted avg       0.92      0.91      0.91      1082\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Iteration 1972: Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.8725\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.92      0.93        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.85      0.80      0.83       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.88      0.68      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.60      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.85       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       0.86      0.27      0.41        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.88      0.69      0.73       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.81      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 323.0319802761078 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Threshold: 0.002547879656776786\n",
      "Acquired samples: 25\n",
      "Sampling duration: 11.458023309707642 seconds\n",
      "New train size: 1997\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4644, Accuracy: 0.862, F1 Micro: 0.9197, F1 Macro: 0.9153\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2809, Accuracy: 0.9399, F1 Micro: 0.9634, F1 Macro: 0.961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1954, Accuracy: 0.9495, F1 Micro: 0.969, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1564, Accuracy: 0.959, F1 Micro: 0.9748, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1269, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1063, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0892, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0777, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9756\n",
      "Epoch 9/10, Train Loss: 0.064, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9744\n",
      "Epoch 10/10, Train Loss: 0.0534, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9741\n",
      "\n",
      "Aspect detection accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.95      0.95      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3598, Accuracy: 0.8485, F1 Micro: 0.8485, F1 Macro: 0.7984\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2255, Accuracy: 0.8775, F1 Micro: 0.8775, F1 Macro: 0.8342\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1754, Accuracy: 0.8975, F1 Micro: 0.8975, F1 Macro: 0.8661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1121, Accuracy: 0.8993, F1 Micro: 0.8993, F1 Macro: 0.8667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0811, Accuracy: 0.9011, F1 Micro: 0.9011, F1 Macro: 0.8715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0711, Accuracy: 0.9047, F1 Micro: 0.9047, F1 Macro: 0.8765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0504, Accuracy: 0.9047, F1 Micro: 0.9047, F1 Macro: 0.8753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0421, Accuracy: 0.9047, F1 Micro: 0.9047, F1 Macro: 0.8753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0543, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8763\n",
      "Epoch 10/10, Train Loss: 0.0259, Accuracy: 0.9056, F1 Micro: 0.9056, F1 Macro: 0.8781\n",
      "\n",
      "Sentiment analysis accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.99      0.94       783\n",
      "    positive       0.95      0.71      0.82       319\n",
      "\n",
      "    accuracy                           0.91      1102\n",
      "   macro avg       0.92      0.85      0.88      1102\n",
      "weighted avg       0.91      0.91      0.90      1102\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1997: Accuracy: 0.9587, F1 Micro: 0.9587, F1 Macro: 0.8684\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.87      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.79      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.90      0.69      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.78      0.61      0.66       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.89      0.88       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.86      0.91      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.90      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.90      0.87       162\n",
      "     neutral       0.95      0.95      0.95       387\n",
      "    positive       0.89      0.36      0.52        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.74      0.78       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.89      0.88        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 330.2114188671112 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.0019966068211942915\n",
      "Acquired samples: 50\n",
      "Sampling duration: 10.200543403625488 seconds\n",
      "New train size: 2047\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4526, Accuracy: 0.8672, F1 Micro: 0.9226, F1 Macro: 0.9186\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2799, Accuracy: 0.9365, F1 Micro: 0.9613, F1 Macro: 0.9587\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.197, Accuracy: 0.9495, F1 Micro: 0.9689, F1 Macro: 0.9664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.152, Accuracy: 0.9542, F1 Micro: 0.9718, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.129, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1031, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9753\n",
      "Epoch 7/10, Train Loss: 0.0876, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0743, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0616, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "Epoch 10/10, Train Loss: 0.054, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9747\n",
      "\n",
      "Aspect detection accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3626, Accuracy: 0.8695, F1 Micro: 0.8695, F1 Macro: 0.8359\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.228, Accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8724\n",
      "Epoch 3/10, Train Loss: 0.1364, Accuracy: 0.8952, F1 Micro: 0.8952, F1 Macro: 0.8563\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.111, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0744, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.8854\n",
      "Epoch 6/10, Train Loss: 0.0614, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8818\n",
      "Epoch 7/10, Train Loss: 0.0423, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8816\n",
      "Epoch 8/10, Train Loss: 0.0337, Accuracy: 0.9081, F1 Micro: 0.9081, F1 Macro: 0.8783\n",
      "Epoch 9/10, Train Loss: 0.0339, Accuracy: 0.909, F1 Micro: 0.909, F1 Macro: 0.88\n",
      "Epoch 10/10, Train Loss: 0.0273, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8824\n",
      "\n",
      "Sentiment analysis accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.8854\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       781\n",
      "    positive       0.92      0.75      0.83       307\n",
      "\n",
      "    accuracy                           0.91      1088\n",
      "   macro avg       0.92      0.86      0.89      1088\n",
      "weighted avg       0.91      0.91      0.91      1088\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2047: Accuracy: 0.9587, F1 Micro: 0.9587, F1 Macro: 0.8727\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.88      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.83      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.85      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.94       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.88      0.65      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.54      0.57       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.83      0.95      0.88        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.92      0.90       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.74      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 327.41684079170227 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.0018290465464815499\n",
      "Acquired samples: 50\n",
      "Sampling duration: 8.629787683486938 seconds\n",
      "New train size: 2097\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.451, Accuracy: 0.8738, F1 Micro: 0.9257, F1 Macro: 0.9205\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2744, Accuracy: 0.9358, F1 Micro: 0.9609, F1 Macro: 0.9587\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1894, Accuracy: 0.9469, F1 Micro: 0.9674, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1517, Accuracy: 0.9563, F1 Micro: 0.973, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1243, Accuracy: 0.9585, F1 Micro: 0.9744, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1043, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9753\n",
      "Epoch 7/10, Train Loss: 0.0876, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9744\n",
      "Epoch 8/10, Train Loss: 0.0741, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.062, Accuracy: 0.9665, F1 Micro: 0.9792, F1 Macro: 0.9772\n",
      "Epoch 10/10, Train Loss: 0.0507, Accuracy: 0.9661, F1 Micro: 0.9789, F1 Macro: 0.977\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9792, F1 Macro: 0.9772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.95      0.94      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3489, Accuracy: 0.8608, F1 Micro: 0.8608, F1 Macro: 0.8205\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1984, Accuracy: 0.8915, F1 Micro: 0.8915, F1 Macro: 0.8562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1643, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.8703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1098, Accuracy: 0.9014, F1 Micro: 0.9014, F1 Macro: 0.8689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0767, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8816\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0567, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.8821\n",
      "Epoch 7/10, Train Loss: 0.0427, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.876\n",
      "Epoch 8/10, Train Loss: 0.0477, Accuracy: 0.9014, F1 Micro: 0.9014, F1 Macro: 0.8698\n",
      "Epoch 9/10, Train Loss: 0.0258, Accuracy: 0.9014, F1 Micro: 0.9014, F1 Macro: 0.8707\n",
      "Epoch 10/10, Train Loss: 0.0246, Accuracy: 0.9014, F1 Micro: 0.9014, F1 Macro: 0.8698\n",
      "\n",
      "Sentiment analysis accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.8821\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       788\n",
      "    positive       0.95      0.73      0.82       318\n",
      "\n",
      "    accuracy                           0.91      1106\n",
      "   macro avg       0.92      0.86      0.88      1106\n",
      "weighted avg       0.91      0.91      0.91      1106\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2097: Accuracy: 0.9604, F1 Micro: 0.9604, F1 Macro: 0.8792\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.87      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.95      0.94       571\n",
      "weighted avg       0.96      0.95      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.87      0.71      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.61      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.90      0.91       200\n",
      "     neutral       0.95      0.94      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.87      0.86       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.88      0.32      0.47        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.72      0.76       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.88        85\n",
      "     neutral       0.98      0.97      0.98       418\n",
      "    positive       0.94      0.96      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.62      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.71      0.73        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.77      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 330.2975044250488 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.0027936744038015602\n",
      "Acquired samples: 50\n",
      "Sampling duration: 7.65647292137146 seconds\n",
      "New train size: 2147\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4458, Accuracy: 0.8769, F1 Micro: 0.9274, F1 Macro: 0.9225\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2687, Accuracy: 0.9417, F1 Micro: 0.9642, F1 Macro: 0.961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1884, Accuracy: 0.9495, F1 Micro: 0.969, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1484, Accuracy: 0.9545, F1 Micro: 0.9719, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1221, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1025, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.087, Accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9767\n",
      "Epoch 8/10, Train Loss: 0.0715, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "Epoch 9/10, Train Loss: 0.06, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9756\n",
      "Epoch 10/10, Train Loss: 0.0504, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9762\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3454, Accuracy: 0.8505, F1 Micro: 0.8505, F1 Macro: 0.8169\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2125, Accuracy: 0.894, F1 Micro: 0.894, F1 Macro: 0.8676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1537, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8828\n",
      "Epoch 4/10, Train Loss: 0.1227, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.881\n",
      "Epoch 5/10, Train Loss: 0.1108, Accuracy: 0.9085, F1 Micro: 0.9085, F1 Macro: 0.8815\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0811, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0587, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.888\n",
      "Epoch 8/10, Train Loss: 0.0504, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8788\n",
      "Epoch 9/10, Train Loss: 0.0486, Accuracy: 0.9121, F1 Micro: 0.9121, F1 Macro: 0.8875\n",
      "Epoch 10/10, Train Loss: 0.0358, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.882\n",
      "\n",
      "Sentiment analysis accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       783\n",
      "    positive       0.93      0.76      0.84       321\n",
      "\n",
      "    accuracy                           0.91      1104\n",
      "   macro avg       0.92      0.87      0.89      1104\n",
      "weighted avg       0.91      0.91      0.91      1104\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2147: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.8884\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.60      0.60      0.60        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.83      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.78      0.81        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.62      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.86       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.75      0.55      0.63        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.85      0.79      0.81       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.89      0.88        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.95      0.93      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.84      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 337.2854404449463 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.0019523186609148979\n",
      "Acquired samples: 50\n",
      "Sampling duration: 5.899513006210327 seconds\n",
      "New train size: 2197\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4417, Accuracy: 0.8773, F1 Micro: 0.9282, F1 Macro: 0.9242\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2619, Accuracy: 0.9431, F1 Micro: 0.9652, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1886, Accuracy: 0.9514, F1 Micro: 0.9702, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.149, Accuracy: 0.958, F1 Micro: 0.974, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1222, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0978, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0857, Accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9766\n",
      "Epoch 8/10, Train Loss: 0.0692, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0576, Accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9767\n",
      "Epoch 10/10, Train Loss: 0.0487, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9755\n",
      "\n",
      "Aspect detection accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.93      0.96      0.94       317\n",
      "       linen       0.91      0.98      0.94       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.349, Accuracy: 0.8603, F1 Micro: 0.8603, F1 Macro: 0.8335\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2111, Accuracy: 0.901, F1 Micro: 0.901, F1 Macro: 0.8782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1258, Accuracy: 0.9214, F1 Micro: 0.9214, F1 Macro: 0.8967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0891, Accuracy: 0.9223, F1 Micro: 0.9223, F1 Macro: 0.9008\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0782, Accuracy: 0.9241, F1 Micro: 0.9241, F1 Macro: 0.9016\n",
      "Epoch 6/10, Train Loss: 0.0441, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.8985\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0447, Accuracy: 0.9241, F1 Micro: 0.9241, F1 Macro: 0.9014\n",
      "Epoch 8/10, Train Loss: 0.0264, Accuracy: 0.9214, F1 Micro: 0.9214, F1 Macro: 0.8982\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0317, Accuracy: 0.9241, F1 Micro: 0.9241, F1 Macro: 0.9025\n",
      "Epoch 10/10, Train Loss: 0.0349, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.8968\n",
      "\n",
      "Sentiment analysis accuracy: 0.9241, F1 Micro: 0.9241, F1 Macro: 0.9025\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       773\n",
      "    positive       0.93      0.80      0.86       308\n",
      "\n",
      "    accuracy                           0.92      1081\n",
      "   macro avg       0.93      0.89      0.90      1081\n",
      "weighted avg       0.92      0.92      0.92      1081\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2197: Accuracy: 0.9602, F1 Micro: 0.9602, F1 Macro: 0.8787\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.90      0.93        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.82      0.79      0.81        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.64      0.68       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.87      0.90       200\n",
      "     neutral       0.93      0.96      0.94       315\n",
      "    positive       0.90      0.98      0.94        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.92      0.94      0.93       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86       162\n",
      "     neutral       0.91      0.98      0.95       387\n",
      "    positive       0.89      0.36      0.52        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.72      0.77       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.88        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.48      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.65      0.88      0.75        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.79       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 344.9622187614441 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.0018701327266171575\n",
      "Acquired samples: 50\n",
      "Sampling duration: 3.7660560607910156 seconds\n",
      "New train size: 2247\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4424, Accuracy: 0.8845, F1 Micro: 0.9319, F1 Macro: 0.9278\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2559, Accuracy: 0.945, F1 Micro: 0.9663, F1 Macro: 0.9642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1812, Accuracy: 0.95, F1 Micro: 0.9693, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1429, Accuracy: 0.9608, F1 Micro: 0.9758, F1 Macro: 0.9738\n",
      "Epoch 5/10, Train Loss: 0.117, Accuracy: 0.9592, F1 Micro: 0.9748, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.097, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0818, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9753\n",
      "Epoch 8/10, Train Loss: 0.0704, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9747\n",
      "Epoch 9/10, Train Loss: 0.0579, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0493, Accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.93      0.96      0.94       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3386, Accuracy: 0.8614, F1 Micro: 0.8614, F1 Macro: 0.8153\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1974, Accuracy: 0.9001, F1 Micro: 0.9001, F1 Macro: 0.8723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1352, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8872\n",
      "Epoch 4/10, Train Loss: 0.0897, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8815\n",
      "Epoch 5/10, Train Loss: 0.0636, Accuracy: 0.91, F1 Micro: 0.91, F1 Macro: 0.8817\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0593, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8913\n",
      "Epoch 7/10, Train Loss: 0.046, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0358, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.8911\n",
      "Epoch 9/10, Train Loss: 0.0355, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8867\n",
      "Epoch 10/10, Train Loss: 0.0181, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8786\n",
      "\n",
      "Sentiment analysis accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.8911\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       788\n",
      "    positive       0.95      0.75      0.84       323\n",
      "\n",
      "    accuracy                           0.92      1111\n",
      "   macro avg       0.93      0.87      0.89      1111\n",
      "weighted avg       0.92      0.92      0.91      1111\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2247: Accuracy: 0.9608, F1 Micro: 0.9608, F1 Macro: 0.8807\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.87      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.95      0.94       571\n",
      "weighted avg       0.96      0.95      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.82      0.74      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.62      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.89      0.98      0.93        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.94      0.93       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.87       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.74      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.69      0.77        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.86      0.88       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.91      0.99      0.95       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 347.0238444805145 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Threshold: 0.0015426517464220523\n",
      "Acquired samples: 36\n",
      "Sampling duration: 2.4008758068084717 seconds\n",
      "New train size: 2283\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4385, Accuracy: 0.8832, F1 Micro: 0.9309, F1 Macro: 0.9254\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2531, Accuracy: 0.9427, F1 Micro: 0.9651, F1 Macro: 0.9629\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.179, Accuracy: 0.9524, F1 Micro: 0.9707, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1453, Accuracy: 0.9595, F1 Micro: 0.975, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1174, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0916, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9763\n",
      "Epoch 7/10, Train Loss: 0.0806, Accuracy: 0.9613, F1 Micro: 0.9761, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0681, Accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9769\n",
      "Epoch 9/10, Train Loss: 0.0565, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9758\n",
      "Epoch 10/10, Train Loss: 0.0469, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3261, Accuracy: 0.8717, F1 Micro: 0.8717, F1 Macro: 0.8402\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1902, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8793\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1224, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8849\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0965, Accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8883\n",
      "Epoch 5/10, Train Loss: 0.08, Accuracy: 0.909, F1 Micro: 0.909, F1 Macro: 0.8818\n",
      "Epoch 6/10, Train Loss: 0.0507, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.886\n",
      "Epoch 7/10, Train Loss: 0.0288, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0401, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8926\n",
      "Epoch 9/10, Train Loss: 0.0181, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0236, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.8932\n",
      "\n",
      "Sentiment analysis accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.8932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       777\n",
      "    positive       0.93      0.77      0.84       322\n",
      "\n",
      "    accuracy                           0.92      1099\n",
      "   macro avg       0.92      0.87      0.89      1099\n",
      "weighted avg       0.92      0.92      0.91      1099\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2283: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.8874\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.86      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.83      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.29      0.40         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.82      0.78      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.81      0.68      0.72       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.87      0.90       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.80      0.55      0.65        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.87      0.79      0.82       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.95      0.93      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.82      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 354.3711144924164 s\n",
      "Total runtime: 7894.36918258667 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[4], 4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6765120,
     "sourceId": 10886992,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8457.099536,
   "end_time": "2025-03-31T06:55:50.602919",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-31T04:34:53.503383",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "036eef3596b943659b2869a2469f7a1e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "03e02ff20fbd40f4be4736b5147aaf31": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "07c7ab7169f2404c84a96f3d6311261e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_21941795a8794e86959226e4b0d7da46",
        "IPY_MODEL_cdd3acc182224dd3bfd3306121353b7f",
        "IPY_MODEL_bb3af0c636d246659accbdfcedcf5e64"
       ],
       "layout": "IPY_MODEL_036eef3596b943659b2869a2469f7a1e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "09bd513f5ff043eea3a6357d405fdc57": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4cfa4505dbeb409cb28026e738e4bc24",
        "IPY_MODEL_f7bd8e2f610f46cca4100de5b5ce6d07",
        "IPY_MODEL_7e25c5f295e847c79e04d2dd44f6ad8d"
       ],
       "layout": "IPY_MODEL_7c5ff87eed684fdd9d1d3bb2aa839845",
       "tabbable": null,
       "tooltip": null
      }
     },
     "0bf8279b0e7047bdbfbfb372e95c50f4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1764a379b2fe4f2889c548fe6fffc7e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1daae7981a06468e967e009c1f1bee2b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2271eeb09cca44c3931d793e662f4a3c",
       "placeholder": "​",
       "style": "IPY_MODEL_03e02ff20fbd40f4be4736b5147aaf31",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "212a1f03e85a4ded9dac8b88d4a41efc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "21941795a8794e86959226e4b0d7da46": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2bd0b251cd9b4e1ea1201fadcbacc1f0",
       "placeholder": "​",
       "style": "IPY_MODEL_4defbe866762447a85a4f13e6135e16f",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors: 100%"
      }
     },
     "2271eeb09cca44c3931d793e662f4a3c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2491f6d77f5448ad81d7240a2d4fcb1b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "25b5b82acb5e4599bb49fbb8143ec0a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2bd0b251cd9b4e1ea1201fadcbacc1f0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "30ba63142c304a9ba1ea31acd494060e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "39bc1105c3534046880ee6125c4977fb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b7e5f8488a91414aa0da5a8a37207f5f",
       "placeholder": "​",
       "style": "IPY_MODEL_884d5386574e42a28eb012706ad127fa",
       "tabbable": null,
       "tooltip": null,
       "value": " 2.00/2.00 [00:00&lt;00:00, 166B/s]"
      }
     },
     "3eec86f35a2144f2a2255834943d00e9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "45258ecd8313421e8649d081091e664a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1daae7981a06468e967e009c1f1bee2b",
        "IPY_MODEL_c2d019d5a2a64a70838db1057f2a4ce8",
        "IPY_MODEL_39bc1105c3534046880ee6125c4977fb"
       ],
       "layout": "IPY_MODEL_0bf8279b0e7047bdbfbfb372e95c50f4",
       "tabbable": null,
       "tooltip": null
      }
     },
     "45f19db540e84708b09a639da4ddb4da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4a044b2cd186406a993f28ca4b96ab25": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4ca269ab37d3493fbf5f681b309e3c95": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f690f5295f3c44e891c40529a312a495",
       "placeholder": "​",
       "style": "IPY_MODEL_7cfa7ffa0a5a413baeec7e8616ce90f9",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.53k/1.53k [00:00&lt;00:00, 163kB/s]"
      }
     },
     "4cfa4505dbeb409cb28026e738e4bc24": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fb5c757468a349ebbf566c5db5f5ec5f",
       "placeholder": "​",
       "style": "IPY_MODEL_4a044b2cd186406a993f28ca4b96ab25",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json: 100%"
      }
     },
     "4defbe866762447a85a4f13e6135e16f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "50c7a26b070941d996e32a51e8b1fd03": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5faa53ef5fc04a6dbe5aee459459270c",
        "IPY_MODEL_5989812376e543298845dac8e9076f74",
        "IPY_MODEL_b63d772a08b04351a607ce641f7a526b"
       ],
       "layout": "IPY_MODEL_81fa9a10851d4bc8a57743daea09d57b",
       "tabbable": null,
       "tooltip": null
      }
     },
     "53d80e6032db4f3ca2f2453176e34146": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5989812376e543298845dac8e9076f74": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_53d80e6032db4f3ca2f2453176e34146",
       "max": 229167,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5b94fe19757849f789a9369e2e4c5dd1",
       "tabbable": null,
       "tooltip": null,
       "value": 229167
      }
     },
     "5b94fe19757849f789a9369e2e4c5dd1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5faa53ef5fc04a6dbe5aee459459270c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f4fe944a1e334110bf7e2685174dd916",
       "placeholder": "​",
       "style": "IPY_MODEL_30ba63142c304a9ba1ea31acd494060e",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: 100%"
      }
     },
     "6553dfe8e9ee476fa33b9ee2607a2710": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "70694065854144fc9090a877129dfefb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "71563a83051346e6b85677a6ff9e656d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7c3151b028cb4b449673befe8ead4c21": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7c5ff87eed684fdd9d1d3bb2aa839845": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7cfa7ffa0a5a413baeec7e8616ce90f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7e25c5f295e847c79e04d2dd44f6ad8d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_acfa4bfd0c734eef8365fff445bd5298",
       "placeholder": "​",
       "style": "IPY_MODEL_70694065854144fc9090a877129dfefb",
       "tabbable": null,
       "tooltip": null,
       "value": " 112/112 [00:00&lt;00:00, 12.1kB/s]"
      }
     },
     "81fa9a10851d4bc8a57743daea09d57b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "884d5386574e42a28eb012706ad127fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "895ead77533e482ba0490dd15d0327b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c2ef62ae437e4d18994c8a384c1dd96e",
       "placeholder": "​",
       "style": "IPY_MODEL_2491f6d77f5448ad81d7240a2d4fcb1b",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "962c997ba74a4db4a273e83cafa8c0fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_895ead77533e482ba0490dd15d0327b4",
        "IPY_MODEL_bb813105ad494e9996b90a6ab8692bec",
        "IPY_MODEL_4ca269ab37d3493fbf5f681b309e3c95"
       ],
       "layout": "IPY_MODEL_6553dfe8e9ee476fa33b9ee2607a2710",
       "tabbable": null,
       "tooltip": null
      }
     },
     "9f0fdfed77e3468e8c406ae50ec6fbf8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a147bb41e39441008cd869169b0b70dc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "acfa4bfd0c734eef8365fff445bd5298": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b63d772a08b04351a607ce641f7a526b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_71563a83051346e6b85677a6ff9e656d",
       "placeholder": "​",
       "style": "IPY_MODEL_d2223700d9994ad2950db1ab4a88e6b2",
       "tabbable": null,
       "tooltip": null,
       "value": " 229k/229k [00:00&lt;00:00, 5.13MB/s]"
      }
     },
     "b6e89ee94b2a4f3bbc9698b57e9d3fcf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b7e5f8488a91414aa0da5a8a37207f5f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bb3af0c636d246659accbdfcedcf5e64": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b6e89ee94b2a4f3bbc9698b57e9d3fcf",
       "placeholder": "​",
       "style": "IPY_MODEL_d3207c964bdc4eb7a2717eef066befa1",
       "tabbable": null,
       "tooltip": null,
       "value": " 498M/498M [00:02&lt;00:00, 228MB/s]"
      }
     },
     "bb813105ad494e9996b90a6ab8692bec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a147bb41e39441008cd869169b0b70dc",
       "max": 1534,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_25b5b82acb5e4599bb49fbb8143ec0a4",
       "tabbable": null,
       "tooltip": null,
       "value": 1534
      }
     },
     "c2d019d5a2a64a70838db1057f2a4ce8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9f0fdfed77e3468e8c406ae50ec6fbf8",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_45f19db540e84708b09a639da4ddb4da",
       "tabbable": null,
       "tooltip": null,
       "value": 2
      }
     },
     "c2ef62ae437e4d18994c8a384c1dd96e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cdd3acc182224dd3bfd3306121353b7f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7c3151b028cb4b449673befe8ead4c21",
       "max": 497787752,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_212a1f03e85a4ded9dac8b88d4a41efc",
       "tabbable": null,
       "tooltip": null,
       "value": 497787752
      }
     },
     "d2223700d9994ad2950db1ab4a88e6b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d3207c964bdc4eb7a2717eef066befa1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f4fe944a1e334110bf7e2685174dd916": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f690f5295f3c44e891c40529a312a495": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f7bd8e2f610f46cca4100de5b5ce6d07": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3eec86f35a2144f2a2255834943d00e9",
       "max": 112,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1764a379b2fe4f2889c548fe6fffc7e0",
       "tabbable": null,
       "tooltip": null,
       "value": 112
      }
     },
     "fb5c757468a349ebbf566c5db5f5ec5f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
