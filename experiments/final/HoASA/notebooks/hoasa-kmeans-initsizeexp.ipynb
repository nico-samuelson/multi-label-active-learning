{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d5bfad3",
   "metadata": {
    "papermill": {
     "duration": 0.012607,
     "end_time": "2025-05-17T15:04:48.535893",
     "exception": false,
     "start_time": "2025-05-17T15:04:48.523286",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42641651",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T15:04:48.559665Z",
     "iopub.status.busy": "2025-05-17T15:04:48.559338Z",
     "iopub.status.idle": "2025-05-17T15:05:12.708405Z",
     "shell.execute_reply": "2025-05-17T15:05:12.707448Z"
    },
    "papermill": {
     "duration": 24.16314,
     "end_time": "2025-05-17T15:05:12.710373",
     "exception": false,
     "start_time": "2025-05-17T15:04:48.547233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f43beb8",
   "metadata": {
    "papermill": {
     "duration": 0.011234,
     "end_time": "2025-05-17T15:05:12.733090",
     "exception": false,
     "start_time": "2025-05-17T15:05:12.721856",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "003f9a1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T15:05:12.757008Z",
     "iopub.status.busy": "2025-05-17T15:05:12.756437Z",
     "iopub.status.idle": "2025-05-17T15:05:12.760808Z",
     "shell.execute_reply": "2025-05-17T15:05:12.759800Z"
    },
    "papermill": {
     "duration": 0.017879,
     "end_time": "2025-05-17T15:05:12.762318",
     "exception": false,
     "start_time": "2025-05-17T15:05:12.744439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6669bc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T15:05:12.785377Z",
     "iopub.status.busy": "2025-05-17T15:05:12.785106Z",
     "iopub.status.idle": "2025-05-17T15:05:12.789236Z",
     "shell.execute_reply": "2025-05-17T15:05:12.788555Z"
    },
    "papermill": {
     "duration": 0.017193,
     "end_time": "2025-05-17T15:05:12.790583",
     "exception": false,
     "start_time": "2025-05-17T15:05:12.773390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/working/results') == False:\n",
    "    os.mkdir('/kaggle/working/results')\n",
    "\n",
    "if os.path.exists('/kaggle/working/acquired_data') == False:\n",
    "    os.mkdir('/kaggle/working/acquired_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41172ed5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T15:05:12.813391Z",
     "iopub.status.busy": "2025-05-17T15:05:12.813096Z",
     "iopub.status.idle": "2025-05-17T15:05:12.822076Z",
     "shell.execute_reply": "2025-05-17T15:05:12.821376Z"
    },
    "papermill": {
     "duration": 0.021925,
     "end_time": "2025-05-17T15:05:12.823460",
     "exception": false,
     "start_time": "2025-05-17T15:05:12.801535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71d5076",
   "metadata": {
    "papermill": {
     "duration": 0.010712,
     "end_time": "2025-05-17T15:05:12.846009",
     "exception": false,
     "start_time": "2025-05-17T15:05:12.835297",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "058a9933",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T15:05:12.868786Z",
     "iopub.status.busy": "2025-05-17T15:05:12.868473Z",
     "iopub.status.idle": "2025-05-17T15:05:12.931715Z",
     "shell.execute_reply": "2025-05-17T15:05:12.930078Z"
    },
    "papermill": {
     "duration": 0.076965,
     "end_time": "2025-05-17T15:05:12.933712",
     "exception": false,
     "start_time": "2025-05-17T15:05:12.856747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Shared resources\n",
    "aspect_accuracies = manager.list()\n",
    "aspect_f1_micros = manager.list()\n",
    "aspect_f1_macros = manager.list()\n",
    "sentiment_accuracies = manager.list()\n",
    "sentiment_f1_micros = manager.list()\n",
    "sentiment_f1_macros = manager.list()\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "\n",
    "# Non shared resources\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "sequence_length = 48\n",
    "\n",
    "aspect_list = ['ac', 'air_panas', 'bau', 'general', 'kebersihan', 'linen', 'service', 'sunrise_meal', 'tv', 'wifi']\n",
    "aspect_mapping = {'ac': 0, 'air_panas': 1, 'bau': 2, 'general': 3, 'kebersihan': 4, 'linen': 5, 'service': 6, 'sunrise_meal': 7, 'tv': 8, 'wifi': 9}\n",
    "label_mapping = {\"neg\": 0, \"neut\": 1, 'neg_pos': 1, 'pos': 2}\n",
    "ignored_keys = ['labels', 'ori_text', 'ori_label', 'ori_indices', 'aspect']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54d6ff0",
   "metadata": {
    "papermill": {
     "duration": 0.011364,
     "end_time": "2025-05-17T15:05:12.957531",
     "exception": false,
     "start_time": "2025-05-17T15:05:12.946167",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6c9e842",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T15:05:12.982040Z",
     "iopub.status.busy": "2025-05-17T15:05:12.981690Z",
     "iopub.status.idle": "2025-05-17T15:05:13.077481Z",
     "shell.execute_reply": "2025-05-17T15:05:13.076479Z"
    },
    "papermill": {
     "duration": 0.110127,
     "end_time": "2025-05-17T15:05:13.079182",
     "exception": false,
     "start_time": "2025-05-17T15:05:12.969055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>ac</th>\n",
       "      <th>air_panas</th>\n",
       "      <th>bau</th>\n",
       "      <th>general</th>\n",
       "      <th>kebersihan</th>\n",
       "      <th>linen</th>\n",
       "      <th>service</th>\n",
       "      <th>sunrise_meal</th>\n",
       "      <th>tv</th>\n",
       "      <th>wifi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kebersihan kurang...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sangat mengecewakan... hotel bad image, kebers...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tempat nyaman bersih tapi tv terlalu tinggi ti...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>pos</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>semuanya bagus sesuai profile,dan harga promo ...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>pos</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tempat tidur sangat keras, bantal besar dan ke...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review    ac air_panas   bau  \\\n",
       "0                               kebersihan kurang...  neut      neut  neut   \n",
       "1  sangat mengecewakan... hotel bad image, kebers...  neut      neut  neut   \n",
       "2  Tempat nyaman bersih tapi tv terlalu tinggi ti...  neut      neut  neut   \n",
       "3  semuanya bagus sesuai profile,dan harga promo ...  neut       neg  neut   \n",
       "4  Tempat tidur sangat keras, bantal besar dan ke...   neg       neg  neut   \n",
       "\n",
       "  general kebersihan linen service sunrise_meal    tv  wifi  \n",
       "0    neut        neg  neut    neut         neut  neut  neut  \n",
       "1    neut        neg  neut    neut         neut  neut  neut  \n",
       "2    neut        pos  neut    neut         neut   neg  neut  \n",
       "3     pos       neut  neut    neut         neut  neut  neut  \n",
       "4    neut       neut   neg    neut         neut  neut  neut  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/hoasa-dataset/train_preprocess.csv', encoding='latin-1')\n",
    "val_data = pd.read_csv('/kaggle/input/hoasa-dataset/valid_preprocess.csv', encoding='latin-1')\n",
    "test_data = pd.read_csv('/kaggle/input/hoasa-dataset/test_preprocess.csv', encoding='latin-1')\n",
    "\n",
    "data = pd.concat([train_data, val_data, test_data], ignore_index=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "353e477f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T15:05:13.103377Z",
     "iopub.status.busy": "2025-05-17T15:05:13.103120Z",
     "iopub.status.idle": "2025-05-17T15:05:13.111370Z",
     "shell.execute_reply": "2025-05-17T15:05:13.110636Z"
    },
    "papermill": {
     "duration": 0.021261,
     "end_time": "2025-05-17T15:05:13.112761",
     "exception": false,
     "start_time": "2025-05-17T15:05:13.091500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d242618",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T15:05:13.135801Z",
     "iopub.status.busy": "2025-05-17T15:05:13.135557Z",
     "iopub.status.idle": "2025-05-17T15:05:13.147720Z",
     "shell.execute_reply": "2025-05-17T15:05:13.146684Z"
    },
    "papermill": {
     "duration": 0.025252,
     "end_time": "2025-05-17T15:05:13.149121",
     "exception": false,
     "start_time": "2025-05-17T15:05:13.123869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2283,) (2283, 10)\n",
      "(571,) (571, 10)\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_data.columns[1:]\n",
    "val_labels = val_data.columns[1:]\n",
    "\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['review'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['review'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464dce72",
   "metadata": {
    "papermill": {
     "duration": 0.011145,
     "end_time": "2025-05-17T15:05:13.171816",
     "exception": false,
     "start_time": "2025-05-17T15:05:13.160671",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BUILD DATASET & DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b936dc21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T15:05:13.196368Z",
     "iopub.status.busy": "2025-05-17T15:05:13.195990Z",
     "iopub.status.idle": "2025-05-17T15:05:13.203187Z",
     "shell.execute_reply": "2025-05-17T15:05:13.202246Z"
    },
    "papermill": {
     "duration": 0.021099,
     "end_time": "2025-05-17T15:05:13.204681",
     "exception": false,
     "start_time": "2025-05-17T15:05:13.183582",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AspectDetectionDataset(Dataset):\n",
    "    def __init__(self, texts, labels, label_mapping, tokenizer, max_length=sequence_length, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        \n",
    "        original_labels = [self.label_mapping[label] for label in self.labels[idx]]\n",
    "        encoded_labels = [1 if label == 1 else 0 for label in original_labels]\n",
    "        \n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['ori_indices'] = idx\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(original_labels, dtype=torch.float)\n",
    "        item['labels'] = torch.tensor(encoded_labels, dtype=torch.float if self.use_float else torch.long)\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30ef0793",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T15:05:13.228870Z",
     "iopub.status.busy": "2025-05-17T15:05:13.228586Z",
     "iopub.status.idle": "2025-05-17T15:05:13.236357Z",
     "shell.execute_reply": "2025-05-17T15:05:13.235586Z"
    },
    "papermill": {
     "duration": 0.021514,
     "end_time": "2025-05-17T15:05:13.237780",
     "exception": false,
     "start_time": "2025-05-17T15:05:13.216266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentAnalysisDataset(Dataset):\n",
    "    def __init__(self, texts, labels, aspects, indices, label_mapping, tokenizer, max_length=96, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.aspects = aspects\n",
    "        self.indices = indices\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = aspect_token + ' ' + self.aspects[idx] + ' ' + review_token + ' ' + self.texts[idx] \n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "\n",
    "        if isinstance(self.labels[idx], str):\n",
    "            self.labels[idx] = self.label_mapping[self.labels[idx]]\n",
    "        elif torch.is_tensor(self.labels[idx]):\n",
    "            self.labels[idx] = int(self.labels[idx].item())\n",
    "\n",
    "        encoded_label = 1 if self.labels[idx] == 2 else self.labels[idx]\n",
    "        one_hot_label = F.one_hot(torch.tensor(encoded_label, dtype=torch.long), num_classes=2).float()\n",
    "\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['aspect'] = self.aspects[idx]\n",
    "        item['labels'] = one_hot_label\n",
    "        item['ori_indices'] = self.indices[idx]\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2af94eaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T15:05:13.261262Z",
     "iopub.status.busy": "2025-05-17T15:05:13.260996Z",
     "iopub.status.idle": "2025-05-17T15:05:14.357172Z",
     "shell.execute_reply": "2025-05-17T15:05:14.356362Z"
    },
    "papermill": {
     "duration": 1.109821,
     "end_time": "2025-05-17T15:05:14.358881",
     "exception": false,
     "start_time": "2025-05-17T15:05:13.249060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34bdf3c559fb4beca86d5b25674f598a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "168fd7083cb345e984af4cfa477d31c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d21ed71bc74059b660a9862566621a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "785170004ee742dd9872340bc243db1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "review_token = '[REVIEW]'\n",
    "aspect_token = '[ASPECT]'\n",
    "special_tokens_dict = {'additional_special_tokens': [review_token, aspect_token]}\n",
    "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "003c824f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T15:05:14.384303Z",
     "iopub.status.busy": "2025-05-17T15:05:14.383962Z",
     "iopub.status.idle": "2025-05-17T15:05:14.388712Z",
     "shell.execute_reply": "2025-05-17T15:05:14.388014Z"
    },
    "papermill": {
     "duration": 0.018749,
     "end_time": "2025-05-17T15:05:14.390241",
     "exception": false,
     "start_time": "2025-05-17T15:05:14.371492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_aspect_dataset(X_train, y_train, X_val, y_val, sequence_length, num_workers=4):\n",
    "    train_dataset = AspectDetectionDataset(X_train, y_train, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = AspectDetectionDataset(X_val, y_val, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b705b644",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T15:05:14.414994Z",
     "iopub.status.busy": "2025-05-17T15:05:14.414758Z",
     "iopub.status.idle": "2025-05-17T15:05:14.425830Z",
     "shell.execute_reply": "2025-05-17T15:05:14.425131Z"
    },
    "papermill": {
     "duration": 0.02508,
     "end_time": "2025-05-17T15:05:14.427277",
     "exception": false,
     "start_time": "2025-05-17T15:05:14.402197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_sentiment_dataset(device, train_dataset, val_dataset, aspect_detection_model, tokenizer, max_length=sequence_length):\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    aspect_detection_model.to(device)\n",
    "    aspect_detection_model.eval()\n",
    "\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    train_aspects = []\n",
    "    train_indices = []\n",
    "\n",
    "    val_data = []\n",
    "    val_labels = []\n",
    "    val_aspects = []\n",
    "    val_indices = []\n",
    "\n",
    "    # Transform train set\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        train_aspects.append(aspect_list[j])\n",
    "                        train_data.append(batch['ori_text'][i])\n",
    "                        train_labels.append(batch['ori_label'][i][j])\n",
    "                        train_indices.append(batch['ori_indices'][i])\n",
    "            \n",
    "        # Transform validation set\n",
    "        for batch in val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        val_aspects.append(aspect_list[j])\n",
    "                        val_data.append(batch['ori_text'][i])\n",
    "                        val_labels.append(batch['ori_label'][i][j])\n",
    "                        val_indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    train_dataset = SentimentAnalysisDataset(train_data, train_labels, train_aspects, train_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "    val_dataset = SentimentAnalysisDataset(val_data, val_labels, val_aspects, val_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da205c67",
   "metadata": {
    "papermill": {
     "duration": 0.011465,
     "end_time": "2025-05-17T15:05:14.450978",
     "exception": false,
     "start_time": "2025-05-17T15:05:14.439513",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2324eca8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T15:05:14.475722Z",
     "iopub.status.busy": "2025-05-17T15:05:14.475446Z",
     "iopub.status.idle": "2025-05-17T15:05:14.479550Z",
     "shell.execute_reply": "2025-05-17T15:05:14.478849Z"
    },
    "papermill": {
     "duration": 0.018079,
     "end_time": "2025-05-17T15:05:14.480774",
     "exception": false,
     "start_time": "2025-05-17T15:05:14.462695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6d33dd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T15:05:14.506174Z",
     "iopub.status.busy": "2025-05-17T15:05:14.505872Z",
     "iopub.status.idle": "2025-05-17T15:05:14.510992Z",
     "shell.execute_reply": "2025-05-17T15:05:14.510350Z"
    },
    "papermill": {
     "duration": 0.019177,
     "end_time": "2025-05-17T15:05:14.512432",
     "exception": false,
     "start_time": "2025-05-17T15:05:14.493255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p, label, classes):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        labels=label,\n",
    "        target_names=classes,\n",
    "        zero_division=0\n",
    "    ) \n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "843b986a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T15:05:14.540120Z",
     "iopub.status.busy": "2025-05-17T15:05:14.539846Z",
     "iopub.status.idle": "2025-05-17T15:05:14.547161Z",
     "shell.execute_reply": "2025-05-17T15:05:14.546280Z"
    },
    "papermill": {
     "duration": 0.02185,
     "end_time": "2025-05-17T15:05:14.548419",
     "exception": false,
     "start_time": "2025-05-17T15:05:14.526569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics_overall(p, classes):\n",
    "    preds = torch.tensor(p.predictions)\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Ensure it's in the correct shape\n",
    "    if preds.shape != labels.shape:\n",
    "        raise ValueError(\"Shape mismatch: predictions and labels must have the same shape.\")\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Compute per-label (column-wise) precision, recall, F1\n",
    "    precision_list, recall_list, f1_micro_list, f1_macro_list = [], [], [], []\n",
    "    \n",
    "    for i in range(labels.shape[1]):  # Loop through each column (multi-output)\n",
    "        prec, rec, f1_micro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='micro', zero_division=0\n",
    "        )\n",
    "        _, _, f1_macro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='macro', zero_division=0\n",
    "        )\n",
    "\n",
    "        precision_list.append(prec)\n",
    "        recall_list.append(rec)\n",
    "        f1_micro_list.append(f1_micro)\n",
    "        f1_macro_list.append(f1_macro)\n",
    "\n",
    "    # Compute average metrics across all outputs\n",
    "    precision = sum(precision_list) / len(precision_list)\n",
    "    recall = sum(recall_list) / len(recall_list)\n",
    "    f1_micro = sum(f1_micro_list) / len(f1_micro_list)\n",
    "    f1_macro = sum(f1_macro_list) / len(f1_macro_list)\n",
    "\n",
    "    # Generate classification report per output\n",
    "    reports = [classification_report(labels[:, i], preds[:, i], target_names=classes, zero_division=0) for i in range(labels.shape[1])]\n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'reports': reports  # Returns list of reports, one for each output label\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "076c7357",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T15:05:14.573828Z",
     "iopub.status.busy": "2025-05-17T15:05:14.573560Z",
     "iopub.status.idle": "2025-05-17T15:05:14.604469Z",
     "shell.execute_reply": "2025-05-17T15:05:14.603466Z"
    },
    "papermill": {
     "duration": 0.04552,
     "end_time": "2025-05-17T15:05:14.606125",
     "exception": false,
     "start_time": "2025-05-17T15:05:14.560605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, aspect_metrics, sentiment_metrics, metrics, trials, seed, filename):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=len(train_labels),\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    )\n",
    "\n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in aspect_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    aspect_optimizer = torch.optim.AdamW(aspect_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Define DataLoaders\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    aspect_train_loader, aspect_val_loader, aspect_train_dataset, aspect_val_dataset = build_aspect_dataset(current_X_train, current_y_train, X_val, y_val, sequence_length)\n",
    "\n",
    "    # Prepare everything with Accelerator\n",
    "    aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader = accelerator.prepare(\n",
    "        aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader\n",
    "    )\n",
    "\n",
    "    nearest_cp = current_train_size\n",
    "    if nearest_cp not in checkpoints:\n",
    "        for cp in checkpoints:\n",
    "            if cp > current_train_size:\n",
    "                nearest_cp = cp\n",
    "                break\n",
    "    percentage = math.ceil(nearest_cp / total_data * 100)\n",
    "\n",
    "    aspect_result = None\n",
    "    start_time = time.time()\n",
    "\n",
    "    # ASPECT DETECTION\n",
    "    accelerator.print(\"ASPECT DETECTION\")\n",
    "    for epoch in range(epochs):\n",
    "        aspect_model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in aspect_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            aspect_optimizer.zero_grad()\n",
    "            outputs = aspect_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            aspect_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        aspect_model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in aspect_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = aspect_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}),\n",
    "            None,\n",
    "            aspect_list,\n",
    "        )\n",
    "\n",
    "        if aspect_result is None or result['f1_micro'] >= aspect_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(aspect_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'{filename}-aspect-{trials + 1}-model-{percentage}',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "            aspect_result = result\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(aspect_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    accelerator.print(f\"\\nAspect detection accuracy: {round(aspect_result['accuracy'], 4)}, F1 Micro: {round(aspect_result['f1_micro'], 4)}, F1 Macro: {round(aspect_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(aspect_result['report'])\n",
    "\n",
    "    best_aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{trials + 1}-model-{percentage}')\n",
    "    best_aspect_model = accelerator.prepare(best_aspect_model)\n",
    "\n",
    "    # SENTIMENT ANALYSIS ON NON NEUTRAL ASPECTS\n",
    "    accelerator.print(\"--------------------------------------------------\")\n",
    "    accelerator.print(\"SENTIMENT ANALYSIS\")\n",
    "\n",
    "    sentiment_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=2,\n",
    "    )\n",
    "    sentiment_optimizer = torch.optim.AdamW(sentiment_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "\n",
    "    for name, param in sentiment_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    sentiment_train_loader, sentiment_val_loader, sentiment_train_dataset, sentiment_val_dataset = build_sentiment_dataset(\n",
    "        device, aspect_train_dataset, aspect_val_dataset, best_aspect_model, tokenizer, max_length=sequence_length\n",
    "    )\n",
    "    sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader = accelerator.prepare(\n",
    "        sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader\n",
    "    )\n",
    "    sentiment_result = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        sentiment_model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch in sentiment_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            sentiment_optimizer.zero_grad()\n",
    "            outputs = sentiment_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            sentiment_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        sentiment_model.eval()\n",
    "        sentiment_val_outputs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in sentiment_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                \n",
    "                outputs = sentiment_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                for i in range(len(preds)):\n",
    "                    val_output = {\n",
    "                        'label': batch['labels'][i],\n",
    "                        'aspect': batch['aspect'][i],\n",
    "                        'ori_indices': batch['ori_indices'][i],\n",
    "                        'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                    }\n",
    "                    sentiment_val_outputs.append(val_output)\n",
    "\n",
    "        sentiment_val_outputs = accelerator.gather_for_metrics(sentiment_val_outputs)\n",
    "        unique_val_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_val_outputs}\n",
    "        sentiment_val_outputs = list(unique_val_outputs.values())\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': [item['pred'] for item in sentiment_val_outputs], 'label_ids': [np.argmax(item['label'].cpu().numpy()) for item in sentiment_val_outputs]}),\n",
    "            [0, 1],\n",
    "            ['negative', 'positive']\n",
    "        )\n",
    "\n",
    "        if sentiment_result is None or result['f1_micro'] >= sentiment_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            sentiment_result = result\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(sentiment_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                 f'{filename}-sentiment-{trials + 1}-model-{percentage}',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(sentiment_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "\n",
    "    accelerator.print(f\"\\nSentiment analysis accuracy: {round(sentiment_result['accuracy'], 4)}, F1 Micro: {round(sentiment_result['f1_micro'], 4)}, F1 Macro: {round(sentiment_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(sentiment_result['report'])\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    best_sentiment_model = BertForSequenceClassification.from_pretrained( f'{filename}-sentiment-{trials + 1}-model-{percentage}')\n",
    "    best_sentiment_model = accelerator.prepare(best_sentiment_model)\n",
    "\n",
    "    # Compute overall metrics\n",
    "    aspect_labels = []\n",
    "    aspect_indices = []\n",
    "    aspect_preds = []\n",
    "\n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = []\n",
    "    \n",
    "    best_aspect_model.eval()\n",
    "    best_sentiment_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in aspect_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = best_aspect_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            aspect_indices.append(accelerator.gather(batch['ori_indices']))\n",
    "            aspect_labels.append(accelerator.gather(batch['ori_label']))\n",
    "            aspect_preds.append(accelerator.gather(preds))\n",
    "\n",
    "        aspect_indices = torch.cat(aspect_indices).cpu().numpy()\n",
    "        aspect_labels = torch.cat(aspect_labels).cpu().numpy()\n",
    "        aspect_preds = torch.cat(aspect_preds).cpu().numpy()\n",
    "\n",
    "        accelerator.wait_for_everyone()\n",
    "        aspect_outputs = [\n",
    "            {'ori_indices': aspect_indices[i], \n",
    "             'ori_labels': aspect_labels[i], \n",
    "             'pred': aspect_preds[i]}\n",
    "            for i in range(len(aspect_preds))\n",
    "        ]\n",
    "        aspect_outputs = {x['ori_indices'].item(): x for x in aspect_outputs}\n",
    "    \n",
    "        for batch in sentiment_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = best_sentiment_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "    \n",
    "            for i in range(len(preds)):\n",
    "                output = {\n",
    "                    'aspect': batch['aspect'][i],\n",
    "                    'ori_indices': batch['ori_indices'][i],\n",
    "                    'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                }\n",
    "                sentiment_outputs.append(output)\n",
    "\n",
    "        sentiment_outputs = accelerator.gather_for_metrics(sentiment_outputs)\n",
    "        sentiment_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_outputs}\n",
    "\n",
    "    # Replcae non neutral aspect to its predicted sentiment\n",
    "    accelerator.wait_for_everyone()\n",
    "    if accelerator.is_main_process:\n",
    "        i = -1\n",
    "        for (ori_index, aspect), value in sentiment_outputs.items():\n",
    "            aspect = aspect_mapping[aspect]\n",
    "            aspect_outputs[ori_index]['pred'][aspect] = 2 if value['pred'] == 1.0 else value['pred']\n",
    "\n",
    "        result = compute_metrics_overall(\n",
    "            type('EvalOutput', (object,), {'predictions': [output['pred'] for output in aspect_outputs.values()], 'label_ids': [output['ori_labels'] for output in aspect_outputs.values()]}),\n",
    "            ['negative', 'neutral', 'positive'],\n",
    "        )\n",
    "\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        accelerator.print(f\"Iteration {current_train_size}: Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        for i in range(len(train_labels)):\n",
    "            accelerator.print(f\"Aspect {aspect_list[i]} report:\")\n",
    "            accelerator.print(result['reports'][i])\n",
    "       \n",
    "        \n",
    "        aspect_metrics[0].append(aspect_result['accuracy'])\n",
    "        aspect_metrics[1].append(aspect_result['f1_micro'])\n",
    "        aspect_metrics[2].append(aspect_result['f1_macro'])\n",
    "        sentiment_metrics[0].append(sentiment_result['accuracy'])\n",
    "        sentiment_metrics[1].append(sentiment_result['f1_micro'])\n",
    "        sentiment_metrics[2].append(sentiment_result['f1_macro'])\n",
    "        metrics[0].append(current_train_size)\n",
    "        metrics[1].append(result['accuracy'])\n",
    "        metrics[2].append(result['f1_micro'])\n",
    "        metrics[3].append(result['f1_macro'])\n",
    "        \n",
    "    accelerator.print(f\"Total train time: {duration} s\")\n",
    "    accelerator.end_training()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31649047",
   "metadata": {
    "papermill": {
     "duration": 0.011605,
     "end_time": "2025-05-17T15:05:14.630991",
     "exception": false,
     "start_time": "2025-05-17T15:05:14.619386",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PLOT THE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57a4f950",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T15:05:14.655968Z",
     "iopub.status.busy": "2025-05-17T15:05:14.655556Z",
     "iopub.status.idle": "2025-05-17T15:05:14.661798Z",
     "shell.execute_reply": "2025-05-17T15:05:14.661086Z"
    },
    "papermill": {
     "duration": 0.020359,
     "end_time": "2025-05-17T15:05:14.663069",
     "exception": false,
     "start_time": "2025-05-17T15:05:14.642710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b72e536",
   "metadata": {
    "papermill": {
     "duration": 0.011911,
     "end_time": "2025-05-17T15:05:14.687131",
     "exception": false,
     "start_time": "2025-05-17T15:05:14.675220",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QUERY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1098c3d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T15:05:14.712375Z",
     "iopub.status.busy": "2025-05-17T15:05:14.712128Z",
     "iopub.status.idle": "2025-05-17T15:05:14.736706Z",
     "shell.execute_reply": "2025-05-17T15:05:14.736066Z"
    },
    "papermill": {
     "duration": 0.038932,
     "end_time": "2025-05-17T15:05:14.738126",
     "exception": false,
     "start_time": "2025-05-17T15:05:14.699194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kmeans_clustering_sampling(aspect_model, sentiment_model, X_pool, train_indices, remaining_indices, sampling_dur, new_samples, trials, filename, n_clusters=min_increment):\n",
    "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model.to(device)\n",
    "    aspect_model.eval()\n",
    "    sentiment_model.to(device)\n",
    "    sentiment_model.eval()\n",
    "\n",
    "    current_train_size = len(train_indices)\n",
    "    aspect_dataset = AspectDetectionDataset(\n",
    "        X_pool, \n",
    "        [['neut' for i in range(len(train_labels))] for x in range(len(X_pool))], \n",
    "        label_mapping, \n",
    "        tokenizer, \n",
    "        max_length=sequence_length\n",
    "    )\n",
    "    aspect_loader = DataLoader(\n",
    "        aspect_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = {}\n",
    "\n",
    "    aspects = []\n",
    "    data = []\n",
    "    labels = []\n",
    "    indices = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Pass through aspect detction model\n",
    "    for batch in aspect_loader:\n",
    "        token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "        input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "        attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = aspect_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).logits\n",
    "            embeddings = aspect_model.base_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "\n",
    "        for i in range(len(outputs)):\n",
    "            aspect_outputs[batch['ori_indices'][i].item()] = embeddings.last_hidden_state[i].mean(dim=1).cpu().numpy()\n",
    "            \n",
    "            for j in range(len(outputs[i])):\n",
    "                if int(outputs[i][j].round()) != 1:\n",
    "                    aspects.append(aspect_list[j])\n",
    "                    data.append(batch['ori_text'][i])\n",
    "                    labels.append(batch['ori_label'][i][j])\n",
    "                    indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    if len(data) > 0:\n",
    "        sentiment_dataset = SentimentAnalysisDataset(data, labels, aspects, indices, label_mapping, tokenizer, max_length=sequence_length)\n",
    "        sentiment_loader = torch.utils.data.DataLoader(\n",
    "            sentiment_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4,\n",
    "        )\n",
    "    \n",
    "        # Pass through sentiment analysis model\n",
    "        for batch in sentiment_loader:\n",
    "            token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "            input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "            attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                outputs = sentiment_model.base_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "    \n",
    "            for i in range(len(outputs.last_hidden_state)):\n",
    "                ori_index = batch['ori_indices'][i].item()\n",
    "                if ori_index in sentiment_outputs.keys():\n",
    "                    sentiment_outputs[ori_index].append(outputs.last_hidden_state[i].mean(dim=1).cpu().numpy())\n",
    "                else:\n",
    "                    sentiment_outputs[ori_index] = [outputs.last_hidden_state[i].mean(dim=1).cpu().numpy()]\n",
    "\n",
    "    for key, val in sentiment_outputs.items():\n",
    "        sentiment_outputs[key] = np.mean(val, axis=0)\n",
    "\n",
    "    collected_indices = set()  # Initialize set to store selected indices\n",
    "    thresholds = []\n",
    "\n",
    "    if accelerator.is_main_process:\n",
    "        aspect_outputs = dict(sorted(aspect_outputs.items()))\n",
    "\n",
    "        if len(data) > 0:\n",
    "            for key, val in sentiment_outputs.items():\n",
    "                aspect_outputs[key] = np.mean([val, aspect_outputs[key]], axis=0)\n",
    "\n",
    "        embeddings = np.array(list(aspect_outputs.values()))\n",
    "        target_samples = len(embeddings[:math.ceil(0.1 * len(embeddings))])\n",
    "    \n",
    "        # Check nearest checkpoint\n",
    "        nearest_cp = 0\n",
    "        arrived_at_cp = False\n",
    "        for cp in checkpoints:\n",
    "            if cp > current_train_size:\n",
    "                nearest_cp = cp\n",
    "                break\n",
    "                \n",
    "        # Determine number of maximum samples to be acquired\n",
    "        if target_samples <= n_clusters and n_clusters < nearest_cp - current_train_size:\n",
    "            target_samples = n_clusters\n",
    "        elif target_samples > n_clusters and target_samples < nearest_cp - current_train_size:\n",
    "            target_samples = target_samples\n",
    "        else:\n",
    "            arrived_at_cp = True\n",
    "            target_samples = nearest_cp - current_train_size\n",
    "\n",
    "        # No clustering needed when there's little data left\n",
    "        if current_train_size >= checkpoints[len(checkpoints)-1] - min_increment:\n",
    "            end_time = time.time()\n",
    "            duration = end_time - start_time\n",
    "            \n",
    "            temp = train_indices.copy()\n",
    "            temp.extend(remaining_indices)\n",
    "            \n",
    "            # Save acquired data up to checkpoint\n",
    "            acquired_data = pd.DataFrame({\n",
    "                'processed_text': [X_train[i] for i in temp],\n",
    "                'ac': [y_train[i][0] for i in temp],\n",
    "                'air_panas': [y_train[i][1] for i in temp],\n",
    "                'bau': [y_train[i][2] for i in temp],\n",
    "                'general': [y_train[i][3] for i in temp],\n",
    "                'kebersihan': [y_train[i][4] for i in temp],\n",
    "                'linen': [y_train[i][5] for i in temp],\n",
    "                'service': [y_train[i][6] for i in temp],\n",
    "                'sunrise_meal': [y_train[i][7] for i in temp],\n",
    "                'tv': [y_train[i][8] for i in temp],\n",
    "                'wifi': [y_train[i][9] for i in temp],\n",
    "            })\n",
    "            acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "\n",
    "            print(\"Nearest checkpoint:\", nearest_cp)\n",
    "            print(\"Acquired samples:\", len(remaining_indices))\n",
    "            print(f\"Sampling duration: {duration} seconds\")\n",
    "            \n",
    "            sampling_dur.append(duration)\n",
    "            for i in remaining_indices:\n",
    "                new_samples.append(i)\n",
    "        else:\n",
    "            # Cluster the data based on its embeddings\n",
    "            kmeans=KMeans(n_clusters=n_clusters, n_init=1)\n",
    "            kmeans.fit(embeddings)\n",
    "            \n",
    "            for cluster_id in range(n_clusters):\n",
    "                # Cluster center and indices of samples in the current cluster\n",
    "                cluster_center = kmeans.cluster_centers_[cluster_id]\n",
    "                cluster_indices = np.where(kmeans.labels_ == cluster_id)[0]\n",
    "            \n",
    "                if cluster_indices.size == 0:\n",
    "                    # Skip clusters with no members\n",
    "                    print(f\"Cluster {cluster_id} has no members, skipping.\")\n",
    "                    continue\n",
    "            \n",
    "                # Calculate distances of each point in the cluster from the cluster center\n",
    "                cluster_distances = np.linalg.norm(embeddings[cluster_indices] - cluster_center, axis=1)\n",
    "            \n",
    "                # Determine the local threshold (10th percentile of closest distances to cluster center)\n",
    "                local_threshold = np.percentile(cluster_distances, 90)\n",
    "                thresholds.append(local_threshold)\n",
    "            \n",
    "                below_threshold_indices = cluster_indices[cluster_distances >= local_threshold]\n",
    "                collected_indices.update(below_threshold_indices)\n",
    "\n",
    "            # To handle multiple points with same distance\n",
    "            if len(collected_indices) > target_samples:\n",
    "                collected_indices = np.array(list(collected_indices))\n",
    "                np.random.shuffle(collected_indices)\n",
    "                collected_indices = collected_indices[:target_samples]\n",
    "                \n",
    "            end_time = time.time() \n",
    "            duration = end_time - start_time \n",
    "    \n",
    "            if arrived_at_cp:\n",
    "                temp = train_indices.copy()\n",
    "                temp.extend(collected_indices)\n",
    "                \n",
    "                # Save acquired data up to checkpoint\n",
    "                acquired_data = pd.DataFrame({\n",
    "                    'processed_text': [X_train[i] for i in temp],\n",
    "                    'ac': [y_train[i][0] for i in temp],\n",
    "                    'air_panas': [y_train[i][1] for i in temp],\n",
    "                    'bau': [y_train[i][2] for i in temp],\n",
    "                    'general': [y_train[i][3] for i in temp],\n",
    "                    'kebersihan': [y_train[i][4] for i in temp],\n",
    "                    'linen': [y_train[i][5] for i in temp],\n",
    "                    'service': [y_train[i][6] for i in temp],\n",
    "                    'sunrise_meal': [y_train[i][7] for i in temp],\n",
    "                    'tv': [y_train[i][8] for i in temp],\n",
    "                    'wifi': [y_train[i][9] for i in temp],\n",
    "                })\n",
    "        \n",
    "                acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "            \n",
    "            print(\"Nearest checkpoint:\", nearest_cp)\n",
    "            print(\"Acquired samples:\", len(collected_indices))\n",
    "            print(f\"Sampling duration: {duration} seconds\")\n",
    "        \n",
    "            sampling_dur.append(duration)\n",
    "            for i in collected_indices:\n",
    "                new_samples.append(remaining_indices[i])\n",
    "\n",
    "        threshold_data = pd.DataFrame({\n",
    "            'Threshold': thresholds\n",
    "        })\n",
    "        threshold_data.to_csv(f\"results/{filename}-thresholds-{trials+1}-{current_train_size}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56573efc",
   "metadata": {
    "papermill": {
     "duration": 0.012188,
     "end_time": "2025-05-17T15:05:14.762883",
     "exception": false,
     "start_time": "2025-05-17T15:05:14.750695",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42dcf65a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T15:05:14.788158Z",
     "iopub.status.busy": "2025-05-17T15:05:14.787808Z",
     "iopub.status.idle": "2025-05-17T15:05:14.799237Z",
     "shell.execute_reply": "2025-05-17T15:05:14.798496Z"
    },
    "papermill": {
     "duration": 0.025849,
     "end_time": "2025-05-17T15:05:14.800609",
     "exception": false,
     "start_time": "2025-05-17T15:05:14.774760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i, init_size):\n",
    "    aspect_accuracies = manager.list()\n",
    "    aspect_f1_micros = manager.list()\n",
    "    aspect_f1_macros = manager.list()\n",
    "    sentiment_accuracies = manager.list()\n",
    "    sentiment_f1_micros = manager.list()\n",
    "    sentiment_f1_macros = manager.list()\n",
    "    accuracies = manager.list()\n",
    "    f1_micros = manager.list()\n",
    "    f1_macros = manager.list()\n",
    "    data_used = manager.list()\n",
    "    sampling_dur = manager.list()\n",
    "    new_samples = manager.list()\n",
    "    filename = f'hoasa-kmeans-init-{init_size}'\n",
    "\n",
    "    set_seed(seed)\n",
    "    \n",
    "    print(\"===============================================\")\n",
    "    print(\"Init Size {}\".format(init_size))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        # Train the model\n",
    "        args = (\n",
    "            current_train_size, \n",
    "            train_indices, \n",
    "            (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "            (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "            (data_used, accuracies, f1_micros, f1_macros), \n",
    "            i,\n",
    "            seed,\n",
    "            filename\n",
    "        )\n",
    "        notebook_launcher(train_model, args, num_processes=2)\n",
    "\n",
    "        nearest_cp = current_train_size\n",
    "        if nearest_cp not in checkpoints:\n",
    "            for cp in checkpoints:\n",
    "                if cp > current_train_size:\n",
    "                    nearest_cp = cp\n",
    "                    break\n",
    "        percentage = math.ceil(nearest_cp / total_data * 100)\n",
    "\n",
    "        aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{i+1}-model-{percentage}')\n",
    "        sentiment_model = BertForSequenceClassification.from_pretrained(f'{filename}-sentiment-{i+1}-model-{percentage}')\n",
    "    \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples = manager.list()\n",
    "        sampling_args = (\n",
    "            aspect_model, \n",
    "            sentiment_model, \n",
    "            [X_train[i] for i in remaining_indices], \n",
    "            train_indices, \n",
    "            remaining_indices, \n",
    "            sampling_dur, \n",
    "            new_samples, \n",
    "            i,\n",
    "            filename\n",
    "        )\n",
    "        notebook_launcher(kmeans_clustering_sampling, sampling_args, num_processes=2)\n",
    "        new_samples = list(new_samples)\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    args = (\n",
    "        current_train_size, \n",
    "        train_indices, \n",
    "        (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "        (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "        (data_used, accuracies, f1_micros, f1_macros), \n",
    "        i,\n",
    "        seed,\n",
    "        filename\n",
    "    )\n",
    "    notebook_launcher(train_model, args, num_processes=2)\n",
    "    data_used, accuracies, f1_micros, f1_macros, sampling_dur = list(data_used), list(accuracies), list(f1_micros), list(f1_macros), list(sampling_dur)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    # print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Aspect Accuracy': aspect_accuracies,\n",
    "        'Aspect F1 Micro': aspect_f1_micros,\n",
    "        'Aspect F1 Macro': aspect_f1_macros,\n",
    "        'Sentiment Accuracy': sentiment_accuracies,\n",
    "        'Sentiment F1 Micro': sentiment_f1_micros,\n",
    "        'Sentiment F1 Macro': sentiment_f1_macros,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    \n",
    "    sampling_dur.insert(0, 0)\n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    results.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c296c1f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T15:05:14.825697Z",
     "iopub.status.busy": "2025-05-17T15:05:14.825428Z",
     "iopub.status.idle": "2025-05-17T17:36:40.301796Z",
     "shell.execute_reply": "2025-05-17T17:36:40.300934Z"
    },
    "papermill": {
     "duration": 9085.490414,
     "end_time": "2025-05-17T17:36:40.303470",
     "exception": false,
     "start_time": "2025-05-17T15:05:14.813056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "Init Size 1\n",
      "Random seed: 81\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7629, Accuracy: 0.4733, F1 Micro: 0.5873, F1 Macro: 0.491\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.7254, Accuracy: 0.5719, F1 Micro: 0.6993, F1 Macro: 0.6035\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.6779, Accuracy: 0.6304, F1 Micro: 0.7608, F1 Macro: 0.6848\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.616, Accuracy: 0.6764, F1 Micro: 0.8005, F1 Macro: 0.756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.5873, Accuracy: 0.7193, F1 Micro: 0.8328, F1 Macro: 0.8117\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.5466, Accuracy: 0.7545, F1 Micro: 0.8574, F1 Macro: 0.8462\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.5374, Accuracy: 0.7812, F1 Micro: 0.8753, F1 Macro: 0.868\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4948, Accuracy: 0.7958, F1 Micro: 0.8848, F1 Macro: 0.8769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.4842, Accuracy: 0.7986, F1 Micro: 0.8866, F1 Macro: 0.8784\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.4772, Accuracy: 0.8003, F1 Micro: 0.8874, F1 Macro: 0.8785\n",
      "\n",
      "Aspect detection accuracy: 0.8003, F1 Micro: 0.8874, F1 Macro: 0.8785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.80      1.00      0.89       462\n",
      "   air_panas       0.83      1.00      0.91       480\n",
      "         bau       0.86      0.99      0.92       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.57      0.75      0.65       317\n",
      "       linen       0.68      1.00      0.81       392\n",
      "     service       0.73      1.00      0.85       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.90      1.00      0.95       516\n",
      "        wifi       0.86      1.00      0.93       498\n",
      "\n",
      "   micro avg       0.81      0.98      0.89      4614\n",
      "   macro avg       0.80      0.97      0.88      4614\n",
      "weighted avg       0.82      0.98      0.89      4614\n",
      " samples avg       0.81      0.98      0.88      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7093, Accuracy: 0.3975, F1 Micro: 0.3975, F1 Macro: 0.2844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.6098, Accuracy: 0.3975, F1 Micro: 0.3975, F1 Macro: 0.2844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5463, Accuracy: 0.3975, F1 Micro: 0.3975, F1 Macro: 0.2844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4848, Accuracy: 0.3975, F1 Micro: 0.3975, F1 Macro: 0.2844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4943, Accuracy: 0.3975, F1 Micro: 0.3975, F1 Macro: 0.2844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4027, Accuracy: 0.3975, F1 Micro: 0.3975, F1 Macro: 0.2844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3762, Accuracy: 0.3975, F1 Micro: 0.3975, F1 Macro: 0.2844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4164, Accuracy: 0.3975, F1 Micro: 0.3975, F1 Macro: 0.2844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3284, Accuracy: 0.3975, F1 Micro: 0.3975, F1 Macro: 0.2844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3549, Accuracy: 0.3975, F1 Micro: 0.3975, F1 Macro: 0.2844\n",
      "\n",
      "Sentiment analysis accuracy: 0.3975, F1 Micro: 0.3975, F1 Macro: 0.2844\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.40      1.00      0.57        64\n",
      "    positive       0.00      0.00      0.00        97\n",
      "\n",
      "    accuracy                           0.40       161\n",
      "   macro avg       0.20      0.50      0.28       161\n",
      "weighted avg       0.16      0.40      0.23       161\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 28: Accuracy: 0.7972, F1 Micro: 0.7972, F1 Macro: 0.3046\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        97\n",
      "     neutral       0.80      1.00      0.89       459\n",
      "    positive       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.80       571\n",
      "   macro avg       0.27      0.33      0.30       571\n",
      "weighted avg       0.65      0.80      0.72       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        86\n",
      "     neutral       0.83      1.00      0.91       475\n",
      "    positive       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.28      0.33      0.30       571\n",
      "weighted avg       0.69      0.83      0.76       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        78\n",
      "     neutral       0.86      0.99      0.92       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.74      0.85      0.79       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.41      0.32      0.36       200\n",
      "     neutral       0.57      0.75      0.65       315\n",
      "    positive       0.00      0.00      0.00        56\n",
      "\n",
      "    accuracy                           0.53       571\n",
      "   macro avg       0.33      0.36      0.34       571\n",
      "weighted avg       0.46      0.53      0.48       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00       162\n",
      "     neutral       0.68      1.00      0.81       387\n",
      "    positive       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.68       571\n",
      "   macro avg       0.23      0.33      0.27       571\n",
      "weighted avg       0.46      0.68      0.55       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        85\n",
      "     neutral       0.73      1.00      0.85       418\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.73       571\n",
      "   macro avg       0.24      0.33      0.28       571\n",
      "weighted avg       0.54      0.73      0.62       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.89      1.00      0.94       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.30      0.33      0.31       571\n",
      "weighted avg       0.80      0.89      0.85       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        74\n",
      "     neutral       0.87      1.00      0.93       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.80       571\n",
      "\n",
      "Total train time: 76.33472943305969 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 226\n",
      "Sampling duration: 30.82155966758728 seconds\n",
      "New train size: 254\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6358, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8851\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4822, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4522, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4396, Accuracy: 0.8024, F1 Micro: 0.8902, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.415, Accuracy: 0.8092, F1 Micro: 0.8934, F1 Macro: 0.8885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3809, Accuracy: 0.8286, F1 Micro: 0.902, F1 Macro: 0.8948\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.358, Accuracy: 0.8408, F1 Micro: 0.9075, F1 Macro: 0.8997\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3305, Accuracy: 0.8556, F1 Micro: 0.9157, F1 Macro: 0.9097\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3124, Accuracy: 0.8627, F1 Micro: 0.9197, F1 Macro: 0.9145\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2707, Accuracy: 0.8747, F1 Micro: 0.9263, F1 Macro: 0.9212\n",
      "\n",
      "Aspect detection accuracy: 0.8747, F1 Micro: 0.9263, F1 Macro: 0.9212\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.85      1.00      0.92       462\n",
      "   air_panas       0.91      0.98      0.94       480\n",
      "         bau       0.90      0.98      0.94       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.72      0.88      0.79       317\n",
      "       linen       0.78      0.98      0.87       392\n",
      "     service       0.90      0.98      0.94       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.92      1.00      0.96       516\n",
      "        wifi       0.95      0.99      0.97       498\n",
      "\n",
      "   micro avg       0.88      0.98      0.93      4614\n",
      "   macro avg       0.87      0.98      0.92      4614\n",
      "weighted avg       0.88      0.98      0.93      4614\n",
      " samples avg       0.88      0.98      0.92      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.513, Accuracy: 0.7277, F1 Micro: 0.7277, F1 Macro: 0.4212\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5117, Accuracy: 0.7277, F1 Micro: 0.7277, F1 Macro: 0.4212\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3459, Accuracy: 0.7731, F1 Micro: 0.7731, F1 Macro: 0.6441\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3251, Accuracy: 0.8098, F1 Micro: 0.8098, F1 Macro: 0.749\n",
      "Epoch 5/10, Train Loss: 0.2253, Accuracy: 0.7906, F1 Micro: 0.7906, F1 Macro: 0.6736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2657, Accuracy: 0.815, F1 Micro: 0.815, F1 Macro: 0.7257\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2199, Accuracy: 0.8185, F1 Micro: 0.8185, F1 Macro: 0.734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1602, Accuracy: 0.8255, F1 Micro: 0.8255, F1 Macro: 0.7577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1326, Accuracy: 0.8255, F1 Micro: 0.8255, F1 Macro: 0.7513\n",
      "Epoch 10/10, Train Loss: 0.1277, Accuracy: 0.822, F1 Micro: 0.822, F1 Macro: 0.7541\n",
      "\n",
      "Sentiment analysis accuracy: 0.8255, F1 Micro: 0.8255, F1 Macro: 0.7513\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.94      0.89       417\n",
      "    positive       0.77      0.51      0.62       156\n",
      "\n",
      "    accuracy                           0.83       573\n",
      "   macro avg       0.80      0.73      0.75       573\n",
      "weighted avg       0.82      0.83      0.81       573\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 254: Accuracy: 0.868, F1 Micro: 0.868, F1 Macro: 0.532\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.32      0.48        97\n",
      "     neutral       0.85      1.00      0.92       459\n",
      "    positive       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.61      0.44      0.47       571\n",
      "weighted avg       0.85      0.86      0.82       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.51      0.63        86\n",
      "     neutral       0.91      0.98      0.94       475\n",
      "    positive       0.50      0.10      0.17        10\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.74      0.53      0.58       571\n",
      "weighted avg       0.89      0.90      0.88       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.31      0.43        78\n",
      "     neutral       0.90      0.98      0.94       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.54      0.43      0.46       571\n",
      "weighted avg       0.87      0.89      0.86       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.58      0.68       200\n",
      "     neutral       0.72      0.88      0.80       315\n",
      "    positive       0.48      0.36      0.41        56\n",
      "\n",
      "    accuracy                           0.73       571\n",
      "   macro avg       0.67      0.61      0.63       571\n",
      "weighted avg       0.73      0.73      0.72       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.37      0.53       162\n",
      "     neutral       0.77      0.98      0.87       387\n",
      "    positive       0.33      0.18      0.24        22\n",
      "\n",
      "    accuracy                           0.78       571\n",
      "   macro avg       0.67      0.51      0.54       571\n",
      "weighted avg       0.79      0.78      0.75       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.71      0.76        85\n",
      "     neutral       0.90      0.98      0.94       418\n",
      "    positive       0.89      0.59      0.71        68\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.87      0.76      0.80       571\n",
      "weighted avg       0.89      0.89      0.88       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.19      0.30        54\n",
      "     neutral       0.92      1.00      0.96       511\n",
      "    positive       1.00      0.17      0.29         6\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.45      0.51       571\n",
      "weighted avg       0.90      0.91      0.89       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.64      0.74        74\n",
      "     neutral       0.95      0.99      0.97       494\n",
      "    positive       0.50      0.33      0.40         3\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.78      0.65      0.70       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Total train time: 105.29537725448608 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 203\n",
      "Sampling duration: 57.63197588920593 seconds\n",
      "New train size: 457\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5728, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4675, Accuracy: 0.8014, F1 Micro: 0.8897, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4493, Accuracy: 0.8288, F1 Micro: 0.9024, F1 Macro: 0.8964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.41, Accuracy: 0.8417, F1 Micro: 0.9087, F1 Macro: 0.9034\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3506, Accuracy: 0.8797, F1 Micro: 0.929, F1 Macro: 0.9244\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2874, Accuracy: 0.9054, F1 Micro: 0.943, F1 Macro: 0.9387\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2587, Accuracy: 0.913, F1 Micro: 0.9473, F1 Macro: 0.9431\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2207, Accuracy: 0.9262, F1 Micro: 0.9549, F1 Macro: 0.9512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1927, Accuracy: 0.9281, F1 Micro: 0.956, F1 Macro: 0.9518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1774, Accuracy: 0.9309, F1 Micro: 0.9579, F1 Macro: 0.9546\n",
      "\n",
      "Aspect detection accuracy: 0.9309, F1 Micro: 0.9579, F1 Macro: 0.9546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.98       462\n",
      "   air_panas       0.96      0.98      0.97       480\n",
      "         bau       0.96      0.97      0.96       496\n",
      "     general       0.89      0.99      0.93       500\n",
      "  kebersihan       0.83      0.93      0.88       317\n",
      "       linen       0.84      0.97      0.90       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.94      1.00      0.97       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.99      0.99      0.99       498\n",
      "\n",
      "   micro avg       0.94      0.98      0.96      4614\n",
      "   macro avg       0.93      0.98      0.95      4614\n",
      "weighted avg       0.94      0.98      0.96      4614\n",
      " samples avg       0.94      0.98      0.95      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5647, Accuracy: 0.729, F1 Micro: 0.729, F1 Macro: 0.4331\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3882, Accuracy: 0.7727, F1 Micro: 0.7727, F1 Macro: 0.7355\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3025, Accuracy: 0.8, F1 Micro: 0.8, F1 Macro: 0.6641\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2276, Accuracy: 0.8415, F1 Micro: 0.8415, F1 Macro: 0.7847\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2274, Accuracy: 0.8546, F1 Micro: 0.8546, F1 Macro: 0.7928\n",
      "Epoch 6/10, Train Loss: 0.1738, Accuracy: 0.8525, F1 Micro: 0.8525, F1 Macro: 0.786\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1581, Accuracy: 0.8634, F1 Micro: 0.8634, F1 Macro: 0.8065\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1114, Accuracy: 0.8656, F1 Micro: 0.8656, F1 Macro: 0.8109\n",
      "Epoch 9/10, Train Loss: 0.0924, Accuracy: 0.8601, F1 Micro: 0.8601, F1 Macro: 0.7952\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0665, Accuracy: 0.8689, F1 Micro: 0.8689, F1 Macro: 0.8158\n",
      "\n",
      "Sentiment analysis accuracy: 0.8689, F1 Micro: 0.8689, F1 Macro: 0.8158\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.97      0.91       664\n",
      "    positive       0.88      0.61      0.72       251\n",
      "\n",
      "    accuracy                           0.87       915\n",
      "   macro avg       0.87      0.79      0.82       915\n",
      "weighted avg       0.87      0.87      0.86       915\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 457: Accuracy: 0.9224, F1 Micro: 0.9224, F1 Macro: 0.6811\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90        97\n",
      "     neutral       0.98      0.99      0.98       459\n",
      "    positive       0.91      0.67      0.77        15\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.85      0.88       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.73      0.79        86\n",
      "     neutral       0.96      0.98      0.97       475\n",
      "    positive       0.31      0.40      0.35        10\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.71      0.70      0.70       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.76      0.77        78\n",
      "     neutral       0.96      0.97      0.96       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.58      0.57      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.89      0.99      0.93       496\n",
      "    positive       0.67      0.21      0.31        68\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.52      0.40      0.42       571\n",
      "weighted avg       0.85      0.88      0.85       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.75      0.80       200\n",
      "     neutral       0.83      0.93      0.88       315\n",
      "    positive       0.86      0.68      0.76        56\n",
      "\n",
      "    accuracy                           0.84       571\n",
      "   macro avg       0.85      0.79      0.81       571\n",
      "weighted avg       0.84      0.84      0.84       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.61      0.72       162\n",
      "     neutral       0.84      0.98      0.90       387\n",
      "    positive       0.57      0.18      0.28        22\n",
      "\n",
      "    accuracy                           0.84       571\n",
      "   macro avg       0.76      0.59      0.63       571\n",
      "weighted avg       0.84      0.84      0.83       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.81      0.83        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.94      0.87      0.90        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.89      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.03      0.07        29\n",
      "     neutral       0.94      1.00      0.97       525\n",
      "    positive       0.67      0.47      0.55        17\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.87      0.50      0.53       571\n",
      "weighted avg       0.93      0.93      0.91       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.17      0.29         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.68      0.72       571\n",
      "weighted avg       0.98      0.98      0.97       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.92      0.91        74\n",
      "     neutral       0.99      0.99      0.99       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.63      0.64      0.63       571\n",
      "weighted avg       0.97      0.98      0.98       571\n",
      "\n",
      "Total train time: 144.3084225654602 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 183\n",
      "Sampling duration: 59.74243187904358 seconds\n",
      "New train size: 640\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5604, Accuracy: 0.8012, F1 Micro: 0.8896, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4717, Accuracy: 0.8208, F1 Micro: 0.8981, F1 Macro: 0.8914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4335, Accuracy: 0.8351, F1 Micro: 0.9059, F1 Macro: 0.9014\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3692, Accuracy: 0.8854, F1 Micro: 0.9317, F1 Macro: 0.9258\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3032, Accuracy: 0.9156, F1 Micro: 0.9485, F1 Macro: 0.9434\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2683, Accuracy: 0.93, F1 Micro: 0.9572, F1 Macro: 0.9531\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2279, Accuracy: 0.93, F1 Micro: 0.9574, F1 Macro: 0.9542\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1862, Accuracy: 0.9418, F1 Micro: 0.9643, F1 Macro: 0.9612\n",
      "Epoch 9/10, Train Loss: 0.1757, Accuracy: 0.9413, F1 Micro: 0.9641, F1 Macro: 0.9611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1479, Accuracy: 0.9458, F1 Micro: 0.9667, F1 Macro: 0.9638\n",
      "\n",
      "Aspect detection accuracy: 0.9458, F1 Micro: 0.9667, F1 Macro: 0.9638\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.97      0.99      0.98       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.90      0.99      0.94       500\n",
      "  kebersihan       0.86      0.94      0.90       317\n",
      "       linen       0.90      0.96      0.93       392\n",
      "     service       0.97      0.96      0.96       423\n",
      "sunrise_meal       0.96      1.00      0.98       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      4614\n",
      "   macro avg       0.95      0.98      0.96      4614\n",
      "weighted avg       0.95      0.98      0.97      4614\n",
      " samples avg       0.95      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.515, Accuracy: 0.7915, F1 Micro: 0.7915, F1 Macro: 0.6896\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3642, Accuracy: 0.8087, F1 Micro: 0.8087, F1 Macro: 0.6797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2935, Accuracy: 0.8674, F1 Micro: 0.8674, F1 Macro: 0.8185\n",
      "Epoch 4/10, Train Loss: 0.2359, Accuracy: 0.8654, F1 Micro: 0.8654, F1 Macro: 0.8303\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1795, Accuracy: 0.8836, F1 Micro: 0.8836, F1 Macro: 0.8378\n",
      "Epoch 6/10, Train Loss: 0.1344, Accuracy: 0.8725, F1 Micro: 0.8725, F1 Macro: 0.829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0974, Accuracy: 0.8968, F1 Micro: 0.8968, F1 Macro: 0.8601\n",
      "Epoch 8/10, Train Loss: 0.0552, Accuracy: 0.8957, F1 Micro: 0.8957, F1 Macro: 0.8589\n",
      "Epoch 9/10, Train Loss: 0.0566, Accuracy: 0.8937, F1 Micro: 0.8937, F1 Macro: 0.8545\n",
      "Epoch 10/10, Train Loss: 0.07, Accuracy: 0.8927, F1 Micro: 0.8927, F1 Macro: 0.8525\n",
      "\n",
      "Sentiment analysis accuracy: 0.8968, F1 Micro: 0.8968, F1 Macro: 0.8601\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93       720\n",
      "    positive       0.89      0.71      0.79       268\n",
      "\n",
      "    accuracy                           0.90       988\n",
      "   macro avg       0.89      0.84      0.86       988\n",
      "weighted avg       0.90      0.90      0.89       988\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 640: Accuracy: 0.9385, F1 Micro: 0.9385, F1 Macro: 0.7996\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.87      0.91        97\n",
      "     neutral       0.98      0.99      0.98       459\n",
      "    positive       0.82      0.93      0.87        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.81      0.88        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.58      0.70      0.64        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.83      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.79      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.90      0.99      0.94       496\n",
      "    positive       0.83      0.29      0.43        68\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.58      0.43      0.46       571\n",
      "weighted avg       0.88      0.90      0.87       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.80      0.84       200\n",
      "     neutral       0.86      0.94      0.90       315\n",
      "    positive       0.84      0.73      0.78        56\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.86      0.82      0.84       571\n",
      "weighted avg       0.87      0.87      0.87       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.77      0.82       162\n",
      "     neutral       0.89      0.96      0.93       387\n",
      "    positive       0.57      0.36      0.44        22\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.78      0.70      0.73       571\n",
      "weighted avg       0.88      0.88      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.84      0.83        85\n",
      "     neutral       0.97      0.96      0.96       418\n",
      "    positive       0.85      0.91      0.88        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.88      0.90      0.89       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.28      0.39        29\n",
      "     neutral       0.96      1.00      0.98       525\n",
      "    positive       0.73      0.65      0.69        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.79      0.64      0.69       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.87      0.90        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       0.80      0.67      0.73         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.84      0.87       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.96      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 162.48944520950317 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 165\n",
      "Sampling duration: 56.38248157501221 seconds\n",
      "New train size: 805\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5451, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4683, Accuracy: 0.8271, F1 Micro: 0.9018, F1 Macro: 0.897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4024, Accuracy: 0.8741, F1 Micro: 0.9257, F1 Macro: 0.9195\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3129, Accuracy: 0.9146, F1 Micro: 0.9483, F1 Macro: 0.944\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2524, Accuracy: 0.9347, F1 Micro: 0.9599, F1 Macro: 0.9561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.214, Accuracy: 0.9413, F1 Micro: 0.9638, F1 Macro: 0.9595\n",
      "Epoch 7/10, Train Loss: 0.1808, Accuracy: 0.9398, F1 Micro: 0.9632, F1 Macro: 0.9604\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1584, Accuracy: 0.946, F1 Micro: 0.9667, F1 Macro: 0.9633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1411, Accuracy: 0.9483, F1 Micro: 0.968, F1 Macro: 0.9647\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1206, Accuracy: 0.9516, F1 Micro: 0.9701, F1 Macro: 0.967\n",
      "\n",
      "Aspect detection accuracy: 0.9516, F1 Micro: 0.9701, F1 Macro: 0.967\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.92      0.98      0.95       500\n",
      "  kebersihan       0.90      0.92      0.91       317\n",
      "       linen       0.89      0.97      0.93       392\n",
      "     service       0.97      0.95      0.96       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4832, Accuracy: 0.8173, F1 Micro: 0.8173, F1 Macro: 0.7297\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.326, Accuracy: 0.8462, F1 Micro: 0.8462, F1 Macro: 0.7827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.252, Accuracy: 0.8654, F1 Micro: 0.8654, F1 Macro: 0.8266\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2031, Accuracy: 0.8798, F1 Micro: 0.8798, F1 Macro: 0.8474\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1516, Accuracy: 0.8875, F1 Micro: 0.8875, F1 Macro: 0.8606\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1332, Accuracy: 0.8894, F1 Micro: 0.8894, F1 Macro: 0.8597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1019, Accuracy: 0.899, F1 Micro: 0.899, F1 Macro: 0.8735\n",
      "Epoch 8/10, Train Loss: 0.076, Accuracy: 0.8856, F1 Micro: 0.8856, F1 Macro: 0.8564\n",
      "Epoch 9/10, Train Loss: 0.0478, Accuracy: 0.8942, F1 Micro: 0.8942, F1 Macro: 0.8621\n",
      "Epoch 10/10, Train Loss: 0.0412, Accuracy: 0.8923, F1 Micro: 0.8923, F1 Macro: 0.8613\n",
      "\n",
      "Sentiment analysis accuracy: 0.899, F1 Micro: 0.899, F1 Macro: 0.8735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.95      0.93       738\n",
      "    positive       0.86      0.77      0.82       302\n",
      "\n",
      "    accuracy                           0.90      1040\n",
      "   macro avg       0.89      0.86      0.87      1040\n",
      "weighted avg       0.90      0.90      0.90      1040\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 805: Accuracy: 0.9436, F1 Micro: 0.9436, F1 Macro: 0.8248\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.81      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.81      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.92      0.98      0.95       496\n",
      "    positive       0.79      0.49      0.60        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.57      0.49      0.52       571\n",
      "weighted avg       0.89      0.91      0.90       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.82      0.85       200\n",
      "     neutral       0.89      0.92      0.91       315\n",
      "    positive       0.81      0.89      0.85        56\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.86      0.88      0.87       571\n",
      "weighted avg       0.88      0.88      0.88       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.72      0.81       162\n",
      "     neutral       0.89      0.97      0.93       387\n",
      "    positive       0.55      0.50      0.52        22\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.78      0.73      0.75       571\n",
      "weighted avg       0.88      0.88      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.75      0.80        85\n",
      "     neutral       0.97      0.95      0.96       418\n",
      "    positive       0.76      0.96      0.85        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.86      0.89      0.87       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.34      0.50        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.65      0.88      0.75        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.74      0.75       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.91      0.93        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.94      0.97      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.96      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 186.37461066246033 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 148\n",
      "Sampling duration: 51.31034278869629 seconds\n",
      "New train size: 953\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5295, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4483, Accuracy: 0.8391, F1 Micro: 0.9079, F1 Macro: 0.9025\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3586, Accuracy: 0.9033, F1 Micro: 0.9422, F1 Macro: 0.938\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2782, Accuracy: 0.9283, F1 Micro: 0.9564, F1 Macro: 0.9531\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.23, Accuracy: 0.9434, F1 Micro: 0.9653, F1 Macro: 0.9622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1961, Accuracy: 0.9476, F1 Micro: 0.9678, F1 Macro: 0.9652\n",
      "Epoch 7/10, Train Loss: 0.1637, Accuracy: 0.9472, F1 Micro: 0.9675, F1 Macro: 0.9647\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1446, Accuracy: 0.949, F1 Micro: 0.9686, F1 Macro: 0.9659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1211, Accuracy: 0.9559, F1 Micro: 0.9728, F1 Macro: 0.9703\n",
      "Epoch 10/10, Train Loss: 0.1086, Accuracy: 0.9547, F1 Micro: 0.972, F1 Macro: 0.9693\n",
      "\n",
      "Aspect detection accuracy: 0.9559, F1 Micro: 0.9728, F1 Macro: 0.9703\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.92      0.99      0.95       500\n",
      "  kebersihan       0.92      0.92      0.92       317\n",
      "       linen       0.90      0.98      0.94       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4796, Accuracy: 0.8295, F1 Micro: 0.8295, F1 Macro: 0.7677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.321, Accuracy: 0.8672, F1 Micro: 0.8672, F1 Macro: 0.8276\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2432, Accuracy: 0.8934, F1 Micro: 0.8934, F1 Macro: 0.8586\n",
      "Epoch 4/10, Train Loss: 0.2015, Accuracy: 0.8886, F1 Micro: 0.8886, F1 Macro: 0.8455\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1347, Accuracy: 0.905, F1 Micro: 0.905, F1 Macro: 0.874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0907, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8774\n",
      "Epoch 7/10, Train Loss: 0.0789, Accuracy: 0.9021, F1 Micro: 0.9021, F1 Macro: 0.8744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0623, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0621, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8774\n",
      "Epoch 10/10, Train Loss: 0.0376, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8775\n",
      "\n",
      "Sentiment analysis accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       743\n",
      "    positive       0.93      0.73      0.82       289\n",
      "\n",
      "    accuracy                           0.91      1032\n",
      "   macro avg       0.91      0.85      0.88      1032\n",
      "weighted avg       0.91      0.91      0.90      1032\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 953: Accuracy: 0.9497, F1 Micro: 0.9497, F1 Macro: 0.8433\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.86      0.89        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.81      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.92      0.99      0.95       496\n",
      "    positive       0.85      0.50      0.63        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.59      0.50      0.53       571\n",
      "weighted avg       0.90      0.92      0.90       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.87       200\n",
      "     neutral       0.92      0.92      0.92       315\n",
      "    positive       0.84      0.86      0.85        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.88      0.88      0.88       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.75      0.81       162\n",
      "     neutral       0.89      0.98      0.94       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.87      0.71      0.77       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.81      0.85        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.95      0.93      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.45      0.60        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.89      0.76      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 198.9341745376587 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 133\n",
      "Sampling duration: 46.83307695388794 seconds\n",
      "New train size: 1086\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5308, Accuracy: 0.8042, F1 Micro: 0.8909, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4371, Accuracy: 0.862, F1 Micro: 0.9194, F1 Macro: 0.9126\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3394, Accuracy: 0.9132, F1 Micro: 0.9475, F1 Macro: 0.9433\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2609, Accuracy: 0.9359, F1 Micro: 0.961, F1 Macro: 0.9587\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2124, Accuracy: 0.9432, F1 Micro: 0.9653, F1 Macro: 0.9629\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.189, Accuracy: 0.95, F1 Micro: 0.9692, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1579, Accuracy: 0.9514, F1 Micro: 0.9701, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1329, Accuracy: 0.9543, F1 Micro: 0.9718, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1208, Accuracy: 0.9559, F1 Micro: 0.9727, F1 Macro: 0.9701\n",
      "Epoch 10/10, Train Loss: 0.1006, Accuracy: 0.9556, F1 Micro: 0.9725, F1 Macro: 0.9699\n",
      "\n",
      "Aspect detection accuracy: 0.9559, F1 Micro: 0.9727, F1 Macro: 0.9701\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.92      0.99      0.95       500\n",
      "  kebersihan       0.91      0.92      0.92       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4845, Accuracy: 0.8387, F1 Micro: 0.8387, F1 Macro: 0.7948\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3324, Accuracy: 0.8521, F1 Micro: 0.8521, F1 Macro: 0.8151\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2747, Accuracy: 0.8855, F1 Micro: 0.8855, F1 Macro: 0.8503\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1766, Accuracy: 0.8903, F1 Micro: 0.8903, F1 Macro: 0.8557\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1365, Accuracy: 0.8912, F1 Micro: 0.8912, F1 Macro: 0.8535\n",
      "Epoch 6/10, Train Loss: 0.1112, Accuracy: 0.8884, F1 Micro: 0.8884, F1 Macro: 0.8478\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0695, Accuracy: 0.896, F1 Micro: 0.896, F1 Macro: 0.8615\n",
      "Epoch 8/10, Train Loss: 0.0461, Accuracy: 0.8884, F1 Micro: 0.8884, F1 Macro: 0.849\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0631, Accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0582, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8712\n",
      "\n",
      "Sentiment analysis accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8712\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.93       749\n",
      "    positive       0.93      0.72      0.81       299\n",
      "\n",
      "    accuracy                           0.90      1048\n",
      "   macro avg       0.91      0.85      0.87      1048\n",
      "weighted avg       0.90      0.90      0.90      1048\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1086: Accuracy: 0.9492, F1 Micro: 0.9492, F1 Macro: 0.8369\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.89        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.91      0.78      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.76      0.80        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.92      0.99      0.95       496\n",
      "    positive       0.85      0.50      0.63        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.59      0.50      0.53       571\n",
      "weighted avg       0.90      0.92      0.90       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.84      0.86       200\n",
      "     neutral       0.91      0.92      0.92       315\n",
      "    positive       0.83      0.88      0.85        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.87      0.88      0.88       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.83      0.84       162\n",
      "     neutral       0.92      0.96      0.94       387\n",
      "    positive       0.86      0.27      0.41        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.87      0.69      0.73       571\n",
      "weighted avg       0.89      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.84      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.90      0.94      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.45      0.59        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.76      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 222.184508562088 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 120\n",
      "Sampling duration: 42.07261800765991 seconds\n",
      "New train size: 1206\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5187, Accuracy: 0.8092, F1 Micro: 0.8931, F1 Macro: 0.8877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4215, Accuracy: 0.8873, F1 Micro: 0.9332, F1 Macro: 0.9282\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3151, Accuracy: 0.9274, F1 Micro: 0.956, F1 Macro: 0.9528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.242, Accuracy: 0.9436, F1 Micro: 0.9655, F1 Macro: 0.9629\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1929, Accuracy: 0.9486, F1 Micro: 0.9685, F1 Macro: 0.9657\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.177, Accuracy: 0.9502, F1 Micro: 0.9694, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1416, Accuracy: 0.9547, F1 Micro: 0.9721, F1 Macro: 0.9699\n",
      "Epoch 8/10, Train Loss: 0.1226, Accuracy: 0.9538, F1 Micro: 0.9716, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1064, Accuracy: 0.9568, F1 Micro: 0.9733, F1 Macro: 0.9707\n",
      "Epoch 10/10, Train Loss: 0.0914, Accuracy: 0.9557, F1 Micro: 0.9726, F1 Macro: 0.9701\n",
      "\n",
      "Aspect detection accuracy: 0.9568, F1 Micro: 0.9733, F1 Macro: 0.9707\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.93      0.99      0.96       500\n",
      "  kebersihan       0.91      0.93      0.92       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.96      0.97      0.96       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4581, Accuracy: 0.8237, F1 Micro: 0.8237, F1 Macro: 0.7329\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3136, Accuracy: 0.8607, F1 Micro: 0.8607, F1 Macro: 0.8155\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2336, Accuracy: 0.8749, F1 Micro: 0.8749, F1 Macro: 0.8256\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.201, Accuracy: 0.8872, F1 Micro: 0.8872, F1 Macro: 0.8464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1384, Accuracy: 0.8929, F1 Micro: 0.8929, F1 Macro: 0.8567\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0984, Accuracy: 0.8929, F1 Micro: 0.8929, F1 Macro: 0.8537\n",
      "Epoch 7/10, Train Loss: 0.0858, Accuracy: 0.891, F1 Micro: 0.891, F1 Macro: 0.8507\n",
      "Epoch 8/10, Train Loss: 0.0762, Accuracy: 0.8891, F1 Micro: 0.8891, F1 Macro: 0.8542\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0507, Accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.8707\n",
      "Epoch 10/10, Train Loss: 0.0472, Accuracy: 0.8976, F1 Micro: 0.8976, F1 Macro: 0.8632\n",
      "\n",
      "Sentiment analysis accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.8707\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93       757\n",
      "    positive       0.91      0.72      0.81       298\n",
      "\n",
      "    accuracy                           0.90      1055\n",
      "   macro avg       0.91      0.85      0.87      1055\n",
      "weighted avg       0.90      0.90      0.90      1055\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1206: Accuracy: 0.9508, F1 Micro: 0.9508, F1 Macro: 0.8469\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.84      0.89        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.58      0.70      0.64        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.84      0.84       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.81      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.99      0.96       496\n",
      "    positive       0.88      0.53      0.66        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.60      0.51      0.54       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87       200\n",
      "     neutral       0.91      0.93      0.92       315\n",
      "    positive       0.90      0.84      0.87        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.90      0.88      0.89       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.79      0.84       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       0.58      0.50      0.54        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.80      0.75      0.77       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.82      0.84        85\n",
      "     neutral       0.96      0.97      0.96       418\n",
      "    positive       0.95      0.91      0.93        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.90      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.84      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 229.89009428024292 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 108\n",
      "Sampling duration: 38.445608377456665 seconds\n",
      "New train size: 1314\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5174, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3967, Accuracy: 0.8925, F1 Micro: 0.9361, F1 Macro: 0.9316\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2806, Accuracy: 0.9363, F1 Micro: 0.9611, F1 Macro: 0.9585\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2237, Accuracy: 0.9413, F1 Micro: 0.9641, F1 Macro: 0.9618\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1881, Accuracy: 0.9479, F1 Micro: 0.9681, F1 Macro: 0.9655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1593, Accuracy: 0.953, F1 Micro: 0.971, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1355, Accuracy: 0.9597, F1 Micro: 0.975, F1 Macro: 0.9728\n",
      "Epoch 8/10, Train Loss: 0.1127, Accuracy: 0.9573, F1 Micro: 0.9736, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0985, Accuracy: 0.9608, F1 Micro: 0.9756, F1 Macro: 0.9733\n",
      "Epoch 10/10, Train Loss: 0.0847, Accuracy: 0.9587, F1 Micro: 0.9744, F1 Macro: 0.9717\n",
      "\n",
      "Aspect detection accuracy: 0.9608, F1 Micro: 0.9756, F1 Macro: 0.9733\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.93      0.98      0.96       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4402, Accuracy: 0.8448, F1 Micro: 0.8448, F1 Macro: 0.7912\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2969, Accuracy: 0.876, F1 Micro: 0.876, F1 Macro: 0.8436\n",
      "Epoch 3/10, Train Loss: 0.218, Accuracy: 0.8751, F1 Micro: 0.8751, F1 Macro: 0.8264\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1524, Accuracy: 0.8981, F1 Micro: 0.8981, F1 Macro: 0.8658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1019, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0827, Accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8718\n",
      "Epoch 7/10, Train Loss: 0.0729, Accuracy: 0.8944, F1 Micro: 0.8944, F1 Macro: 0.8638\n",
      "Epoch 8/10, Train Loss: 0.0612, Accuracy: 0.899, F1 Micro: 0.899, F1 Macro: 0.8669\n",
      "Epoch 9/10, Train Loss: 0.0442, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8699\n",
      "Epoch 10/10, Train Loss: 0.0317, Accuracy: 0.8981, F1 Micro: 0.8981, F1 Macro: 0.8645\n",
      "\n",
      "Sentiment analysis accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8718\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93       775\n",
      "    positive       0.92      0.73      0.81       314\n",
      "\n",
      "    accuracy                           0.90      1089\n",
      "   macro avg       0.91      0.85      0.87      1089\n",
      "weighted avg       0.90      0.90      0.90      1089\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1314: Accuracy: 0.9538, F1 Micro: 0.9538, F1 Macro: 0.8489\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.79      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.85      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.98      0.96       496\n",
      "    positive       0.81      0.57      0.67        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.58      0.52      0.54       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.90      0.88       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.89      0.89      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.90      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.84      0.86       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.57      0.55      0.56        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.80      0.78      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.82      0.86        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.52      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.78      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.88      0.88      0.88       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 241.8637728691101 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 97\n",
      "Sampling duration: 34.76552987098694 seconds\n",
      "New train size: 1411\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5102, Accuracy: 0.8113, F1 Micro: 0.8944, F1 Macro: 0.89\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3905, Accuracy: 0.9003, F1 Micro: 0.9396, F1 Macro: 0.9325\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2799, Accuracy: 0.9399, F1 Micro: 0.9632, F1 Macro: 0.9608\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2154, Accuracy: 0.9469, F1 Micro: 0.9674, F1 Macro: 0.9653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1799, Accuracy: 0.9521, F1 Micro: 0.9704, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1472, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9735\n",
      "Epoch 7/10, Train Loss: 0.1265, Accuracy: 0.9575, F1 Micro: 0.9738, F1 Macro: 0.9711\n",
      "Epoch 8/10, Train Loss: 0.1062, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9728\n",
      "Epoch 9/10, Train Loss: 0.0939, Accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9716\n",
      "Epoch 10/10, Train Loss: 0.0835, Accuracy: 0.959, F1 Micro: 0.9747, F1 Macro: 0.9722\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.95      0.91      0.93       317\n",
      "       linen       0.91      0.97      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.452, Accuracy: 0.8488, F1 Micro: 0.8488, F1 Macro: 0.7972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2971, Accuracy: 0.8726, F1 Micro: 0.8726, F1 Macro: 0.8328\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2235, Accuracy: 0.8863, F1 Micro: 0.8863, F1 Macro: 0.8534\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1924, Accuracy: 0.8928, F1 Micro: 0.8928, F1 Macro: 0.8593\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.157, Accuracy: 0.8955, F1 Micro: 0.8955, F1 Macro: 0.8687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1098, Accuracy: 0.901, F1 Micro: 0.901, F1 Macro: 0.8721\n",
      "Epoch 7/10, Train Loss: 0.1002, Accuracy: 0.9001, F1 Micro: 0.9001, F1 Macro: 0.8692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0756, Accuracy: 0.9019, F1 Micro: 0.9019, F1 Macro: 0.8725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0478, Accuracy: 0.9047, F1 Micro: 0.9047, F1 Macro: 0.8782\n",
      "Epoch 10/10, Train Loss: 0.0447, Accuracy: 0.8928, F1 Micro: 0.8928, F1 Macro: 0.8675\n",
      "\n",
      "Sentiment analysis accuracy: 0.9047, F1 Micro: 0.9047, F1 Macro: 0.8782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.94       770\n",
      "    positive       0.92      0.74      0.82       321\n",
      "\n",
      "    accuracy                           0.90      1091\n",
      "   macro avg       0.91      0.86      0.88      1091\n",
      "weighted avg       0.91      0.90      0.90      1091\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1411: Accuracy: 0.9548, F1 Micro: 0.9548, F1 Macro: 0.8517\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.83      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.81      0.93      0.86       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.86      0.65      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.54      0.57       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88       200\n",
      "     neutral       0.95      0.91      0.93       315\n",
      "    positive       0.80      0.98      0.88        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.92      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.80      0.85       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.80      0.55      0.65        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.77      0.81       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.48      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.94      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.81      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.89      0.93       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 252.64205861091614 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 16\n",
      "Sampling duration: 31.26660180091858 seconds\n",
      "New train size: 1427\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5077, Accuracy: 0.8108, F1 Micro: 0.8927, F1 Macro: 0.8839\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3838, Accuracy: 0.9069, F1 Micro: 0.9441, F1 Macro: 0.9397\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2699, Accuracy: 0.9337, F1 Micro: 0.9596, F1 Macro: 0.9564\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2217, Accuracy: 0.9495, F1 Micro: 0.9688, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1806, Accuracy: 0.9521, F1 Micro: 0.9705, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1502, Accuracy: 0.9578, F1 Micro: 0.974, F1 Macro: 0.972\n",
      "Epoch 7/10, Train Loss: 0.1298, Accuracy: 0.9569, F1 Micro: 0.9734, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.106, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9729\n",
      "Epoch 9/10, Train Loss: 0.0936, Accuracy: 0.9599, F1 Micro: 0.9751, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0793, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9742\n",
      "\n",
      "Aspect detection accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9742\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4399, Accuracy: 0.857, F1 Micro: 0.857, F1 Macro: 0.8146\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2473, Accuracy: 0.8793, F1 Micro: 0.8793, F1 Macro: 0.8398\n",
      "Epoch 3/10, Train Loss: 0.1781, Accuracy: 0.87, F1 Micro: 0.87, F1 Macro: 0.8182\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1633, Accuracy: 0.8923, F1 Micro: 0.8923, F1 Macro: 0.8559\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1127, Accuracy: 0.909, F1 Micro: 0.909, F1 Macro: 0.8836\n",
      "Epoch 6/10, Train Loss: 0.0755, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.878\n",
      "Epoch 7/10, Train Loss: 0.0445, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8661\n",
      "Epoch 8/10, Train Loss: 0.0501, Accuracy: 0.9016, F1 Micro: 0.9016, F1 Macro: 0.8709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0389, Accuracy: 0.909, F1 Micro: 0.909, F1 Macro: 0.8834\n",
      "Epoch 10/10, Train Loss: 0.0347, Accuracy: 0.9034, F1 Micro: 0.9034, F1 Macro: 0.8776\n",
      "\n",
      "Sentiment analysis accuracy: 0.909, F1 Micro: 0.909, F1 Macro: 0.8834\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       764\n",
      "    positive       0.92      0.76      0.83       313\n",
      "\n",
      "    accuracy                           0.91      1077\n",
      "   macro avg       0.91      0.86      0.88      1077\n",
      "weighted avg       0.91      0.91      0.91      1077\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1427: Accuracy: 0.9555, F1 Micro: 0.9555, F1 Macro: 0.86\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.88      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.81      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.83      0.71      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.56      0.58       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88       200\n",
      "     neutral       0.93      0.93      0.93       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.83      0.85       162\n",
      "     neutral       0.92      0.97      0.95       387\n",
      "    positive       0.78      0.32      0.45        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.71      0.75       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.81      0.85        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.41      0.56        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.68      0.88      0.77        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.76      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 259.5571885108948 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 86\n",
      "Sampling duration: 31.149762630462646 seconds\n",
      "New train size: 1513\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5065, Accuracy: 0.8224, F1 Micro: 0.8991, F1 Macro: 0.8924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3648, Accuracy: 0.916, F1 Micro: 0.949, F1 Macro: 0.9451\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2626, Accuracy: 0.9387, F1 Micro: 0.9625, F1 Macro: 0.9598\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2037, Accuracy: 0.9462, F1 Micro: 0.967, F1 Macro: 0.9646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1753, Accuracy: 0.9543, F1 Micro: 0.9719, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1414, Accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1206, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9735\n",
      "Epoch 8/10, Train Loss: 0.1012, Accuracy: 0.9602, F1 Micro: 0.9753, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0898, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0775, Accuracy: 0.9639, F1 Micro: 0.9775, F1 Macro: 0.9751\n",
      "\n",
      "Aspect detection accuracy: 0.9639, F1 Micro: 0.9775, F1 Macro: 0.9751\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.95      0.91      0.93       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4288, Accuracy: 0.8498, F1 Micro: 0.8498, F1 Macro: 0.8046\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2603, Accuracy: 0.8759, F1 Micro: 0.8759, F1 Macro: 0.8361\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1897, Accuracy: 0.893, F1 Micro: 0.893, F1 Macro: 0.8623\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.157, Accuracy: 0.893, F1 Micro: 0.893, F1 Macro: 0.8671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1057, Accuracy: 0.9029, F1 Micro: 0.9029, F1 Macro: 0.8773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0847, Accuracy: 0.9056, F1 Micro: 0.9056, F1 Macro: 0.879\n",
      "Epoch 7/10, Train Loss: 0.0699, Accuracy: 0.8993, F1 Micro: 0.8993, F1 Macro: 0.8716\n",
      "Epoch 8/10, Train Loss: 0.0483, Accuracy: 0.8993, F1 Micro: 0.8993, F1 Macro: 0.8708\n",
      "Epoch 9/10, Train Loss: 0.0319, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8765\n",
      "Epoch 10/10, Train Loss: 0.0326, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.877\n",
      "\n",
      "Sentiment analysis accuracy: 0.9056, F1 Micro: 0.9056, F1 Macro: 0.879\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       782\n",
      "    positive       0.93      0.74      0.82       330\n",
      "\n",
      "    accuracy                           0.91      1112\n",
      "   macro avg       0.91      0.86      0.88      1112\n",
      "weighted avg       0.91      0.91      0.90      1112\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1513: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.8633\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.94      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.78      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.83      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.14      0.20         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.83      0.74      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.71      0.62      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89       200\n",
      "     neutral       0.95      0.90      0.93       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.67      0.36      0.47        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.83      0.73      0.76       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.82      0.85        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.48      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.79      0.80       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.97      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.60      1.00      0.75         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.86      0.99      0.91       571\n",
      "weighted avg       1.00      0.99      1.00       571\n",
      "\n",
      "Total train time: 273.3963541984558 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 77\n",
      "Sampling duration: 28.223470449447632 seconds\n",
      "New train size: 1590\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4963, Accuracy: 0.8243, F1 Micro: 0.8991, F1 Macro: 0.889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3593, Accuracy: 0.9187, F1 Micro: 0.9509, F1 Macro: 0.9471\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2516, Accuracy: 0.9396, F1 Micro: 0.9631, F1 Macro: 0.9607\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1994, Accuracy: 0.9507, F1 Micro: 0.9698, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1614, Accuracy: 0.9556, F1 Micro: 0.9726, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1394, Accuracy: 0.9602, F1 Micro: 0.9753, F1 Macro: 0.9732\n",
      "Epoch 7/10, Train Loss: 0.1154, Accuracy: 0.9597, F1 Micro: 0.975, F1 Macro: 0.9725\n",
      "Epoch 8/10, Train Loss: 0.0981, Accuracy: 0.9594, F1 Micro: 0.9748, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0856, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9747\n",
      "Epoch 10/10, Train Loss: 0.0738, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9744\n",
      "\n",
      "Aspect detection accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4373, Accuracy: 0.8459, F1 Micro: 0.8459, F1 Macro: 0.791\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.252, Accuracy: 0.8821, F1 Micro: 0.8821, F1 Macro: 0.8466\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1575, Accuracy: 0.8994, F1 Micro: 0.8994, F1 Macro: 0.8731\n",
      "Epoch 4/10, Train Loss: 0.1229, Accuracy: 0.8957, F1 Micro: 0.8957, F1 Macro: 0.8679\n",
      "Epoch 5/10, Train Loss: 0.0814, Accuracy: 0.8985, F1 Micro: 0.8985, F1 Macro: 0.8736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0705, Accuracy: 0.9012, F1 Micro: 0.9012, F1 Macro: 0.8746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0552, Accuracy: 0.9039, F1 Micro: 0.9039, F1 Macro: 0.8774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0398, Accuracy: 0.9039, F1 Micro: 0.9039, F1 Macro: 0.8774\n",
      "Epoch 9/10, Train Loss: 0.0341, Accuracy: 0.9003, F1 Micro: 0.9003, F1 Macro: 0.8749\n",
      "Epoch 10/10, Train Loss: 0.0246, Accuracy: 0.9021, F1 Micro: 0.9021, F1 Macro: 0.8761\n",
      "\n",
      "Sentiment analysis accuracy: 0.9039, F1 Micro: 0.9039, F1 Macro: 0.8774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.93       773\n",
      "    positive       0.93      0.73      0.82       330\n",
      "\n",
      "    accuracy                           0.90      1103\n",
      "   macro avg       0.91      0.86      0.88      1103\n",
      "weighted avg       0.91      0.90      0.90      1103\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1590: Accuracy: 0.9564, F1 Micro: 0.9564, F1 Macro: 0.8621\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.89        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.75      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.83      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.81      0.76      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.58      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.84      0.85       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       1.00      0.41      0.58        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.93      0.74      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.48      0.61        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.64      0.82      0.72        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.77      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 277.92102789878845 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 70\n",
      "Sampling duration: 25.48393940925598 seconds\n",
      "New train size: 1660\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4989, Accuracy: 0.8262, F1 Micro: 0.9018, F1 Macro: 0.8973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3494, Accuracy: 0.9224, F1 Micro: 0.953, F1 Macro: 0.95\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.239, Accuracy: 0.938, F1 Micro: 0.9622, F1 Macro: 0.96\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1905, Accuracy: 0.9521, F1 Micro: 0.9705, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1641, Accuracy: 0.9576, F1 Micro: 0.9739, F1 Macro: 0.9717\n",
      "Epoch 6/10, Train Loss: 0.1331, Accuracy: 0.9573, F1 Micro: 0.9736, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.114, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9739\n",
      "Epoch 8/10, Train Loss: 0.0986, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0832, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0716, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9755\n",
      "\n",
      "Aspect detection accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4037, Accuracy: 0.8439, F1 Micro: 0.8439, F1 Macro: 0.7742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2341, Accuracy: 0.8972, F1 Micro: 0.8972, F1 Macro: 0.8644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.155, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.132, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8822\n",
      "Epoch 5/10, Train Loss: 0.0845, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8796\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0753, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8873\n",
      "Epoch 7/10, Train Loss: 0.0577, Accuracy: 0.91, F1 Micro: 0.91, F1 Macro: 0.883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0479, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.8878\n",
      "Epoch 9/10, Train Loss: 0.0322, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.879\n",
      "Epoch 10/10, Train Loss: 0.0344, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8776\n",
      "\n",
      "Sentiment analysis accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.8878\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       778\n",
      "    positive       0.94      0.75      0.83       311\n",
      "\n",
      "    accuracy                           0.91      1089\n",
      "   macro avg       0.92      0.86      0.89      1089\n",
      "weighted avg       0.92      0.91      0.91      1089\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1660: Accuracy: 0.9587, F1 Micro: 0.9587, F1 Macro: 0.8622\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.79      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.86      0.65      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.54      0.57       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.77      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.59      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 289.0469660758972 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 52\n",
      "Sampling duration: 23.106379747390747 seconds\n",
      "New train size: 1712\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4907, Accuracy: 0.8302, F1 Micro: 0.9035, F1 Macro: 0.8985\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3348, Accuracy: 0.9276, F1 Micro: 0.9559, F1 Macro: 0.9523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2399, Accuracy: 0.9431, F1 Micro: 0.9651, F1 Macro: 0.9619\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1882, Accuracy: 0.9533, F1 Micro: 0.9711, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1645, Accuracy: 0.9552, F1 Micro: 0.9725, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1289, Accuracy: 0.9592, F1 Micro: 0.9747, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1105, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0993, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0818, Accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.9769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0692, Accuracy: 0.9661, F1 Micro: 0.979, F1 Macro: 0.9771\n",
      "\n",
      "Aspect detection accuracy: 0.9661, F1 Micro: 0.979, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.96      0.93      0.95       317\n",
      "       linen       0.93      0.98      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.385, Accuracy: 0.8683, F1 Micro: 0.8683, F1 Macro: 0.8205\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2398, Accuracy: 0.8965, F1 Micro: 0.8965, F1 Macro: 0.8686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.18, Accuracy: 0.9092, F1 Micro: 0.9092, F1 Macro: 0.883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1331, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8878\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0937, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.8902\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0575, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.8897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0584, Accuracy: 0.9155, F1 Micro: 0.9155, F1 Macro: 0.892\n",
      "Epoch 8/10, Train Loss: 0.0516, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0334, Accuracy: 0.9155, F1 Micro: 0.9155, F1 Macro: 0.8906\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0355, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.8951\n",
      "\n",
      "Sentiment analysis accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.8951\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       781\n",
      "    positive       0.94      0.77      0.85       320\n",
      "\n",
      "    accuracy                           0.92      1101\n",
      "   macro avg       0.92      0.88      0.90      1101\n",
      "weighted avg       0.92      0.92      0.92      1101\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1712: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.8717\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.98      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.87      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.86      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.82      0.75      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.58      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.92      0.91       200\n",
      "     neutral       0.96      0.93      0.95       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.84      0.87       162\n",
      "     neutral       0.93      0.98      0.95       387\n",
      "    positive       0.75      0.41      0.53        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.86      0.74      0.78       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.92      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.80      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.96      0.96        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 306.8465292453766 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 58\n",
      "Sampling duration: 18.52113652229309 seconds\n",
      "New train size: 1770\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4897, Accuracy: 0.8406, F1 Micro: 0.9077, F1 Macro: 0.8998\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3272, Accuracy: 0.9311, F1 Micro: 0.9579, F1 Macro: 0.9548\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2289, Accuracy: 0.9483, F1 Micro: 0.9682, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1786, Accuracy: 0.955, F1 Micro: 0.9723, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1477, Accuracy: 0.9566, F1 Micro: 0.9732, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1285, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9752\n",
      "Epoch 7/10, Train Loss: 0.1103, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0908, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0796, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9761\n",
      "Epoch 10/10, Train Loss: 0.0657, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9758\n",
      "\n",
      "Aspect detection accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3995, Accuracy: 0.864, F1 Micro: 0.864, F1 Macro: 0.8238\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2421, Accuracy: 0.8876, F1 Micro: 0.8876, F1 Macro: 0.853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1828, Accuracy: 0.8976, F1 Micro: 0.8976, F1 Macro: 0.8668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.131, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8838\n",
      "Epoch 5/10, Train Loss: 0.0944, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8812\n",
      "Epoch 6/10, Train Loss: 0.0793, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8812\n",
      "Epoch 7/10, Train Loss: 0.0615, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0551, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.8877\n",
      "Epoch 9/10, Train Loss: 0.0343, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.8856\n",
      "Epoch 10/10, Train Loss: 0.0217, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.887\n",
      "\n",
      "Sentiment analysis accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.8877\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       779\n",
      "    positive       0.95      0.75      0.83       324\n",
      "\n",
      "    accuracy                           0.91      1103\n",
      "   macro avg       0.92      0.86      0.89      1103\n",
      "weighted avg       0.92      0.91      0.91      1103\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1770: Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.8817\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.87      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.95      0.94       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.83      0.72      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.76      0.61      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.90       200\n",
      "     neutral       0.93      0.94      0.94       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.75      0.79       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.82      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.89      0.97      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.62      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 300.79515266418457 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 52\n",
      "Sampling duration: 19.615519046783447 seconds\n",
      "New train size: 1822\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4921, Accuracy: 0.8356, F1 Micro: 0.9053, F1 Macro: 0.8972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3288, Accuracy: 0.9286, F1 Micro: 0.9567, F1 Macro: 0.9541\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2254, Accuracy: 0.9443, F1 Micro: 0.9659, F1 Macro: 0.964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1804, Accuracy: 0.95, F1 Micro: 0.9693, F1 Macro: 0.9667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1491, Accuracy: 0.9575, F1 Micro: 0.9737, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1233, Accuracy: 0.9608, F1 Micro: 0.9758, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1058, Accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0889, Accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9767\n",
      "Epoch 9/10, Train Loss: 0.0771, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9758\n",
      "Epoch 10/10, Train Loss: 0.0655, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.96      0.92      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4078, Accuracy: 0.8694, F1 Micro: 0.8694, F1 Macro: 0.8363\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2351, Accuracy: 0.8937, F1 Micro: 0.8937, F1 Macro: 0.8669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1834, Accuracy: 0.8991, F1 Micro: 0.8991, F1 Macro: 0.869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1254, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8789\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1009, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8825\n",
      "Epoch 6/10, Train Loss: 0.0743, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8733\n",
      "Epoch 7/10, Train Loss: 0.0661, Accuracy: 0.8982, F1 Micro: 0.8982, F1 Macro: 0.8747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0541, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8866\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0401, Accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8879\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.029, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8907\n",
      "\n",
      "Sentiment analysis accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8907\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       784\n",
      "    positive       0.93      0.76      0.84       326\n",
      "\n",
      "    accuracy                           0.91      1110\n",
      "   macro avg       0.92      0.87      0.89      1110\n",
      "weighted avg       0.92      0.91      0.91      1110\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1822: Accuracy: 0.9602, F1 Micro: 0.9602, F1 Macro: 0.8768\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.81      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.84      0.76      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.58      0.59       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.93      0.91       200\n",
      "     neutral       0.96      0.92      0.94       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.69      0.50      0.58        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.84      0.77      0.80       571\n",
      "weighted avg       0.91      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.92      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.82      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.96      0.96        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 307.3855764865875 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 17.664817333221436 seconds\n",
      "New train size: 1872\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4835, Accuracy: 0.8536, F1 Micro: 0.9147, F1 Macro: 0.9084\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3124, Accuracy: 0.9333, F1 Micro: 0.9594, F1 Macro: 0.9568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2214, Accuracy: 0.9432, F1 Micro: 0.9654, F1 Macro: 0.9634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1781, Accuracy: 0.9528, F1 Micro: 0.9709, F1 Macro: 0.9687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1437, Accuracy: 0.9587, F1 Micro: 0.9745, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.121, Accuracy: 0.9618, F1 Micro: 0.9764, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.103, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9755\n",
      "Epoch 8/10, Train Loss: 0.083, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.073, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "Epoch 10/10, Train Loss: 0.0613, Accuracy: 0.9616, F1 Micro: 0.9763, F1 Macro: 0.9743\n",
      "\n",
      "Aspect detection accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3721, Accuracy: 0.8648, F1 Micro: 0.8648, F1 Macro: 0.829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2235, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1556, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8819\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1109, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0735, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.8916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0713, Accuracy: 0.9185, F1 Micro: 0.9185, F1 Macro: 0.8929\n",
      "Epoch 7/10, Train Loss: 0.0493, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.8894\n",
      "Epoch 8/10, Train Loss: 0.0392, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.8875\n",
      "Epoch 9/10, Train Loss: 0.0266, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.8897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0177, Accuracy: 0.9185, F1 Micro: 0.9185, F1 Macro: 0.8937\n",
      "\n",
      "Sentiment analysis accuracy: 0.9185, F1 Micro: 0.9185, F1 Macro: 0.8937\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       771\n",
      "    positive       0.94      0.76      0.84       309\n",
      "\n",
      "    accuracy                           0.92      1080\n",
      "   macro avg       0.93      0.87      0.89      1080\n",
      "weighted avg       0.92      0.92      0.92      1080\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1872: Accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.8621\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.92      0.91        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.77      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.85      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.58       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       200\n",
      "     neutral       0.93      0.93      0.93       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.81      0.85       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       0.78      0.32      0.45        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.70      0.75       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.82      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.89      0.96      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.69      0.75        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.84      0.86       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.96      0.96        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 310.27906703948975 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 16.112233638763428 seconds\n",
      "New train size: 1922\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.476, Accuracy: 0.8578, F1 Micro: 0.9175, F1 Macro: 0.9116\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3161, Accuracy: 0.9286, F1 Micro: 0.9569, F1 Macro: 0.9546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2157, Accuracy: 0.9457, F1 Micro: 0.9668, F1 Macro: 0.9646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1713, Accuracy: 0.9549, F1 Micro: 0.9722, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.138, Accuracy: 0.9587, F1 Micro: 0.9744, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1173, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0981, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.975\n",
      "Epoch 8/10, Train Loss: 0.0848, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0719, Accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9766\n",
      "Epoch 10/10, Train Loss: 0.0576, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9756\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3682, Accuracy: 0.8696, F1 Micro: 0.8696, F1 Macro: 0.8338\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2138, Accuracy: 0.8868, F1 Micro: 0.8868, F1 Macro: 0.8477\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1449, Accuracy: 0.9149, F1 Micro: 0.9149, F1 Macro: 0.8918\n",
      "Epoch 4/10, Train Loss: 0.1008, Accuracy: 0.9085, F1 Micro: 0.9085, F1 Macro: 0.881\n",
      "Epoch 5/10, Train Loss: 0.076, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.888\n",
      "Epoch 6/10, Train Loss: 0.067, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0403, Accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.8972\n",
      "Epoch 8/10, Train Loss: 0.0467, Accuracy: 0.9121, F1 Micro: 0.9121, F1 Macro: 0.8865\n",
      "Epoch 9/10, Train Loss: 0.0224, Accuracy: 0.9158, F1 Micro: 0.9158, F1 Macro: 0.8923\n",
      "Epoch 10/10, Train Loss: 0.024, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.891\n",
      "\n",
      "Sentiment analysis accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.8972\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       782\n",
      "    positive       0.93      0.78      0.85       322\n",
      "\n",
      "    accuracy                           0.92      1104\n",
      "   macro avg       0.92      0.88      0.90      1104\n",
      "weighted avg       0.92      0.92      0.92      1104\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1922: Accuracy: 0.9604, F1 Micro: 0.9604, F1 Macro: 0.8729\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.79      1.00      0.88        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.92      0.97      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.83      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.77      0.76      0.77       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.81      0.76      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.63      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88       162\n",
      "     neutral       0.93      0.98      0.95       387\n",
      "    positive       0.80      0.55      0.65        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.88        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.91      0.82      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 310.52920842170715 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 13.962871313095093 seconds\n",
      "New train size: 1972\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4794, Accuracy: 0.8497, F1 Micro: 0.9129, F1 Macro: 0.907\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3133, Accuracy: 0.9318, F1 Micro: 0.9584, F1 Macro: 0.9555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2099, Accuracy: 0.9477, F1 Micro: 0.968, F1 Macro: 0.9657\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1716, Accuracy: 0.9503, F1 Micro: 0.9695, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1427, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9732\n",
      "Epoch 6/10, Train Loss: 0.1186, Accuracy: 0.9587, F1 Micro: 0.9745, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0989, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.081, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.976\n",
      "Epoch 9/10, Train Loss: 0.0706, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.975\n",
      "Epoch 10/10, Train Loss: 0.0605, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9753\n",
      "\n",
      "Aspect detection accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3585, Accuracy: 0.8734, F1 Micro: 0.8734, F1 Macro: 0.8322\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2343, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.8749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1467, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1314, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0823, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.8894\n",
      "Epoch 6/10, Train Loss: 0.0689, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.887\n",
      "Epoch 7/10, Train Loss: 0.06, Accuracy: 0.9092, F1 Micro: 0.9092, F1 Macro: 0.8801\n",
      "Epoch 8/10, Train Loss: 0.0531, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8828\n",
      "Epoch 9/10, Train Loss: 0.0343, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.8817\n",
      "Epoch 10/10, Train Loss: 0.0409, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.886\n",
      "\n",
      "Sentiment analysis accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.8894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       777\n",
      "    positive       0.93      0.76      0.84       313\n",
      "\n",
      "    accuracy                           0.91      1090\n",
      "   macro avg       0.92      0.87      0.89      1090\n",
      "weighted avg       0.92      0.91      0.91      1090\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1972: Accuracy: 0.9587, F1 Micro: 0.9587, F1 Macro: 0.8653\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.88      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.83      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.79      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.57      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.83      0.95      0.88        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.83      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.62      0.45      0.53        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.81      0.75      0.78       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.95      0.90      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.83      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 313.67271971702576 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 25\n",
      "Sampling duration: 12.101211786270142 seconds\n",
      "New train size: 1997\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4787, Accuracy: 0.8583, F1 Micro: 0.9174, F1 Macro: 0.912\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2997, Accuracy: 0.9316, F1 Micro: 0.9585, F1 Macro: 0.9558\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2024, Accuracy: 0.9462, F1 Micro: 0.9671, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.165, Accuracy: 0.9536, F1 Micro: 0.9714, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1388, Accuracy: 0.9604, F1 Micro: 0.9756, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1108, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9758\n",
      "Epoch 7/10, Train Loss: 0.0954, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9755\n",
      "Epoch 8/10, Train Loss: 0.0787, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0665, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0572, Accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9768\n",
      "\n",
      "Aspect detection accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3516, Accuracy: 0.8635, F1 Micro: 0.8635, F1 Macro: 0.8145\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2196, Accuracy: 0.8999, F1 Micro: 0.8999, F1 Macro: 0.8682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.141, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1021, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8839\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0741, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.8886\n",
      "Epoch 6/10, Train Loss: 0.0676, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8839\n",
      "Epoch 7/10, Train Loss: 0.0362, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8817\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.017, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8895\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0364, Accuracy: 0.9181, F1 Micro: 0.9181, F1 Macro: 0.8934\n",
      "Epoch 10/10, Train Loss: 0.0239, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8769\n",
      "\n",
      "Sentiment analysis accuracy: 0.9181, F1 Micro: 0.9181, F1 Macro: 0.8934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       783\n",
      "    positive       0.94      0.76      0.84       316\n",
      "\n",
      "    accuracy                           0.92      1099\n",
      "   macro avg       0.93      0.87      0.89      1099\n",
      "weighted avg       0.92      0.92      0.92      1099\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1997: Accuracy: 0.9604, F1 Micro: 0.9604, F1 Macro: 0.8856\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.83      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.86      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.14      0.20         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.85      0.66      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.71      0.60      0.64       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.89       200\n",
      "     neutral       0.93      0.94      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.65      0.50      0.56        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.83      0.77      0.80       571\n",
      "weighted avg       0.91      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.84      0.86       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 329.543488740921 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 11.256837844848633 seconds\n",
      "New train size: 2047\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4645, Accuracy: 0.8722, F1 Micro: 0.9248, F1 Macro: 0.9181\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2937, Accuracy: 0.9372, F1 Micro: 0.9617, F1 Macro: 0.9595\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2107, Accuracy: 0.9481, F1 Micro: 0.9682, F1 Macro: 0.9656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1658, Accuracy: 0.9543, F1 Micro: 0.9719, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1326, Accuracy: 0.9606, F1 Micro: 0.9757, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1139, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0947, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0794, Accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9768\n",
      "Epoch 9/10, Train Loss: 0.0665, Accuracy: 0.9642, F1 Micro: 0.9777, F1 Macro: 0.9755\n",
      "Epoch 10/10, Train Loss: 0.0555, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.93      0.98      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3556, Accuracy: 0.873, F1 Micro: 0.873, F1 Macro: 0.8271\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.21, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.154, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8858\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1045, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8856\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0812, Accuracy: 0.9203, F1 Micro: 0.9203, F1 Macro: 0.8975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0563, Accuracy: 0.9203, F1 Micro: 0.9203, F1 Macro: 0.8961\n",
      "Epoch 7/10, Train Loss: 0.0438, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.8901\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0356, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9016\n",
      "Epoch 9/10, Train Loss: 0.0368, Accuracy: 0.9184, F1 Micro: 0.9184, F1 Macro: 0.8963\n",
      "Epoch 10/10, Train Loss: 0.0331, Accuracy: 0.9184, F1 Micro: 0.9184, F1 Macro: 0.8936\n",
      "\n",
      "Sentiment analysis accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       769\n",
      "    positive       0.93      0.79      0.86       310\n",
      "\n",
      "    accuracy                           0.92      1079\n",
      "   macro avg       0.92      0.88      0.90      1079\n",
      "weighted avg       0.92      0.92      0.92      1079\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2047: Accuracy: 0.9597, F1 Micro: 0.9597, F1 Macro: 0.8721\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.84      0.89        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.58      0.70      0.64        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.84      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.83      0.85        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.57      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.88      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.83      0.86       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       0.77      0.45      0.57        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.75      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.48      0.61        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.68      0.88      0.77        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.79      0.79       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 333.1098430156708 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 9.568656921386719 seconds\n",
      "New train size: 2097\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4679, Accuracy: 0.8665, F1 Micro: 0.9219, F1 Macro: 0.9168\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2877, Accuracy: 0.9354, F1 Micro: 0.9606, F1 Macro: 0.9581\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.207, Accuracy: 0.9507, F1 Micro: 0.9697, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1563, Accuracy: 0.9563, F1 Micro: 0.973, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1349, Accuracy: 0.9592, F1 Micro: 0.9748, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1085, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.092, Accuracy: 0.9677, F1 Micro: 0.9799, F1 Macro: 0.978\n",
      "Epoch 8/10, Train Loss: 0.0773, Accuracy: 0.9668, F1 Micro: 0.9794, F1 Macro: 0.9772\n",
      "Epoch 9/10, Train Loss: 0.0658, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9754\n",
      "Epoch 10/10, Train Loss: 0.0523, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9763\n",
      "\n",
      "Aspect detection accuracy: 0.9677, F1 Micro: 0.9799, F1 Macro: 0.978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3649, Accuracy: 0.8582, F1 Micro: 0.8582, F1 Macro: 0.8115\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1958, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1368, Accuracy: 0.9131, F1 Micro: 0.9131, F1 Macro: 0.8847\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1121, Accuracy: 0.9149, F1 Micro: 0.9149, F1 Macro: 0.8922\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0802, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.8965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0561, Accuracy: 0.9241, F1 Micro: 0.9241, F1 Macro: 0.9016\n",
      "Epoch 7/10, Train Loss: 0.0599, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.8914\n",
      "Epoch 8/10, Train Loss: 0.0501, Accuracy: 0.9149, F1 Micro: 0.9149, F1 Macro: 0.8877\n",
      "Epoch 9/10, Train Loss: 0.0247, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.8988\n",
      "Epoch 10/10, Train Loss: 0.0314, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.8974\n",
      "\n",
      "Sentiment analysis accuracy: 0.9241, F1 Micro: 0.9241, F1 Macro: 0.9016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       783\n",
      "    positive       0.93      0.79      0.85       310\n",
      "\n",
      "    accuracy                           0.92      1093\n",
      "   macro avg       0.93      0.88      0.90      1093\n",
      "weighted avg       0.92      0.92      0.92      1093\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2097: Accuracy: 0.9623, F1 Micro: 0.9623, F1 Macro: 0.892\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.88      0.93        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.78      0.70      0.74        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.86      0.88       571\n",
      "weighted avg       0.98      0.98      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.75      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.62      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.87      0.90       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.89      0.88       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.77      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.82      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 341.39732837677 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 7.675978899002075 seconds\n",
      "New train size: 2147\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4643, Accuracy: 0.8738, F1 Micro: 0.9257, F1 Macro: 0.9193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2808, Accuracy: 0.9363, F1 Micro: 0.961, F1 Macro: 0.958\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1987, Accuracy: 0.9503, F1 Micro: 0.9695, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1599, Accuracy: 0.9523, F1 Micro: 0.9706, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1281, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.975\n",
      "Epoch 6/10, Train Loss: 0.1036, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9732\n",
      "Epoch 7/10, Train Loss: 0.0922, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0725, Accuracy: 0.9649, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0617, Accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0533, Accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.98      0.98       496\n",
      "     general       0.96      0.99      0.97       500\n",
      "  kebersihan       0.94      0.95      0.94       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3465, Accuracy: 0.856, F1 Micro: 0.856, F1 Macro: 0.7959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.203, Accuracy: 0.9052, F1 Micro: 0.9052, F1 Macro: 0.8784\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1305, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8815\n",
      "Epoch 4/10, Train Loss: 0.0918, Accuracy: 0.9052, F1 Micro: 0.9052, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0671, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.886\n",
      "Epoch 6/10, Train Loss: 0.0595, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0448, Accuracy: 0.9152, F1 Micro: 0.9152, F1 Macro: 0.8916\n",
      "Epoch 8/10, Train Loss: 0.0349, Accuracy: 0.9043, F1 Micro: 0.9043, F1 Macro: 0.8787\n",
      "Epoch 9/10, Train Loss: 0.0285, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.8888\n",
      "Epoch 10/10, Train Loss: 0.0154, Accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.8901\n",
      "\n",
      "Sentiment analysis accuracy: 0.9152, F1 Micro: 0.9152, F1 Macro: 0.8916\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       780\n",
      "    positive       0.92      0.78      0.84       317\n",
      "\n",
      "    accuracy                           0.92      1097\n",
      "   macro avg       0.92      0.87      0.89      1097\n",
      "weighted avg       0.92      0.92      0.91      1097\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2147: Accuracy: 0.9595, F1 Micro: 0.9595, F1 Macro: 0.8666\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.86      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.50      0.50      0.50        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.81      0.79      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        78\n",
      "     neutral       0.98      0.98      0.98       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.94      0.87       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.96      0.99      0.97       496\n",
      "    positive       0.89      0.75      0.82        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.78      0.63      0.67       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.86      0.89       200\n",
      "     neutral       0.94      0.95      0.94       315\n",
      "    positive       0.83      0.98      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.75      0.79       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.84      0.85        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.87      0.97      0.92        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.95      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.80      0.94      0.86        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.84      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 341.6716492176056 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 5.957550287246704 seconds\n",
      "New train size: 2197\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4546, Accuracy: 0.8821, F1 Micro: 0.9305, F1 Macro: 0.9251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2734, Accuracy: 0.938, F1 Micro: 0.962, F1 Macro: 0.9592\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1922, Accuracy: 0.951, F1 Micro: 0.97, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1547, Accuracy: 0.9547, F1 Micro: 0.9721, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1262, Accuracy: 0.9582, F1 Micro: 0.9742, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1023, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9744\n",
      "Epoch 7/10, Train Loss: 0.086, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0741, Accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9765\n",
      "Epoch 9/10, Train Loss: 0.0621, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.053, Accuracy: 0.9661, F1 Micro: 0.979, F1 Macro: 0.9772\n",
      "\n",
      "Aspect detection accuracy: 0.9661, F1 Micro: 0.979, F1 Macro: 0.9772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.92      0.97      0.95       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3391, Accuracy: 0.8839, F1 Micro: 0.8839, F1 Macro: 0.8504\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1873, Accuracy: 0.9053, F1 Micro: 0.9053, F1 Macro: 0.8749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1219, Accuracy: 0.9155, F1 Micro: 0.9155, F1 Macro: 0.8896\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0868, Accuracy: 0.9155, F1 Micro: 0.9155, F1 Macro: 0.8935\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0747, Accuracy: 0.9211, F1 Micro: 0.9211, F1 Macro: 0.8985\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.052, Accuracy: 0.9257, F1 Micro: 0.9257, F1 Macro: 0.9048\n",
      "Epoch 7/10, Train Loss: 0.0376, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.8966\n",
      "Epoch 8/10, Train Loss: 0.0239, Accuracy: 0.9211, F1 Micro: 0.9211, F1 Macro: 0.8976\n",
      "Epoch 9/10, Train Loss: 0.0273, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.8915\n",
      "Epoch 10/10, Train Loss: 0.0208, Accuracy: 0.9229, F1 Micro: 0.9229, F1 Macro: 0.9002\n",
      "\n",
      "Sentiment analysis accuracy: 0.9257, F1 Micro: 0.9257, F1 Macro: 0.9048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       770\n",
      "    positive       0.93      0.80      0.86       307\n",
      "\n",
      "    accuracy                           0.93      1077\n",
      "   macro avg       0.93      0.89      0.90      1077\n",
      "weighted avg       0.93      0.93      0.92      1077\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2197: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.8809\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.80      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.82      0.75      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.62      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.85      0.90       200\n",
      "     neutral       0.92      0.97      0.95       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.84      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.79      0.50      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.87      0.77      0.81       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.82      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.89      0.96      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.83      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 347.42554569244385 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 4.177537441253662 seconds\n",
      "New train size: 2247\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4548, Accuracy: 0.8814, F1 Micro: 0.9295, F1 Macro: 0.9227\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2647, Accuracy: 0.9424, F1 Micro: 0.9647, F1 Macro: 0.9625\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1875, Accuracy: 0.9497, F1 Micro: 0.9691, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1505, Accuracy: 0.959, F1 Micro: 0.9747, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.122, Accuracy: 0.9641, F1 Micro: 0.9776, F1 Macro: 0.9755\n",
      "Epoch 6/10, Train Loss: 0.0982, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0831, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9756\n",
      "Epoch 8/10, Train Loss: 0.0737, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0619, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.976\n",
      "Epoch 10/10, Train Loss: 0.0504, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9751\n",
      "\n",
      "Aspect detection accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.98      0.95      0.96       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.342, Accuracy: 0.8516, F1 Micro: 0.8516, F1 Macro: 0.7954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1864, Accuracy: 0.8921, F1 Micro: 0.8921, F1 Macro: 0.8625\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1277, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8762\n",
      "Epoch 4/10, Train Loss: 0.1004, Accuracy: 0.8948, F1 Micro: 0.8948, F1 Macro: 0.8622\n",
      "Epoch 5/10, Train Loss: 0.0705, Accuracy: 0.9029, F1 Micro: 0.9029, F1 Macro: 0.8773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0572, Accuracy: 0.9047, F1 Micro: 0.9047, F1 Macro: 0.879\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0338, Accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.8797\n",
      "Epoch 8/10, Train Loss: 0.0396, Accuracy: 0.9056, F1 Micro: 0.9056, F1 Macro: 0.8774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0309, Accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.8805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0172, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8857\n",
      "\n",
      "Sentiment analysis accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       784\n",
      "    positive       0.94      0.75      0.83       328\n",
      "\n",
      "    accuracy                           0.91      1112\n",
      "   macro avg       0.92      0.86      0.89      1112\n",
      "weighted avg       0.91      0.91      0.91      1112\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2247: Accuracy: 0.9595, F1 Micro: 0.9595, F1 Macro: 0.8721\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.83      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.85      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.88      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88       162\n",
      "     neutral       0.94      0.97      0.96       387\n",
      "    positive       1.00      0.50      0.67        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.94      0.78      0.83       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.88      0.84        85\n",
      "     neutral       0.98      0.95      0.96       418\n",
      "    positive       0.92      0.97      0.94        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.62      0.73        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.80      0.94      0.86        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.85      0.86       571\n",
      "weighted avg       0.98      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.91      0.99      0.95       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 352.2561299800873 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 36\n",
      "Sampling duration: 2.296922206878662 seconds\n",
      "New train size: 2283\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4456, Accuracy: 0.8873, F1 Micro: 0.9335, F1 Macro: 0.9294\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2593, Accuracy: 0.9401, F1 Micro: 0.9634, F1 Macro: 0.9612\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1813, Accuracy: 0.9486, F1 Micro: 0.9684, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1477, Accuracy: 0.9573, F1 Micro: 0.9736, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.119, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0989, Accuracy: 0.9651, F1 Micro: 0.9784, F1 Macro: 0.9762\n",
      "Epoch 7/10, Train Loss: 0.0832, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9761\n",
      "Epoch 8/10, Train Loss: 0.0694, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.975\n",
      "Epoch 9/10, Train Loss: 0.0583, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9752\n",
      "Epoch 10/10, Train Loss: 0.0487, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9741\n",
      "\n",
      "Aspect detection accuracy: 0.9651, F1 Micro: 0.9784, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.92      0.95      0.93       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3356, Accuracy: 0.8829, F1 Micro: 0.8829, F1 Macro: 0.8443\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1917, Accuracy: 0.8941, F1 Micro: 0.8941, F1 Macro: 0.8601\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1299, Accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8852\n",
      "Epoch 4/10, Train Loss: 0.0953, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8817\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0616, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0579, Accuracy: 0.921, F1 Micro: 0.921, F1 Macro: 0.898\n",
      "Epoch 7/10, Train Loss: 0.0522, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8909\n",
      "Epoch 8/10, Train Loss: 0.0345, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8914\n",
      "Epoch 9/10, Train Loss: 0.0322, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8911\n",
      "Epoch 10/10, Train Loss: 0.0348, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.8937\n",
      "\n",
      "Sentiment analysis accuracy: 0.921, F1 Micro: 0.921, F1 Macro: 0.898\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       768\n",
      "    positive       0.93      0.78      0.85       308\n",
      "\n",
      "    accuracy                           0.92      1076\n",
      "   macro avg       0.93      0.88      0.90      1076\n",
      "weighted avg       0.92      0.92      0.92      1076\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2283: Accuracy: 0.9592, F1 Micro: 0.9592, F1 Macro: 0.8729\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.85      0.89        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.81      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.57      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.84      0.88       200\n",
      "     neutral       0.92      0.95      0.93       315\n",
      "    positive       0.84      0.95      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.91      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.75      0.55      0.63        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.86      0.79      0.82       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.95      0.93      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.84      0.86       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 346.667183637619 s\n",
      "Total runtime: 9084.411217689514 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "initial_train_size = int(0.01 * total_data)\n",
    "active_learning(81, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e521a687",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-17T17:36:40.796311Z",
     "iopub.status.busy": "2025-05-17T17:36:40.795926Z",
     "iopub.status.idle": "2025-05-17T19:51:41.627823Z",
     "shell.execute_reply": "2025-05-17T19:51:41.626523Z"
    },
    "papermill": {
     "duration": 8101.084401,
     "end_time": "2025-05-17T19:51:41.629850",
     "exception": false,
     "start_time": "2025-05-17T17:36:40.545449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "Init Size 10\n",
      "Random seed: 81\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6304, Accuracy: 0.8014, F1 Micro: 0.8897, F1 Macro: 0.8853\n",
      "Epoch 2/10, Train Loss: 0.4839, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Epoch 3/10, Train Loss: 0.4418, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4257, Accuracy: 0.803, F1 Micro: 0.8905, F1 Macro: 0.8861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4169, Accuracy: 0.8304, F1 Micro: 0.9037, F1 Macro: 0.8985\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3785, Accuracy: 0.8505, F1 Micro: 0.9137, F1 Macro: 0.9087\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3439, Accuracy: 0.8767, F1 Micro: 0.9277, F1 Macro: 0.9227\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3093, Accuracy: 0.8839, F1 Micro: 0.9316, F1 Macro: 0.9269\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.274, Accuracy: 0.9042, F1 Micro: 0.9423, F1 Macro: 0.9378\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.2436, Accuracy: 0.9104, F1 Micro: 0.9458, F1 Macro: 0.9416\n",
      "\n",
      "Aspect detection accuracy: 0.9104, F1 Micro: 0.9458, F1 Macro: 0.9416\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.97      0.99      0.98       462\n",
      "   air_panas       0.92      0.99      0.96       480\n",
      "         bau       0.93      0.97      0.95       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.88      0.81      0.84       317\n",
      "       linen       0.87      0.96      0.91       392\n",
      "     service       0.93      0.99      0.96       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.90      1.00      0.95       516\n",
      "        wifi       0.97      0.99      0.98       498\n",
      "\n",
      "   micro avg       0.92      0.98      0.95      4614\n",
      "   macro avg       0.92      0.97      0.94      4614\n",
      "weighted avg       0.92      0.98      0.95      4614\n",
      " samples avg       0.92      0.98      0.94      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5629, Accuracy: 0.7088, F1 Micro: 0.7088, F1 Macro: 0.4148\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3944, Accuracy: 0.7804, F1 Micro: 0.7804, F1 Macro: 0.7113\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3384, Accuracy: 0.7995, F1 Micro: 0.7995, F1 Macro: 0.7497\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2906, Accuracy: 0.815, F1 Micro: 0.815, F1 Macro: 0.7518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.233, Accuracy: 0.815, F1 Micro: 0.815, F1 Macro: 0.7668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2122, Accuracy: 0.815, F1 Micro: 0.815, F1 Macro: 0.7615\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1913, Accuracy: 0.8222, F1 Micro: 0.8222, F1 Macro: 0.7497\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1635, Accuracy: 0.8305, F1 Micro: 0.8305, F1 Macro: 0.7737\n",
      "Epoch 9/10, Train Loss: 0.1457, Accuracy: 0.8103, F1 Micro: 0.8103, F1 Macro: 0.767\n",
      "Epoch 10/10, Train Loss: 0.1325, Accuracy: 0.827, F1 Micro: 0.827, F1 Macro: 0.7615\n",
      "\n",
      "Sentiment analysis accuracy: 0.8305, F1 Micro: 0.8305, F1 Macro: 0.7737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.94      0.89       594\n",
      "    positive       0.79      0.57      0.66       244\n",
      "\n",
      "    accuracy                           0.83       838\n",
      "   macro avg       0.82      0.75      0.77       838\n",
      "weighted avg       0.83      0.83      0.82       838\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 285: Accuracy: 0.8984, F1 Micro: 0.8984, F1 Macro: 0.5821\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.87      0.89        97\n",
      "     neutral       0.97      0.99      0.98       459\n",
      "    positive       0.88      0.47      0.61        15\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.92      0.78      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.58      0.71        86\n",
      "     neutral       0.92      0.99      0.96       475\n",
      "    positive       0.50      0.30      0.37        10\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.78      0.62      0.68       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.59      0.65        78\n",
      "     neutral       0.93      0.97      0.95       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.55      0.52      0.53       571\n",
      "weighted avg       0.90      0.91      0.91       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.33      0.01      0.03        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.40      0.34      0.32       571\n",
      "weighted avg       0.80      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.73      0.76       200\n",
      "     neutral       0.88      0.81      0.84       315\n",
      "    positive       0.46      0.79      0.58        56\n",
      "\n",
      "    accuracy                           0.78       571\n",
      "   macro avg       0.71      0.78      0.73       571\n",
      "weighted avg       0.81      0.78      0.79       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.73      0.78       162\n",
      "     neutral       0.87      0.96      0.91       387\n",
      "    positive       1.00      0.18      0.31        22\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.90      0.62      0.67       571\n",
      "weighted avg       0.87      0.86      0.85       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.64      0.72        85\n",
      "     neutral       0.92      1.00      0.96       418\n",
      "    positive       0.84      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.78      0.82       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.90      1.00      0.95       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.30      0.33      0.32       571\n",
      "weighted avg       0.80      0.89      0.85       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.81      0.86        74\n",
      "     neutral       0.97      0.99      0.98       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.63      0.60      0.61       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Total train time: 121.3492820262909 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 200\n",
      "Sampling duration: 60.875969648361206 seconds\n",
      "New train size: 485\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5664, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4682, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4478, Accuracy: 0.8155, F1 Micro: 0.8967, F1 Macro: 0.8926\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3958, Accuracy: 0.8602, F1 Micro: 0.9188, F1 Macro: 0.9133\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3406, Accuracy: 0.899, F1 Micro: 0.9395, F1 Macro: 0.9345\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2841, Accuracy: 0.9075, F1 Micro: 0.9444, F1 Macro: 0.9405\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2442, Accuracy: 0.9234, F1 Micro: 0.9535, F1 Macro: 0.9503\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2098, Accuracy: 0.9292, F1 Micro: 0.9568, F1 Macro: 0.9537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1858, Accuracy: 0.9344, F1 Micro: 0.9598, F1 Macro: 0.9565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1635, Accuracy: 0.9415, F1 Micro: 0.964, F1 Macro: 0.9611\n",
      "\n",
      "Aspect detection accuracy: 0.9415, F1 Micro: 0.964, F1 Macro: 0.9611\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.95      0.99      0.97       480\n",
      "         bau       0.96      0.96      0.96       496\n",
      "     general       0.89      0.98      0.94       500\n",
      "  kebersihan       0.90      0.90      0.90       317\n",
      "       linen       0.89      0.97      0.93       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.95      1.00      0.97       530\n",
      "          tv       0.98      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.95      0.98      0.96      4614\n",
      "   macro avg       0.95      0.98      0.96      4614\n",
      "weighted avg       0.95      0.98      0.96      4614\n",
      " samples avg       0.95      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5287, Accuracy: 0.718, F1 Micro: 0.718, F1 Macro: 0.4214\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3423, Accuracy: 0.8308, F1 Micro: 0.8308, F1 Macro: 0.7645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2623, Accuracy: 0.8449, F1 Micro: 0.8449, F1 Macro: 0.8046\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2414, Accuracy: 0.861, F1 Micro: 0.861, F1 Macro: 0.8151\n",
      "Epoch 5/10, Train Loss: 0.173, Accuracy: 0.8469, F1 Micro: 0.8469, F1 Macro: 0.7759\n",
      "Epoch 6/10, Train Loss: 0.1552, Accuracy: 0.851, F1 Micro: 0.851, F1 Macro: 0.7853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0995, Accuracy: 0.8711, F1 Micro: 0.8711, F1 Macro: 0.8232\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0838, Accuracy: 0.8771, F1 Micro: 0.8771, F1 Macro: 0.8329\n",
      "Epoch 9/10, Train Loss: 0.0845, Accuracy: 0.8751, F1 Micro: 0.8751, F1 Macro: 0.8306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.055, Accuracy: 0.8822, F1 Micro: 0.8822, F1 Macro: 0.8434\n",
      "\n",
      "Sentiment analysis accuracy: 0.8822, F1 Micro: 0.8822, F1 Macro: 0.8434\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92       712\n",
      "    positive       0.88      0.68      0.77       281\n",
      "\n",
      "    accuracy                           0.88       993\n",
      "   macro avg       0.88      0.82      0.84       993\n",
      "weighted avg       0.88      0.88      0.88       993\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 485: Accuracy: 0.9336, F1 Micro: 0.9336, F1 Macro: 0.7521\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.90      0.93        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.82      0.93      0.87        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.92      0.94      0.93       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.71      0.81        86\n",
      "     neutral       0.95      0.99      0.97       475\n",
      "    positive       0.50      0.50      0.50        10\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.80      0.73      0.76       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.79      0.78        78\n",
      "     neutral       0.96      0.96      0.96       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.58      0.59      0.58       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.90      0.98      0.94       496\n",
      "    positive       0.69      0.26      0.38        68\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.53      0.42      0.44       571\n",
      "weighted avg       0.86      0.89      0.86       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.81      0.83       200\n",
      "     neutral       0.90      0.90      0.90       315\n",
      "    positive       0.80      0.91      0.85        56\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.85      0.87      0.86       571\n",
      "weighted avg       0.87      0.87      0.87       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.75      0.82       162\n",
      "     neutral       0.89      0.97      0.93       387\n",
      "    positive       0.62      0.36      0.46        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.80      0.70      0.74       571\n",
      "weighted avg       0.88      0.89      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.87      0.84        85\n",
      "     neutral       0.97      0.96      0.97       418\n",
      "    positive       0.89      0.87      0.88        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.89      0.90      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.10      0.18        29\n",
      "     neutral       0.95      1.00      0.97       525\n",
      "    positive       0.53      0.47      0.50        17\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.69      0.52      0.55       571\n",
      "weighted avg       0.92      0.94      0.92       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.87      0.91        54\n",
      "     neutral       0.98      1.00      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.98      0.85      0.90       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.86      0.87       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 149.4989504814148 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 180\n",
      "Sampling duration: 59.614946365356445 seconds\n",
      "New train size: 665\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5588, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4654, Accuracy: 0.8085, F1 Micro: 0.8911, F1 Macro: 0.8808\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4233, Accuracy: 0.8545, F1 Micro: 0.9154, F1 Macro: 0.9089\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3651, Accuracy: 0.8998, F1 Micro: 0.9396, F1 Macro: 0.934\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2941, Accuracy: 0.921, F1 Micro: 0.9521, F1 Macro: 0.9488\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2398, Accuracy: 0.9328, F1 Micro: 0.959, F1 Macro: 0.956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2167, Accuracy: 0.9384, F1 Micro: 0.9624, F1 Macro: 0.9597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1821, Accuracy: 0.9443, F1 Micro: 0.9658, F1 Macro: 0.9627\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1566, Accuracy: 0.9451, F1 Micro: 0.9663, F1 Macro: 0.9634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1418, Accuracy: 0.9458, F1 Micro: 0.9668, F1 Macro: 0.9637\n",
      "\n",
      "Aspect detection accuracy: 0.9458, F1 Micro: 0.9668, F1 Macro: 0.9637\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.97      0.99      0.98       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.96      0.97      0.97       496\n",
      "     general       0.92      0.98      0.95       500\n",
      "  kebersihan       0.88      0.91      0.90       317\n",
      "       linen       0.89      0.98      0.93       392\n",
      "     service       0.95      0.98      0.97       423\n",
      "sunrise_meal       0.96      1.00      0.98       530\n",
      "          tv       0.98      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      4614\n",
      "   macro avg       0.95      0.98      0.96      4614\n",
      "weighted avg       0.95      0.98      0.97      4614\n",
      " samples avg       0.95      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5276, Accuracy: 0.82, F1 Micro: 0.82, F1 Macro: 0.7672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3146, Accuracy: 0.8252, F1 Micro: 0.8252, F1 Macro: 0.7298\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2625, Accuracy: 0.8528, F1 Micro: 0.8528, F1 Macro: 0.7847\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2134, Accuracy: 0.8814, F1 Micro: 0.8814, F1 Macro: 0.8466\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1685, Accuracy: 0.8957, F1 Micro: 0.8957, F1 Macro: 0.8637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1142, Accuracy: 0.8967, F1 Micro: 0.8967, F1 Macro: 0.8648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0875, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0733, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8663\n",
      "Epoch 9/10, Train Loss: 0.0587, Accuracy: 0.8998, F1 Micro: 0.8998, F1 Macro: 0.868\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0527, Accuracy: 0.9049, F1 Micro: 0.9049, F1 Macro: 0.8759\n",
      "\n",
      "Sentiment analysis accuracy: 0.9049, F1 Micro: 0.9049, F1 Macro: 0.8759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94       704\n",
      "    positive       0.89      0.75      0.82       274\n",
      "\n",
      "    accuracy                           0.90       978\n",
      "   macro avg       0.90      0.86      0.88       978\n",
      "weighted avg       0.90      0.90      0.90       978\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 665: Accuracy: 0.9389, F1 Micro: 0.9389, F1 Macro: 0.8023\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.86      0.91        97\n",
      "     neutral       0.97      0.99      0.98       459\n",
      "    positive       0.80      0.80      0.80        15\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.91      0.88      0.90       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.79      0.86        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.55      0.60      0.57        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.81      0.79      0.80       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.78      0.80        78\n",
      "     neutral       0.96      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.75      0.81       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.92      0.98      0.95       496\n",
      "    positive       0.79      0.46      0.58        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.57      0.48      0.51       571\n",
      "weighted avg       0.89      0.91      0.89       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.79      0.83       200\n",
      "     neutral       0.88      0.91      0.90       315\n",
      "    positive       0.78      0.89      0.83        56\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.85      0.87      0.85       571\n",
      "weighted avg       0.87      0.87      0.87       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.73      0.81       162\n",
      "     neutral       0.89      0.98      0.93       387\n",
      "    positive       0.62      0.36      0.46        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.80      0.69      0.73       571\n",
      "weighted avg       0.88      0.89      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.82      0.86        85\n",
      "     neutral       0.95      0.98      0.97       418\n",
      "    positive       0.92      0.85      0.89        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.89      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.70      0.24      0.36        29\n",
      "     neutral       0.96      1.00      0.98       525\n",
      "    positive       0.71      0.71      0.71        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.79      0.65      0.68       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.83      0.89        54\n",
      "     neutral       0.98      1.00      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.98      0.83      0.89       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.92      0.95        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.97      0.93       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 174.44014239311218 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 162\n",
      "Sampling duration: 56.04399824142456 seconds\n",
      "New train size: 827\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5411, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4614, Accuracy: 0.8283, F1 Micro: 0.902, F1 Macro: 0.8952\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3924, Accuracy: 0.8934, F1 Micro: 0.9366, F1 Macro: 0.9316\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3134, Accuracy: 0.9177, F1 Micro: 0.9499, F1 Macro: 0.9449\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2444, Accuracy: 0.9361, F1 Micro: 0.961, F1 Macro: 0.9585\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2123, Accuracy: 0.9458, F1 Micro: 0.9668, F1 Macro: 0.9641\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1785, Accuracy: 0.9502, F1 Micro: 0.9693, F1 Macro: 0.9666\n",
      "Epoch 8/10, Train Loss: 0.1572, Accuracy: 0.9497, F1 Micro: 0.9689, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1397, Accuracy: 0.9547, F1 Micro: 0.972, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1195, Accuracy: 0.955, F1 Micro: 0.9722, F1 Macro: 0.9693\n",
      "\n",
      "Aspect detection accuracy: 0.955, F1 Micro: 0.9722, F1 Macro: 0.9693\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.96      0.99      0.97       496\n",
      "     general       0.93      0.99      0.96       500\n",
      "  kebersihan       0.93      0.90      0.91       317\n",
      "       linen       0.90      0.98      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.99       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4697, Accuracy: 0.8417, F1 Micro: 0.8417, F1 Macro: 0.7961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2763, Accuracy: 0.8745, F1 Micro: 0.8745, F1 Macro: 0.8327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2388, Accuracy: 0.8803, F1 Micro: 0.8803, F1 Macro: 0.8366\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1916, Accuracy: 0.8929, F1 Micro: 0.8929, F1 Macro: 0.8547\n",
      "Epoch 5/10, Train Loss: 0.1517, Accuracy: 0.89, F1 Micro: 0.89, F1 Macro: 0.8501\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1074, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0826, Accuracy: 0.9025, F1 Micro: 0.9025, F1 Macro: 0.8743\n",
      "Epoch 8/10, Train Loss: 0.0861, Accuracy: 0.8958, F1 Micro: 0.8958, F1 Macro: 0.8614\n",
      "Epoch 9/10, Train Loss: 0.0616, Accuracy: 0.8986, F1 Micro: 0.8986, F1 Macro: 0.8647\n",
      "Epoch 10/10, Train Loss: 0.0496, Accuracy: 0.9006, F1 Micro: 0.9006, F1 Macro: 0.8693\n",
      "\n",
      "Sentiment analysis accuracy: 0.9025, F1 Micro: 0.9025, F1 Macro: 0.8743\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.93       743\n",
      "    positive       0.88      0.76      0.81       293\n",
      "\n",
      "    accuracy                           0.90      1036\n",
      "   macro avg       0.90      0.86      0.87      1036\n",
      "weighted avg       0.90      0.90      0.90      1036\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 827: Accuracy: 0.9471, F1 Micro: 0.9471, F1 Macro: 0.818\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.90      0.93        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.78      0.93      0.85        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.89        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.45      0.50      0.48        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.78      0.78      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.73      0.80        78\n",
      "     neutral       0.96      0.99      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.74      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.92      0.99      0.96       496\n",
      "    positive       0.88      0.51      0.65        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.60      0.50      0.53       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86       200\n",
      "     neutral       0.93      0.90      0.91       315\n",
      "    positive       0.77      0.96      0.86        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.86      0.90      0.88       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.75      0.82       162\n",
      "     neutral       0.90      0.98      0.94       387\n",
      "    positive       0.43      0.27      0.33        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.75      0.67      0.70       571\n",
      "weighted avg       0.88      0.89      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.84      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.41      0.57        29\n",
      "     neutral       0.97      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.88      0.76      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.98      0.86      0.91       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.95      0.96        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.98      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 187.64949297904968 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 146\n",
      "Sampling duration: 50.93711709976196 seconds\n",
      "New train size: 973\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5309, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4493, Accuracy: 0.8455, F1 Micro: 0.9112, F1 Macro: 0.9059\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3648, Accuracy: 0.9099, F1 Micro: 0.9456, F1 Macro: 0.941\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2757, Accuracy: 0.9363, F1 Micro: 0.9609, F1 Macro: 0.9574\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2262, Accuracy: 0.9479, F1 Micro: 0.968, F1 Macro: 0.9654\n",
      "Epoch 6/10, Train Loss: 0.1962, Accuracy: 0.945, F1 Micro: 0.9664, F1 Macro: 0.9638\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1696, Accuracy: 0.9561, F1 Micro: 0.9729, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1443, Accuracy: 0.9576, F1 Micro: 0.9738, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1198, Accuracy: 0.959, F1 Micro: 0.9746, F1 Macro: 0.9719\n",
      "Epoch 10/10, Train Loss: 0.1132, Accuracy: 0.9576, F1 Micro: 0.9738, F1 Macro: 0.9714\n",
      "\n",
      "Aspect detection accuracy: 0.959, F1 Micro: 0.9746, F1 Macro: 0.9719\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.93      0.90      0.92       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.96      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5025, Accuracy: 0.8319, F1 Micro: 0.8319, F1 Macro: 0.7591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3233, Accuracy: 0.8609, F1 Micro: 0.8609, F1 Macro: 0.8158\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2546, Accuracy: 0.8758, F1 Micro: 0.8758, F1 Macro: 0.8318\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1863, Accuracy: 0.8786, F1 Micro: 0.8786, F1 Macro: 0.8336\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1568, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8745\n",
      "Epoch 6/10, Train Loss: 0.1304, Accuracy: 0.8945, F1 Micro: 0.8945, F1 Macro: 0.8654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1053, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.079, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8796\n",
      "Epoch 9/10, Train Loss: 0.0626, Accuracy: 0.8982, F1 Micro: 0.8982, F1 Macro: 0.8662\n",
      "Epoch 10/10, Train Loss: 0.0404, Accuracy: 0.9001, F1 Micro: 0.9001, F1 Macro: 0.872\n",
      "\n",
      "Sentiment analysis accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8796\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       760\n",
      "    positive       0.93      0.73      0.82       311\n",
      "\n",
      "    accuracy                           0.91      1071\n",
      "   macro avg       0.92      0.86      0.88      1071\n",
      "weighted avg       0.91      0.91      0.90      1071\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 973: Accuracy: 0.9525, F1 Micro: 0.9525, F1 Macro: 0.8386\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.80      0.40      0.53        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.89      0.75      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.81      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.82      0.62      0.71        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.53      0.55       571\n",
      "weighted avg       0.91      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.88       200\n",
      "     neutral       0.93      0.90      0.92       315\n",
      "    positive       0.80      0.93      0.86        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.87      0.90      0.88       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.81      0.85       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       0.73      0.36      0.48        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.85      0.72      0.76       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.84      0.86        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.52      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.76      0.76        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.76      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 206.5886082649231 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 131\n",
      "Sampling duration: 45.98215579986572 seconds\n",
      "New train size: 1104\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5302, Accuracy: 0.8012, F1 Micro: 0.8896, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4418, Accuracy: 0.8667, F1 Micro: 0.9213, F1 Macro: 0.9135\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3371, Accuracy: 0.9155, F1 Micro: 0.9491, F1 Macro: 0.946\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2634, Accuracy: 0.9429, F1 Micro: 0.9648, F1 Macro: 0.9619\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.219, Accuracy: 0.9464, F1 Micro: 0.9672, F1 Macro: 0.9648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1795, Accuracy: 0.9507, F1 Micro: 0.9697, F1 Macro: 0.9667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1593, Accuracy: 0.9542, F1 Micro: 0.9716, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1348, Accuracy: 0.9556, F1 Micro: 0.9725, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1206, Accuracy: 0.9576, F1 Micro: 0.9738, F1 Macro: 0.9713\n",
      "Epoch 10/10, Train Loss: 0.1021, Accuracy: 0.9569, F1 Micro: 0.9734, F1 Macro: 0.9708\n",
      "\n",
      "Aspect detection accuracy: 0.9576, F1 Micro: 0.9738, F1 Macro: 0.9713\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.94      0.91      0.93       317\n",
      "       linen       0.90      0.98      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.99       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.99      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.443, Accuracy: 0.8566, F1 Micro: 0.8566, F1 Macro: 0.8039\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3018, Accuracy: 0.8699, F1 Micro: 0.8699, F1 Macro: 0.8266\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2382, Accuracy: 0.886, F1 Micro: 0.886, F1 Macro: 0.8527\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1888, Accuracy: 0.9022, F1 Micro: 0.9022, F1 Macro: 0.8731\n",
      "Epoch 5/10, Train Loss: 0.1234, Accuracy: 0.8965, F1 Micro: 0.8965, F1 Macro: 0.8705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0881, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8829\n",
      "Epoch 7/10, Train Loss: 0.0752, Accuracy: 0.9041, F1 Micro: 0.9041, F1 Macro: 0.8747\n",
      "Epoch 8/10, Train Loss: 0.0615, Accuracy: 0.9022, F1 Micro: 0.9022, F1 Macro: 0.8725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0457, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8788\n",
      "Epoch 10/10, Train Loss: 0.0391, Accuracy: 0.8879, F1 Micro: 0.8879, F1 Macro: 0.8622\n",
      "\n",
      "Sentiment analysis accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       751\n",
      "    positive       0.94      0.73      0.82       302\n",
      "\n",
      "    accuracy                           0.91      1053\n",
      "   macro avg       0.92      0.85      0.88      1053\n",
      "weighted avg       0.91      0.91      0.90      1053\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1104: Accuracy: 0.9515, F1 Micro: 0.9515, F1 Macro: 0.8339\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.88      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.80      0.40      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.76      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.79      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.84      0.62      0.71        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.53      0.56       571\n",
      "weighted avg       0.91      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88       200\n",
      "     neutral       0.94      0.91      0.92       315\n",
      "    positive       0.84      0.95      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.91      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.78      0.84       162\n",
      "     neutral       0.90      0.98      0.94       387\n",
      "    positive       1.00      0.27      0.43        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.93      0.68      0.73       571\n",
      "weighted avg       0.90      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.87      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.94      0.90      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.41      0.55        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.74      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.91      0.93        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.91      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.95      0.97        74\n",
      "     neutral       0.99      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.98      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 224.42625308036804 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 118\n",
      "Sampling duration: 42.07374572753906 seconds\n",
      "New train size: 1222\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5274, Accuracy: 0.8148, F1 Micro: 0.8957, F1 Macro: 0.8898\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4204, Accuracy: 0.8835, F1 Micro: 0.9306, F1 Macro: 0.924\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3137, Accuracy: 0.9304, F1 Micro: 0.9577, F1 Macro: 0.9548\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.242, Accuracy: 0.9458, F1 Micro: 0.9667, F1 Macro: 0.9643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1984, Accuracy: 0.9505, F1 Micro: 0.9695, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1692, Accuracy: 0.9545, F1 Micro: 0.972, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1456, Accuracy: 0.9573, F1 Micro: 0.9736, F1 Macro: 0.971\n",
      "Epoch 8/10, Train Loss: 0.1231, Accuracy: 0.9568, F1 Micro: 0.9731, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1104, Accuracy: 0.9595, F1 Micro: 0.9749, F1 Macro: 0.9723\n",
      "Epoch 10/10, Train Loss: 0.0924, Accuracy: 0.9585, F1 Micro: 0.9743, F1 Macro: 0.972\n",
      "\n",
      "Aspect detection accuracy: 0.9595, F1 Micro: 0.9749, F1 Macro: 0.9723\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.95      0.91      0.93       317\n",
      "       linen       0.91      0.98      0.94       392\n",
      "     service       0.97      0.96      0.96       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.452, Accuracy: 0.8419, F1 Micro: 0.8419, F1 Macro: 0.7959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3068, Accuracy: 0.8675, F1 Micro: 0.8675, F1 Macro: 0.8344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2201, Accuracy: 0.8803, F1 Micro: 0.8803, F1 Macro: 0.8411\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1947, Accuracy: 0.8894, F1 Micro: 0.8894, F1 Macro: 0.8588\n",
      "Epoch 5/10, Train Loss: 0.1295, Accuracy: 0.8867, F1 Micro: 0.8867, F1 Macro: 0.8522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1051, Accuracy: 0.8967, F1 Micro: 0.8967, F1 Macro: 0.8682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1, Accuracy: 0.8967, F1 Micro: 0.8967, F1 Macro: 0.8673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0634, Accuracy: 0.8976, F1 Micro: 0.8976, F1 Macro: 0.8677\n",
      "Epoch 9/10, Train Loss: 0.0514, Accuracy: 0.8949, F1 Micro: 0.8949, F1 Macro: 0.8655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0436, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8737\n",
      "\n",
      "Sentiment analysis accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93       767\n",
      "    positive       0.91      0.74      0.82       327\n",
      "\n",
      "    accuracy                           0.90      1094\n",
      "   macro avg       0.90      0.85      0.87      1094\n",
      "weighted avg       0.90      0.90      0.90      1094\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1222: Accuracy: 0.9534, F1 Micro: 0.9534, F1 Macro: 0.846\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.85      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.77      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.84      0.68      0.75        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.55      0.57       571\n",
      "weighted avg       0.92      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.90      0.88       200\n",
      "     neutral       0.95      0.91      0.93       315\n",
      "    positive       0.86      0.96      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.78      0.84       162\n",
      "     neutral       0.90      0.98      0.94       387\n",
      "    positive       0.73      0.50      0.59        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.85      0.75      0.79       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        85\n",
      "     neutral       0.97      0.96      0.97       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.91      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.83      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.89      0.91        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.62      0.83      0.71         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.85      0.91      0.87       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 239.08478355407715 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 107\n",
      "Sampling duration: 37.6899631023407 seconds\n",
      "New train size: 1329\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.52, Accuracy: 0.8095, F1 Micro: 0.8912, F1 Macro: 0.8791\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4066, Accuracy: 0.8983, F1 Micro: 0.9394, F1 Macro: 0.9343\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2922, Accuracy: 0.9306, F1 Micro: 0.9579, F1 Macro: 0.9549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2244, Accuracy: 0.9453, F1 Micro: 0.9663, F1 Macro: 0.9638\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1906, Accuracy: 0.9535, F1 Micro: 0.9713, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1565, Accuracy: 0.9554, F1 Micro: 0.9724, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1317, Accuracy: 0.9578, F1 Micro: 0.974, F1 Macro: 0.9717\n",
      "Epoch 8/10, Train Loss: 0.1183, Accuracy: 0.9559, F1 Micro: 0.9729, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1012, Accuracy: 0.959, F1 Micro: 0.9746, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.083, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.974\n",
      "\n",
      "Aspect detection accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.94      0.91      0.93       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4437, Accuracy: 0.8489, F1 Micro: 0.8489, F1 Macro: 0.7973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2943, Accuracy: 0.881, F1 Micro: 0.881, F1 Macro: 0.845\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2205, Accuracy: 0.8874, F1 Micro: 0.8874, F1 Macro: 0.8485\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1572, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1152, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8755\n",
      "Epoch 6/10, Train Loss: 0.0846, Accuracy: 0.9029, F1 Micro: 0.9029, F1 Macro: 0.8767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0644, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8811\n",
      "Epoch 8/10, Train Loss: 0.0484, Accuracy: 0.9002, F1 Micro: 0.9002, F1 Macro: 0.8728\n",
      "Epoch 9/10, Train Loss: 0.0326, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8774\n",
      "Epoch 10/10, Train Loss: 0.039, Accuracy: 0.9029, F1 Micro: 0.9029, F1 Macro: 0.8736\n",
      "\n",
      "Sentiment analysis accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       773\n",
      "    positive       0.91      0.76      0.83       319\n",
      "\n",
      "    accuracy                           0.91      1092\n",
      "   macro avg       0.91      0.86      0.88      1092\n",
      "weighted avg       0.91      0.91      0.90      1092\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1329: Accuracy: 0.9559, F1 Micro: 0.9559, F1 Macro: 0.8533\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.88      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.86      0.87       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.85      0.84        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.77      0.83       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.85      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.58       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.89      0.88       200\n",
      "     neutral       0.94      0.91      0.93       315\n",
      "    positive       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.81      0.85       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       0.62      0.45      0.53        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.81      0.75      0.77       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.84      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.45      0.59        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.64      0.94      0.76        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.80      0.78       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.91      0.99      0.95       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 253.91000699996948 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 96\n",
      "Sampling duration: 34.52262330055237 seconds\n",
      "New train size: 1425\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5161, Accuracy: 0.8182, F1 Micro: 0.8975, F1 Macro: 0.8919\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.396, Accuracy: 0.901, F1 Micro: 0.9409, F1 Macro: 0.9367\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2794, Accuracy: 0.9401, F1 Micro: 0.9634, F1 Macro: 0.9609\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2212, Accuracy: 0.9429, F1 Micro: 0.9652, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1859, Accuracy: 0.9569, F1 Micro: 0.9734, F1 Macro: 0.9713\n",
      "Epoch 6/10, Train Loss: 0.154, Accuracy: 0.9563, F1 Micro: 0.973, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1315, Accuracy: 0.9604, F1 Micro: 0.9754, F1 Macro: 0.973\n",
      "Epoch 8/10, Train Loss: 0.1135, Accuracy: 0.9602, F1 Micro: 0.9753, F1 Macro: 0.9727\n",
      "Epoch 9/10, Train Loss: 0.0962, Accuracy: 0.9597, F1 Micro: 0.975, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0835, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9744\n",
      "\n",
      "Aspect detection accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.93      0.92      0.93       317\n",
      "       linen       0.94      0.95      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4288, Accuracy: 0.8575, F1 Micro: 0.8575, F1 Macro: 0.8143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2748, Accuracy: 0.8796, F1 Micro: 0.8796, F1 Macro: 0.8389\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2009, Accuracy: 0.9044, F1 Micro: 0.9044, F1 Macro: 0.8741\n",
      "Epoch 4/10, Train Loss: 0.1358, Accuracy: 0.8961, F1 Micro: 0.8961, F1 Macro: 0.863\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0978, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8851\n",
      "Epoch 6/10, Train Loss: 0.074, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8748\n",
      "Epoch 7/10, Train Loss: 0.0632, Accuracy: 0.9081, F1 Micro: 0.9081, F1 Macro: 0.8801\n",
      "Epoch 8/10, Train Loss: 0.0459, Accuracy: 0.898, F1 Micro: 0.898, F1 Macro: 0.8638\n",
      "Epoch 9/10, Train Loss: 0.0285, Accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8721\n",
      "Epoch 10/10, Train Loss: 0.0301, Accuracy: 0.9053, F1 Micro: 0.9053, F1 Macro: 0.878\n",
      "\n",
      "Sentiment analysis accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8851\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       777\n",
      "    positive       0.91      0.77      0.83       311\n",
      "\n",
      "    accuracy                           0.91      1088\n",
      "   macro avg       0.91      0.87      0.89      1088\n",
      "weighted avg       0.91      0.91      0.91      1088\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1425: Accuracy: 0.9564, F1 Micro: 0.9564, F1 Macro: 0.856\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.91      0.79      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.85      0.84        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.77      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.98      0.96       496\n",
      "    positive       0.84      0.60      0.70        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.53      0.55       571\n",
      "weighted avg       0.91      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.89       200\n",
      "     neutral       0.93      0.92      0.93       315\n",
      "    positive       0.83      0.96      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.59      0.59      0.59        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.80      0.80      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.84      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.91      0.99      0.95       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 253.66530752182007 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 2\n",
      "Sampling duration: 32.03012251853943 seconds\n",
      "New train size: 1427\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5074, Accuracy: 0.8139, F1 Micro: 0.8951, F1 Macro: 0.8889\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3879, Accuracy: 0.904, F1 Micro: 0.9427, F1 Macro: 0.9385\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2745, Accuracy: 0.9394, F1 Micro: 0.9629, F1 Macro: 0.9602\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2173, Accuracy: 0.9502, F1 Micro: 0.9693, F1 Macro: 0.9668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1732, Accuracy: 0.9543, F1 Micro: 0.9718, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1504, Accuracy: 0.9594, F1 Micro: 0.9749, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1334, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9736\n",
      "Epoch 8/10, Train Loss: 0.1068, Accuracy: 0.9604, F1 Micro: 0.9754, F1 Macro: 0.9729\n",
      "Epoch 9/10, Train Loss: 0.0947, Accuracy: 0.9601, F1 Micro: 0.9752, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0837, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.974\n",
      "\n",
      "Aspect detection accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.92      0.94      0.93       317\n",
      "       linen       0.93      0.96      0.94       392\n",
      "     service       0.96      0.96      0.96       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4135, Accuracy: 0.857, F1 Micro: 0.857, F1 Macro: 0.8117\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2595, Accuracy: 0.8634, F1 Micro: 0.8634, F1 Macro: 0.815\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1841, Accuracy: 0.8992, F1 Micro: 0.8992, F1 Macro: 0.8711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1467, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.882\n",
      "Epoch 5/10, Train Loss: 0.088, Accuracy: 0.8882, F1 Micro: 0.8882, F1 Macro: 0.8545\n",
      "Epoch 6/10, Train Loss: 0.0874, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8771\n",
      "Epoch 7/10, Train Loss: 0.0585, Accuracy: 0.9001, F1 Micro: 0.9001, F1 Macro: 0.8754\n",
      "Epoch 8/10, Train Loss: 0.0508, Accuracy: 0.8946, F1 Micro: 0.8946, F1 Macro: 0.8663\n",
      "Epoch 9/10, Train Loss: 0.0306, Accuracy: 0.9047, F1 Micro: 0.9047, F1 Macro: 0.8784\n",
      "Epoch 10/10, Train Loss: 0.035, Accuracy: 0.8992, F1 Micro: 0.8992, F1 Macro: 0.8703\n",
      "\n",
      "Sentiment analysis accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       769\n",
      "    positive       0.90      0.76      0.83       322\n",
      "\n",
      "    accuracy                           0.91      1091\n",
      "   macro avg       0.91      0.87      0.88      1091\n",
      "weighted avg       0.91      0.91      0.90      1091\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1427: Accuracy: 0.9552, F1 Micro: 0.9552, F1 Macro: 0.848\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.88      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.60      0.60      0.60        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.83      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.57      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.89       200\n",
      "     neutral       0.92      0.94      0.93       315\n",
      "    positive       0.85      0.95      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.83      0.85       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.55      0.50      0.52        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.79      0.76      0.77       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.82      0.82        85\n",
      "     neutral       0.96      0.96      0.96       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.48      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.67      0.94      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.81      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.94      0.97      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.91      0.99      0.95       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 260.41812777519226 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 86\n",
      "Sampling duration: 32.042234659194946 seconds\n",
      "New train size: 1513\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5069, Accuracy: 0.8266, F1 Micro: 0.9007, F1 Macro: 0.8929\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3771, Accuracy: 0.9075, F1 Micro: 0.9448, F1 Macro: 0.9415\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2605, Accuracy: 0.9401, F1 Micro: 0.9634, F1 Macro: 0.9611\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2107, Accuracy: 0.9535, F1 Micro: 0.9714, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1708, Accuracy: 0.9547, F1 Micro: 0.972, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1372, Accuracy: 0.9563, F1 Micro: 0.9729, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1244, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1032, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9746\n",
      "Epoch 9/10, Train Loss: 0.09, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0745, Accuracy: 0.9634, F1 Micro: 0.9772, F1 Macro: 0.9747\n",
      "\n",
      "Aspect detection accuracy: 0.9634, F1 Micro: 0.9772, F1 Macro: 0.9747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.91      0.93       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4265, Accuracy: 0.8342, F1 Micro: 0.8342, F1 Macro: 0.7652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2848, Accuracy: 0.8808, F1 Micro: 0.8808, F1 Macro: 0.8463\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1989, Accuracy: 0.8943, F1 Micro: 0.8943, F1 Macro: 0.8635\n",
      "Epoch 4/10, Train Loss: 0.1381, Accuracy: 0.8916, F1 Micro: 0.8916, F1 Macro: 0.8586\n",
      "Epoch 5/10, Train Loss: 0.0956, Accuracy: 0.8934, F1 Micro: 0.8934, F1 Macro: 0.8612\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0935, Accuracy: 0.8978, F1 Micro: 0.8978, F1 Macro: 0.8678\n",
      "Epoch 7/10, Train Loss: 0.0489, Accuracy: 0.897, F1 Micro: 0.897, F1 Macro: 0.8682\n",
      "Epoch 8/10, Train Loss: 0.058, Accuracy: 0.897, F1 Micro: 0.897, F1 Macro: 0.8656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0388, Accuracy: 0.8978, F1 Micro: 0.8978, F1 Macro: 0.8698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0367, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.8714\n",
      "\n",
      "Sentiment analysis accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.8714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93       783\n",
      "    positive       0.94      0.71      0.81       333\n",
      "\n",
      "    accuracy                           0.90      1116\n",
      "   macro avg       0.91      0.85      0.87      1116\n",
      "weighted avg       0.90      0.90      0.90      1116\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1513: Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.8761\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.80      0.40      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.77      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.85      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.29      0.40         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.82      0.67      0.72       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.90      0.89       200\n",
      "     neutral       0.95      0.91      0.93       315\n",
      "    positive       0.83      0.98      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.93      0.91       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.83      0.85       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       0.88      0.32      0.47        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.71      0.76       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.85      0.84        85\n",
      "     neutral       0.97      0.96      0.97       418\n",
      "    positive       0.90      0.94      0.92        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.72      0.76        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.83      0.86       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 274.2841808795929 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 77\n",
      "Sampling duration: 28.68388319015503 seconds\n",
      "New train size: 1590\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4986, Accuracy: 0.8127, F1 Micro: 0.895, F1 Macro: 0.89\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3652, Accuracy: 0.9134, F1 Micro: 0.9477, F1 Macro: 0.9434\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2565, Accuracy: 0.9462, F1 Micro: 0.967, F1 Macro: 0.9649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2039, Accuracy: 0.9491, F1 Micro: 0.9688, F1 Macro: 0.9667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.166, Accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1442, Accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1189, Accuracy: 0.9622, F1 Micro: 0.9766, F1 Macro: 0.9747\n",
      "Epoch 8/10, Train Loss: 0.1026, Accuracy: 0.9618, F1 Micro: 0.9764, F1 Macro: 0.9743\n",
      "Epoch 9/10, Train Loss: 0.0861, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0743, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9753\n",
      "\n",
      "Aspect detection accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4026, Accuracy: 0.8524, F1 Micro: 0.8524, F1 Macro: 0.797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2463, Accuracy: 0.8973, F1 Micro: 0.8973, F1 Macro: 0.8682\n",
      "Epoch 3/10, Train Loss: 0.1861, Accuracy: 0.8854, F1 Micro: 0.8854, F1 Macro: 0.8448\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.126, Accuracy: 0.9056, F1 Micro: 0.9056, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0934, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8881\n",
      "Epoch 6/10, Train Loss: 0.0717, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8805\n",
      "Epoch 7/10, Train Loss: 0.0453, Accuracy: 0.9001, F1 Micro: 0.9001, F1 Macro: 0.8692\n",
      "Epoch 8/10, Train Loss: 0.0521, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.8865\n",
      "Epoch 9/10, Train Loss: 0.023, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8852\n",
      "Epoch 10/10, Train Loss: 0.0231, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8844\n",
      "\n",
      "Sentiment analysis accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8881\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       771\n",
      "    positive       0.94      0.75      0.84       320\n",
      "\n",
      "    accuracy                           0.91      1091\n",
      "   macro avg       0.92      0.87      0.89      1091\n",
      "weighted avg       0.91      0.91      0.91      1091\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1590: Accuracy: 0.958, F1 Micro: 0.958, F1 Macro: 0.8756\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.88      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.80      0.40      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.76      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.81      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.57      0.59       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.84      0.87       162\n",
      "     neutral       0.92      0.97      0.95       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.76      0.80       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.82      0.83        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.88      0.94      0.91        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.91      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.92      0.84      0.87       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 278.64103293418884 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 70\n",
      "Sampling duration: 26.318597316741943 seconds\n",
      "New train size: 1660\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.495, Accuracy: 0.8172, F1 Micro: 0.8974, F1 Macro: 0.8928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3575, Accuracy: 0.9156, F1 Micro: 0.9491, F1 Macro: 0.9452\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2508, Accuracy: 0.9481, F1 Micro: 0.9682, F1 Macro: 0.9659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2001, Accuracy: 0.9497, F1 Micro: 0.9691, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1625, Accuracy: 0.9556, F1 Micro: 0.9726, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1384, Accuracy: 0.9585, F1 Micro: 0.9744, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1157, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0997, Accuracy: 0.962, F1 Micro: 0.9765, F1 Macro: 0.9742\n",
      "Epoch 9/10, Train Loss: 0.0895, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0721, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.95      0.92      0.93       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4047, Accuracy: 0.8633, F1 Micro: 0.8633, F1 Macro: 0.8272\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2426, Accuracy: 0.8788, F1 Micro: 0.8788, F1 Macro: 0.8529\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1741, Accuracy: 0.9043, F1 Micro: 0.9043, F1 Macro: 0.8776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1223, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0962, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8815\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0673, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8852\n",
      "Epoch 7/10, Train Loss: 0.056, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0399, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.8873\n",
      "Epoch 9/10, Train Loss: 0.0257, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8826\n",
      "Epoch 10/10, Train Loss: 0.027, Accuracy: 0.9061, F1 Micro: 0.9061, F1 Macro: 0.8812\n",
      "\n",
      "Sentiment analysis accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.8873\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       779\n",
      "    positive       0.94      0.75      0.83       318\n",
      "\n",
      "    accuracy                           0.91      1097\n",
      "   macro avg       0.92      0.86      0.89      1097\n",
      "weighted avg       0.92      0.91      0.91      1097\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1660: Accuracy: 0.9592, F1 Micro: 0.9592, F1 Macro: 0.8723\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.83      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.58       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.90      0.89       200\n",
      "     neutral       0.95      0.92      0.93       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.77      0.45      0.57        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.86      0.76      0.80       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.82      0.86        85\n",
      "     neutral       0.97      0.99      0.98       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.62      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 291.3741729259491 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 52\n",
      "Sampling duration: 23.35461139678955 seconds\n",
      "New train size: 1712\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4949, Accuracy: 0.8356, F1 Micro: 0.906, F1 Macro: 0.9012\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3392, Accuracy: 0.9208, F1 Micro: 0.9523, F1 Macro: 0.9488\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2364, Accuracy: 0.9431, F1 Micro: 0.9652, F1 Macro: 0.9629\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1843, Accuracy: 0.9556, F1 Micro: 0.9726, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1503, Accuracy: 0.9599, F1 Micro: 0.9752, F1 Macro: 0.9732\n",
      "Epoch 6/10, Train Loss: 0.1279, Accuracy: 0.9585, F1 Micro: 0.9743, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1093, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0928, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9749\n",
      "Epoch 9/10, Train Loss: 0.0815, Accuracy: 0.9615, F1 Micro: 0.9762, F1 Macro: 0.9741\n",
      "Epoch 10/10, Train Loss: 0.0649, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9744\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.91      0.98      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3933, Accuracy: 0.8672, F1 Micro: 0.8672, F1 Macro: 0.8188\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2577, Accuracy: 0.9011, F1 Micro: 0.9011, F1 Macro: 0.8731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1647, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8833\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.132, Accuracy: 0.9153, F1 Micro: 0.9153, F1 Macro: 0.8896\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0833, Accuracy: 0.9171, F1 Micro: 0.9171, F1 Macro: 0.8913\n",
      "Epoch 6/10, Train Loss: 0.0484, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8833\n",
      "Epoch 7/10, Train Loss: 0.0465, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.8869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0438, Accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.8911\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.038, Accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.8922\n",
      "Epoch 10/10, Train Loss: 0.0299, Accuracy: 0.9181, F1 Micro: 0.9181, F1 Macro: 0.8916\n",
      "\n",
      "Sentiment analysis accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.8922\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       767\n",
      "    positive       0.94      0.76      0.84       295\n",
      "\n",
      "    accuracy                           0.92      1062\n",
      "   macro avg       0.93      0.87      0.89      1062\n",
      "weighted avg       0.92      0.92      0.92      1062\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1712: Accuracy: 0.9571, F1 Micro: 0.9571, F1 Macro: 0.8627\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.91      0.91        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.81      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.87      0.60      0.71        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.53      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.90       200\n",
      "     neutral       0.93      0.94      0.94       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.81      0.86       162\n",
      "     neutral       0.91      0.98      0.95       387\n",
      "    positive       0.88      0.32      0.47        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.70      0.76       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.85      0.84        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.82      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 291.6424779891968 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 58\n",
      "Sampling duration: 21.14900493621826 seconds\n",
      "New train size: 1770\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4944, Accuracy: 0.8406, F1 Micro: 0.9075, F1 Macro: 0.8994\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3394, Accuracy: 0.9302, F1 Micro: 0.9574, F1 Macro: 0.9539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2337, Accuracy: 0.9443, F1 Micro: 0.9657, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1835, Accuracy: 0.9486, F1 Micro: 0.9686, F1 Macro: 0.9663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1512, Accuracy: 0.9583, F1 Micro: 0.9743, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1291, Accuracy: 0.9609, F1 Micro: 0.9759, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1096, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.093, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9758\n",
      "Epoch 9/10, Train Loss: 0.0786, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9749\n",
      "Epoch 10/10, Train Loss: 0.0667, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9755\n",
      "\n",
      "Aspect detection accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.92      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3796, Accuracy: 0.8702, F1 Micro: 0.8702, F1 Macro: 0.8282\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2142, Accuracy: 0.8838, F1 Micro: 0.8838, F1 Macro: 0.8468\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1659, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8734\n",
      "Epoch 4/10, Train Loss: 0.1237, Accuracy: 0.8966, F1 Micro: 0.8966, F1 Macro: 0.8635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0966, Accuracy: 0.9056, F1 Micro: 0.9056, F1 Macro: 0.8783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0538, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8843\n",
      "Epoch 7/10, Train Loss: 0.0499, Accuracy: 0.9029, F1 Micro: 0.9029, F1 Macro: 0.8724\n",
      "Epoch 8/10, Train Loss: 0.0553, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8817\n",
      "Epoch 9/10, Train Loss: 0.0461, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8825\n",
      "Epoch 10/10, Train Loss: 0.0279, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8825\n",
      "\n",
      "Sentiment analysis accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8843\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       781\n",
      "    positive       0.94      0.74      0.83       321\n",
      "\n",
      "    accuracy                           0.91      1102\n",
      "   macro avg       0.92      0.86      0.88      1102\n",
      "weighted avg       0.91      0.91      0.91      1102\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1770: Accuracy: 0.9588, F1 Micro: 0.9588, F1 Macro: 0.868\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.93      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.77      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.82      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.57      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.90       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.83      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.77      0.45      0.57        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.75      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.85      0.84        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.66      0.76        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.84      0.86       571\n",
      "weighted avg       0.98      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 294.7238554954529 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 52\n",
      "Sampling duration: 19.39386773109436 seconds\n",
      "New train size: 1822\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.488, Accuracy: 0.8457, F1 Micro: 0.9104, F1 Macro: 0.9036\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3264, Accuracy: 0.9262, F1 Micro: 0.9552, F1 Macro: 0.9524\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2336, Accuracy: 0.9441, F1 Micro: 0.9659, F1 Macro: 0.9634\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1868, Accuracy: 0.9512, F1 Micro: 0.97, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1517, Accuracy: 0.9599, F1 Micro: 0.9752, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1227, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9744\n",
      "Epoch 7/10, Train Loss: 0.1076, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0921, Accuracy: 0.9663, F1 Micro: 0.9791, F1 Macro: 0.9768\n",
      "Epoch 9/10, Train Loss: 0.0752, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9744\n",
      "Epoch 10/10, Train Loss: 0.064, Accuracy: 0.9623, F1 Micro: 0.9765, F1 Macro: 0.9739\n",
      "\n",
      "Aspect detection accuracy: 0.9663, F1 Micro: 0.9791, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.94      0.93      0.93       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3928, Accuracy: 0.8411, F1 Micro: 0.8411, F1 Macro: 0.8132\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2315, Accuracy: 0.905, F1 Micro: 0.905, F1 Macro: 0.878\n",
      "Epoch 3/10, Train Loss: 0.1678, Accuracy: 0.8959, F1 Micro: 0.8959, F1 Macro: 0.872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.103, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8878\n",
      "Epoch 5/10, Train Loss: 0.0826, Accuracy: 0.9123, F1 Micro: 0.9123, F1 Macro: 0.8894\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0536, Accuracy: 0.9178, F1 Micro: 0.9178, F1 Macro: 0.8958\n",
      "Epoch 7/10, Train Loss: 0.0607, Accuracy: 0.9169, F1 Micro: 0.9169, F1 Macro: 0.895\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0439, Accuracy: 0.9196, F1 Micro: 0.9196, F1 Macro: 0.8963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0343, Accuracy: 0.9224, F1 Micro: 0.9224, F1 Macro: 0.9007\n",
      "Epoch 10/10, Train Loss: 0.0216, Accuracy: 0.9169, F1 Micro: 0.9169, F1 Macro: 0.8925\n",
      "\n",
      "Sentiment analysis accuracy: 0.9224, F1 Micro: 0.9224, F1 Macro: 0.9007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       777\n",
      "    positive       0.94      0.78      0.85       318\n",
      "\n",
      "    accuracy                           0.92      1095\n",
      "   macro avg       0.93      0.88      0.90      1095\n",
      "weighted avg       0.92      0.92      0.92      1095\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1822: Accuracy: 0.9611, F1 Micro: 0.9611, F1 Macro: 0.8867\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.90      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.64      0.70      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.86      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.81      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.83      0.93      0.87       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.85      0.78      0.82        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.77      0.63      0.67       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.88       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.85      0.95      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.85      0.50      0.63        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.77      0.82       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.66      0.76        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.80      0.94      0.86        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.86      0.87       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 303.9962613582611 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 17.366708993911743 seconds\n",
      "New train size: 1872\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4826, Accuracy: 0.8533, F1 Micro: 0.9151, F1 Macro: 0.9101\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3173, Accuracy: 0.9319, F1 Micro: 0.9585, F1 Macro: 0.9555\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2192, Accuracy: 0.9464, F1 Micro: 0.9671, F1 Macro: 0.9649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1696, Accuracy: 0.9542, F1 Micro: 0.9717, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1485, Accuracy: 0.9576, F1 Micro: 0.9739, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.125, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9749\n",
      "Epoch 7/10, Train Loss: 0.1016, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0864, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9752\n",
      "Epoch 9/10, Train Loss: 0.0713, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0628, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9759\n",
      "\n",
      "Aspect detection accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.95      0.94      0.94       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3806, Accuracy: 0.8537, F1 Micro: 0.8537, F1 Macro: 0.7944\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2109, Accuracy: 0.9025, F1 Micro: 0.9025, F1 Macro: 0.8734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1478, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8821\n",
      "Epoch 4/10, Train Loss: 0.1123, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0691, Accuracy: 0.9181, F1 Micro: 0.9181, F1 Macro: 0.8943\n",
      "Epoch 6/10, Train Loss: 0.0617, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8883\n",
      "Epoch 7/10, Train Loss: 0.0532, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8928\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0376, Accuracy: 0.9181, F1 Micro: 0.9181, F1 Macro: 0.8938\n",
      "Epoch 9/10, Train Loss: 0.0291, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8818\n",
      "Epoch 10/10, Train Loss: 0.0243, Accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8882\n",
      "\n",
      "Sentiment analysis accuracy: 0.9181, F1 Micro: 0.9181, F1 Macro: 0.8938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       774\n",
      "    positive       0.94      0.76      0.84       313\n",
      "\n",
      "    accuracy                           0.92      1087\n",
      "   macro avg       0.93      0.87      0.89      1087\n",
      "weighted avg       0.92      0.92      0.92      1087\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1872: Accuracy: 0.9587, F1 Micro: 0.9587, F1 Macro: 0.8695\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.86      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.94       571\n",
      "weighted avg       0.96      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.88      0.74      0.80        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.62      0.67       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91       200\n",
      "     neutral       0.95      0.94      0.94       315\n",
      "    positive       0.89      0.98      0.93        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.92      0.94      0.93       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.82      0.86       162\n",
      "     neutral       0.92      0.97      0.95       387\n",
      "    positive       0.75      0.41      0.53        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.85      0.73      0.78       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.90      0.94      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.45      0.58        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.67      0.82      0.74        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.76      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.98      0.86      0.91       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 320.8533842563629 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 15.708356857299805 seconds\n",
      "New train size: 1922\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4854, Accuracy: 0.8582, F1 Micro: 0.9168, F1 Macro: 0.9098\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3054, Accuracy: 0.9354, F1 Micro: 0.9607, F1 Macro: 0.9583\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2195, Accuracy: 0.9488, F1 Micro: 0.9685, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.175, Accuracy: 0.9552, F1 Micro: 0.9724, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1415, Accuracy: 0.9592, F1 Micro: 0.9748, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1254, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0995, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0833, Accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9768\n",
      "Epoch 9/10, Train Loss: 0.0705, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9754\n",
      "Epoch 10/10, Train Loss: 0.0607, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9759\n",
      "\n",
      "Aspect detection accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.96      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.95      0.94      0.94       317\n",
      "       linen       0.93      0.98      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3656, Accuracy: 0.8843, F1 Micro: 0.8843, F1 Macro: 0.8486\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2114, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8806\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1402, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1112, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.8934\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.082, Accuracy: 0.9201, F1 Micro: 0.9201, F1 Macro: 0.8963\n",
      "Epoch 6/10, Train Loss: 0.0737, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.8951\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0618, Accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.8989\n",
      "Epoch 8/10, Train Loss: 0.0564, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8881\n",
      "Epoch 9/10, Train Loss: 0.0329, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8848\n",
      "Epoch 10/10, Train Loss: 0.0319, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.8946\n",
      "\n",
      "Sentiment analysis accuracy: 0.9219, F1 Micro: 0.9219, F1 Macro: 0.8989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       778\n",
      "    positive       0.94      0.78      0.85       311\n",
      "\n",
      "    accuracy                           0.92      1089\n",
      "   macro avg       0.93      0.88      0.90      1089\n",
      "weighted avg       0.92      0.92      0.92      1089\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1922: Accuracy: 0.9604, F1 Micro: 0.9604, F1 Macro: 0.8754\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.86      0.82        78\n",
      "     neutral       0.98      0.96      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.83      0.72      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.57      0.58       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.90      0.91       200\n",
      "     neutral       0.95      0.94      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88       162\n",
      "     neutral       0.93      0.98      0.95       387\n",
      "    positive       1.00      0.45      0.62        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.95      0.76      0.82       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.82      0.86        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.92      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 324.754132270813 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 13.931910514831543 seconds\n",
      "New train size: 1972\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4793, Accuracy: 0.8472, F1 Micro: 0.912, F1 Macro: 0.9069\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3115, Accuracy: 0.9318, F1 Micro: 0.9586, F1 Macro: 0.9561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2105, Accuracy: 0.9516, F1 Micro: 0.9702, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1667, Accuracy: 0.9576, F1 Micro: 0.9738, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1381, Accuracy: 0.9587, F1 Micro: 0.9745, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1141, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0976, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9751\n",
      "Epoch 8/10, Train Loss: 0.0821, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9736\n",
      "Epoch 9/10, Train Loss: 0.0707, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9749\n",
      "Epoch 10/10, Train Loss: 0.0594, Accuracy: 0.962, F1 Micro: 0.9763, F1 Macro: 0.974\n",
      "\n",
      "Aspect detection accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9751\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3648, Accuracy: 0.8466, F1 Micro: 0.8466, F1 Macro: 0.812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2006, Accuracy: 0.9002, F1 Micro: 0.9002, F1 Macro: 0.8717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1542, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.8799\n",
      "Epoch 4/10, Train Loss: 0.1005, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.07, Accuracy: 0.9067, F1 Micro: 0.9067, F1 Macro: 0.8776\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0547, Accuracy: 0.9168, F1 Micro: 0.9168, F1 Macro: 0.8928\n",
      "Epoch 7/10, Train Loss: 0.0625, Accuracy: 0.914, F1 Micro: 0.914, F1 Macro: 0.8896\n",
      "Epoch 8/10, Train Loss: 0.0331, Accuracy: 0.9131, F1 Micro: 0.9131, F1 Macro: 0.8888\n",
      "Epoch 9/10, Train Loss: 0.0298, Accuracy: 0.9159, F1 Micro: 0.9159, F1 Macro: 0.891\n",
      "Epoch 10/10, Train Loss: 0.0374, Accuracy: 0.9085, F1 Micro: 0.9085, F1 Macro: 0.8825\n",
      "\n",
      "Sentiment analysis accuracy: 0.9168, F1 Micro: 0.9168, F1 Macro: 0.8928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       768\n",
      "    positive       0.94      0.76      0.84       314\n",
      "\n",
      "    accuracy                           0.92      1082\n",
      "   macro avg       0.92      0.87      0.89      1082\n",
      "weighted avg       0.92      0.92      0.91      1082\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1972: Accuracy: 0.9578, F1 Micro: 0.9578, F1 Macro: 0.8815\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.86      0.89        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.91      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.81      0.85        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.76      0.60      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       200\n",
      "     neutral       0.93      0.93      0.93       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.75      0.55      0.63        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.78      0.81       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.82      0.84        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.89      0.96      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.81      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 324.49635195732117 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 25\n",
      "Sampling duration: 12.242089033126831 seconds\n",
      "New train size: 1997\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4815, Accuracy: 0.8656, F1 Micro: 0.9214, F1 Macro: 0.9156\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3045, Accuracy: 0.9344, F1 Micro: 0.96, F1 Macro: 0.9575\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2065, Accuracy: 0.9481, F1 Micro: 0.9682, F1 Macro: 0.966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1717, Accuracy: 0.9552, F1 Micro: 0.9724, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1387, Accuracy: 0.9592, F1 Micro: 0.9748, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1164, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9752\n",
      "Epoch 7/10, Train Loss: 0.0976, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0806, Accuracy: 0.9655, F1 Micro: 0.9786, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.067, Accuracy: 0.9661, F1 Micro: 0.979, F1 Macro: 0.9773\n",
      "Epoch 10/10, Train Loss: 0.0584, Accuracy: 0.9655, F1 Micro: 0.9786, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.9661, F1 Micro: 0.979, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.96      0.94      0.95       317\n",
      "       linen       0.94      0.97      0.96       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3768, Accuracy: 0.8597, F1 Micro: 0.8597, F1 Macro: 0.8208\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2255, Accuracy: 0.8998, F1 Micro: 0.8998, F1 Macro: 0.8694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1371, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8784\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1005, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8859\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0827, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8811\n",
      "Epoch 6/10, Train Loss: 0.0693, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0605, Accuracy: 0.9162, F1 Micro: 0.9162, F1 Macro: 0.8895\n",
      "Epoch 8/10, Train Loss: 0.0364, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.038, Accuracy: 0.9171, F1 Micro: 0.9171, F1 Macro: 0.8906\n",
      "Epoch 10/10, Train Loss: 0.023, Accuracy: 0.9162, F1 Micro: 0.9162, F1 Macro: 0.8903\n",
      "\n",
      "Sentiment analysis accuracy: 0.9171, F1 Micro: 0.9171, F1 Macro: 0.8906\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       787\n",
      "    positive       0.95      0.75      0.84       311\n",
      "\n",
      "    accuracy                           0.92      1098\n",
      "   macro avg       0.93      0.87      0.89      1098\n",
      "weighted avg       0.92      0.92      0.91      1098\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1997: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.867\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.83      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.77      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.61      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.91      0.91       200\n",
      "     neutral       0.95      0.94      0.95       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.92      0.94      0.93       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88       162\n",
      "     neutral       0.94      0.97      0.96       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.75      0.80       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.82      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 334.9638259410858 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 11.300512790679932 seconds\n",
      "New train size: 2047\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4735, Accuracy: 0.8712, F1 Micro: 0.9244, F1 Macro: 0.9188\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2994, Accuracy: 0.9349, F1 Micro: 0.9603, F1 Macro: 0.9581\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2111, Accuracy: 0.9458, F1 Micro: 0.9669, F1 Macro: 0.9646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1626, Accuracy: 0.9561, F1 Micro: 0.9729, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1328, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1146, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0978, Accuracy: 0.9655, F1 Micro: 0.9786, F1 Macro: 0.9768\n",
      "Epoch 8/10, Train Loss: 0.0793, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9742\n",
      "Epoch 9/10, Train Loss: 0.0684, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9762\n",
      "Epoch 10/10, Train Loss: 0.0584, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9753\n",
      "\n",
      "Aspect detection accuracy: 0.9655, F1 Micro: 0.9786, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.98      0.98      0.98       496\n",
      "     general       0.93      0.98      0.96       500\n",
      "  kebersihan       0.93      0.96      0.95       317\n",
      "       linen       0.93      0.98      0.95       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3604, Accuracy: 0.8661, F1 Micro: 0.8661, F1 Macro: 0.8143\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2133, Accuracy: 0.8984, F1 Micro: 0.8984, F1 Macro: 0.8656\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1469, Accuracy: 0.9123, F1 Micro: 0.9123, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1134, Accuracy: 0.9197, F1 Micro: 0.9197, F1 Macro: 0.8949\n",
      "Epoch 5/10, Train Loss: 0.0965, Accuracy: 0.9178, F1 Micro: 0.9178, F1 Macro: 0.8927\n",
      "Epoch 6/10, Train Loss: 0.0588, Accuracy: 0.9141, F1 Micro: 0.9141, F1 Macro: 0.8884\n",
      "Epoch 7/10, Train Loss: 0.0453, Accuracy: 0.9123, F1 Micro: 0.9123, F1 Macro: 0.8821\n",
      "Epoch 8/10, Train Loss: 0.0333, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8862\n",
      "Epoch 9/10, Train Loss: 0.0222, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.8873\n",
      "Epoch 10/10, Train Loss: 0.0268, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8871\n",
      "\n",
      "Sentiment analysis accuracy: 0.9197, F1 Micro: 0.9197, F1 Macro: 0.8949\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       780\n",
      "    positive       0.93      0.78      0.84       303\n",
      "\n",
      "    accuracy                           0.92      1083\n",
      "   macro avg       0.92      0.88      0.89      1083\n",
      "weighted avg       0.92      0.92      0.92      1083\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2047: Accuracy: 0.9594, F1 Micro: 0.9594, F1 Macro: 0.8705\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.85        78\n",
      "     neutral       0.98      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.98      0.96       496\n",
      "    positive       0.83      0.59      0.69        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.59      0.52      0.55       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.86      0.90       200\n",
      "     neutral       0.93      0.96      0.95       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.92      0.94      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88       162\n",
      "     neutral       0.93      0.98      0.95       387\n",
      "    positive       0.79      0.50      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.87      0.77      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.87      0.85        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.90      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.70      0.94      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.83      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 330.69077348709106 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 9.55773115158081 seconds\n",
      "New train size: 2097\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4711, Accuracy: 0.8738, F1 Micro: 0.9259, F1 Macro: 0.921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2886, Accuracy: 0.9352, F1 Micro: 0.9605, F1 Macro: 0.9578\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1983, Accuracy: 0.9497, F1 Micro: 0.9691, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1626, Accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1331, Accuracy: 0.9592, F1 Micro: 0.9747, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1099, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0896, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9764\n",
      "Epoch 8/10, Train Loss: 0.0763, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9743\n",
      "Epoch 9/10, Train Loss: 0.0677, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.976\n",
      "Epoch 10/10, Train Loss: 0.0569, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9758\n",
      "\n",
      "Aspect detection accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.94      0.95      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3535, Accuracy: 0.8674, F1 Micro: 0.8674, F1 Macro: 0.8254\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2056, Accuracy: 0.8981, F1 Micro: 0.8981, F1 Macro: 0.8697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.165, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8786\n",
      "Epoch 4/10, Train Loss: 0.1077, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8771\n",
      "Epoch 5/10, Train Loss: 0.0679, Accuracy: 0.9053, F1 Micro: 0.9053, F1 Macro: 0.8781\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0724, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8835\n",
      "Epoch 7/10, Train Loss: 0.0491, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8812\n",
      "Epoch 8/10, Train Loss: 0.036, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8787\n",
      "Epoch 9/10, Train Loss: 0.0291, Accuracy: 0.9026, F1 Micro: 0.9026, F1 Macro: 0.8739\n",
      "Epoch 10/10, Train Loss: 0.0334, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8809\n",
      "\n",
      "Sentiment analysis accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8835\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       787\n",
      "    positive       0.93      0.75      0.83       322\n",
      "\n",
      "    accuracy                           0.91      1109\n",
      "   macro avg       0.92      0.86      0.88      1109\n",
      "weighted avg       0.91      0.91      0.91      1109\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2097: Accuracy: 0.9588, F1 Micro: 0.9588, F1 Macro: 0.8598\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.85      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.82      0.94      0.87       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.56      0.57       571\n",
      "weighted avg       0.92      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.89      0.90       200\n",
      "     neutral       0.94      0.95      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.88      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.70      0.32      0.44        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.83      0.72      0.75       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.85        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.62      0.73        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.85      0.86       571\n",
      "weighted avg       0.98      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.75      1.00      0.86         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.90      0.98      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 335.1822922229767 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 7.867537498474121 seconds\n",
      "New train size: 2147\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4638, Accuracy: 0.8778, F1 Micro: 0.9282, F1 Macro: 0.923\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2754, Accuracy: 0.9418, F1 Micro: 0.9644, F1 Macro: 0.9621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2, Accuracy: 0.9521, F1 Micro: 0.9706, F1 Macro: 0.9687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1592, Accuracy: 0.9568, F1 Micro: 0.9734, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1295, Accuracy: 0.9611, F1 Micro: 0.976, F1 Macro: 0.9741\n",
      "Epoch 6/10, Train Loss: 0.106, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0905, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0751, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.063, Accuracy: 0.9665, F1 Micro: 0.9792, F1 Macro: 0.9772\n",
      "Epoch 10/10, Train Loss: 0.0532, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9792, F1 Macro: 0.9772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3562, Accuracy: 0.8718, F1 Micro: 0.8718, F1 Macro: 0.8252\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1885, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1294, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.88\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0949, Accuracy: 0.9185, F1 Micro: 0.9185, F1 Macro: 0.8952\n",
      "Epoch 5/10, Train Loss: 0.069, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.8935\n",
      "Epoch 6/10, Train Loss: 0.0565, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.8921\n",
      "Epoch 7/10, Train Loss: 0.04, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.8905\n",
      "Epoch 8/10, Train Loss: 0.0279, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8874\n",
      "Epoch 9/10, Train Loss: 0.0294, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.8931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0161, Accuracy: 0.9203, F1 Micro: 0.9203, F1 Macro: 0.8968\n",
      "\n",
      "Sentiment analysis accuracy: 0.9203, F1 Micro: 0.9203, F1 Macro: 0.8968\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       780\n",
      "    positive       0.93      0.78      0.85       312\n",
      "\n",
      "    accuracy                           0.92      1092\n",
      "   macro avg       0.93      0.88      0.90      1092\n",
      "weighted avg       0.92      0.92      0.92      1092\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2147: Accuracy: 0.9608, F1 Micro: 0.9608, F1 Macro: 0.8759\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.81      0.84       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.83      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.81      0.75      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.58      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.87      0.89       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.89      0.98      0.93        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.76      0.80       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.80      0.86        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.89      0.96      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.81      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 349.5846438407898 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 6.004066228866577 seconds\n",
      "New train size: 2197\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4646, Accuracy: 0.8793, F1 Micro: 0.9286, F1 Macro: 0.9219\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2775, Accuracy: 0.9335, F1 Micro: 0.9595, F1 Macro: 0.9572\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1918, Accuracy: 0.9507, F1 Micro: 0.9697, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.156, Accuracy: 0.9561, F1 Micro: 0.973, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1294, Accuracy: 0.9618, F1 Micro: 0.9764, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1049, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0854, Accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0751, Accuracy: 0.9663, F1 Micro: 0.9791, F1 Macro: 0.9769\n",
      "Epoch 9/10, Train Loss: 0.0639, Accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0527, Accuracy: 0.967, F1 Micro: 0.9795, F1 Macro: 0.9774\n",
      "\n",
      "Aspect detection accuracy: 0.967, F1 Micro: 0.9795, F1 Macro: 0.9774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.98      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.98      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3358, Accuracy: 0.8527, F1 Micro: 0.8527, F1 Macro: 0.7926\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1848, Accuracy: 0.8976, F1 Micro: 0.8976, F1 Macro: 0.8662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1303, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0901, Accuracy: 0.9075, F1 Micro: 0.9075, F1 Macro: 0.8833\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0608, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.886\n",
      "Epoch 6/10, Train Loss: 0.0544, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8824\n",
      "Epoch 7/10, Train Loss: 0.0386, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8832\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0324, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0418, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8922\n",
      "Epoch 10/10, Train Loss: 0.0236, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8876\n",
      "\n",
      "Sentiment analysis accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8922\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       789\n",
      "    positive       0.94      0.76      0.84       324\n",
      "\n",
      "    accuracy                           0.92      1113\n",
      "   macro avg       0.93      0.87      0.89      1113\n",
      "weighted avg       0.92      0.92      0.91      1113\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2197: Accuracy: 0.9615, F1 Micro: 0.9615, F1 Macro: 0.8855\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.81      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.29      0.36         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.84      0.75      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.76      0.67      0.71       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.88       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.77      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.94      0.96      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.66      0.76        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.84      0.86       571\n",
      "weighted avg       0.98      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 365.5820803642273 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 4.205608129501343 seconds\n",
      "New train size: 2247\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.445, Accuracy: 0.8873, F1 Micro: 0.9331, F1 Macro: 0.9278\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2576, Accuracy: 0.941, F1 Micro: 0.964, F1 Macro: 0.9618\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1859, Accuracy: 0.9516, F1 Micro: 0.9702, F1 Macro: 0.9683\n",
      "Epoch 4/10, Train Loss: 0.1478, Accuracy: 0.9503, F1 Micro: 0.9697, F1 Macro: 0.9673\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1223, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0998, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0829, Accuracy: 0.9667, F1 Micro: 0.9793, F1 Macro: 0.9771\n",
      "Epoch 8/10, Train Loss: 0.07, Accuracy: 0.9646, F1 Micro: 0.9781, F1 Macro: 0.976\n",
      "Epoch 9/10, Train Loss: 0.0597, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9757\n",
      "Epoch 10/10, Train Loss: 0.0508, Accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9764\n",
      "\n",
      "Aspect detection accuracy: 0.9667, F1 Micro: 0.9793, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.93      0.98      0.96       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3397, Accuracy: 0.8756, F1 Micro: 0.8756, F1 Macro: 0.8383\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1882, Accuracy: 0.9085, F1 Micro: 0.9085, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1232, Accuracy: 0.9158, F1 Micro: 0.9158, F1 Macro: 0.8918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0845, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.8911\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.064, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.8953\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0572, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.8995\n",
      "Epoch 7/10, Train Loss: 0.0476, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.8933\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0421, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9001\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0343, Accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9098\n",
      "Epoch 10/10, Train Loss: 0.0276, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.8915\n",
      "\n",
      "Sentiment analysis accuracy: 0.9305, F1 Micro: 0.9305, F1 Macro: 0.9098\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.99      0.95       780\n",
      "    positive       0.96      0.79      0.87       313\n",
      "\n",
      "    accuracy                           0.93      1093\n",
      "   macro avg       0.94      0.89      0.91      1093\n",
      "weighted avg       0.93      0.93      0.93      1093\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2247: Accuracy: 0.9623, F1 Micro: 0.9623, F1 Macro: 0.899\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.83      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.79      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.29      0.40         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.83      0.76      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.82      0.68      0.72       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.88       162\n",
      "     neutral       0.93      0.98      0.96       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.76      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.72      0.81        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.89      0.94      0.91        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.89      0.90       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 356.0937776565552 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 36\n",
      "Sampling duration: 2.3413445949554443 seconds\n",
      "New train size: 2283\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4528, Accuracy: 0.8826, F1 Micro: 0.9299, F1 Macro: 0.9228\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2642, Accuracy: 0.9415, F1 Micro: 0.9643, F1 Macro: 0.9621\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1879, Accuracy: 0.9512, F1 Micro: 0.9701, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1484, Accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1199, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.101, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0834, Accuracy: 0.9642, F1 Micro: 0.9779, F1 Macro: 0.9758\n",
      "Epoch 8/10, Train Loss: 0.0697, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9755\n",
      "Epoch 9/10, Train Loss: 0.0587, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0485, Accuracy: 0.9655, F1 Micro: 0.9786, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.9655, F1 Micro: 0.9786, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.93      0.99      0.96       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3563, Accuracy: 0.8818, F1 Micro: 0.8818, F1 Macro: 0.8403\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1863, Accuracy: 0.8957, F1 Micro: 0.8957, F1 Macro: 0.8564\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1301, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1052, Accuracy: 0.9181, F1 Micro: 0.9181, F1 Macro: 0.8914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0556, Accuracy: 0.9181, F1 Micro: 0.9181, F1 Macro: 0.8909\n",
      "Epoch 6/10, Train Loss: 0.0528, Accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.8865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0471, Accuracy: 0.9181, F1 Micro: 0.9181, F1 Macro: 0.8884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0357, Accuracy: 0.9199, F1 Micro: 0.9199, F1 Macro: 0.8928\n",
      "Epoch 9/10, Train Loss: 0.0471, Accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.8915\n",
      "Epoch 10/10, Train Loss: 0.0295, Accuracy: 0.9162, F1 Micro: 0.9162, F1 Macro: 0.8895\n",
      "\n",
      "Sentiment analysis accuracy: 0.9199, F1 Micro: 0.9199, F1 Macro: 0.8928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       779\n",
      "    positive       0.94      0.76      0.84       295\n",
      "\n",
      "    accuracy                           0.92      1074\n",
      "   macro avg       0.93      0.87      0.89      1074\n",
      "weighted avg       0.92      0.92      0.92      1074\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2283: Accuracy: 0.9595, F1 Micro: 0.9595, F1 Macro: 0.8709\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.64      0.70      0.67        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.87      0.87      0.87       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.86      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.99      0.96       496\n",
      "    positive       0.89      0.59      0.71        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.61      0.53      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.88      0.90       200\n",
      "     neutral       0.93      0.94      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87       162\n",
      "     neutral       0.93      0.98      0.95       387\n",
      "    positive       0.89      0.36      0.52        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.73      0.78       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.84      0.86        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.66      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.80      0.71      0.75        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.94      0.98      0.96       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 363.80635690689087 s\n",
      "Total runtime: 8099.830374002457 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "initial_train_size = int(0.1 * total_data)\n",
    "active_learning(81, 0, 10)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6765788,
     "sourceId": 10888066,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17219.190488,
   "end_time": "2025-05-17T19:51:44.861179",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-17T15:04:45.670691",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03ab7794cc4d4601a166a0163b060a28": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0fba761271d84848ba27bd9ac6f89db9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7c120aaef4da4e0dbb8adfa9846c7ffe",
       "placeholder": "​",
       "style": "IPY_MODEL_bf21b8198619400db95653da706f532d",
       "tabbable": null,
       "tooltip": null,
       "value": " 229k/229k [00:00&lt;00:00, 6.82MB/s]"
      }
     },
     "14fcd6cd32b645c487c0fe13ad4c4a6d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1a569003bf7d449e8c84625a339b3a3c",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4f05b0e794974bfba92e1dad4f6ebb3f",
       "tabbable": null,
       "tooltip": null,
       "value": 2.0
      }
     },
     "168fd7083cb345e984af4cfa477d31c9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a940c45a6df34854815a4a26d73774c9",
        "IPY_MODEL_b00ccf0d12cf49118557cc4ae4299284",
        "IPY_MODEL_0fba761271d84848ba27bd9ac6f89db9"
       ],
       "layout": "IPY_MODEL_6eab4664e67e4d1686cf1d631b9081a7",
       "tabbable": null,
       "tooltip": null
      }
     },
     "173e51e254414e73905ad9fc764ec607": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d7c0cc92d9054892b26cf48baf141402",
       "placeholder": "​",
       "style": "IPY_MODEL_fb1bcbd260374fe89a06c886bf98feef",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json: 100%"
      }
     },
     "1974eafa62dd40deae14ef76f7570c07": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1a569003bf7d449e8c84625a339b3a3c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1ab6005ba0a343d4a54394d64fa8b56f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_28aff7edb9c749dea4572b711a839234",
       "placeholder": "​",
       "style": "IPY_MODEL_73333847bd2b41b2b6baba4d3d919587",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "1b1d6f201bab477ab2605c288bcb1da0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "28aff7edb9c749dea4572b711a839234": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "32d21ed71bc74059b660a9862566621a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_173e51e254414e73905ad9fc764ec607",
        "IPY_MODEL_8af9fbf7074745a3a029f42b182e2410",
        "IPY_MODEL_379b8dc270c447519c7e86b7c1b55983"
       ],
       "layout": "IPY_MODEL_d58464e52a7b44af912b232ee892af41",
       "tabbable": null,
       "tooltip": null
      }
     },
     "34bdf3c559fb4beca86d5b25674f598a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8aeac2e2ab064555bf6ce7769ce3e542",
        "IPY_MODEL_14fcd6cd32b645c487c0fe13ad4c4a6d",
        "IPY_MODEL_3fa8aafe550f4a8290878c2c728edbbc"
       ],
       "layout": "IPY_MODEL_b5ebc47fdd5d48d9b6baee53991fa01d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "379b8dc270c447519c7e86b7c1b55983": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_85086c7f50034f2bb302fc84d8faab30",
       "placeholder": "​",
       "style": "IPY_MODEL_96ace9d5d1514fa4a6f01e2f36aa2a64",
       "tabbable": null,
       "tooltip": null,
       "value": " 112/112 [00:00&lt;00:00, 9.88kB/s]"
      }
     },
     "3893038ca686435ca9e06dae131e7c54": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3fa8aafe550f4a8290878c2c728edbbc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_84258317f96e49308d9ed1d89ee5ffc8",
       "placeholder": "​",
       "style": "IPY_MODEL_89cf3e2cd00942bb9f0c60b41985d726",
       "tabbable": null,
       "tooltip": null,
       "value": " 2.00/2.00 [00:00&lt;00:00, 150B/s]"
      }
     },
     "4e5c41a59c79499f930776b1dc588cd8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4f05b0e794974bfba92e1dad4f6ebb3f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "63a3177306ef4a4cb8cb4eaff5ce97b6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "64b1b53f3c45450ea710ef700eadee81": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6eab4664e67e4d1686cf1d631b9081a7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7198bdf882c5452cb1a6e598b0f828f2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "73333847bd2b41b2b6baba4d3d919587": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "785170004ee742dd9872340bc243db1c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1ab6005ba0a343d4a54394d64fa8b56f",
        "IPY_MODEL_8fd606761ab34743a8f2e5a78d2cc89b",
        "IPY_MODEL_b270f35f13c346f3a0f646d28b8465c7"
       ],
       "layout": "IPY_MODEL_f8c4f28fac114d6f8db4aa5f7176e046",
       "tabbable": null,
       "tooltip": null
      }
     },
     "7c120aaef4da4e0dbb8adfa9846c7ffe": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "84258317f96e49308d9ed1d89ee5ffc8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "85086c7f50034f2bb302fc84d8faab30": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "89cf3e2cd00942bb9f0c60b41985d726": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8aeac2e2ab064555bf6ce7769ce3e542": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1b1d6f201bab477ab2605c288bcb1da0",
       "placeholder": "​",
       "style": "IPY_MODEL_1974eafa62dd40deae14ef76f7570c07",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "8af9fbf7074745a3a029f42b182e2410": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_64b1b53f3c45450ea710ef700eadee81",
       "max": 112.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_03ab7794cc4d4601a166a0163b060a28",
       "tabbable": null,
       "tooltip": null,
       "value": 112.0
      }
     },
     "8fd606761ab34743a8f2e5a78d2cc89b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_956a7eb278224c85a8fa316867c8d5a9",
       "max": 1534.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a1a609b8c7ac4ed7a81740bf13732808",
       "tabbable": null,
       "tooltip": null,
       "value": 1534.0
      }
     },
     "90b733f4b8974498a840f015ec855bac": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "956a7eb278224c85a8fa316867c8d5a9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "96ace9d5d1514fa4a6f01e2f36aa2a64": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a1a609b8c7ac4ed7a81740bf13732808": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a940c45a6df34854815a4a26d73774c9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e0b59d1c79754116812730d5dd9ce4ac",
       "placeholder": "​",
       "style": "IPY_MODEL_7198bdf882c5452cb1a6e598b0f828f2",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: 100%"
      }
     },
     "b00ccf0d12cf49118557cc4ae4299284": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_90b733f4b8974498a840f015ec855bac",
       "max": 229167.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4e5c41a59c79499f930776b1dc588cd8",
       "tabbable": null,
       "tooltip": null,
       "value": 229167.0
      }
     },
     "b270f35f13c346f3a0f646d28b8465c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3893038ca686435ca9e06dae131e7c54",
       "placeholder": "​",
       "style": "IPY_MODEL_63a3177306ef4a4cb8cb4eaff5ce97b6",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.53k/1.53k [00:00&lt;00:00, 134kB/s]"
      }
     },
     "b5ebc47fdd5d48d9b6baee53991fa01d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bf21b8198619400db95653da706f532d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d58464e52a7b44af912b232ee892af41": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d7c0cc92d9054892b26cf48baf141402": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e0b59d1c79754116812730d5dd9ce4ac": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f8c4f28fac114d6f8db4aa5f7176e046": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fb1bcbd260374fe89a06c886bf98feef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
