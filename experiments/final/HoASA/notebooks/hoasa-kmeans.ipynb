{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a316948e",
   "metadata": {
    "papermill": {
     "duration": 0.012334,
     "end_time": "2025-03-31T04:27:43.675677",
     "exception": false,
     "start_time": "2025-03-31T04:27:43.663343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d48bde71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:27:43.699074Z",
     "iopub.status.busy": "2025-03-31T04:27:43.698802Z",
     "iopub.status.idle": "2025-03-31T04:28:06.430242Z",
     "shell.execute_reply": "2025-03-31T04:28:06.429579Z"
    },
    "papermill": {
     "duration": 22.744934,
     "end_time": "2025-03-31T04:28:06.431910",
     "exception": false,
     "start_time": "2025-03-31T04:27:43.686976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, f1_score, classification_report\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from torch.multiprocessing import Manager\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, BertPreTrainedModel, BertConfig, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3d7e8a",
   "metadata": {
    "papermill": {
     "duration": 0.010834,
     "end_time": "2025-03-31T04:28:06.454261",
     "exception": false,
     "start_time": "2025-03-31T04:28:06.443427",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe801de0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:28:06.477500Z",
     "iopub.status.busy": "2025-03-31T04:28:06.476931Z",
     "iopub.status.idle": "2025-03-31T04:28:06.480546Z",
     "shell.execute_reply": "2025-03-31T04:28:06.479856Z"
    },
    "papermill": {
     "duration": 0.01648,
     "end_time": "2025-03-31T04:28:06.481689",
     "exception": false,
     "start_time": "2025-03-31T04:28:06.465209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e14e8934",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:28:06.504601Z",
     "iopub.status.busy": "2025-03-31T04:28:06.504382Z",
     "iopub.status.idle": "2025-03-31T04:28:06.508266Z",
     "shell.execute_reply": "2025-03-31T04:28:06.507472Z"
    },
    "papermill": {
     "duration": 0.0168,
     "end_time": "2025-03-31T04:28:06.509612",
     "exception": false,
     "start_time": "2025-03-31T04:28:06.492812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists('/kaggle/working/results') == False:\n",
    "    os.mkdir('/kaggle/working/results')\n",
    "\n",
    "if os.path.exists('/kaggle/working/acquired_data') == False:\n",
    "    os.mkdir('/kaggle/working/acquired_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "417ca5aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:28:06.532688Z",
     "iopub.status.busy": "2025-03-31T04:28:06.532468Z",
     "iopub.status.idle": "2025-03-31T04:28:06.541370Z",
     "shell.execute_reply": "2025-03-31T04:28:06.540579Z"
    },
    "papermill": {
     "duration": 0.02169,
     "end_time": "2025-03-31T04:28:06.542567",
     "exception": false,
     "start_time": "2025-03-31T04:28:06.520877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    torch.backends.cudnn.benchmark=False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4152b8a8",
   "metadata": {
    "papermill": {
     "duration": 0.010784,
     "end_time": "2025-03-31T04:28:06.564403",
     "exception": false,
     "start_time": "2025-03-31T04:28:06.553619",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GLOBAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a37c99e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:28:06.587036Z",
     "iopub.status.busy": "2025-03-31T04:28:06.586813Z",
     "iopub.status.idle": "2025-03-31T04:28:06.642712Z",
     "shell.execute_reply": "2025-03-31T04:28:06.641162Z"
    },
    "papermill": {
     "duration": 0.069493,
     "end_time": "2025-03-31T04:28:06.644842",
     "exception": false,
     "start_time": "2025-03-31T04:28:06.575349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "manager = Manager()\n",
    "\n",
    "# Shared resources\n",
    "aspect_accuracies = manager.list()\n",
    "aspect_f1_micros = manager.list()\n",
    "aspect_f1_macros = manager.list()\n",
    "sentiment_accuracies = manager.list()\n",
    "sentiment_f1_micros = manager.list()\n",
    "sentiment_f1_macros = manager.list()\n",
    "accuracies = manager.list()\n",
    "f1_micros = manager.list()\n",
    "f1_macros = manager.list()\n",
    "\n",
    "# Non shared resources\n",
    "filename = 'hoasa-kmeans'\n",
    "epochs = 10\n",
    "batch_size = 16\n",
    "sequence_length = 48\n",
    "\n",
    "aspect_list = ['ac', 'air_panas', 'bau', 'general', 'kebersihan', 'linen', 'service', 'sunrise_meal', 'tv', 'wifi']\n",
    "aspect_mapping = {'ac': 0, 'air_panas': 1, 'bau': 2, 'general': 3, 'kebersihan': 4, 'linen': 5, 'service': 6, 'sunrise_meal': 7, 'tv': 8, 'wifi': 9}\n",
    "label_mapping = {\"neg\": 0, \"neut\": 1, 'neg_pos': 1, 'pos': 2}\n",
    "ignored_keys = ['labels', 'ori_text', 'ori_label', 'ori_indices', 'aspect']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a2e34f",
   "metadata": {
    "papermill": {
     "duration": 0.011018,
     "end_time": "2025-03-31T04:28:06.667084",
     "exception": false,
     "start_time": "2025-03-31T04:28:06.656066",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LOAD AND PREPROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba458125",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:28:06.690282Z",
     "iopub.status.busy": "2025-03-31T04:28:06.689931Z",
     "iopub.status.idle": "2025-03-31T04:28:06.765096Z",
     "shell.execute_reply": "2025-03-31T04:28:06.764343Z"
    },
    "papermill": {
     "duration": 0.088507,
     "end_time": "2025-03-31T04:28:06.766574",
     "exception": false,
     "start_time": "2025-03-31T04:28:06.678067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>ac</th>\n",
       "      <th>air_panas</th>\n",
       "      <th>bau</th>\n",
       "      <th>general</th>\n",
       "      <th>kebersihan</th>\n",
       "      <th>linen</th>\n",
       "      <th>service</th>\n",
       "      <th>sunrise_meal</th>\n",
       "      <th>tv</th>\n",
       "      <th>wifi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kebersihan kurang...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sangat mengecewakan... hotel bad image, kebers...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tempat nyaman bersih tapi tv terlalu tinggi ti...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>pos</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>semuanya bagus sesuai profile,dan harga promo ...</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>pos</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tempat tidur sangat keras, bantal besar dan ke...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neg</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "      <td>neut</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review    ac air_panas   bau  \\\n",
       "0                               kebersihan kurang...  neut      neut  neut   \n",
       "1  sangat mengecewakan... hotel bad image, kebers...  neut      neut  neut   \n",
       "2  Tempat nyaman bersih tapi tv terlalu tinggi ti...  neut      neut  neut   \n",
       "3  semuanya bagus sesuai profile,dan harga promo ...  neut       neg  neut   \n",
       "4  Tempat tidur sangat keras, bantal besar dan ke...   neg       neg  neut   \n",
       "\n",
       "  general kebersihan linen service sunrise_meal    tv  wifi  \n",
       "0    neut        neg  neut    neut         neut  neut  neut  \n",
       "1    neut        neg  neut    neut         neut  neut  neut  \n",
       "2    neut        pos  neut    neut         neut   neg  neut  \n",
       "3     pos       neut  neut    neut         neut  neut  neut  \n",
       "4    neut       neut   neg    neut         neut  neut  neut  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/hoasa-dataset/train_preprocess.csv', encoding='latin-1')\n",
    "val_data = pd.read_csv('/kaggle/input/hoasa-dataset/valid_preprocess.csv', encoding='latin-1')\n",
    "test_data = pd.read_csv('/kaggle/input/hoasa-dataset/test_preprocess.csv', encoding='latin-1')\n",
    "\n",
    "data = pd.concat([train_data, val_data, test_data], ignore_index=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62f29058",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:28:06.790015Z",
     "iopub.status.busy": "2025-03-31T04:28:06.789759Z",
     "iopub.status.idle": "2025-03-31T04:28:06.797701Z",
     "shell.execute_reply": "2025-03-31T04:28:06.796903Z"
    },
    "papermill": {
     "duration": 0.020886,
     "end_time": "2025-03-31T04:28:06.798962",
     "exception": false,
     "start_time": "2025-03-31T04:28:06.778076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff223836",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:28:06.821890Z",
     "iopub.status.busy": "2025-03-31T04:28:06.821668Z",
     "iopub.status.idle": "2025-03-31T04:28:06.832842Z",
     "shell.execute_reply": "2025-03-31T04:28:06.832209Z"
    },
    "papermill": {
     "duration": 0.023947,
     "end_time": "2025-03-31T04:28:06.834076",
     "exception": false,
     "start_time": "2025-03-31T04:28:06.810129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2283,) (2283, 10)\n",
      "(571,) (571, 10)\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_data.columns[1:]\n",
    "val_labels = val_data.columns[1:]\n",
    "\n",
    "# Extract features and labels for training and validation\n",
    "X_train = train_data['review'].values\n",
    "y_train = train_data[train_labels].values\n",
    "X_val = val_data['review'].values\n",
    "y_val = val_data[val_labels].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c454ca63",
   "metadata": {
    "papermill": {
     "duration": 0.011209,
     "end_time": "2025-03-31T04:28:06.856458",
     "exception": false,
     "start_time": "2025-03-31T04:28:06.845249",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BUILD DATASET & DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03d0bcd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:28:06.880121Z",
     "iopub.status.busy": "2025-03-31T04:28:06.879896Z",
     "iopub.status.idle": "2025-03-31T04:28:06.885666Z",
     "shell.execute_reply": "2025-03-31T04:28:06.885008Z"
    },
    "papermill": {
     "duration": 0.018768,
     "end_time": "2025-03-31T04:28:06.886893",
     "exception": false,
     "start_time": "2025-03-31T04:28:06.868125",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AspectDetectionDataset(Dataset):\n",
    "    def __init__(self, texts, labels, label_mapping, tokenizer, max_length=sequence_length, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        \n",
    "        original_labels = [self.label_mapping[label] for label in self.labels[idx]]\n",
    "        encoded_labels = [1 if label == 1 else 0 for label in original_labels]\n",
    "        \n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['ori_indices'] = idx\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(original_labels, dtype=torch.float)\n",
    "        item['labels'] = torch.tensor(encoded_labels, dtype=torch.float if self.use_float else torch.long)\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93f54628",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:28:06.909775Z",
     "iopub.status.busy": "2025-03-31T04:28:06.909577Z",
     "iopub.status.idle": "2025-03-31T04:28:06.915917Z",
     "shell.execute_reply": "2025-03-31T04:28:06.915321Z"
    },
    "papermill": {
     "duration": 0.019121,
     "end_time": "2025-03-31T04:28:06.917110",
     "exception": false,
     "start_time": "2025-03-31T04:28:06.897989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentAnalysisDataset(Dataset):\n",
    "    def __init__(self, texts, labels, aspects, indices, label_mapping, tokenizer, max_length=96, use_float=True):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.aspects = aspects\n",
    "        self.indices = indices\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.use_float = use_float\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = aspect_token + ' ' + self.aspects[idx] + ' ' + review_token + ' ' + self.texts[idx] \n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "\n",
    "        if isinstance(self.labels[idx], str):\n",
    "            self.labels[idx] = self.label_mapping[self.labels[idx]]\n",
    "        elif torch.is_tensor(self.labels[idx]):\n",
    "            self.labels[idx] = int(self.labels[idx].item())\n",
    "\n",
    "        encoded_label = 1 if self.labels[idx] == 2 else self.labels[idx]\n",
    "        one_hot_label = F.one_hot(torch.tensor(encoded_label, dtype=torch.long), num_classes=2).float()\n",
    "\n",
    "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
    "        item['aspect'] = self.aspects[idx]\n",
    "        item['labels'] = one_hot_label\n",
    "        item['ori_indices'] = self.indices[idx]\n",
    "        item['ori_text'] = self.texts[idx]\n",
    "        item['ori_label'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2de1774",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:28:06.940494Z",
     "iopub.status.busy": "2025-03-31T04:28:06.940287Z",
     "iopub.status.idle": "2025-03-31T04:28:07.848142Z",
     "shell.execute_reply": "2025-03-31T04:28:07.847514Z"
    },
    "papermill": {
     "duration": 0.921002,
     "end_time": "2025-03-31T04:28:07.849572",
     "exception": false,
     "start_time": "2025-03-31T04:28:06.928570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2e583225e14f228fe37379503089d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a62650e310e4d2dbb5a3ff6c6b43b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77b41effde9b4dda894d167d84b73caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da68c00ec9be4c8d95fa2e4f7ea4d603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "review_token = '[REVIEW]'\n",
    "aspect_token = '[ASPECT]'\n",
    "special_tokens_dict = {'additional_special_tokens': [review_token, aspect_token]}\n",
    "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21ff56b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:28:07.874831Z",
     "iopub.status.busy": "2025-03-31T04:28:07.874593Z",
     "iopub.status.idle": "2025-03-31T04:28:07.878822Z",
     "shell.execute_reply": "2025-03-31T04:28:07.878186Z"
    },
    "papermill": {
     "duration": 0.018176,
     "end_time": "2025-03-31T04:28:07.880117",
     "exception": false,
     "start_time": "2025-03-31T04:28:07.861941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_aspect_dataset(X_train, y_train, X_val, y_val, sequence_length, num_workers=4):\n",
    "    train_dataset = AspectDetectionDataset(X_train, y_train, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    val_dataset = AspectDetectionDataset(X_val, y_val, label_mapping, tokenizer, max_length=sequence_length)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=num_workers,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=num_workers, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86a23b82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:28:07.904101Z",
     "iopub.status.busy": "2025-03-31T04:28:07.903870Z",
     "iopub.status.idle": "2025-03-31T04:28:07.913185Z",
     "shell.execute_reply": "2025-03-31T04:28:07.912609Z"
    },
    "papermill": {
     "duration": 0.022501,
     "end_time": "2025-03-31T04:28:07.914319",
     "exception": false,
     "start_time": "2025-03-31T04:28:07.891818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_sentiment_dataset(device, train_dataset, val_dataset, aspect_detection_model, tokenizer, max_length=sequence_length):\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    aspect_detection_model.to(device)\n",
    "    aspect_detection_model.eval()\n",
    "\n",
    "    train_data = []\n",
    "    train_labels = []\n",
    "    train_aspects = []\n",
    "    train_indices = []\n",
    "\n",
    "    val_data = []\n",
    "    val_labels = []\n",
    "    val_aspects = []\n",
    "    val_indices = []\n",
    "\n",
    "    # Transform train set\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch in train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        train_aspects.append(aspect_list[j])\n",
    "                        train_data.append(batch['ori_text'][i])\n",
    "                        train_labels.append(batch['ori_label'][i][j])\n",
    "                        train_indices.append(batch['ori_indices'][i])\n",
    "            \n",
    "        # Transform validation set\n",
    "        for batch in val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = aspect_detection_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            for i in range(len(preds)):\n",
    "                for j in range(len(preds[i])):\n",
    "                    if int(preds[i][j]) != 1:\n",
    "                        val_aspects.append(aspect_list[j])\n",
    "                        val_data.append(batch['ori_text'][i])\n",
    "                        val_labels.append(batch['ori_label'][i][j])\n",
    "                        val_indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    train_dataset = SentimentAnalysisDataset(train_data, train_labels, train_aspects, train_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "    val_dataset = SentimentAnalysisDataset(val_data, val_labels, val_aspects, val_indices, label_mapping, tokenizer, max_length=max_length)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4, \n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf280368",
   "metadata": {
    "papermill": {
     "duration": 0.011482,
     "end_time": "2025-03-31T04:28:07.937460",
     "exception": false,
     "start_time": "2025-03-31T04:28:07.925978",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TRAIN THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29327cb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:28:07.961602Z",
     "iopub.status.busy": "2025-03-31T04:28:07.961387Z",
     "iopub.status.idle": "2025-03-31T04:28:07.964897Z",
     "shell.execute_reply": "2025-03-31T04:28:07.964294Z"
    },
    "papermill": {
     "duration": 0.016756,
     "end_time": "2025-03-31T04:28:07.965963",
     "exception": false,
     "start_time": "2025-03-31T04:28:07.949207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_data = len(X_train) + len(X_val)\n",
    "initial_train_size = int(0.05 * total_data)\n",
    "checkpoints = [\n",
    "    int(0.5 * total_data), \n",
    "    int(0.6 * total_data), \n",
    "    int(0.7 * total_data),\n",
    "    len(X_train)\n",
    "]\n",
    "min_increment = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "418148e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:28:07.989939Z",
     "iopub.status.busy": "2025-03-31T04:28:07.989736Z",
     "iopub.status.idle": "2025-03-31T04:28:07.993946Z",
     "shell.execute_reply": "2025-03-31T04:28:07.993404Z"
    },
    "papermill": {
     "duration": 0.017534,
     "end_time": "2025-03-31T04:28:07.995143",
     "exception": false,
     "start_time": "2025-03-31T04:28:07.977609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(p, label, classes):\n",
    "    preds = torch.tensor(p.predictions) # Sigmoid and threshold for multi-label\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Standard multi-label precision, recall, and F1 metrics\n",
    "    precision, recall, f1_micro, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
    "    _, _, f1_macro, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
    "\n",
    "    report = classification_report(\n",
    "        labels, \n",
    "        preds, \n",
    "        labels=label,\n",
    "        target_names=classes,\n",
    "        zero_division=0\n",
    "    ) \n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'report': report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edcfef36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:28:08.019598Z",
     "iopub.status.busy": "2025-03-31T04:28:08.019374Z",
     "iopub.status.idle": "2025-03-31T04:28:08.025392Z",
     "shell.execute_reply": "2025-03-31T04:28:08.024606Z"
    },
    "papermill": {
     "duration": 0.019396,
     "end_time": "2025-03-31T04:28:08.026577",
     "exception": false,
     "start_time": "2025-03-31T04:28:08.007181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics_overall(p, classes):\n",
    "    preds = torch.tensor(p.predictions)\n",
    "    labels = torch.tensor(p.label_ids)\n",
    "\n",
    "    # Ensure it's in the correct shape\n",
    "    if preds.shape != labels.shape:\n",
    "        raise ValueError(\"Shape mismatch: predictions and labels must have the same shape.\")\n",
    "\n",
    "    # Hamming accuracy: proportion of correctly predicted labels over total labels\n",
    "    hamming_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "    # Compute per-label (column-wise) precision, recall, F1\n",
    "    precision_list, recall_list, f1_micro_list, f1_macro_list = [], [], [], []\n",
    "    \n",
    "    for i in range(labels.shape[1]):  # Loop through each column (multi-output)\n",
    "        prec, rec, f1_micro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='micro', zero_division=0\n",
    "        )\n",
    "        _, _, f1_macro, _ = precision_recall_fscore_support(\n",
    "            labels[:, i], preds[:, i], average='macro', zero_division=0\n",
    "        )\n",
    "\n",
    "        precision_list.append(prec)\n",
    "        recall_list.append(rec)\n",
    "        f1_micro_list.append(f1_micro)\n",
    "        f1_macro_list.append(f1_macro)\n",
    "\n",
    "    # Compute average metrics across all outputs\n",
    "    precision = sum(precision_list) / len(precision_list)\n",
    "    recall = sum(recall_list) / len(recall_list)\n",
    "    f1_micro = sum(f1_micro_list) / len(f1_micro_list)\n",
    "    f1_macro = sum(f1_macro_list) / len(f1_macro_list)\n",
    "\n",
    "    # Generate classification report per output\n",
    "    reports = [classification_report(labels[:, i], preds[:, i], target_names=classes, zero_division=0) for i in range(labels.shape[1])]\n",
    "\n",
    "    return {\n",
    "        'accuracy': hamming_accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_micro': f1_micro,\n",
    "        'f1_macro': f1_macro,\n",
    "        'reports': reports  # Returns list of reports, one for each output label\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f44924e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:28:08.051062Z",
     "iopub.status.busy": "2025-03-31T04:28:08.050827Z",
     "iopub.status.idle": "2025-03-31T04:28:08.076248Z",
     "shell.execute_reply": "2025-03-31T04:28:08.075469Z"
    },
    "papermill": {
     "duration": 0.039191,
     "end_time": "2025-03-31T04:28:08.077614",
     "exception": false,
     "start_time": "2025-03-31T04:28:08.038423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(current_train_size, train_indices, aspect_metrics, sentiment_metrics, metrics, trials, seed):\n",
    "    accelerator = Accelerator(mixed_precision='fp16')  # Initialize the accelerator\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=len(train_labels),\n",
    "        problem_type=\"multi_label_classification\"\n",
    "    )\n",
    "\n",
    "    # Freeze the first few layers of the encoder\n",
    "    for name, param in aspect_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    # Define optimizer and loss function\n",
    "    aspect_optimizer = torch.optim.AdamW(aspect_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Define DataLoaders\n",
    "    current_X_train = [X_train[i] for i in train_indices]\n",
    "    current_y_train = [y_train[i] for i in train_indices]\n",
    "    aspect_train_loader, aspect_val_loader, aspect_train_dataset, aspect_val_dataset = build_aspect_dataset(current_X_train, current_y_train, X_val, y_val, sequence_length)\n",
    "\n",
    "    # Prepare everything with Accelerator\n",
    "    aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader = accelerator.prepare(\n",
    "        aspect_model, aspect_optimizer, aspect_train_loader, aspect_val_loader\n",
    "    )\n",
    "\n",
    "    aspect_result = None\n",
    "    start_time = time.time()\n",
    "\n",
    "    # ASPECT DETECTION\n",
    "    accelerator.print(\"ASPECT DETECTION\")\n",
    "    for epoch in range(epochs):\n",
    "        aspect_model.train()\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for batch in aspect_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            aspect_optimizer.zero_grad()\n",
    "            outputs = aspect_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            aspect_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        aspect_model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in aspect_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                labels = batch['labels']\n",
    "                \n",
    "                outputs = aspect_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                # Gather predictions and labels from all devices\n",
    "                all_preds.append(accelerator.gather(preds))\n",
    "                all_labels.append(accelerator.gather(labels))\n",
    "\n",
    "        all_preds = torch.cat(all_preds).cpu().numpy()\n",
    "        all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': all_preds, 'label_ids': all_labels}),\n",
    "            None,\n",
    "            aspect_list,\n",
    "        )\n",
    "\n",
    "        if aspect_result is None or result['f1_micro'] >= aspect_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(aspect_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                f'{filename}-aspect-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "            aspect_result = result\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(aspect_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "\n",
    "    accelerator.print(f\"\\nAspect detection accuracy: {round(aspect_result['accuracy'], 4)}, F1 Micro: {round(aspect_result['f1_micro'], 4)}, F1 Macro: {round(aspect_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(aspect_result['report'])\n",
    "\n",
    "    best_aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{trials + 1}-model')\n",
    "    best_aspect_model = accelerator.prepare(best_aspect_model)\n",
    "\n",
    "    # SENTIMENT ANALYSIS ON NON NEUTRAL ASPECTS\n",
    "    accelerator.print(\"--------------------------------------------------\")\n",
    "    accelerator.print(\"SENTIMENT ANALYSIS\")\n",
    "\n",
    "    sentiment_model = BertForSequenceClassification.from_pretrained(\n",
    "        'indobenchmark/indobert-base-p1',\n",
    "        num_labels=2,\n",
    "    )\n",
    "    sentiment_optimizer = torch.optim.AdamW(sentiment_model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "\n",
    "    for name, param in sentiment_model.named_parameters():\n",
    "        if \"encoder.layer\" in name:\n",
    "            layer_num = name.split(\".\")[3]\n",
    "            try:\n",
    "                if int(layer_num) < 6:\n",
    "                    param.requires_grad = False\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    sentiment_train_loader, sentiment_val_loader, sentiment_train_dataset, sentiment_val_dataset = build_sentiment_dataset(\n",
    "        device, aspect_train_dataset, aspect_val_dataset, best_aspect_model, tokenizer, max_length=sequence_length\n",
    "    )\n",
    "    sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader = accelerator.prepare(\n",
    "        sentiment_model, sentiment_optimizer, sentiment_train_loader, sentiment_val_loader\n",
    "    )\n",
    "    sentiment_result = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        sentiment_model.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch in sentiment_train_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            labels = batch['labels']\n",
    "        \n",
    "            sentiment_optimizer.zero_grad()\n",
    "            outputs = sentiment_model(**inputs)\n",
    "            loss = loss_fn(outputs.logits, labels)\n",
    "            accelerator.backward(loss)\n",
    "            sentiment_optimizer.step()\n",
    "        \n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        sentiment_model.eval()\n",
    "        sentiment_val_outputs = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in sentiment_val_loader:\n",
    "                inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "                \n",
    "                outputs = sentiment_model(**inputs)\n",
    "                preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "                for i in range(len(preds)):\n",
    "                    val_output = {\n",
    "                        'label': batch['labels'][i],\n",
    "                        'aspect': batch['aspect'][i],\n",
    "                        'ori_indices': batch['ori_indices'][i],\n",
    "                        'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                    }\n",
    "                    sentiment_val_outputs.append(val_output)\n",
    "\n",
    "        sentiment_val_outputs = accelerator.gather_for_metrics(sentiment_val_outputs)\n",
    "        unique_val_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_val_outputs}\n",
    "        sentiment_val_outputs = list(unique_val_outputs.values())\n",
    "\n",
    "        result = compute_metrics(\n",
    "            type('EvalOutput', (object,), {'predictions': [item['pred'] for item in sentiment_val_outputs], 'label_ids': [np.argmax(item['label'].cpu().numpy()) for item in sentiment_val_outputs]}),\n",
    "            [0, 1],\n",
    "            ['negative', 'positive']\n",
    "        )\n",
    "\n",
    "        if sentiment_result is None or result['f1_micro'] >= sentiment_result['f1_micro']:\n",
    "            accelerator.print(\"Higher F1 achieved, saving model\")\n",
    "            sentiment_result = result\n",
    "            \n",
    "            accelerator.wait_for_everyone()\n",
    "            unwrapped_model = accelerator.unwrap_model(sentiment_model)\n",
    "            unwrapped_model.save_pretrained(\n",
    "                 f'{filename}-sentiment-{trials + 1}-model',\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "            )\n",
    "\n",
    "        accelerator.print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {round(epoch_loss / len(sentiment_train_loader), 4)}, Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "\n",
    "    accelerator.print(f\"\\nSentiment analysis accuracy: {round(sentiment_result['accuracy'], 4)}, F1 Micro: {round(sentiment_result['f1_micro'], 4)}, F1 Macro: {round(sentiment_result['f1_macro'], 4)}\")\n",
    "    accelerator.print(sentiment_result['report'])\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    best_sentiment_model = BertForSequenceClassification.from_pretrained( f'{filename}-sentiment-{trials + 1}-model')\n",
    "    best_sentiment_model = accelerator.prepare(best_sentiment_model)\n",
    "\n",
    "    # Compute overall metrics\n",
    "    aspect_labels = []\n",
    "    aspect_indices = []\n",
    "    aspect_preds = []\n",
    "\n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = []\n",
    "    \n",
    "    best_aspect_model.eval()\n",
    "    best_sentiment_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in aspect_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = best_aspect_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "\n",
    "            aspect_indices.append(accelerator.gather(batch['ori_indices']))\n",
    "            aspect_labels.append(accelerator.gather(batch['ori_label']))\n",
    "            aspect_preds.append(accelerator.gather(preds))\n",
    "\n",
    "        aspect_indices = torch.cat(aspect_indices).cpu().numpy()\n",
    "        aspect_labels = torch.cat(aspect_labels).cpu().numpy()\n",
    "        aspect_preds = torch.cat(aspect_preds).cpu().numpy()\n",
    "\n",
    "        accelerator.wait_for_everyone()\n",
    "        aspect_outputs = [\n",
    "            {'ori_indices': aspect_indices[i], \n",
    "             'ori_labels': aspect_labels[i], \n",
    "             'pred': aspect_preds[i]}\n",
    "            for i in range(len(aspect_preds))\n",
    "        ]\n",
    "        aspect_outputs = {x['ori_indices'].item(): x for x in aspect_outputs}\n",
    "    \n",
    "        for batch in sentiment_val_loader:\n",
    "            inputs = {key: val for key, val in batch.items() if key not in ignored_keys}\n",
    "            outputs = best_sentiment_model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits).round()\n",
    "    \n",
    "            for i in range(len(preds)):\n",
    "                output = {\n",
    "                    'aspect': batch['aspect'][i],\n",
    "                    'ori_indices': batch['ori_indices'][i],\n",
    "                    'pred': np.argmax(preds[i].cpu().numpy()),\n",
    "                }\n",
    "                sentiment_outputs.append(output)\n",
    "\n",
    "        sentiment_outputs = accelerator.gather_for_metrics(sentiment_outputs)\n",
    "        sentiment_outputs = {(x['ori_indices'].item(), x['aspect']): x for x in sentiment_outputs}\n",
    "\n",
    "    # Replcae non neutral aspect to its predicted sentiment\n",
    "    accelerator.wait_for_everyone()\n",
    "    if accelerator.is_main_process:\n",
    "        i = -1\n",
    "        for (ori_index, aspect), value in sentiment_outputs.items():\n",
    "            aspect = aspect_mapping[aspect]\n",
    "            aspect_outputs[ori_index]['pred'][aspect] = 2 if value['pred'] == 1.0 else value['pred']\n",
    "\n",
    "        result = compute_metrics_overall(\n",
    "            type('EvalOutput', (object,), {'predictions': [output['pred'] for output in aspect_outputs.values()], 'label_ids': [output['ori_labels'] for output in aspect_outputs.values()]}),\n",
    "            ['negative', 'neutral', 'positive'],\n",
    "        )\n",
    "\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        accelerator.print(f\"Iteration {current_train_size}: Accuracy: {round(result['accuracy'], 4)}, F1 Micro: {round(result['f1_micro'], 4)}, F1 Macro: {round(result['f1_macro'], 4)}\")\n",
    "        accelerator.print(\"--------------------------------------------------\")\n",
    "        for i in range(len(train_labels)):\n",
    "            accelerator.print(f\"Aspect {aspect_list[i]} report:\")\n",
    "            accelerator.print(result['reports'][i])\n",
    "       \n",
    "        \n",
    "        aspect_metrics[0].append(aspect_result['accuracy'])\n",
    "        aspect_metrics[1].append(aspect_result['f1_micro'])\n",
    "        aspect_metrics[2].append(aspect_result['f1_macro'])\n",
    "        sentiment_metrics[0].append(sentiment_result['accuracy'])\n",
    "        sentiment_metrics[1].append(sentiment_result['f1_micro'])\n",
    "        sentiment_metrics[2].append(sentiment_result['f1_macro'])\n",
    "        metrics[0].append(current_train_size)\n",
    "        metrics[1].append(result['accuracy'])\n",
    "        metrics[2].append(result['f1_micro'])\n",
    "        metrics[3].append(result['f1_macro'])\n",
    "        \n",
    "    accelerator.print(f\"Total train time: {duration} s\")\n",
    "    accelerator.end_training()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defd48d4",
   "metadata": {
    "papermill": {
     "duration": 0.011512,
     "end_time": "2025-03-31T04:28:08.102257",
     "exception": false,
     "start_time": "2025-03-31T04:28:08.090745",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# PLOT THE RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30c264ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:28:08.126172Z",
     "iopub.status.busy": "2025-03-31T04:28:08.125946Z",
     "iopub.status.idle": "2025-03-31T04:28:08.131009Z",
     "shell.execute_reply": "2025-03-31T04:28:08.130403Z"
    },
    "papermill": {
     "duration": 0.018409,
     "end_time": "2025-03-31T04:28:08.132201",
     "exception": false,
     "start_time": "2025-03-31T04:28:08.113792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_result(data_used, accuracies, f1_micros, f1_macros):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(21, 5))\n",
    "    data_used = [round(data / total_data * 100, 1) for data in data_used]\n",
    "\n",
    "    # Plot for Accuracy\n",
    "    axs[0].plot(data_used, accuracies, label=\"Accuracy\", color=\"blue\")\n",
    "    axs[0].set_xlabel(\"Percentage of data used\")\n",
    "    axs[0].set_title(\"Accuracy\")\n",
    "    axs[0].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Micro\n",
    "    axs[1].plot(data_used, f1_micros, label=\"F1 Micro\", color=\"orange\")\n",
    "    axs[1].set_xlabel(\"Percentage of data used\")\n",
    "    axs[1].set_title(\"F1 Micro\")\n",
    "    axs[1].set_xticks(data_used)\n",
    "\n",
    "    # Plot for F1 Macro\n",
    "    axs[2].plot(data_used, f1_macros, label=\"F1 Macro\", color=\"green\")\n",
    "    axs[2].set_xlabel(\"Percentage of data used\")\n",
    "    axs[2].set_title(\"F1 Macro\")\n",
    "    axs[2].set_xticks(data_used)\n",
    "\n",
    "    # Adjust layout and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8575d3",
   "metadata": {
    "papermill": {
     "duration": 0.011364,
     "end_time": "2025-03-31T04:28:08.155112",
     "exception": false,
     "start_time": "2025-03-31T04:28:08.143748",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QUERY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5615d55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:28:08.180394Z",
     "iopub.status.busy": "2025-03-31T04:28:08.180169Z",
     "iopub.status.idle": "2025-03-31T04:28:08.199590Z",
     "shell.execute_reply": "2025-03-31T04:28:08.198918Z"
    },
    "papermill": {
     "duration": 0.032793,
     "end_time": "2025-03-31T04:28:08.200701",
     "exception": false,
     "start_time": "2025-03-31T04:28:08.167908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kmeans_clustering_sampling(aspect_model, sentiment_model, X_pool, train_indices, remaining_indices, sampling_dur, new_samples, trials, n_clusters=min_increment):\n",
    "    accelerator = Accelerator(mixed_precision=\"fp16\")\n",
    "    device = accelerator.device\n",
    "\n",
    "    aspect_model.to(device)\n",
    "    aspect_model.eval()\n",
    "    sentiment_model.to(device)\n",
    "    sentiment_model.eval()\n",
    "\n",
    "    current_train_size = len(train_indices)\n",
    "    aspect_dataset = AspectDetectionDataset(\n",
    "        X_pool, \n",
    "        [['neut' for i in range(len(train_labels))] for x in range(len(X_pool))], \n",
    "        label_mapping, \n",
    "        tokenizer, \n",
    "        max_length=sequence_length\n",
    "    )\n",
    "    aspect_loader = DataLoader(\n",
    "        aspect_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    aspect_outputs = {}\n",
    "    sentiment_outputs = {}\n",
    "\n",
    "    aspects = []\n",
    "    data = []\n",
    "    labels = []\n",
    "    indices = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Pass through aspect detction model\n",
    "    for batch in aspect_loader:\n",
    "        token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "        input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "        attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = aspect_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).logits\n",
    "            embeddings = aspect_model.base_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "\n",
    "        for i in range(len(outputs)):\n",
    "            aspect_outputs[batch['ori_indices'][i].item()] = embeddings.last_hidden_state[i].mean(dim=1).cpu().numpy()\n",
    "            \n",
    "            for j in range(len(outputs[i])):\n",
    "                if int(outputs[i][j].round()) != 1:\n",
    "                    aspects.append(aspect_list[j])\n",
    "                    data.append(batch['ori_text'][i])\n",
    "                    labels.append(batch['ori_label'][i][j])\n",
    "                    indices.append(batch['ori_indices'][i])\n",
    "\n",
    "    if len(data) > 0:\n",
    "        sentiment_dataset = SentimentAnalysisDataset(data, labels, aspects, indices, label_mapping, tokenizer, max_length=sequence_length)\n",
    "        sentiment_loader = torch.utils.data.DataLoader(\n",
    "            sentiment_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=4,\n",
    "        )\n",
    "    \n",
    "        # Pass through sentiment analysis model\n",
    "        for batch in sentiment_loader:\n",
    "            token_type_ids = batch['token_type_ids'].to(device, non_blocking=True)\n",
    "            input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
    "            attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
    "    \n",
    "            with torch.no_grad():\n",
    "                outputs = sentiment_model.base_model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "    \n",
    "            for i in range(len(outputs.last_hidden_state)):\n",
    "                ori_index = batch['ori_indices'][i].item()\n",
    "                if ori_index in sentiment_outputs.keys():\n",
    "                    sentiment_outputs[ori_index].append(outputs.last_hidden_state[i].mean(dim=1).cpu().numpy())\n",
    "                else:\n",
    "                    sentiment_outputs[ori_index] = [outputs.last_hidden_state[i].mean(dim=1).cpu().numpy()]\n",
    "\n",
    "    for key, val in sentiment_outputs.items():\n",
    "        sentiment_outputs[key] = np.mean(val, axis=0)\n",
    "\n",
    "    collected_indices = set()  # Initialize set to store selected indices\n",
    "    thresholds = []\n",
    "\n",
    "    if accelerator.is_main_process:\n",
    "        aspect_outputs = dict(sorted(aspect_outputs.items()))\n",
    "\n",
    "        if len(data) > 0:\n",
    "            for key, val in sentiment_outputs.items():\n",
    "                aspect_outputs[key] = np.mean([val, aspect_outputs[key]], axis=0)\n",
    "\n",
    "        embeddings = np.array(list(aspect_outputs.values()))\n",
    "        target_samples = len(embeddings[:math.ceil(0.1 * len(embeddings))])\n",
    "    \n",
    "        # Check nearest checkpoint\n",
    "        nearest_cp = 0\n",
    "        arrived_at_cp = False\n",
    "        for cp in checkpoints:\n",
    "            if cp > current_train_size:\n",
    "                nearest_cp = cp\n",
    "                break\n",
    "                \n",
    "        # Determine number of maximum samples to be acquired\n",
    "        if target_samples <= n_clusters and n_clusters < nearest_cp - current_train_size:\n",
    "            target_samples = n_clusters\n",
    "        elif target_samples > n_clusters and target_samples < nearest_cp - current_train_size:\n",
    "            target_samples = target_samples\n",
    "        else:\n",
    "            arrived_at_cp = True\n",
    "            target_samples = nearest_cp - current_train_size\n",
    "\n",
    "        # No clustering needed when there's little data left\n",
    "        if current_train_size >= checkpoints[len(checkpoints)-1] - min_increment:\n",
    "            end_time = time.time()\n",
    "            duration = end_time - start_time\n",
    "            \n",
    "            temp = train_indices.copy()\n",
    "            temp.extend(remaining_indices)\n",
    "            \n",
    "            # Save acquired data up to checkpoint\n",
    "            acquired_data = pd.DataFrame({\n",
    "                'processed_text': [X_train[i] for i in temp],\n",
    "                'ac': [y_train[i][0] for i in temp],\n",
    "                'air_panas': [y_train[i][1] for i in temp],\n",
    "                'bau': [y_train[i][2] for i in temp],\n",
    "                'general': [y_train[i][3] for i in temp],\n",
    "                'kebersihan': [y_train[i][4] for i in temp],\n",
    "                'linen': [y_train[i][5] for i in temp],\n",
    "                'service': [y_train[i][6] for i in temp],\n",
    "                'sunrise_meal': [y_train[i][7] for i in temp],\n",
    "                'tv': [y_train[i][8] for i in temp],\n",
    "                'wifi': [y_train[i][9] for i in temp],\n",
    "            })\n",
    "            acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "\n",
    "            print(\"Nearest checkpoint:\", nearest_cp)\n",
    "            print(\"Acquired samples:\", len(remaining_indices))\n",
    "            print(f\"Sampling duration: {duration} seconds\")\n",
    "            \n",
    "            sampling_dur.append(duration)\n",
    "            for i in remaining_indices:\n",
    "                new_samples.append(i)\n",
    "        else:\n",
    "            # Cluster the data based on its embeddings\n",
    "            kmeans=KMeans(n_clusters=n_clusters, n_init=1)\n",
    "            kmeans.fit(embeddings)\n",
    "            \n",
    "            for cluster_id in range(n_clusters):\n",
    "                # Cluster center and indices of samples in the current cluster\n",
    "                cluster_center = kmeans.cluster_centers_[cluster_id]\n",
    "                cluster_indices = np.where(kmeans.labels_ == cluster_id)[0]\n",
    "            \n",
    "                if cluster_indices.size == 0:\n",
    "                    # Skip clusters with no members\n",
    "                    print(f\"Cluster {cluster_id} has no members, skipping.\")\n",
    "                    continue\n",
    "            \n",
    "                # Calculate distances of each point in the cluster from the cluster center\n",
    "                cluster_distances = np.linalg.norm(embeddings[cluster_indices] - cluster_center, axis=1)\n",
    "            \n",
    "                # Determine the local threshold (10th percentile of closest distances to cluster center)\n",
    "                local_threshold = np.percentile(cluster_distances, 90)\n",
    "                thresholds.append(local_threshold)\n",
    "            \n",
    "                below_threshold_indices = cluster_indices[cluster_distances >= local_threshold]\n",
    "                collected_indices.update(below_threshold_indices)\n",
    "\n",
    "            # To handle multiple points with same distance\n",
    "            if len(collected_indices) > target_samples:\n",
    "                collected_indices = np.array(list(collected_indices))\n",
    "                np.random.shuffle(collected_indices)\n",
    "                collected_indices = collected_indices[:target_samples]\n",
    "                \n",
    "            end_time = time.time() \n",
    "            duration = end_time - start_time \n",
    "    \n",
    "            if arrived_at_cp:\n",
    "                temp = train_indices.copy()\n",
    "                temp.extend(collected_indices)\n",
    "                \n",
    "                # Save acquired data up to checkpoint\n",
    "                acquired_data = pd.DataFrame({\n",
    "                    'processed_text': [X_train[i] for i in temp],\n",
    "                    'ac': [y_train[i][0] for i in temp],\n",
    "                    'air_panas': [y_train[i][1] for i in temp],\n",
    "                    'bau': [y_train[i][2] for i in temp],\n",
    "                    'general': [y_train[i][3] for i in temp],\n",
    "                    'kebersihan': [y_train[i][4] for i in temp],\n",
    "                    'linen': [y_train[i][5] for i in temp],\n",
    "                    'service': [y_train[i][6] for i in temp],\n",
    "                    'sunrise_meal': [y_train[i][7] for i in temp],\n",
    "                    'tv': [y_train[i][8] for i in temp],\n",
    "                    'wifi': [y_train[i][9] for i in temp],\n",
    "                })\n",
    "        \n",
    "                acquired_data.to_csv(f'acquired_data/{filename}-{trials+1}-data-{nearest_cp}.csv', index=False)\n",
    "            \n",
    "            print(\"Nearest checkpoint:\", nearest_cp)\n",
    "            print(\"Acquired samples:\", len(collected_indices))\n",
    "            print(f\"Sampling duration: {duration} seconds\")\n",
    "        \n",
    "            sampling_dur.append(duration)\n",
    "            for i in collected_indices:\n",
    "                new_samples.append(remaining_indices[i])\n",
    "\n",
    "        threshold_data = pd.DataFrame({\n",
    "            'Threshold': thresholds\n",
    "        })\n",
    "        threshold_data.to_csv(f\"results/{filename}-thresholds-{trials+1}-{current_train_size}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494b7c4b",
   "metadata": {
    "papermill": {
     "duration": 0.011437,
     "end_time": "2025-03-31T04:28:08.223763",
     "exception": false,
     "start_time": "2025-03-31T04:28:08.212326",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# MAIN LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3eeb341f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:28:08.247786Z",
     "iopub.status.busy": "2025-03-31T04:28:08.247580Z",
     "iopub.status.idle": "2025-03-31T04:28:08.256182Z",
     "shell.execute_reply": "2025-03-31T04:28:08.255579Z"
    },
    "papermill": {
     "duration": 0.022112,
     "end_time": "2025-03-31T04:28:08.257514",
     "exception": false,
     "start_time": "2025-03-31T04:28:08.235402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def active_learning(seed, i):\n",
    "    aspect_accuracies = manager.list()\n",
    "    aspect_f1_micros = manager.list()\n",
    "    aspect_f1_macros = manager.list()\n",
    "    sentiment_accuracies = manager.list()\n",
    "    sentiment_f1_micros = manager.list()\n",
    "    sentiment_f1_macros = manager.list()\n",
    "    accuracies = manager.list()\n",
    "    f1_micros = manager.list()\n",
    "    f1_macros = manager.list()\n",
    "    data_used = manager.list()\n",
    "    sampling_dur = manager.list()\n",
    "    new_samples = manager.list()\n",
    "\n",
    "    set_seed(seed)\n",
    "    \n",
    "    print(\"===============================================\")\n",
    "    print(\"TRIAL {}\".format(i+1))\n",
    "    print(\"Random seed:\", seed)\n",
    "    \n",
    "    train_indices = np.random.choice(range(len(X_train)), initial_train_size, replace=False).tolist()\n",
    "    remaining_indices = list(set(range(len(X_train))) - set(train_indices))\n",
    "    \n",
    "    current_train_size = initial_train_size\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while current_train_size < checkpoints[len(checkpoints) - 1]:\n",
    "        # Train the model\n",
    "        args = (\n",
    "            current_train_size, \n",
    "            train_indices, \n",
    "            (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "            (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "            (data_used, accuracies, f1_micros, f1_macros), \n",
    "            i,\n",
    "            seed\n",
    "        )\n",
    "        notebook_launcher(train_model, args, num_processes=2)\n",
    "\n",
    "        aspect_model = BertForSequenceClassification.from_pretrained(f'{filename}-aspect-{i+1}-model')\n",
    "        sentiment_model = BertForSequenceClassification.from_pretrained(f'{filename}-sentiment-{i+1}-model')\n",
    "    \n",
    "        # Perform query strategy to select new samples\n",
    "        new_samples = manager.list()\n",
    "        sampling_args = (\n",
    "            aspect_model, \n",
    "            sentiment_model, \n",
    "            [X_train[i] for i in remaining_indices], \n",
    "            train_indices, \n",
    "            remaining_indices, \n",
    "            sampling_dur, \n",
    "            new_samples, \n",
    "            i\n",
    "        )\n",
    "        notebook_launcher(kmeans_clustering_sampling, sampling_args, num_processes=2)\n",
    "        new_samples = list(new_samples)\n",
    "        train_indices.extend(new_samples)\n",
    "        remaining_indices = list(set(remaining_indices) - set(new_samples))\n",
    "    \n",
    "        # Update current training size\n",
    "        current_train_size = len(train_indices)\n",
    "        print(\"New train size: {}\".format(current_train_size))\n",
    "    \n",
    "    # Train last epoch\n",
    "    args = (\n",
    "        current_train_size, \n",
    "        train_indices, \n",
    "        (aspect_accuracies, aspect_f1_micros, aspect_f1_macros), \n",
    "        (sentiment_accuracies, sentiment_f1_micros, sentiment_f1_macros),\n",
    "        (data_used, accuracies, f1_micros, f1_macros), \n",
    "        i,\n",
    "        seed\n",
    "    )\n",
    "    notebook_launcher(train_model, args, num_processes=2)\n",
    "    data_used, accuracies, f1_micros, f1_macros, sampling_dur = list(data_used), list(accuracies), list(f1_micros), list(f1_macros), list(sampling_dur)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    # print(f\"Total sampling time: {np.array(sampling_dur).sum().round(2)} seconds\")\n",
    "    print(f\"Total runtime: {duration} seconds\")\n",
    "    \n",
    "    plot_result(data_used, accuracies, f1_micros, f1_macros)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Data Used': data_used,\n",
    "        'Aspect Accuracy': aspect_accuracies,\n",
    "        'Aspect F1 Micro': aspect_f1_micros,\n",
    "        'Aspect F1 Macro': aspect_f1_macros,\n",
    "        'Sentiment Accuracy': sentiment_accuracies,\n",
    "        'Sentiment F1 Micro': sentiment_f1_micros,\n",
    "        'Sentiment F1 Macro': sentiment_f1_macros,\n",
    "        'Accuracy': accuracies,\n",
    "        'F1 Micro': f1_micros,\n",
    "        'F1 Macro': f1_macros,\n",
    "    })\n",
    "    \n",
    "    sampling_dur.insert(0, 0)\n",
    "    results['Sampling Duration'] = sampling_dur\n",
    "    results.to_csv(f'results/{filename}-{i+1}-results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7a16df8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:28:08.281641Z",
     "iopub.status.busy": "2025-03-31T04:28:08.281442Z",
     "iopub.status.idle": "2025-03-31T04:28:08.284424Z",
     "shell.execute_reply": "2025-03-31T04:28:08.283779Z"
    },
    "papermill": {
     "duration": 0.016319,
     "end_time": "2025-03-31T04:28:08.285604",
     "exception": false,
     "start_time": "2025-03-31T04:28:08.269285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seeds = [50, 81, 14, 3, 94]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e669acf",
   "metadata": {
    "papermill": {
     "duration": 0.011391,
     "end_time": "2025-03-31T04:28:08.308730",
     "exception": false,
     "start_time": "2025-03-31T04:28:08.297339",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396051c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 1\n",
      "Random seed: 50\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5865, Accuracy: 0.7995, F1 Micro: 0.8876, F1 Macro: 0.8805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4747, Accuracy: 0.801, F1 Micro: 0.8892, F1 Macro: 0.8841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4337, Accuracy: 0.8007, F1 Micro: 0.8893, F1 Macro: 0.8848\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.425, Accuracy: 0.8033, F1 Micro: 0.8905, F1 Macro: 0.8856\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4065, Accuracy: 0.8064, F1 Micro: 0.8916, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4121, Accuracy: 0.8101, F1 Micro: 0.8933, F1 Macro: 0.8874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3857, Accuracy: 0.8177, F1 Micro: 0.8971, F1 Macro: 0.8914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3725, Accuracy: 0.8321, F1 Micro: 0.9044, F1 Macro: 0.8994\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3428, Accuracy: 0.841, F1 Micro: 0.9088, F1 Macro: 0.9042\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3197, Accuracy: 0.8507, F1 Micro: 0.9137, F1 Macro: 0.9092\n",
      "\n",
      "Aspect detection accuracy: 0.8507, F1 Micro: 0.9137, F1 Macro: 0.9092\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.84      1.00      0.91       462\n",
      "   air_panas       0.84      1.00      0.91       480\n",
      "         bau       0.86      1.00      0.93       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.80      0.85      0.83       317\n",
      "       linen       0.71      0.99      0.83       392\n",
      "     service       0.88      0.97      0.93       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.90      1.00      0.95       516\n",
      "        wifi       0.86      1.00      0.93       498\n",
      "\n",
      "   micro avg       0.85      0.99      0.91      4614\n",
      "   macro avg       0.85      0.98      0.91      4614\n",
      "weighted avg       0.85      0.99      0.91      4614\n",
      " samples avg       0.85      0.99      0.91      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6014, Accuracy: 0.6293, F1 Micro: 0.6293, F1 Macro: 0.3862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5503, Accuracy: 0.6293, F1 Micro: 0.6293, F1 Macro: 0.3862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4934, Accuracy: 0.6293, F1 Micro: 0.6293, F1 Macro: 0.3862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3898, Accuracy: 0.6878, F1 Micro: 0.6878, F1 Macro: 0.5444\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3441, Accuracy: 0.7488, F1 Micro: 0.7488, F1 Macro: 0.6959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2311, Accuracy: 0.7634, F1 Micro: 0.7634, F1 Macro: 0.719\n",
      "Epoch 7/10, Train Loss: 0.181, Accuracy: 0.7439, F1 Micro: 0.7439, F1 Macro: 0.6915\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2402, Accuracy: 0.7756, F1 Micro: 0.7756, F1 Macro: 0.7399\n",
      "Epoch 9/10, Train Loss: 0.1526, Accuracy: 0.7512, F1 Micro: 0.7512, F1 Macro: 0.6996\n",
      "Epoch 10/10, Train Loss: 0.1164, Accuracy: 0.7537, F1 Micro: 0.7537, F1 Macro: 0.7047\n",
      "\n",
      "Sentiment analysis accuracy: 0.7756, F1 Micro: 0.7756, F1 Macro: 0.7399\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.91      0.84       258\n",
      "    positive       0.78      0.55      0.64       152\n",
      "\n",
      "    accuracy                           0.78       410\n",
      "   macro avg       0.78      0.73      0.74       410\n",
      "weighted avg       0.78      0.78      0.76       410\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 142: Accuracy: 0.8419, F1 Micro: 0.8419, F1 Macro: 0.4131\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.27      0.42        97\n",
      "     neutral       0.84      1.00      0.91       459\n",
      "    positive       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.59      0.42      0.44       571\n",
      "weighted avg       0.84      0.85      0.81       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.01      0.02        86\n",
      "     neutral       0.83      1.00      0.91       475\n",
      "    positive       1.00      0.10      0.18        10\n",
      "\n",
      "    accuracy                           0.84       571\n",
      "   macro avg       0.94      0.37      0.37       571\n",
      "weighted avg       0.86      0.84      0.76       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        78\n",
      "     neutral       0.86      1.00      0.92       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.74      0.86      0.80       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.69      0.71       200\n",
      "     neutral       0.80      0.85      0.83       315\n",
      "    positive       0.43      0.38      0.40        56\n",
      "\n",
      "    accuracy                           0.75       571\n",
      "   macro avg       0.66      0.64      0.65       571\n",
      "weighted avg       0.74      0.75      0.75       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.18      0.30       162\n",
      "     neutral       0.71      0.99      0.83       387\n",
      "    positive       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.72       571\n",
      "   macro avg       0.52      0.39      0.37       571\n",
      "weighted avg       0.72      0.72      0.64       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.48      0.59        85\n",
      "     neutral       0.88      0.98      0.93       418\n",
      "    positive       0.76      0.62      0.68        68\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.80      0.69      0.73       571\n",
      "weighted avg       0.85      0.86      0.85       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.89      1.00      0.94       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.30      0.33      0.31       571\n",
      "weighted avg       0.80      0.89      0.85       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        74\n",
      "     neutral       0.87      1.00      0.93       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.80       571\n",
      "\n",
      "Total train time: 77.75232577323914 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 215\n",
      "Sampling duration: 50.9647958278656 seconds\n",
      "New train size: 357\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5414, Accuracy: 0.8007, F1 Micro: 0.8893, F1 Macro: 0.8848\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4635, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.446, Accuracy: 0.8186, F1 Micro: 0.8974, F1 Macro: 0.8914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3999, Accuracy: 0.8415, F1 Micro: 0.9092, F1 Macro: 0.9054\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3563, Accuracy: 0.854, F1 Micro: 0.9157, F1 Macro: 0.912\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3118, Accuracy: 0.8682, F1 Micro: 0.923, F1 Macro: 0.9189\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2714, Accuracy: 0.8925, F1 Micro: 0.9365, F1 Macro: 0.9329\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2303, Accuracy: 0.9047, F1 Micro: 0.9428, F1 Macro: 0.9388\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2104, Accuracy: 0.9102, F1 Micro: 0.9462, F1 Macro: 0.9429\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1851, Accuracy: 0.9203, F1 Micro: 0.9516, F1 Macro: 0.9476\n",
      "\n",
      "Aspect detection accuracy: 0.9203, F1 Micro: 0.9516, F1 Macro: 0.9476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.96      0.99      0.98       462\n",
      "   air_panas       0.93      0.99      0.96       480\n",
      "         bau       0.93      0.99      0.96       496\n",
      "     general       0.89      0.98      0.94       500\n",
      "  kebersihan       0.87      0.87      0.87       317\n",
      "       linen       0.81      0.98      0.88       392\n",
      "     service       0.95      0.95      0.95       423\n",
      "sunrise_meal       0.93      1.00      0.97       530\n",
      "          tv       0.98      1.00      0.99       516\n",
      "        wifi       0.98      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.93      0.98      0.95      4614\n",
      "   macro avg       0.92      0.97      0.95      4614\n",
      "weighted avg       0.93      0.98      0.95      4614\n",
      " samples avg       0.93      0.98      0.95      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5533, Accuracy: 0.7161, F1 Micro: 0.7161, F1 Macro: 0.4396\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4251, Accuracy: 0.8164, F1 Micro: 0.8164, F1 Macro: 0.728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2899, Accuracy: 0.8438, F1 Micro: 0.8438, F1 Macro: 0.7899\n",
      "Epoch 4/10, Train Loss: 0.2469, Accuracy: 0.8347, F1 Micro: 0.8347, F1 Macro: 0.7631\n",
      "Epoch 5/10, Train Loss: 0.2308, Accuracy: 0.8415, F1 Micro: 0.8415, F1 Macro: 0.7745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.183, Accuracy: 0.8597, F1 Micro: 0.8597, F1 Macro: 0.8126\n",
      "Epoch 7/10, Train Loss: 0.1868, Accuracy: 0.8552, F1 Micro: 0.8552, F1 Macro: 0.8071\n",
      "Epoch 8/10, Train Loss: 0.1362, Accuracy: 0.8518, F1 Micro: 0.8518, F1 Macro: 0.7991\n",
      "Epoch 9/10, Train Loss: 0.1055, Accuracy: 0.8586, F1 Micro: 0.8586, F1 Macro: 0.8072\n",
      "Epoch 10/10, Train Loss: 0.0788, Accuracy: 0.8586, F1 Micro: 0.8586, F1 Macro: 0.8072\n",
      "\n",
      "Sentiment analysis accuracy: 0.8597, F1 Micro: 0.8597, F1 Macro: 0.8126\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.96      0.91       622\n",
      "    positive       0.86      0.62      0.72       255\n",
      "\n",
      "    accuracy                           0.86       877\n",
      "   macro avg       0.86      0.79      0.81       877\n",
      "weighted avg       0.86      0.86      0.85       877\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 357: Accuracy: 0.91, F1 Micro: 0.91, F1 Macro: 0.6243\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        97\n",
      "     neutral       0.96      0.99      0.98       459\n",
      "    positive       1.00      0.20      0.33        15\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.68      0.73       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.62      0.73        86\n",
      "     neutral       0.93      0.99      0.96       475\n",
      "    positive       0.25      0.10      0.14        10\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.69      0.57      0.61       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.55      0.68        78\n",
      "     neutral       0.93      0.99      0.96       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.60      0.51      0.54       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.89      0.98      0.94       496\n",
      "    positive       0.67      0.24      0.35        68\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.52      0.41      0.43       571\n",
      "weighted avg       0.85      0.88      0.85       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.77      0.80       200\n",
      "     neutral       0.87      0.87      0.87       315\n",
      "    positive       0.63      0.80      0.71        56\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.78      0.81      0.79       571\n",
      "weighted avg       0.83      0.83      0.83       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.55      0.68       162\n",
      "     neutral       0.80      0.98      0.88       387\n",
      "    positive       0.67      0.09      0.16        22\n",
      "\n",
      "    accuracy                           0.82       571\n",
      "   macro avg       0.79      0.54      0.58       571\n",
      "weighted avg       0.83      0.82      0.80       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.75      0.74        85\n",
      "     neutral       0.95      0.95      0.95       418\n",
      "    positive       0.76      0.76      0.76        68\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.82      0.82      0.82       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.03      0.07        29\n",
      "     neutral       0.93      1.00      0.97       525\n",
      "    positive       0.67      0.35      0.46        17\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.87      0.46      0.50       571\n",
      "weighted avg       0.93      0.93      0.90       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.83      0.86        54\n",
      "     neutral       0.98      1.00      0.99       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.62      0.61      0.61       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.89      0.91        74\n",
      "     neutral       0.98      1.00      0.99       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.64      0.63      0.63       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Total train time: 108.21511554718018 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 193\n",
      "Sampling duration: 60.62181353569031 seconds\n",
      "New train size: 550\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5144, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4619, Accuracy: 0.8054, F1 Micro: 0.8916, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4165, Accuracy: 0.8505, F1 Micro: 0.9136, F1 Macro: 0.9094\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3614, Accuracy: 0.8783, F1 Micro: 0.9287, F1 Macro: 0.9251\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3037, Accuracy: 0.9101, F1 Micro: 0.946, F1 Macro: 0.942\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2491, Accuracy: 0.9262, F1 Micro: 0.9551, F1 Macro: 0.9516\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2059, Accuracy: 0.9326, F1 Micro: 0.959, F1 Macro: 0.956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1802, Accuracy: 0.9358, F1 Micro: 0.9608, F1 Macro: 0.9575\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1584, Accuracy: 0.9417, F1 Micro: 0.9642, F1 Macro: 0.9613\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1359, Accuracy: 0.9436, F1 Micro: 0.9653, F1 Macro: 0.9618\n",
      "\n",
      "Aspect detection accuracy: 0.9436, F1 Micro: 0.9653, F1 Macro: 0.9618\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.92      0.98      0.95       500\n",
      "  kebersihan       0.87      0.92      0.89       317\n",
      "       linen       0.85      0.97      0.91       392\n",
      "     service       0.97      0.95      0.96       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      4614\n",
      "   macro avg       0.95      0.98      0.96      4614\n",
      "weighted avg       0.95      0.98      0.97      4614\n",
      " samples avg       0.95      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5314, Accuracy: 0.7948, F1 Micro: 0.7948, F1 Macro: 0.6894\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3835, Accuracy: 0.7948, F1 Micro: 0.7948, F1 Macro: 0.6593\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2712, Accuracy: 0.8398, F1 Micro: 0.8398, F1 Macro: 0.7849\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.224, Accuracy: 0.8438, F1 Micro: 0.8438, F1 Macro: 0.7741\n",
      "Epoch 5/10, Train Loss: 0.223, Accuracy: 0.8418, F1 Micro: 0.8418, F1 Macro: 0.7705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1624, Accuracy: 0.8609, F1 Micro: 0.8609, F1 Macro: 0.804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.092, Accuracy: 0.8789, F1 Micro: 0.8789, F1 Macro: 0.8409\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0846, Accuracy: 0.8789, F1 Micro: 0.8789, F1 Macro: 0.8339\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0768, Accuracy: 0.8839, F1 Micro: 0.8839, F1 Macro: 0.8514\n",
      "Epoch 10/10, Train Loss: 0.0518, Accuracy: 0.8809, F1 Micro: 0.8809, F1 Macro: 0.8451\n",
      "\n",
      "Sentiment analysis accuracy: 0.8839, F1 Micro: 0.8839, F1 Macro: 0.8514\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.95      0.92       712\n",
      "    positive       0.85      0.72      0.78       287\n",
      "\n",
      "    accuracy                           0.88       999\n",
      "   macro avg       0.87      0.84      0.85       999\n",
      "weighted avg       0.88      0.88      0.88       999\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 550: Accuracy: 0.9345, F1 Micro: 0.9345, F1 Macro: 0.7751\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.89      0.92        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.71      1.00      0.83        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.96      0.92       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.84      0.87        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.81      0.77      0.79       571\n",
      "weighted avg       0.95      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.73      0.78        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.57      0.58       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.92      0.98      0.95       496\n",
      "    positive       0.76      0.47      0.58        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.56      0.48      0.51       571\n",
      "weighted avg       0.89      0.91      0.89       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.83       200\n",
      "     neutral       0.87      0.92      0.89       315\n",
      "    positive       0.82      0.75      0.79        56\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.85      0.82      0.84       571\n",
      "weighted avg       0.86      0.86      0.86       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.66      0.76       162\n",
      "     neutral       0.85      0.97      0.91       387\n",
      "    positive       0.40      0.18      0.25        22\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.71      0.60      0.64       571\n",
      "weighted avg       0.85      0.85      0.84       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.78      0.81        85\n",
      "     neutral       0.97      0.95      0.96       418\n",
      "    positive       0.75      0.91      0.82        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.85      0.88      0.86       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.31      0.45        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.71      0.74       571\n",
      "weighted avg       0.95      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.91      0.92        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.71      0.83      0.77         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.91      0.89       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.97      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 142.62016105651855 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 174\n",
      "Sampling duration: 58.0077543258667 seconds\n",
      "New train size: 724\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5019, Accuracy: 0.8017, F1 Micro: 0.8898, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4383, Accuracy: 0.8318, F1 Micro: 0.9047, F1 Macro: 0.9004\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3783, Accuracy: 0.87, F1 Micro: 0.924, F1 Macro: 0.9203\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2969, Accuracy: 0.9141, F1 Micro: 0.9484, F1 Macro: 0.9455\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2415, Accuracy: 0.9262, F1 Micro: 0.9554, F1 Macro: 0.9521\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2007, Accuracy: 0.933, F1 Micro: 0.9593, F1 Macro: 0.9562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1738, Accuracy: 0.9399, F1 Micro: 0.9633, F1 Macro: 0.9602\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1524, Accuracy: 0.9424, F1 Micro: 0.9647, F1 Macro: 0.9616\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.14, Accuracy: 0.9497, F1 Micro: 0.9689, F1 Macro: 0.9655\n",
      "Epoch 10/10, Train Loss: 0.119, Accuracy: 0.9483, F1 Micro: 0.9682, F1 Macro: 0.965\n",
      "\n",
      "Aspect detection accuracy: 0.9497, F1 Micro: 0.9689, F1 Macro: 0.9655\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.88      0.91      0.90       317\n",
      "       linen       0.90      0.95      0.93       392\n",
      "     service       0.95      0.97      0.96       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.95      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5262, Accuracy: 0.8177, F1 Micro: 0.8177, F1 Macro: 0.7764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3188, Accuracy: 0.8322, F1 Micro: 0.8322, F1 Macro: 0.7662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2651, Accuracy: 0.8602, F1 Micro: 0.8602, F1 Macro: 0.8236\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.24, Accuracy: 0.8785, F1 Micro: 0.8785, F1 Macro: 0.8415\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1872, Accuracy: 0.8901, F1 Micro: 0.8901, F1 Macro: 0.8569\n",
      "Epoch 6/10, Train Loss: 0.1025, Accuracy: 0.8804, F1 Micro: 0.8804, F1 Macro: 0.8425\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0837, Accuracy: 0.893, F1 Micro: 0.893, F1 Macro: 0.8619\n",
      "Epoch 8/10, Train Loss: 0.0619, Accuracy: 0.8862, F1 Micro: 0.8862, F1 Macro: 0.8563\n",
      "Epoch 9/10, Train Loss: 0.0571, Accuracy: 0.8881, F1 Micro: 0.8881, F1 Macro: 0.8526\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0509, Accuracy: 0.8949, F1 Micro: 0.8949, F1 Macro: 0.8634\n",
      "\n",
      "Sentiment analysis accuracy: 0.8949, F1 Micro: 0.8949, F1 Macro: 0.8634\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93       730\n",
      "    positive       0.93      0.70      0.80       307\n",
      "\n",
      "    accuracy                           0.89      1037\n",
      "   macro avg       0.91      0.84      0.86      1037\n",
      "weighted avg       0.90      0.89      0.89      1037\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 724: Accuracy: 0.9434, F1 Micro: 0.9434, F1 Macro: 0.7976\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.83      0.87        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.81      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.79      0.81        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.60      0.59      0.59       571\n",
      "weighted avg       0.94      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.79      0.62      0.69        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.58      0.53      0.55       571\n",
      "weighted avg       0.91      0.92      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.85       200\n",
      "     neutral       0.89      0.91      0.90       315\n",
      "    positive       0.89      0.84      0.86        56\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.88      0.86      0.87       571\n",
      "weighted avg       0.88      0.88      0.88       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.79      0.81       162\n",
      "     neutral       0.90      0.95      0.92       387\n",
      "    positive       0.71      0.23      0.34        22\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.82      0.66      0.69       571\n",
      "weighted avg       0.87      0.88      0.87       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.79      0.83        85\n",
      "     neutral       0.95      0.97      0.96       418\n",
      "    positive       0.89      0.87      0.88        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.88      0.89       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.31      0.46        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.87      0.73      0.75       571\n",
      "weighted avg       0.96      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.92      0.94        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.98      0.86      0.91       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 157.86020040512085 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 156\n",
      "Sampling duration: 54.46924614906311 seconds\n",
      "New train size: 880\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4985, Accuracy: 0.8156, F1 Micro: 0.8947, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4297, Accuracy: 0.8444, F1 Micro: 0.9093, F1 Macro: 0.901\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3476, Accuracy: 0.896, F1 Micro: 0.9383, F1 Macro: 0.9354\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2746, Accuracy: 0.9222, F1 Micro: 0.953, F1 Macro: 0.9494\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2246, Accuracy: 0.9398, F1 Micro: 0.9632, F1 Macro: 0.9599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1877, Accuracy: 0.9422, F1 Micro: 0.9646, F1 Macro: 0.9615\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1586, Accuracy: 0.9467, F1 Micro: 0.9673, F1 Macro: 0.9642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1368, Accuracy: 0.9479, F1 Micro: 0.9681, F1 Macro: 0.965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.118, Accuracy: 0.9524, F1 Micro: 0.9706, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1039, Accuracy: 0.9526, F1 Micro: 0.9707, F1 Macro: 0.9673\n",
      "\n",
      "Aspect detection accuracy: 0.9526, F1 Micro: 0.9707, F1 Macro: 0.9673\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.96      1.00      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.93      0.98      0.96       500\n",
      "  kebersihan       0.92      0.88      0.90       317\n",
      "       linen       0.89      0.97      0.93       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.99       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5026, Accuracy: 0.83, F1 Micro: 0.83, F1 Macro: 0.785\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3006, Accuracy: 0.852, F1 Micro: 0.852, F1 Macro: 0.8068\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2296, Accuracy: 0.8672, F1 Micro: 0.8672, F1 Macro: 0.8201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1765, Accuracy: 0.8739, F1 Micro: 0.8739, F1 Macro: 0.8298\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1246, Accuracy: 0.8892, F1 Micro: 0.8892, F1 Macro: 0.8549\n",
      "Epoch 6/10, Train Loss: 0.0977, Accuracy: 0.873, F1 Micro: 0.873, F1 Macro: 0.8269\n",
      "Epoch 7/10, Train Loss: 0.0976, Accuracy: 0.8883, F1 Micro: 0.8883, F1 Macro: 0.8517\n",
      "Epoch 8/10, Train Loss: 0.0535, Accuracy: 0.8797, F1 Micro: 0.8797, F1 Macro: 0.8371\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0469, Accuracy: 0.8902, F1 Micro: 0.8902, F1 Macro: 0.86\n",
      "Epoch 10/10, Train Loss: 0.0239, Accuracy: 0.8892, F1 Micro: 0.8892, F1 Macro: 0.8535\n",
      "\n",
      "Sentiment analysis accuracy: 0.8902, F1 Micro: 0.8902, F1 Macro: 0.86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.92       738\n",
      "    positive       0.88      0.72      0.80       309\n",
      "\n",
      "    accuracy                           0.89      1047\n",
      "   macro avg       0.89      0.84      0.86      1047\n",
      "weighted avg       0.89      0.89      0.89      1047\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 880: Accuracy: 0.9448, F1 Micro: 0.9448, F1 Macro: 0.8153\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.79      1.00      0.88        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.92      0.97      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.79      0.87        86\n",
      "     neutral       0.96      1.00      0.98       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.76      0.80       571\n",
      "weighted avg       0.96      0.96      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.76      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.98      0.96       496\n",
      "    positive       0.83      0.57      0.68        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.59      0.52      0.55       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.88      0.85       200\n",
      "     neutral       0.92      0.88      0.90       315\n",
      "    positive       0.85      0.93      0.89        56\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.87      0.89      0.88       571\n",
      "weighted avg       0.88      0.88      0.88       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.73      0.80       162\n",
      "     neutral       0.89      0.97      0.93       387\n",
      "    positive       0.61      0.50      0.55        22\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.80      0.73      0.76       571\n",
      "weighted avg       0.88      0.88      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.85      0.84        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.88      0.90        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.90      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.45      0.59        29\n",
      "     neutral       0.97      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.87      0.76      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.83      0.89        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       0.60      1.00      0.75         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.85      0.94      0.88       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.96      0.96        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.50      0.67      0.57         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.82      0.87      0.84       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 174.78934907913208 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 141\n",
      "Sampling duration: 49.868470907211304 seconds\n",
      "New train size: 1021\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4993, Accuracy: 0.8123, F1 Micro: 0.8949, F1 Macro: 0.8901\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4174, Accuracy: 0.8646, F1 Micro: 0.9211, F1 Macro: 0.9169\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3155, Accuracy: 0.9181, F1 Micro: 0.9506, F1 Macro: 0.9472\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2413, Accuracy: 0.9349, F1 Micro: 0.9603, F1 Macro: 0.9574\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2049, Accuracy: 0.9385, F1 Micro: 0.9626, F1 Macro: 0.9599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1703, Accuracy: 0.947, F1 Micro: 0.9675, F1 Macro: 0.9645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1459, Accuracy: 0.954, F1 Micro: 0.9716, F1 Macro: 0.9687\n",
      "Epoch 8/10, Train Loss: 0.1283, Accuracy: 0.9538, F1 Micro: 0.9715, F1 Macro: 0.9682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1108, Accuracy: 0.9542, F1 Micro: 0.9717, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0959, Accuracy: 0.9559, F1 Micro: 0.9728, F1 Macro: 0.9698\n",
      "\n",
      "Aspect detection accuracy: 0.9559, F1 Micro: 0.9728, F1 Macro: 0.9698\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.96      0.97      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.89      0.93      0.91       317\n",
      "       linen       0.90      0.98      0.94       392\n",
      "     service       0.96      0.97      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.459, Accuracy: 0.8465, F1 Micro: 0.8465, F1 Macro: 0.7789\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3145, Accuracy: 0.8591, F1 Micro: 0.8591, F1 Macro: 0.8256\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2478, Accuracy: 0.8958, F1 Micro: 0.8958, F1 Macro: 0.8617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1736, Accuracy: 0.8986, F1 Micro: 0.8986, F1 Macro: 0.8684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1267, Accuracy: 0.9035, F1 Micro: 0.9035, F1 Macro: 0.8713\n",
      "Epoch 6/10, Train Loss: 0.0772, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8658\n",
      "Epoch 7/10, Train Loss: 0.0695, Accuracy: 0.9025, F1 Micro: 0.9025, F1 Macro: 0.8715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0514, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8872\n",
      "Epoch 9/10, Train Loss: 0.0455, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8812\n",
      "Epoch 10/10, Train Loss: 0.0347, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8806\n",
      "\n",
      "Sentiment analysis accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8872\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       737\n",
      "    positive       0.92      0.77      0.83       299\n",
      "\n",
      "    accuracy                           0.91      1036\n",
      "   macro avg       0.91      0.87      0.89      1036\n",
      "weighted avg       0.91      0.91      0.91      1036\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1021: Accuracy: 0.9497, F1 Micro: 0.9497, F1 Macro: 0.8165\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.87      0.90        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.60      0.60      0.60        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.82      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.78      0.80        78\n",
      "     neutral       0.96      0.97      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.59      0.59       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.87      0.66      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.55      0.57       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.81      0.85       200\n",
      "     neutral       0.89      0.93      0.91       315\n",
      "    positive       0.82      0.89      0.85        56\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.87      0.88      0.87       571\n",
      "weighted avg       0.88      0.88      0.88       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.76      0.83       162\n",
      "     neutral       0.90      0.98      0.94       387\n",
      "    positive       0.73      0.50      0.59        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.85      0.75      0.79       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.82      0.84        85\n",
      "     neutral       0.96      0.97      0.97       418\n",
      "    positive       0.93      0.91      0.92        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.90      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.41      0.57        29\n",
      "     neutral       0.97      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.88      0.76      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 191.14831829071045 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 127\n",
      "Sampling duration: 45.161128520965576 seconds\n",
      "New train size: 1148\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4933, Accuracy: 0.8076, F1 Micro: 0.8927, F1 Macro: 0.8881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.397, Accuracy: 0.8821, F1 Micro: 0.9305, F1 Macro: 0.9268\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3, Accuracy: 0.9259, F1 Micro: 0.9552, F1 Macro: 0.9525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2278, Accuracy: 0.9453, F1 Micro: 0.9665, F1 Macro: 0.9638\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1822, Accuracy: 0.9472, F1 Micro: 0.9677, F1 Macro: 0.965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1532, Accuracy: 0.9486, F1 Micro: 0.9686, F1 Macro: 0.9654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1364, Accuracy: 0.9571, F1 Micro: 0.9734, F1 Macro: 0.9703\n",
      "Epoch 8/10, Train Loss: 0.1197, Accuracy: 0.955, F1 Micro: 0.9723, F1 Macro: 0.9692\n",
      "Epoch 9/10, Train Loss: 0.1006, Accuracy: 0.9521, F1 Micro: 0.9705, F1 Macro: 0.9676\n",
      "Epoch 10/10, Train Loss: 0.0851, Accuracy: 0.9569, F1 Micro: 0.9733, F1 Macro: 0.9704\n",
      "\n",
      "Aspect detection accuracy: 0.9571, F1 Micro: 0.9734, F1 Macro: 0.9703\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.93      0.89      0.91       317\n",
      "       linen       0.89      0.97      0.93       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4797, Accuracy: 0.8347, F1 Micro: 0.8347, F1 Macro: 0.7701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3116, Accuracy: 0.8627, F1 Micro: 0.8627, F1 Macro: 0.8187\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2433, Accuracy: 0.8861, F1 Micro: 0.8861, F1 Macro: 0.8532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1691, Accuracy: 0.8926, F1 Micro: 0.8926, F1 Macro: 0.8624\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1308, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0874, Accuracy: 0.9029, F1 Micro: 0.9029, F1 Macro: 0.8748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0673, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.875\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.066, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8781\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0534, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8805\n",
      "Epoch 10/10, Train Loss: 0.0298, Accuracy: 0.901, F1 Micro: 0.901, F1 Macro: 0.8727\n",
      "\n",
      "Sentiment analysis accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       754\n",
      "    positive       0.95      0.73      0.82       317\n",
      "\n",
      "    accuracy                           0.91      1071\n",
      "   macro avg       0.92      0.86      0.88      1071\n",
      "weighted avg       0.91      0.91      0.90      1071\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1148: Accuracy: 0.952, F1 Micro: 0.952, F1 Macro: 0.8516\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.84      0.88        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.81      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.76      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.83      0.66      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.55      0.57       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.89      0.86       200\n",
      "     neutral       0.93      0.89      0.91       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.89      0.91      0.90       571\n",
      "weighted avg       0.90      0.89      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.77      0.83       162\n",
      "     neutral       0.89      0.97      0.93       387\n",
      "    positive       0.73      0.36      0.48        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.84      0.70      0.75       571\n",
      "weighted avg       0.89      0.89      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.91      0.87        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 205.4608976840973 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 114\n",
      "Sampling duration: 39.32907319068909 seconds\n",
      "New train size: 1262\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4829, Accuracy: 0.8217, F1 Micro: 0.8996, F1 Macro: 0.895\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3823, Accuracy: 0.8905, F1 Micro: 0.9353, F1 Macro: 0.9318\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2724, Accuracy: 0.9304, F1 Micro: 0.9579, F1 Macro: 0.9554\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2046, Accuracy: 0.9488, F1 Micro: 0.9686, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1716, Accuracy: 0.9498, F1 Micro: 0.9693, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1404, Accuracy: 0.9563, F1 Micro: 0.9729, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1236, Accuracy: 0.958, F1 Micro: 0.974, F1 Macro: 0.9709\n",
      "Epoch 8/10, Train Loss: 0.1052, Accuracy: 0.9569, F1 Micro: 0.9734, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0892, Accuracy: 0.9613, F1 Micro: 0.9759, F1 Macro: 0.9731\n",
      "Epoch 10/10, Train Loss: 0.0771, Accuracy: 0.9609, F1 Micro: 0.9757, F1 Macro: 0.9727\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.9759, F1 Macro: 0.9731\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.96      0.88      0.92       317\n",
      "       linen       0.91      0.98      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4413, Accuracy: 0.8465, F1 Micro: 0.8465, F1 Macro: 0.7993\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2902, Accuracy: 0.8674, F1 Micro: 0.8674, F1 Macro: 0.8288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2153, Accuracy: 0.8801, F1 Micro: 0.8801, F1 Macro: 0.8423\n",
      "Epoch 4/10, Train Loss: 0.1561, Accuracy: 0.8774, F1 Micro: 0.8774, F1 Macro: 0.837\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1019, Accuracy: 0.8955, F1 Micro: 0.8955, F1 Macro: 0.8673\n",
      "Epoch 6/10, Train Loss: 0.0768, Accuracy: 0.891, F1 Micro: 0.891, F1 Macro: 0.8617\n",
      "Epoch 7/10, Train Loss: 0.0774, Accuracy: 0.8928, F1 Micro: 0.8928, F1 Macro: 0.8637\n",
      "Epoch 8/10, Train Loss: 0.0589, Accuracy: 0.8874, F1 Micro: 0.8874, F1 Macro: 0.8529\n",
      "Epoch 9/10, Train Loss: 0.035, Accuracy: 0.8919, F1 Micro: 0.8919, F1 Macro: 0.8596\n",
      "Epoch 10/10, Train Loss: 0.0341, Accuracy: 0.8892, F1 Micro: 0.8892, F1 Macro: 0.8578\n",
      "\n",
      "Sentiment analysis accuracy: 0.8955, F1 Micro: 0.8955, F1 Macro: 0.8673\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93       770\n",
      "    positive       0.91      0.72      0.81       331\n",
      "\n",
      "    accuracy                           0.90      1101\n",
      "   macro avg       0.90      0.85      0.87      1101\n",
      "weighted avg       0.90      0.90      0.89      1101\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1262: Accuracy: 0.9539, F1 Micro: 0.9539, F1 Macro: 0.8494\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.82      0.84       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.81      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.61      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.92      0.88       200\n",
      "     neutral       0.96      0.88      0.92       315\n",
      "    positive       0.83      0.96      0.89        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.88      0.92      0.90       571\n",
      "weighted avg       0.91      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.80      0.84       162\n",
      "     neutral       0.91      0.98      0.94       387\n",
      "    positive       0.80      0.36      0.50        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.87      0.71      0.76       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.80      0.84        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.92      0.97      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.48      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.67      0.94      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.81      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.99      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.88      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 216.05332589149475 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 103\n",
      "Sampling duration: 37.11384916305542 seconds\n",
      "New train size: 1365\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4917, Accuracy: 0.8373, F1 Micro: 0.9071, F1 Macro: 0.9025\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3694, Accuracy: 0.905, F1 Micro: 0.9433, F1 Macro: 0.9398\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2574, Accuracy: 0.934, F1 Micro: 0.9598, F1 Macro: 0.9572\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2009, Accuracy: 0.9474, F1 Micro: 0.9678, F1 Macro: 0.9653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1676, Accuracy: 0.9497, F1 Micro: 0.9691, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1368, Accuracy: 0.9594, F1 Micro: 0.9749, F1 Macro: 0.972\n",
      "Epoch 7/10, Train Loss: 0.1198, Accuracy: 0.9569, F1 Micro: 0.9735, F1 Macro: 0.9707\n",
      "Epoch 8/10, Train Loss: 0.1013, Accuracy: 0.9568, F1 Micro: 0.9733, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0832, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9731\n",
      "Epoch 10/10, Train Loss: 0.0758, Accuracy: 0.9601, F1 Micro: 0.9752, F1 Macro: 0.9726\n",
      "\n",
      "Aspect detection accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9731\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.93      0.92      0.92       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4282, Accuracy: 0.8383, F1 Micro: 0.8383, F1 Macro: 0.772\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2829, Accuracy: 0.8776, F1 Micro: 0.8776, F1 Macro: 0.8403\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2151, Accuracy: 0.8888, F1 Micro: 0.8888, F1 Macro: 0.8539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1373, Accuracy: 0.8972, F1 Micro: 0.8972, F1 Macro: 0.866\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.107, Accuracy: 0.9037, F1 Micro: 0.9037, F1 Macro: 0.8762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0753, Accuracy: 0.9047, F1 Micro: 0.9047, F1 Macro: 0.8778\n",
      "Epoch 7/10, Train Loss: 0.068, Accuracy: 0.8953, F1 Micro: 0.8953, F1 Macro: 0.8684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0476, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8799\n",
      "Epoch 9/10, Train Loss: 0.033, Accuracy: 0.8972, F1 Micro: 0.8972, F1 Macro: 0.8657\n",
      "Epoch 10/10, Train Loss: 0.0447, Accuracy: 0.9047, F1 Micro: 0.9047, F1 Macro: 0.8786\n",
      "\n",
      "Sentiment analysis accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       755\n",
      "    positive       0.93      0.74      0.82       315\n",
      "\n",
      "    accuracy                           0.91      1070\n",
      "   macro avg       0.91      0.86      0.88      1070\n",
      "weighted avg       0.91      0.91      0.90      1070\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1365: Accuracy: 0.9546, F1 Micro: 0.9546, F1 Macro: 0.861\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.85      0.90        86\n",
      "     neutral       0.97      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.78      0.82       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.79      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.89      0.69      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.56      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88       200\n",
      "     neutral       0.93      0.92      0.92       315\n",
      "    positive       0.90      0.96      0.93        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.82      0.85       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.73      0.78       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.81      0.84        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.94      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.80      0.94      0.86        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.82      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.96      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 226.0545039176941 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 62\n",
      "Sampling duration: 33.440362215042114 seconds\n",
      "New train size: 1427\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4882, Accuracy: 0.8358, F1 Micro: 0.9058, F1 Macro: 0.9002\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3571, Accuracy: 0.9123, F1 Micro: 0.9474, F1 Macro: 0.9443\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2453, Accuracy: 0.9378, F1 Micro: 0.9621, F1 Macro: 0.9596\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1974, Accuracy: 0.947, F1 Micro: 0.9675, F1 Macro: 0.9649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.169, Accuracy: 0.9521, F1 Micro: 0.9705, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1356, Accuracy: 0.9549, F1 Micro: 0.9722, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1162, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9745\n",
      "Epoch 8/10, Train Loss: 0.1038, Accuracy: 0.9563, F1 Micro: 0.973, F1 Macro: 0.9704\n",
      "Epoch 9/10, Train Loss: 0.0868, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9733\n",
      "Epoch 10/10, Train Loss: 0.0747, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9732\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.92      0.93      0.93       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4266, Accuracy: 0.8574, F1 Micro: 0.8574, F1 Macro: 0.8144\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2543, Accuracy: 0.8861, F1 Micro: 0.8861, F1 Macro: 0.8573\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1773, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8768\n",
      "Epoch 4/10, Train Loss: 0.1297, Accuracy: 0.8991, F1 Micro: 0.8991, F1 Macro: 0.8697\n",
      "Epoch 5/10, Train Loss: 0.1, Accuracy: 0.8972, F1 Micro: 0.8972, F1 Macro: 0.867\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0749, Accuracy: 0.9056, F1 Micro: 0.9056, F1 Macro: 0.8785\n",
      "Epoch 7/10, Train Loss: 0.0595, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.8747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0423, Accuracy: 0.9056, F1 Micro: 0.9056, F1 Macro: 0.8787\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0388, Accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.8816\n",
      "Epoch 10/10, Train Loss: 0.0264, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.8774\n",
      "\n",
      "Sentiment analysis accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.8816\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.94       762\n",
      "    positive       0.92      0.75      0.83       318\n",
      "\n",
      "    accuracy                           0.91      1080\n",
      "   macro avg       0.91      0.86      0.88      1080\n",
      "weighted avg       0.91      0.91      0.90      1080\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1427: Accuracy: 0.9562, F1 Micro: 0.9562, F1 Macro: 0.875\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.84      0.88        86\n",
      "     neutral       0.97      1.00      0.98       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.87      0.78      0.82       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.79      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.77      0.62      0.66       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87       200\n",
      "     neutral       0.92      0.93      0.93       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.85       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.80      0.36      0.50        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.72      0.76       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.84      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.92      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.80      0.94      0.86        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.83      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 231.03837418556213 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 86\n",
      "Sampling duration: 31.675100326538086 seconds\n",
      "New train size: 1513\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4775, Accuracy: 0.8377, F1 Micro: 0.9065, F1 Macro: 0.9005\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3389, Accuracy: 0.9186, F1 Micro: 0.951, F1 Macro: 0.9481\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2385, Accuracy: 0.9394, F1 Micro: 0.963, F1 Macro: 0.9608\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1894, Accuracy: 0.951, F1 Micro: 0.9699, F1 Macro: 0.9676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.155, Accuracy: 0.9543, F1 Micro: 0.9719, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1329, Accuracy: 0.9559, F1 Micro: 0.9728, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1134, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0936, Accuracy: 0.9611, F1 Micro: 0.9758, F1 Macro: 0.9731\n",
      "Epoch 9/10, Train Loss: 0.0806, Accuracy: 0.9597, F1 Micro: 0.975, F1 Macro: 0.9722\n",
      "Epoch 10/10, Train Loss: 0.0681, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9729\n",
      "\n",
      "Aspect detection accuracy: 0.9611, F1 Micro: 0.9758, F1 Macro: 0.9731\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.94      0.91      0.92       317\n",
      "       linen       0.92      0.95      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4229, Accuracy: 0.8501, F1 Micro: 0.8501, F1 Macro: 0.8037\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2571, Accuracy: 0.8839, F1 Micro: 0.8839, F1 Macro: 0.8543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.21, Accuracy: 0.8876, F1 Micro: 0.8876, F1 Macro: 0.8614\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1414, Accuracy: 0.8921, F1 Micro: 0.8921, F1 Macro: 0.86\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0912, Accuracy: 0.8967, F1 Micro: 0.8967, F1 Macro: 0.867\n",
      "Epoch 6/10, Train Loss: 0.0736, Accuracy: 0.8867, F1 Micro: 0.8867, F1 Macro: 0.8494\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0769, Accuracy: 0.8976, F1 Micro: 0.8976, F1 Macro: 0.8695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.056, Accuracy: 0.8995, F1 Micro: 0.8995, F1 Macro: 0.8701\n",
      "Epoch 9/10, Train Loss: 0.031, Accuracy: 0.8985, F1 Micro: 0.8985, F1 Macro: 0.8708\n",
      "Epoch 10/10, Train Loss: 0.0319, Accuracy: 0.8967, F1 Micro: 0.8967, F1 Macro: 0.8652\n",
      "\n",
      "Sentiment analysis accuracy: 0.8995, F1 Micro: 0.8995, F1 Macro: 0.8701\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93       769\n",
      "    positive       0.93      0.71      0.81       325\n",
      "\n",
      "    accuracy                           0.90      1094\n",
      "   macro avg       0.91      0.85      0.87      1094\n",
      "weighted avg       0.90      0.90      0.90      1094\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1513: Accuracy: 0.9543, F1 Micro: 0.9543, F1 Macro: 0.8552\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.76      0.80        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       0.50      1.00      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.77      0.91      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.85      0.66      0.74        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.60      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.89      0.88       200\n",
      "     neutral       0.94      0.91      0.92       315\n",
      "    positive       0.86      0.96      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.81      0.82       162\n",
      "     neutral       0.92      0.95      0.94       387\n",
      "    positive       0.73      0.36      0.48        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.82      0.71      0.75       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.87      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.83      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.99      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.88      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 246.9368212223053 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 77\n",
      "Sampling duration: 28.712496519088745 seconds\n",
      "New train size: 1590\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4727, Accuracy: 0.8474, F1 Micro: 0.9121, F1 Macro: 0.9082\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3278, Accuracy: 0.9219, F1 Micro: 0.953, F1 Macro: 0.9509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2368, Accuracy: 0.9425, F1 Micro: 0.9648, F1 Macro: 0.9622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1841, Accuracy: 0.9503, F1 Micro: 0.9695, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1552, Accuracy: 0.9512, F1 Micro: 0.97, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1296, Accuracy: 0.9569, F1 Micro: 0.9734, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1062, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0908, Accuracy: 0.9618, F1 Micro: 0.9762, F1 Macro: 0.973\n",
      "Epoch 9/10, Train Loss: 0.08, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9731\n",
      "Epoch 10/10, Train Loss: 0.0665, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9738\n",
      "\n",
      "Aspect detection accuracy: 0.9618, F1 Micro: 0.9762, F1 Macro: 0.973\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.87      0.91       317\n",
      "       linen       0.92      0.98      0.95       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.97      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4074, Accuracy: 0.8555, F1 Micro: 0.8555, F1 Macro: 0.8146\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2669, Accuracy: 0.8761, F1 Micro: 0.8761, F1 Macro: 0.8409\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.187, Accuracy: 0.8851, F1 Micro: 0.8851, F1 Macro: 0.8518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1411, Accuracy: 0.895, F1 Micro: 0.895, F1 Macro: 0.8659\n",
      "Epoch 5/10, Train Loss: 0.1046, Accuracy: 0.8932, F1 Micro: 0.8932, F1 Macro: 0.8633\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0783, Accuracy: 0.8995, F1 Micro: 0.8995, F1 Macro: 0.8712\n",
      "Epoch 7/10, Train Loss: 0.0523, Accuracy: 0.8977, F1 Micro: 0.8977, F1 Macro: 0.8705\n",
      "Epoch 8/10, Train Loss: 0.0468, Accuracy: 0.8977, F1 Micro: 0.8977, F1 Macro: 0.8689\n",
      "Epoch 9/10, Train Loss: 0.0383, Accuracy: 0.8932, F1 Micro: 0.8932, F1 Macro: 0.8664\n",
      "Epoch 10/10, Train Loss: 0.0323, Accuracy: 0.8896, F1 Micro: 0.8896, F1 Macro: 0.8558\n",
      "\n",
      "Sentiment analysis accuracy: 0.8995, F1 Micro: 0.8995, F1 Macro: 0.8712\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93       776\n",
      "    positive       0.94      0.71      0.81       338\n",
      "\n",
      "    accuracy                           0.90      1114\n",
      "   macro avg       0.92      0.85      0.87      1114\n",
      "weighted avg       0.90      0.90      0.89      1114\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1590: Accuracy: 0.9559, F1 Micro: 0.9559, F1 Macro: 0.8723\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.81      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.75      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.62      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.91      0.87       200\n",
      "     neutral       0.95      0.87      0.91       315\n",
      "    positive       0.85      0.95      0.90        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.88      0.91      0.89       571\n",
      "weighted avg       0.90      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.81      0.85       162\n",
      "     neutral       0.92      0.98      0.94       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.73      0.79       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.88      0.86        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.94      0.96      0.95        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.52      0.64        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.80      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 253.28346514701843 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 70\n",
      "Sampling duration: 25.99895668029785 seconds\n",
      "New train size: 1660\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.471, Accuracy: 0.8538, F1 Micro: 0.9157, F1 Macro: 0.9119\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3256, Accuracy: 0.9274, F1 Micro: 0.9561, F1 Macro: 0.9536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.223, Accuracy: 0.9396, F1 Micro: 0.9632, F1 Macro: 0.961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1808, Accuracy: 0.9552, F1 Micro: 0.9724, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1519, Accuracy: 0.9576, F1 Micro: 0.9738, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1262, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1014, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0892, Accuracy: 0.9613, F1 Micro: 0.9761, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0763, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.065, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.974\n",
      "\n",
      "Aspect detection accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.94      0.93       317\n",
      "       linen       0.91      0.97      0.94       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3866, Accuracy: 0.8571, F1 Micro: 0.8571, F1 Macro: 0.8028\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2369, Accuracy: 0.8942, F1 Micro: 0.8942, F1 Macro: 0.8664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1602, Accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1203, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8881\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0906, Accuracy: 0.9156, F1 Micro: 0.9156, F1 Macro: 0.8914\n",
      "Epoch 6/10, Train Loss: 0.0638, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.88\n",
      "Epoch 7/10, Train Loss: 0.0583, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8885\n",
      "Epoch 8/10, Train Loss: 0.0344, Accuracy: 0.9109, F1 Micro: 0.9109, F1 Macro: 0.8834\n",
      "Epoch 9/10, Train Loss: 0.0368, Accuracy: 0.91, F1 Micro: 0.91, F1 Macro: 0.8834\n",
      "Epoch 10/10, Train Loss: 0.0292, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8874\n",
      "\n",
      "Sentiment analysis accuracy: 0.9156, F1 Micro: 0.9156, F1 Macro: 0.8914\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       762\n",
      "    positive       0.94      0.76      0.84       316\n",
      "\n",
      "    accuracy                           0.92      1078\n",
      "   macro avg       0.93      0.87      0.89      1078\n",
      "weighted avg       0.92      0.92      0.91      1078\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1660: Accuracy: 0.9562, F1 Micro: 0.9562, F1 Macro: 0.8762\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.79      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.61      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88       200\n",
      "     neutral       0.93      0.94      0.93       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.80      0.84       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.88      0.74      0.79       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.62      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.77      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.96      0.96        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.93      0.96       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 260.69305515289307 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 52\n",
      "Sampling duration: 23.915183067321777 seconds\n",
      "New train size: 1712\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4607, Accuracy: 0.8509, F1 Micro: 0.9141, F1 Macro: 0.9102\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.312, Accuracy: 0.929, F1 Micro: 0.9568, F1 Macro: 0.9537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2192, Accuracy: 0.9429, F1 Micro: 0.9651, F1 Macro: 0.9629\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1788, Accuracy: 0.9521, F1 Micro: 0.9706, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1424, Accuracy: 0.9568, F1 Micro: 0.9734, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1201, Accuracy: 0.959, F1 Micro: 0.9747, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.098, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9748\n",
      "Epoch 8/10, Train Loss: 0.085, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9734\n",
      "Epoch 9/10, Train Loss: 0.072, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9746\n",
      "Epoch 10/10, Train Loss: 0.0601, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9745\n",
      "\n",
      "Aspect detection accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.98      0.98      0.98       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.92      0.94      0.93       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3705, Accuracy: 0.8657, F1 Micro: 0.8657, F1 Macro: 0.8203\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2497, Accuracy: 0.8991, F1 Micro: 0.8991, F1 Macro: 0.8688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1802, Accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.8808\n",
      "Epoch 4/10, Train Loss: 0.1272, Accuracy: 0.9009, F1 Micro: 0.9009, F1 Macro: 0.869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0874, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8838\n",
      "Epoch 6/10, Train Loss: 0.0865, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8791\n",
      "Epoch 7/10, Train Loss: 0.0641, Accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.8774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0462, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.8861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0323, Accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.8923\n",
      "Epoch 10/10, Train Loss: 0.0218, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.8901\n",
      "\n",
      "Sentiment analysis accuracy: 0.9176, F1 Micro: 0.9176, F1 Macro: 0.8923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       771\n",
      "    positive       0.94      0.76      0.84       309\n",
      "\n",
      "    accuracy                           0.92      1080\n",
      "   macro avg       0.93      0.87      0.89      1080\n",
      "weighted avg       0.92      0.92      0.91      1080\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1712: Accuracy: 0.9578, F1 Micro: 0.9578, F1 Macro: 0.8655\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.85      0.80      0.83       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.85        78\n",
      "     neutral       0.98      0.98      0.98       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.78      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.85      0.65      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.54      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87       200\n",
      "     neutral       0.92      0.94      0.93       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.91      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.80      0.55      0.65        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.78      0.82       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.84      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 262.59359192848206 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 58\n",
      "Sampling duration: 21.463778734207153 seconds\n",
      "New train size: 1770\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4571, Accuracy: 0.8599, F1 Micro: 0.9189, F1 Macro: 0.9154\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3001, Accuracy: 0.9335, F1 Micro: 0.9596, F1 Macro: 0.9574\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2114, Accuracy: 0.942, F1 Micro: 0.9646, F1 Macro: 0.9623\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1672, Accuracy: 0.9545, F1 Micro: 0.972, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1387, Accuracy: 0.9571, F1 Micro: 0.9736, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1175, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9733\n",
      "Epoch 7/10, Train Loss: 0.0983, Accuracy: 0.9597, F1 Micro: 0.9752, F1 Macro: 0.9729\n",
      "Epoch 8/10, Train Loss: 0.0821, Accuracy: 0.9599, F1 Micro: 0.9752, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0707, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9747\n",
      "Epoch 10/10, Train Loss: 0.061, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9741\n",
      "\n",
      "Aspect detection accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.92      0.98      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3895, Accuracy: 0.8623, F1 Micro: 0.8623, F1 Macro: 0.8077\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.225, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8781\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1598, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1297, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8887\n",
      "Epoch 5/10, Train Loss: 0.0787, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8747\n",
      "Epoch 6/10, Train Loss: 0.0681, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8796\n",
      "Epoch 7/10, Train Loss: 0.0443, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.8878\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.039, Accuracy: 0.9181, F1 Micro: 0.9181, F1 Macro: 0.8917\n",
      "Epoch 9/10, Train Loss: 0.0255, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0307, Accuracy: 0.9191, F1 Micro: 0.9191, F1 Macro: 0.8941\n",
      "\n",
      "Sentiment analysis accuracy: 0.9191, F1 Micro: 0.9191, F1 Macro: 0.8941\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       769\n",
      "    positive       0.94      0.76      0.84       306\n",
      "\n",
      "    accuracy                           0.92      1075\n",
      "   macro avg       0.93      0.87      0.89      1075\n",
      "weighted avg       0.92      0.92      0.92      1075\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1770: Accuracy: 0.9574, F1 Micro: 0.9574, F1 Macro: 0.8694\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      0.92      0.95        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.86      0.60      0.71        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.84      0.88       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.78      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.82      0.62      0.71        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.53      0.55       571\n",
      "weighted avg       0.91      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.90      0.89       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.81      0.85       162\n",
      "     neutral       0.92      0.98      0.94       387\n",
      "    positive       0.89      0.36      0.52        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.72      0.77       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.94      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.82      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 270.69318413734436 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 52\n",
      "Sampling duration: 19.365944147109985 seconds\n",
      "New train size: 1822\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4595, Accuracy: 0.8609, F1 Micro: 0.9193, F1 Macro: 0.9156\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3017, Accuracy: 0.9243, F1 Micro: 0.9539, F1 Macro: 0.95\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.218, Accuracy: 0.945, F1 Micro: 0.9664, F1 Macro: 0.9639\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1767, Accuracy: 0.9542, F1 Micro: 0.9718, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1428, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1166, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9746\n",
      "Epoch 7/10, Train Loss: 0.1004, Accuracy: 0.9602, F1 Micro: 0.9753, F1 Macro: 0.9727\n",
      "Epoch 8/10, Train Loss: 0.0864, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0695, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9748\n",
      "Epoch 10/10, Train Loss: 0.0605, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9743\n",
      "\n",
      "Aspect detection accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9748\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3701, Accuracy: 0.8723, F1 Micro: 0.8723, F1 Macro: 0.8266\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.218, Accuracy: 0.9001, F1 Micro: 0.9001, F1 Macro: 0.8702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1541, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.88\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1059, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8816\n",
      "Epoch 5/10, Train Loss: 0.0886, Accuracy: 0.9029, F1 Micro: 0.9029, F1 Macro: 0.8689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0709, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8801\n",
      "Epoch 7/10, Train Loss: 0.054, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.88\n",
      "Epoch 8/10, Train Loss: 0.0303, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0226, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.884\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0211, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.8854\n",
      "\n",
      "Sentiment analysis accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.8854\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       774\n",
      "    positive       0.94      0.74      0.83       307\n",
      "\n",
      "    accuracy                           0.91      1081\n",
      "   macro avg       0.92      0.86      0.89      1081\n",
      "weighted avg       0.91      0.91      0.91      1081\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1822: Accuracy: 0.9571, F1 Micro: 0.9571, F1 Macro: 0.8602\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.90      0.93        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.84        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.99      0.96       496\n",
      "    positive       0.85      0.60      0.71        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.53      0.56       571\n",
      "weighted avg       0.91      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.89      0.89       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.84      0.87       162\n",
      "     neutral       0.92      0.97      0.95       387\n",
      "    positive       0.92      0.50      0.65        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.77      0.82       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.84      0.84        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.92      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.82      0.87       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 282.53438353538513 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 17.95639157295227 seconds\n",
      "New train size: 1872\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4558, Accuracy: 0.8679, F1 Micro: 0.9222, F1 Macro: 0.9156\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2865, Accuracy: 0.9342, F1 Micro: 0.9599, F1 Macro: 0.9577\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2079, Accuracy: 0.9474, F1 Micro: 0.9678, F1 Macro: 0.9657\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1674, Accuracy: 0.9509, F1 Micro: 0.9699, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1423, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1141, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9746\n",
      "Epoch 7/10, Train Loss: 0.0967, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0818, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9758\n",
      "Epoch 9/10, Train Loss: 0.0681, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9757\n",
      "Epoch 10/10, Train Loss: 0.0563, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9753\n",
      "\n",
      "Aspect detection accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.92      0.93      0.93       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3745, Accuracy: 0.8603, F1 Micro: 0.8603, F1 Macro: 0.8059\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2424, Accuracy: 0.8925, F1 Micro: 0.8925, F1 Macro: 0.8669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1441, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8819\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1133, Accuracy: 0.909, F1 Micro: 0.909, F1 Macro: 0.8808\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0902, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.8885\n",
      "Epoch 6/10, Train Loss: 0.0582, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8856\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0369, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8909\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0433, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8919\n",
      "Epoch 9/10, Train Loss: 0.035, Accuracy: 0.909, F1 Micro: 0.909, F1 Macro: 0.883\n",
      "Epoch 10/10, Train Loss: 0.0275, Accuracy: 0.909, F1 Micro: 0.909, F1 Macro: 0.8838\n",
      "\n",
      "Sentiment analysis accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8919\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       771\n",
      "    positive       0.93      0.77      0.84       317\n",
      "\n",
      "    accuracy                           0.92      1088\n",
      "   macro avg       0.92      0.87      0.89      1088\n",
      "weighted avg       0.92      0.92      0.91      1088\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1872: Accuracy: 0.9587, F1 Micro: 0.9587, F1 Macro: 0.8681\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.81      0.84       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.82      0.85        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.57      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87       200\n",
      "     neutral       0.92      0.93      0.93       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.84      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.76      0.81       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.45      0.59        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.67      0.94      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.80      0.79       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 283.78023982048035 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 15.443431854248047 seconds\n",
      "New train size: 1922\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4484, Accuracy: 0.8731, F1 Micro: 0.9257, F1 Macro: 0.9216\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2846, Accuracy: 0.9377, F1 Micro: 0.9619, F1 Macro: 0.9595\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2043, Accuracy: 0.9477, F1 Micro: 0.968, F1 Macro: 0.9659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1582, Accuracy: 0.9582, F1 Micro: 0.9742, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1304, Accuracy: 0.9583, F1 Micro: 0.9742, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1096, Accuracy: 0.9606, F1 Micro: 0.9755, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0919, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.974\n",
      "Epoch 8/10, Train Loss: 0.0795, Accuracy: 0.9616, F1 Micro: 0.9763, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0646, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0539, Accuracy: 0.9634, F1 Micro: 0.9772, F1 Macro: 0.9744\n",
      "\n",
      "Aspect detection accuracy: 0.9634, F1 Micro: 0.9772, F1 Macro: 0.9744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.93      0.91      0.92       317\n",
      "       linen       0.93      0.98      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3681, Accuracy: 0.8561, F1 Micro: 0.8561, F1 Macro: 0.8029\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2214, Accuracy: 0.8796, F1 Micro: 0.8796, F1 Macro: 0.8388\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1489, Accuracy: 0.8959, F1 Micro: 0.8959, F1 Macro: 0.8654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1085, Accuracy: 0.9014, F1 Micro: 0.9014, F1 Macro: 0.8733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0843, Accuracy: 0.9014, F1 Micro: 0.9014, F1 Macro: 0.8736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0743, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.8816\n",
      "Epoch 7/10, Train Loss: 0.0507, Accuracy: 0.9032, F1 Micro: 0.9032, F1 Macro: 0.8772\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0405, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.8805\n",
      "Epoch 9/10, Train Loss: 0.0351, Accuracy: 0.9032, F1 Micro: 0.9032, F1 Macro: 0.8762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0211, Accuracy: 0.9086, F1 Micro: 0.9086, F1 Macro: 0.8826\n",
      "\n",
      "Sentiment analysis accuracy: 0.9086, F1 Micro: 0.9086, F1 Macro: 0.8826\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       777\n",
      "    positive       0.94      0.74      0.83       328\n",
      "\n",
      "    accuracy                           0.91      1105\n",
      "   macro avg       0.92      0.86      0.88      1105\n",
      "weighted avg       0.91      0.91      0.91      1105\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1922: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.8776\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.92      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.87      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.95      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.75      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.62      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.88      0.87       200\n",
      "     neutral       0.93      0.90      0.92       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.91      0.90       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.83      0.86       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.74      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.82      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.90      0.94      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.84      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.87      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 299.1274480819702 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 14.383671283721924 seconds\n",
      "New train size: 1972\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4592, Accuracy: 0.8734, F1 Micro: 0.9257, F1 Macro: 0.9212\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2865, Accuracy: 0.9351, F1 Micro: 0.9605, F1 Macro: 0.9584\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2028, Accuracy: 0.9488, F1 Micro: 0.9686, F1 Macro: 0.9663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1599, Accuracy: 0.9542, F1 Micro: 0.9718, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1261, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1097, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.093, Accuracy: 0.9648, F1 Micro: 0.9782, F1 Macro: 0.9761\n",
      "Epoch 8/10, Train Loss: 0.078, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.065, Accuracy: 0.9653, F1 Micro: 0.9785, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0575, Accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9787, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3863, Accuracy: 0.8719, F1 Micro: 0.8719, F1 Macro: 0.8298\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2055, Accuracy: 0.8819, F1 Micro: 0.8819, F1 Macro: 0.8401\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1425, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8863\n",
      "Epoch 4/10, Train Loss: 0.0997, Accuracy: 0.9019, F1 Micro: 0.9019, F1 Macro: 0.8725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0766, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8869\n",
      "Epoch 6/10, Train Loss: 0.0515, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0398, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8866\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0226, Accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.8897\n",
      "Epoch 9/10, Train Loss: 0.0212, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8864\n",
      "Epoch 10/10, Train Loss: 0.0284, Accuracy: 0.9092, F1 Micro: 0.9092, F1 Macro: 0.883\n",
      "\n",
      "Sentiment analysis accuracy: 0.9146, F1 Micro: 0.9146, F1 Macro: 0.8897\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       779\n",
      "    positive       0.95      0.75      0.84       322\n",
      "\n",
      "    accuracy                           0.91      1101\n",
      "   macro avg       0.93      0.87      0.89      1101\n",
      "weighted avg       0.92      0.91      0.91      1101\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1972: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.8826\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.87      0.87       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.85      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.77      0.62      0.66       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.89       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.76      0.81       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.59      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.97      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 300.18498611450195 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 25\n",
      "Sampling duration: 12.149384260177612 seconds\n",
      "New train size: 1997\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4441, Accuracy: 0.8719, F1 Micro: 0.9249, F1 Macro: 0.9208\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2818, Accuracy: 0.9365, F1 Micro: 0.9612, F1 Macro: 0.9589\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1965, Accuracy: 0.947, F1 Micro: 0.9677, F1 Macro: 0.9655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1605, Accuracy: 0.9554, F1 Micro: 0.9725, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1296, Accuracy: 0.9608, F1 Micro: 0.9758, F1 Macro: 0.9734\n",
      "Epoch 6/10, Train Loss: 0.1115, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0916, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0753, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0659, Accuracy: 0.9639, F1 Micro: 0.9775, F1 Macro: 0.9751\n",
      "Epoch 10/10, Train Loss: 0.0561, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9745\n",
      "\n",
      "Aspect detection accuracy: 0.9639, F1 Micro: 0.9775, F1 Macro: 0.9751\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.96      0.97      0.97       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3695, Accuracy: 0.8574, F1 Micro: 0.8574, F1 Macro: 0.8115\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2259, Accuracy: 0.8915, F1 Micro: 0.8915, F1 Macro: 0.8607\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1433, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.111, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8766\n",
      "Epoch 5/10, Train Loss: 0.0903, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0781, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8824\n",
      "Epoch 7/10, Train Loss: 0.0358, Accuracy: 0.9067, F1 Micro: 0.9067, F1 Macro: 0.8822\n",
      "Epoch 8/10, Train Loss: 0.0388, Accuracy: 0.9049, F1 Micro: 0.9049, F1 Macro: 0.8789\n",
      "Epoch 9/10, Train Loss: 0.0273, Accuracy: 0.8969, F1 Micro: 0.8969, F1 Macro: 0.8688\n",
      "Epoch 10/10, Train Loss: 0.0198, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8761\n",
      "\n",
      "Sentiment analysis accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8824\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       779\n",
      "    positive       0.94      0.74      0.83       336\n",
      "\n",
      "    accuracy                           0.91      1115\n",
      "   macro avg       0.92      0.86      0.88      1115\n",
      "weighted avg       0.91      0.91      0.90      1115\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1997: Accuracy: 0.958, F1 Micro: 0.958, F1 Macro: 0.8819\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.87      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.86      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.96      0.97      0.97       496\n",
      "    positive       0.80      0.78      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.63      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.89      0.89       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.84      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.74      0.78       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.87      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.83      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 297.92839074134827 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 11.361889123916626 seconds\n",
      "New train size: 2047\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4397, Accuracy: 0.8753, F1 Micro: 0.9266, F1 Macro: 0.9221\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2777, Accuracy: 0.9365, F1 Micro: 0.9614, F1 Macro: 0.9592\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1996, Accuracy: 0.9514, F1 Micro: 0.9702, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1524, Accuracy: 0.9576, F1 Micro: 0.9737, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1301, Accuracy: 0.9601, F1 Micro: 0.9754, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1018, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0877, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0758, Accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9767\n",
      "Epoch 9/10, Train Loss: 0.0611, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9755\n",
      "Epoch 10/10, Train Loss: 0.0536, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.99      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3559, Accuracy: 0.8861, F1 Micro: 0.8861, F1 Macro: 0.8511\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2155, Accuracy: 0.8982, F1 Micro: 0.8982, F1 Macro: 0.8668\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1268, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.8949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.093, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9009\n",
      "Epoch 5/10, Train Loss: 0.0699, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.8971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0579, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.8997\n",
      "Epoch 7/10, Train Loss: 0.0411, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.8949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.029, Accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.9003\n",
      "Epoch 9/10, Train Loss: 0.0326, Accuracy: 0.9141, F1 Micro: 0.9141, F1 Macro: 0.8908\n",
      "Epoch 10/10, Train Loss: 0.0275, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.9004\n",
      "\n",
      "Sentiment analysis accuracy: 0.9244, F1 Micro: 0.9244, F1 Macro: 0.9003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.99      0.95       768\n",
      "    positive       0.96      0.77      0.85       303\n",
      "\n",
      "    accuracy                           0.92      1071\n",
      "   macro avg       0.94      0.88      0.90      1071\n",
      "weighted avg       0.93      0.92      0.92      1071\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2047: Accuracy: 0.9602, F1 Micro: 0.9602, F1 Macro: 0.8842\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.76      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.81      0.84        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.87      0.71      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.61      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.89       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.88      0.91      0.89        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.91      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.83      0.85       162\n",
      "     neutral       0.92      0.97      0.95       387\n",
      "    positive       1.00      0.41      0.58        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.93      0.74      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.96      0.94      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.80      0.94      0.86        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.84      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 302.44265055656433 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 9.421239852905273 seconds\n",
      "New train size: 2097\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4444, Accuracy: 0.8844, F1 Micro: 0.932, F1 Macro: 0.9288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.267, Accuracy: 0.9366, F1 Micro: 0.9615, F1 Macro: 0.9594\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1955, Accuracy: 0.9531, F1 Micro: 0.9712, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1542, Accuracy: 0.9573, F1 Micro: 0.9737, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1228, Accuracy: 0.9615, F1 Micro: 0.9762, F1 Macro: 0.9738\n",
      "Epoch 6/10, Train Loss: 0.1063, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0846, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0738, Accuracy: 0.9634, F1 Micro: 0.9772, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0609, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9756\n",
      "Epoch 10/10, Train Loss: 0.0522, Accuracy: 0.9637, F1 Micro: 0.9774, F1 Macro: 0.9753\n",
      "\n",
      "Aspect detection accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9756\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3394, Accuracy: 0.8597, F1 Micro: 0.8597, F1 Macro: 0.8156\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2141, Accuracy: 0.8912, F1 Micro: 0.8912, F1 Macro: 0.8618\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1461, Accuracy: 0.8966, F1 Micro: 0.8966, F1 Macro: 0.8663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0928, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8756\n",
      "Epoch 5/10, Train Loss: 0.0773, Accuracy: 0.9002, F1 Micro: 0.9002, F1 Macro: 0.8695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0775, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.881\n",
      "Epoch 7/10, Train Loss: 0.0601, Accuracy: 0.9056, F1 Micro: 0.9056, F1 Macro: 0.8769\n",
      "Epoch 8/10, Train Loss: 0.0348, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8756\n",
      "Epoch 9/10, Train Loss: 0.0333, Accuracy: 0.8948, F1 Micro: 0.8948, F1 Macro: 0.8669\n",
      "Epoch 10/10, Train Loss: 0.0328, Accuracy: 0.8957, F1 Micro: 0.8957, F1 Macro: 0.8662\n",
      "\n",
      "Sentiment analysis accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.881\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       784\n",
      "    positive       0.95      0.73      0.82       328\n",
      "\n",
      "    accuracy                           0.91      1112\n",
      "   macro avg       0.92      0.86      0.88      1112\n",
      "weighted avg       0.91      0.91      0.90      1112\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2097: Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.8779\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.85      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.85      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.58       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.85      0.50      0.63        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.77      0.82       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.88      0.87        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.92      0.97      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.69      0.74        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 309.16983246803284 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 7.778894424438477 seconds\n",
      "New train size: 2147\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4353, Accuracy: 0.8882, F1 Micro: 0.9336, F1 Macro: 0.93\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2632, Accuracy: 0.9373, F1 Micro: 0.9618, F1 Macro: 0.9596\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.188, Accuracy: 0.9566, F1 Micro: 0.9733, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1487, Accuracy: 0.9599, F1 Micro: 0.9752, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1218, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0863, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0694, Accuracy: 0.9646, F1 Micro: 0.9781, F1 Macro: 0.9762\n",
      "Epoch 9/10, Train Loss: 0.0596, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9754\n",
      "Epoch 10/10, Train Loss: 0.0496, Accuracy: 0.9618, F1 Micro: 0.9764, F1 Macro: 0.9744\n",
      "\n",
      "Aspect detection accuracy: 0.9646, F1 Micro: 0.9781, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.99      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.92      0.96      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.99      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.99      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3401, Accuracy: 0.8631, F1 Micro: 0.8631, F1 Macro: 0.8347\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1964, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.8991\n",
      "Epoch 3/10, Train Loss: 0.125, Accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.8787\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.088, Accuracy: 0.924, F1 Micro: 0.924, F1 Macro: 0.8991\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0731, Accuracy: 0.9249, F1 Micro: 0.9249, F1 Macro: 0.901\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0608, Accuracy: 0.9297, F1 Micro: 0.9297, F1 Macro: 0.9069\n",
      "Epoch 7/10, Train Loss: 0.0292, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9049\n",
      "Epoch 8/10, Train Loss: 0.0356, Accuracy: 0.9211, F1 Micro: 0.9211, F1 Macro: 0.8949\n",
      "Epoch 9/10, Train Loss: 0.0344, Accuracy: 0.9278, F1 Micro: 0.9278, F1 Macro: 0.9046\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0194, Accuracy: 0.9335, F1 Micro: 0.9335, F1 Macro: 0.9115\n",
      "\n",
      "Sentiment analysis accuracy: 0.9335, F1 Micro: 0.9335, F1 Macro: 0.9115\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.99      0.96       763\n",
      "    positive       0.96      0.79      0.87       289\n",
      "\n",
      "    accuracy                           0.93      1052\n",
      "   macro avg       0.94      0.89      0.91      1052\n",
      "weighted avg       0.93      0.93      0.93      1052\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2147: Accuracy: 0.9597, F1 Micro: 0.9597, F1 Macro: 0.8712\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.88      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.77      0.83        78\n",
      "     neutral       0.96      0.99      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.68      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.60      0.65       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.85      0.89       200\n",
      "     neutral       0.92      0.96      0.94       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.92      0.50      0.65        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.78      0.83       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.95      0.93      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.86      0.71      0.77        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.76      0.82       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 311.9537994861603 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 5.906068563461304 seconds\n",
      "New train size: 2197\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4371, Accuracy: 0.8835, F1 Micro: 0.9314, F1 Macro: 0.9281\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2588, Accuracy: 0.9394, F1 Micro: 0.963, F1 Macro: 0.9606\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1837, Accuracy: 0.953, F1 Micro: 0.9711, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.147, Accuracy: 0.958, F1 Micro: 0.974, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1206, Accuracy: 0.9639, F1 Micro: 0.9775, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0981, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0815, Accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.9769\n",
      "Epoch 8/10, Train Loss: 0.0692, Accuracy: 0.9648, F1 Micro: 0.978, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0581, Accuracy: 0.9674, F1 Micro: 0.9797, F1 Macro: 0.9777\n",
      "Epoch 10/10, Train Loss: 0.0494, Accuracy: 0.9637, F1 Micro: 0.9774, F1 Macro: 0.9753\n",
      "\n",
      "Aspect detection accuracy: 0.9674, F1 Micro: 0.9797, F1 Macro: 0.9777\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.93      0.98      0.95       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3449, Accuracy: 0.8796, F1 Micro: 0.8796, F1 Macro: 0.8442\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1731, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1313, Accuracy: 0.9197, F1 Micro: 0.9197, F1 Macro: 0.8973\n",
      "Epoch 4/10, Train Loss: 0.0853, Accuracy: 0.9133, F1 Micro: 0.9133, F1 Macro: 0.8895\n",
      "Epoch 5/10, Train Loss: 0.0677, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8888\n",
      "Epoch 6/10, Train Loss: 0.0523, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.8948\n",
      "Epoch 7/10, Train Loss: 0.0357, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.8937\n",
      "Epoch 8/10, Train Loss: 0.03, Accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.894\n",
      "Epoch 9/10, Train Loss: 0.0183, Accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.8922\n",
      "Epoch 10/10, Train Loss: 0.0222, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8887\n",
      "\n",
      "Sentiment analysis accuracy: 0.9197, F1 Micro: 0.9197, F1 Macro: 0.8973\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       779\n",
      "    positive       0.93      0.78      0.85       317\n",
      "\n",
      "    accuracy                           0.92      1096\n",
      "   macro avg       0.92      0.88      0.90      1096\n",
      "weighted avg       0.92      0.92      0.92      1096\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2197: Accuracy: 0.9611, F1 Micro: 0.9611, F1 Macro: 0.8716\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.80      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.77      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.84      0.78      0.81        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.68      0.74       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.86       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       0.85      0.50      0.63        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.77      0.81       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.88      0.87        85\n",
      "     neutral       0.98      0.97      0.98       418\n",
      "    positive       0.94      0.97      0.96        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.55      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.97      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.60      1.00      0.75         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.86      0.99      0.91       571\n",
      "weighted avg       1.00      0.99      1.00       571\n",
      "\n",
      "Total train time: 318.4301962852478 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 4.036613464355469 seconds\n",
      "New train size: 2247\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4317, Accuracy: 0.892, F1 Micro: 0.9361, F1 Macro: 0.9327\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2479, Accuracy: 0.9403, F1 Micro: 0.9636, F1 Macro: 0.9614\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.18, Accuracy: 0.9514, F1 Micro: 0.9702, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.146, Accuracy: 0.9587, F1 Micro: 0.9745, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1198, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.975\n",
      "Epoch 6/10, Train Loss: 0.097, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0815, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.069, Accuracy: 0.9648, F1 Micro: 0.9782, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0549, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9763\n",
      "Epoch 10/10, Train Loss: 0.0458, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.98       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3142, Accuracy: 0.8668, F1 Micro: 0.8668, F1 Macro: 0.8417\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2085, Accuracy: 0.9078, F1 Micro: 0.9078, F1 Macro: 0.8812\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1251, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8893\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0926, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.8934\n",
      "Epoch 5/10, Train Loss: 0.0581, Accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.8929\n",
      "Epoch 6/10, Train Loss: 0.0551, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8872\n",
      "Epoch 7/10, Train Loss: 0.0363, Accuracy: 0.8942, F1 Micro: 0.8942, F1 Macro: 0.8575\n",
      "Epoch 8/10, Train Loss: 0.0454, Accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.8902\n",
      "Epoch 9/10, Train Loss: 0.0247, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8906\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0172, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.8956\n",
      "\n",
      "Sentiment analysis accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.8956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       777\n",
      "    positive       0.94      0.77      0.85       319\n",
      "\n",
      "    accuracy                           0.92      1096\n",
      "   macro avg       0.93      0.87      0.90      1096\n",
      "weighted avg       0.92      0.92      0.92      1096\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2247: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.8756\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.90      0.93        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.86      0.84        78\n",
      "     neutral       0.98      0.97      0.98       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.94      0.87       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.84      0.76      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.63      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.86      0.89       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.83      0.85       162\n",
      "     neutral       0.92      0.97      0.95       387\n",
      "    positive       0.70      0.32      0.44        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.83      0.71      0.75       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.89      0.86        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.94      0.97      0.96        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.66      0.76        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.84      0.94      0.89        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.86      0.88       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 327.8114013671875 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 36\n",
      "Sampling duration: 2.222321033477783 seconds\n",
      "New train size: 2283\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4211, Accuracy: 0.8948, F1 Micro: 0.9374, F1 Macro: 0.9336\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.242, Accuracy: 0.9417, F1 Micro: 0.9644, F1 Macro: 0.9625\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1782, Accuracy: 0.9514, F1 Micro: 0.9701, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1402, Accuracy: 0.959, F1 Micro: 0.9746, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1152, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9747\n",
      "Epoch 6/10, Train Loss: 0.0938, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0766, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.976\n",
      "Epoch 8/10, Train Loss: 0.0649, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9749\n",
      "Epoch 9/10, Train Loss: 0.0551, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0473, Accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.93      0.98      0.95       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3539, Accuracy: 0.8824, F1 Micro: 0.8824, F1 Macro: 0.8511\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1958, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8843\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1171, Accuracy: 0.9204, F1 Micro: 0.9204, F1 Macro: 0.898\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0719, Accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.899\n",
      "Epoch 5/10, Train Loss: 0.0567, Accuracy: 0.9213, F1 Micro: 0.9213, F1 Macro: 0.8965\n",
      "Epoch 6/10, Train Loss: 0.0588, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8893\n",
      "Epoch 7/10, Train Loss: 0.0413, Accuracy: 0.9204, F1 Micro: 0.9204, F1 Macro: 0.8977\n",
      "Epoch 8/10, Train Loss: 0.0325, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8895\n",
      "Epoch 9/10, Train Loss: 0.0245, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.8913\n",
      "Epoch 10/10, Train Loss: 0.0174, Accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.8964\n",
      "\n",
      "Sentiment analysis accuracy: 0.9222, F1 Micro: 0.9222, F1 Macro: 0.899\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       774\n",
      "    positive       0.93      0.78      0.85       306\n",
      "\n",
      "    accuracy                           0.92      1080\n",
      "   macro avg       0.93      0.88      0.90      1080\n",
      "weighted avg       0.92      0.92      0.92      1080\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2283: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.8656\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.82      0.85        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.82      0.69      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.56      0.57       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.90       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       0.92      0.50      0.65        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.92      0.77      0.82       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.94      0.97      0.96        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.45      0.59        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.78      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.91      0.99      0.95       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 322.1960210800171 s\n",
      "Total runtime: 7337.795103311539 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3227745b",
   "metadata": {
    "papermill": {
     "duration": 0.011347,
     "end_time": "2025-03-31T04:28:08.359190",
     "exception": false,
     "start_time": "2025-03-31T04:28:08.347843",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56af784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 2\n",
      "Random seed: 81\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6846, Accuracy: 0.7771, F1 Micro: 0.873, F1 Macro: 0.8661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5356, Accuracy: 0.8012, F1 Micro: 0.8896, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4856, Accuracy: 0.8019, F1 Micro: 0.8899, F1 Macro: 0.8853\n",
      "Epoch 4/10, Train Loss: 0.4451, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Epoch 5/10, Train Loss: 0.447, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4104, Accuracy: 0.8038, F1 Micro: 0.8908, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4062, Accuracy: 0.8099, F1 Micro: 0.893, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4023, Accuracy: 0.8189, F1 Micro: 0.8974, F1 Macro: 0.8906\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3668, Accuracy: 0.8349, F1 Micro: 0.9047, F1 Macro: 0.8978\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3363, Accuracy: 0.8422, F1 Micro: 0.9091, F1 Macro: 0.9034\n",
      "\n",
      "Aspect detection accuracy: 0.8422, F1 Micro: 0.9091, F1 Macro: 0.9034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.80      1.00      0.89       462\n",
      "   air_panas       0.83      1.00      0.91       480\n",
      "         bau       0.86      1.00      0.93       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.66      0.86      0.75       317\n",
      "       linen       0.73      0.99      0.84       392\n",
      "     service       0.92      0.96      0.94       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.90      1.00      0.95       516\n",
      "        wifi       0.91      1.00      0.95       498\n",
      "\n",
      "   micro avg       0.84      0.99      0.91      4614\n",
      "   macro avg       0.84      0.98      0.90      4614\n",
      "weighted avg       0.85      0.99      0.91      4614\n",
      " samples avg       0.84      0.99      0.91      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6158, Accuracy: 0.6141, F1 Micro: 0.6141, F1 Macro: 0.3805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4961, Accuracy: 0.6141, F1 Micro: 0.6141, F1 Macro: 0.3805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4198, Accuracy: 0.6141, F1 Micro: 0.6141, F1 Macro: 0.3805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4426, Accuracy: 0.6141, F1 Micro: 0.6141, F1 Macro: 0.3805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3147, Accuracy: 0.7391, F1 Micro: 0.7391, F1 Macro: 0.6783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2361, Accuracy: 0.7636, F1 Micro: 0.7636, F1 Macro: 0.7349\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2395, Accuracy: 0.7663, F1 Micro: 0.7663, F1 Macro: 0.7452\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2328, Accuracy: 0.7935, F1 Micro: 0.7935, F1 Macro: 0.781\n",
      "Epoch 9/10, Train Loss: 0.1405, Accuracy: 0.7799, F1 Micro: 0.7799, F1 Macro: 0.7604\n",
      "Epoch 10/10, Train Loss: 0.0903, Accuracy: 0.7745, F1 Micro: 0.7745, F1 Macro: 0.7461\n",
      "\n",
      "Sentiment analysis accuracy: 0.7935, F1 Micro: 0.7935, F1 Macro: 0.781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.84      0.83       226\n",
      "    positive       0.74      0.72      0.73       142\n",
      "\n",
      "    accuracy                           0.79       368\n",
      "   macro avg       0.78      0.78      0.78       368\n",
      "weighted avg       0.79      0.79      0.79       368\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 142: Accuracy: 0.8343, F1 Micro: 0.8343, F1 Macro: 0.4065\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        97\n",
      "     neutral       0.80      1.00      0.89       459\n",
      "    positive       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.80       571\n",
      "   macro avg       0.27      0.33      0.30       571\n",
      "weighted avg       0.65      0.80      0.72       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        86\n",
      "     neutral       0.83      1.00      0.91       475\n",
      "    positive       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.28      0.33      0.30       571\n",
      "weighted avg       0.69      0.83      0.76       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.03      0.05        78\n",
      "     neutral       0.86      1.00      0.93       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.51      0.34      0.32       571\n",
      "weighted avg       0.83      0.86      0.80       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.75      0.36      0.49       200\n",
      "     neutral       0.66      0.86      0.75       315\n",
      "    positive       0.27      0.32      0.30        56\n",
      "\n",
      "    accuracy                           0.63       571\n",
      "   macro avg       0.56      0.51      0.51       571\n",
      "weighted avg       0.65      0.63      0.61       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.23      0.37       162\n",
      "     neutral       0.72      0.99      0.84       387\n",
      "    positive       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.74       571\n",
      "   macro avg       0.55      0.41      0.40       571\n",
      "weighted avg       0.75      0.74      0.67       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.61      0.71        85\n",
      "     neutral       0.92      0.96      0.94       418\n",
      "    positive       0.72      0.75      0.73        68\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.83      0.78      0.79       571\n",
      "weighted avg       0.88      0.89      0.88       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.89      1.00      0.94       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.30      0.33      0.31       571\n",
      "weighted avg       0.80      0.89      0.85       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.36      0.52        74\n",
      "     neutral       0.91      1.00      0.95       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.61      0.45      0.49       571\n",
      "weighted avg       0.91      0.91      0.89       571\n",
      "\n",
      "Total train time: 88.60727834701538 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 215\n",
      "Sampling duration: 54.544042110443115 seconds\n",
      "New train size: 357\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5984, Accuracy: 0.8014, F1 Micro: 0.8897, F1 Macro: 0.8852\n",
      "Epoch 2/10, Train Loss: 0.4729, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4591, Accuracy: 0.8094, F1 Micro: 0.8929, F1 Macro: 0.8867\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4355, Accuracy: 0.8227, F1 Micro: 0.9, F1 Macro: 0.8952\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3857, Accuracy: 0.858, F1 Micro: 0.9173, F1 Macro: 0.9124\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3276, Accuracy: 0.8878, F1 Micro: 0.9327, F1 Macro: 0.9258\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2883, Accuracy: 0.8955, F1 Micro: 0.9374, F1 Macro: 0.9321\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2492, Accuracy: 0.9122, F1 Micro: 0.9468, F1 Macro: 0.9428\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.229, Accuracy: 0.9187, F1 Micro: 0.9509, F1 Macro: 0.9477\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1978, Accuracy: 0.9243, F1 Micro: 0.9539, F1 Macro: 0.9511\n",
      "\n",
      "Aspect detection accuracy: 0.9243, F1 Micro: 0.9539, F1 Macro: 0.9511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.97      0.99      0.98       462\n",
      "   air_panas       0.94      0.99      0.97       480\n",
      "         bau       0.96      0.97      0.97       496\n",
      "     general       0.87      0.98      0.92       500\n",
      "  kebersihan       0.89      0.89      0.89       317\n",
      "       linen       0.85      0.97      0.91       392\n",
      "     service       0.94      0.96      0.95       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.96      1.00      0.98       516\n",
      "        wifi       0.98      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.93      0.98      0.95      4614\n",
      "   macro avg       0.93      0.97      0.95      4614\n",
      "weighted avg       0.93      0.98      0.95      4614\n",
      " samples avg       0.93      0.98      0.95      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5712, Accuracy: 0.7244, F1 Micro: 0.7244, F1 Macro: 0.4201\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4249, Accuracy: 0.8015, F1 Micro: 0.8015, F1 Macro: 0.7038\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2802, Accuracy: 0.8049, F1 Micro: 0.8049, F1 Macro: 0.7583\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2505, Accuracy: 0.8324, F1 Micro: 0.8324, F1 Macro: 0.7536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2168, Accuracy: 0.8445, F1 Micro: 0.8445, F1 Macro: 0.7797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.175, Accuracy: 0.8501, F1 Micro: 0.8501, F1 Macro: 0.7947\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1403, Accuracy: 0.8578, F1 Micro: 0.8578, F1 Macro: 0.7998\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1235, Accuracy: 0.8633, F1 Micro: 0.8633, F1 Macro: 0.8128\n",
      "Epoch 9/10, Train Loss: 0.088, Accuracy: 0.8589, F1 Micro: 0.8589, F1 Macro: 0.7955\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0888, Accuracy: 0.8699, F1 Micro: 0.8699, F1 Macro: 0.8178\n",
      "\n",
      "Sentiment analysis accuracy: 0.8699, F1 Micro: 0.8699, F1 Macro: 0.8178\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.97      0.92       657\n",
      "    positive       0.88      0.61      0.72       250\n",
      "\n",
      "    accuracy                           0.87       907\n",
      "   macro avg       0.88      0.79      0.82       907\n",
      "weighted avg       0.87      0.87      0.86       907\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 357: Accuracy: 0.9159, F1 Micro: 0.9159, F1 Macro: 0.6449\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.85      0.90        97\n",
      "     neutral       0.97      0.99      0.98       459\n",
      "    positive       0.81      0.87      0.84        15\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.91      0.90      0.91       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.70      0.78        86\n",
      "     neutral       0.94      0.99      0.97       475\n",
      "    positive       0.43      0.30      0.35        10\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.76      0.66      0.70       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.76      0.79        78\n",
      "     neutral       0.96      0.97      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.58      0.58       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      0.98      0.92       496\n",
      "    positive       0.18      0.03      0.05        68\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.35      0.34      0.32       571\n",
      "weighted avg       0.78      0.86      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.80      0.82       200\n",
      "     neutral       0.89      0.89      0.89       315\n",
      "    positive       0.73      0.84      0.78        56\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.82      0.84      0.83       571\n",
      "weighted avg       0.86      0.85      0.85       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.67      0.76       162\n",
      "     neutral       0.85      0.97      0.91       387\n",
      "    positive       0.67      0.27      0.39        22\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.80      0.64      0.69       571\n",
      "weighted avg       0.85      0.86      0.85       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.78      0.78        85\n",
      "     neutral       0.94      0.96      0.95       418\n",
      "    positive       0.84      0.75      0.79        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.85      0.83      0.84       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.03      0.07        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.25      0.06      0.10        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.72      0.36      0.37       571\n",
      "weighted avg       0.91      0.92      0.89       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.63      0.74        54\n",
      "     neutral       0.96      1.00      0.98       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.62      0.54      0.57       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.89      0.91        74\n",
      "     neutral       0.98      1.00      0.99       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.64      0.63      0.63       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Total train time: 128.63874793052673 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 193\n",
      "Sampling duration: 60.552427768707275 seconds\n",
      "New train size: 550\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.56, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4781, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4384, Accuracy: 0.8382, F1 Micro: 0.9067, F1 Macro: 0.8988\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3906, Accuracy: 0.867, F1 Micro: 0.9223, F1 Macro: 0.9176\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3332, Accuracy: 0.9068, F1 Micro: 0.9438, F1 Macro: 0.9395\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2722, Accuracy: 0.9264, F1 Micro: 0.955, F1 Macro: 0.9518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2373, Accuracy: 0.9326, F1 Micro: 0.9589, F1 Macro: 0.956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2007, Accuracy: 0.9363, F1 Micro: 0.9611, F1 Macro: 0.9581\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1695, Accuracy: 0.937, F1 Micro: 0.9616, F1 Macro: 0.959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1532, Accuracy: 0.9398, F1 Micro: 0.9631, F1 Macro: 0.9603\n",
      "\n",
      "Aspect detection accuracy: 0.9398, F1 Micro: 0.9631, F1 Macro: 0.9603\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.98       462\n",
      "   air_panas       0.96      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.88      0.99      0.93       500\n",
      "  kebersihan       0.92      0.89      0.91       317\n",
      "       linen       0.85      0.98      0.91       392\n",
      "     service       0.95      0.96      0.96       423\n",
      "sunrise_meal       0.96      1.00      0.98       530\n",
      "          tv       0.98      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.94      0.98      0.96      4614\n",
      "   macro avg       0.94      0.98      0.96      4614\n",
      "weighted avg       0.95      0.98      0.96      4614\n",
      " samples avg       0.94      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5316, Accuracy: 0.7479, F1 Micro: 0.7479, F1 Macro: 0.4943\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3891, Accuracy: 0.8337, F1 Micro: 0.8337, F1 Macro: 0.7518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3118, Accuracy: 0.8441, F1 Micro: 0.8441, F1 Macro: 0.7942\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2243, Accuracy: 0.863, F1 Micro: 0.863, F1 Macro: 0.8018\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1377, Accuracy: 0.8672, F1 Micro: 0.8672, F1 Macro: 0.8052\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1307, Accuracy: 0.8713, F1 Micro: 0.8713, F1 Macro: 0.8287\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1134, Accuracy: 0.8828, F1 Micro: 0.8828, F1 Macro: 0.8352\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0849, Accuracy: 0.887, F1 Micro: 0.887, F1 Macro: 0.8481\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1033, Accuracy: 0.8891, F1 Micro: 0.8891, F1 Macro: 0.8478\n",
      "Epoch 10/10, Train Loss: 0.0882, Accuracy: 0.887, F1 Micro: 0.887, F1 Macro: 0.8445\n",
      "\n",
      "Sentiment analysis accuracy: 0.8891, F1 Micro: 0.8891, F1 Macro: 0.8478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.93       699\n",
      "    positive       0.88      0.68      0.77       257\n",
      "\n",
      "    accuracy                           0.89       956\n",
      "   macro avg       0.88      0.82      0.85       956\n",
      "weighted avg       0.89      0.89      0.88       956\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 550: Accuracy: 0.9327, F1 Micro: 0.9327, F1 Macro: 0.7515\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.88      0.91        97\n",
      "     neutral       0.98      0.99      0.98       459\n",
      "    positive       0.87      0.87      0.87        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.77      0.83        86\n",
      "     neutral       0.96      0.99      0.98       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.84      0.79      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.77      0.82        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.61      0.58      0.60       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.88      0.99      0.93       496\n",
      "    positive       0.67      0.12      0.20        68\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.52      0.37      0.38       571\n",
      "weighted avg       0.84      0.88      0.83       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86       200\n",
      "     neutral       0.92      0.89      0.91       315\n",
      "    positive       0.82      0.95      0.88        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.86      0.90      0.88       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.65      0.77       162\n",
      "     neutral       0.85      0.98      0.91       387\n",
      "    positive       0.67      0.27      0.39        22\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.81      0.64      0.69       571\n",
      "weighted avg       0.86      0.86      0.85       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.75      0.77        85\n",
      "     neutral       0.95      0.96      0.96       418\n",
      "    positive       0.87      0.85      0.86        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.87      0.86      0.86       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.14      0.24        29\n",
      "     neutral       0.96      1.00      0.98       525\n",
      "    positive       0.72      0.76      0.74        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.83      0.63      0.65       571\n",
      "weighted avg       0.94      0.95      0.93       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.87      0.90        54\n",
      "     neutral       0.98      1.00      0.99       511\n",
      "    positive       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.97      0.79      0.85       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.95      0.95        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.87      0.87      0.87       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 162.09363198280334 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 174\n",
      "Sampling duration: 57.32785940170288 seconds\n",
      "New train size: 724\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5443, Accuracy: 0.8021, F1 Micro: 0.89, F1 Macro: 0.8855\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.471, Accuracy: 0.8156, F1 Micro: 0.8952, F1 Macro: 0.8868\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4242, Accuracy: 0.8571, F1 Micro: 0.9173, F1 Macro: 0.9125\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3501, Accuracy: 0.9061, F1 Micro: 0.9438, F1 Macro: 0.9393\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2785, Accuracy: 0.9285, F1 Micro: 0.9567, F1 Macro: 0.9536\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2501, Accuracy: 0.9358, F1 Micro: 0.9608, F1 Macro: 0.9578\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2036, Accuracy: 0.9479, F1 Micro: 0.968, F1 Macro: 0.9655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1719, Accuracy: 0.9509, F1 Micro: 0.9697, F1 Macro: 0.9664\n",
      "Epoch 9/10, Train Loss: 0.1562, Accuracy: 0.9502, F1 Micro: 0.9693, F1 Macro: 0.9667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1306, Accuracy: 0.9531, F1 Micro: 0.971, F1 Macro: 0.9679\n",
      "\n",
      "Aspect detection accuracy: 0.9531, F1 Micro: 0.971, F1 Macro: 0.9679\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.96      0.99      0.97       496\n",
      "     general       0.91      0.99      0.95       500\n",
      "  kebersihan       0.94      0.87      0.91       317\n",
      "       linen       0.91      0.97      0.94       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5027, Accuracy: 0.8321, F1 Micro: 0.8321, F1 Macro: 0.7707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3613, Accuracy: 0.856, F1 Micro: 0.856, F1 Macro: 0.8102\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2915, Accuracy: 0.8618, F1 Micro: 0.8618, F1 Macro: 0.815\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2415, Accuracy: 0.8724, F1 Micro: 0.8724, F1 Macro: 0.8332\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1811, Accuracy: 0.88, F1 Micro: 0.88, F1 Macro: 0.8396\n",
      "Epoch 6/10, Train Loss: 0.1514, Accuracy: 0.8704, F1 Micro: 0.8704, F1 Macro: 0.8176\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1332, Accuracy: 0.8858, F1 Micro: 0.8858, F1 Macro: 0.8485\n",
      "Epoch 8/10, Train Loss: 0.1088, Accuracy: 0.8704, F1 Micro: 0.8704, F1 Macro: 0.8409\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0937, Accuracy: 0.8896, F1 Micro: 0.8896, F1 Macro: 0.8532\n",
      "Epoch 10/10, Train Loss: 0.0686, Accuracy: 0.8839, F1 Micro: 0.8839, F1 Macro: 0.844\n",
      "\n",
      "Sentiment analysis accuracy: 0.8896, F1 Micro: 0.8896, F1 Macro: 0.8532\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.97      0.93       745\n",
      "    positive       0.90      0.69      0.78       297\n",
      "\n",
      "    accuracy                           0.89      1042\n",
      "   macro avg       0.89      0.83      0.85      1042\n",
      "weighted avg       0.89      0.89      0.88      1042\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 724: Accuracy: 0.9452, F1 Micro: 0.9452, F1 Macro: 0.7985\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.95      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.80      0.40      0.53        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.89      0.75      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.74      0.81        78\n",
      "     neutral       0.96      0.99      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.62      0.58      0.59       571\n",
      "weighted avg       0.94      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.91      0.99      0.95       496\n",
      "    positive       0.85      0.41      0.55        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.59      0.47      0.50       571\n",
      "weighted avg       0.89      0.91      0.89       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.89      0.85       200\n",
      "     neutral       0.94      0.87      0.90       315\n",
      "    positive       0.86      0.91      0.89        56\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.87      0.89      0.88       571\n",
      "weighted avg       0.89      0.88      0.88       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.78      0.83       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.69      0.41      0.51        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.83      0.72      0.76       571\n",
      "weighted avg       0.89      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.75      0.82        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.86      0.91      0.89        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.88      0.89       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.38      0.52        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.67      0.82      0.74        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.73      0.75       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.88      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 179.71733212471008 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 156\n",
      "Sampling duration: 52.89501881599426 seconds\n",
      "New train size: 880\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5436, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4561, Accuracy: 0.8281, F1 Micro: 0.902, F1 Macro: 0.8956\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3905, Accuracy: 0.8939, F1 Micro: 0.9365, F1 Macro: 0.9296\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.298, Accuracy: 0.934, F1 Micro: 0.9597, F1 Macro: 0.9566\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2482, Accuracy: 0.942, F1 Micro: 0.9646, F1 Macro: 0.9617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2025, Accuracy: 0.9481, F1 Micro: 0.9681, F1 Macro: 0.9659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1732, Accuracy: 0.9493, F1 Micro: 0.969, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1555, Accuracy: 0.9564, F1 Micro: 0.9731, F1 Macro: 0.9706\n",
      "Epoch 9/10, Train Loss: 0.1298, Accuracy: 0.9559, F1 Micro: 0.9728, F1 Macro: 0.9705\n",
      "Epoch 10/10, Train Loss: 0.1184, Accuracy: 0.9536, F1 Micro: 0.9715, F1 Macro: 0.969\n",
      "\n",
      "Aspect detection accuracy: 0.9564, F1 Micro: 0.9731, F1 Macro: 0.9706\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.92      0.99      0.95       500\n",
      "  kebersihan       0.88      0.96      0.92       317\n",
      "       linen       0.91      0.97      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4824, Accuracy: 0.8387, F1 Micro: 0.8387, F1 Macro: 0.8003\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3094, Accuracy: 0.8688, F1 Micro: 0.8688, F1 Macro: 0.8169\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2419, Accuracy: 0.8795, F1 Micro: 0.8795, F1 Macro: 0.8388\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2029, Accuracy: 0.8892, F1 Micro: 0.8892, F1 Macro: 0.8469\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.166, Accuracy: 0.898, F1 Micro: 0.898, F1 Macro: 0.8654\n",
      "Epoch 6/10, Train Loss: 0.124, Accuracy: 0.896, F1 Micro: 0.896, F1 Macro: 0.8629\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0888, Accuracy: 0.8989, F1 Micro: 0.8989, F1 Macro: 0.8658\n",
      "Epoch 8/10, Train Loss: 0.0928, Accuracy: 0.897, F1 Micro: 0.897, F1 Macro: 0.8633\n",
      "Epoch 9/10, Train Loss: 0.0763, Accuracy: 0.8912, F1 Micro: 0.8912, F1 Macro: 0.8525\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0478, Accuracy: 0.8999, F1 Micro: 0.8999, F1 Macro: 0.8666\n",
      "\n",
      "Sentiment analysis accuracy: 0.8999, F1 Micro: 0.8999, F1 Macro: 0.8666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93       743\n",
      "    positive       0.90      0.72      0.80       286\n",
      "\n",
      "    accuracy                           0.90      1029\n",
      "   macro avg       0.90      0.84      0.87      1029\n",
      "weighted avg       0.90      0.90      0.90      1029\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 880: Accuracy: 0.9476, F1 Micro: 0.9476, F1 Macro: 0.7945\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.98      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.89        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.78      0.81       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.79      0.81        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.60      0.59      0.59       571\n",
      "weighted avg       0.94      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.92      0.99      0.95       496\n",
      "    positive       0.85      0.50      0.63        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.59      0.50      0.53       571\n",
      "weighted avg       0.90      0.92      0.90       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.80      0.85       200\n",
      "     neutral       0.88      0.96      0.92       315\n",
      "    positive       0.84      0.86      0.85        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.88      0.87      0.87       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.80      0.82       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.62      0.23      0.33        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.80      0.67      0.70       571\n",
      "weighted avg       0.88      0.89      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.82      0.84        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.89      0.93      0.91        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.91      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.52      0.64        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.72      0.76      0.74        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.76      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       0.80      0.67      0.73         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.86      0.89       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.95      0.96        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.60      1.00      0.75         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.86      0.98      0.90       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 199.85682010650635 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 141\n",
      "Sampling duration: 47.260106563568115 seconds\n",
      "New train size: 1021\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5329, Accuracy: 0.8014, F1 Micro: 0.8897, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4514, Accuracy: 0.8394, F1 Micro: 0.907, F1 Macro: 0.8997\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3562, Accuracy: 0.9083, F1 Micro: 0.9451, F1 Macro: 0.9412\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2626, Accuracy: 0.9293, F1 Micro: 0.957, F1 Macro: 0.9537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.228, Accuracy: 0.9403, F1 Micro: 0.9636, F1 Macro: 0.9609\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1899, Accuracy: 0.9509, F1 Micro: 0.9698, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1609, Accuracy: 0.9526, F1 Micro: 0.9708, F1 Macro: 0.9681\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1369, Accuracy: 0.9557, F1 Micro: 0.9727, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1211, Accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9715\n",
      "Epoch 10/10, Train Loss: 0.1029, Accuracy: 0.9571, F1 Micro: 0.9734, F1 Macro: 0.9705\n",
      "\n",
      "Aspect detection accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.93      0.98      0.96       500\n",
      "  kebersihan       0.92      0.93      0.93       317\n",
      "       linen       0.93      0.95      0.94       392\n",
      "     service       0.96      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4795, Accuracy: 0.8341, F1 Micro: 0.8341, F1 Macro: 0.7665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3081, Accuracy: 0.869, F1 Micro: 0.869, F1 Macro: 0.8259\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2587, Accuracy: 0.8926, F1 Micro: 0.8926, F1 Macro: 0.8574\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1766, Accuracy: 0.8992, F1 Micro: 0.8992, F1 Macro: 0.8682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1344, Accuracy: 0.901, F1 Micro: 0.901, F1 Macro: 0.8713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.108, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8762\n",
      "Epoch 7/10, Train Loss: 0.0724, Accuracy: 0.8963, F1 Micro: 0.8963, F1 Macro: 0.8613\n",
      "Epoch 8/10, Train Loss: 0.0801, Accuracy: 0.8935, F1 Micro: 0.8935, F1 Macro: 0.8577\n",
      "Epoch 9/10, Train Loss: 0.0523, Accuracy: 0.8897, F1 Micro: 0.8897, F1 Macro: 0.8523\n",
      "Epoch 10/10, Train Loss: 0.0701, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8715\n",
      "\n",
      "Sentiment analysis accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.94       755\n",
      "    positive       0.92      0.74      0.82       306\n",
      "\n",
      "    accuracy                           0.90      1061\n",
      "   macro avg       0.91      0.85      0.88      1061\n",
      "weighted avg       0.91      0.90      0.90      1061\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1021: Accuracy: 0.9515, F1 Micro: 0.9515, F1 Macro: 0.838\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.97      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.85      0.88        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.88      0.81      0.84       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.79      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.98      0.96       496\n",
      "    positive       0.83      0.56      0.67        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.59      0.51      0.54       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88       200\n",
      "     neutral       0.92      0.93      0.93       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.85       162\n",
      "     neutral       0.93      0.96      0.94       387\n",
      "    positive       0.69      0.50      0.58        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.83      0.76      0.79       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.85      0.84        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.97      0.88      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.90      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.45      0.59        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.68      0.88      0.77        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.78      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.89      0.92        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       0.62      0.83      0.71         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.86      0.91      0.88       571\n",
      "weighted avg       0.99      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.96      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 221.3926408290863 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 127\n",
      "Sampling duration: 42.90125823020935 seconds\n",
      "New train size: 1148\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5222, Accuracy: 0.8062, F1 Micro: 0.892, F1 Macro: 0.8873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4349, Accuracy: 0.8795, F1 Micro: 0.9289, F1 Macro: 0.9245\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3293, Accuracy: 0.9292, F1 Micro: 0.9567, F1 Macro: 0.9531\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2506, Accuracy: 0.9425, F1 Micro: 0.9649, F1 Macro: 0.9624\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2059, Accuracy: 0.9455, F1 Micro: 0.9666, F1 Macro: 0.9642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1759, Accuracy: 0.951, F1 Micro: 0.9698, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1533, Accuracy: 0.9538, F1 Micro: 0.9715, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.132, Accuracy: 0.958, F1 Micro: 0.974, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.115, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9733\n",
      "Epoch 10/10, Train Loss: 0.099, Accuracy: 0.9582, F1 Micro: 0.9741, F1 Macro: 0.9718\n",
      "\n",
      "Aspect detection accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9733\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.96      1.00      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.94      0.93      0.93       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4435, Accuracy: 0.8542, F1 Micro: 0.8542, F1 Macro: 0.8045\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.308, Accuracy: 0.8721, F1 Micro: 0.8721, F1 Macro: 0.8316\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2349, Accuracy: 0.8965, F1 Micro: 0.8965, F1 Macro: 0.8654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.169, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.879\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1262, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.8863\n",
      "Epoch 6/10, Train Loss: 0.1136, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8798\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0683, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.8877\n",
      "Epoch 8/10, Train Loss: 0.0788, Accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.8836\n",
      "Epoch 9/10, Train Loss: 0.041, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8855\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0381, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8891\n",
      "\n",
      "Sentiment analysis accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8891\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       758\n",
      "    positive       0.93      0.76      0.84       305\n",
      "\n",
      "    accuracy                           0.91      1063\n",
      "   macro avg       0.92      0.87      0.89      1063\n",
      "weighted avg       0.92      0.91      0.91      1063\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1148: Accuracy: 0.9543, F1 Micro: 0.9543, F1 Macro: 0.8527\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.95      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.79      0.87        86\n",
      "     neutral       0.96      1.00      0.98       475\n",
      "    positive       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.88      0.83      0.85       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.77      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.14      0.20         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.68      0.75        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.71      0.60      0.64       571\n",
      "weighted avg       0.92      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.85      0.95      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.81      0.85       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       0.67      0.36      0.47        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.82      0.72      0.75       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.84      0.86        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.48      0.60        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.82      0.76        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.77      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 240.5354425907135 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 114\n",
      "Sampling duration: 39.0890691280365 seconds\n",
      "New train size: 1262\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5131, Accuracy: 0.8099, F1 Micro: 0.8927, F1 Macro: 0.8855\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4122, Accuracy: 0.8856, F1 Micro: 0.9323, F1 Macro: 0.9272\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.302, Accuracy: 0.9325, F1 Micro: 0.9589, F1 Macro: 0.9563\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2362, Accuracy: 0.9432, F1 Micro: 0.9653, F1 Macro: 0.963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1973, Accuracy: 0.9531, F1 Micro: 0.9711, F1 Macro: 0.9689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1608, Accuracy: 0.9538, F1 Micro: 0.9715, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1341, Accuracy: 0.9585, F1 Micro: 0.9743, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1189, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9735\n",
      "Epoch 9/10, Train Loss: 0.1027, Accuracy: 0.959, F1 Micro: 0.9747, F1 Macro: 0.9727\n",
      "Epoch 10/10, Train Loss: 0.0895, Accuracy: 0.9583, F1 Micro: 0.9741, F1 Macro: 0.9714\n",
      "\n",
      "Aspect detection accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9735\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4615, Accuracy: 0.8614, F1 Micro: 0.8614, F1 Macro: 0.8152\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2865, Accuracy: 0.8848, F1 Micro: 0.8848, F1 Macro: 0.851\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2388, Accuracy: 0.8923, F1 Micro: 0.8923, F1 Macro: 0.8626\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.164, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8785\n",
      "Epoch 5/10, Train Loss: 0.1308, Accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0789, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8786\n",
      "Epoch 7/10, Train Loss: 0.0985, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8755\n",
      "Epoch 8/10, Train Loss: 0.0646, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.051, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8806\n",
      "Epoch 10/10, Train Loss: 0.0414, Accuracy: 0.9054, F1 Micro: 0.9054, F1 Macro: 0.8759\n",
      "\n",
      "Sentiment analysis accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.94       762\n",
      "    positive       0.92      0.75      0.82       306\n",
      "\n",
      "    accuracy                           0.91      1068\n",
      "   macro avg       0.91      0.86      0.88      1068\n",
      "weighted avg       0.91      0.91      0.91      1068\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1262: Accuracy: 0.9541, F1 Micro: 0.9541, F1 Macro: 0.8337\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      0.94      0.96        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.98      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.87      0.78      0.82       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.78      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.78      0.75      0.77       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.84      0.63      0.72        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.54      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.89       200\n",
      "     neutral       0.93      0.93      0.93       315\n",
      "    positive       0.86      0.96      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.83      0.86       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.74      0.78       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.84      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.55      0.64        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.68      0.76      0.72        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.81      0.77      0.78       571\n",
      "weighted avg       0.96      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.88      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 255.51844453811646 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 103\n",
      "Sampling duration: 35.464704275131226 seconds\n",
      "New train size: 1365\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5132, Accuracy: 0.8102, F1 Micro: 0.8932, F1 Macro: 0.8868\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4133, Accuracy: 0.8906, F1 Micro: 0.9353, F1 Macro: 0.9309\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2871, Accuracy: 0.9321, F1 Micro: 0.9588, F1 Macro: 0.9562\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2244, Accuracy: 0.9443, F1 Micro: 0.9659, F1 Macro: 0.9638\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1796, Accuracy: 0.9517, F1 Micro: 0.9703, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1506, Accuracy: 0.9523, F1 Micro: 0.9705, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1381, Accuracy: 0.9585, F1 Micro: 0.9743, F1 Macro: 0.9718\n",
      "Epoch 8/10, Train Loss: 0.1103, Accuracy: 0.958, F1 Micro: 0.974, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0972, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9741\n",
      "Epoch 10/10, Train Loss: 0.0858, Accuracy: 0.9597, F1 Micro: 0.975, F1 Macro: 0.9725\n",
      "\n",
      "Aspect detection accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4237, Accuracy: 0.847, F1 Micro: 0.847, F1 Macro: 0.806\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2731, Accuracy: 0.871, F1 Micro: 0.871, F1 Macro: 0.8279\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2234, Accuracy: 0.8977, F1 Micro: 0.8977, F1 Macro: 0.8687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1685, Accuracy: 0.8995, F1 Micro: 0.8995, F1 Macro: 0.869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1268, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8789\n",
      "Epoch 6/10, Train Loss: 0.0958, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8789\n",
      "Epoch 7/10, Train Loss: 0.0749, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8745\n",
      "Epoch 8/10, Train Loss: 0.0665, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8764\n",
      "Epoch 9/10, Train Loss: 0.0429, Accuracy: 0.9032, F1 Micro: 0.9032, F1 Macro: 0.8769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0372, Accuracy: 0.9078, F1 Micro: 0.9078, F1 Macro: 0.881\n",
      "\n",
      "Sentiment analysis accuracy: 0.9078, F1 Micro: 0.9078, F1 Macro: 0.881\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       768\n",
      "    positive       0.93      0.74      0.82       317\n",
      "\n",
      "    accuracy                           0.91      1085\n",
      "   macro avg       0.92      0.86      0.88      1085\n",
      "weighted avg       0.91      0.91      0.90      1085\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1365: Accuracy: 0.9559, F1 Micro: 0.9559, F1 Macro: 0.8473\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.79      1.00      0.88        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.92      0.97      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.86      0.87       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.81      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.76      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.87      0.66      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.55      0.57       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.89       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.80      0.83       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.87      0.73      0.77       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.85      0.84        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.62      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.88      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.89      0.93       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 272.5071265697479 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 62\n",
      "Sampling duration: 32.15773892402649 seconds\n",
      "New train size: 1427\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5091, Accuracy: 0.8054, F1 Micro: 0.8917, F1 Macro: 0.8871\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3923, Accuracy: 0.9017, F1 Micro: 0.9413, F1 Macro: 0.937\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2773, Accuracy: 0.9384, F1 Micro: 0.9624, F1 Macro: 0.9597\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.216, Accuracy: 0.9464, F1 Micro: 0.9671, F1 Macro: 0.9642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1812, Accuracy: 0.9556, F1 Micro: 0.9725, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.15, Accuracy: 0.9587, F1 Micro: 0.9745, F1 Macro: 0.9723\n",
      "Epoch 7/10, Train Loss: 0.1332, Accuracy: 0.958, F1 Micro: 0.974, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1086, Accuracy: 0.9589, F1 Micro: 0.9746, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0911, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9743\n",
      "Epoch 10/10, Train Loss: 0.0812, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9732\n",
      "\n",
      "Aspect detection accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9743\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.92      0.93      0.93       317\n",
      "       linen       0.93      0.96      0.94       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4488, Accuracy: 0.8601, F1 Micro: 0.8601, F1 Macro: 0.819\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2625, Accuracy: 0.873, F1 Micro: 0.873, F1 Macro: 0.8271\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2012, Accuracy: 0.899, F1 Micro: 0.899, F1 Macro: 0.8684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1338, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8787\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0979, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8821\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0753, Accuracy: 0.9092, F1 Micro: 0.9092, F1 Macro: 0.8842\n",
      "Epoch 7/10, Train Loss: 0.0775, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8781\n",
      "Epoch 8/10, Train Loss: 0.0657, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0442, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.8858\n",
      "Epoch 10/10, Train Loss: 0.0423, Accuracy: 0.9018, F1 Micro: 0.9018, F1 Macro: 0.8716\n",
      "\n",
      "Sentiment analysis accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.8858\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       762\n",
      "    positive       0.92      0.76      0.83       317\n",
      "\n",
      "    accuracy                           0.91      1079\n",
      "   macro avg       0.91      0.87      0.89      1079\n",
      "weighted avg       0.91      0.91      0.91      1079\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1427: Accuracy: 0.9557, F1 Micro: 0.9557, F1 Macro: 0.869\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.86      0.89        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.78      0.81       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.81      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.83      0.74      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.76      0.62      0.66       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.88       200\n",
      "     neutral       0.92      0.93      0.93       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.80      0.84       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.52      0.50      0.51        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.78      0.76      0.77       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.96      0.94      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.45      0.58        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.76      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 278.72594380378723 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 86\n",
      "Sampling duration: 30.03977060317993 seconds\n",
      "New train size: 1513\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5041, Accuracy: 0.8092, F1 Micro: 0.8935, F1 Macro: 0.8888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3666, Accuracy: 0.9148, F1 Micro: 0.9488, F1 Macro: 0.9455\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2606, Accuracy: 0.9398, F1 Micro: 0.9633, F1 Macro: 0.9608\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2041, Accuracy: 0.9516, F1 Micro: 0.9701, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1651, Accuracy: 0.9569, F1 Micro: 0.9733, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1417, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.974\n",
      "Epoch 7/10, Train Loss: 0.1152, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1021, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9748\n",
      "Epoch 9/10, Train Loss: 0.0867, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0746, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9754\n",
      "\n",
      "Aspect detection accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4157, Accuracy: 0.8611, F1 Micro: 0.8611, F1 Macro: 0.8114\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2737, Accuracy: 0.8924, F1 Micro: 0.8924, F1 Macro: 0.8646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1742, Accuracy: 0.9052, F1 Micro: 0.9052, F1 Macro: 0.8782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1293, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8769\n",
      "Epoch 5/10, Train Loss: 0.1095, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0804, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.8866\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0561, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8906\n",
      "Epoch 8/10, Train Loss: 0.0435, Accuracy: 0.9006, F1 Micro: 0.9006, F1 Macro: 0.8749\n",
      "Epoch 9/10, Train Loss: 0.0434, Accuracy: 0.9034, F1 Micro: 0.9034, F1 Macro: 0.8739\n",
      "Epoch 10/10, Train Loss: 0.0453, Accuracy: 0.9043, F1 Micro: 0.9043, F1 Macro: 0.8769\n",
      "\n",
      "Sentiment analysis accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8906\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       773\n",
      "    positive       0.93      0.76      0.84       314\n",
      "\n",
      "    accuracy                           0.92      1087\n",
      "   macro avg       0.92      0.87      0.89      1087\n",
      "weighted avg       0.92      0.92      0.91      1087\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1513: Accuracy: 0.958, F1 Micro: 0.958, F1 Macro: 0.8727\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.90      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.64      0.70      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.86      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.85      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.81      0.69      0.75        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.56      0.57       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.86      0.96      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.83      0.85       162\n",
      "     neutral       0.92      0.97      0.95       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.75      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.59      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.78      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 294.587265253067 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 77\n",
      "Sampling duration: 27.369053602218628 seconds\n",
      "New train size: 1590\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5039, Accuracy: 0.8191, F1 Micro: 0.8973, F1 Macro: 0.8901\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3721, Accuracy: 0.9144, F1 Micro: 0.9484, F1 Macro: 0.9447\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2524, Accuracy: 0.9446, F1 Micro: 0.9661, F1 Macro: 0.9635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.203, Accuracy: 0.9498, F1 Micro: 0.9692, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.169, Accuracy: 0.9564, F1 Micro: 0.9731, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1458, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.117, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1023, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.975\n",
      "Epoch 9/10, Train Loss: 0.0888, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0753, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "\n",
      "Aspect detection accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.97      0.96       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.90      0.97      0.94       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4199, Accuracy: 0.8598, F1 Micro: 0.8598, F1 Macro: 0.8116\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2754, Accuracy: 0.8976, F1 Micro: 0.8976, F1 Macro: 0.8675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1648, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.8802\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1459, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8893\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0935, Accuracy: 0.9179, F1 Micro: 0.9179, F1 Macro: 0.8954\n",
      "Epoch 6/10, Train Loss: 0.0671, Accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.8918\n",
      "Epoch 7/10, Train Loss: 0.0504, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8905\n",
      "Epoch 8/10, Train Loss: 0.0509, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0392, Accuracy: 0.9197, F1 Micro: 0.9197, F1 Macro: 0.8968\n",
      "Epoch 10/10, Train Loss: 0.0327, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8905\n",
      "\n",
      "Sentiment analysis accuracy: 0.9197, F1 Micro: 0.9197, F1 Macro: 0.8968\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       771\n",
      "    positive       0.93      0.78      0.85       313\n",
      "\n",
      "    accuracy                           0.92      1084\n",
      "   macro avg       0.92      0.88      0.90      1084\n",
      "weighted avg       0.92      0.92      0.92      1084\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1590: Accuracy: 0.9574, F1 Micro: 0.9574, F1 Macro: 0.8603\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.95      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.85      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.97      0.96       496\n",
      "    positive       0.79      0.76      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.58      0.58      0.58       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.91      0.91       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.79      0.84       162\n",
      "     neutral       0.90      0.98      0.94       387\n",
      "    positive       0.60      0.27      0.37        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.80      0.68      0.72       571\n",
      "weighted avg       0.89      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.94      0.90      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.82      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.91      0.99      0.95       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 305.28321647644043 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 70\n",
      "Sampling duration: 24.59521985054016 seconds\n",
      "New train size: 1660\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4962, Accuracy: 0.829, F1 Micro: 0.9021, F1 Macro: 0.8946\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.353, Accuracy: 0.9158, F1 Micro: 0.949, F1 Macro: 0.9449\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2442, Accuracy: 0.9434, F1 Micro: 0.9654, F1 Macro: 0.9629\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1954, Accuracy: 0.951, F1 Micro: 0.9699, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1652, Accuracy: 0.9587, F1 Micro: 0.9744, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1348, Accuracy: 0.9608, F1 Micro: 0.9756, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1153, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9748\n",
      "Epoch 8/10, Train Loss: 0.0992, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.085, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9759\n",
      "Epoch 10/10, Train Loss: 0.0716, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.975\n",
      "\n",
      "Aspect detection accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3983, Accuracy: 0.8586, F1 Micro: 0.8586, F1 Macro: 0.8152\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.253, Accuracy: 0.8896, F1 Micro: 0.8896, F1 Macro: 0.8533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1709, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1366, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1011, Accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.8856\n",
      "Epoch 6/10, Train Loss: 0.0756, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8789\n",
      "Epoch 7/10, Train Loss: 0.0557, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0614, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8849\n",
      "Epoch 9/10, Train Loss: 0.0429, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.8697\n",
      "Epoch 10/10, Train Loss: 0.0379, Accuracy: 0.9033, F1 Micro: 0.9033, F1 Macro: 0.8738\n",
      "\n",
      "Sentiment analysis accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8849\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.99      0.94       779\n",
      "    positive       0.95      0.73      0.83       317\n",
      "\n",
      "    accuracy                           0.91      1096\n",
      "   macro avg       0.93      0.86      0.88      1096\n",
      "weighted avg       0.92      0.91      0.91      1096\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1660: Accuracy: 0.9587, F1 Micro: 0.9587, F1 Macro: 0.8733\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.92      0.80      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.85      0.83        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.84      0.68      0.75        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.55      0.57       571\n",
      "weighted avg       0.92      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.89       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.85      0.95      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.84      0.86       162\n",
      "     neutral       0.92      0.97      0.95       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.74      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.88      0.87        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.72      0.76        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.83      0.86       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 312.7815520763397 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 52\n",
      "Sampling duration: 22.173887729644775 seconds\n",
      "New train size: 1712\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4923, Accuracy: 0.8274, F1 Micro: 0.902, F1 Macro: 0.8963\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3464, Accuracy: 0.9217, F1 Micro: 0.9522, F1 Macro: 0.9479\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2428, Accuracy: 0.9411, F1 Micro: 0.9642, F1 Macro: 0.9622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.184, Accuracy: 0.954, F1 Micro: 0.9717, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1496, Accuracy: 0.9564, F1 Micro: 0.9732, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1327, Accuracy: 0.9594, F1 Micro: 0.9749, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1126, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9754\n",
      "Epoch 8/10, Train Loss: 0.0941, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9753\n",
      "Epoch 9/10, Train Loss: 0.0792, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.975\n",
      "Epoch 10/10, Train Loss: 0.0654, Accuracy: 0.9639, F1 Micro: 0.9775, F1 Macro: 0.9753\n",
      "\n",
      "Aspect detection accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.95      0.92      0.94       317\n",
      "       linen       0.92      0.98      0.95       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.391, Accuracy: 0.8573, F1 Micro: 0.8573, F1 Macro: 0.8091\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2334, Accuracy: 0.8902, F1 Micro: 0.8902, F1 Macro: 0.8556\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1818, Accuracy: 0.8939, F1 Micro: 0.8939, F1 Macro: 0.8581\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1344, Accuracy: 0.8984, F1 Micro: 0.8984, F1 Macro: 0.8678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0949, Accuracy: 0.9058, F1 Micro: 0.9058, F1 Macro: 0.8768\n",
      "Epoch 6/10, Train Loss: 0.0816, Accuracy: 0.903, F1 Micro: 0.903, F1 Macro: 0.8739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0736, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8848\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0468, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8861\n",
      "Epoch 9/10, Train Loss: 0.0345, Accuracy: 0.9085, F1 Micro: 0.9085, F1 Macro: 0.8819\n",
      "Epoch 10/10, Train Loss: 0.0334, Accuracy: 0.9058, F1 Micro: 0.9058, F1 Macro: 0.8793\n",
      "\n",
      "Sentiment analysis accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8861\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       775\n",
      "    positive       0.94      0.75      0.83       318\n",
      "\n",
      "    accuracy                           0.91      1093\n",
      "   macro avg       0.92      0.86      0.89      1093\n",
      "weighted avg       0.91      0.91      0.91      1093\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1712: Accuracy: 0.9583, F1 Micro: 0.9583, F1 Macro: 0.87\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.91      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.82      0.93      0.86       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.86      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.91      0.90       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.81      0.85       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       0.75      0.41      0.53        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.73      0.78       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.66      0.76        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.80      0.94      0.86        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.86      0.87       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 317.10115218162537 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 58\n",
      "Sampling duration: 20.304869890213013 seconds\n",
      "New train size: 1770\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4876, Accuracy: 0.8342, F1 Micro: 0.9057, F1 Macro: 0.901\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3331, Accuracy: 0.9253, F1 Micro: 0.9549, F1 Macro: 0.952\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2316, Accuracy: 0.9467, F1 Micro: 0.9674, F1 Macro: 0.9654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1818, Accuracy: 0.9523, F1 Micro: 0.9706, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1497, Accuracy: 0.9566, F1 Micro: 0.9731, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1277, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1063, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0881, Accuracy: 0.9668, F1 Micro: 0.9794, F1 Macro: 0.9774\n",
      "Epoch 9/10, Train Loss: 0.0729, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "Epoch 10/10, Train Loss: 0.0654, Accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9764\n",
      "\n",
      "Aspect detection accuracy: 0.9668, F1 Micro: 0.9794, F1 Macro: 0.9774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3888, Accuracy: 0.8662, F1 Micro: 0.8662, F1 Macro: 0.8195\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2299, Accuracy: 0.8891, F1 Micro: 0.8891, F1 Macro: 0.852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1564, Accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.8821\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1312, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.8874\n",
      "Epoch 5/10, Train Loss: 0.1065, Accuracy: 0.89, F1 Micro: 0.89, F1 Macro: 0.8635\n",
      "Epoch 6/10, Train Loss: 0.0666, Accuracy: 0.9047, F1 Micro: 0.9047, F1 Macro: 0.88\n",
      "Epoch 7/10, Train Loss: 0.0667, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8871\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0361, Accuracy: 0.9203, F1 Micro: 0.9203, F1 Macro: 0.897\n",
      "Epoch 9/10, Train Loss: 0.0244, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8878\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0387, Accuracy: 0.9212, F1 Micro: 0.9212, F1 Macro: 0.8974\n",
      "\n",
      "Sentiment analysis accuracy: 0.9212, F1 Micro: 0.9212, F1 Macro: 0.8974\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       781\n",
      "    positive       0.94      0.77      0.85       310\n",
      "\n",
      "    accuracy                           0.92      1091\n",
      "   macro avg       0.93      0.88      0.90      1091\n",
      "weighted avg       0.92      0.92      0.92      1091\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1770: Accuracy: 0.9613, F1 Micro: 0.9613, F1 Macro: 0.88\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.93      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.84      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.79      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.89      0.71      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.56      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.88       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.76      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.62      0.73        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.85      0.86       571\n",
      "weighted avg       0.98      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.96      0.96        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.93      0.96       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 335.61237120628357 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 52\n",
      "Sampling duration: 18.223987579345703 seconds\n",
      "New train size: 1822\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4876, Accuracy: 0.8368, F1 Micro: 0.9069, F1 Macro: 0.9016\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3305, Accuracy: 0.9311, F1 Micro: 0.9579, F1 Macro: 0.9551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2322, Accuracy: 0.946, F1 Micro: 0.9669, F1 Macro: 0.965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1796, Accuracy: 0.9559, F1 Micro: 0.9728, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1495, Accuracy: 0.9583, F1 Micro: 0.9742, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1292, Accuracy: 0.9616, F1 Micro: 0.9763, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1055, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0836, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0757, Accuracy: 0.9649, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0639, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9763\n",
      "\n",
      "Aspect detection accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3809, Accuracy: 0.8668, F1 Micro: 0.8668, F1 Macro: 0.8241\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.231, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.8721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.179, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1077, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0866, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.882\n",
      "Epoch 6/10, Train Loss: 0.0564, Accuracy: 0.9042, F1 Micro: 0.9042, F1 Macro: 0.8733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.037, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8901\n",
      "Epoch 8/10, Train Loss: 0.0431, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8791\n",
      "Epoch 9/10, Train Loss: 0.0399, Accuracy: 0.9133, F1 Micro: 0.9133, F1 Macro: 0.8873\n",
      "Epoch 10/10, Train Loss: 0.016, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8849\n",
      "\n",
      "Sentiment analysis accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8901\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       778\n",
      "    positive       0.92      0.77      0.84       318\n",
      "\n",
      "    accuracy                           0.91      1096\n",
      "   macro avg       0.92      0.87      0.89      1096\n",
      "weighted avg       0.91      0.91      0.91      1096\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1822: Accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.863\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.82      0.69      0.75        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.56      0.57       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.89      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.64      0.41      0.50        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.82      0.74      0.77       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.90      0.97      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.84      0.86       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.91      0.92        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.62      0.83      0.71         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.85      0.91      0.88       571\n",
      "weighted avg       0.99      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 341.555814743042 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 16.570268392562866 seconds\n",
      "New train size: 1872\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.486, Accuracy: 0.845, F1 Micro: 0.9107, F1 Macro: 0.9052\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3228, Accuracy: 0.9325, F1 Micro: 0.9589, F1 Macro: 0.9566\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2205, Accuracy: 0.9469, F1 Micro: 0.9675, F1 Macro: 0.9654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1718, Accuracy: 0.9517, F1 Micro: 0.9703, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1449, Accuracy: 0.9575, F1 Micro: 0.9738, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1208, Accuracy: 0.9595, F1 Micro: 0.975, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1005, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0838, Accuracy: 0.9644, F1 Micro: 0.9778, F1 Macro: 0.9756\n",
      "Epoch 9/10, Train Loss: 0.0709, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.062, Accuracy: 0.9674, F1 Micro: 0.9797, F1 Macro: 0.9775\n",
      "\n",
      "Aspect detection accuracy: 0.9674, F1 Micro: 0.9797, F1 Macro: 0.9775\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.98      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3795, Accuracy: 0.8685, F1 Micro: 0.8685, F1 Macro: 0.8253\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2282, Accuracy: 0.9018, F1 Micro: 0.9018, F1 Macro: 0.8738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1466, Accuracy: 0.909, F1 Micro: 0.909, F1 Macro: 0.8843\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1065, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.8883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0812, Accuracy: 0.9153, F1 Micro: 0.9153, F1 Macro: 0.8929\n",
      "Epoch 6/10, Train Loss: 0.0632, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.8881\n",
      "Epoch 7/10, Train Loss: 0.0463, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8833\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0374, Accuracy: 0.9207, F1 Micro: 0.9207, F1 Macro: 0.8982\n",
      "Epoch 9/10, Train Loss: 0.034, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.8959\n",
      "Epoch 10/10, Train Loss: 0.0427, Accuracy: 0.9162, F1 Micro: 0.9162, F1 Macro: 0.8935\n",
      "\n",
      "Sentiment analysis accuracy: 0.9207, F1 Micro: 0.9207, F1 Macro: 0.8982\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       785\n",
      "    positive       0.95      0.77      0.85       325\n",
      "\n",
      "    accuracy                           0.92      1110\n",
      "   macro avg       0.93      0.88      0.90      1110\n",
      "weighted avg       0.92      0.92      0.92      1110\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1872: Accuracy: 0.9618, F1 Micro: 0.9618, F1 Macro: 0.8898\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.85      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.83      0.79      0.81        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.69      0.74       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.89      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.88       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.77      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.84      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.69      0.77        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.86      0.87       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 343.8483798503876 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 14.754598140716553 seconds\n",
      "New train size: 1922\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4789, Accuracy: 0.8542, F1 Micro: 0.9145, F1 Macro: 0.9064\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3059, Accuracy: 0.9335, F1 Micro: 0.9593, F1 Macro: 0.9561\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2169, Accuracy: 0.9488, F1 Micro: 0.9686, F1 Macro: 0.9661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1727, Accuracy: 0.9564, F1 Micro: 0.9731, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1389, Accuracy: 0.9599, F1 Micro: 0.9752, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1167, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0981, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0835, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0702, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.976\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0595, Accuracy: 0.9663, F1 Micro: 0.9791, F1 Macro: 0.9768\n",
      "\n",
      "Aspect detection accuracy: 0.9663, F1 Micro: 0.9791, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.95      0.92      0.93       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3598, Accuracy: 0.8454, F1 Micro: 0.8454, F1 Macro: 0.8183\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2527, Accuracy: 0.8911, F1 Micro: 0.8911, F1 Macro: 0.8531\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1588, Accuracy: 0.9021, F1 Micro: 0.9021, F1 Macro: 0.8692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1056, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.885\n",
      "Epoch 5/10, Train Loss: 0.0803, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8821\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0713, Accuracy: 0.914, F1 Micro: 0.914, F1 Macro: 0.8885\n",
      "Epoch 7/10, Train Loss: 0.0528, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0414, Accuracy: 0.9158, F1 Micro: 0.9158, F1 Macro: 0.8908\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0326, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.8945\n",
      "Epoch 10/10, Train Loss: 0.0279, Accuracy: 0.9131, F1 Micro: 0.9131, F1 Macro: 0.8884\n",
      "\n",
      "Sentiment analysis accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.8945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       780\n",
      "    positive       0.93      0.77      0.84       313\n",
      "\n",
      "    accuracy                           0.92      1093\n",
      "   macro avg       0.92      0.87      0.89      1093\n",
      "weighted avg       0.92      0.92      0.92      1093\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1922: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.8787\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.83      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.89      0.72      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.57      0.59       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.89       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.88       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.67      0.55      0.60        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.84      0.79      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.84      0.85        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.96      0.96        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 352.565536737442 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 13.817463874816895 seconds\n",
      "New train size: 1972\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4787, Accuracy: 0.8616, F1 Micro: 0.9195, F1 Macro: 0.9147\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3031, Accuracy: 0.9339, F1 Micro: 0.9598, F1 Macro: 0.9575\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2138, Accuracy: 0.9451, F1 Micro: 0.9663, F1 Macro: 0.9638\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1714, Accuracy: 0.9561, F1 Micro: 0.9729, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1399, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9746\n",
      "Epoch 6/10, Train Loss: 0.1138, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.095, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9757\n",
      "Epoch 8/10, Train Loss: 0.0823, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9754\n",
      "Epoch 9/10, Train Loss: 0.0693, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0607, Accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3566, Accuracy: 0.8698, F1 Micro: 0.8698, F1 Macro: 0.831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2335, Accuracy: 0.8818, F1 Micro: 0.8818, F1 Macro: 0.8419\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1618, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.8727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0967, Accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.8876\n",
      "Epoch 5/10, Train Loss: 0.0798, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.8875\n",
      "Epoch 6/10, Train Loss: 0.0578, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8813\n",
      "Epoch 7/10, Train Loss: 0.0449, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.033, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.8917\n",
      "Epoch 9/10, Train Loss: 0.0303, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0269, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.892\n",
      "\n",
      "Sentiment analysis accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.892\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       774\n",
      "    positive       0.93      0.77      0.84       317\n",
      "\n",
      "    accuracy                           0.92      1091\n",
      "   macro avg       0.92      0.87      0.89      1091\n",
      "weighted avg       0.92      0.92      0.91      1091\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1972: Accuracy: 0.9594, F1 Micro: 0.9594, F1 Macro: 0.8725\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.83      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.75      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.77      0.62      0.66       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.89       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.76      0.81       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.84      0.87        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.90      0.97      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.62      0.73        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.85      0.86       571\n",
      "weighted avg       0.98      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.87      0.90        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.71      0.83      0.77         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.90      0.89       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.91      0.99      0.95       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 353.4070110321045 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint:1997 \n",
      "Acquired samples: 25\n",
      "Sampling duration: 11.410505771636963 seconds\n",
      "New train size: 1997\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4802, Accuracy: 0.8687, F1 Micro: 0.9231, F1 Macro: 0.9167\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3035, Accuracy: 0.9332, F1 Micro: 0.9594, F1 Macro: 0.9571\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2168, Accuracy: 0.95, F1 Micro: 0.9693, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1708, Accuracy: 0.9561, F1 Micro: 0.9729, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1386, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9738\n",
      "Epoch 6/10, Train Loss: 0.1145, Accuracy: 0.9594, F1 Micro: 0.9749, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0982, Accuracy: 0.9618, F1 Micro: 0.9764, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.08, Accuracy: 0.9653, F1 Micro: 0.9785, F1 Macro: 0.9766\n",
      "Epoch 9/10, Train Loss: 0.0683, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9766\n",
      "Epoch 10/10, Train Loss: 0.0574, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9757\n",
      "\n",
      "Aspect detection accuracy: 0.9653, F1 Micro: 0.9785, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.95      0.94      0.94       317\n",
      "       linen       0.92      0.98      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3644, Accuracy: 0.865, F1 Micro: 0.865, F1 Macro: 0.8138\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2091, Accuracy: 0.9022, F1 Micro: 0.9022, F1 Macro: 0.8709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1495, Accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.8873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1032, Accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.8884\n",
      "Epoch 5/10, Train Loss: 0.0782, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0519, Accuracy: 0.9209, F1 Micro: 0.9209, F1 Macro: 0.8965\n",
      "Epoch 7/10, Train Loss: 0.0448, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.8903\n",
      "Epoch 8/10, Train Loss: 0.0392, Accuracy: 0.9181, F1 Micro: 0.9181, F1 Macro: 0.8927\n",
      "Epoch 9/10, Train Loss: 0.0284, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8859\n",
      "Epoch 10/10, Train Loss: 0.0302, Accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.8807\n",
      "\n",
      "Sentiment analysis accuracy: 0.9209, F1 Micro: 0.9209, F1 Macro: 0.8965\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       771\n",
      "    positive       0.94      0.77      0.85       303\n",
      "\n",
      "    accuracy                           0.92      1074\n",
      "   macro avg       0.93      0.88      0.90      1074\n",
      "weighted avg       0.92      0.92      0.92      1074\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1997: Accuracy: 0.9592, F1 Micro: 0.9592, F1 Macro: 0.8721\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.85      0.90        86\n",
      "     neutral       0.97      1.00      0.99       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.92      0.78      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.84        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.84      0.68      0.75        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.55      0.57       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.90      0.91       200\n",
      "     neutral       0.95      0.94      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.81      0.85       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.75      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.85        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.94      0.91      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.94      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.82      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.96      0.96        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.93      0.96       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 353.6987602710724 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 10.582374572753906 seconds\n",
      "New train size: 2047\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4713, Accuracy: 0.8755, F1 Micro: 0.9267, F1 Macro: 0.9208\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2947, Accuracy: 0.9366, F1 Micro: 0.9612, F1 Macro: 0.9583\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2098, Accuracy: 0.947, F1 Micro: 0.9676, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1643, Accuracy: 0.9573, F1 Micro: 0.9737, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.138, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1122, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9755\n",
      "Epoch 7/10, Train Loss: 0.0964, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0806, Accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9766\n",
      "Epoch 9/10, Train Loss: 0.0692, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9752\n",
      "Epoch 10/10, Train Loss: 0.0569, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.91      0.96      0.93       317\n",
      "       linen       0.95      0.97      0.96       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3394, Accuracy: 0.8718, F1 Micro: 0.8718, F1 Macro: 0.8271\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1967, Accuracy: 0.8976, F1 Micro: 0.8976, F1 Macro: 0.8653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1405, Accuracy: 0.9133, F1 Micro: 0.9133, F1 Macro: 0.8871\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1027, Accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.8908\n",
      "Epoch 5/10, Train Loss: 0.0787, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.8814\n",
      "Epoch 6/10, Train Loss: 0.0569, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0573, Accuracy: 0.9207, F1 Micro: 0.9207, F1 Macro: 0.8977\n",
      "Epoch 8/10, Train Loss: 0.0266, Accuracy: 0.9197, F1 Micro: 0.9197, F1 Macro: 0.8947\n",
      "Epoch 9/10, Train Loss: 0.0257, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8871\n",
      "Epoch 10/10, Train Loss: 0.036, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8902\n",
      "\n",
      "Sentiment analysis accuracy: 0.9207, F1 Micro: 0.9207, F1 Macro: 0.8977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       774\n",
      "    positive       0.93      0.78      0.85       310\n",
      "\n",
      "    accuracy                           0.92      1084\n",
      "   macro avg       0.92      0.88      0.90      1084\n",
      "weighted avg       0.92      0.92      0.92      1084\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2047: Accuracy: 0.9602, F1 Micro: 0.9602, F1 Macro: 0.8765\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.87      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.86      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.94      0.94       571\n",
      "weighted avg       0.96      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.89      0.75      0.82        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.62      0.58      0.60       571\n",
      "weighted avg       0.93      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.83      0.88       200\n",
      "     neutral       0.91      0.96      0.93       315\n",
      "    positive       0.88      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.89       162\n",
      "     neutral       0.94      0.97      0.96       387\n",
      "    positive       0.77      0.45      0.57        22\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.87      0.77      0.81       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.84      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.89      0.96      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.84      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 354.5262038707733 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 8.83902621269226 seconds\n",
      "New train size: 2097\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4685, Accuracy: 0.8691, F1 Micro: 0.9231, F1 Macro: 0.9175\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2863, Accuracy: 0.9359, F1 Micro: 0.961, F1 Macro: 0.9586\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1996, Accuracy: 0.9488, F1 Micro: 0.9685, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1635, Accuracy: 0.9552, F1 Micro: 0.9723, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.132, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1086, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9758\n",
      "Epoch 7/10, Train Loss: 0.0914, Accuracy: 0.9637, F1 Micro: 0.9774, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0764, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9762\n",
      "Epoch 9/10, Train Loss: 0.0655, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0575, Accuracy: 0.9663, F1 Micro: 0.979, F1 Macro: 0.9769\n",
      "\n",
      "Aspect detection accuracy: 0.9663, F1 Micro: 0.979, F1 Macro: 0.9769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.98      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3669, Accuracy: 0.8643, F1 Micro: 0.8643, F1 Macro: 0.817\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2066, Accuracy: 0.9021, F1 Micro: 0.9021, F1 Macro: 0.8747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1353, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8859\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1009, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8852\n",
      "Epoch 5/10, Train Loss: 0.0747, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0692, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8933\n",
      "Epoch 7/10, Train Loss: 0.037, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.8758\n",
      "Epoch 8/10, Train Loss: 0.0316, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8851\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0298, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8931\n",
      "Epoch 10/10, Train Loss: 0.0203, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8788\n",
      "\n",
      "Sentiment analysis accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8931\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       786\n",
      "    positive       0.94      0.76      0.84       327\n",
      "\n",
      "    accuracy                           0.92      1113\n",
      "   macro avg       0.92      0.87      0.89      1113\n",
      "weighted avg       0.92      0.92      0.91      1113\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2097: Accuracy: 0.9609, F1 Micro: 0.9609, F1 Macro: 0.8804\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.88      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.86      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.76      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.58      0.59       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.65      0.50      0.56        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.82      0.77      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.94      0.96      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.66      0.76        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.80      0.94      0.86        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.86      0.87       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 370.38047456741333 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 7.2280285358428955 seconds\n",
      "New train size: 2147\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4616, Accuracy: 0.8795, F1 Micro: 0.929, F1 Macro: 0.9241\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2816, Accuracy: 0.9375, F1 Micro: 0.9619, F1 Macro: 0.9598\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1969, Accuracy: 0.9484, F1 Micro: 0.9684, F1 Macro: 0.9667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1553, Accuracy: 0.9568, F1 Micro: 0.9734, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1302, Accuracy: 0.9616, F1 Micro: 0.9763, F1 Macro: 0.9744\n",
      "Epoch 6/10, Train Loss: 0.1072, Accuracy: 0.9597, F1 Micro: 0.9752, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0873, Accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9766\n",
      "Epoch 8/10, Train Loss: 0.0737, Accuracy: 0.9651, F1 Micro: 0.9784, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0624, Accuracy: 0.9663, F1 Micro: 0.979, F1 Macro: 0.977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0506, Accuracy: 0.9668, F1 Micro: 0.9794, F1 Macro: 0.9773\n",
      "\n",
      "Aspect detection accuracy: 0.9668, F1 Micro: 0.9794, F1 Macro: 0.9773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.98      0.98       496\n",
      "     general       0.96      0.97      0.97       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.93      0.98      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3464, Accuracy: 0.8692, F1 Micro: 0.8692, F1 Macro: 0.8212\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1927, Accuracy: 0.9012, F1 Micro: 0.9012, F1 Macro: 0.8682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1467, Accuracy: 0.9131, F1 Micro: 0.9131, F1 Macro: 0.8869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1062, Accuracy: 0.9167, F1 Micro: 0.9167, F1 Macro: 0.894\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0825, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.8967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0562, Accuracy: 0.9241, F1 Micro: 0.9241, F1 Macro: 0.9018\n",
      "Epoch 7/10, Train Loss: 0.0492, Accuracy: 0.9195, F1 Micro: 0.9195, F1 Macro: 0.8991\n",
      "Epoch 8/10, Train Loss: 0.0417, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8862\n",
      "Epoch 9/10, Train Loss: 0.0301, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8789\n",
      "Epoch 10/10, Train Loss: 0.0351, Accuracy: 0.9186, F1 Micro: 0.9186, F1 Macro: 0.895\n",
      "\n",
      "Sentiment analysis accuracy: 0.9241, F1 Micro: 0.9241, F1 Macro: 0.9018\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       778\n",
      "    positive       0.95      0.78      0.86       315\n",
      "\n",
      "    accuracy                           0.92      1093\n",
      "   macro avg       0.93      0.88      0.90      1093\n",
      "weighted avg       0.93      0.92      0.92      1093\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2147: Accuracy: 0.9609, F1 Micro: 0.9609, F1 Macro: 0.8864\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.88      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.86      0.87       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.85        78\n",
      "     neutral       0.98      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.29      0.36         7\n",
      "     neutral       0.96      0.97      0.97       496\n",
      "    positive       0.80      0.78      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.76      0.68      0.71       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.87      0.89       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87       162\n",
      "     neutral       0.93      0.98      0.95       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.74      0.79       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.66      0.73        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.76      0.76        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 375.14478969573975 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 5.6326422691345215 seconds\n",
      "New train size: 2197\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4534, Accuracy: 0.8755, F1 Micro: 0.9266, F1 Macro: 0.9198\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2737, Accuracy: 0.9387, F1 Micro: 0.9626, F1 Macro: 0.9605\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1915, Accuracy: 0.953, F1 Micro: 0.9711, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1569, Accuracy: 0.955, F1 Micro: 0.9723, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1251, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1062, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0845, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0739, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0613, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0516, Accuracy: 0.9663, F1 Micro: 0.9791, F1 Macro: 0.9769\n",
      "\n",
      "Aspect detection accuracy: 0.9663, F1 Micro: 0.9791, F1 Macro: 0.9769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.92      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3478, Accuracy: 0.8487, F1 Micro: 0.8487, F1 Macro: 0.7787\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2168, Accuracy: 0.8952, F1 Micro: 0.8952, F1 Macro: 0.8626\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1342, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.089, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.8875\n",
      "Epoch 5/10, Train Loss: 0.0613, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.8844\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0468, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.8926\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0339, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.8942\n",
      "Epoch 8/10, Train Loss: 0.0258, Accuracy: 0.9152, F1 Micro: 0.9152, F1 Macro: 0.8897\n",
      "Epoch 9/10, Train Loss: 0.0285, Accuracy: 0.9161, F1 Micro: 0.9161, F1 Macro: 0.8897\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0146, Accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.8981\n",
      "\n",
      "Sentiment analysis accuracy: 0.9216, F1 Micro: 0.9216, F1 Macro: 0.8981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       782\n",
      "    positive       0.95      0.77      0.85       315\n",
      "\n",
      "    accuracy                           0.92      1097\n",
      "   macro avg       0.93      0.88      0.90      1097\n",
      "weighted avg       0.92      0.92      0.92      1097\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2197: Accuracy: 0.9613, F1 Micro: 0.9613, F1 Macro: 0.893\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.87      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.86      0.87       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.83      0.85        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.61      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.91      0.90       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.80      0.55      0.65        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.87      0.79      0.83       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 387.8404200077057 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 3.7983243465423584 seconds\n",
      "New train size: 2247\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4592, Accuracy: 0.883, F1 Micro: 0.9309, F1 Macro: 0.9259\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2732, Accuracy: 0.9391, F1 Micro: 0.9627, F1 Macro: 0.9604\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1871, Accuracy: 0.9507, F1 Micro: 0.9697, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.15, Accuracy: 0.9566, F1 Micro: 0.9732, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1204, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1036, Accuracy: 0.9637, F1 Micro: 0.9774, F1 Macro: 0.9753\n",
      "Epoch 7/10, Train Loss: 0.0848, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0731, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0585, Accuracy: 0.9661, F1 Micro: 0.979, F1 Macro: 0.9768\n",
      "Epoch 10/10, Train Loss: 0.0497, Accuracy: 0.9653, F1 Micro: 0.9785, F1 Macro: 0.9763\n",
      "\n",
      "Aspect detection accuracy: 0.9661, F1 Micro: 0.979, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3552, Accuracy: 0.87, F1 Micro: 0.87, F1 Macro: 0.8333\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2069, Accuracy: 0.9002, F1 Micro: 0.9002, F1 Macro: 0.8702\n",
      "Epoch 3/10, Train Loss: 0.1386, Accuracy: 0.8965, F1 Micro: 0.8965, F1 Macro: 0.8648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1037, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.8861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0782, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.8874\n",
      "Epoch 6/10, Train Loss: 0.0484, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0458, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8879\n",
      "Epoch 8/10, Train Loss: 0.0418, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8804\n",
      "Epoch 9/10, Train Loss: 0.0287, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8797\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0217, Accuracy: 0.9158, F1 Micro: 0.9158, F1 Macro: 0.8908\n",
      "\n",
      "Sentiment analysis accuracy: 0.9158, F1 Micro: 0.9158, F1 Macro: 0.8908\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       781\n",
      "    positive       0.92      0.77      0.84       311\n",
      "\n",
      "    accuracy                           0.92      1092\n",
      "   macro avg       0.92      0.87      0.89      1092\n",
      "weighted avg       0.92      0.92      0.91      1092\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2247: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.8905\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.65      0.73       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.84      0.86       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.67      0.55      0.60        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.83      0.78      0.81       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.62      0.73        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.85      0.86       571\n",
      "weighted avg       0.98      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 385.3093903064728 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 36\n",
      "Sampling duration: 2.0841970443725586 seconds\n",
      "New train size: 2283\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4415, Accuracy: 0.8847, F1 Micro: 0.9319, F1 Macro: 0.927\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.257, Accuracy: 0.9432, F1 Micro: 0.9652, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1811, Accuracy: 0.9493, F1 Micro: 0.9689, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1462, Accuracy: 0.9554, F1 Micro: 0.9725, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1189, Accuracy: 0.962, F1 Micro: 0.9765, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0995, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0848, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0682, Accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.9765\n",
      "Epoch 9/10, Train Loss: 0.0574, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9762\n",
      "Epoch 10/10, Train Loss: 0.0489, Accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3289, Accuracy: 0.8792, F1 Micro: 0.8792, F1 Macro: 0.8458\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1988, Accuracy: 0.9039, F1 Micro: 0.9039, F1 Macro: 0.8761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1413, Accuracy: 0.9131, F1 Micro: 0.9131, F1 Macro: 0.8882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1031, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.8942\n",
      "Epoch 5/10, Train Loss: 0.0678, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8848\n",
      "Epoch 6/10, Train Loss: 0.0485, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.878\n",
      "Epoch 7/10, Train Loss: 0.0371, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8842\n",
      "Epoch 8/10, Train Loss: 0.036, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.878\n",
      "Epoch 9/10, Train Loss: 0.0275, Accuracy: 0.9113, F1 Micro: 0.9113, F1 Macro: 0.8853\n",
      "Epoch 10/10, Train Loss: 0.0233, Accuracy: 0.9131, F1 Micro: 0.9131, F1 Macro: 0.8879\n",
      "\n",
      "Sentiment analysis accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.8942\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.94       779\n",
      "    positive       0.92      0.78      0.84       314\n",
      "\n",
      "    accuracy                           0.92      1093\n",
      "   macro avg       0.92      0.88      0.89      1093\n",
      "weighted avg       0.92      0.92      0.92      1093\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2283: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.8732\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.81      0.85        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.76      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.75      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.77      0.62      0.66       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       200\n",
      "     neutral       0.93      0.93      0.93       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.69      0.50      0.58        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.83      0.77      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.82      0.86        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.82      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 386.57363653182983 s\n",
      "Total runtime: 8473.180364847183 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffa2e08",
   "metadata": {
    "papermill": {
     "duration": 0.011772,
     "end_time": "2025-03-31T04:28:08.410632",
     "exception": false,
     "start_time": "2025-03-31T04:28:08.398860",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aff5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 3\n",
      "Random seed: 14\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6341, Accuracy: 0.7974, F1 Micro: 0.8859, F1 Macro: 0.8768\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5134, Accuracy: 0.8014, F1 Micro: 0.8897, F1 Macro: 0.8853\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4829, Accuracy: 0.8017, F1 Micro: 0.8897, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4632, Accuracy: 0.8045, F1 Micro: 0.8906, F1 Macro: 0.8847\n",
      "Epoch 5/10, Train Loss: 0.4642, Accuracy: 0.8047, F1 Micro: 0.8903, F1 Macro: 0.8835\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4501, Accuracy: 0.8075, F1 Micro: 0.891, F1 Macro: 0.8822\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.451, Accuracy: 0.8149, F1 Micro: 0.8947, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.4034, Accuracy: 0.8273, F1 Micro: 0.9007, F1 Macro: 0.892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3957, Accuracy: 0.8345, F1 Micro: 0.9041, F1 Macro: 0.8954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3562, Accuracy: 0.8448, F1 Micro: 0.9097, F1 Macro: 0.9016\n",
      "\n",
      "Aspect detection accuracy: 0.8448, F1 Micro: 0.9097, F1 Macro: 0.9016\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.83      1.00      0.90       462\n",
      "   air_panas       0.83      1.00      0.91       480\n",
      "         bau       0.86      1.00      0.93       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.70      0.75      0.73       317\n",
      "       linen       0.77      0.94      0.85       392\n",
      "     service       0.90      0.98      0.94       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.90      1.00      0.95       516\n",
      "        wifi       0.88      1.00      0.94       498\n",
      "\n",
      "   micro avg       0.85      0.98      0.91      4614\n",
      "   macro avg       0.85      0.97      0.90      4614\n",
      "weighted avg       0.85      0.98      0.91      4614\n",
      " samples avg       0.85      0.97      0.91      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.7316, Accuracy: 0.5412, F1 Micro: 0.5412, F1 Macro: 0.3512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.612, Accuracy: 0.5412, F1 Micro: 0.5412, F1 Macro: 0.3512\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.5437, Accuracy: 0.5645, F1 Micro: 0.5645, F1 Macro: 0.4185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.5596, Accuracy: 0.5751, F1 Micro: 0.5751, F1 Macro: 0.4522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4998, Accuracy: 0.5877, F1 Micro: 0.5877, F1 Macro: 0.5659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.478, Accuracy: 0.6025, F1 Micro: 0.6025, F1 Macro: 0.5626\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3806, Accuracy: 0.666, F1 Micro: 0.666, F1 Macro: 0.6564\n",
      "Epoch 8/10, Train Loss: 0.3522, Accuracy: 0.6195, F1 Micro: 0.6195, F1 Macro: 0.5823\n",
      "Epoch 9/10, Train Loss: 0.3548, Accuracy: 0.6575, F1 Micro: 0.6575, F1 Macro: 0.6482\n",
      "Epoch 10/10, Train Loss: 0.3088, Accuracy: 0.6237, F1 Micro: 0.6237, F1 Macro: 0.6009\n",
      "\n",
      "Sentiment analysis accuracy: 0.666, F1 Micro: 0.666, F1 Macro: 0.6564\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.77      0.71       256\n",
      "    positive       0.67      0.54      0.60       217\n",
      "\n",
      "    accuracy                           0.67       473\n",
      "   macro avg       0.67      0.66      0.66       473\n",
      "weighted avg       0.67      0.67      0.66       473\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 142: Accuracy: 0.8285, F1 Micro: 0.8285, F1 Macro: 0.4061\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.16      0.28        97\n",
      "     neutral       0.83      1.00      0.91       459\n",
      "    positive       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.61      0.39      0.40       571\n",
      "weighted avg       0.83      0.83      0.78       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        86\n",
      "     neutral       0.83      1.00      0.91       475\n",
      "    positive       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.28      0.33      0.30       571\n",
      "weighted avg       0.69      0.83      0.76       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        78\n",
      "     neutral       0.86      1.00      0.92       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.74      0.86      0.80       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.43      0.50       200\n",
      "     neutral       0.70      0.75      0.73       315\n",
      "    positive       0.28      0.45      0.34        56\n",
      "\n",
      "    accuracy                           0.61       571\n",
      "   macro avg       0.53      0.54      0.52       571\n",
      "weighted avg       0.62      0.61      0.61       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.30      0.42       162\n",
      "     neutral       0.76      0.94      0.84       387\n",
      "    positive       0.17      0.18      0.18        22\n",
      "\n",
      "    accuracy                           0.73       571\n",
      "   macro avg       0.54      0.47      0.48       571\n",
      "weighted avg       0.72      0.73      0.70       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.41      0.51        85\n",
      "     neutral       0.90      0.98      0.93       418\n",
      "    positive       0.72      0.68      0.70        68\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.76      0.69      0.71       571\n",
      "weighted avg       0.84      0.86      0.84       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.89      1.00      0.94       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.30      0.33      0.31       571\n",
      "weighted avg       0.80      0.89      0.85       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.24        74\n",
      "     neutral       0.88      1.00      0.94       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.63      0.38      0.39       571\n",
      "weighted avg       0.89      0.88      0.84       571\n",
      "\n",
      "Total train time: 81.755197763443 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 215\n",
      "Sampling duration: 55.72192406654358 seconds\n",
      "New train size: 357\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5676, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.465, Accuracy: 0.8038, F1 Micro: 0.8905, F1 Macro: 0.8851\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4481, Accuracy: 0.8111, F1 Micro: 0.8939, F1 Macro: 0.8883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4248, Accuracy: 0.8311, F1 Micro: 0.9029, F1 Macro: 0.8952\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.393, Accuracy: 0.8547, F1 Micro: 0.9155, F1 Macro: 0.9101\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3413, Accuracy: 0.8887, F1 Micro: 0.9339, F1 Macro: 0.9291\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2954, Accuracy: 0.8997, F1 Micro: 0.94, F1 Macro: 0.9363\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.256, Accuracy: 0.9064, F1 Micro: 0.9438, F1 Macro: 0.9399\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2233, Accuracy: 0.9174, F1 Micro: 0.9501, F1 Macro: 0.9465\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1928, Accuracy: 0.9257, F1 Micro: 0.9548, F1 Macro: 0.9509\n",
      "\n",
      "Aspect detection accuracy: 0.9257, F1 Micro: 0.9548, F1 Macro: 0.9509\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.97      0.99      0.98       462\n",
      "   air_panas       0.94      0.99      0.96       480\n",
      "         bau       0.93      0.99      0.96       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.86      0.87      0.87       317\n",
      "       linen       0.86      0.96      0.91       392\n",
      "     service       0.93      0.98      0.96       423\n",
      "sunrise_meal       0.94      1.00      0.97       530\n",
      "          tv       0.97      1.00      0.98       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.93      0.98      0.95      4614\n",
      "   macro avg       0.93      0.98      0.95      4614\n",
      "weighted avg       0.93      0.98      0.96      4614\n",
      " samples avg       0.93      0.98      0.95      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5515, Accuracy: 0.7273, F1 Micro: 0.7273, F1 Macro: 0.425\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4942, Accuracy: 0.7991, F1 Micro: 0.7991, F1 Macro: 0.7544\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3284, Accuracy: 0.8316, F1 Micro: 0.8316, F1 Macro: 0.7737\n",
      "Epoch 4/10, Train Loss: 0.282, Accuracy: 0.8036, F1 Micro: 0.8036, F1 Macro: 0.7605\n",
      "Epoch 5/10, Train Loss: 0.2583, Accuracy: 0.8126, F1 Micro: 0.8126, F1 Macro: 0.7012\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2902, Accuracy: 0.8328, F1 Micro: 0.8328, F1 Macro: 0.7931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2358, Accuracy: 0.8451, F1 Micro: 0.8451, F1 Macro: 0.7989\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1825, Accuracy: 0.8507, F1 Micro: 0.8507, F1 Macro: 0.7805\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1815, Accuracy: 0.8732, F1 Micro: 0.8732, F1 Macro: 0.8287\n",
      "Epoch 10/10, Train Loss: 0.1404, Accuracy: 0.8597, F1 Micro: 0.8597, F1 Macro: 0.8171\n",
      "\n",
      "Sentiment analysis accuracy: 0.8732, F1 Micro: 0.8732, F1 Macro: 0.8287\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.95      0.92       647\n",
      "    positive       0.84      0.66      0.74       244\n",
      "\n",
      "    accuracy                           0.87       891\n",
      "   macro avg       0.86      0.81      0.83       891\n",
      "weighted avg       0.87      0.87      0.87       891\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 357: Accuracy: 0.9159, F1 Micro: 0.9159, F1 Macro: 0.6768\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        97\n",
      "     neutral       0.97      0.99      0.98       459\n",
      "    positive       0.71      0.67      0.69        15\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.87      0.84      0.86       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.70      0.78        86\n",
      "     neutral       0.94      0.99      0.96       475\n",
      "    positive       0.75      0.30      0.43        10\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.86      0.66      0.73       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.55      0.67        78\n",
      "     neutral       0.93      0.99      0.96       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.60      0.51      0.54       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.67      0.06      0.11        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.51      0.35      0.35       571\n",
      "weighted avg       0.84      0.87      0.82       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.76      0.80       200\n",
      "     neutral       0.86      0.87      0.87       315\n",
      "    positive       0.64      0.84      0.72        56\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.78      0.82      0.80       571\n",
      "weighted avg       0.83      0.83      0.83       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.65      0.74       162\n",
      "     neutral       0.86      0.96      0.91       387\n",
      "    positive       0.36      0.36      0.36        22\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.70      0.66      0.67       571\n",
      "weighted avg       0.85      0.85      0.84       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.67      0.75        85\n",
      "     neutral       0.93      0.98      0.96       418\n",
      "    positive       0.82      0.78      0.80        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.81      0.83       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.21      0.34        29\n",
      "     neutral       0.94      1.00      0.97       525\n",
      "    positive       0.83      0.29      0.43        17\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.50      0.58       571\n",
      "weighted avg       0.94      0.94      0.92       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.78      0.84        54\n",
      "     neutral       0.97      1.00      0.98       511\n",
      "    positive       1.00      0.33      0.50         6\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.96      0.70      0.77       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.64      0.63      0.64       571\n",
      "weighted avg       0.97      0.98      0.98       571\n",
      "\n",
      "Total train time: 125.39115357398987 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 193\n",
      "Sampling duration: 68.40518736839294 seconds\n",
      "New train size: 550\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5366, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4722, Accuracy: 0.8054, F1 Micro: 0.8915, F1 Macro: 0.8868\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4417, Accuracy: 0.8316, F1 Micro: 0.9042, F1 Macro: 0.8994\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.393, Accuracy: 0.8745, F1 Micro: 0.9264, F1 Macro: 0.9222\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3168, Accuracy: 0.9108, F1 Micro: 0.946, F1 Macro: 0.9418\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.272, Accuracy: 0.9259, F1 Micro: 0.9551, F1 Macro: 0.9519\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2369, Accuracy: 0.9349, F1 Micro: 0.9603, F1 Macro: 0.9571\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.196, Accuracy: 0.9378, F1 Micro: 0.962, F1 Macro: 0.9582\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1674, Accuracy: 0.9408, F1 Micro: 0.9637, F1 Macro: 0.9603\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1524, Accuracy: 0.9417, F1 Micro: 0.9642, F1 Macro: 0.9605\n",
      "\n",
      "Aspect detection accuracy: 0.9417, F1 Micro: 0.9642, F1 Macro: 0.9605\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.98       462\n",
      "   air_panas       0.96      0.99      0.97       480\n",
      "         bau       0.95      0.99      0.97       496\n",
      "     general       0.92      0.99      0.95       500\n",
      "  kebersihan       0.87      0.89      0.88       317\n",
      "       linen       0.87      0.97      0.91       392\n",
      "     service       0.96      0.97      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.98      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.95      0.98      0.96      4614\n",
      "   macro avg       0.94      0.98      0.96      4614\n",
      "weighted avg       0.95      0.98      0.96      4614\n",
      " samples avg       0.95      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5539, Accuracy: 0.7669, F1 Micro: 0.7669, F1 Macro: 0.6507\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3751, Accuracy: 0.7853, F1 Micro: 0.7853, F1 Macro: 0.763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2985, Accuracy: 0.8476, F1 Micro: 0.8476, F1 Macro: 0.8083\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2637, Accuracy: 0.8507, F1 Micro: 0.8507, F1 Macro: 0.7937\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1998, Accuracy: 0.865, F1 Micro: 0.865, F1 Macro: 0.8162\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1761, Accuracy: 0.8742, F1 Micro: 0.8742, F1 Macro: 0.8456\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1446, Accuracy: 0.8753, F1 Micro: 0.8753, F1 Macro: 0.837\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1004, Accuracy: 0.8845, F1 Micro: 0.8845, F1 Macro: 0.8476\n",
      "Epoch 9/10, Train Loss: 0.0796, Accuracy: 0.8742, F1 Micro: 0.8742, F1 Macro: 0.83\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0658, Accuracy: 0.8896, F1 Micro: 0.8896, F1 Macro: 0.8599\n",
      "\n",
      "Sentiment analysis accuracy: 0.8896, F1 Micro: 0.8896, F1 Macro: 0.8599\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.96      0.92       688\n",
      "    positive       0.88      0.72      0.80       290\n",
      "\n",
      "    accuracy                           0.89       978\n",
      "   macro avg       0.89      0.84      0.86       978\n",
      "weighted avg       0.89      0.89      0.89       978\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 550: Accuracy: 0.9327, F1 Micro: 0.9327, F1 Macro: 0.7718\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.90      0.93        97\n",
      "     neutral       0.98      0.99      0.98       459\n",
      "    positive       0.81      0.87      0.84        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.79      0.83        86\n",
      "     neutral       0.96      0.99      0.97       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.83      0.73      0.77       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.68      0.77        78\n",
      "     neutral       0.95      0.99      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.56      0.58       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.92      0.99      0.95       496\n",
      "    positive       0.83      0.44      0.58        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.58      0.48      0.51       571\n",
      "weighted avg       0.89      0.91      0.89       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.77      0.80       200\n",
      "     neutral       0.87      0.89      0.88       315\n",
      "    positive       0.72      0.88      0.79        56\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.81      0.84      0.83       571\n",
      "weighted avg       0.85      0.85      0.85       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.70      0.78       162\n",
      "     neutral       0.86      0.97      0.91       387\n",
      "    positive       0.60      0.27      0.37        22\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.78      0.65      0.69       571\n",
      "weighted avg       0.86      0.87      0.86       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.72      0.79        85\n",
      "     neutral       0.96      0.97      0.97       418\n",
      "    positive       0.77      0.91      0.83        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.87      0.87      0.86       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.34      0.47        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.79      0.65      0.71        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.82      0.66      0.72       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.91      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.89      0.93        74\n",
      "     neutral       0.98      1.00      0.99       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.98      0.85      0.91       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 159.88756227493286 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 174\n",
      "Sampling duration: 64.92176055908203 seconds\n",
      "New train size: 724\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5396, Accuracy: 0.8042, F1 Micro: 0.8891, F1 Macro: 0.8794\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4653, Accuracy: 0.8109, F1 Micro: 0.8943, F1 Macro: 0.8898\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.425, Accuracy: 0.8741, F1 Micro: 0.9258, F1 Macro: 0.9199\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3417, Accuracy: 0.9054, F1 Micro: 0.9434, F1 Macro: 0.9394\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2788, Accuracy: 0.928, F1 Micro: 0.9563, F1 Macro: 0.9533\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2332, Accuracy: 0.9344, F1 Micro: 0.96, F1 Macro: 0.9571\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2032, Accuracy: 0.9439, F1 Micro: 0.9655, F1 Macro: 0.9626\n",
      "Epoch 8/10, Train Loss: 0.1735, Accuracy: 0.9422, F1 Micro: 0.9648, F1 Macro: 0.9617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1491, Accuracy: 0.9458, F1 Micro: 0.9667, F1 Macro: 0.9637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1305, Accuracy: 0.9519, F1 Micro: 0.9704, F1 Macro: 0.9673\n",
      "\n",
      "Aspect detection accuracy: 0.9519, F1 Micro: 0.9704, F1 Macro: 0.9673\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.96      0.99      0.97       480\n",
      "         bau       0.95      0.99      0.97       496\n",
      "     general       0.92      0.99      0.95       500\n",
      "  kebersihan       0.91      0.90      0.90       317\n",
      "       linen       0.89      0.98      0.93       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5417, Accuracy: 0.8164, F1 Micro: 0.8164, F1 Macro: 0.7814\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3249, Accuracy: 0.8574, F1 Micro: 0.8574, F1 Macro: 0.8094\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2413, Accuracy: 0.8633, F1 Micro: 0.8633, F1 Macro: 0.8095\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2092, Accuracy: 0.876, F1 Micro: 0.876, F1 Macro: 0.8259\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1452, Accuracy: 0.9043, F1 Micro: 0.9043, F1 Macro: 0.8753\n",
      "Epoch 6/10, Train Loss: 0.1327, Accuracy: 0.9033, F1 Micro: 0.9033, F1 Macro: 0.8745\n",
      "Epoch 7/10, Train Loss: 0.0955, Accuracy: 0.8867, F1 Micro: 0.8867, F1 Macro: 0.8422\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0803, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8782\n",
      "Epoch 9/10, Train Loss: 0.0602, Accuracy: 0.9033, F1 Micro: 0.9033, F1 Macro: 0.8726\n",
      "Epoch 10/10, Train Loss: 0.0259, Accuracy: 0.8984, F1 Micro: 0.8984, F1 Macro: 0.862\n",
      "\n",
      "Sentiment analysis accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       734\n",
      "    positive       0.93      0.73      0.82       290\n",
      "\n",
      "    accuracy                           0.91      1024\n",
      "   macro avg       0.92      0.85      0.88      1024\n",
      "weighted avg       0.91      0.91      0.90      1024\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 724: Accuracy: 0.9464, F1 Micro: 0.9464, F1 Macro: 0.8105\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.95      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.81      0.84        86\n",
      "     neutral       0.96      0.99      0.97       475\n",
      "    positive       1.00      0.30      0.46        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.70      0.76       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.72      0.80        78\n",
      "     neutral       0.95      0.99      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.62      0.57      0.59       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.92      0.99      0.95       496\n",
      "    positive       0.85      0.49      0.62        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.59      0.49      0.52       571\n",
      "weighted avg       0.90      0.92      0.90       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85       200\n",
      "     neutral       0.91      0.90      0.90       315\n",
      "    positive       0.85      0.89      0.87        56\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.87      0.88      0.88       571\n",
      "weighted avg       0.88      0.88      0.88       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.76      0.84       162\n",
      "     neutral       0.89      0.98      0.93       387\n",
      "    positive       0.64      0.41      0.50        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.82      0.72      0.76       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.82      0.84        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.76      0.76        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.77      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.96      0.97        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 179.03742957115173 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 156\n",
      "Sampling duration: 58.840452671051025 seconds\n",
      "New train size: 880\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5237, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4544, Accuracy: 0.841, F1 Micro: 0.9087, F1 Macro: 0.9036\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3803, Accuracy: 0.9009, F1 Micro: 0.9405, F1 Macro: 0.9355\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2873, Accuracy: 0.9333, F1 Micro: 0.9593, F1 Macro: 0.9565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2282, Accuracy: 0.9352, F1 Micro: 0.9607, F1 Macro: 0.9581\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1942, Accuracy: 0.9458, F1 Micro: 0.9669, F1 Macro: 0.9643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1636, Accuracy: 0.951, F1 Micro: 0.9698, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1435, Accuracy: 0.9535, F1 Micro: 0.9713, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1253, Accuracy: 0.9556, F1 Micro: 0.9725, F1 Macro: 0.9696\n",
      "Epoch 10/10, Train Loss: 0.1092, Accuracy: 0.9533, F1 Micro: 0.9711, F1 Macro: 0.9681\n",
      "\n",
      "Aspect detection accuracy: 0.9556, F1 Micro: 0.9725, F1 Macro: 0.9696\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.96      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.91      0.92      0.91       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.99       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5398, Accuracy: 0.8147, F1 Micro: 0.8147, F1 Macro: 0.7336\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3506, Accuracy: 0.8639, F1 Micro: 0.8639, F1 Macro: 0.8263\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2817, Accuracy: 0.88, F1 Micro: 0.88, F1 Macro: 0.8438\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2144, Accuracy: 0.8951, F1 Micro: 0.8951, F1 Macro: 0.8651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.129, Accuracy: 0.897, F1 Micro: 0.897, F1 Macro: 0.8704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.097, Accuracy: 0.9008, F1 Micro: 0.9008, F1 Macro: 0.8744\n",
      "Epoch 7/10, Train Loss: 0.0707, Accuracy: 0.8922, F1 Micro: 0.8922, F1 Macro: 0.8579\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0571, Accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8773\n",
      "Epoch 9/10, Train Loss: 0.0589, Accuracy: 0.8998, F1 Micro: 0.8998, F1 Macro: 0.8727\n",
      "Epoch 10/10, Train Loss: 0.0527, Accuracy: 0.8979, F1 Micro: 0.8979, F1 Macro: 0.87\n",
      "\n",
      "Sentiment analysis accuracy: 0.9017, F1 Micro: 0.9017, F1 Macro: 0.8773\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.96      0.93       741\n",
      "    positive       0.90      0.76      0.82       317\n",
      "\n",
      "    accuracy                           0.90      1058\n",
      "   macro avg       0.90      0.86      0.88      1058\n",
      "weighted avg       0.90      0.90      0.90      1058\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 880: Accuracy: 0.9483, F1 Micro: 0.9483, F1 Macro: 0.8309\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.77      0.85        86\n",
      "     neutral       0.96      0.99      0.98       475\n",
      "    positive       0.60      0.60      0.60        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.83      0.79      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.76      0.80        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.74      0.81       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.82      0.68      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.55      0.57       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.83      0.85       200\n",
      "     neutral       0.91      0.92      0.91       315\n",
      "    positive       0.86      0.96      0.91        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.88      0.90      0.89       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.80      0.84       162\n",
      "     neutral       0.91      0.96      0.94       387\n",
      "    positive       0.56      0.41      0.47        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.79      0.73      0.75       571\n",
      "weighted avg       0.89      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.84      0.85        85\n",
      "     neutral       0.97      0.96      0.97       418\n",
      "    positive       0.88      0.94      0.91        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.91      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.34      0.50        29\n",
      "     neutral       0.97      1.00      0.99       525\n",
      "    positive       0.64      0.82      0.72        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.72      0.73       571\n",
      "weighted avg       0.96      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.91      0.93        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       0.75      1.00      0.86         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.90      0.97      0.93       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.96      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 203.34660577774048 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 141\n",
      "Sampling duration: 53.70458173751831 seconds\n",
      "New train size: 1021\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5136, Accuracy: 0.8021, F1 Micro: 0.89, F1 Macro: 0.8855\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4299, Accuracy: 0.8597, F1 Micro: 0.9187, F1 Macro: 0.9139\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3471, Accuracy: 0.9148, F1 Micro: 0.9486, F1 Macro: 0.9448\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2582, Accuracy: 0.9365, F1 Micro: 0.9613, F1 Macro: 0.9589\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2172, Accuracy: 0.9403, F1 Micro: 0.9636, F1 Macro: 0.961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1768, Accuracy: 0.9476, F1 Micro: 0.9677, F1 Macro: 0.9654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1511, Accuracy: 0.9505, F1 Micro: 0.9696, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1377, Accuracy: 0.9563, F1 Micro: 0.9729, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1098, Accuracy: 0.9563, F1 Micro: 0.973, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0965, Accuracy: 0.9566, F1 Micro: 0.9733, F1 Macro: 0.9709\n",
      "\n",
      "Aspect detection accuracy: 0.9566, F1 Micro: 0.9733, F1 Macro: 0.9709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      1.00      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.91      0.94      0.92       317\n",
      "       linen       0.88      0.98      0.93       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.96      1.00      0.98       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      4614\n",
      "   macro avg       0.96      0.99      0.97      4614\n",
      "weighted avg       0.96      0.99      0.97      4614\n",
      " samples avg       0.96      0.99      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4984, Accuracy: 0.8611, F1 Micro: 0.8611, F1 Macro: 0.8113\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3289, Accuracy: 0.8869, F1 Micro: 0.8869, F1 Macro: 0.8534\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2281, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8808\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1649, Accuracy: 0.9177, F1 Micro: 0.9177, F1 Macro: 0.8939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1209, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.8939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0861, Accuracy: 0.9236, F1 Micro: 0.9236, F1 Macro: 0.8998\n",
      "Epoch 7/10, Train Loss: 0.0704, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.8953\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0537, Accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.906\n",
      "Epoch 9/10, Train Loss: 0.04, Accuracy: 0.9246, F1 Micro: 0.9246, F1 Macro: 0.9\n",
      "Epoch 10/10, Train Loss: 0.0552, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.8963\n",
      "\n",
      "Sentiment analysis accuracy: 0.9286, F1 Micro: 0.9286, F1 Macro: 0.906\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       729\n",
      "    positive       0.94      0.79      0.86       279\n",
      "\n",
      "    accuracy                           0.93      1008\n",
      "   macro avg       0.93      0.89      0.91      1008\n",
      "weighted avg       0.93      0.93      0.93      1008\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1021: Accuracy: 0.9515, F1 Micro: 0.9515, F1 Macro: 0.8173\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.85      0.90        86\n",
      "     neutral       0.97      1.00      0.98       475\n",
      "    positive       0.78      0.70      0.74        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.85      0.87       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.77      0.82        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.61      0.58      0.60       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.86      0.65      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.54      0.57       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.83      0.87       200\n",
      "     neutral       0.91      0.94      0.92       315\n",
      "    positive       0.88      0.89      0.88        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.89      0.89       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.76      0.84       162\n",
      "     neutral       0.88      0.98      0.93       387\n",
      "    positive       0.88      0.32      0.47        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.90      0.69      0.75       571\n",
      "weighted avg       0.90      0.89      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.31      0.46        29\n",
      "     neutral       0.96      1.00      0.98       525\n",
      "    positive       0.76      0.76      0.76        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.88      0.69      0.74       571\n",
      "weighted avg       0.95      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.96      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 223.33345222473145 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 127\n",
      "Sampling duration: 48.69786262512207 seconds\n",
      "New train size: 1148\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5086, Accuracy: 0.805, F1 Micro: 0.8913, F1 Macro: 0.8863\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4215, Accuracy: 0.8847, F1 Micro: 0.9318, F1 Macro: 0.927\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3141, Accuracy: 0.9194, F1 Micro: 0.9514, F1 Macro: 0.9479\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2352, Accuracy: 0.9382, F1 Micro: 0.9623, F1 Macro: 0.9599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1968, Accuracy: 0.9491, F1 Micro: 0.9686, F1 Macro: 0.9662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.165, Accuracy: 0.9568, F1 Micro: 0.9733, F1 Macro: 0.9706\n",
      "Epoch 7/10, Train Loss: 0.138, Accuracy: 0.9554, F1 Micro: 0.9725, F1 Macro: 0.9702\n",
      "Epoch 8/10, Train Loss: 0.1177, Accuracy: 0.9559, F1 Micro: 0.9727, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1057, Accuracy: 0.9592, F1 Micro: 0.9747, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0897, Accuracy: 0.9599, F1 Micro: 0.9752, F1 Macro: 0.9726\n",
      "\n",
      "Aspect detection accuracy: 0.9599, F1 Micro: 0.9752, F1 Macro: 0.9726\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.92      0.93      0.92       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4938, Accuracy: 0.8111, F1 Micro: 0.8111, F1 Macro: 0.7086\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2929, Accuracy: 0.8712, F1 Micro: 0.8712, F1 Macro: 0.8395\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2392, Accuracy: 0.8938, F1 Micro: 0.8938, F1 Macro: 0.8665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1643, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.885\n",
      "Epoch 5/10, Train Loss: 0.1256, Accuracy: 0.8976, F1 Micro: 0.8976, F1 Macro: 0.8649\n",
      "Epoch 6/10, Train Loss: 0.0802, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8823\n",
      "Epoch 7/10, Train Loss: 0.0835, Accuracy: 0.9032, F1 Micro: 0.9032, F1 Macro: 0.8756\n",
      "Epoch 8/10, Train Loss: 0.0528, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8858\n",
      "Epoch 9/10, Train Loss: 0.0468, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.876\n",
      "Epoch 10/10, Train Loss: 0.0275, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8727\n",
      "\n",
      "Sentiment analysis accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.885\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       754\n",
      "    positive       0.95      0.74      0.83       310\n",
      "\n",
      "    accuracy                           0.91      1064\n",
      "   macro avg       0.92      0.86      0.89      1064\n",
      "weighted avg       0.91      0.91      0.91      1064\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1148: Accuracy: 0.9539, F1 Micro: 0.9539, F1 Macro: 0.8452\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.92      0.94        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.87      0.87      0.87        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.87      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.92      0.79      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.77      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.85      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.58       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87       200\n",
      "     neutral       0.92      0.93      0.92       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.91      0.90       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.84      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.75      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.87      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.91      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.45      0.57        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.72      0.76      0.74        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.74      0.76       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 234.0277533531189 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 114\n",
      "Sampling duration: 44.359652280807495 seconds\n",
      "New train size: 1262\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.498, Accuracy: 0.8097, F1 Micro: 0.8911, F1 Macro: 0.8783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3974, Accuracy: 0.8889, F1 Micro: 0.9344, F1 Macro: 0.93\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2915, Accuracy: 0.9321, F1 Micro: 0.9585, F1 Macro: 0.9546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2244, Accuracy: 0.946, F1 Micro: 0.9669, F1 Macro: 0.9645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1803, Accuracy: 0.951, F1 Micro: 0.9699, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1533, Accuracy: 0.9594, F1 Micro: 0.9748, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1297, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9729\n",
      "Epoch 8/10, Train Loss: 0.1095, Accuracy: 0.9583, F1 Micro: 0.9742, F1 Macro: 0.9717\n",
      "Epoch 9/10, Train Loss: 0.0977, Accuracy: 0.9576, F1 Micro: 0.9738, F1 Macro: 0.9712\n",
      "Epoch 10/10, Train Loss: 0.0803, Accuracy: 0.959, F1 Micro: 0.9746, F1 Macro: 0.9723\n",
      "\n",
      "Aspect detection accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9729\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.92      0.93      0.92       317\n",
      "       linen       0.91      0.98      0.95       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4496, Accuracy: 0.8577, F1 Micro: 0.8577, F1 Macro: 0.8063\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2947, Accuracy: 0.8661, F1 Micro: 0.8661, F1 Macro: 0.8141\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2224, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1584, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8825\n",
      "Epoch 5/10, Train Loss: 0.1056, Accuracy: 0.9026, F1 Micro: 0.9026, F1 Macro: 0.8782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.076, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.8861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0722, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.8908\n",
      "Epoch 8/10, Train Loss: 0.0426, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8817\n",
      "Epoch 9/10, Train Loss: 0.0284, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8809\n",
      "Epoch 10/10, Train Loss: 0.042, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8789\n",
      "\n",
      "Sentiment analysis accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.8908\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       757\n",
      "    positive       0.93      0.77      0.84       311\n",
      "\n",
      "    accuracy                           0.91      1068\n",
      "   macro avg       0.92      0.87      0.89      1068\n",
      "weighted avg       0.92      0.91      0.91      1068\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1262: Accuracy: 0.9543, F1 Micro: 0.9543, F1 Macro: 0.8656\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.85      0.90        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.64      0.70      0.67        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.85      0.85       571\n",
      "weighted avg       0.97      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.83      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.81      0.71      0.76        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.56      0.57       571\n",
      "weighted avg       0.92      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.87       200\n",
      "     neutral       0.92      0.93      0.92       315\n",
      "    positive       0.85      0.93      0.89        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.90      0.90       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.80      0.85       162\n",
      "     neutral       0.91      0.98      0.95       387\n",
      "    positive       0.75      0.41      0.53        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.73      0.78       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.82      0.85        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.92      0.90      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.90      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.80      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 247.53826546669006 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 103\n",
      "Sampling duration: 39.769298791885376 seconds\n",
      "New train size: 1365\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4972, Accuracy: 0.8021, F1 Micro: 0.89, F1 Macro: 0.8855\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.392, Accuracy: 0.9005, F1 Micro: 0.9407, F1 Macro: 0.9368\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2762, Accuracy: 0.9318, F1 Micro: 0.9584, F1 Macro: 0.9546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2064, Accuracy: 0.946, F1 Micro: 0.9669, F1 Macro: 0.9642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1784, Accuracy: 0.9554, F1 Micro: 0.9725, F1 Macro: 0.9699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1501, Accuracy: 0.9566, F1 Micro: 0.9733, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1196, Accuracy: 0.9571, F1 Micro: 0.9735, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1055, Accuracy: 0.9611, F1 Micro: 0.976, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0939, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.975\n",
      "Epoch 10/10, Train Loss: 0.0751, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.974\n",
      "\n",
      "Aspect detection accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.454, Accuracy: 0.8251, F1 Micro: 0.8251, F1 Macro: 0.7946\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2686, Accuracy: 0.8906, F1 Micro: 0.8906, F1 Macro: 0.8531\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1981, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8798\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1499, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8877\n",
      "Epoch 5/10, Train Loss: 0.1084, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.875\n",
      "Epoch 6/10, Train Loss: 0.0853, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8844\n",
      "Epoch 7/10, Train Loss: 0.0536, Accuracy: 0.9121, F1 Micro: 0.9121, F1 Macro: 0.8876\n",
      "Epoch 8/10, Train Loss: 0.051, Accuracy: 0.9121, F1 Micro: 0.9121, F1 Macro: 0.8836\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0264, Accuracy: 0.9158, F1 Micro: 0.9158, F1 Macro: 0.8904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.037, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.8956\n",
      "\n",
      "Sentiment analysis accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.8956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       766\n",
      "    positive       0.95      0.76      0.84       303\n",
      "\n",
      "    accuracy                           0.92      1069\n",
      "   macro avg       0.93      0.87      0.90      1069\n",
      "weighted avg       0.92      0.92      0.92      1069\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1365: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.8623\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.97      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.86      0.90        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.78      0.70      0.74        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.85      0.87       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.77      0.82        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.85      0.66      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.55      0.57       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.89       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.84      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.89      0.36      0.52        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.73      0.77       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.91      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.82      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 264.991685628891 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 62\n",
      "Sampling duration: 36.55341839790344 seconds\n",
      "New train size: 1427\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4934, Accuracy: 0.8224, F1 Micro: 0.8998, F1 Macro: 0.8949\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3764, Accuracy: 0.9085, F1 Micro: 0.945, F1 Macro: 0.9413\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2717, Accuracy: 0.9405, F1 Micro: 0.9635, F1 Macro: 0.9604\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2026, Accuracy: 0.9517, F1 Micro: 0.9703, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1621, Accuracy: 0.9582, F1 Micro: 0.9741, F1 Macro: 0.9714\n",
      "Epoch 6/10, Train Loss: 0.1389, Accuracy: 0.9556, F1 Micro: 0.9726, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1171, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0988, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0884, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9741\n",
      "Epoch 10/10, Train Loss: 0.0751, Accuracy: 0.9601, F1 Micro: 0.9752, F1 Macro: 0.9726\n",
      "\n",
      "Aspect detection accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.95      0.92      0.93       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4277, Accuracy: 0.8438, F1 Micro: 0.8438, F1 Macro: 0.8045\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2807, Accuracy: 0.8669, F1 Micro: 0.8669, F1 Macro: 0.8363\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2047, Accuracy: 0.8817, F1 Micro: 0.8817, F1 Macro: 0.8376\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1458, Accuracy: 0.9057, F1 Micro: 0.9057, F1 Macro: 0.8785\n",
      "Epoch 5/10, Train Loss: 0.1131, Accuracy: 0.903, F1 Micro: 0.903, F1 Macro: 0.8731\n",
      "Epoch 6/10, Train Loss: 0.0945, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8772\n",
      "Epoch 7/10, Train Loss: 0.0608, Accuracy: 0.8993, F1 Micro: 0.8993, F1 Macro: 0.8643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0419, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8795\n",
      "Epoch 9/10, Train Loss: 0.0368, Accuracy: 0.903, F1 Micro: 0.903, F1 Macro: 0.8728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0347, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.882\n",
      "\n",
      "Sentiment analysis accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.882\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       771\n",
      "    positive       0.93      0.74      0.82       311\n",
      "\n",
      "    accuracy                           0.91      1082\n",
      "   macro avg       0.92      0.86      0.88      1082\n",
      "weighted avg       0.91      0.91      0.91      1082\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1427: Accuracy: 0.9557, F1 Micro: 0.9557, F1 Macro: 0.8488\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.89        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.79      0.82       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.77      0.82        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.75      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.84      0.63      0.72        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.54      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.90       200\n",
      "     neutral       0.95      0.92      0.93       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.83      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.79      0.50      0.61        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.77      0.81       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.84      0.87        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.91      0.91      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.66      0.73        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 273.81644558906555 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 86\n",
      "Sampling duration: 33.99878978729248 seconds\n",
      "New train size: 1513\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4901, Accuracy: 0.8238, F1 Micro: 0.9004, F1 Macro: 0.8966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3664, Accuracy: 0.9102, F1 Micro: 0.9459, F1 Macro: 0.9416\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2545, Accuracy: 0.9363, F1 Micro: 0.9613, F1 Macro: 0.9588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1962, Accuracy: 0.9517, F1 Micro: 0.9702, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1569, Accuracy: 0.9536, F1 Micro: 0.9715, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1345, Accuracy: 0.959, F1 Micro: 0.9746, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1145, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0978, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9749\n",
      "Epoch 9/10, Train Loss: 0.083, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9739\n",
      "Epoch 10/10, Train Loss: 0.0729, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9744\n",
      "\n",
      "Aspect detection accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.92      0.94      0.93       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4438, Accuracy: 0.8664, F1 Micro: 0.8664, F1 Macro: 0.8238\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2682, Accuracy: 0.885, F1 Micro: 0.885, F1 Macro: 0.8464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1806, Accuracy: 0.9007, F1 Micro: 0.9007, F1 Macro: 0.8686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1411, Accuracy: 0.91, F1 Micro: 0.91, F1 Macro: 0.8845\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.124, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8842\n",
      "Epoch 6/10, Train Loss: 0.08, Accuracy: 0.9063, F1 Micro: 0.9063, F1 Macro: 0.8769\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0623, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.8903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0437, Accuracy: 0.9165, F1 Micro: 0.9165, F1 Macro: 0.8907\n",
      "Epoch 9/10, Train Loss: 0.039, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8863\n",
      "Epoch 10/10, Train Loss: 0.0358, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8882\n",
      "\n",
      "Sentiment analysis accuracy: 0.9165, F1 Micro: 0.9165, F1 Macro: 0.8907\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       769\n",
      "    positive       0.95      0.75      0.84       309\n",
      "\n",
      "    accuracy                           0.92      1078\n",
      "   macro avg       0.93      0.87      0.89      1078\n",
      "weighted avg       0.92      0.92      0.91      1078\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1513: Accuracy: 0.9573, F1 Micro: 0.9573, F1 Macro: 0.8617\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.86      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.82      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.77      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.84      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.56      0.57       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.89       200\n",
      "     neutral       0.92      0.94      0.93       315\n",
      "    positive       0.86      0.91      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.91      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.85      0.50      0.63        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.78      0.82       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.87      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.94      0.88      0.91        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.95      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 287.05752396583557 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 77\n",
      "Sampling duration: 30.38989233970642 seconds\n",
      "New train size: 1590\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4837, Accuracy: 0.8224, F1 Micro: 0.8999, F1 Macro: 0.8954\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3623, Accuracy: 0.9148, F1 Micro: 0.9487, F1 Macro: 0.9454\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2459, Accuracy: 0.9398, F1 Micro: 0.963, F1 Macro: 0.96\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1924, Accuracy: 0.95, F1 Micro: 0.9693, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1583, Accuracy: 0.9559, F1 Micro: 0.9728, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1319, Accuracy: 0.9582, F1 Micro: 0.9742, F1 Macro: 0.9716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.116, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9737\n",
      "Epoch 8/10, Train Loss: 0.0944, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0831, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9749\n",
      "Epoch 10/10, Train Loss: 0.07, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9746\n",
      "\n",
      "Aspect detection accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.96      0.93      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.96      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4487, Accuracy: 0.8524, F1 Micro: 0.8524, F1 Macro: 0.8046\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2858, Accuracy: 0.8819, F1 Micro: 0.8819, F1 Macro: 0.8549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2067, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8818\n",
      "Epoch 4/10, Train Loss: 0.146, Accuracy: 0.8911, F1 Micro: 0.8911, F1 Macro: 0.8519\n",
      "Epoch 5/10, Train Loss: 0.0954, Accuracy: 0.905, F1 Micro: 0.905, F1 Macro: 0.8741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0565, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.882\n",
      "Epoch 7/10, Train Loss: 0.0517, Accuracy: 0.9096, F1 Micro: 0.9096, F1 Macro: 0.8823\n",
      "Epoch 8/10, Train Loss: 0.0459, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8788\n",
      "Epoch 9/10, Train Loss: 0.0336, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8818\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0256, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.8825\n",
      "\n",
      "Sentiment analysis accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.8825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       772\n",
      "    positive       0.94      0.73      0.83       312\n",
      "\n",
      "    accuracy                           0.91      1084\n",
      "   macro avg       0.92      0.86      0.88      1084\n",
      "weighted avg       0.91      0.91      0.91      1084\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1590: Accuracy: 0.9567, F1 Micro: 0.9567, F1 Macro: 0.8655\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.87      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.83      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.83      0.66      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.59      0.55      0.57       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91       200\n",
      "     neutral       0.96      0.93      0.94       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.89      0.36      0.52        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.73      0.78       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.81      0.83        85\n",
      "     neutral       0.96      0.97      0.97       418\n",
      "    positive       0.94      0.90      0.92        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.89      0.90       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.92      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 295.1431291103363 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 70\n",
      "Sampling duration: 27.536884307861328 seconds\n",
      "New train size: 1660\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4778, Accuracy: 0.8332, F1 Micro: 0.9045, F1 Macro: 0.8993\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3476, Accuracy: 0.916, F1 Micro: 0.9494, F1 Macro: 0.946\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2457, Accuracy: 0.9408, F1 Micro: 0.9638, F1 Macro: 0.9612\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1917, Accuracy: 0.9505, F1 Micro: 0.9696, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1572, Accuracy: 0.9564, F1 Micro: 0.973, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1276, Accuracy: 0.9566, F1 Micro: 0.9731, F1 Macro: 0.9704\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1089, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9754\n",
      "Epoch 8/10, Train Loss: 0.0945, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9742\n",
      "Epoch 9/10, Train Loss: 0.0777, Accuracy: 0.962, F1 Micro: 0.9765, F1 Macro: 0.9741\n",
      "Epoch 10/10, Train Loss: 0.067, Accuracy: 0.9597, F1 Micro: 0.975, F1 Macro: 0.9724\n",
      "\n",
      "Aspect detection accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.93      0.99      0.96       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      0.99      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4524, Accuracy: 0.8512, F1 Micro: 0.8512, F1 Macro: 0.7985\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2836, Accuracy: 0.8825, F1 Micro: 0.8825, F1 Macro: 0.8496\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2118, Accuracy: 0.899, F1 Micro: 0.899, F1 Macro: 0.8652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1423, Accuracy: 0.8999, F1 Micro: 0.8999, F1 Macro: 0.8688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1046, Accuracy: 0.9063, F1 Micro: 0.9063, F1 Macro: 0.8753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0813, Accuracy: 0.9063, F1 Micro: 0.9063, F1 Macro: 0.8753\n",
      "Epoch 7/10, Train Loss: 0.0768, Accuracy: 0.9027, F1 Micro: 0.9027, F1 Macro: 0.8738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.053, Accuracy: 0.91, F1 Micro: 0.91, F1 Macro: 0.8817\n",
      "Epoch 9/10, Train Loss: 0.0391, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0462, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8832\n",
      "\n",
      "Sentiment analysis accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8832\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       779\n",
      "    positive       0.95      0.73      0.83       310\n",
      "\n",
      "    accuracy                           0.91      1089\n",
      "   macro avg       0.92      0.86      0.88      1089\n",
      "weighted avg       0.91      0.91      0.91      1089\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1660: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.8703\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.90      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.81      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.99      0.96       496\n",
      "    positive       0.85      0.57      0.68        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.59      0.52      0.55       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.87      0.75      0.79       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.87      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.94      0.90      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      0.99      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.83      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 307.51200437545776 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 52\n",
      "Sampling duration: 25.034729957580566 seconds\n",
      "New train size: 1712\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4766, Accuracy: 0.8464, F1 Micro: 0.9107, F1 Macro: 0.9032\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3286, Accuracy: 0.9233, F1 Micro: 0.9534, F1 Macro: 0.9498\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.231, Accuracy: 0.9382, F1 Micro: 0.9624, F1 Macro: 0.96\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.182, Accuracy: 0.954, F1 Micro: 0.9716, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1492, Accuracy: 0.9568, F1 Micro: 0.9734, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1236, Accuracy: 0.9583, F1 Micro: 0.9743, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1029, Accuracy: 0.9592, F1 Micro: 0.9748, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0894, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0779, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0621, Accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9764\n",
      "\n",
      "Aspect detection accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.94      0.95      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4136, Accuracy: 0.8539, F1 Micro: 0.8539, F1 Macro: 0.8084\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2484, Accuracy: 0.8739, F1 Micro: 0.8739, F1 Macro: 0.8267\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1671, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1125, Accuracy: 0.9165, F1 Micro: 0.9165, F1 Macro: 0.8924\n",
      "Epoch 5/10, Train Loss: 0.0879, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8838\n",
      "Epoch 6/10, Train Loss: 0.0714, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8817\n",
      "Epoch 7/10, Train Loss: 0.0586, Accuracy: 0.9047, F1 Micro: 0.9047, F1 Macro: 0.8786\n",
      "Epoch 8/10, Train Loss: 0.0392, Accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.888\n",
      "Epoch 9/10, Train Loss: 0.0269, Accuracy: 0.9102, F1 Micro: 0.9102, F1 Macro: 0.8846\n",
      "Epoch 10/10, Train Loss: 0.0265, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8809\n",
      "\n",
      "Sentiment analysis accuracy: 0.9165, F1 Micro: 0.9165, F1 Macro: 0.8924\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       781\n",
      "    positive       0.94      0.76      0.84       321\n",
      "\n",
      "    accuracy                           0.92      1102\n",
      "   macro avg       0.93      0.87      0.89      1102\n",
      "weighted avg       0.92      0.92      0.91      1102\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1712: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.8826\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.92      0.80      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.82      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.82      0.74      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.62      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.89      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.85      0.50      0.63        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.78      0.81       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.94      0.96      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.82      0.76        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 315.9634346961975 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 58\n",
      "Sampling duration: 22.959388256072998 seconds\n",
      "New train size: 1770\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.476, Accuracy: 0.838, F1 Micro: 0.9076, F1 Macro: 0.9029\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.326, Accuracy: 0.925, F1 Micro: 0.9547, F1 Macro: 0.9522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.231, Accuracy: 0.945, F1 Micro: 0.9664, F1 Macro: 0.9644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1797, Accuracy: 0.9493, F1 Micro: 0.9689, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1407, Accuracy: 0.9589, F1 Micro: 0.9746, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1252, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1013, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0858, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0768, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9759\n",
      "Epoch 10/10, Train Loss: 0.0657, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9755\n",
      "\n",
      "Aspect detection accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.96       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.94      0.97      0.95       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4026, Accuracy: 0.866, F1 Micro: 0.866, F1 Macro: 0.8236\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2517, Accuracy: 0.8924, F1 Micro: 0.8924, F1 Macro: 0.8589\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1712, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8818\n",
      "Epoch 4/10, Train Loss: 0.1203, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0971, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.882\n",
      "Epoch 6/10, Train Loss: 0.0722, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8825\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0527, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8812\n",
      "Epoch 8/10, Train Loss: 0.0459, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8791\n",
      "Epoch 9/10, Train Loss: 0.0341, Accuracy: 0.907, F1 Micro: 0.907, F1 Macro: 0.8805\n",
      "Epoch 10/10, Train Loss: 0.0194, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8788\n",
      "\n",
      "Sentiment analysis accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       777\n",
      "    positive       0.94      0.73      0.82       320\n",
      "\n",
      "    accuracy                           0.91      1097\n",
      "   macro avg       0.92      0.86      0.88      1097\n",
      "weighted avg       0.91      0.91      0.91      1097\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1770: Accuracy: 0.958, F1 Micro: 0.958, F1 Macro: 0.8683\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.87      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.96       496\n",
      "    positive       0.85      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.58       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.85      0.95      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.73      0.36      0.48        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.85      0.73      0.77       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.86      0.85        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.92      0.97      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.52      0.64        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.89      0.76      0.81       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 322.3450040817261 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 52\n",
      "Sampling duration: 20.37920904159546 seconds\n",
      "New train size: 1822\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4743, Accuracy: 0.8382, F1 Micro: 0.9074, F1 Macro: 0.9026\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3191, Accuracy: 0.9306, F1 Micro: 0.9576, F1 Macro: 0.9537\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2269, Accuracy: 0.9493, F1 Micro: 0.9689, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1706, Accuracy: 0.9507, F1 Micro: 0.9696, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1409, Accuracy: 0.9573, F1 Micro: 0.9736, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1164, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9738\n",
      "Epoch 7/10, Train Loss: 0.0978, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9738\n",
      "Epoch 8/10, Train Loss: 0.0861, Accuracy: 0.9604, F1 Micro: 0.9754, F1 Macro: 0.9732\n",
      "Epoch 9/10, Train Loss: 0.0725, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0593, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9744\n",
      "\n",
      "Aspect detection accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.96      0.91      0.94       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4238, Accuracy: 0.8552, F1 Micro: 0.8552, F1 Macro: 0.8048\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2218, Accuracy: 0.8813, F1 Micro: 0.8813, F1 Macro: 0.8552\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1655, Accuracy: 0.8975, F1 Micro: 0.8975, F1 Macro: 0.8662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1249, Accuracy: 0.9002, F1 Micro: 0.9002, F1 Macro: 0.8698\n",
      "Epoch 5/10, Train Loss: 0.0841, Accuracy: 0.8993, F1 Micro: 0.8993, F1 Macro: 0.8679\n",
      "Epoch 6/10, Train Loss: 0.0671, Accuracy: 0.8966, F1 Micro: 0.8966, F1 Macro: 0.8694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0538, Accuracy: 0.9029, F1 Micro: 0.9029, F1 Macro: 0.877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0501, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0343, Accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.8821\n",
      "Epoch 10/10, Train Loss: 0.0133, Accuracy: 0.9047, F1 Micro: 0.9047, F1 Macro: 0.8764\n",
      "\n",
      "Sentiment analysis accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.8821\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       781\n",
      "    positive       0.93      0.75      0.83       331\n",
      "\n",
      "    accuracy                           0.91      1112\n",
      "   macro avg       0.91      0.86      0.88      1112\n",
      "weighted avg       0.91      0.91      0.90      1112\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1822: Accuracy: 0.9569, F1 Micro: 0.9569, F1 Macro: 0.8852\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.87      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.78      0.70      0.74        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.91      0.86      0.88       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.81      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.81      0.74      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.67      0.73       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.92      0.90       200\n",
      "     neutral       0.96      0.91      0.93       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.94      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.83      0.85       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.67      0.55      0.60        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.82      0.78      0.80       571\n",
      "weighted avg       0.90      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.87      0.87        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.45      0.59        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.68      0.76      0.72        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.74      0.77       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 329.86757826805115 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 18.611024141311646 seconds\n",
      "New train size: 1872\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4678, Accuracy: 0.8569, F1 Micro: 0.9162, F1 Macro: 0.9084\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3074, Accuracy: 0.9332, F1 Micro: 0.9589, F1 Macro: 0.9549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2123, Accuracy: 0.9486, F1 Micro: 0.9684, F1 Macro: 0.9658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1699, Accuracy: 0.9554, F1 Micro: 0.9725, F1 Macro: 0.97\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1399, Accuracy: 0.9592, F1 Micro: 0.9747, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1139, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9748\n",
      "Epoch 7/10, Train Loss: 0.0947, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9743\n",
      "Epoch 8/10, Train Loss: 0.0828, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0713, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9751\n",
      "Epoch 10/10, Train Loss: 0.0575, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9743\n",
      "\n",
      "Aspect detection accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9751\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3812, Accuracy: 0.8575, F1 Micro: 0.8575, F1 Macro: 0.8068\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2335, Accuracy: 0.8858, F1 Micro: 0.8858, F1 Macro: 0.8495\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1567, Accuracy: 0.9041, F1 Micro: 0.9041, F1 Macro: 0.8773\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1089, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.8793\n",
      "Epoch 5/10, Train Loss: 0.0784, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.8672\n",
      "Epoch 6/10, Train Loss: 0.0572, Accuracy: 0.8913, F1 Micro: 0.8913, F1 Macro: 0.8528\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0508, Accuracy: 0.9078, F1 Micro: 0.9078, F1 Macro: 0.8795\n",
      "Epoch 8/10, Train Loss: 0.0276, Accuracy: 0.9032, F1 Micro: 0.9032, F1 Macro: 0.8722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0319, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8883\n",
      "Epoch 10/10, Train Loss: 0.0285, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.8793\n",
      "\n",
      "Sentiment analysis accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8883\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       778\n",
      "    positive       0.94      0.75      0.83       317\n",
      "\n",
      "    accuracy                           0.91      1095\n",
      "   macro avg       0.92      0.86      0.89      1095\n",
      "weighted avg       0.92      0.91      0.91      1095\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1872: Accuracy: 0.9578, F1 Micro: 0.9578, F1 Macro: 0.8704\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.91      0.79      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.83      0.65      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.92      0.59      0.65       571\n",
      "weighted avg       0.93      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.88      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.77      0.45      0.57        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.76      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.88      0.87        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 335.69473457336426 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 16.667606353759766 seconds\n",
      "New train size: 1922\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4672, Accuracy: 0.854, F1 Micro: 0.9157, F1 Macro: 0.9109\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3033, Accuracy: 0.929, F1 Micro: 0.957, F1 Macro: 0.9546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.212, Accuracy: 0.9418, F1 Micro: 0.9646, F1 Macro: 0.9624\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1696, Accuracy: 0.9566, F1 Micro: 0.9732, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1397, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1147, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9747\n",
      "Epoch 7/10, Train Loss: 0.0954, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9741\n",
      "Epoch 8/10, Train Loss: 0.0827, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0681, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0568, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.975\n",
      "\n",
      "Aspect detection accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3831, Accuracy: 0.8643, F1 Micro: 0.8643, F1 Macro: 0.8134\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2204, Accuracy: 0.8903, F1 Micro: 0.8903, F1 Macro: 0.8545\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1357, Accuracy: 0.9006, F1 Micro: 0.9006, F1 Macro: 0.8689\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0993, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8798\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0854, Accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.8914\n",
      "Epoch 6/10, Train Loss: 0.0596, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.8879\n",
      "Epoch 7/10, Train Loss: 0.0514, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8893\n",
      "Epoch 8/10, Train Loss: 0.0287, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.8876\n",
      "Epoch 9/10, Train Loss: 0.0181, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.8874\n",
      "Epoch 10/10, Train Loss: 0.0266, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.8871\n",
      "\n",
      "Sentiment analysis accuracy: 0.9173, F1 Micro: 0.9173, F1 Macro: 0.8914\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.99      0.94       767\n",
      "    positive       0.95      0.75      0.84       309\n",
      "\n",
      "    accuracy                           0.92      1076\n",
      "   macro avg       0.93      0.87      0.89      1076\n",
      "weighted avg       0.92      0.92      0.91      1076\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1922: Accuracy: 0.9574, F1 Micro: 0.9574, F1 Macro: 0.8493\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.91      0.79      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.82      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.77      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.57      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       200\n",
      "     neutral       0.93      0.93      0.93       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.87       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.80      0.36      0.50        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.73      0.77       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.45      0.58        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.80      0.71      0.75        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.72      0.77       571\n",
      "weighted avg       0.96      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.98      0.86      0.91       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.99      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 342.2142355442047 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 15.241425275802612 seconds\n",
      "New train size: 1972\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4676, Accuracy: 0.8622, F1 Micro: 0.9195, F1 Macro: 0.9137\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3004, Accuracy: 0.9358, F1 Micro: 0.9608, F1 Macro: 0.9587\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2028, Accuracy: 0.9467, F1 Micro: 0.9674, F1 Macro: 0.9651\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1674, Accuracy: 0.9526, F1 Micro: 0.9709, F1 Macro: 0.9686\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1345, Accuracy: 0.9587, F1 Micro: 0.9745, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1189, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.097, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9756\n",
      "Epoch 8/10, Train Loss: 0.0791, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0671, Accuracy: 0.9649, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "Epoch 10/10, Train Loss: 0.0563, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "\n",
      "Aspect detection accuracy: 0.9649, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.92      0.98      0.95       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4043, Accuracy: 0.8776, F1 Micro: 0.8776, F1 Macro: 0.8414\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1998, Accuracy: 0.9037, F1 Micro: 0.9037, F1 Macro: 0.8732\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1529, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0994, Accuracy: 0.9215, F1 Micro: 0.9215, F1 Macro: 0.8972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0686, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.8994\n",
      "Epoch 6/10, Train Loss: 0.0611, Accuracy: 0.9168, F1 Micro: 0.9168, F1 Macro: 0.8927\n",
      "Epoch 7/10, Train Loss: 0.0434, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8847\n",
      "Epoch 8/10, Train Loss: 0.0303, Accuracy: 0.9215, F1 Micro: 0.9215, F1 Macro: 0.8967\n",
      "Epoch 9/10, Train Loss: 0.0406, Accuracy: 0.9224, F1 Micro: 0.9224, F1 Macro: 0.8983\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0335, Accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9059\n",
      "\n",
      "Sentiment analysis accuracy: 0.928, F1 Micro: 0.928, F1 Macro: 0.9059\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.99      0.95       767\n",
      "    positive       0.96      0.78      0.86       303\n",
      "\n",
      "    accuracy                           0.93      1070\n",
      "   macro avg       0.94      0.88      0.91      1070\n",
      "weighted avg       0.93      0.93      0.93      1070\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1972: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.8741\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.97      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.69      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.56      0.58       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.87      0.90       200\n",
      "     neutral       0.93      0.94      0.94       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.83      0.87       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.92      0.76      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.96      0.94      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.62      0.73        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.81      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 347.7148585319519 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 25\n",
      "Sampling duration: 13.275478839874268 seconds\n",
      "New train size: 1997\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4563, Accuracy: 0.8656, F1 Micro: 0.9217, F1 Macro: 0.916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.301, Accuracy: 0.9345, F1 Micro: 0.96, F1 Macro: 0.9568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.207, Accuracy: 0.9498, F1 Micro: 0.9693, F1 Macro: 0.9669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1592, Accuracy: 0.9549, F1 Micro: 0.9722, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1348, Accuracy: 0.9595, F1 Micro: 0.975, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.116, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0918, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0788, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0651, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "Epoch 10/10, Train Loss: 0.0566, Accuracy: 0.9632, F1 Micro: 0.9771, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.97      0.97       500\n",
      "  kebersihan       0.93      0.94      0.93       317\n",
      "       linen       0.95      0.97      0.96       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3995, Accuracy: 0.861, F1 Micro: 0.861, F1 Macro: 0.8121\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2201, Accuracy: 0.8892, F1 Micro: 0.8892, F1 Macro: 0.8532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1439, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8783\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0894, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.071, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.8956\n",
      "Epoch 6/10, Train Loss: 0.0611, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.8845\n",
      "Epoch 7/10, Train Loss: 0.0499, Accuracy: 0.9164, F1 Micro: 0.9164, F1 Macro: 0.8942\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0267, Accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.8966\n",
      "Epoch 9/10, Train Loss: 0.0236, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8911\n",
      "Epoch 10/10, Train Loss: 0.033, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8864\n",
      "\n",
      "Sentiment analysis accuracy: 0.9192, F1 Micro: 0.9192, F1 Macro: 0.8966\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       776\n",
      "    positive       0.95      0.77      0.85       325\n",
      "\n",
      "    accuracy                           0.92      1101\n",
      "   macro avg       0.93      0.87      0.90      1101\n",
      "weighted avg       0.92      0.92      0.92      1101\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1997: Accuracy: 0.9588, F1 Micro: 0.9588, F1 Macro: 0.8659\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.97      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44         7\n",
      "     neutral       0.96      0.97      0.97       496\n",
      "    positive       0.81      0.81      0.81        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.69      0.74       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.89       200\n",
      "     neutral       0.93      0.94      0.93       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.89       162\n",
      "     neutral       0.95      0.97      0.96       387\n",
      "    positive       0.85      0.50      0.63        22\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.89      0.79      0.83       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.90      0.94      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.55      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.80      0.71      0.75        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.75      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 353.28894209861755 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 11.877418994903564 seconds\n",
      "New train size: 2047\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4612, Accuracy: 0.8691, F1 Micro: 0.9231, F1 Macro: 0.9172\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2964, Accuracy: 0.9363, F1 Micro: 0.9612, F1 Macro: 0.959\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2058, Accuracy: 0.9438, F1 Micro: 0.9656, F1 Macro: 0.9632\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1612, Accuracy: 0.9552, F1 Micro: 0.9723, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1284, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1058, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0932, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0757, Accuracy: 0.9642, F1 Micro: 0.9777, F1 Macro: 0.9753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0658, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9761\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0559, Accuracy: 0.9655, F1 Micro: 0.9786, F1 Macro: 0.9765\n",
      "\n",
      "Aspect detection accuracy: 0.9655, F1 Micro: 0.9786, F1 Macro: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3878, Accuracy: 0.8643, F1 Micro: 0.8643, F1 Macro: 0.8176\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2132, Accuracy: 0.9095, F1 Micro: 0.9095, F1 Macro: 0.8823\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1393, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.886\n",
      "Epoch 4/10, Train Loss: 0.1057, Accuracy: 0.9067, F1 Micro: 0.9067, F1 Macro: 0.8802\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0719, Accuracy: 0.916, F1 Micro: 0.916, F1 Macro: 0.8903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.066, Accuracy: 0.9178, F1 Micro: 0.9178, F1 Macro: 0.8922\n",
      "Epoch 7/10, Train Loss: 0.0354, Accuracy: 0.9169, F1 Micro: 0.9169, F1 Macro: 0.8909\n",
      "Epoch 8/10, Train Loss: 0.0419, Accuracy: 0.9123, F1 Micro: 0.9123, F1 Macro: 0.8855\n",
      "Epoch 9/10, Train Loss: 0.0269, Accuracy: 0.9169, F1 Micro: 0.9169, F1 Macro: 0.8906\n",
      "Epoch 10/10, Train Loss: 0.022, Accuracy: 0.9123, F1 Micro: 0.9123, F1 Macro: 0.886\n",
      "\n",
      "Sentiment analysis accuracy: 0.9178, F1 Micro: 0.9178, F1 Macro: 0.8922\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       778\n",
      "    positive       0.93      0.76      0.84       305\n",
      "\n",
      "    accuracy                           0.92      1083\n",
      "   macro avg       0.92      0.87      0.89      1083\n",
      "weighted avg       0.92      0.92      0.92      1083\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2047: Accuracy: 0.9595, F1 Micro: 0.9595, F1 Macro: 0.8725\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.92      0.93        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.86      0.60      0.71        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.84      0.88       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.88      0.68      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.60      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.86      0.96      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.71      0.45      0.56        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.84      0.76      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.82      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 360.5265791416168 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 9.856144905090332 seconds\n",
      "New train size: 2097\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4584, Accuracy: 0.8694, F1 Micro: 0.9235, F1 Macro: 0.9184\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2891, Accuracy: 0.937, F1 Micro: 0.9615, F1 Macro: 0.9591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2034, Accuracy: 0.9483, F1 Micro: 0.9683, F1 Macro: 0.9659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1592, Accuracy: 0.9569, F1 Micro: 0.9734, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1284, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9731\n",
      "Epoch 6/10, Train Loss: 0.1104, Accuracy: 0.9578, F1 Micro: 0.974, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0892, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0729, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.067, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0548, Accuracy: 0.9661, F1 Micro: 0.979, F1 Macro: 0.9771\n",
      "\n",
      "Aspect detection accuracy: 0.9661, F1 Micro: 0.979, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.94      0.97      0.96       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.364, Accuracy: 0.8717, F1 Micro: 0.8717, F1 Macro: 0.8306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2086, Accuracy: 0.8946, F1 Micro: 0.8946, F1 Macro: 0.8573\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1567, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0969, Accuracy: 0.9065, F1 Micro: 0.9065, F1 Macro: 0.8751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0759, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.054, Accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.8874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0443, Accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0387, Accuracy: 0.9175, F1 Micro: 0.9175, F1 Macro: 0.8903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0209, Accuracy: 0.9184, F1 Micro: 0.9184, F1 Macro: 0.8942\n",
      "Epoch 10/10, Train Loss: 0.0216, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.8822\n",
      "\n",
      "Sentiment analysis accuracy: 0.9184, F1 Micro: 0.9184, F1 Macro: 0.8942\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.94       783\n",
      "    positive       0.92      0.78      0.84       308\n",
      "\n",
      "    accuracy                           0.92      1091\n",
      "   macro avg       0.92      0.88      0.89      1091\n",
      "weighted avg       0.92      0.92      0.92      1091\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2097: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.8662\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.91      0.93        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.87      0.87       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.83      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.88      0.63      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.61      0.54      0.57       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.90      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88       162\n",
      "     neutral       0.94      0.97      0.96       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.77      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.52      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      1.00      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.84      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.89      0.91        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.67      1.00      0.80         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.87      0.96      0.90       571\n",
      "weighted avg       0.99      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 374.8245794773102 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 8.006309032440186 seconds\n",
      "New train size: 2147\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.448, Accuracy: 0.8748, F1 Micro: 0.9264, F1 Macro: 0.921\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2777, Accuracy: 0.9335, F1 Micro: 0.9593, F1 Macro: 0.9559\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1954, Accuracy: 0.9502, F1 Micro: 0.9693, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1562, Accuracy: 0.9585, F1 Micro: 0.9743, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1249, Accuracy: 0.9651, F1 Micro: 0.9784, F1 Macro: 0.9763\n",
      "Epoch 6/10, Train Loss: 0.1022, Accuracy: 0.9618, F1 Micro: 0.9762, F1 Macro: 0.9737\n",
      "Epoch 7/10, Train Loss: 0.0848, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9732\n",
      "Epoch 8/10, Train Loss: 0.0733, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9764\n",
      "Epoch 9/10, Train Loss: 0.0599, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0527, Accuracy: 0.9665, F1 Micro: 0.9792, F1 Macro: 0.9772\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9792, F1 Macro: 0.9772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.94      0.95      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3673, Accuracy: 0.8645, F1 Micro: 0.8645, F1 Macro: 0.8183\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2225, Accuracy: 0.9, F1 Micro: 0.9, F1 Macro: 0.8692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1332, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8806\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0896, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8811\n",
      "Epoch 5/10, Train Loss: 0.0829, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.878\n",
      "Epoch 6/10, Train Loss: 0.0607, Accuracy: 0.9055, F1 Micro: 0.9055, F1 Macro: 0.8751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0462, Accuracy: 0.9082, F1 Micro: 0.9082, F1 Macro: 0.8837\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0398, Accuracy: 0.9182, F1 Micro: 0.9182, F1 Macro: 0.8942\n",
      "Epoch 9/10, Train Loss: 0.0296, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.8897\n",
      "Epoch 10/10, Train Loss: 0.0231, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.8887\n",
      "\n",
      "Sentiment analysis accuracy: 0.9182, F1 Micro: 0.9182, F1 Macro: 0.8942\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       781\n",
      "    positive       0.95      0.76      0.84       319\n",
      "\n",
      "    accuracy                           0.92      1100\n",
      "   macro avg       0.93      0.87      0.89      1100\n",
      "weighted avg       0.92      0.92      0.92      1100\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2147: Accuracy: 0.9608, F1 Micro: 0.9608, F1 Macro: 0.8835\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.76      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.82      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.87      0.76      0.81        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.77      0.63      0.67       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.89      0.90       200\n",
      "     neutral       0.94      0.95      0.94       315\n",
      "    positive       0.86      0.96      0.91        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.88       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.80      0.55      0.65        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.66      0.73        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 370.9396800994873 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 6.078143835067749 seconds\n",
      "New train size: 2197\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.447, Accuracy: 0.8832, F1 Micro: 0.9306, F1 Macro: 0.9242\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2738, Accuracy: 0.9363, F1 Micro: 0.9612, F1 Macro: 0.9588\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1873, Accuracy: 0.9495, F1 Micro: 0.969, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1465, Accuracy: 0.9575, F1 Micro: 0.9737, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1259, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9759\n",
      "Epoch 6/10, Train Loss: 0.1043, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9754\n",
      "Epoch 7/10, Train Loss: 0.0863, Accuracy: 0.962, F1 Micro: 0.9764, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0703, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0573, Accuracy: 0.9661, F1 Micro: 0.979, F1 Macro: 0.977\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0484, Accuracy: 0.9665, F1 Micro: 0.9792, F1 Macro: 0.9771\n",
      "\n",
      "Aspect detection accuracy: 0.9665, F1 Micro: 0.9792, F1 Macro: 0.9771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.95      0.96      0.95       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3671, Accuracy: 0.868, F1 Micro: 0.868, F1 Macro: 0.8275\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2083, Accuracy: 0.8951, F1 Micro: 0.8951, F1 Macro: 0.8593\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1519, Accuracy: 0.9141, F1 Micro: 0.9141, F1 Macro: 0.8889\n",
      "Epoch 4/10, Train Loss: 0.1034, Accuracy: 0.9078, F1 Micro: 0.9078, F1 Macro: 0.8778\n",
      "Epoch 5/10, Train Loss: 0.0662, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.8867\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.048, Accuracy: 0.915, F1 Micro: 0.915, F1 Macro: 0.8897\n",
      "Epoch 7/10, Train Loss: 0.0468, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.8821\n",
      "Epoch 8/10, Train Loss: 0.0271, Accuracy: 0.9078, F1 Micro: 0.9078, F1 Macro: 0.8826\n",
      "Epoch 9/10, Train Loss: 0.0282, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.8852\n",
      "Epoch 10/10, Train Loss: 0.0202, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.8886\n",
      "\n",
      "Sentiment analysis accuracy: 0.915, F1 Micro: 0.915, F1 Macro: 0.8897\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       788\n",
      "    positive       0.93      0.76      0.84       318\n",
      "\n",
      "    accuracy                           0.92      1106\n",
      "   macro avg       0.92      0.87      0.89      1106\n",
      "weighted avg       0.92      0.92      0.91      1106\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2197: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.8887\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.83      0.84        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.82      0.72      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.66      0.73       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.89       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88       162\n",
      "     neutral       0.95      0.96      0.96       387\n",
      "    positive       0.79      0.50      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.87      0.78      0.82       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.93      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 376.16151332855225 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 4.184035778045654 seconds\n",
      "New train size: 2247\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4428, Accuracy: 0.8832, F1 Micro: 0.9311, F1 Macro: 0.9261\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2612, Accuracy: 0.9384, F1 Micro: 0.9624, F1 Macro: 0.9599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1871, Accuracy: 0.954, F1 Micro: 0.9716, F1 Macro: 0.9693\n",
      "Epoch 4/10, Train Loss: 0.151, Accuracy: 0.9536, F1 Micro: 0.9715, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1164, Accuracy: 0.9592, F1 Micro: 0.9748, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0983, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0821, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0681, Accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9762\n",
      "Epoch 9/10, Train Loss: 0.0561, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9755\n",
      "Epoch 10/10, Train Loss: 0.048, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.93      0.93       317\n",
      "       linen       0.95      0.96      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3597, Accuracy: 0.8747, F1 Micro: 0.8747, F1 Macro: 0.8378\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1984, Accuracy: 0.9028, F1 Micro: 0.9028, F1 Macro: 0.8732\n",
      "Epoch 3/10, Train Loss: 0.1369, Accuracy: 0.901, F1 Micro: 0.901, F1 Macro: 0.8702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1038, Accuracy: 0.9064, F1 Micro: 0.9064, F1 Macro: 0.8765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0726, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.885\n",
      "Epoch 6/10, Train Loss: 0.0614, Accuracy: 0.9092, F1 Micro: 0.9092, F1 Macro: 0.8824\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.059, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.8864\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0489, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8856\n",
      "Epoch 9/10, Train Loss: 0.0368, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.875\n",
      "Epoch 10/10, Train Loss: 0.0264, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.8843\n",
      "\n",
      "Sentiment analysis accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8856\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.99      0.94       781\n",
      "    positive       0.96      0.73      0.83       320\n",
      "\n",
      "    accuracy                           0.91      1101\n",
      "   macro avg       0.93      0.86      0.89      1101\n",
      "weighted avg       0.92      0.91      0.91      1101\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2247: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.8818\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.62      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.88      0.88       200\n",
      "     neutral       0.93      0.93      0.93       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.89      0.87       162\n",
      "     neutral       0.95      0.96      0.95       387\n",
      "    positive       0.88      0.32      0.47        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.72      0.76       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.95      0.91      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.84      0.86       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 383.4925582408905 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 36\n",
      "Sampling duration: 2.221954584121704 seconds\n",
      "New train size: 2283\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4414, Accuracy: 0.8799, F1 Micro: 0.9289, F1 Macro: 0.9227\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2608, Accuracy: 0.9394, F1 Micro: 0.963, F1 Macro: 0.9606\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1872, Accuracy: 0.9495, F1 Micro: 0.9691, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1422, Accuracy: 0.9576, F1 Micro: 0.9738, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1195, Accuracy: 0.9594, F1 Micro: 0.9748, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1015, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0828, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0704, Accuracy: 0.9655, F1 Micro: 0.9786, F1 Macro: 0.9765\n",
      "Epoch 9/10, Train Loss: 0.0609, Accuracy: 0.9641, F1 Micro: 0.9776, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0489, Accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9769\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.93      0.96      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3443, Accuracy: 0.8686, F1 Micro: 0.8686, F1 Macro: 0.8279\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1764, Accuracy: 0.9026, F1 Micro: 0.9026, F1 Macro: 0.8737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1326, Accuracy: 0.9072, F1 Micro: 0.9072, F1 Macro: 0.8801\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0993, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.889\n",
      "Epoch 5/10, Train Loss: 0.076, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.8851\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.044, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.8883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0435, Accuracy: 0.9182, F1 Micro: 0.9182, F1 Macro: 0.8948\n",
      "Epoch 8/10, Train Loss: 0.0379, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8843\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0301, Accuracy: 0.9191, F1 Micro: 0.9191, F1 Macro: 0.8961\n",
      "Epoch 10/10, Train Loss: 0.0197, Accuracy: 0.9081, F1 Micro: 0.9081, F1 Macro: 0.8825\n",
      "\n",
      "Sentiment analysis accuracy: 0.9191, F1 Micro: 0.9191, F1 Macro: 0.8961\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.94       774\n",
      "    positive       0.93      0.78      0.85       314\n",
      "\n",
      "    accuracy                           0.92      1088\n",
      "   macro avg       0.92      0.88      0.90      1088\n",
      "weighted avg       0.92      0.92      0.92      1088\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2283: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.8864\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.67      0.29      0.40         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.85      0.78      0.82        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.83      0.68      0.73       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.86      0.90       200\n",
      "     neutral       0.93      0.96      0.94       315\n",
      "    positive       0.89      0.98      0.93        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.92      0.94      0.93       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.77      0.45      0.57        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.76      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.84      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.82      0.76        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.78      0.80       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 390.5329623222351 s\n",
      "Total runtime: 8429.664876461029 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACCoAAAHqCAYAAADInz0eAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAADdkklEQVR4nOzdeXhU5dnH8e8kkIQ17EEQCZsggoAICApqRVncoKK4sqhYF9RKq0Wlaq0trVVerBtoXVBBFEFcwQVFURCQzQVB9n0VSFhDkpn3j0kCgYCEbZLJ93Nd55qZM+ecuZ9o27szv/M8gVAoFEKSJEmSJEmSJEmSJOk4iIl0AZIkSZIkSZIkSZIkqegwqCBJkiRJkiRJkiRJko4bgwqSJEmSJEmSJEmSJOm4MaggSZIkSZIkSZIkSZKOG4MKkiRJkiRJkiRJkiTpuDGoIEmSJEmSJEmSJEmSjhuDCpIkSZIkSZIkSZIk6bgxqCBJkiRJkiRJkiRJko4bgwqSJEmSJEmSJEmSJOm4MaggSZIkSZIKtF69epGcnBzpMiRJkiRJ0lFiUEGSDtOzzz5LIBCgVatWkS5FkiRJOiKvvPIKgUAgz61///45x33yySfceOONNGrUiNjY2HyHB7KvedNNN+X5/gMPPJBzzMaNG49kSJIkSSpC7GclqfApFukCJKmwGj58OMnJyUybNo2FCxdSt27dSJckSZIkHZFHHnmEWrVq5drXqFGjnOcjRozgzTff5PTTT6datWqH9RkJCQmMHj2aZ599lri4uFzvvfHGGyQkJLBr165c+1944QWCweBhfZ4kSZKKjoLaz0qS9ueMCpJ0GJYsWcLkyZMZNGgQlStXZvjw4ZEuKU/bt2+PdAmSJEkqRDp16sR1112Xa2vatGnO+//85z9JTU3lm2++oUmTJof1GR07diQ1NZVx48bl2j958mSWLFnCRRddtN85xYsXJz4+/rA+b2/BYNAvjSVJkqJYQe1njzW/B5ZUGBlUkKTDMHz4cMqXL89FF11Et27d8gwqbNmyhbvvvpvk5GTi4+M58cQT6dGjR64pv3bt2sXDDz/MySefTEJCAieccAK///3vWbRoEQATJ04kEAgwceLEXNdeunQpgUCAV155JWdfr169KF26NIsWLaJz586UKVOGa6+9FoBJkyZxxRVXcNJJJxEfH0+NGjW4++672blz5351z5s3jyuvvJLKlStTokQJ6tevzwMPPADAF198QSAQ4J133tnvvBEjRhAIBJgyZUq+/56SJEkqHKpVq0bx4sWP6BrVq1enXbt2jBgxItf+4cOH07hx41x3vGXr1avXftPyBoNBnnzySRo3bkxCQgKVK1emY8eOfPfddznHBAIB+vbty/Dhwzn11FOJj49n/PjxAMyaNYtOnTpRtmxZSpcuzfnnn8+33357RGOTJElSwRapfvZofT8L8PDDDxMIBJg7dy7XXHMN5cuX5+yzzwYgIyODv//979SpU4f4+HiSk5O5//77SUtLO6IxS9Kx4NIPknQYhg8fzu9//3vi4uK4+uqree6555g+fTotWrQAYNu2bbRt25aff/6ZG264gdNPP52NGzfy3nvvsXLlSipVqkRmZiYXX3wxEyZM4KqrruKuu+5i69atfPrpp/z444/UqVMn33VlZGTQoUMHzj77bB5//HFKliwJwKhRo9ixYwe33norFStWZNq0aTz11FOsXLmSUaNG5Zz//fff07ZtW4oXL87NN99McnIyixYt4v333+cf//gH5557LjVq1GD48OF07dp1v79JnTp1aN269RH8ZSVJkhRJKSkp+62lW6lSpaP+Oddccw133XUX27Zto3Tp0mRkZDBq1Cj69et3yDMe3Hjjjbzyyit06tSJm266iYyMDCZNmsS3337LGWeckXPc559/zltvvUXfvn2pVKkSycnJ/PTTT7Rt25ayZcty7733Urx4cYYOHcq5557Ll19+SatWrY76mCVJknTsFdR+9mh9P7u3K664gnr16vHPf/6TUCgEwE033cSwYcPo1q0bf/rTn5g6dSoDBw7k559/zvPmM0mKJIMKkpRPM2bMYN68eTz11FMAnH322Zx44okMHz48J6jwn//8hx9//JExY8bk+kF/wIABOU3jq6++yoQJExg0aBB33313zjH9+/fPOSa/0tLSuOKKKxg4cGCu/f/+978pUaJEzuubb76ZunXrcv/997N8+XJOOukkAO644w5CoRAzZ87M2Qfwr3/9CwjfkXbdddcxaNAgUlJSSExMBGDDhg188sknuZK9kiRJKnzat2+/377D7U0Pplu3bvTt25exY8dy3XXX8cknn7Bx40auvvpqXn755d88/4svvuCVV17hzjvv5Mknn8zZ/6c//Wm/eufPn88PP/xAw4YNc/Z17dqV9PR0vv76a2rXrg1Ajx49qF+/Pvfeey9ffvnlURqpJEmSjqeC2s8ere9n99akSZNcszrMmTOHYcOGcdNNN/HCCy8AcNttt1GlShUef/xxvvjiC84777yj9jeQpCPl0g+SlE/Dhw8nKSkpp6kLBAJ0796dkSNHkpmZCcDo0aNp0qTJfrMOZB+ffUylSpW44447DnjM4bj11lv327d3E7x9+3Y2btxImzZtCIVCzJo1CwiHDb766ituuOGGXE3wvvX06NGDtLQ03n777Zx9b775JhkZGVx33XWHXbckSZIi75lnnuHTTz/NtR0L5cuXp2PHjrzxxhtAeBmxNm3aULNmzUM6f/To0QQCAR566KH93tu3lz7nnHNyhRQyMzP55JNP6NKlS05IAeCEE07gmmuu4euvvyY1NfVwhiVJkqQIK6j97NH8fjbbLbfckuv1Rx99BEC/fv1y7f/Tn/4EwIcffpifIUrSMeeMCpKUD5mZmYwcOZLzzjuPJUuW5Oxv1aoVTzzxBBMmTODCCy9k0aJFXH755Qe91qJFi6hfvz7Fih29/youVqwYJ5544n77ly9fzoMPPsh7773H5s2bc72XkpICwOLFiwHyXENtbw0aNKBFixYMHz6cG2+8EQiHN84880zq1q17NIYhSZKkCGnZsmWuZROOpWuuuYbrr7+e5cuXM3bsWB577LFDPnfRokVUq1aNChUq/OaxtWrVyvV6w4YN7Nixg/r16+937CmnnEIwGGTFihWceuqph1yPJEmSCoaC2s8eze9ns+3b5y5btoyYmJj9vqOtWrUq5cqVY9myZYd0XUk6XgwqSFI+fP7556xZs4aRI0cycuTI/d4fPnw4F1544VH7vAPNrJA9c8O+4uPjiYmJ2e/YCy64gE2bNvGXv/yFBg0aUKpUKVatWkWvXr0IBoP5rqtHjx7cddddrFy5krS0NL799luefvrpfF9HkiRJRdell15KfHw8PXv2JC0tjSuvvPKYfM7ed69JkiRJR8uh9rPH4vtZOHCfeySz9UrS8WRQQZLyYfjw4VSpUoVnnnlmv/fGjBnDO++8w5AhQ6hTpw4//vjjQa9Vp04dpk6dSnp6OsWLF8/zmPLlywOwZcuWXPvzk3794Ycf+OWXXxg2bBg9evTI2b/vtGfZ097+Vt0AV111Ff369eONN95g586dFC9enO7dux9yTZIkSVKJEiXo0qULr7/+Op06daJSpUqHfG6dOnX4+OOP2bRp0yHNqrC3ypUrU7JkSebPn7/fe/PmzSMmJoYaNWrk65qSJEkqeg61nz0W38/mpWbNmgSDQRYsWMApp5ySs3/dunVs2bLlkJdZk6TjJea3D5EkAezcuZMxY8Zw8cUX061bt/22vn37snXrVt577z0uv/xy5syZwzvvvLPfdUKhEACXX345GzduzHMmguxjatasSWxsLF999VWu95999tlDrjs2NjbXNbOfP/nkk7mOq1y5Mu3ateOll15i+fLledaTrVKlSnTq1InXX3+d4cOH07Fjx3x9sSxJkiQB/PnPf+ahhx7ir3/9a77Ou/zyywmFQvztb3/b7719e9d9xcbGcuGFF/Luu++ydOnSnP3r1q1jxIgRnH322ZQtWzZf9UiSJKloOpR+9lh8P5uXzp07AzB48OBc+wcNGgTARRdd9JvXkKTjyRkVJOkQvffee2zdupVLL700z/fPPPNMKleuzPDhwxkxYgRvv/02V1xxBTfccAPNmzdn06ZNvPfeewwZMoQmTZrQo0cPXn31Vfr168e0adNo27Yt27dv57PPPuO2227jsssuIzExkSuuuIKnnnqKQCBAnTp1+OCDD1i/fv0h192gQQPq1KnDn//8Z1atWkXZsmUZPXr0fmuhAfz3v//l7LPP5vTTT+fmm2+mVq1aLF26lA8//JDZs2fnOrZHjx5069YNgL///e+H/oeUJElSofX999/z3nvvAbBw4UJSUlJ49NFHAWjSpAmXXHJJvq7XpEkTmjRpku86zjvvPK6//nr++9//smDBAjp27EgwGGTSpEmcd9559O3b96DnP/roo3z66aecffbZ3HbbbRQrVoyhQ4eSlpZ20LWFJUmSVLhFop89Vt/P5lVLz549ef7559myZQvnnHMO06ZNY9iwYXTp0oXzzjsvX2OTpGPNoIIkHaLhw4eTkJDABRdckOf7MTExXHTRRQwfPpy0tDQmTZrEQw89xDvvvMOwYcOoUqUK559/PieeeCIQTtJ+9NFH/OMf/2DEiBGMHj2aihUrcvbZZ9O4ceOc6z711FOkp6czZMgQ4uPjufLKK/nPf/5Do0aNDqnu4sWL8/7773PnnXcycOBAEhIS6Nq1K3379t2viW7SpAnffvstf/3rX3nuuefYtWsXNWvWzHN9tUsuuYTy5csTDAYPGN6QJElSdJk5c+Z+d4tlv+7Zs2e+v9g9Ei+//DKnnXYaL774Ivfccw+JiYmcccYZtGnT5jfPPfXUU5k0aRL33XcfAwcOJBgM0qpVK15//XVatWp1HKqXJElSJESinz1W38/m5X//+x+1a9fmlVde4Z133qFq1arcd999PPTQQ0d9XJJ0pAKhQ5kvRpKkfWRkZFCtWjUuueQSXnzxxUiXI0mSJEmSJEmSpEIiJtIFSJIKp7Fjx7JhwwZ69OgR6VIkSZIkSZIkSZJUiDijgiQpX6ZOncr333/P3//+dypVqsTMmTMjXZIkSZIkSZIkSZIKEWdUkCTly3PPPcett95KlSpVePXVVyNdjiRJkiRJkiRJkgoZZ1SQJEmSJEmSJEmSJEnHjTMqSJIkSZIkSZIkSZKk48aggiRJkiRJkiRJkiRJOm6KRbqAoyUYDLJ69WrKlClDIBCIdDmSJEk6hkKhEFu3bqVatWrExERf9tbeVpIkqeiwt5UkSVK0yE9vGzVBhdWrV1OjRo1IlyFJkqTjaMWKFZx44omRLuOos7eVJEkqeuxtJUmSFC0OpbeNmqBCmTJlgPCgy5YtG+FqJEmSdCylpqZSo0aNnB4w2tjbSpIkFR32tpIkSYoW+eltoyaokD1tWNmyZW14JUmSiohonTrW3laSJKnosbeVJElStDiU3jb6Fj2TJEmSJEmSJEmSJEkFlkEFSZIkSZIkSZIkSZJ03BhUkCRJkiRJkiRJkiRJx41BBUmSJEmSJEkqIp555hmSk5NJSEigVatWTJs27YDHpqen88gjj1CnTh0SEhJo0qQJ48ePP47VSpIkKVoZVJAkSZIkSZKkIuDNN9+kX79+PPTQQ8ycOZMmTZrQoUMH1q9fn+fxAwYMYOjQoTz11FPMnTuXW265ha5duzJr1qzjXLkkSZKijUEFSZIkSZIkSSoCBg0aRJ8+fejduzcNGzZkyJAhlCxZkpdeeinP41977TXuv/9+OnfuTO3atbn11lvp3LkzTzzxxHGuXJIkSdHGoIIkSZIkSZIkRbndu3czY8YM2rdvn7MvJiaG9u3bM2XKlDzPSUtLIyEhIde+EiVK8PXXXx/wc9LS0khNTc21SZIkSfsyqCBJkiRJkiRJUW7jxo1kZmaSlJSUa39SUhJr167N85wOHTowaNAgFixYQDAY5NNPP2XMmDGsWbPmgJ8zcOBAEhMTc7YaNWoc1XFIkiQpOhhUkCRJkiRJkiTt58knn6RevXo0aNCAuLg4+vbtS+/evYmJOfDXyvfddx8pKSk524oVK45jxZIkSSosDCpIkiRJkiRJUpSrVKkSsbGxrFu3Ltf+devWUbVq1TzPqVy5MmPHjmX79u0sW7aMefPmUbp0aWrXrn3Az4mPj6ds2bK5NkmSJGlfBhUkSZIkSZIkKcrFxcXRvHlzJkyYkLMvGAwyYcIEWrdufdBzExISqF69OhkZGYwePZrLLrvsWJcrSZKkKFcs0gVIkiRJkiRJko69fv360bNnT8444wxatmzJ4MGD2b59O7179wagR48eVK9enYEDBwIwdepUVq1aRdOmTVm1ahUPP/wwwWCQe++9N5LDkCRJUhQwqCBJkiRJkiRJRUD37t3ZsGEDDz74IGvXrqVp06aMHz+epKQkAJYvX05MzJ5JeHft2sWAAQNYvHgxpUuXpnPnzrz22muUK1cuQiOQJElStDispR+eeeYZkpOTSUhIoFWrVkybNu2Ax6anp/PII49Qp04dEhISaNKkCePHj9/vuFWrVnHddddRsWJFSpQoQePGjfnuu+8OpzxJkiTpkNnbSpIkqSjp27cvy5YtIy0tjalTp9KqVauc9yZOnMgrr7yS8/qcc85h7ty57Nq1i40bN/Lqq69SrVq1CFQtSZKkaJPvGRXefPNN+vXrx5AhQ2jVqhWDBw+mQ4cOzJ8/nypVqux3/IABA3j99dd54YUXaNCgAR9//DFdu3Zl8uTJNGvWDIDNmzdz1llncd555zFu3DgqV67MggULKF++/JGPUJIkKQqkpcHixbBoEQSDUKIEJCSEH/Pa4uIgEIh01QWfva0kSVIEZKbBtsWwbRGEghBbAmITsh5LQLESe57HloAYm1tJkiRFn9S0VL5b/R0NKjWgWpmiFwYNhEKhUH5OaNWqFS1atODpp58GIBgMUqNGDe644w769++/3/HVqlXjgQce4Pbbb8/Zd/nll1OiRAlef/11APr3788333zDpEmTDnsgqampJCYmkpKSQtmyZQ/7OpIkSZGSmQkrVsCCBfDLL7m3pUvDAYVDFQjkDi6ULAknnQT16sHJJ+/ZkpOhWCFcDOxo9X72tpIkScdIMBN2rICtC2DrL5D6S/hx6y+wfWk4oHDIAvsEGEpCqZOgTD0oc3J4K3sylEqGmMLX3EZ77xft45MkSTpUoVCI79d9z7iF4xi3cByTV0wmI5hBbCCWS+pfwh+a/4ELal9AbExspEs9bPnp/fLVue/evZsZM2Zw33335eyLiYmhffv2TJkyJc9z0tLSSEhIyLWvRIkSfP311zmv33vvPTp06MAVV1zBl19+SfXq1bntttvo06dPfsqTJElZQiGYPBliY6FVK28+KihCIdiyBVatCm8rV+YOJSxcGJ454UBKlw4HDeLiYOfOvLfsCGooBDt2hLdsv/wCn32W+5rFikGdOuHQwr4hhmrV9vy7s3s3bNsGW7fm/ZieDjfccFT/XMecva0kSYVEKAQbJ0MgFira3BYYoRCkb4Edq8LbzpXhUEJOIGEhBA/S3BYrHQ4axMRB5s7cW0bWI9n3V4Ugc0d4y7b1F1i7T3MbKAZl6mSFF+rtCTCUORlK7NXcZu6GjG2QsRXSsx4ztkF61mMwHeoUsuZWkiRJBdKWXVv4bPFnjFswjvGLxrN66+pc759Q+gTWbFvD2HljGTtvLDUTa9Ln9D7c0OwGTihzwmF/7twNcxn+/XA27tjI0EuGHukwjol8BRU2btxIZmYmSUlJufYnJSUxb968PM/p0KEDgwYNol27dtSpU4cJEyYwZswYMjMzc45ZvHgxzz33HP369eP+++9n+vTp3HnnncTFxdGzZ888r5uWlkbaXt/kp6am5mcokiRFpWAQ3n0XHn0UZs4M76tTB3r1gh49wnfUF2Vr18ITT8AXX8C558Ktt4b/PkdDWhqsWbMnhLBqFaxevf/rnTsPfp24uD3BgX23pKSDfy8fCoUDBXkFGLZtC8/KkB2KWLAgvO3cCfPnh7d9lSwZXl5i27bwdQ8mPr7wBRXsbSVJKuBCQVj5Lvz4KGzOam5L14HavaBWj/Ad9UXZzrUw7wlY9wVUORfq3Rr+kf5oyEyDnWtgZ3YIYRXsXL3n+Y6s15m/0dzGxIX/mWWHBfYODiQcQnMb3J13gCFjW3hWhpxQxILwlrkTUueHt33FlgwvL5GxLXzdg9Ydb1BBkiRFlckrJvPWT29xV6u7qFW+VqTLiWqhUIjZa2czfuH4nFkTMkN7vjssUawEv6v1OzrV7USnep2oXb42P63/iRdmvsCwOcNYlrKMAV8M4OEvH+bS+pfyh+Z/oH3t9sQEYn7zs1emruSNH95g+A/DmbNuDgCxgVge/d2jVC5V+ZiN+XDla+mH1atXU716dSZPnkzr1q1z9t977718+eWXTJ06db9zNmzYQJ8+fXj//fcJBALUqVOH9u3b89JLL7Ez65v6uLg4zjjjDCZPnpxz3p133sn06dMPeDfbww8/zN/+9rf99juFmCSpKMrMhNGjwwGFH34I7ytZEmJiwj8yQ/g7wPPPh969oUuX8PtFxcqV8Nhj8MILsGvXnv2BAHTsCLffDp06hf9eB7NjR3jWg32XZli4ENavP/R6KlSA6tXDW926ucMIJ50UngnjeAgGwwGKvceSPbbFi8P/Xu0rPh7KlAnP7pD9mP181Kjf/hseLUdj+lh7W0mSCqhgJqwYDT89CluymtvYkhCICf/IDEAAqp4PtXvDiV2gWBFqbneshLmPwaIXIHOv5pYAnNARTr4dqnUK/70OJmNHeNaD7KUZspdn2LYQduWjuY2rACWrQ4nqUKZu7kBCyZPgeE1bGwqGAxR7jyV7bNsWQyiP5jYmHoqXCc/ukP2Y/fzsUb/9NzxKon1phGgfnyRJBd2Yn8dw9eir2Z25m4olKvLWFW/xu1q/i3RZUSUUCvH+L+/zzrx3GL9wPGu3rc31fv2K9XOCCe1qtiOhWEKe19mZvpNRc0cxdMZQJq/Y891i7fK16XN6H3o37U1S6dw3XW3euZm3577N8B+G89WyrwhlzUpWLKYYnep24trG13JZg8sO+JlHW356v3wFFXbv3k3JkiV5++236dKlS87+nj17smXLFt59990Dnrtr1y5+/fVXqlWrRv/+/fnggw/46aefAKhZsyYXXHAB//vf/3KOf+6553j00UdZtWpVntfL666zGjVq2PBKkoqUjAwYORL+8Q/IvgG8TBm44w64++7w3fBjxsDLL8PEiXvOK1sWrroqPNPCmWdG7+y5y5bBv/4FL720Z0aAM8+Enj3DM0+MH7/n2Nq1wzMs9OgBKSn7/3D/yy+wYsXBPy8+PrxcQnYIoXr1vF8nHJ+e8Iikp4dnYMjI2BNGKF0aihePdGVhR+PLTntbSZIKmGAGLBsJP/0DUrOa22JloP4dUP/u8N3wK8bA4pdh/cQ95xUvCzWvglq9oFIUN7fbl8FP/4LFL+2ZEaDimVC7Z3jmiTV7Nbela4dnWKjVA3an7Pnxfu+lGXb8RnMbEx9eLiE7hFCyevh19vPs17GFoLkNpsO2pRDKyAoiZAUSYgpGcxvtP+RH+/gkScqPzTs38+hXj1K+RHnuaXMP8cXij+nn/W/m//jDB38gGAqSGJ9ISloKsYFYnrjwCe5sdSeBaO2dj6NQKMSfPvkT//ft/+XsK1m8JOfXOp9OdTvRsW7Hw5rF4sf1P/L8jOd5dc6rpKSlAOHwQZcGXbj59JvZsmsLw38YzkcLPiI9mJ5zXtuT2nJt42vp1rAbFUtWPPIB5tMxCyoAtGrVipYtW/LUU08BEAwGOemkk+jbty/9+/f/zfPT09M55ZRTuPLKK/nnP/8JwDXXXMOKFSuYNGlSznF33303U6dOzXUn2sHY8EqSipL0dHjtNRg4MHw3P0C5cvDHP8Kdd0L58vufs2QJDBsW3pYu3bO/fv09S0NUq3bsaz8eFi4M/21efTX8QztAu3bw17+GZ5XI7r8XLoTnngsHGbZsObRrlysX/pvtPQtCvXrhmRAqVIje78ULmqPV+9nbSpJUAATTYclr8NPA8N38AMXLQYM/Qv07IS6P5nbbElg8DJYMCy8BkK1s/XBgoVYPKBklze3WheG/zZJXwz+0A1RpB43+Ckl7NbdbF8KC52DRS5C+5dCuXbxc+G+295IMZeqFl9WIs7k9XqK994v28UmSdKjGLRjHTe/fxOqtqwFoktSE4b8fzqlVTj3qnxUKhXjsm8foPyH8/daNzW5kcMfB3Pbhbbz2/WsA9GzSkyEXDzlud9pHo31DCre3uJ0uDbrQ9qS2Ry2EsiN9B2/99BbPz3ieKSvznq31tKTTuKbRNVzd+GpOSozsEnnHNKjw5ptv0rNnT4YOHUrLli0ZPHgwb731FvPmzSMpKYkePXpQvXp1Bg4cCMDUqVNZtWoVTZs2ZdWqVTz88MMsWbKEmTNnUq5cOQCmT59OmzZt+Nvf/saVV17JtGnT6NOnD88//zzXXnvtUR+0JEmFVVpaeHaEf/0rPFsAQMWK0K8f9O0bninhtwSD8OWX8Mor8Pbb4eUMIDxlf4cO4dDCpZcWjrv+9zVvXnh2iREjwuMEaN8+HFBo1+7A5+3YET7nmWdg9mwoUSIcPtg3jHDyyeG/t9/XRt7R6v3sbSVJiqDMtPDsCHP/FZ4tACC+IjToByf3Dc+U8FtCQVj/JSx+BZa/DZlZzW0gBqp2gNq94MRLC8dd//tKmReeXWLZiPA4Aaq2DwcUqhykuc3YAUtHwIJnYPNsiC0RDh/sG0Yoc3L4721zG3HR3vtF+/gkSfotqWmp9Pu4Hy/OehGAuhXqsmXXFjbu2Eh8bDyPXfAYfVv2JeYoLTsVCoW459N7eGLKEwD85ay/MPD8gQQCAUKhEIO/HcyfP/0zwVCQltVb8k73d6hWJkpCvsdRKBSi38f9GDx1MABDLx7Kzc1vPqaf+f2673l+xvO88eMblIkrw9WNruba066lUZVGx/Rz8+OYBhUAnn76af7zn/+wdu1amjZtyn//+19atWoFwLnnnktycjKvvPIKAF9++SW33norixcvpnTp0nTu3Jl//etfVNvnls0PPviA++67jwULFlCrVi369etHnz59DrkmG15JUjTbuRP+9z/4978he+b4pCT485/hllvCU/Ifjq1bYdSocPjh66/37C9fHrp3h/POg5YtoWbNY/v9ZSgUDmHExx/e5/zwAzz6aHgs2Z1N584wYAC0bp2/OjZvDs+aEHN8lqPVYTqavZ+9rSRJx1nGTlj0P5j7b9iZ1dwmJMEpf4a6t4Sn5T8c6Vth+ahw+GHDXs1tXHk4qTsknQcVW0Kp49DcBtPCSycczuds+QF+fDQ8lqz1ZanWGU4dAJXz2dzu3gxx5cLBDRVY0d77Rfv4JEk6mAmLJ3DDezewPGU5AQLc1eou/nH+P0hNS+WGd29g3MJxAFxQ+wJe6fLKEQcGMoIZ9Hm/D6/MfgWA/1zwH/7c5s/7HffZ4s+4ctSVbN61maqlqzLmyjG0rpGPXrOIi0RIobA45kGFgsiGV5IKnu3b4aOP4KefoG3b8B3tBWV9+4Js925YsSK8PMPSpbBgQXj2g3Xrwu9Xrw733gt9+oTv/D9aFi4Mf86wYbByZe73KlUKBxZatNjzWLny4X1Oair8+GM4XJD9+MMPsGlTOKhQseKerUKF3K/33bZsCYc3xo7dc/0uXcIBhebND68+FQ7R3vtF+/gkqVDK2A6rP4ItP0GVtuE72gvI+vYFWuZu2LEivDzD9qWwdUF49oNdWc1tierQ8F6o0weKHcXmduvC8OcsGQY79mlu4yuFAwsVWoQfK7aAhMNsbtNTYcuP4XBBStbjlh9g96ZwUCG+YniLqwjxFbIe99631/P0LeHwxsqxe65/YhdoNAAq2NxGs2jv/aJ9fJIk5WXb7m385dO/8Ox3zwJQq1wtXunyCu1q7pkZKxQK8dx3z/GnT/7EroxdVChRgaEXD6Vbw26H9Zk703dy1eireG/+e8QGYvnfpf+jV9NeBzx+0aZFdHmzCz+u/5G42Die7fwsN55+42F9dlESCoW4++O7eXLqkwA8f/Hz9Gl+6DcoRTuDCja8khQx27fDhx+G72z/6KM9ywpA+C79iy8O/5DcoQOUKhWxMtm1KxygmD07/Fi8ePhH8QoVwnVmP8/eSpU6ejddpaeHgwBLluwJI+y9rVq1Z9mCvdWsCf37Q+/e4R/0j5XMTPjiC3jnHZg2DebMCde8r+Tk3OGF00/PPbPD7t3hpRj2DiP88AMsX370aw4E4Ior4IEH4LTTjv71VfBEe+8X7eOTpEIjYzus+jB8Z/vqj/YsKwDhu/SrXQw1usAJHaBYBJvbzF2Q8lN4mv8tP4UDFPEVIK5CuM64Cnu9rhCu9Wg1t8H0cBBg25I9YYRtS/c837lqz7IFeytVExr2h9q9IfYYNrfBTFj/Bax4B36dBlvmhGver57kPaGFii2h/Om5Z3bI3A2p83KHEbb8ADuOQXNLAE66Ak59AMrb3BYF0d77Rfv4JEna16Rlk+j1bi8Wb14MwK1n3MpjFzxG6bi8Zw6bt3Ee1465lplrZgLQq2kvnuz4JGXjD/1/N1N2pXDpyEv5atlXxMfG82a3N7mswWW/ed623dvoObYnY34eA0DfFn0Z1GEQxWMNZefFkMJvM6hgwytJx9W2bbnDCTt37nmvVq3wD9lffAEbNuzZn5AAF14YDi1cckn4jv1jZdOmcCAhe5s1C37+OfyD/KH6rSDDvu+VKROeAWHp0v0DCStX5h1E2FtCQjgIUKtW+PHMM+HqqyMzI0VaWjisMG0aTJ8efpw3b//jYmKgYUOoWzc8C8T8+ZCRkfc1q1eHxo2hUaPwY+PG4XGmpsKvv/72tmlT+HHnTujWLRxQOOWUY/pnUAET7b1ftI9Pkgq09G2weu9wwl7Nbala4R+y130BaXs1t7EJUPXC8N3v1S+BhGPY3KZtCgcScrZZkPozhPLR3MYU3xNayCvIsG/IoXiZ8AwI25fuH0jYuTLvIMLeYhPCQYBStaB0MlQ8E5KvjsyMFJlpsHlOOLSwaXr4MTWP5jYQA2UbQpm64VkgUudD6ADNbYnqUK4xlGsEiY3Dz0snh2dbSPt1z7b7QM83hR8zd8JJ3cIBhUSb26Ik2nu/aB+fJEnZdqbv5IHPH2Dwt4MJEaJG2Rq8dNlLtK/d/jfP3Z25m79N/Bv/+uZfBENBkssl81rX1zj7pLN/89x129bRcXhHZq+dTdn4srx31Xuck3zOIdcdDAX5x1f/4MGJDwJwTs1zGHXFKCqXOsxZxw5TKBRizbY1R7z8xbGyb0jhhUte4KbTb4pwVQWPQQUbXkk65rZuhQ8+CIcTxo0Lz1CQrXbt8N3tV1wRvss+EAiHAiZPDk/R/8474R/vs8XEhJeG6NIlvCUnH15NoRAsWxYOIuwdTDjQHfwVK0KzZuEfyQOB8I/feW27dx9ePQcTHx8e595bdighORmqVDm2y+YeqZQUmDEjd3hh3+UiABITc4cRGjeGU08NhzmOhlCoYP+ddOxEe+8X7eOTpAInfSus+iAcTlgzLjxDQbbStcN3t590Rfgu+0AgfJf+xsnhKfpXvAPb92puAzFQuW04tHBil/AP1ocjFILty8JBhL2DCQe6gz++IpRvFv6hPBDI+vF7U/hx7+fBY9DcxsSHx1lqr610rT3PEwp4c7s7BTbNyB1e2He5CIDiibnDCOUaQ+Kp4WDH0WBzW2RFe+8X7eOTJAlg6sqp9Bzbk/m/zgfghqY3MKjDIBITEvN1na+Xf83171zP0i1LiQnE0P+s/jx07kPExcblefySzUu48PULWbhpIVVKVWH8teNpdkKzwxrDu/Pe5bp3rmPb7m2clHgS7171Lk2rNj2sax2OO8fdyVPTnqJnk568cMkLBWpWh1AoxB/H/5H/TvsvYEjhYAwq2PBK0jGxdSu8/344nDB+fO5wQt26e8IJTZse/Pu1UCi8BMA774SDC7Nn536/aVPo2jUcWsgOEexr9+7wrAj7hhJSUvL+zNq1w9dt1iz82LRp+K7+3/oeMBQK37V/oBBD9rZ5c+7XKSnhsEFeIYTkZEhKCgc0osmaNeHQwpIlUK9e+J/diSf6XauOjWjv/aJ9fJJUIKRvhVXvZ4UTxu8TTqi7Vzih6W83t1t+gJXvhIMLm2fnfr98Uzixazi0UO4AzW3m7vCsCPuGEtIP0NyWrh2+bvlmWY9Nw3f1H0pzm7nzwCGGnOebc79OTwmHDfIKIZROhoSkcEAjmuxcA79OD88gUaZe+J9dSZtbHRvR3vtF+/gkSUVbWkYaD098mMcmP0YwFOSE0ifwwiUvcNHJFx32NVPTUrlz3J0MmzMMgOYnNOf1379Og0oNch33w7of6PB6B9ZsW0NyuWQ+ue4T6lWsd0TjmbthLpeNvIyFmxZSolgJXr7sZbo36n5E1zwUo34axZVvX5nzulPdToy6YhSl4vK/xF5mMJNPFn3Ci7Ne5ONFH9OoSiOuOvUqrjz1Sk4oc0K+r2dIIX8MKtjwStJRk5qaO5yQlrbnvXr19oQTmjQ5/O/sli4NBxbGjoVJk3Ivi1C7djiwcM454eOygwk//QTpeSwtW7x4+A7+7DBCs2Zw2mnhO/slRY9o7/2ifXySFDHpqbDyfVgxClaPh+BezW2ZenvCCeWOoLndtjQcWFg5FjZMyr0sQuna4cBClXPCSydkBxNSfoJgHs1tTHFIbLQnjFC+GZQ7DeJsbqVoEu29X7SPT5JUNO1I38G3K7/lrvF38eP6HwG47rTreLLjk1QocXRm3Hp77tvc/P7NbN61mRLFSvDEhU9wyxm3EAgEmLxiMheNuIgtu7bQqEojPr7u46O2ZMLmnZu5evTVfLzoYwD+ctZf+Of5/yTmGIWTF29eTLOhzUhNS6VLgy58vPBjdmbspEW1Fnx4zYeHvATF4s2LeWnWS7wy+xVWbV213/sBApybfC5XN7qa35/yeyqWrPib1wyFQtw1/i6emvYUAP+75H/cePqN+RtgEWNQwYZXko5ISgq89144nPDxx7mXPqhff0844UCzHRyJDRvCS0qMHQuffJJ71oZ9JSbuP0vCKadAXN6zYEmKItHe+0X7+CTpuNqdAqvey5o54ePcSx+UrQ81ssMJx6C53bUhvKTEyrGw9pPcszbsq3ji/rMklD0FDjDFq6ToEe29X7SPT5IU3UKhEGu3rWX22tnMWTcn5/GXX38hmBVKrlKqCkMuGkLXU7oe9c9flbqKXu/24rPFnwHQuV5nrm50NTe/fzM7M3bSpkYbPrj6A8qXKH9UPzczmMl9E+7jP5P/A8C9be7l3xf8+6h+BsDuzN20fbkt01ZN46waZzGx10S+W/0dF4+4mF93/kq9CvX4+LqPqVW+Vp7n70zfyZifx/DirBf5YukXOfsrlKjA9addzxUNr2DGmhmM/HEkU1ZOyXm/WEwxOtTpwFWNruKy+pdRJr7MftfeO6QQIMALl7xgSOEQGFSw4ZWkfNuyZU844ZNPcocTGjTYE05o1Oj4zXa6bVu4lrFjYcaM8PISewcTatZ05lWpqIr23i/axydJx9zuLbAyK5yw9pN9wgkN9syckHgcm9v0beFaVoyFzTPCy0vsHUwoZXMrFVXR3vtF+/gkSdEjPTOd+b/OZ87aObmCCRt2bMjz+CqlqtC5Xmcea//YId/1fziCoSBPTX2Kv3z2F9Iy98wK16luJ96+8m1KFi95zD77pVkvceN74R/nX+/6Oteedu1Rvf49n9zD41Mep3xCeWbfMpuTEk8CYP7G+XR4vQPLUpZRtXRVPrrmI5qd0AwIBwhmrpnJi7NeZMQPI0hJCy+ZFyDABXUu4MZmN3JZ/cuILxaf67OWblnKmz++yRs/vsGcdXNy9icUS+Diky/mqlOvonO9zpQoXoJQKMSd4+7k6elPEyDA/y79Hzc0u+Gojj1aGVSw4ZWkQ7J5M7z7Lrz9djgQsPdSCqecsieccOqpfmcqqWCJ9t4v2scnScfE7s2w8l1Y/nZWOGGv5rbsKXuFE2xuJRUs0d77Rfv4JEmF05ZdW5izdk6uWRJ+Wv9TriBAtphADPUr1qdp1aY0SWoSfqzahKqlqx7Xmn9c/yPXjbmOOevmcE3ja3jlslcoHlv8mH/u/RPuZ+DXA4mPjWdS70m0qN7iqFx33IJxdB7RGYB3ur9DlwZdcr2/eutqOg3vxPfrvqdMXBle7foqK1JW8OKsF3MFDWom1qR30970atqLmuVqHtJn/7zhZ0b+OJI3fnyDBZsW5OwvE1eGLg26EAgEeHXOq4YUDoNBBRteSUVUKARpaeHlEg62rVwJY8bAZ5/lDieceuqecELDhpEbhyT9lmjv/aJ9fJJ0SEIhCKaFl0vYewvu83rHSlgxBtZ9ljuckHjqXuEEm1tJBVe0937RPj5JOhoyg5m8PfdtRv88mlJxpUgqlUSVUlVIKpVEUuk9zyuVrERsTGykyy00MoOZrExdycJNC3O2Xzb9wvfrvmfplqV5nlMmrgynJZ2WK5RwapVTj+msBfmRnpnOL7/+QsPKDQkcpwB2MBSky8guvP/L+1QrU43pfaZTrUy1I7rmqtRVNB3alI07NnJHyzv4b6f/5nlcyq4UurzZhYlLJ+baHx8bT9dTunJjsxv5Xa3fEROIOaw6QqEQs9fO5o0f32DkjyNZkboi5z1DCofHoIINr6QCLDMT5s2Dn3+G7dt/O1Sw97Zz58HfT9s/7PmbGjXaE0445ZSjP15JOhaivfeL9vFJiiLBTEidB6k/Q8b2A4cJ8ty38zeOP4zmNrHRXuEEm1tJhUO0937RPj5JOhLZAYVHvnqEuRvm/ubxAQJUKlkpV3gh12PppFzPE4olHIdRRFZGMINlW5blCiMs3Bx+XLx5Mbszdx/w3JMST8o9S0JSE2qVr3XYP3pHs9S0VFq/2Jq5G+bSsnpLvuz15WH/+5UZzKT9a+2ZuHQizao2Y8qNU/ZbpmFvuzJ20XNsT9766S2aVm3Kjc1u5JrG11ChRIXDHU6egqEgU1ZMYeSPI/ly2Zfc0+Yerm9y/VH9jKLAoIINr6QCIjuUMGPGnm3WLNix49h/diAACQl5b2XKQPv24XBCgwbHvhZJOtqivfeL9vFJKqSyQwmbZoS3zTNg0yzIPA7NLQGITdizxez1vHgZSGqfFU6wuZVU+ER77xft45Okw5FXQKFcQjluPeNWysSVYd32dazbvo7129ezblv4ceOOjYTI3096ZeLK5Ao17B1iqFKqCsnlkml+QvPjdmf+4dqduZslm5fkGUZYumUpGcGMA55bPKY4tcvXpm6FutStUJc65evQOKkxpyWddtR/6I52izYtosULLdi8azPXn3Y9w7oMO6x/d/428W88/OXDlI4rzcybZ1KvYr3fPCcUCrFhxwaqlKpyOKXrOMpP71fsONUkSVEvP6GEUqWgcWMoX/7AYYIj3YoXd+ldSZIkHab8hBKKlYLExhBXPneYYN9AwW/tP9ixMTa3kiRJKvwOFFDod2Y/7mx1J4kJiQc8NyOYwcYdG3OFF3LCDNvX7bdvd+Zutu7eytZNW1m4aeEBr/u7Wr/jmc7P0KBSwQn9pmemM3beWIbNGcbcDXNZlrKMYCh4wOPjY+OpU6EOdSvUpV6FejmhhLoV6lKjbA2XyzhK6lSow6grRtHh9Q689v1rnJZ0Gn9u8+d8XePLpV/yyFePADDkoiGHFFIACAQChhSikEEFSToM+Q0lNGsGZ5wBzZuHt5NPhlh7I0mSJBUE+Q0llG8GFc6ACs3DW5mTwS/+JEmSpAM6koBCtmIxxahauipVS1eFpIMfGwqFSElL2T/QsNfrddvXMXPNTD5f8jmnPXcaf2r9Jwa0G0CpuFJHY8iHZe22tbww4wWGzBjC6q2rc71XsnjJPQGE8nVzhRGql63ucg3Hyfm1z2dwx8HcMe4O7v30XhpWbkjnep0P6dwN2zdwzZhrCIaC9Grai2tPu/YYV6uCzqCCJP2G/IYSTj99TyDBUIIkSZIKlHyHEk7fE0gwlCBJkiTly9EIKByOQCBAuYRylEsoR/1K9Q943OLNi7lr/F188MsH/OubfzH8h+EM7jiYrg26HrflIEKhEN+u/Janpz/NqJ9GkR5MB6BKqSrcfPrNXFjnQupWqEvV0lUL/BIVRcXtLW7n+3Xf88LMF7h69NVMvWnqb87IEQqF6PVuL1ZvXU2DSg14utPTx6laFWQGFSRpL/uGEr77DmbPzjuUULp0eKYEQwmSJEkqkPYNJWz6DjbPPkAooXTWTAmGEiRJkqQjFamAQn7VLl+b969+n/fmv8ed4+5kWcoyLn/rcjrW7chTnZ6iboW6x+yzd6bvZOSPI3l6+tPMXDMzZ3/rE1vTt2VfLj/lcuKLxR+zz9fhCwQCPN35aX7e+DNfL/+aS9+4lKk3TaV8ifIHPOf/vv0/PlrwEfGx8bzZ7c2IztyhgsOggqQi60hCCWecAfXqGUqQJElSAXFEoYQzoEw9QwmSJEnSETpQQOHuM+/mzlZ3Ui6hXGQLPIBL619K+9rtGThpII9NfozxC8fT6NlG/OWsv9D/7P6UKF7iqH3W0i1LeW76c/xv1v/YtHMTAPGx8VzT+Bpub3E7zas1P2qfpWMnLjaO0VeOpsULLViwaQHd3+7OR9d+RLGY/X96nr5qOv0/6w/A4I6DOS3ptONdrgqoQCgUCkW6iKMhNTWVxMREUlJSKFu2bKTLkVTAhEKwbBlMngxTpxpKkKTCLtp7v2gfn6QjFArB9mWwcTJsnGooQZIKuWjv/aJ9fJIEEAwFGfXTqEIXUMjLL7/+wh3j7uCTRZ8AUKtcLf7b6b9cfPLFh33NYCjIhMUTeHr607w//31ChH+arJlYk9ta3MaNzW6kYsmKR6V+HV+z187mrJfOYkf6Du4+824GdRiU6/2UXSk0G9qMJVuW0K1hN97q9pZLeES5/PR+zqggKSqlpcGsWeFgQva2Zs3+x+0dSjjjjPCjoQRJkiQVKJlpsHkWbJicFU6YDDvzaG5zhRLOyFq+wVCCJEmSdKwEQ0Henvs2f/vyb4U+oJDt5IonM/7a8Yz+eTR3f3w3S7Ys4ZI3LuHS+pfyZMcnSS6XfMjXSk1LZdjsYTwz/Rnm/zo/Z/8FtS+gb8u+XFTvImL9/yuFWtOqTXm1y6t0G9WN//v2/2hcpTG9m/UGIBQKcfMHN7NkyxKSyyXzwiUvGFJQLgYVJEWFtWthypQ9oYQZM8Jhhb0VKwannw6tW0OLFuFQwsknQ0xMZGqWJEmS8rRzLWycEg4kbJgcXsohuE9zGygGFU6HSq2hQotwKKHsyRCwuZUkSZKOtbwCConxifRr3a/QBhT2FggE6NawGx3rduTvX/6dQd8O4r357/Hpok95oO0D/LnNn4kvFn/A8+dumMsz057h1e9fZdvubQCUiStD76a9ua3FbdSvVP94DUXHweUNL+ehcx7ib1/+jVs+vIX6lerTpkYbXpj5Am/99BbFYoox8vKRhf4/Fzr6XPpBUqGTmQk//ph7toTFi/c/rnJlaNNmz9a8OZQ4ektpSZIiKNp7v2gfn6S9BDMh5cc9oYSNk2FbHs1tfGWo3AYqZW0VmkMxm1tJigbR3vtF+/gkFS3RHlA4kLkb5nL7R7czcelEAOpVqMfTnZ/mwjoX5hyTEczg/fnv8/T0p/l8yec5+xtWbkjfFn257rTrKBNf5niXruMkGApyxagrGPPzGJJKJfHyZS/z+7d+z66MXTzW/jHuOeueSJeo48SlHyRFlS1b4Ntv94QSpk6FbdtyHxMIQKNGuYMJdeqE90uSJEkFxu4tsPHbPcGEX6dCxj7NLQEo12hPKKFyGyhtcytJkiRFSlENKGRrWLkhn/f4nDd+fIM/ffInFmxaQIfXO9CtYTceaPsA4xaM47nvnmNF6goAYgIxdGnQhb4t+nJu8rlO918ExARiGNZlGAs3LeT7dd/TeURnADrV7cSf2vwpwtWpoDKoIKlACYXgl19yL+Mwd254/97KloUzz9wTSmjZEhITI1OzJEmSlKdQCLb+El7GIXu2hJS5wD7NbfGyUPHMPTMmVGwJcTa3kiRJUqRlBxQe+fIRftrwE1C0Agp7CwQCXNP4Gi6qdxEPT3yYp6Y9xdtz3+btuW/nHFOpZCVuPv1m/nDGHzgp8aQIVqtIKB1XmnevepcWL7Rg446NnFD6BIZ1GUaMSxTqAAwqSIqoHTtg+vQ9oYQpU+DXX/c/rm7d3LMlNGwIsbHHv15JkiTpgDJ2wK/T95otYQqk5dHclq67J5RQuQ2UbQgxNreSJElSQXGggMLdZ97NXWfeVaQCCvtKTEjk/zr+H72a9uL2j27nmxXf0LJ6S/q26MsVp15BQrGESJeoCEoul8xH13zEfyb/h3va3EPlUpUjXZIKMIMKko6rFSv2hBImT4bZsyEjI/cxCQnQosWeUMKZZ0KVKhEpV5IkSTqw7Sv2hBI2TobNsyG0T3MbmwAVWuwJJlQ6ExJsbiVJkqSCyIDCoWtStQmTek9i3fZ1VC1dNdLlqABpUb0Fb13xVqTLUCFgUEHSMbN7dziIsHcwYdWq/Y+rVg3OOmtPMKFpU4iLO97VSpIkSQeRuTscRNg4eU84YWcezW2JalD5rKxQQhso3xRibW4lSZKkgu6HdT/whw/+wJSVUwADCociEAgYUpB02AwqSDoimZmwejUsWRLeli4NPy5YADNnwq5duY+PjYVmzcKBhNatw481akAgEJHyJUmSpD2CmbBzNWxfAtuWwPal4cetC2DzTMjcp7kNxEL5ZlmhhNbhWRNK2txKkiRJhcn23dt55MtHeGLKE2SGMikdV5o/t/6zAQVJOsYMKkg6qFAI1q/PHULYe1u+HNLTD3x+hQp7Zkpo0wbOOANKlTpu5UuSJEl7hEKwa31WEGHpXoGErMcdyyF4kOY2rkI4lJC9jEPFM6CYza0kSZJUWH34y4fc/tHtLEtZBkDXBl35b6f/cmLZEyNcmSRFP4MKkti8Oe8gwtKl4W3HjoOfX6wYnHQS1KoFycnhx1q1oHlzOPlkbyiTJEnScbR7c+7ZELKDCNuXhsMJmb/R3AaKQamToFQtKJ2c9VgLKjSHMja3kiRJUjRYvXU1d42/i7fnvg3ASYkn8XSnp7mk/iURrkySig6DClIRsH173iGE7OcpKQc/PxCA6tX3BBD2DiPUqgXVqoXDCpIkSdIxl7E992wI2aGE7Nfpv9HcEoCS1fcEEEolZz1mvS5RDWJsbiVJkqRolBnM5Nnpz/LA5w+wdfdWYgOx3H3m3Tx07kOUjisd6fIkqUjx2xcpCqSlhZdgyCuEsGQJbNjw29eoUuXAQYQaNSA+/liPQpIkSQIy02D78r2WZViae3mGtENobhOqHDiIULIGxNrcSpIkSUXNzDUz+cMHf+C71d8B0Kp6K4ZePJQmVZtEuDJJKpoMKkiFSCgE774Ls2blDiKsXh1+72DKlTtwEKFmTSjl0rqSJEk6nkIhWPkubJ6VO4iwczXwG81t8XLh0EF2ECE7hFC6FpSqCcVsbiVJkiSFbU3byoNfPMh/p/2XYChIYnwiA88fyM3NbyY2JjbS5UlSkWVQQSoktm2DXr1g9Oi83y9Z8sBBhOTkcFBBkiRJKhDSt8G3vWDFAZrb2JJ7zYKQvE8QIRniyh2/WiVJkiQVWmPnjeWOcXewMnUlAN1P7c7/dfg/TihzQoQrkyQZVJAKgUWL4LLL4KefIC4Orr8e6tbNHUqoXBkCgUhXKkmSJP2GrYvgq8sg5SeIiYNa10PpurmXaYi3uZUkSZJ0+JanLOeOcXfw3vz3AKhVrhbPXvQsHet2jHBlkqRsBhWkAu7jj+Gqq2DLFjjhBBgzBs48M9JVSZIkSYdh9cfwzVWQvgVKnABtx0Alm1tJkiRJR0dGMIP/Tv0vD37xINvTt1Msphj3tLmHAe0GULJ4yUiXJ0nai0EFqYAKheCxx+D++yEYhNatw8s+nOCMVJIkSSpsQiH4+TGYcz+EglCpNbQdHQ4rSJIkSTou0jPTmb12NsnlkqlcqnKkyznqpq2axh8++AOz184G4KwaZzH04qGcWuXUyBYmScqTQQWpANq+HW64Ad56K/y6Tx946imIj49sXZIkSVK+ZWyHb2+A5VnNbZ0+cMZTEGtzK0mSJB0Ps9fOZtjsYYz4cQTrt68HoGnVprSv1Z72tdvTtmbbQj3bQMquFB74/AGenf4sIUKUTyjPYxc8xg3NbiAmEBPp8iRJB2BQQSpgliyBLl3g+++hePFwQOEPf4h0VZIkSdJh2LYEvuoCW76HmOLQ/CmoZ3MrSZIkHWtrt61l+PfDefX7V/l+3fc5+8vElWHr7q3MXjub2Wtn8/iUx4mLjaNNjTY5wYXm1ZpTLKbg/3wUCoV4e+7b3DX+LtZsWwPA9addz+MXPk6VUlUiXJ0k6bcU/P+lkYqQzz6D7t1h0yZISgov9XDWWZGuSpIkSToMaz+Dr7vD7k2QkBRe6qGyza0kSZJ0rOzK2MV7899j2JxhfLzwYzJDmQDExcZxaf1L6dmkJx3qdGDTzk18vuRzPlv8GZ8u/pQVqSuYuHQiE5dOZMAXA0iMT+S8WuflBBdOrngygUAgwqPLbcnmJdz+0e2MWzgOgHoV6vHcRc9xfu3zI1yZJOlQGVSQCoBQCAYNgnvvhWAQWraEMWOgevVIVyZJkiTlUygE8wbB7HshFISKLaHtGChpcytJkiQdbaFQiG9XfsuwOcN486c32bJrS857raq3omeTnnRv1J0KJSrk7E8qncTVja/m6sZXEwqFWLhpIZ8t/ozPlnzG50s+Z8uuLYydN5ax88YCUKNsDc6vfT7ta7Xn/NrnU7V01eM8yj3SM9N5YsoTPPLlI+zM2ElcbBz3nX0f/c/uT0KxhIjVJUnKP4MKUoTt2AF9+sCIEeHXvXvDs89Cgj2VJEmSCpuMHTC1DyzLam5r94YWz0Ksza0kSZJ0NC3bsozXvn+NV+e8yoJNC3L21yhbg+tPu54eTXpQv1L937xOIBCgXsV61KtYj1tb3EpmMJOZa2bmBBe+Xv41K1JX8MrsV3hl9isANKrSiAtqX0D72u1pV7MdpeNKH6th5jJ5xWT+8MEf+HH9jwCcm3wuQy4ackjjlCQVPIFQKBSKdBFHQ2pqKomJiaSkpFC2bNlIlyMdkmXLoGtXmDULihWDwYPhttuggM2iJUlSgRPtvV+0j09Ravsy+KorbJ4FgWLQfDDUs7mVJOm3RHvvF+3jk46nbbu3MXruaIbNGcYXS7/I2V+yeEkuP+VyejbpyXm1ziMmEHPUPnNH+g6+Wf5NTnBh1ppZhNjzs1KxmGK0PrE17WuHl4loUa0FxWOLH7XPB9i0cxP9P+vPCzNfAKBSyUo8ceETXH/a9QVuSQpJKury0/s5o4IUIV98AVdeCRs3QuXKMGoUnHNOpKuSJEmSDsO6L+DrKyFtI8RXhrNHQZLNrSRJknSkgqEgE5dOZNicYYyeO5rt6dtz3jsv+Tx6NOnB5adcTpn4Msfk80sWL8kFdS7ggjoXALBxx0a+WPJFTnBh8ebFTFo+iUnLJ/HQxIcoE1eGc5PPzQkunFLplMMOE4RCIUb8MIK7P76bDTs2AHBD0xt47ILHqFiy4lEboyQpMgwqSMdZKARPPQX9+kFmJjRvDmPGwEknRboySZIkKZ9CIfjlKZjZD0KZUKE5tB0DpWxuJUmSpCPxy6+/8OqcV3nt+9dYnrI8Z3/dCnXp2aQn1592PTXL1TzudVUqWYkrTr2CK069AoDFmxczYfEEPlvyGRMWT+DXnb/y/i/v8/4v7wNwQukTckIL59c6n+plqx/S5yz4dQG3fXQbny3+DIBTKp3CkIuH0K5mu2MzMEnScWdQQTqOdu2CW26BYcPCr6+7Dp5/HkqUiGxdkiRJUr5l7oJpt8CSrOY2+Tpo+TwUs7mVJEmSDsfmnZt586c3GTZnGN+u/DZnf2J8It1P7U7Ppj1pfWLrArXcQe3ytandvDZ9mvchGAoyZ+2cnNkWvlr2FWu2reG171/jte9fA8KBg+zgwjk1zyExITHX9dIy0njsm8f4x6R/kJaZRkKxBAa0HcA9Z91DXGxcJIYoSTpGDCpIx8mKFfD738N330FsLDz+ONx1l0v2SpIkqRDavgIm/R42fQeBWGj2ONS3uZUkSZLyKyOYwccLP2bYnGG8N/890jLTAIgJxNCxbkd6nNaDS+tfSoniBT8QHBOIodkJzWh2QjPuOesedmXsYsqKKTnBhe9Wf8fPG3/m540/89S0p4gNxNKyesuc4EJ6Zjq3f3Q783+dD8CFdS7k2c7PUqdCnQiPTJJ0LMQczknPPPMMycnJJCQk0KpVK6ZNm3bAY9PT03nkkUeoU6cOCQkJNGnShPHjxx/w+H/9618EAgH++Mc/Hk5pUoE0aRKccUY4pFCxInzyCfzxj36PK0lSQWBvK+XT+knw8RnhkEJ8RTjvE2jwR5tbSZIkKR/mrJ1Dv4/7UX1QdS5+42JGzR1FWmYajas05vELHmdVv1V8eM2HdG/UvVCEFPKSUCyB82qdxz/O/wdTb5rKxns2MubKMdx2xm3Uq1CPzFAmU1ZO4e9f/Z1zXjmH9q+1Z/6v80kqlcSI349g/LXjDSlIUhTL94wKb775Jv369WPIkCG0atWKwYMH06FDB+bPn0+VKlX2O37AgAG8/vrrvPDCCzRo0ICPP/6Yrl27MnnyZJo1a5br2OnTpzN06FBOO+20wx+RVICEQvDcc+GZEzIyoEkTGDsWkpMjXZkkSQJ7WylfQiFY8BzMuAtCGVCuCbQbC6WTI12ZJEmSVCis27aOET+MYNicYcxZNydnf+WSlbmm8TX0bNKTplWbFqilHY6m8iXK0/WUrnQ9pSsAy7YsY8KSCUxYMoHPFn/Gxh0b6XN6HwaeP5DyJcpHuFpJ0rEWCIVCofyc0KpVK1q0aMHTTz8NQDAYpEaNGtxxxx30799/v+OrVavGAw88wO23356z7/LLL6dEiRK8/vrrOfu2bdvG6aefzrPPPsujjz5K06ZNGTx48CHXlZqaSmJiIikpKZQtWzY/Q5KOibQ0uP12ePHF8Ourrgo/L1kysnVJkhQNjlbvZ28rHaLMNPjudliU1dzWvApavQjFbG4lSTpS0d77Rfv4pN+SlpHG+7+8z7A5wxi3YByZoUwAiscU55L6l9CzSU861e1E8djiEa40skKhELszdxNfLD7SpUiSjkB+er98zaiwe/duZsyYwX333ZezLyYmhvbt2zNlypQ8z0lLSyMhISHXvhIlSvD111/n2nf77bdz0UUX0b59ex599NHfrCUtLY20tLSc16mpqfkZinRMrVoFl18OU6dCTAz8+9/wpz85G64kSQWJva10iHasgkmXw69TIRADTf8NDWxuJUmSpAMJhUJMXTWVYbOH8eZPb7J51+ac91pWb0nPJj3pfmp3KpasGMEqC5ZAIGBIQZKKmHwFFTZu3EhmZiZJSUm59iclJTFv3rw8z+nQoQODBg2iXbt21KlThwkTJjBmzBgyMzNzjhk5ciQzZ85k+vTph1zLwIED+dvf/paf8qXjYvLkcEhh7VooXx5GjoQLL4x0VZIkaV/2ttIh2DA5HFLYtRbiysNZI+EEm1tJkiQpLytSVvDa96/x6pxXmf/r/Jz91ctU5/rTrqdHkx6cUvmUCFYoSVLBEXOsP+DJJ5+kXr16NGjQgLi4OPr27Uvv3r2JiQl/9IoVK7jrrrsYPnz4fnenHcx9991HSkpKzrZixYpjNQTpkD3/PJx7bjik0LgxTJ9uSEGSpGhib6siZeHzMOHccEihXGPoMN2QgiRJkpSHH9b9QMfXO1JzcE0e+PwB5v86nxLFSnBt42v55LpPWPbHZQxsP9CQgiRJe8nXjAqVKlUiNjaWdevW5dq/bt06qlatmuc5lStXZuzYsezatYtff/2VatWq0b9/f2rXrg3AjBkzWL9+PaeffnrOOZmZmXz11Vc8/fTTpKWlERsbu9914+PjiY93GiAVDLt3w513wtCh4dfdusHLL0Pp0pGtS5IkHZi9rXQAmbthxp2wMKu5rdENznwZitvcSpIkSXvbvns7j3z5CE9MeYLMUHimvXNqnkPPJj25vOHllI0/+NrckiQVZfkKKsTFxdG8eXMmTJhAly5dAAgGg0yYMIG+ffse9NyEhASqV69Oeno6o0eP5sorrwTg/PPP54cffsh1bO/evWnQoAF/+ctf8vwiVypI1qwJBxMmTw4v0/vPf8Jf/uKSvZIkFXT2tlIedq6BSd1g42QgAE3+CQ1tbiVJkqR9fbTgI27/6HaWblkKwO9P+T2PtX+MOhXqRLYwSZIKiXwFFQD69etHz549OeOMM2jZsiWDBw9m+/bt9O7dG4AePXpQvXp1Bg4cCMDUqVNZtWoVTZs2ZdWqVTz88MMEg0HuvfdeAMqUKUOjRo1yfUapUqWoWLHifvulgmbqVPj972H1akhMhDfegE6dIl2VJEk6VPa20l42ToVJv4edq6F4Ipz1BlSzuZUkSZL2tnrrav44/o+MmjsKgJMST+LpTk9zSf1LIlyZJEmFS76DCt27d2fDhg08+OCDrF27lqZNmzJ+/HiSkpIAWL58ec4avQC7du1iwIABLF68mNKlS9O5c2dee+01ypUrd9QGIUXCSy/BrbeGl31o2BDGjoV69SJdlSRJyg97WynLopdg+q0Q3A2JDaHtWChrcytJkiRlywxmMuS7Idz/+f2kpqUSG4jlj2f+kYfPfZjScS6TJklSfgVCoVAo0kUcDampqSQmJpKSkkLZsq77pGMnPR3uvhueeSb8uksXePVVKFMmomVJklSkRHvvF+3jUwESTIcZd8OCrOb2xC7Q+lUobnMrSdLxcrx7v2eeeYb//Oc/rF27liZNmvDUU0/RsmXLAx4/ePBgnnvuOZYvX06lSpXo1q0bAwcOJCEh4ZA+z95W0WD22tn84YM/MG3VNABaVGvB0IuH0uyEZhGuTJKkgiU/vV++Z1SQirL16+GKK+Crr8KvH3kEHngA9rrRUpIkSSocdq2Hr6+A9VnNbeNHoNEDELC5lSQpWr355pv069ePIUOG0KpVKwYPHkyHDh2YP38+VapU2e/4ESNG0L9/f1566SXatGnDL7/8Qq9evQgEAgwaNCgCI5COr227t/HwxIcZ/O1gMkOZlIkrwz/P/ye3nnErsTGxkS5PkqRCzaCCdIi++w66doWVK6FsWXj9dbjEZcckSZJUGP36HUzqCjtWQvGy0Pp1ONHmVpKkaDdo0CD69OlD7969ARgyZAgffvghL730Ev3799/v+MmTJ3PWWWdxzTXXAJCcnMzVV1/N1KlTj2vdUiR88MsH3P7R7SxPWQ5At4bdeLLjk1QrUy3ClUmSFB28VUY6BK++CmefHQ4p1K8PU6caUpAkSVIhtfhV+PTscEihbH24cKohBUmSioDdu3czY8YM2rdvn7MvJiaG9u3bM2XKlDzPadOmDTNmzGDatPB094sXL+ajjz6ic+fOB/yctLQ0UlNTc21SYbIqdRXd3urGJW9cwvKU5dRMrMkHV3/AqCtGGVKQJOkockYF6SDS0+Gee+DJJ8OvL744PJNCYmJk65IkSZLyLZgOs+6B+VnNbbWLoc3rEGdzK0lSUbBx40YyMzNJSkrKtT8pKYl58+blec4111zDxo0bOfvsswmFQmRkZHDLLbdw//33H/BzBg4cyN/+9rejWrt0PGQGM3l2+rM88PkDbN29ldhALP1a9+Ohcx6iVFypSJcnSVLUcUYF6QA2bIAOHfaEFB58EN5915CCJEmSCqFdG+CLDntCCo0ehHPeNaQgSZIOauLEifzzn//k2WefZebMmYwZM4YPP/yQv//97wc857777iMlJSVnW7FixXGsWDo8s9bM4swXz+TO8XeydfdWWlVvxYybZ/DYBY8ZUpAk6RhxRgUpD7NmQZcusHw5lC4dXvqha9dIVyVJkiQdhk2z4KsusGM5FCsNrV+FGja3kiQVNZUqVSI2NpZ169bl2r9u3TqqVq2a5zl//etfuf7667npppsAaNy4Mdu3b+fmm2/mgQceICZm//vg4uPjiY+PP/oDkI6Bbbu38eAXD/Lk1CcJhoKUjS/Lv87/Fzc3v5nYmNhIlydJUlRzRgVpHyNGwFlnhUMKdevC1KmGFCRJklRILR0Bn54VDimUrgsdphpSkCSpiIqLi6N58+ZMmDAhZ18wGGTChAm0bt06z3N27NixXxghNjb8420oFDp2xUrHwbvz3qXhMw35v2//j2AoyJWnXsm82+dxa4tbDSlIknQcOKOClCUjA/r3hyeeCL/u1CkcWihXLqJlSZIkSfkXzIDZ/WFeVnN7Qic4awTElYtoWZIkKbL69etHz549OeOMM2jZsiWDBw9m+/bt9O7dG4AePXpQvXp1Bg4cCMAll1zCoEGDaNasGa1atWLhwoX89a9/5ZJLLskJLEiFzYqUFdw5/k7GzhsLQHK5ZJ7t/Cyd6nWKbGGSJBUxBhUk4Ndf4aqr4LPPwq/vuw/+/nfw/29JkiSp0En7Fb65CtZmNbcN74PT/g7eFSZJUpHXvXt3NmzYwIMPPsjatWtp2rQp48ePJykpCYDly5fnmkFhwIABBAIBBgwYwKpVq6hcuTKXXHIJ//jHPyI1BOmwZQQzeHra0/z1i7+ybfc2isUU40+t/8SD5zxIyeIlI12eJElFTiAUJXN0paamkpiYSEpKCmXLlo10OSpEvv8eunSBJUugZEl45RW44opIVyVJkg4m2nu/aB+fjqHN38NXXWD7EogtCa1fgZNsbiVJKsiivfeL9vGpcJixegY3f3AzM9fMBKD1ia0ZevFQGic1jnBlkiRFl/z0fs6ooCLtrbegd2/YsQNq1YJ334XG9qaSJEkqjJa9Bd/2hswdUKoWnPMulLO5lSRJUtG1NW0rf/3irzw17SmCoSCJ8Yn8u/2/6dO8DzGBmN++gCRJOmYMKqhIysyEBx6Af/87/PqCC2DkSKhQIbJ1SZIkSfkWzITvH4C5Wc1t1QvgrJEQb3MrSZKkoikUCjF23ljuGHcHq7auAuDqRlczqMMgqpauGuHqJEkSGFRQEbRlC1x1FXz8cfj1PffAP/8JxfxPgyRJkgqb3Vvgm6tgTVZze8o90OSfEGNzK0mSpKJpecpy7hh3B+/Nfw+A2uVr89xFz3FhnQsjXJkkSdqb316pSFm+HDp1grlzoUQJeOmlcGhBkiRJKnS2L4eJnSBlLsSWgFYvQbLNrSRJkoqmjGAG/536Xx784kG2p2+nWEwx7m1zLwPaDaBE8RKRLk+SJO3DoIKKjDlzoHNnWL0aqlWDDz6AZs0iXZUkSZJ0GDbPgYmdYedqKFENzvkAKtjcSpIkqWiavmo6N39wM7PXzgbgrBpnMfTioZxa5dTIFiZJkg7IoIKKhAkToGtX2LoVGjaEcePgpJMiXZUkSZJ0GNZOgK+6QsZWSGwI546DUja3kiRJKnpS01J5YMIDPDP9GUKEKJdQjv9c8B9uaHYDMYGYSJcnSZIOwqCCot6IEdCrF6SnwznnwDvvQPnyka5KkiRJOgxLR8C3vSCYDlXOgXbvQJzNrSRJkoqWUCjE6J9Hc9f4u1i9dTUA1za+licufIKk0kkRrk6SJB0KgwqKWqEQ/Oc/8Je/hF9feSW8+irEx0e2LkmSJCnfQiH4+T8wO6u5PelKaP0qxNrcSpIkqWhZumUpfT/qy4cLPgSgboW6PNv5WS6oc0GEK5MkSflhUEFRKTMT/vhHePrp8Ou774bHH4cYZ/uSJElSYRPMhJl/hF+ymtv6d8Ppj4NT2UqSJKkISc9M58mpT/LQxIfYkb6D4jHF+ctZf+H+tvdToniJSJcnSZLyyaCCos7OnXDtteElHgIBeOKJcFBBkiRJKnQydsLka2HlO0AATn8CGtjcSpIkqWj5duW3/OGDP/D9uu8BaHtSW4ZePJRTKp8S4cokSdLhMqigqPLrr3DppTB5MsTFwWuvhZd8kCRJkgqdtF/hy0th42SIiYPWr0FNm1tJkiQVHSm7Urh/wv08991zhAhRoUQF/nPBf+jVtBcxzjAmSVKhZlBBUWPpUujYEebPh3LlYOxYOOecCBclSZIkHY5tS2FiR0idD8XLQbuxkGRzK0mSpKIhFAoxau4o7hp/F2u3rQWgR5MePH7B41QuVTnC1UmSpKPBoIKiwqxZ0LkzrF0LJ54I48fDqadGuipJkiTpMGyaBRM7w661UPJEOHc8lLO5lSRJUtGwZPMSbv/odsYtHAdAvQr1GHLxEH5X63cRrkySJB1NBhVU6H3yCVx+OWzbBo0bw7hxUL16pKuSJEmSDsOaT2DS5ZCxDco1hnPHQUmbW0mSJEW/jGAGg6YM4uGJD7MzYydxsXH0P6s/97W9j4RiCZEuT5IkHWUGFVSoDRsGN90EGRnwu9/BmDGQmBjpqiRJkqTDsHgYTL0JQhmQ9DtoOwbibG4lSZJUNPT9qC9DZwwF4Jya5zDk4iE0qNQgwlVJkqRjJSbSBUiHIxSCf/4TevUKhxSuuSY8k4IhBUmSJBU6oRD89E/4tlc4pFDzmvBMCoYUJEmSVESM+mkUQ2cMJUCA5y9+ni96fmFIQZKkKOeMCip0MjLgjjtgyJDw63vvhYEDIcbYjSRJkgqbYAZ8dwcszGpuT7kXmg6EgM2tJEmSioZlW5bR5/0+APQ/uz99mveJcEWSJOl4MKigQmXHDrjqKnj/fQgE4Mknw6EFSZIkqdDJ2AHfXAWr3gcC0PxJqG9zK0mSpKIjI5jBNWOuISUthTNPPJO/nfu3SJckSZKOE4MKKjQ2bIBLLoGpUyE+HoYPh8svj3RVkiRJ0mHYtQG+vAR+nQox8dBmOJxkcytJkqSi5W8T/8bkFZMpG1+WEb8fQfHY4pEuSZIkHScGFVQoLFoEnTrBggVQvnx4RoWzzop0VZIkSdJh2LoIJnaCrQsgrjyc8z5UtrmVJElS0fLFki/4x6R/APD8xc9Tq3ytCFckSZKOJ4MKKvCmT4eLL4b166FmTRg3Dk45JdJVSZIkSYfh1+nw5cWwaz2UqgnnjoNEm1tJkiQVLRt3bOS6d64jRIgbm91I90bdI12SJEk6zmIiXYB0MB99BOeeGw4pNG0KU6YYUpAkSVIhteoj+OzccEihfFO4cIohBUmSJBU5oVCIG969gdVbV9OgUgOe7PhkpEuSJEkRYFBBBdaLL8Kll8KOHXDBBfDll3DCCZGuSpIkSToMi16Ery6FzB1Q9QJo/yWUsLmVJElS0fP0tKd5/5f3iYuNY+TlIykVVyrSJUmSpAgwqKACJxSChx+Gm26CzEzo0QM++ADKlo10ZZIkSVI+hULw/cMw9SYIZUKtHnDOB1Dc5laSJElFz+y1s/nzp38G4PELHqdJ1SYRrkiSJEVKsUgXIO0tIwNuuSU8mwLA/ffDo49CIBDZuiRJkqR8C2bA9FvCsykAnHo/nGZzK0mSpKJp++7tXPX2VezO3M0lJ19C35Z9I12SJEmKIIMKKjC2bYPu3eGjjyAmBp55JhxakCRJkgqd9G3wTXdY/REEYuCMZ6Ceza0kSZKKrjvH3cn8X+dTrUw1XrrsJQIGeCVJKtIMKqhAWL8eLroIvvsOSpSAN96Ayy6LdFWSJEnSYdi1HiZeBJu+g9gScNYbcKLNrSRJkoqukT+O5KXZLxEgwPDfD6dSyUqRLkmSJEWYQQVF3IIF0LEjLF4MFSvCBx/AmWdGuipJkiTpMKQugIkdYdtiiK8I53wAlWxuJUmSVHQt3ryYP3zwBwAeaPsA5yafG9mCJElSgWBQQRE1dSpcfDFs3Ai1asH48XDyyZGuSpIkSToMG6fClxdD2kYoVQvOGw9lbW4lSZJUdKVnpnPN6GtITUulTY02PHTuQ5EuSZIkFRAxkS5ARdf778N554VDCs2bw5QphhQkSZJUSK18HyacFw4pVGgOF04xpCBJkqQi78EvHmTqqqmUSyjHiN+PoFiM905KkqQwgwqKiKFDoUsX2LkTOnWCiRMhKSnSVUmSJEmHYcFQmNQFMnfCCZ3g/IlQwuZWkiRJRdtniz/j39/8G4AXLnmBmuVqRrgiSZJUkBhU0HEVCsGAAXDLLRAMQu/e8O67ULp0pCuTJEmS8ikUgjkDYPotEApC7d5wzrtQ3OZWkiRJRdv67eu5/p3rCRHi5tNvplvDbpEuSZIkFTDOs6TjJj0d+vSBYcPCrx96KLwFApGtS5IkScq3YDpM7QNLsprbRg9BY5tbSZIkKRgK0mtsL9ZuW0vDyg35v47/F+mSJElSAWRQQcfF1q3QrRt88gnExsKQIXDTTZGuSpIkSToM6VthUjdY+wkEYqHFEKhrcytJkiQBPPntk4xbOI6EYgmMvHwkJYuXjHRJkiSpADKooGNuzRq46CKYNQtKloS33gq/liRJkgqdnWtg4kWweRbEloSz34LqNreSJEkSwIzVM/jLZ38BYNCFg2ic1DjCFUmSpIIq5nBOeuaZZ0hOTiYhIYFWrVoxbdq0Ax6bnp7OI488Qp06dUhISKBJkyaMHz8+1zEDBw6kRYsWlClThipVqtClSxfmz59/OKWpgJk3D1q3DocUKleGiRMNKUiSpILF3laHLGUefNI6HFKIrwztJxpSkCRJkrJsTdvKVaOvIj2YTtcGXbnljFsiXZIkSSrA8h1UePPNN+nXrx8PPfQQM2fOpEmTJnTo0IH169fnefyAAQMYOnQoTz31FHPnzuWWW26ha9euzJo1K+eYL7/8kttvv51vv/2WTz/9lPT0dC688EK2b99++CNTxH3zDZx1FixbBnXrwpQp0KJFpKuSJEnaw95Wh2zDN/DpWbB9GZSuCxdOgYo2t5IkSVK2vuP6snDTQk4seyL/u/R/BAKBSJckSZIKsEAoFArl54RWrVrRokULnn76aQCCwSA1atTgjjvuoH///vsdX61aNR544AFuv/32nH2XX345JUqU4PXXX8/zMzZs2ECVKlX48ssvadeu3SHVlZqaSmJiIikpKZQtWzY/Q9Ix8M47cM01sGsXtGwJH3wQnlFBkiTpaDhavZ+9rQ7Jindg8jWQuQsqtoRzPoAEm1tJknR0RHvvF+3jU9jr37/O9e9cT0wghok9J9K2ZttIlyRJkiIgP71fvmZU2L17NzNmzKB9+/Z7LhATQ/v27ZkyZUqe56SlpZGQkJBrX4kSJfj6668P+DkpKSkAVKhQ4YDHpKWlkZqammtTwfDMM3D55eGQwsUXw+efG1KQJEkFj72tDskvz8Cky8MhhWoXw/mfG1KQJEmS9rJw00Ju/fBWAB5s96AhBUmSdEjyFVTYuHEjmZmZJCUl5dqflJTE2rVr8zynQ4cODBo0iAULFhAMBvn0008ZM2YMa9asyfP4YDDIH//4R8466ywaNWp0wFoGDhxIYmJizlajRo38DEXHQDAI/ftD374QCsHNN4dnVihVKtKVSZIk7c/eVgcVCsLs/vBdXyAEdW+Gdu9AMZtbSZIkKdvuzN1cPfpqtu3eRtuT2vJAuwciXZIkSSok8hVUOBxPPvkk9erVo0GDBsTFxdG3b1969+5NTEzeH3377bfz448/MnLkyINe97777iMlJSVnW7FixbEoX4do927o0QP+/e/w67//HYYMgWLFIluXJEnS0WRvW0Rk7oYpPWBuVnN72t+hxRCIsbmVJEmS9vbAhAf4bvV3lE8oz/DfD6eYPbMkSTpE+QoqVKpUidjYWNatW5dr/7p166hatWqe51SuXJmxY8eyfft2li1bxrx58yhdujS1a9fe79i+ffvywQcf8MUXX3DiiScetJb4+HjKli2ba1NkpKRA584wfDjExsLLL8OAARAIRLoySZKkA7O3VZ52p8DEzrB0OARi4cyXoZHNrSRJkrSvjxd+zONTHgfgpcteokaiM8NJkqRDl6+gQlxcHM2bN2fChAk5+4LBIBMmTKB169YHPTchIYHq1auTkZHB6NGjueyyy3LeC4VC9O3bl3feeYfPP/+cWrVq5XMYipRVq6BdO5gwIbzEw4cfQq9eka5KkiTpt9nbaj87VsFn7WDdhPASD+d8CLV7RboqSZIkqcBZu20tPcb2AOC2M26jS4MukS1IkiQVOvmeh6lfv3707NmTM844g5YtWzJ48GC2b99O7969AejRowfVq1dn4MCBAEydOpVVq1bRtGlTVq1axcMPP0wwGOTee+/Nuebtt9/OiBEjePfddylTpkzOmsCJiYmUKFHiaIxTx8DcudCxI6xYAUlJ4ZBC8+aRrkqSJOnQ2dsqR8pc+KIj7FgBCUlw7odQweZWkiRJ2lcwFKTn2J6s376exlUa8/iFj0e6JEmSVAjlO6jQvXt3NmzYwIMPPsjatWtp2rQp48ePJykpCYDly5fnWqN3165dDBgwgMWLF1O6dGk6d+7Ma6+9Rrly5XKOee655wA499xzc33Wyy+/TC9vzy+QvvoKLrsMtmyBk0+G8ePBmwUlSVJhY28rANZ/BV9eBulboMzJcN54KG1zK0mSJOXliclP8MmiTyhRrAQju42kRHED2ZIkKf8CoVAoFOkijobU1FQSExNJSUlxTd9jbNQouO462L0bWreG996DSpUiXZUkSSpKor33i/bxFSjLR8Hk6yC4Gyq1hnbvQYLNrSRJOn6ivfeL9vEVNdNXTafNS23ICGYw9OKh3Nz85kiXJEmSCpD89H4xB31X2sfgwdC9ezik0KULTJhgSEGSJEmF1LzB8HX3cEjhxC7wuwmGFCRJkqQDSE1L5arRV5ERzKBbw270Ob1PpEuSJEmFmEEFHZJgEP70J7j7bgiF4Lbb4O23wWWWJUmSVOiEgjDzTzDzbiAE9W6Ds9+GYja3kiRJUl5CoRC3fngrizcv5qTEk3j+4ucJBAKRLkuSJBVixSJdgAq+tDTo2RPefDP8+l//gnvvBftQSZIkFTqZaTClJyzPam6b/gtOsbmVJEmSDubVOa8y4ocRxAZieePyNyhfonykS5IkSYWcQQUdVHo6dOoEX3wBxYrByy/DdddFuipJkiTpMATTYWInWPcFBIrBmS9DLZtbSZIk6WB++fUXbv/odgAePvdh2tRoE+GKJElSNDCooIP68MNwSKF0aXjnHWjfPtIVSZIkSYdp1YfhkEKx0tDuHahqcytJkiQdTFpGGle9fRXb07dzbvK53Hf2fZEuSZIkRYmYSBeggu2rr8KP111nSEGSJEmF3Pqs5jb5OkMKkiRJ0iG4b8J9zFo7i4olKvJ619eJjYmNdEmSJClKGFTQQU2aFH5s2zaydUiSJElHbENWc1vF5laSJEn6LR8t+Ij/+/b/AHj5spepXrZ6hCuSJEnRxKCCDmjrVpg5M/zcoIIkSZIKtfStsDmrua1scytJkiQdzJqta+g5ticAd7S8g0vqXxLhiiRJUrQxqKADmjIFgkFIToYaNSJdjSRJknQENk6BUBBKJUMpm1tJkiTpQIKhINe/cz0bd2ykSVITHrvgsUiXJEmSopBBBR2Qyz5IkiQpaqzPam6dTUGSJEk6qMe+eYwJSyZQsnhJRnYbSUKxhEiXJEmSopBBBR2QQQVJkiRFjQ1ZzW0Vm1tJkiTpQL5d+S0DPh8AwFOdnqJBpQYRrkiSJEUrgwrKU1oafPtt+Hm7dpGtRZIkSToimWmwMau5rWJzK0mSJOUlZVcKV4++msxQJt1P7U7vpr0jXZIkSYpiBhWUp+++C4cVqlSBk0+OdDWSJEnSEdj0HQTTIKEKlLG5lSRJkvYVCoX4wwd/YOmWpSSXS2boxUMJBAKRLkuSJEUxgwrKU/ayD2efDfajkiRJKtTWZzW3lW1uJUmSpLy8PPtl3vzpTWIDsbxx+RskJiRGuiRJkhTlDCooT9lBhbYu4StJkqTCbkN2UMHmVpIkSdrXzxt+5o5xdwDw6O8e5cwTz4xwRZIkqSgwqKD9ZGbC11+HnxtUkCRJUqEWzIQNWc1tFZtbSZIkaW+7MnZx9eir2ZG+g/Nrnc+9Z90b6ZIkSVIRYVBB+/nhB0hNhTJloEmTSFcjSZIkHYGUHyA9FYqVgXI2t5IkSdLe7v30Xuasm0OlkpV4retrxAT8yUCSJB0fdh3aT/ayD23aQLFika1FkiRJOiLrs5d9aAMxNreSJElStvfnv89T054CYFiXYZxQ5oQIVyRJkooSgwraT3ZQwWUfJEmSVOhtyA4q2NxKkiRJ2ValrqL3u70BuPvMu+lcr3OEK5IkSUWNQQXlEgrBV1+FnxtUkCRJUqEWCsH6rOa2is2tJEkSwDPPPENycjIJCQm0atWKadOmHfDYc889l0AgsN920UUXHceKdbRlBjO57p3r+HXnrzSr2oyB5w+MdEmSJKkIMqigXBYuhHXrIC4OWraMdDWSJEnSEdi6EHatg5g4qGhzK0mS9Oabb9KvXz8eeughZs6cSZMmTejQoQPr16/P8/gxY8awZs2anO3HH38kNjaWK6644jhXrqNp4NcDmbh0IqWKl2Jkt5HEF4uPdEmSJKkIMqigXLKXfWjZEhISIluLJEmSdESyl32o2BJibW4lSZIGDRpEnz596N27Nw0bNmTIkCGULFmSl156Kc/jK1SoQNWqVXO2Tz/9lJIlSxpUKMS+Wf4ND098GIBnOj/DyRVPjmxBkiSpyDKooFyygwou+yBJkqRCLzuoUNnmVpIkaffu3cyYMYP27dvn7IuJiaF9+/ZMmTLlkK7x4osvctVVV1GqVKkDHpOWlkZqamquTQXD5p2buWbMNWSGMrm28bX0aNIj0iVJkqQizKCCcjGoIEmSpKixPqu5rWJzK0mStHHjRjIzM0lKSsq1PykpibVr1/7m+dOmTePHH3/kpptuOuhxAwcOJDExMWerUaPGEdWtoyMUCtHn/T4sT1lOnfJ1ePaiZwkEApEuS5IkFWEGFZRj9WpYtAhiYqBNm0hXI0mSJB2BHath2yIIxEAlm1tJkqQj9eKLL9K4cWNatmx50OPuu+8+UlJScrYVK1Ycpwp1MC/MfIHRP4+mWEwx3rj8DcrGl410SZIkqYgrFukCVHBkz6bQpAkkJka2FkmSJOmIZC/7UK4JxNncSpIkVapUidjYWNatW5dr/7p166hatepBz92+fTsjR47kkUce+c3PiY+PJz4+/ohq1dH10/qfuGv8XQAMPH8gLaq3iHBFkiRJzqigvbjsgyRJkqJG9rIPlW1uJUmSAOLi4mjevDkTJkzI2RcMBpkwYQKtW7c+6LmjRo0iLS2N66677liXqaNsZ/pOrhp9FbsydtGhTgf6te4X6ZIkSZIAZ1TQXgwqSJIkKWpkz6hQxeZWkiQpW79+/ejZsydnnHEGLVu2ZPDgwWzfvp3evXsD0KNHD6pXr87AgQNznffiiy/SpUsXKlasGImydQT+/Mmf+XH9j1QpVYVhXYYRE/DeRUmSVDAYVBAAmzfDDz+EnxtUkCRJUqG2ezNsyWpunVFBkiQpR/fu3dmwYQMPPvgga9eupWnTpowfP56kpCQAli9fTkxM7h+y58+fz9dff80nn3wSiZJ1BN75+R2e/e5ZAF7r+hpJpZMiXJEkSdIeBhUEwDffQCgEJ58MSfarkiRJKsw2fAOEoMzJUMLmVpIkaW99+/alb9++eb43ceLE/fbVr1+fUCh0jKvS0bYiZQU3vncjAPe0uYcL61wY4YokSZJyc54nAS77IEmSpCiy3mUfJEmSVHRlBDO4dsy1bN61mRbVWvDo7x6NdEmSJEn7MaggwKCCJEmSosiGrObWZR8kSZJUBP3jq38wafkkysSV4Y3L3yAuNi7SJUmSJO3HoILYsQOmTw8/b9cusrVIkiRJRyRjB/ya1dxWsbmVJElS0fLVsq945KtHAHjuoueoU6FOhCuSJEnKm0EFMXUqZGRA9eqQnBzpaiRJkqQj8OtUCGVAiepQKjnS1UiSJEnHzaadm7h2zLUEQ0F6NunJtaddG+mSJEmSDsiggnIt+xAIRLYWSZIk6Yisz2puq9jcSpIkqegIhULc+N6NrExdSb0K9Xi689ORLkmSJOmgDCooV1BBkiRJKtQ2ZDW3lW1uJUmSVHQM+W4IY+eNpXhMcUZ2G0npuNKRLkmSJOmgDCoUcenpMHly+Hk7l/CVJElSYRZMhw1ZzW0Vm1tJkiQVDT+s+4G7P74bgH+3/zenn3B6hCuSJEn6bQYVirhZs2DHDihfHho2jHQ1kiRJ0hHYNAsyd0BceUi0uZUkSVL025G+g+5vdyctM43O9TrzxzP/GOmSJEmSDolBhSIue9mHs8+GGP9tkCRJUmGWs+zD2RCwuZUkSVL0u3v83fy88Weqlq7Ky5e9TCAQiHRJkiRJh8Rv74q47KBCW5fwlSRJUmGXE1SwuZUkSVL0G/XTKJ6f+TwBArze9XWqlKoS6ZIkSZIOmUGFIiwY3BNUaOcSvpIkSSrMQkFYn9XcVrG5lSRJUnRbt20dfd7vA8BfzvoL59c+P8IVSZIk5Y9BhSLs559h0yYoWRJOPz3S1UiSJElHIOVn2L0JYktCBZtbSZIkRbex88aSkpZC4yqNeeS8RyJdjiRJUr4ZVCjCsmdTOPNMKF48srVIkiRJRyR72YdKZ0KMza0kSZKi27iF4wDofmp3isfa/0qSpMLHoEIRlh1UaOsSvpIkSSrsspd9qGxzK0mSpOi2O3M3E5ZMAKBj3Y4RrkaSJOnwHFZQ4ZlnniE5OZmEhARatWrFtGnTDnhseno6jzzyCHXq1CEhIYEmTZowfvz4I7qmjlwoBF99FX7eziV8JUlSEWZvGwVCIdiQ1dxWsbmVJElSdJu8YjLbdm+jcsnKNDuhWaTLkSRJOiz5Diq8+eab9OvXj4ceeoiZM2fSpEkTOnTowPr16/M8fsCAAQwdOpSnnnqKuXPncsstt9C1a1dmzZp12NfUkVu2DFauhGLFwks/SJIkFUX2tlFi+zLYsRICxcJLP0iSJElRbPzCcFi6Q90OxAScNFmSJBVO+e5iBg0aRJ8+fejduzcNGzZkyJAhlCxZkpdeeinP41977TXuv/9+OnfuTO3atbn11lvp3LkzTzzxxGFfU0cue9mH5s2hZMnI1iJJkhQp9rZRYkNWc1uhORSzuZUkSVJ0yw4qdKrbKcKVSJIkHb58BRV2797NjBkzaN++/Z4LxMTQvn17pkyZkuc5aWlpJCQk5NpXokQJvv7668O+po5cdlChrUv4SpKkIsreNoqsz2puq9jcSpIkKbqt3rqaOevmECDABbUviHQ5kiRJhy1fQYWNGzeSmZlJUlJSrv1JSUmsXbs2z3M6dOjAoEGDWLBgAcFgkE8//ZQxY8awZs2aw74mhL8kTk1NzbXp0H2VtYRvO5fwlSRJRZS9bRTZkNXcVra5lSRJUnT7eOHHAJxR7Qwql6oc4WokSZIO3zFfwOrJJ5+kXr16NGjQgLi4OPr27Uvv3r2JiTmyjx44cCCJiYk5W40aNY5SxdFv/XqYPz/8/KyzIluLJElSYWJvWwDtWg+pWc1tZZtbSZIkRbfxi8LLPnSs2zHClUiSJB2ZfH2jWqlSJWJjY1m3bl2u/evWraNq1ap5nlO5cmXGjh3L9u3bWbZsGfPmzaN06dLUrl37sK8JcN9995GSkpKzrVixIj9DKdKyZiamUSOoUCGytUiSJEWKvW2U2JDV3CY2gnibW0mSJEWvjGAGny76FDCoIEmSCr98BRXi4uJo3rw5EyZMyNkXDAaZMGECrVu3Pui5CQkJVK9enYyMDEaPHs1ll112RNeMj4+nbNmyuTYdmklZS/i2dQlfSZJUhNnbRon1Wc1tFZtbSZIkRbfpq6azeddmyiWUo2X1lpEuR5Ik6YgUy+8J/fr1o2fPnpxxxhm0bNmSwYMHs337dnr37g1Ajx49qF69OgMHDgRg6tSprFq1iqZNm7Jq1SoefvhhgsEg99577yFfU0fXV1lL+BpUkCRJRZ29bRRYn9XcVra5lSRJUnQbvzC87MOFdS6kWEy+v9qXJEkqUPLdzXTv3p0NGzbw4IMPsnbtWpo2bcr48eNJSkoCYPny5bnW6N21axcDBgxg8eLFlC5dms6dO/Paa69Rrly5Q76mjp7UVJg9O/zcoIIkSSrq7G0LufRU2DI7/NwZFSRJkhTlxi8KBxU61nHZB0mSVPgFQqFQKNJFHA2pqakkJiaSkpLiVLkH8fHH0LEj1KoFixdHuhpJkqTDE+29X7SP76hZ/TFM7AilasFlNreSJKlwivbeL9rHd7xs2L6BpMeTCBFiVb9VVCtTLdIlSZIk7Sc/vV/MQd9V1JmUtYSvsylIkiSp0NuQ1dw6m4IkSZKi3KeLPyVEiNOSTjOkIEmSooJBhSLmq6wlfA0qSJIkqdBbn9XcVra5lSRJUnQbv9BlHyRJUnQxqFCEpKXBtGnh5+3aRbYWSZIk6YhkpsGvWc1tFZtbSZIkRa9gKMjHiz4GoGNdgwqSJCk6GFQoQqZPD4cVqlSBevUiXY0kSZJ0BH6dDsE0SKgCZWxuJUmSFL1mr53N+u3rKR1XmrNOOivS5UiSJB0VBhWKkElZS/i2bQuBQGRrkSRJko7IhqzmtrLNrSRJkqJb9rIP59c6n7jYuAhXI0mSdHQYVChCvspawretS/hKkiSpsFuf1dxWtrmVJElSdMsOKrjsgyRJiiYGFYqIzEyYPDn8vJ1L+EqSJKkwC2bCxqzmtorNrSRJkqLXll1bmLwi3Pt2qNMhwtVIkiQdPQYViojvv4fUVChbFk47LdLVSJIkSUdgy/eQngrFy0I5m1tJkiRFrwmLJ5AZyqR+xfrUKl8r0uVIkiQdNQYViohJWUv4tmkDsbGRrUWSJEk6IhuymttKbSDG5laSJEnRy2UfJElStDKoUER8lbWEb1uX8JUkSVJhtz6rua1icytJkqToFQqFGL/IoIIkSYpOBhWKgFBoz4wK7VzCV5IkSYVZKLRnRoXKNreSJEmKXnM3zGVl6koSiiVwTs1zIl2OJEnSUWVQoQhYsADWr4f4eGjRItLVSJIkSUdg6wLYtR5i4qGiza0kSZKiV/ayD+cmn0uJ4iUiXI0kSdLRZVChCMieTaFly3BYQZIkSSq0smdTqNgSYm1uJUmSFL3GLRwHQMc6LvsgSZKij0GFIuCrrCV827qEryRJkgq79VnNbRWbW0mSJEWvbbu3MWl5OKTbsa5BBUmSFH0MKhQB2TMqtHMJX0mSJBV267Oa28o2t5IkSYpeE5dOZHfmbpLLJXNyxZMjXY4kSdJRZ1Ahyq1aBUuWQEwMtG4d6WokSZKkI7BjFWxfAoEYqGxzK0mSpOg1fuF4ILzsQyAQiHA1kiRJR59BhSiXPZtC06ZQtmxES5EkSZKOTPZsCuWaQnGbW0mSJEWv7KBCp3qdIlyJJEnSsWFQIcplBxXauoSvJEmSCrsNWc1tFZtbSZIkRa+FmxayaPMiiscU57zk8yJdjiRJ0jFhUCHKffVV+LGdS/hKkiSpsFuf1dxWsbmVJElS9Bq3YBwAZ590NmXiy0S4GkmSpGPDoEIU27QJfvwx/PzssyNbiyRJknRE0jZBSlZzW9nmVpIkSdFr/KLwsg8d63aMcCWS9P/t3Xd4VHXa//HPTDoEQktCSwgSARGkE0N1JVJkWdsqKywgKljgsaCuYMNyCe6qiLuroj6CuhZ0n8XyWyAsRlAEpBddBZJQRUiC9JZA5v79kczIkAIhZTLD+3VduUzOnO859zk5M3zkuvl+AaDy0KgQwJYsKfhvq1ZSTIxvawEAAADKJacw3NZuJYUTbgEAABCYTpw6oYVbF0qiUQEAAAQ2GhUC2OLCJXx7sYQvAAAA/F1OYbiNJtwCAAAgcC3evljHTx1Xo8hGahfTztflAAAAVBoaFQLY14VL+PZmCV8AAAD4u+zCcBtDuAUAAEDgSs34ddkHh8Ph42oAAAAqD40KAeroUWn16oLvmVEBAAAAfu3UUWlfYbhlRgUAAAAEsNTMgkaFgYkDfVwJAABA5aJRIUAtXy6dOiU1bSo1a+bragAAAIBy2LtcslNSjaZSTcItAAAAAtOOgzv0Q84PcjqcSrkoxdflAAAAVCoaFQLU4sIlfHv1kpghDAAAAH4tpzDcRhNuAQAAELjcyz5c3vRy1Y2o6+NqAAAAKheNCgHq68IlfHuzhC8AAAD8XXZhuI0h3AIAACBwuRsVBrQY4ONKAAAAKh+NCgHo5Enp228Lvu/FEr4AAADwZ66T0t7CcBtNuAUAAEBgOpl/Ul9s+UKSNCCRRgUAABD4aFQIQGvWSMeOSfXqSZdc4utqAAAAgHLYt0bKPyaF1pOiCLcAAAAITMt+WqbDeYfVoEYDdW7c2dflAAAAVDoaFQLQ4sIlfHv2lJz8hgEAAODPcgrDbXRPyUG4BQAAQGByL/vQv0V/Ocm9AADgAkDiCUBfFy7h25slfAEAAODvsgvDbQzhFgAAAIHL3ajAsg8AAOBCQaNCgHG5pG++Kfi+F0v4AgAAwJ+ZS8opDLfRhFsAAAAEpj1H9mjtnrWSpH4t+vm4GgAAgKpBo0KA+eEHaf9+qUYNqWNHX1cDAAAAlMPBH6S8/VJQDake4RYAAACBaX7GfElS50adFVMzxsfVAAAAVA0aFQLM4sIlfJOTpZAQ39YCAAAAlEtOYbhtkCw5CbcAAAAITKmZLPsAAAAuPDQqBJivC5fwZdkHAAAA+L3swnAbQ7gFAABAYMp35es/mf+RRKMCAAC4sNCoEEDMfp1RoXdv39YCAAAAlIuZlF0YbmMItwAAAAhMq35epX3H9ykqLEqXN73c1+UAAABUGRoVAsi2bdKuXQVLPiQl+boaAAAAoByObpOO7ypY8qE+4RYAAACBKTWjYNmHq1pcpWBnsI+rAQAAqDo0KgQQ92wKnTtLNWr4thYAAACgXNyzKdTtLAUTbgEAABCY5mXMkyQNaMGyDwAA4MJCo0IA+bpwCd9eLOELAAAAf5dTGG5jCLcAAAAITL8c+0Urdq2QJPVP7O/jagAAAKoWjQoBxD2jQm+W8AUAAIC/c8+oEEO4BQAAQGBasGWBTKa2MW3VtHZTX5cDAABQpWhUCBBZWdLmzZLDIfXo4etqAAAAgHI4niUd3izJIUUTbgEAACrSK6+8ooSEBIWHhyspKUkrVqwodf8DBw5o7NixatSokcLCwtSyZUvNnTu3iqoNbKkZqZJY9gEAAFyYgn1dACrGN98U/LdtW6luXd/WAgAAAJRLTmG4rdNWCiXcAgAAVJSPPvpI48eP1/Tp05WUlKRp06apf//+2rRpk2JiYorsn5eXp6uuukoxMTH6v//7PzVp0kTbt29XnTp1qr74AOMy16+NCok0KgAAgAsPjQoB4uvCJXx7sYQvAAAA/F12YbiNJtwCAABUpKlTp2r06NEaNWqUJGn69OmaM2eOZsyYoQkTJhTZf8aMGdq3b5+WLl2qkJAQSVJCQkJVlhywNmRtUNbRLNUMqame8T19XQ4AAECVY+mHALG4cAnf3izhCwAAAH+XUxhuYwi3AAAAFSUvL0+rV69WSkqKZ5vT6VRKSoqWLVtW7JjPP/9cycnJGjt2rGJjY9W2bVtNnjxZ+fn5VVV2wHLPpnBl8ysVFhzm42oAAACqHjMqBIBDh6T16wu+Z0YFAAAA+LWTh6QDheGWGRUAAAAqzN69e5Wfn6/Y2Fiv7bGxsdq4cWOxY7Zs2aIvv/xSw4YN09y5c5WRkaG7775bJ0+e1KRJk4odk5ubq9zcXM/Phw4dqriLCCDzMuZJYtkHAABw4TqvGRVeeeUVJSQkKDw8XElJSVqxYkWp+0+bNk2tWrVSRESE4uLidP/99+vEiROe1/Pz8/X444+refPmioiIUIsWLfTMM8/IzM6nvAvO0qWSyyVddJHUuLGvqwEAAPAvZNtqJmepZC4p8iKpBuEWAADAl1wul2JiYvTGG2+oc+fOGjJkiB599FFNnz69xDFTpkxRVFSU5ysuLq4KK/YPB08c1NKdSyXRqAAAAC5cZZ5R4aOPPtL48eM1ffp0JSUladq0aerfv782bdqkmJiYIvt/8MEHmjBhgmbMmKHu3btr8+bNuuWWW+RwODR16lRJ0p///Ge99tpreuedd3TppZdq1apVGjVqlKKionTPPfeU/yoD3NeFS/gymwIAAEDZkG2roezCcMtsCgAAABWqQYMGCgoKUlZWltf2rKwsNWzYsNgxjRo1UkhIiIKCgjzbLrnkEu3Zs0d5eXkKDQ0tMmbixIkaP3685+dDhw7RrHCGL7d+qVOuU7q43sW6qO5Fvi4HAADAJ8o8o8LUqVM1evRojRo1Sm3atNH06dNVo0YNzZgxo9j9ly5dqh49emjo0KFKSEhQv379dPPNN3v9S7WlS5fqmmuu0aBBg5SQkKDf//736tev31n/NRsKLC5cwrc3S/gCAACUCdm2GsopDLcxhFsAAICKFBoaqs6dOystLc2zzeVyKS0tTcnJycWO6dGjhzIyMuRyuTzbNm/erEaNGhXbpCBJYWFhql27ttcXvKVmpEpiNgUAAHBhK1OjQl5enlavXq2UlJRfD+B0KiUlRcuWLSt2TPfu3bV69WrPX8xu2bJFc+fO1dVXX+21T1pamjZv3ixJWr9+vb755hsNHDiwxFpyc3N16NAhr68L0YkTkvvvvJlRAQAA4NyRbauh/BPSL4XhlhkVAAAAKtz48eP15ptv6p133tGPP/6ou+66S0ePHtWoUaMkSSNGjNDEiRM9+991113at2+f7r33Xm3evFlz5szR5MmTNXbsWF9dgt8zM6VmFjQqDEws+f8RAAAAAl2Zln7Yu3ev8vPzFRsb67U9NjZWGzduLHbM0KFDtXfvXvXs2VNmplOnTunOO+/UI4884tlnwoQJOnTokFq3bq2goCDl5+fr2Wef1bBhw0qsZcqUKXrqqafKUn5AWrlSysuTYmOlxERfVwMAAOA/yLbV0C8rJVeeFB4r1SLcAgAAVLQhQ4YoJydHTzzxhPbs2aMOHTooNTXVk4l37Nghp/PXf9sWFxen+fPn6/7779dll12mJk2a6N5779XDDz/sq0vwexv3btSOgzsUFhSmPgl9fF0OAACAz5R56YeyWrRokSZPnqxXX31Va9as0ezZszVnzhw988wznn0+/vhjvf/++/rggw+0Zs0avfPOO3rhhRf0zjvvlHjciRMn6uDBg56vnTt3VvalVEtfFy7h26uX5HD4thYAAIBAR7atZNmF4TaacAsAAFBZxo0bp+3btys3N1fLly9XUlKS57VFixbp7bff9to/OTlZ3377rU6cOKHMzEw98sgjCgoKquKqA8e8jHmSpD4JfVQjpIaPqwEAAPCdMs2o0KBBAwUFBSkrK8tre1ZWlho2bFjsmMcff1zDhw/X7bffLklq166djh49qjFjxujRRx+V0+nUQw89pAkTJugPf/iDZ5/t27drypQpGjlyZLHHDQsLU1hYWFnKD0iLC5fw7c0SvgAAAGVCtq2GcgrDbQzhFgAAAIEpNaNg2YcBLQb4uBIAAADfKtOMCqGhoercubPS0tI821wul9LS0pScnFzsmGPHjnlNFybJ03FrZqXu43K5ylLeBSc/X1q6tOD7XizhCwAAUCZk22rGlS/lFIbbGMItAAAAAs/RvKP6avtXkqQBiTQqAACAC1uZZlSQpPHjx2vkyJHq0qWLunXrpmnTpuno0aMaNWqUJGnEiBFq0qSJpkyZIkkaPHiwpk6dqo4dOyopKUkZGRl6/PHHNXjwYM9f6g4ePFjPPvus4uPjdemll2rt2rWaOnWqbr311gq81MCzfr10+LBUu7bUrp2vqwEAAPA/ZNtq5MB66dRhKaS2FEW4BQAAQOD5avtXysvPU3xUvFo3aO3rcgAAAHyqzI0KQ4YMUU5Ojp544gnt2bNHHTp0UGpqqmJjYyVJO3bs8PoXZI899pgcDocee+wx7dq1S9HR0Z6/vHX729/+pscff1x33323srOz1bhxY91xxx164oknKuASA9fXhUv49ughsSwcAABA2ZFtq5HswnDboIfkJNwCAAAg8Jy+7IPD4fBxNQAAAL7lMPcctX7u0KFDioqK0sGDB1W7dm1fl1MlbrhBmj1bmjJFmjDB19UAAABUnUDPfoF+fcVafIO0c7bUfop0KeEWAABcOAI9+wX69ZVFy7+1VPq+dH0y5BNd2/paX5cDAABQ4cqS/Zylvopqy0xavLjg+14s4QsAAAB/ZiZlF4bbGMItAAAAAk/mvkyl70tXsDNYVza/0tflAAAA+ByNCn5q82YpJ0cKC5O6dPF1NQAAAEA5HN4s5eZIzjCpHuEWAAAAgce97EOPuB6qHXZhzywBAAAg0ajgt74uXMI3KamgWQEAAADwW9mF4bZBkhREuAUAAEDgSc0saFQYkDjAx5UAAABUDzQq+Cn3sg+9e/u2DgAAAKDc3Ms+RBNuAQAAEHhyT+Xqy61fSqJRAQAAwI1GBT/lblToxRK+AAAA8Hc5heE2hnALAACAwPPNjm907OQxNYxsqPax7X1dDgAAQLVAo4If2rlT2rZNcjql5GRfVwMAAACUw9Gd0tFtksMpNSDcAgAAIPCkZvy67IPD4fBxNQAAANUDjQp+yD2bQseOUq1avq0FAAAAKBf3bAp1O0ohhFsAAAAEntTMwkaFFiz7AAAA4Eajgh9yNyr0ZglfAAAA+LvswnAbTbgFAABA4Nl5cKe+z/5eTodTKRel+LocAACAaoNGBT/kblToxRK+AAAA8HfuGRViCLcAAAAIPPMz50uSujXppvo16vu4GgAAgOqDRgU/88sv0n//W/B9z56+rQUAAAAol9xfpIOF4TaacAsAAIDAk5rBsg8AAADFoVHBzyxZUvDf1q2l6Gjf1gIAAACUS05huK3dWgon3AIAACCwnMw/qQVbFkiSBiTSqAAAAHA6GhX8zNdfF/y3N0v4AgAAwN9lF4bbGMItAAAAAs/yXct1KPeQ6kfUV5fGXXxdDgAAQLVCo4KfWVy4hG8vlvAFAACAv8spDLfRhFsAAAAEHveyD/1a9FOQM8jH1QAAAFQvNCr4kaNHpTVrCr6nUQEAAAB+7dRRaV9huI0h3AIAACDwzMuYJ4llHwAAAIpDo4If+fZb6dQpKS5OatbM19UAAAAA5bD3W8lOSTXipJqEWwAAAASWrCNZWrO7oDG3X4t+Pq4GAACg+qFRwY98XbiEL7MpAAAAwO9lF4Zbln0AAABAAPpP5n8kSR0bdlTDyIY+rgYAAKD6oVHBjywuXMK3d2/f1gEAAACUW05huI0h3AIAACDwpGamSmLZBwAAgJLQqOAn8vIKln6QmFEBAAAAfi4/r2DpB0mKIdwCAAAgsOS78jU/Y74kGhUAAABKQqOCn1izRjp+XKpfX7rkEl9XAwAAAJTD/jVS/nEprL5Um3ALAACAwLJm9xr9cvwX1Q6rreSmyb4uBwAAoFqiUcFPfF24hG/PnpLD4dtaAAAAgHLJLgy30YRbAAAABJ55GfMkSSkXpSgkKMTH1QAAAFRPNCr4icWFS/j2ZglfAAAA+LvswnAbTbgFAABA4EnNSJUkDWjBsg8AAAAloVHBD7hc0pIlBd/3YglfAAAA+DNzSXsLw20M4RYAAACBZd/xfVq+a7kkqX9ifx9XAwAAUH3RqOAH/vtfaf9+qWZNqWNHX1cDAAAAlMPB/0p5+6XgmlJdwi0AAAACyxdbvpDLXGoT3UbxUfG+LgcAAKDaolHBD3xduIRvcrIUHOzbWgAAAIByyS4Mtw2SJSfhFgAAAIGFZR8AAADODY0KfmBx4RK+vVnCFwAAAP4uuzDcRhNuAQAAEFjMzNOoMPDigT6uBgAAoHqjUaGaM/u1UaEXS/gCAADAn5lJOYXhNoZwCwAAgMDyXfZ32n1kt2qE1FDP+J6+LgcAAKBao1Ghmtu6Vfr5ZykkREpK8nU1AAAAQDkc3Sod/1lyhkj1CbcAAAAILPPS50mSfpPwG4UHh/u4GgAAgOqNRoVq7uvCJXy7dJEiInxbCwAAAFAu2YXhtl4XKZhwCwAAgMCSmlmw7MOAxAE+rgQAAKD6o1GhmnMv+9CbJXwBAADg77Ldyz4QbgEAABBYDuce1jc7vpFEowIAAMC5oFGhmnM3KvRiCV8AAAD4u5zCcBtNuAUAAEBg+XLrlzrlOqUWdVsosV6ir8sBAACo9mhUqMb27JHS0yWHQ+rRw9fVAAAAAOVwfI90OF2SQ4om3AIAACCwpGYULPswMHGgjysBAADwDzQqVGPu2RTatZPq1PFpKQAAAED5uGdTqNNOCq3j01IAAACAimRmSs0saFRg2QcAAIBzQ6NCNeZuVOjNEr4AAADwd9mF4TaGcAsAAIDAsumXTdp2YJtCg0J1RcIVvi4HAADAL9CoUI25GxV6sYQvAAAA/J17RoVowi0AAAACi3vZh97NeqtmaE0fVwMAAOAfaFSopg4elNavL/ieRgUAAAD4tbyD0v7CcBtDuAUAAEBgcTcqDGjBsg8AAADnikaFamrJEslMatFCatTI19UAAAAA5ZCzRJJJkS2kCMItAAAAAsfxk8f11favJEkDEmlUAAAAOFc0KlRT7mUferOELwAAAPyde9mHGMItAAAAAstX27/SiVMn1LR2U7WJbuPrcgAAAPwGjQrVlLtRgWUfAAAA4PfcjQrRhFsAAAAEFveyDwMTB8rhcPi4GgAAAP9Bo0I1dPy4tHJlwfc0KgAAAMCvnTou/VIYbmMItwAAAAgs8zLmSWLZBwAAgLKiUaEaWrFCysuTGjaUWrTwdTUAAABAOfyyQnLlSeENpUjCLQAAAALHlv1btPmXzQpyBKlv876+LgcAAMCv0KhQDbmXfejdW2K2MAAAAPg197IPMYRbAAAABJb5GfMlSd3juisqPMrH1QAAAPgXGhWqIXejAss+AAAAwO9lF4bbaMItAAAAAktqZqokln0AAAA4HzQqVDOnTklLlxZ8T6MCAAAA/JrrlLS3MNzGEG4BAAAQOPLy85S2JU0SjQoAAADng0aFambdOunIESkqSmrb1tfVAAAAAOWwf5106ogUEiVFEW4BAAAQOJbsWKKjJ48qtmasOjTs4OtyAAAA/M55NSq88sorSkhIUHh4uJKSkrRixYpS9582bZpatWqliIgIxcXF6f7779eJEye89tm1a5f++Mc/qn79+oqIiFC7du20atWq8ynPr7mXfejZUwoK8m0tAAAAFwKybSXKcS/70FNyEm4BAAAQOFIzCpZ96J/YX04H/x4QAACgrILLOuCjjz7S+PHjNX36dCUlJWnatGnq37+/Nm3apJiYmCL7f/DBB5owYYJmzJih7t27a/PmzbrlllvkcDg0depUSdL+/fvVo0cP/eY3v9G8efMUHR2t9PR01a1bt/xX6GfcjQos+wAAAFD5yLaVLLsw3LLsAwAAAALMvIx5kqQBLVj2AQAA4HyUuVFh6tSpGj16tEaNGiVJmj59uubMmaMZM2ZowoQJRfZfunSpevTooaFDh0qSEhISdPPNN2v58uWeff785z8rLi5OM2fO9Gxr3rx5mS/G35nRqAAAAFCVyLaVyOy0GRUItwAAAAgcuw7t0nfZ38khh65qcZWvywEAAPBLZZqTKi8vT6tXr1ZKSsqvB3A6lZKSomXLlhU7pnv37lq9erVnCt0tW7Zo7ty5uvrqqz37fP755+rSpYtuvPFGxcTEqGPHjnrzzTfP53r82saN0t69Uni41KWLr6sBAAAIbGTbSnZoo5S7VwoKl+oRbgEAABA45mfOlyR1bdJVDWo08HE1AAAA/qlMMyrs3btX+fn5io2N9doeGxurjRs3Fjtm6NCh2rt3r3r27Ckz06lTp3TnnXfqkUce8eyzZcsWvfbaaxo/frweeeQRrVy5Uvfcc49CQ0M1cuTIYo+bm5ur3Nxcz8+HDh0qy6VUS+7ZFJKSpNBQ39YCAAAQ6Mi2lcw9m0L9JCmIcAsAAIDAkZqRKollHwAAAMqjTDMqnI9FixZp8uTJevXVV7VmzRrNnj1bc+bM0TPPPOPZx+VyqVOnTpo8ebI6duyoMWPGaPTo0Zo+fXqJx50yZYqioqI8X3FxcZV9KZXO3ajQu7dv6wAAAEDxyLZlkF0YbmMItwAAAAgcp1yntGDLAknSwIsH+rgaAAAA/1WmRoUGDRooKChIWVlZXtuzsrLUsGHDYsc8/vjjGj58uG6//Xa1a9dO1113nSZPnqwpU6bI5XJJkho1aqQ2bdp4jbvkkku0Y8eOEmuZOHGiDh486PnauXNnWS6lWnI3KvRiCV8AAIBKR7atZO4ZFaIJtwAAAAgcK3at0IETB1Q3vK66Nu7q63IAAAD8VpkaFUJDQ9W5c2elpaV5trlcLqWlpSk5ObnYMceOHZPT6X2aoKAgSZKZSZJ69OihTZs2ee2zefNmNWvWrMRawsLCVLt2ba8vf7Zjh7R9uxQUJJVwKwEAAFCByLaV6OgO6eh2yREkNSDcAgAAIHDMS58nSerXop+CnEE+rgYAAMB/BZd1wPjx4zVy5Eh16dJF3bp107Rp03T06FGNGjVKkjRixAg1adJEU6ZMkSQNHjxYU6dOVceOHZWUlKSMjAw9/vjjGjx4sOcvde+//351795dkydP1k033aQVK1bojTfe0BtvvFGBl1q9uWdT6NhRioz0bS0AAAAXCrJtJXEv+1C3oxRCuAUAAEDgSM1MlSQNSBzg40oAAAD8W5kbFYYMGaKcnBw98cQT2rNnjzp06KDU1FTFxsZKknbs2OH1r8wee+wxORwOPfbYY9q1a5eio6M1ePBgPfvss559unbtqk8++UQTJ07U008/rebNm2vatGkaNmxYBVyif3A3KvRmCV8AAIAqQ7atJO5lH2IItwAAAAgc2UezternVZKk/i36+7gaAAAA/+Yw9xy1fu7QoUOKiorSwYMH/XKq3EsvlX74QfrkE+naa31dDQAAQPXm79nvbPz++uZcKh38Qer1iRR3ra+rAQAAqNb8PvudRSBd3/sb3tcfP/mj2se217o71/m6HAAAgGqnLNnPWeqrqBJ79xY0KUhSz56+rQUAAAAolxN7C5oUJCmacAsAAIDAwbIPAAAAFYdGhWrgm28K/nvJJVKDBr6tBQAAACiXnMJwW/sSKZxwCwAAgMDgMpfmZ8yXJA1MHOjjagAAAPwfjQrVwOLCJXx7s4QvAAAA/F1OYbiNIdwCAAAgcKzZvUY5x3JUK7SWkuOSfV0OAACA36NRoRpwNyr06uXbOgAAAIByyy4Mt9GEWwAAAASO1IyCZR/6XtRXoUGhPq4GAADA/9Go4GNHjkhr1hR8T6MCAAAA/NrJI9L+wnAbQ7gFAABA4HA3KgxoMcDHlQAAAAQGGhV8bNkyKT9fio8v+AIAAAD81t5lkuVLNeKlmoRbAACA6uiVV15RQkKCwsPDlZSUpBUrVpS479tvvy2Hw+H1FR4eXoXVVg/7j+/Xsp+WSZL6J/b3cTUAAACBgUYFH3Mv+9CbJXwBAADg73IKw20M4RYAAKA6+uijjzR+/HhNmjRJa9asUfv27dW/f39lZ2eXOKZ27dravXu352v79u1VWHH1kLY1TS5zqXWD1kqok+DrcgAAAAICjQo+5m5UYNkHAAAA+L1sd6MC4RYAAKA6mjp1qkaPHq1Ro0apTZs2mj59umrUqKEZM2aUOMbhcKhhw4aer9jY2CqsuHpwL/swMHGgjysBAAAIHDQq+FBenvTttwXf06gAAAAAv5afJ/1SGG6jCbcAAADVTV5enlavXq2UlBTPNqfTqZSUFC1btqzEcUeOHFGzZs0UFxena665Rv/973+rotxqw8w8jQoDEgf4uBoAAIDAQaOCD61aJZ04ITVoILVu7etqAAAAgHLYt0rKPyGFNZBqE24BAACqm7179yo/P7/IjAixsbHas2dPsWNatWqlGTNm6LPPPtN7770nl8ul7t2766effirxPLm5uTp06JDXlz/7Pvt77Tq8SxHBEerdjCXOAAAAKgqNCj50+rIPDodvawEAAADKJacw3EYTbgEAAAJFcnKyRowYoQ4dOqhPnz6aPXu2oqOj9frrr5c4ZsqUKYqKivJ8xcXFVWHFFc89m8IVCVcoPDjcx9UAAAAEDhoVfOj0RgUAAADAr2UXhtsYwi0AAEB11KBBAwUFBSkrK8tre1ZWlho2bHhOxwgJCVHHjh2VkZFR4j4TJ07UwYMHPV87d+4sV92+lprJsg8AAACVgUYFH8nPl775puB7GhUAAADg11z5Uk5huI0m3AIAAFRHoaGh6ty5s9LS0jzbXC6X0tLSlJycfE7HyM/P13fffadGjRqVuE9YWJhq167t9eWvjuQd0eLtBQ25NCoAAABUrGBfF3Ch+v576eBBKTJS6tDB19UAAAAA5XDwe+nkQSk4UqrbwdfVAAAAoATjx4/XyJEj1aVLF3Xr1k3Tpk3T0aNHNWrUKEnSiBEj1KRJE02ZMkWS9PTTT+vyyy9XYmKiDhw4oOeff17bt2/X7bff7svLqDILty7USddJXVT3Il1c72JflwMAABBQaFTwEfeyD927S8H8FgAAAODP3Ms+NOguOQm3AAAA1dWQIUOUk5OjJ554Qnv27FGHDh2Umpqq2NhYSdKOHTvkdP46Ce/+/fs1evRo7dmzR3Xr1lXnzp21dOlStWnTxleXUKVSMwqXfWgxQA6Hw8fVAAAABBb+FtFH3I0KLPsAAAAAv5dTGG5jCLcAAADV3bhx4zRu3LhiX1u0aJHXzy+99JJeeumlKqiq+jEzzcuYJ4llHwAAACqD8+y7oKKZ0agAAACAAGH2a6NCNOEWAAAAgSF9X7q2HtiqEGeIftP8N74uBwAAIODQqOADmZnS7t1SSIjUrZuvqwEAAADK4UimdHy35AyR6hNuAQAAEBjcyz70atZLkaGRPq4GAAAg8NCo4APu2RS6dZMiInxbCwAAAFAu2YXhtn43KZhwCwAAgMDgblQY0IJlHwAAACoDjQo+wLIPAAAACBgs+wAAAIAAc/zkcS3atkiSNCCRRgUAAIDKQKOCD9CoAAAAgICRTaMCAAAAAsviHYt1/NRxNanVRG1j2vq6HAAAgIBEo0IV271bysiQHA6pe3dfVwMAAACUw/Hd0pEMSQ4pmnALAACAwDAvfZ6kgtkUHA6Hj6sBAAAITDQqVDH3bArt20t16vi0FAAAAKB83LMp1G0vhdbxaSkAAABARUnNTJXEsg8AAACViUaFKsayDwAAAAgYOSz7AAAAgMCy7cA2bdy7UUGOIKVclOLrcgAAAAIWjQpVjEYFAAAABAz3jAoxhFsAAAAEhvkZ8yVJlze9XHXC6/i2GAAAgABGo0IVOnBA2rCh4HsaFQAAAODX8g5IBwrDLTMqAAAAIECw7AMAAEDVoFGhCi1ZIplJF18sNWzo62oAAACAcshZIsmkWhdLEYRbAAAA+L+8/DylbUmTJA1MHOjjagAAAAIbjQpViGUfAAAAEDByCsMtsykAAAAgQCzbuUyH8w4ruka0Ojbq6OtyAAAAAhqNClWIRgUAAAAEjOzCcBtDuAUAAEBgmJcxT5LUP7G/nA7+6hwAAKAykbaqyPHj0sqVBd/TqAAAAAC/duq4tK8w3DKjAgAAAAJEakaqJGlAiwE+rgQAACDw0ahQRZYvl06elBo1ki66yNfVAAAAAOXwy3LJdVKKaCRFEm4BAADg/34+/LPWZ62XQw71a9HP1+UAAAAEPBoVqoh72YfevSWHw7e1AAAAAOXiXvYhmnALAACAwPCfzP9Ikjo37qzomtE+rgYAACDw0ahQRdyNCiz7AAAAAL+XUxhuYwi3AAAACAzuZR8GJg70cSUAAAAXBhoVqsCpU9LSpQXf06gAAAAAv+Y6Je0tDLfRhFsAAAD4v3xXvmdGhQGJA3xcDQAAwIWBRoUqsHatdPSoVKeO1Latr6sBAAAAymH/WunUUSmkjlSHcAsAAAD/t2LXCu0/sV91wuuoW5Nuvi4HAADggkCjQhVwL/vQs6fk5I4DAADAn2UXhtvonpKDcAsAAAD/51724aqLrlKwM9jH1QAAAFwY+JvFKuBuVGDZBwAAAPi9nMJwG0O4BQAAQGBIzSxoVGDZBwAAgKpDo0Ilc7loVAAAAECAMNevjQrRhFsAAAD4v73H9mrlrpWSpP4t+vu4GgAAgAsHjQqVbONG6ZdfpIgIqXNnX1cDAAAAlMOhjVLuL1JQhFSPcAsAAAD/tyBzgUymdjHt1KR2E1+XAwAAcMGgUaGSuWdTuPxyKTTUt7UAAAAA5ZJdGG4bXC4FEW4BAADg/9zLPgxMHOjjSgAAAC4sNCpUMpZ9AAAAQMBg2QcAAAAEEJe5lJpR0KgwIHGAj6sBAAC4sNCoUMm+/rrgvzQqAAAAwO9lF4bbGMItAAAA/N+6PeuUfTRbNUNqqkd8D1+XAwAAcEGhUaESbd8u7dwpBQUVLP0AAAAA+K2j26VjOyVHkFSfcAsAAAD/555Noe9FfRXK0mYAAABVikaFSuRe9qFzZyky0re1AAAAAOWSXRhu63WWQgi3AAAA8H+eZR9asOwDAABAVaNRoRK5GxVY9gEAAAB+L6cw3EYTbgEAAOD/Dp44qKU7l0qSBiTSqAAAAFDVzqtR4ZVXXlFCQoLCw8OVlJSkFStWlLr/tGnT1KpVK0VERCguLk7333+/Tpw4Uey+zz33nBwOh+67777zKa1a+bpwCV8aFQAAAKovsu05yi4MtzGEWwAAAPi/tK1pyrd8tarfSs3rNvd1OQAAABecMjcqfPTRRxo/frwmTZqkNWvWqH379urfv7+ys7OL3f+DDz7QhAkTNGnSJP34449666239NFHH+mRRx4psu/KlSv1+uuv67LLLiv7lVQzOTnSxo0F3/fs6dtaAAAAUDyy7Tk6kSMdKgy30YRbAAAA+D/Psg/MpgAAAOATZW5UmDp1qkaPHq1Ro0apTZs2mj59umrUqKEZM2YUu//SpUvVo0cPDR06VAkJCerXr59uvvnmIv9S7ciRIxo2bJjefPNN1a1b9/yuphr55puC/156qVS/vm9rAQAAQPHItucopzDcRl0qhRFuAQAA4N/MTPMy5kmiUQEAAMBXytSokJeXp9WrVyslJeXXAzidSklJ0bJly4od0717d61evdrzl7dbtmzR3LlzdfXVV3vtN3bsWA0aNMjr2KXJzc3VoUOHvL6qk8WFS/iy7AMAAED1RLYtg+zCcBtNuAUAAID/+yHnB/106CeFB4erT7M+vi4HAADgghRclp337t2r/Px8xcbGem2PjY3VRvc6B2cYOnSo9u7dq549e8rMdOrUKd15551e0+POmjVLa9as0cqVK8+5lilTpuipp54qS/lVikYFAACA6o1sWwY5heE2hnALAAAA/+de9qFPsz6KCInwcTUAAAAXpjIv/VBWixYt0uTJk/Xqq69qzZo1mj17tubMmaNnnnlGkrRz507de++9ev/99xUeHn7Ox504caIOHjzo+dq5c2dlXUKZHT4srVlT8D2NCgAAAIHjQsy2OnlY2l8YbplRAQAAAAEgNbOgUYFlHwAAAHynTDMqNGjQQEFBQcrKyvLanpWVpYYNGxY75vHHH9fw4cN1++23S5LatWuno0ePasyYMXr00Ue1evVqZWdnq1OnTp4x+fn5+vrrr/X3v/9dubm5CgoKKnLcsLAwhYWFlaX8KrNsmeRySQkJUlycr6sBAABAcci252jvMslcUs0EqSbhFgAAAP7taN5Rfb39a0nSwMSBPq4GAADgwlWmGRVCQ0PVuXNnpaWleba5XC6lpaUpOTm52DHHjh2T0+l9GvdfzpqZ+vbtq++++07r1q3zfHXp0kXDhg3TunXriv2L3OqOZR8AAACqP7LtOcouDLfMpgAAAIAAsGjbIuXl5ymhToJa1m/p63IAAAAuWGWaUUGSxo8fr5EjR6pLly7q1q2bpk2bpqNHj2rUqFGSpBEjRqhJkyaaMmWKJGnw4MGaOnWqOnbsqKSkJGVkZOjxxx/X4MGDFRQUpFq1aqlt27Ze56hZs6bq169fZLu/oFEBAADAP5Btz0FOYbiNIdwCAADA/83LmCdJGtBigBwOh4+rAQAAuHCVuVFhyJAhysnJ0RNPPKE9e/aoQ4cOSk1NVWxsrCRpx44dXv/K7LHHHpPD4dBjjz2mXbt2KTo6WoMHD9azzz5bcVdRjeTmSt9+W/A9jQoAAADVG9n2LPJzpb2F4ZYZFQAAABAAUjNSJUkDEgf4uBIAAIALm8PMzNdFVIRDhw4pKipKBw8eVO3atX1Wx5IlUs+eUnS0lJUl0ZQLAABQ8apL9qss1eb6cpZIC3pKYdHS9YRbAACAylBtsl8lqU7Xl7EvQxf/7WIFO4O170/7VCuslk/rAQAACDRlyX7OUl9FmZ2+7AN/jwsAAAC/ln3asg+EWwAAAPg592wKPeN70qQAAADgYzQqVLDTGxUAAAAAv5ZTGG5Z9gEAAAABwLPsQwuWfQAAAPA1GhUqUH6+9M03Bd/TqAAAAAC/5sqXcgrDbQzhFgAAAP7txKkTWrhtoSRp4MUDfVwNAAAAaFSoQN99Jx06JNWqJbVv7+tqAAAAgHI4+J108pAUXEuqQ7gFAACAf1u8fbGOnTymRpGN1C6mna/LAQAAuODRqFCB3Ms+dO8uBQf7thYAAACgXLLdyz50l5yEWwAAAPg3z7IPiQPkcDh8XA0AAABoVKhA7kYFln0AAACA38txNyoQbgEAAOD/UjN/bVQAAACA79GoUEHMpK+/LvieRgUAAAD4NTMpuzDcxhBuAQAA4N92HNyhH3J+kNPhVMpFKb4uBwAAAKJRocJkZEhZWVJoqNStm6+rAQAAAMrhcIZ0Iktyhkr1CbcAAADwb/Mz5kuSkpokqV5EPR9XAwAAAIlGhQrjXvahWzcpPNy3tQAAAADl4l72oX43KYhwCwAAAP/mXvZhYOJAH1cCAAAANxoVKoi7UYFlHwAAAOD33I0K0YRbAAAA+LeT+Sf1xZYvJEkDEgf4uBoAAAC40ahQQb4uXMKXRgUAAAD4vezCcBtDuAUAAIB/W/bTMh3KPaQGNRqoc+POvi4HAAAAhWhUqAA//yxt2SI5HFL37r6uBgAAACiHYz9LR7ZIckgNCLcAAADwb6kZBcs+9GvRT04Hfx0OAABQXZDMKoB72YcOHaSoKJ+WAgAAAJSPe9mHuh2kUMItAAAA/Ju7UWFAC5Z9AAAAqE5oVKgA7kYFln0AAACA38suDLfRhFsAAAD4tz1H9mjtnrWSCmZUAAAAQPVBo0IF+LpwCV8aFQAAAOD3cgrDbQzhFgAAAP7tP5n/kSR1btRZsZGxPq4GAAAAp6NRoZz275e+/77gexoVAAAA4Nfy9ksHCsMtMyoAAADAz3mWfUhk2QcAAIDqhkaFclqyRDKTWraUYmnKBQAAgD/LWSLJpFotpQjCLQAAAPxXvitf8zPnS6JRAQAAoDqiUaGcFhcu4ctsCgAAAPB72YXhlmUfAAAA4OdW/bxK+47vU1RYlC5vermvywEAAMAZaFQop68Ll/ClUQEAAAB+L7sw3LLsAwAAAPyce9mHlItSFOwM9nE1AAAAOBONCuVw7Ji0alXB9zQqAAAAwK+dOibtKwy3zKgAAAAAP5eaWdCowLIPAAAA1RONCuWwfLl06pTUpInUvLmvqwEAAADK4Zflkp2SIppINQm3AAAA8F+/HPtFK3atkESjAgAAQHVFo0I5LC5cwrdXL8nh8G0tAAAAQLlkF4bbGMItAAAA/NsXW76Qy1xqG9NWTWs39XU5AAAAKAaNCuXwdeESviz7AAAAAL+XXRhuowm3AAAA8G/zMuZJkga0YDYFAACA6opGhfN08qS0bFnB9zQqAAAAwK+5Tkp7C8NtDOEWAAAA/stlLqVmpEpi2QcAAIDqjEaF87R2rXTsmFS3rnTppb6uBgAAACiHfWul/GNSaF0pinALAAAA/7Uha4OyjmapRkgN9Yzv6etyAAAAUAIaFc7T4sIlfHv2lJzcRQAAAPiznMJwG91TchBuAQAAAtkrr7yihIQEhYeHKykpSStWrDincbNmzZLD4dC1115buQWWk3s2hSubX6mw4DAfVwMAAICSBPu6AH81ZIhUv77UsKGvKwEAAADKqdkQKay+FE64BQAACGQfffSRxo8fr+nTpyspKUnTpk1T//79tWnTJsXExJQ4btu2bXrwwQfVyw/WwL2lwy1qGNlQjWs19nUpAAAAKIXDzMzXRVSEQ4cOKSoqSgcPHlTt2rV9XQ4AAAAqUaBnv0C/PgAAAPyqKrNfUlKSunbtqr///e+SJJfLpbi4OP3P//yPJkyYUOyY/Px89e7dW7feeqsWL16sAwcO6NNPPz3nc5JtAQAALhxlyX7M6woAAAAAAAAAAS4vL0+rV69WSkqKZ5vT6VRKSoqWLVtW4rinn35aMTExuu2226qiTAAAAFwgWPoBAAAAAAAAAALc3r17lZ+fr9jYWK/tsbGx2rhxY7FjvvnmG7311ltat27dOZ8nNzdXubm5np8PHTp0XvUCAAAgsDGjAgAAAAAAAADAy+HDhzV8+HC9+eabatCgwTmPmzJliqKiojxfcXFxlVglAAAA/BUzKgAAAAAAAABAgGvQoIGCgoKUlZXltT0rK0sNGzYssn9mZqa2bdumwYMHe7a5XC5JUnBwsDZt2qQWLVoUGTdx4kSNHz/e8/OhQ4doVgAAAEARNCoAAAAAAAAAQIALDQ1V586dlZaWpmuvvVZSQeNBWlqaxo0bV2T/1q1b67vvvvPa9thjj+nw4cN6+eWXS2w+CAsLU1hYWIXXDwAAgMBCowIAAAAAAAAAXADGjx+vkSNHqkuXLurWrZumTZumo0ePatSoUZKkESNGqEmTJpoyZYrCw8PVtm1br/F16tSRpCLbAQAAgLKiUQEAAAAAAAAALgBDhgxRTk6OnnjiCe3Zs0cdOnRQamqqYmNjJUk7duyQ0+n0cZUAAAC4EDjMzHxdREU4dOiQoqKidPDgQdWuXdvX5QAAAKASBXr2C/TrAwAAwK8CPfsF+vUBAADgV2XJfrTHAgAAAAAAAAAAAACAKkOjAgAAAAAAAAAAAAAAqDI0KgAAAAAAAAAAAAAAgCpDowIAAAAAAAAAAAAAAKgyNCoAAAAAAAAAAAAAAIAqQ6MCAAAAAAAAAAAAAACoMjQqAAAAAAAAAAAAAACAKhPs6wIqiplJkg4dOuTjSgAAAFDZ3JnPnQEDDdkWAADgwkG2BQAAQKAoS7YNmEaFw4cPS5Li4uJ8XAkAAACqyuHDhxUVFeXrMioc2RYAAODCQ7YFAABAoDiXbOuwAGnVdblc+vnnn1WrVi05HI4qOeehQ4cUFxennTt3qnbt2lVyTl8ItOv09+vxl/qra53VpS5f1lHV566I81V2zZVx/Io85vkeqzw1VPU5q3JcaWP8vX5fncsXn2lmpsOHD6tx48ZyOgNvNTOybeUJtOv09+vxl/qra53VpS6ybdUfo6qPT7atvuPItmRbf0C2rTyBdp3+fj3+Un91rbO61EW2rfpjVPXxybbVdxzZ9sLLtgEzo4LT6VTTpk19cu7atWtXqz/QK0ugXae/X4+/1F9d66wudfmyjqo+d0Wcr7JrrozjV+Qxz/dY5amhqs9ZleNKG+Pv9fvqXFX9uRKI/9rMjWxb+QLtOv39evyl/upaZ3Wpi2xb9ceo6uOTbavvOLJtxY8h21Ycsm3lC7Tr9Pfr8Zf6q2ud1aUusm3VH6Oqj0+2rb7jyLYVP6a6ZtvAa9EFAAAAAAAAAAAAAADVFo0KAAAAAAAAAAAAAACgytCoUA5hYWGaNGmSwsLCfF1KpQq06/T36/GX+qtrndWlLl/WUdXnrojzVXbNlXH8ijzm+R6rPDVU9TmrclxpY/y9fl+dq7p8tqJ8LpTfY6Bdp79fj7/UX13rrC51kW2r/hhVfXyybfUdR7Yl26J4F8rvMdCu09+vx1/qr651Vpe6yLZVf4yqPj7ZtvqOI9teeNnWYWbm6yIAAAAAAAAAAAAAAMCFgRkVAAAAAAAAAAAAAABAlaFRAQAAAAAAAAAAAAAAVBkaFQAAAAAAAAAAAAAAQJWhUaEETz75pBwOh9dX69atSx3zz3/+U61bt1Z4eLjatWunuXPnVlG15+7rr7/W4MGD1bhxYzkcDn366aee106ePKmHH35Y7dq1U82aNdW4cWONGDFCP//8c6nHPJ97VZFKuyZJysrK0i233KLGjRurRo0aGjBggNLT00s95uzZs9WlSxfVqVNHNWvWVIcOHfSPf/yjQuueMmWKunbtqlq1aikmJkbXXnutNm3a5LXPFVdcUeTe3nnnned8jjvvvFMOh0PTpk077zpfe+01XXbZZapdu7Zq166t5ORkzZs3z/P6iRMnNHbsWNWvX1+RkZG64YYblJWVVeoxjxw5onHjxqlp06aKiIhQmzZtNH369Aqv7XzuX0XU9txzz8nhcOi+++7zbCvrfTrf92Nx53YzMw0cOLDY98n5nvvM823btq3IPXd//fOf/5RU/GdGy5YtPfc9PDxc9erVU2Rk5Dk/U2amJ554QpGRkaV+Ht1xxx1q0aKFIiIiFB0drWuuuUYbN24s9diTJk0qcsyLLrrI83pZn7Pirt/99fzzz2vPnj0aPny4GjZsqJo1a6pTp07617/+JUnatWuX/vjHP6p+/fqKiIhQu3bttGrVKs/nSWRkpGrWrKnw8HCFh4crJSXF83lX0lhJ+utf/6qoqCg5nU4FBQUpOjra8zsvbZwkXX311QoJCZHD4VBwcLC6deum5cuXlzouPz9f7du3L3L9V1xxRannKum+3XbbbcWOS0hIKHb/mJgYpaenF/u+jIuLK3ZMz549JUmvv/66EhIS5HQ65XA41KdPH6Wnp5d4rrFjx5b42tChQ0sdd8sttxT7Wq1atUock56eXuJ9iomJKXGcmWn8+PGKiIjwbA8NDVVYWJhatGihZ555RmZW5D0XHBxc4jGL88orryghIUHh4eFKSkrSihUrSn3/oeKQbcm2ZNsCZFuyLdmWbEu2JduSbf0f2ZZsS7YtQLYl25JtybZkW7Kt32dbQ7EmTZpkl156qe3evdvzlZOTU+L+S5YssaCgIPvLX/5iP/zwgz322GMWEhJi3333XRVWfXZz5861Rx991GbPnm2S7JNPPvG8duDAAUtJSbGPPvrINm7caMuWLbNu3bpZ586dSz1mWe9VRSvtmlwul11++eXWq1cvW7FihW3cuNHGjBlj8fHxduTIkRKPuXDhQps9e7b98MMPlpGRYdOmTbOgoCBLTU2tsLr79+9vM2fOtO+//97WrVtnV199dZG6+vTpY6NHj/a6twcPHjyn48+ePdvat29vjRs3tpdeeum86/z8889tzpw5tnnzZtu0aZM98sgjFhISYt9//72Zmd15550WFxdnaWlptmrVKrv88sute/fupR5z9OjR1qJFC1u4cKFt3brVXn/9dQsKCrLPPvusQms7n/tX3tpWrFhhCQkJdtlll9m9997r2V7W+3Q+78eSzu02depUGzhwYJH3yfmeu7jznTp1yut+796925566imLjIy0w4cPm1nxnxnDhw/33Pdhw4ZZ3bp1zel02osvvnhOz9Rzzz1nUVFRNmTIEGvRooX169fP4uLibOvWrV6fR6+//rp99dVXtnXrVlu9erUNHjzY4uLi7NSpUyUeu2/fvuZ0Om3mzJmWlpZm/fr1s/j4eDt+/LiZlf05mzRpkrVq1crWr1/v+Xr55ZfN4XBYZmamXXXVVda1a1dbvny5ZWZm2jPPPGNOp9MWLVpkzZo1s1tuucWWL19uW7Zssfnz51tGRobn8+T++++3yMhI69y5szVs2NAGDRpkzZs3t59//rnEsbNmzbKQkBBr06aNvfjii3bjjTdaZGSkdezY0dq3b1/iODOzWbNmWVBQkD3wwAOWmppqN9xwg4WGhlpkZKTFxcWVOO7ZZ5+1sLAw69y5s61YscLeeOMNi4iIsDp16pQ4xszsxx9/tKZNm9pNN91kc+fOtT//+c8myWJjY4sdl52dbW+//bYlJiZa+/bt7fHHHzdJ5nA4rFGjRnbbbbcVeV927drVdu/ebXPnzrW77rrLHnnkEZNkY8eONTOz3/72txYWFmbDhw83STZw4EBr3ry57dixw+sZWLBggUmyhQsXWnZ2tv3lL3+x2bNn24oVK+zVV181SRYTE1Pk/XL6uJEjR1rdunVt2LBhnmflxx9/tMzMzBLH/PLLL9arVy97/fXXbfHixfbvf//bmjRpYk6n07Zs2VLiuOeee86Cg4Pt4osvthtvvNFCQkKsZs2a5nA47C9/+YtFRkbayy+/XOQ9984771haWpr179/f4uPjbc6cOZ5jnmnWrFkWGhpqM2bMsP/+9782evRoq1OnjmVlZZX6/kbFINuSbcm2Bci2ZFuyLdmWbEu2Jdv6P7It2ZZsW4BsS7Yl25JtybZkW3/PtjQqlGDSpEnWvn37c97/pptuskGDBnltS0pKsjvuuKOCK6s4Z/tDz6zgDzRJtn379hL3Keu9qkxnXtOmTZtMkicAmZnl5+dbdHS0vfnmm2U6dseOHe2xxx6rqFKLyM7ONkn21Vdfebb16dOn2OByNj/99JM1adLEvv/+e2vWrFm5Am9x6tata//7v/9rBw4csJCQEPvnP//pee3HH380SbZs2bISx1966aX29NNPe23r1KmTPfrooxVWm9n53b/y1Hb48GG7+OKLbcGCBV7nPt/7dKbS3o8lndtt7dq11qRJE9u9e/c5vffPdu6zne90HTp0sFtvvdXzc3GfGe77fvq9ct/3s90rl8tlDRs2tOeff95z7AMHDlhYWJh9+OGHpV7X+vXrTZJXqDrz2DVr1rRGjRp5tp157LI+Z8Vd/zXXXGNXXnmlmZnVrFnT3n33Xa/X69WrZwMGDLCePXuWeNzT74P782TOnDkWFhZmv/vd70oc261bN0+YMyv4jGzcuLHdfffdJsm6du1a4jmLG9uwYUOTZG3bti1x3KBBgywxMdGuueYaz7aWLVtadHR0iWPMzB5++GGv67jmmmssPj6+1Pty+p8D9957r7Vo0cKioqIsMjLSgoKCzvq+vPfeey04ONimTp3qdY8XLlxokmzbtm3FPmvuc7lcriI13Xvvvda0adNin73Tx40cOdLq169/1uertHOZFdzb4j473OPcv7fQ0FB79913bdCgQfbHP/7RwsLCLDIy0t588027/vrrbdiwYWbm/ay5ud8XAwYMKLGWkp61KVOmlHp9qBhk2wJk21+RbX9Fti0e2bZ4ZFtvZFuyLdm2ANm2apFtC5Btf0W2/RXZtnhk2+KRbb2Rbcm2ZNsCVZltWfqhFOnp6WrcuLEuuugiDRs2TDt27Chx32XLliklJcVrW//+/bVs2bLKLrNSHTx4UA6HQ3Xq1Cl1v7Lcq6qUm5srSQoPD/dsczqdCgsL0zfffHNOxzAzpaWladOmTerdu3el1CkV3GtJqlevntf2999/Xw0aNFDbtm01ceJEHTt2rNTjuFwuDR8+XA899JAuvfTSCq0xPz9fs2bN0tGjR5WcnKzVq1fr5MmTXs9+69atFR8fX+qz3717d33++efatWuXzEwLFy7U5s2b1a9fvwqrza2s9688tY0dO1aDBg0q8llwvvfpTKW9H0s6tyQdO3ZMQ4cO1SuvvKKGDRue8/lKO3dp5zvd6tWrtW7dOt12221e28/8zLjsssv0+eefa/78+Tp58qTCwsI89/1s92rr1q3as2ePp5b09HRdcsklcjgcevLJJ0v8PDp69Khmzpyp5s2bKy4ursRjHz16VPv37/fUe/fdd6t9+/Ze9ZT1OTv9+m+44Qb9+9//9tyj7t2766OPPtK+ffvkcrk0a9YsnThxQunp6erSpYtuvPFGxcTEqGPHjnrzzTeLvQ/uz5P4+HglJSVp8eLFxY7Ny8vT6tWrvX6PTqdTKSkpWrt2rSSpa9euxZ6zuLGnTp1SkyZNJEk9evQosdbu3btr9+7d+vLLLxUTE6OEhASlp6erXbt2JY6RpM8//9xzHQ0aNNBnn32mQ4cOlXpf3H8OOJ1Ovffee+rSpYuOHz+ukJAQ5efnl/q+zMvL03vvveeZmu7MZ02SoqKilJSU5PU8uMfdeuutcjgcXteQl5enf/zjH4qPjy/y7BU37sCBA/rrX/+qoKAg1atXT/fdd5/X81XauaSC9+DmzZslyeuz4/Rx27Zt0549e9SpUyd99NFH6tChgxYvXqwmTZroxIkTio2N1TfffKOBAwdKKvqec9+Hbt26adGiRSVed0nPmr9nJX9CtiXbSmTb05FtS0e2LYpsWzyyLdmWbEu29QWyLdlWItuejmxbOrJtUWTb4pFtybZk2yrOtpXeCuGn5s6dax9//LGtX7/eUlNTLTk52eLj4+3QoUPF7h8SEmIffPCB17ZXXnnFYmJiqqLc86KzdOcdP37cOnXqZEOHDi31OGW9V5XpzGvKy8uz+Ph4u/HGG23fvn2Wm5trzz33nEmyfv36lXqsAwcOWM2aNS04ONjCwsLsrbfeqrS68/PzbdCgQdajRw+v7a+//rqlpqbahg0b7L333rMmTZrYddddV+qxJk+ebFdddZWnK6oiOnM3bNhgNWvWtKCgIIuKirI5c+aYmdn7779voaGhRfbv2rWr/elPfyrxeCdOnLARI0aYJAsODrbQ0FB75513KrQ2s/O7f+db24cffmht27b1mlbK3U13vvfpdKW9H0s7t5nZmDFj7LbbbvP8fLb3/tnOfbbzne6uu+6ySy65xGtbcZ8ZcXFxdvPNN5skk1Tkvpd2r5YsWWKS7Oeff/Y6dq9evax+/fpFPo9eeeUVq1mzpkmyVq1aldiVe/qxX3/9da96a9So4XmWyvqcnXn98fHx5nQ6LTs728zM9u/fb/369fM8g7Vr17b58+dbWFiYhYWF2cSJE23NmjX2+uuvW3h4uL399ttetf70009enyc33nijOZ3OYse+9NJLJsmWLl3qVeP9999vNWrUKHHc22+/bbt27fKM/X//7/95ppuKjIw0h8NRaq35+fk2ePBgk2RBQUGe37vD4bCHH3642DFm5nUP7rnnHqtRo4bnPpV0rry8PGvUqJE5HA6TZJGRkXbLLbd4znem05+1jz76yIKCgqxJkyb20ksveT1r7s7c/fv324033mg33XST5xjucbt27fI69iuvvGJhYWEmyVq0aFHk2Ttz3Icffmh33323vfbaazZt2jRr3LixhYSE2LXXXnvWc7mNGTPGwsPDi3x2nD7OfV0//vij59lz3y+Hw2EOh8MmT57sGXv6fTjd5Zdfbg6Ho9haTn9eTvfQQw9Zt27diq0dFYtsS7Yl2/6KbEu2JduSbcm2ZFs3sq1/ItuSbcm2vyLbkm3JtmRbsi3Z1s0fsy2NCudo//79Vrt2bc/URGcKtMCbl5dngwcPto4dO57z2lpuZ7tXlam4a1q1apW1b9/e88Hav39/GzhwoA0YMKDUY+Xn51t6erqtXbvWXnjhBYuKiip27ZaKcOedd1qzZs1s586dpe6XlpZW6nRHq1atstjYWK8Pm4oIvLm5uZaenm6rVq2yCRMmWIMGDey///3veQe5559/3lq2bGmff/65rV+/3v72t79ZZGSkLViwoMJqK87Z7t/51rZjxw6LiYmx9evXe7ZVZOAt7f14tnN/9tlnlpiY6FlnzKxsgffMc5/tfKc7duyYRUVF2QsvvFDqOfbv32/h4eEWGxtrDzzwgIWEhBS57+caeE9344032rXXXlvk8+jAgQO2efNm++qrr2zw4MHWqVMnT3g/l2Pv37/fgoODrUuXLsWOOZfn7HSJiYkWGhrqqXHcuHHWrVs3++KLL2zdunX25JNPWlRUlAUHB1tycrLX2P/5n/+xyy+/3KvW4cOHe32euANvcWM7depUJITk5eVZixYtrEaNGhYSElLiOU8PMEeOHLH09HRbtmyZtWvXziQVuT+n1/rhhx9a06ZN7cMPP7QNGzbYu+++6wm9X3zxRbFjzMyrnlatWtm4cePM6XRaZGRkiecyM1u2bJnnf3IcDoeFhIRYq1atzhp4+/XrZ7/97W89n6PnGnjd48504MAB69GjhyUnJxf77JU0zi0zM9Nzn9zPV2ljDh48aMHBwda4ceMinx2nj3Nf16hRo6xbt2726KOPWmxsrDVp0sSCg4Pt2WeftXr16hX5n6sz33OxsbFe0+2dzteBF0WRbc8d2bbsyLZk29KQbcm2ZNsCZFuyLSoO2fbckW3LjmxLti0N2ZZsS7YtQLYl254vGhXKoEuXLjZhwoRiX4uLiysSKp544gm77LLLqqCy81PSH3p5eXl27bXX2mWXXWZ79+49r2OXdq8qU2l/kB84cMDT+datWze7++67y3Ts22677azdvOdj7Nix1rRpU9uyZctZ9z1y5IhJstTU1GJff+mll8zhcFhQUJDnS5I5nU5r1qxZhdXct29fGzNmjOcP9v3793u9Hh8fb1OnTi127LFjxywkJMT+/e9/e22/7bbbrH///hVWW3HOdv/Ot7ZPPvnE8z9Up9939+/iiy++KPN9cjvb+/Fs5x43blyJz0SfPn3KfO6zne/UqVOe8e+++66FhIR43nclOXbsmDkcDvv973/v9Uydft9Lu1fuELB27Vqv7b1797Z77rmn1M+j3Nxcq1GjRpG/sDjbsSMjI61z587Fjjnbc3a6r7/+2iRZmzZtbMKECZaRkWGS9/qMZgXPdWRkpFeHtZnZq6++ao0bN/aqNSYmxuvzpHfv3larVq0SxwYFBXk+N92/87p169qAAQMsPj6+xHG5ubleY91GjBhhDoejSOA9vdamTZva3//+d6/Xo6KizOFw2PTp04sdY2aeetz3bd26dVavXj2rUaNGiecyM9u2bZs5nU57//33LTs72/r27WtRUVGlvi/dYz799FNP4D39eTg98LqftdPP9emnn9qZTn/tzGevtHGnq1+/vuf5Km1MXl6ederUyRwOh23cuLHEOsy8g/T333/v+f307t3b4uLi7I477rBnnnnGWrVq5bX/6e+Lbdu2maQSw3dpz8vvfve7Uq8ZlYdse+7ItueObFuAbFs8si3Z1oxs60a2JduiYpFtzx3Z9tyRbQuQbYtHtiXbmpFt3ci2ZNvz5RTOyZEjR5SZmalGjRoV+3pycrLS0tK8ti1YsMBrzSV/cPLkSd10001KT0/XF198ofr165f5GGe7V74SFRWl6Ohopaena9WqVbrmmmvKNN7lcnnWzKkIZqZx48bpk08+0ZdffqnmzZufdcy6deskqcR7O3z4cG3YsEHr1q3zfDVu3FgPPfSQ5s+fX2G1u+9F586dFRIS4vXsb9q0STt27Cjx2T958qROnjwpp9P74ycoKEgul6vCaivO2e7f+dbWt29ffffdd173vUuXLho2bJjn+7LeJ3c9Z3s/nu3cjz76aJFnQpJeeuklzZw5s8znPtv5goKCPMd466239Lvf/U7R0dElnkeS9u/fLzNT/fr1vZ4p930/271q3ry5GjZs6HV/Dx06pOXLl6tjx46lfh5ZQcNeic9Mccf++eefdeTIEbVt27bYMWd7zk731ltvqUOHDtq9e7caNWrkWcOquGcwNjZWmzZt8tq+efNmNWvWTGamF198UU6nU6NGjfJ8nrjvQ7t27Uoc27lzZ6WlpXn9zsPCwtSnTx/16NGjxHGhoaGesW4ul0tpaWkKCQlRdnZ2seOkgvX3zrzGxo0by8y87tvpYyR56nnrrbfUuXNntW/fXtHR0V7PXXHjZs6cqZiYGN10002Kjo7WkSNHdPDgQQUHB5f4vnSPGTRokOf10p419/NZ3Lgz6xg0aFCRZ6+0cW4//fSTfvnlF0kFz1dJY9y/y40bN2rQoEFq1apViXW4r8v9Hnc6nTp27Jhyc3O1fPly1a1bVy6Xy+tzsLj7MH36dEnSH/7wh2JrL+158besFCjItueObHtuyLZkW7JtAbIt2VYi25JtUdXItueObHtuyLZkW7JtAbIt2VYi25JtK1mlt0L4qQceeMAWLVpkW7dutSVLllhKSoo1aNDA02E2fPhwr06vJUuWWHBwsL3wwgv2448/2qRJkywkJMS+++47X11CsQ4fPmxr1661tWvXmiSbOnWqrV271rZv3255eXn2u9/9zpo2bWrr1q2z3bt3e75yc3M9x7jyyivtb3/7m+fns90rX16TmdnHH39sCxcutMzMTE+H1fXXX+91jDN/n5MnT7b//Oc/lpmZaT/88IO98MILFhwcbG+++WaF1X3XXXdZVFSULVq0yOteHzt2zMzMMjIy7Omnn7ZVq1bZ1q1b7bPPPrOLLrrIevfu7XWcVq1a2ezZs0s8T3mnEJswYYJ99dVXtnXrVtuwYYNNmDDBHA6H/ec//zGzgunP4uPj7csvv7RVq1ZZcnJykSmHzqyxT58+dumll9rChQtty5YtNnPmTAsPD7dXX321wmo73/tXUbWdOa1WWe/Tub4fz+XcZ1IxHezlOXdx50tPTzeHw2Hz5s0rsv8DDzxgcXFxNn36dM9nhntKp4ULF9rQoUOtfv36FhISYhMmTDinZ+q5556zOnXq2LXXXmszZsywq666yho1amRXXnml5/MoMzPTJk+ebKtWrbLt27fbkiVLbPDgwVavXj3Lysoq8di9evWyyMhIe+ONN+zdd9+16OhoczqdtmPHjvN6ztyfmRs2bLCwsDBr3bq1p8a8vDxLTEy0Xr162fLlyy0jI8NeeOEFczgc9tJLL3mmc7r88stt5MiRVqNGDXvvvfc8nydjxoyxqKgoe/vtt+3LL7+03/72t9a8eXNbvHhxiWNnzZploaGh1rFjR2vYsKHdcMMNVrt2bduwYYPNmzfPMy49Pd3atGljoaGh9t5775mZ2dtvv21BQUH22GOP2YIFC+y6666z0NBQCwkJKXXc0KFDLTIy0l544QVbvHixPfnkk+Z0Ok2SPfXUU5aenm7vv/++OZ1OGzFihOc+rlixwoKCgiwkJMSeeuope//99y0sLMyCgoJKPNfDDz9sUVFR9rvf/c7mzp1r119/vUmynj17er0vr776amvSpIklJydbfn6+xcfH2y233GIJCQlWt25de/DBB23t2rV21113WWRkpI0dO9ZznMaNG9uuXbs84+Lj473+nMzMzLRnn33WGjZsaHfddVeRZ889rl69ep7n5PDhw3b77bfb6NGj7fPPP7f33nvPLrroIgsJCbGePXt6xjz88MPFvn8bNmxoDofD3n//fa/3b3HnMjN79tlnzel0Wps2baxXr14WFhZmkZGRJskeffRRa9Cggf3pT3/yZAD3e+6zzz6zdevWWUREhEVFRXlNiXZmXpg1a5aFhYXZ22+/bT/88IONGTPG6tSpY3v27CnyOYGKR7Yl25JtC5BtybZkW7It2ZZsS7b1f2Rbsi3ZtgDZlmxLtiXbkm3Jtv6ebWlUKMGQIUOsUaNGFhoaak2aNLEhQ4Z4rVvTp08fGzlypNeYjz/+2Fq2bGmhoaF26aWX2pw5c6q46rNzT3ly5tfIkSNt69atxb4myWuNr2bNmtmkSZM8P5/tXvnymszMXn75ZWvatKmFhIRYfHy8PfbYY0X+0D7z9/noo49aYmKihYeHW926dS05OdlmzZpVoXWXdK9nzpxpZgVrWPXu3dvq1atnYWFhlpiYaA899FCR9WpOH1Oc8gbeW2+91Zo1a2ahoaEWHR1tffv29YRdM7Pjx4/b3XffbXXr1rUaNWrYddddZ7t37y61xt27d9stt9xijRs3tvDwcGvVqpW9+OKL5nK5Kqy2871/FVXbmSGwrPfpXN+P53LuMxUXeMtz7uLON3HiRIuLi7P8/Pwi+w8ZMsQkWXBwsOczY9myZZ77HhYWZnXq1LGIiIhzfqZcLpc9/vjjFhYW5pnSLDY21uvzaNeuXTZw4ECLiYmxkJAQa9q0qQ0dOrTI9EpnHnvIkCGeP/hVOEWXew2283nO3J+ZwcHBJsmuv/56r8/MzZs32/XXX28xMTFWo0YNu+yyy+zdd981M7P/9//+n7Vt29YkWYMGDeyNN97wHL+4rzZt2timTZtKHWtm9uSTT5Z4jMmTJ1vbtm0tLCzMgoODvaaIOn78uF122WWeqeRCQkKsV69etmLFCs/5ihuXlZVl8fHxnpAbHBxsHTp0sBkzZnjGtG7d2urVq+f1541ZwbSLDofDQkNDrXXr1vbGG2+Ueq7+/ft7XU94eLgNHTrUcnNzvd6XTqfT4uPjbffu3TZ//vwS70d8fHyJn93ucY0bN/aqe9euXda1a1fPPTrz2Tv9fO7n5NixY9a7d28LCQnxvFa7dm27++677eDBg54xmzZtKtP7t7hzud9Dd999t+c95P69hISE2EUXXWSPPvqo5ebmejKA+z0XGxvrqfHMafPOzAtmZn/7298sPj7eQkNDrVu3bvbtt98aqgbZlmxLti1AtiXbkm3JtmRbsi3Z1v+Rbcm2ZNsCZFuyLdmWbEu2Jdv6e7Z1mJkJAAAAAAAAAAAAAACgCjjPvgsAAAAAAAAAAAAAAEDFoFEBAAAAAAAAAAAAAABUGRoVAAAAAAAAAAAAAABAlaFRAQAAAAAAAAAAAAAAVBkaFQAAAAAAAAAAAAAAQJWhUQEAAAAAAAAAAAAAAFQZGhUAAAAAAAAAAAAAAECVoVEBAAAAAAAAAAAAAABUGRoVACDAPfnkk4qNjZXD4dCnn356TmMWLVokh8OhAwcOVGpt1UlCQoKmTZvm6zIAAABQCrLtuSHbAgAAVH9k23NDtgUCF40KAKrcLbfcIofDIYfDodDQUCUmJurpp5/WqVOnfF3aWZUlNFYHP/74o5566im9/vrr2r17twYOHFhp57riiit03333VdrxAQAAqiOybdUh2wIAAFQusm3VIdsCgBTs6wIAXJgGDBigmTNnKjc3V3PnztXYsWMVEhKiiRMnlvlY+fn5cjgccjrpvTpTZmamJOmaa66Rw+HwcTUAAACBiWxbNci2AAAAlY9sWzXItgDAjAoAfCQsLEwNGzZUs2bNdNdddyklJUWff/65JCk3N1cPPvigmjRpopo1ayopKUmLFi3yjH377bdVp04dff7552rTpo3CwsK0Y8cO5ebm6uGHH1ZcXJzCwsKUmJiot956yzPu+++/18CBAxUZGanY2FgNHz5ce/fu9bx+xRVX6J577tGf/vQn1atXTw0bNtSTTz7peT0hIUGSdN1118nhcHh+zszM1DXXXKPY2FhFRkaqa9eu+uKLL7yud/fu3Ro0aJAiIiLUvHlzffDBB0WmrDpw4IBuv/12RUdHq3bt2rryyiu1fv36Uu/jd999pyuvvFIRERGqX7++xowZoyNHjkgqmDps8ODBkiSn01lq4J07d65atmypiIgI/eY3v9G2bdu8Xv/ll1908803q0mTJqpRo4batWunDz/80PP6Lbfcoq+++kovv/yyp+t627Ztys/P12233abmzZsrIiJCrVq10ssvv1zqNbl/v6f79NNPvepfv369fvOb36hWrVqqXbu2OnfurFWrVnle/+abb9SrVy9FREQoLi5O99xzj44ePep5PTs7W4MHD/b8Pt5///1SawIAACgN2ZZsWxKyLQAA8DdkW7JtSci2ACoajQoAqoWIiAjl5eVJksaNG6dly5Zp1qxZ2rBhg2688UYNGDBA6enpnv2PHTumP//5z/rf//1f/fe//1VMTIxGjBihDz/8UH/961/1448/6vXXX1dkZKSkgjB55ZVXqmPHjlq1apVSU1OVlZWlm266yauOd955RzVr1tTy5cv1l7/8RU8//bQWLFggSVq5cqUkaebMmdq9e7fn5yNHjujqq69WWlqa1q5dqwEDBmjw4MHasWOH57gjRozQzz//rEWLFulf//qX3njjDWVnZ3ud+8Ybb1R2drbmzZun1atXq1OnTurbt6/27dtX7D07evSo+vfvr7p162rlypX65z//qS+++ELjxo2TJD344IOaOXOmpILAvXv37mKPs3PnTl1//fUaPHiw1q1bp9tvv10TJkzw2ufEiRPq3Lmz5syZo++//15jxozR8OHDtWLFCknSyy+/rOTkZI0ePdpzrri4OLlcLjVt2lT//Oc/9cMPP+iJJ57QI488oo8//rjYWs7VsGHD1LRpU61cuVKrV6/WhAkTFBISIqngf0AGDBigG264QRs2bNBHH32kb775xnNfpIKAvnPnTi1cuFD/93//p1dffbXI7wMAAOB8kW3JtmVBtgUAANUZ2ZZsWxZkWwBlYgBQxUaOHGnXXHONmZm5XC5bsGCBhYWF2YMPPmjbt2+3oKAg27Vrl9eYvn372sSJE83MbObMmSbJ1q1b53l906ZNJskWLFhQ7DmfeeYZ69evn9e2nTt3miTbtGmTmZn16dPHevbs6bVP165d7eGHH/b8LMk++eSTs17jpZdean/729/MzOzHH380SbZy5UrP6+np6SbJXnrpJTMzW7x4sdWuXdtOnDjhdZwWLVrY66+/Xuw53njjDatbt64dOXLEs23OnDnmdDptz549Zmb2ySef2Nk+6idOnGht2rTx2vbwww+bJNu/f3+J4wYNGmQPPPCA5+c+ffrYvffeW+q5zMzGjh1rN9xwQ4mvz5w506Kiory2nXkdtWrVsrfffrvY8bfddpuNGTPGa9vixYvN6XTa8ePHPc/KihUrPK+7f0fu3wcAAMC5ItuSbcm2AAAgUJBtybZkWwBVKbjSOyEAoBj//ve/FRkZqZMnT8rlcmno0KF68skntWjRIuXn56tly5Ze++fm5qp+/fqen0NDQ3XZZZd5fl63bp2CgoLUp0+fYs+3fv16LVy40NOpe7rMzEzP+U4/piQ1atTorB2bR44c0ZNPPqk5c+Zo9+7dOnXqlI4fP+7pzN20aZOCg4PVqVMnz5jExETVrVvXq74jR454XaMkHT9+3LNe2Zl+/PFHtW/fXjVr1vRs69Gjh1wulzZt2qTY2NhS6z79OElJSV7bkpOTvX7Oz8/X5MmT9fHHH2vXrl3Ky8tTbm6uatSocdbjv/LKK5oxY4Z27Nih48ePKy8vTx06dDin2koyfvx43X777frHP/6hlJQU3XjjjWrRooWkgnu5YcMGr2nBzEwul0tbt27V5s2bFRwcrM6dO3teb926dZFpywAAAM4V2ZZsWx5kWwAAUJ2Qbcm25UG2BVAWNCoA8Inf/OY3eu211xQaGqrGjRsrOLjg4+jIkSMKCgrS6tWrFRQU5DXm9LAaERHhtfZVREREqec7cuSIBg8erD//+c9FXmvUqJHne/c0VG4Oh0Mul6vUYz/44INasGCBXnjhBSUmJioiIkK///3vPVOinYsjR46oUaNGXmu6uVWHIPb888/r5Zdf1rRp09SuXTvVrFlT991331mvcdasWXrwwQf14osvKjk5WbVq1dLzzz+v5cuXlzjG6XTKzLy2nTx50uvnJ598UkOHDtWcOXM0b948TZo0SbNmzdJ1112nI0eO6I477tA999xT5Njx8fHavHlzGa4cAADg7Mi2Resj2xYg2wIAAH9Dti1aH9m2ANkWQEWjUQGAT9SsWVOJiYlFtnfs2FH5+fnKzs5Wr169zvl47dq1k8vl0ldffaWUlJQir3fq1En/+te/lJCQ4AnX5yMkJET5+fle25YsWaJbbrlF1113naSC8Lpt2zbP661atdKpU6e0du1aTzdoRkaG9u/f71Xfnj17FBwcrISEhHOq5ZJLLtHbb7+to0ePerpzlyxZIqfTqVatWp3zNV1yySX6/PPPvbZ9++23Ra7xmmuu0R//+EdJksvl0ubNm9WmTRvPPqGhocXem+7du+vuu+/2bCup09gtOjpahw8f9rqudevWFdmvZcuWatmype6//37dfPPNmjlzpq677jp16tRJP/zwQ7HPl1TQhXvq1CmtXr1aXbt2lVTQPX3gwIFS6wIAACgJ2ZZsWxKyLQAA8DdkW7JtSci2ACqa09cFAMDpWrZsqWHDhmnEiBGaPXu2tm7dqhUrVmjKlCmaM2dOieMSEhI0cuRI3Xrrrfr000+1detWLVq0SB9//LEkaezYsdq3b59uvvlmrVy5UpmZmZo/f75GjRpVJKSVJiEhQWlpadqzZ48nsF588cWaPXu21q1bp/Xr12vo0KFe3bytW7dWSkqKxowZoxUrVmjt2rUaM2aMV3dxSkqKkpOTde211+o///mPtm3bpqVLl+rRRx/VqlWriq1l2LBhCg8P18iRI/X9999r4cKF+p//+R8NHz78nKcPk6Q777xT6enpeuihh7Rp0yZ98MEHevvtt732ufjii7VgwQItXbpUP/74o+644w5lZWUVuTfLly/Xtm3btHfvXrlcLl188cVatWqV5s+fr82bN+vxxx/XypUrS60nKSlJNWrU0COPPKLMzMwi9Rw/flzjxo3TokWLtH37di1ZskQrV67UJZdcIkl6+OGHtXTpUo0bN07r1q1Tenq6PvvsM40bN05Swf+ADBgwQHfccYeWL1+u1atX6/bbbz9rdzcAAEBZkW3JtmRbAAAQKMi2ZFuyLYCKRqMCgGpn5syZGjFihB544AG1atVK1157rVauXKn4+PhSx7322mv6/e9/r7vvvlutW7fW6NGjdfToUUlS48aNtWTJEuXn56tfv35q166d7rvvPtWpU0dO57l/FL744otasGCB4uLi1LFjR0nS1KlTVbduXXXv3l2DBw9W//79vdY1k6R3331XsbGx6t27t6677jqNHj1atWrVUnh4uKSCqcrmzp2r3r17a9SoUWrZsqX+8Ic/aPv27SWG1xo1amj+/Pnat2+funbtqt///vfq27ev/v73v5/z9UgF02r961//0qeffqr27dtr+vTpmjx5stc+jz32mDp16qT+/fvriiuuUMOGDXXttdd67fPggw8qKChIbdq0UXR0tHbs2KE77rhD119/vYYMGaKkpCT98ssvXl26xalXr57ee+89zZ07V+3atdOHH36oJ5980vN6UFCQfvnlF40YMUItW7bUTTfdpIEDB+qpp56SVLBe3VdffaXNmzerV69e6tixo5544gk1btzYc4yZM2eqcePG6tOnj66//nqNGTNGMTExZbpvAAAA54JsS7Yl2wIAgEBBtiXbkm0BVCSHnbmgDACg0v3000+Ki4vTF198ob59+/q6HAAAAOC8kW0BAAAQKMi2AFB1aFQAgCrw5Zdf6siRI2rXrp12796tP/3pT9q1a5c2b96skJAQX5cHAAAAnDOyLQAAAAIF2RYAfCfY1wUAwIXg5MmTeuSRR7RlyxbVqlVL3bt31/vvv0/YBQAAgN8h2wIAACBQkG0BwHeYUQEAAAAAAAAAAAAAAFQZp68LAAAAAAAAAAAAAAAAFw4aFQAAAAAAAAAAAAAAQJWhUQEAAAAAAAAAAAAAAFQZGhUAAAAAAAAAAAAAAECVoVEBAAAAAAAAAAAAAABUGRoVAAAAAAAAAAAAAABAlaFRAQAAAAAAAAAAAAAAVBkaFQAAAAAAAAAAAAAAQJWhUQEAAAAAAAAAAAAAAFSZ/w9wJkNP6N/HqQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f0414f",
   "metadata": {
    "papermill": {
     "duration": 0.011443,
     "end_time": "2025-03-31T04:28:08.499292",
     "exception": false,
     "start_time": "2025-03-31T04:28:08.487849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b6f32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 4\n",
      "Random seed: 3\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6072, Accuracy: 0.7955, F1 Micro: 0.8818, F1 Macro: 0.8546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4916, Accuracy: 0.8016, F1 Micro: 0.8877, F1 Macro: 0.8774\n",
      "Epoch 3/10, Train Loss: 0.453, Accuracy: 0.8024, F1 Micro: 0.8857, F1 Macro: 0.8609\n",
      "Epoch 4/10, Train Loss: 0.4515, Accuracy: 0.8021, F1 Micro: 0.8849, F1 Macro: 0.8543\n",
      "Epoch 5/10, Train Loss: 0.417, Accuracy: 0.8047, F1 Micro: 0.8868, F1 Macro: 0.862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4402, Accuracy: 0.8092, F1 Micro: 0.8902, F1 Macro: 0.874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3799, Accuracy: 0.8141, F1 Micro: 0.8937, F1 Macro: 0.8828\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3851, Accuracy: 0.8252, F1 Micro: 0.899, F1 Macro: 0.8873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3532, Accuracy: 0.8361, F1 Micro: 0.9044, F1 Macro: 0.8918\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3254, Accuracy: 0.8502, F1 Micro: 0.9121, F1 Macro: 0.9018\n",
      "\n",
      "Aspect detection accuracy: 0.8502, F1 Micro: 0.9121, F1 Macro: 0.9018\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.86      1.00      0.93       462\n",
      "   air_panas       0.90      0.99      0.94       480\n",
      "         bau       0.87      1.00      0.93       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.77      0.66      0.71       317\n",
      "       linen       0.74      0.98      0.84       392\n",
      "     service       0.82      0.98      0.89       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.90      1.00      0.95       516\n",
      "        wifi       0.89      1.00      0.94       498\n",
      "\n",
      "   micro avg       0.86      0.97      0.91      4614\n",
      "   macro avg       0.85      0.96      0.90      4614\n",
      "weighted avg       0.86      0.97      0.91      4614\n",
      " samples avg       0.86      0.97      0.91      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5988, Accuracy: 0.6204, F1 Micro: 0.6204, F1 Macro: 0.3829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.5281, Accuracy: 0.6204, F1 Micro: 0.6204, F1 Macro: 0.3829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4888, Accuracy: 0.6259, F1 Micro: 0.6259, F1 Macro: 0.4027\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3707, Accuracy: 0.6861, F1 Micro: 0.6861, F1 Macro: 0.5752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3492, Accuracy: 0.7336, F1 Micro: 0.7336, F1 Macro: 0.6917\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2739, Accuracy: 0.7372, F1 Micro: 0.7372, F1 Macro: 0.7005\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.3739, Accuracy: 0.7409, F1 Micro: 0.7409, F1 Macro: 0.7103\n",
      "Epoch 8/10, Train Loss: 0.2974, Accuracy: 0.7281, F1 Micro: 0.7281, F1 Macro: 0.6718\n",
      "Epoch 9/10, Train Loss: 0.18, Accuracy: 0.7372, F1 Micro: 0.7372, F1 Macro: 0.703\n",
      "Epoch 10/10, Train Loss: 0.1429, Accuracy: 0.7281, F1 Micro: 0.7281, F1 Macro: 0.6706\n",
      "\n",
      "Sentiment analysis accuracy: 0.7409, F1 Micro: 0.7409, F1 Macro: 0.7103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.86      0.80       340\n",
      "    positive       0.70      0.55      0.62       208\n",
      "\n",
      "    accuracy                           0.74       548\n",
      "   macro avg       0.73      0.70      0.71       548\n",
      "weighted avg       0.74      0.74      0.73       548\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 142: Accuracy: 0.8385, F1 Micro: 0.8385, F1 Macro: 0.4347\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.36      0.51        97\n",
      "     neutral       0.87      1.00      0.93       459\n",
      "    positive       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.86       571\n",
      "   macro avg       0.58      0.45      0.48       571\n",
      "weighted avg       0.84      0.86      0.83       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.43      0.56        86\n",
      "     neutral       0.90      0.99      0.94       475\n",
      "    positive       0.20      0.10      0.13        10\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.63      0.51      0.54       571\n",
      "weighted avg       0.87      0.89      0.87       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.12      0.20        78\n",
      "     neutral       0.87      1.00      0.93       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.59      0.37      0.38       571\n",
      "weighted avg       0.87      0.87      0.83       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.65      0.65       200\n",
      "     neutral       0.77      0.66      0.71       315\n",
      "    positive       0.26      0.48      0.34        56\n",
      "\n",
      "    accuracy                           0.64       571\n",
      "   macro avg       0.56      0.60      0.57       571\n",
      "weighted avg       0.68      0.64      0.65       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.30      0.44       162\n",
      "     neutral       0.74      0.98      0.84       387\n",
      "    positive       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.75       571\n",
      "   macro avg       0.53      0.43      0.43       571\n",
      "weighted avg       0.74      0.75      0.70       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.18      0.29        85\n",
      "     neutral       0.81      0.98      0.89       418\n",
      "    positive       0.60      0.44      0.51        68\n",
      "\n",
      "    accuracy                           0.80       571\n",
      "   macro avg       0.77      0.53      0.56       571\n",
      "weighted avg       0.80      0.80      0.76       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.89      1.00      0.94       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.30      0.33      0.31       571\n",
      "weighted avg       0.80      0.89      0.85       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.24      0.39        74\n",
      "     neutral       0.89      1.00      0.94       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.61      0.41      0.44       571\n",
      "weighted avg       0.90      0.89      0.87       571\n",
      "\n",
      "Total train time: 78.56739616394043 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 215\n",
      "Sampling duration: 59.98522114753723 seconds\n",
      "New train size: 357\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5314, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4493, Accuracy: 0.8023, F1 Micro: 0.89, F1 Macro: 0.8855\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4553, Accuracy: 0.8023, F1 Micro: 0.8901, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4105, Accuracy: 0.8292, F1 Micro: 0.9024, F1 Macro: 0.8957\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3713, Accuracy: 0.8648, F1 Micro: 0.9209, F1 Macro: 0.9151\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3131, Accuracy: 0.8901, F1 Micro: 0.9349, F1 Macro: 0.9299\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2667, Accuracy: 0.9007, F1 Micro: 0.941, F1 Macro: 0.9373\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.2209, Accuracy: 0.9184, F1 Micro: 0.9508, F1 Macro: 0.9472\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1989, Accuracy: 0.9191, F1 Micro: 0.9515, F1 Macro: 0.9482\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1805, Accuracy: 0.925, F1 Micro: 0.9546, F1 Macro: 0.9513\n",
      "\n",
      "Aspect detection accuracy: 0.925, F1 Micro: 0.9546, F1 Macro: 0.9513\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.97      0.99      0.98       462\n",
      "   air_panas       0.93      0.99      0.96       480\n",
      "         bau       0.94      0.99      0.96       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.82      0.93      0.87       317\n",
      "       linen       0.88      0.95      0.91       392\n",
      "     service       0.94      0.96      0.95       423\n",
      "sunrise_meal       0.94      1.00      0.97       530\n",
      "          tv       0.96      1.00      0.98       516\n",
      "        wifi       0.98      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.93      0.98      0.95      4614\n",
      "   macro avg       0.92      0.98      0.95      4614\n",
      "weighted avg       0.93      0.98      0.96      4614\n",
      " samples avg       0.93      0.98      0.95      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5184, Accuracy: 0.7526, F1 Micro: 0.7526, F1 Macro: 0.4294\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3482, Accuracy: 0.8077, F1 Micro: 0.8077, F1 Macro: 0.7113\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2982, Accuracy: 0.8288, F1 Micro: 0.8288, F1 Macro: 0.7591\n",
      "Epoch 4/10, Train Loss: 0.2482, Accuracy: 0.8195, F1 Micro: 0.8195, F1 Macro: 0.7669\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2206, Accuracy: 0.8593, F1 Micro: 0.8593, F1 Macro: 0.7991\n",
      "Epoch 6/10, Train Loss: 0.1836, Accuracy: 0.8558, F1 Micro: 0.8558, F1 Macro: 0.7882\n",
      "Epoch 7/10, Train Loss: 0.1881, Accuracy: 0.8535, F1 Micro: 0.8535, F1 Macro: 0.7719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.137, Accuracy: 0.8652, F1 Micro: 0.8652, F1 Macro: 0.7929\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.14, Accuracy: 0.8722, F1 Micro: 0.8722, F1 Macro: 0.8217\n",
      "Epoch 10/10, Train Loss: 0.1166, Accuracy: 0.864, F1 Micro: 0.864, F1 Macro: 0.7841\n",
      "\n",
      "Sentiment analysis accuracy: 0.8722, F1 Micro: 0.8722, F1 Macro: 0.8217\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.93      0.92       642\n",
      "    positive       0.77      0.69      0.73       211\n",
      "\n",
      "    accuracy                           0.87       853\n",
      "   macro avg       0.84      0.81      0.82       853\n",
      "weighted avg       0.87      0.87      0.87       853\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 357: Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.6922\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        97\n",
      "     neutral       0.97      0.99      0.98       459\n",
      "    positive       0.88      0.47      0.61        15\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.92      0.79      0.83       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.59      0.72        86\n",
      "     neutral       0.93      0.99      0.96       475\n",
      "    positive       0.57      0.40      0.47        10\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.80      0.66      0.72       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.64      0.75        78\n",
      "     neutral       0.94      0.99      0.96       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.54      0.57       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.69      0.78       200\n",
      "     neutral       0.82      0.93      0.87       315\n",
      "    positive       0.64      0.70      0.67        56\n",
      "\n",
      "    accuracy                           0.82       571\n",
      "   macro avg       0.79      0.77      0.77       571\n",
      "weighted avg       0.83      0.82      0.82       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.69      0.76       162\n",
      "     neutral       0.88      0.95      0.91       387\n",
      "    positive       0.36      0.36      0.36        22\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.70      0.67      0.68       571\n",
      "weighted avg       0.85      0.85      0.85       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.72      0.78        85\n",
      "     neutral       0.94      0.96      0.95       418\n",
      "    positive       0.75      0.81      0.78        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.85      0.83      0.84       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.24        29\n",
      "     neutral       0.94      1.00      0.97       525\n",
      "    positive       0.62      0.29      0.40        17\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.85      0.48      0.54       571\n",
      "weighted avg       0.93      0.93      0.91       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.63      0.76        54\n",
      "     neutral       0.96      1.00      0.98       511\n",
      "    positive       0.75      0.50      0.60         6\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.89      0.71      0.78       571\n",
      "weighted avg       0.96      0.96      0.95       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.85      0.91        74\n",
      "     neutral       0.98      1.00      0.99       494\n",
      "    positive       0.60      1.00      0.75         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.85      0.95      0.88       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 114.57423949241638 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 193\n",
      "Sampling duration: 69.82255792617798 seconds\n",
      "New train size: 550\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5258, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4572, Accuracy: 0.8057, F1 Micro: 0.8916, F1 Macro: 0.8865\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4114, Accuracy: 0.8365, F1 Micro: 0.9052, F1 Macro: 0.8971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3594, Accuracy: 0.8724, F1 Micro: 0.9254, F1 Macro: 0.9208\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2928, Accuracy: 0.9137, F1 Micro: 0.9481, F1 Macro: 0.944\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2578, Accuracy: 0.9365, F1 Micro: 0.9611, F1 Macro: 0.9582\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2054, Accuracy: 0.9365, F1 Micro: 0.9613, F1 Macro: 0.9585\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.181, Accuracy: 0.9399, F1 Micro: 0.9632, F1 Macro: 0.9604\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1603, Accuracy: 0.9427, F1 Micro: 0.9649, F1 Macro: 0.9622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1423, Accuracy: 0.9479, F1 Micro: 0.968, F1 Macro: 0.9652\n",
      "\n",
      "Aspect detection accuracy: 0.9479, F1 Micro: 0.968, F1 Macro: 0.9652\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.96      0.97      0.97       496\n",
      "     general       0.90      0.99      0.94       500\n",
      "  kebersihan       0.90      0.92      0.91       317\n",
      "       linen       0.89      0.96      0.93       392\n",
      "     service       0.96      0.97      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.95      0.98      0.97      4614\n",
      "   macro avg       0.95      0.98      0.97      4614\n",
      "weighted avg       0.95      0.98      0.97      4614\n",
      " samples avg       0.95      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5244, Accuracy: 0.7766, F1 Micro: 0.7766, F1 Macro: 0.6806\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3685, Accuracy: 0.8297, F1 Micro: 0.8297, F1 Macro: 0.753\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3074, Accuracy: 0.8567, F1 Micro: 0.8567, F1 Macro: 0.8095\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2486, Accuracy: 0.8617, F1 Micro: 0.8617, F1 Macro: 0.8096\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.208, Accuracy: 0.8758, F1 Micro: 0.8758, F1 Macro: 0.8269\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1544, Accuracy: 0.8828, F1 Micro: 0.8828, F1 Macro: 0.8393\n",
      "Epoch 7/10, Train Loss: 0.1157, Accuracy: 0.8818, F1 Micro: 0.8818, F1 Macro: 0.8285\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0961, Accuracy: 0.8938, F1 Micro: 0.8938, F1 Macro: 0.8622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0706, Accuracy: 0.8978, F1 Micro: 0.8978, F1 Macro: 0.8605\n",
      "Epoch 10/10, Train Loss: 0.0446, Accuracy: 0.8918, F1 Micro: 0.8918, F1 Macro: 0.8527\n",
      "\n",
      "Sentiment analysis accuracy: 0.8978, F1 Micro: 0.8978, F1 Macro: 0.8605\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93       726\n",
      "    positive       0.90      0.70      0.79       272\n",
      "\n",
      "    accuracy                           0.90       998\n",
      "   macro avg       0.90      0.84      0.86       998\n",
      "weighted avg       0.90      0.90      0.89       998\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 550: Accuracy: 0.9413, F1 Micro: 0.9413, F1 Macro: 0.7828\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.81      0.86        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.57      0.40      0.47        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.82      0.74      0.77       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.76      0.78        78\n",
      "     neutral       0.96      0.97      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.58      0.58       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.90      0.99      0.94       496\n",
      "    positive       0.81      0.31      0.45        68\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.57      0.43      0.46       571\n",
      "weighted avg       0.88      0.90      0.87       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.81      0.84       200\n",
      "     neutral       0.90      0.92      0.91       315\n",
      "    positive       0.83      0.93      0.87        56\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.87      0.89      0.87       571\n",
      "weighted avg       0.88      0.88      0.88       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.79      0.84       162\n",
      "     neutral       0.89      0.97      0.93       387\n",
      "    positive       0.75      0.27      0.40        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.84      0.68      0.72       571\n",
      "weighted avg       0.89      0.89      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.76      0.80        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.88      0.88      0.88        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.89      0.87      0.88       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.34      0.49        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.87      0.70      0.75       571\n",
      "weighted avg       0.95      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.99      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.88      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 144.8350329399109 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 174\n",
      "Sampling duration: 63.90232062339783 seconds\n",
      "New train size: 724\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5024, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4555, Accuracy: 0.8339, F1 Micro: 0.9052, F1 Macro: 0.8998\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3845, Accuracy: 0.8776, F1 Micro: 0.928, F1 Macro: 0.923\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3034, Accuracy: 0.9139, F1 Micro: 0.9482, F1 Macro: 0.9445\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2441, Accuracy: 0.9333, F1 Micro: 0.9595, F1 Macro: 0.9568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2043, Accuracy: 0.9392, F1 Micro: 0.9628, F1 Macro: 0.9602\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1699, Accuracy: 0.9457, F1 Micro: 0.9667, F1 Macro: 0.9643\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1516, Accuracy: 0.9488, F1 Micro: 0.9686, F1 Macro: 0.9662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1296, Accuracy: 0.9512, F1 Micro: 0.97, F1 Macro: 0.9675\n",
      "Epoch 10/10, Train Loss: 0.1185, Accuracy: 0.949, F1 Micro: 0.9686, F1 Macro: 0.9658\n",
      "\n",
      "Aspect detection accuracy: 0.9512, F1 Micro: 0.97, F1 Macro: 0.9675\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.91      0.99      0.95       500\n",
      "  kebersihan       0.89      0.95      0.92       317\n",
      "       linen       0.91      0.96      0.94       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.95      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5085, Accuracy: 0.7966, F1 Micro: 0.7966, F1 Macro: 0.7445\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3699, Accuracy: 0.8554, F1 Micro: 0.8554, F1 Macro: 0.7988\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2921, Accuracy: 0.8584, F1 Micro: 0.8584, F1 Macro: 0.7985\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2265, Accuracy: 0.8903, F1 Micro: 0.8903, F1 Macro: 0.8572\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.181, Accuracy: 0.8973, F1 Micro: 0.8973, F1 Macro: 0.8644\n",
      "Epoch 6/10, Train Loss: 0.1058, Accuracy: 0.8933, F1 Micro: 0.8933, F1 Macro: 0.8602\n",
      "Epoch 7/10, Train Loss: 0.0917, Accuracy: 0.8953, F1 Micro: 0.8953, F1 Macro: 0.8628\n",
      "Epoch 8/10, Train Loss: 0.1032, Accuracy: 0.8953, F1 Micro: 0.8953, F1 Macro: 0.8642\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0638, Accuracy: 0.8993, F1 Micro: 0.8993, F1 Macro: 0.8631\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.055, Accuracy: 0.9003, F1 Micro: 0.9003, F1 Macro: 0.8635\n",
      "\n",
      "Sentiment analysis accuracy: 0.9003, F1 Micro: 0.9003, F1 Macro: 0.8635\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93       726\n",
      "    positive       0.93      0.69      0.79       277\n",
      "\n",
      "    accuracy                           0.90      1003\n",
      "   macro avg       0.91      0.84      0.86      1003\n",
      "weighted avg       0.90      0.90      0.90      1003\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 724: Accuracy: 0.9438, F1 Micro: 0.9438, F1 Macro: 0.7992\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.91      0.94        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.80      0.85        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.87      0.80      0.83       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.74      0.78        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.57      0.58       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.91      0.99      0.95       496\n",
      "    positive       0.82      0.41      0.55        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.58      0.47      0.50       571\n",
      "weighted avg       0.89      0.91      0.89       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.81      0.85       200\n",
      "     neutral       0.88      0.95      0.92       315\n",
      "    positive       0.87      0.86      0.86        56\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.89      0.87      0.88       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.81      0.84       162\n",
      "     neutral       0.91      0.96      0.94       387\n",
      "    positive       0.67      0.36      0.47        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.81      0.71      0.75       571\n",
      "weighted avg       0.89      0.89      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.95      0.81      0.87        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.91      0.87      0.89       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.52      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.80      0.71      0.75        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.74      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.92      0.94        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.98      0.86      0.91       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 157.83809447288513 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 156\n",
      "Sampling duration: 59.26169419288635 seconds\n",
      "New train size: 880\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5067, Accuracy: 0.8012, F1 Micro: 0.8842, F1 Macro: 0.8509\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4547, Accuracy: 0.8349, F1 Micro: 0.9057, F1 Macro: 0.8999\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3639, Accuracy: 0.9078, F1 Micro: 0.9444, F1 Macro: 0.9383\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.282, Accuracy: 0.929, F1 Micro: 0.957, F1 Macro: 0.9539\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2209, Accuracy: 0.9425, F1 Micro: 0.9648, F1 Macro: 0.9618\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1897, Accuracy: 0.9455, F1 Micro: 0.9666, F1 Macro: 0.9641\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1602, Accuracy: 0.9493, F1 Micro: 0.9689, F1 Macro: 0.9665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1377, Accuracy: 0.9528, F1 Micro: 0.9709, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1227, Accuracy: 0.955, F1 Micro: 0.9723, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1025, Accuracy: 0.9557, F1 Micro: 0.9727, F1 Macro: 0.9704\n",
      "\n",
      "Aspect detection accuracy: 0.9557, F1 Micro: 0.9727, F1 Macro: 0.9704\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.95      0.98      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.92      0.94      0.93       317\n",
      "       linen       0.88      0.98      0.93       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.99      0.97      4614\n",
      " samples avg       0.96      0.99      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4888, Accuracy: 0.8476, F1 Micro: 0.8476, F1 Macro: 0.7948\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3273, Accuracy: 0.883, F1 Micro: 0.883, F1 Macro: 0.8416\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2405, Accuracy: 0.8948, F1 Micro: 0.8948, F1 Macro: 0.8609\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1893, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1909, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8913\n",
      "Epoch 6/10, Train Loss: 0.146, Accuracy: 0.9086, F1 Micro: 0.9086, F1 Macro: 0.8772\n",
      "Epoch 7/10, Train Loss: 0.0679, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.8869\n",
      "Epoch 8/10, Train Loss: 0.0746, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0375, Accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8878\n",
      "Epoch 10/10, Train Loss: 0.0359, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8866\n",
      "\n",
      "Sentiment analysis accuracy: 0.9154, F1 Micro: 0.9154, F1 Macro: 0.8878\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       734\n",
      "    positive       0.93      0.75      0.83       283\n",
      "\n",
      "    accuracy                           0.92      1017\n",
      "   macro avg       0.92      0.87      0.89      1017\n",
      "weighted avg       0.92      0.92      0.91      1017\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 880: Accuracy: 0.9494, F1 Micro: 0.9494, F1 Macro: 0.8347\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.97      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.87      0.90        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.86      0.82      0.84       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.72      0.78        78\n",
      "     neutral       0.95      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.73      0.81       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.88      0.62      0.72        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.94      0.58      0.65       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.87      0.89       200\n",
      "     neutral       0.92      0.94      0.93       315\n",
      "    positive       0.88      0.91      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.91      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.73      0.81       162\n",
      "     neutral       0.88      0.98      0.93       387\n",
      "    positive       0.60      0.27      0.37        22\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.79      0.66      0.70       571\n",
      "weighted avg       0.88      0.88      0.87       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.79      0.82        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.89      0.85      0.87        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.87      0.89       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.52      0.64        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.87      0.76      0.81        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.89      0.76      0.81       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.95      0.95        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.87      0.87      0.87       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 179.86133551597595 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 141\n",
      "Sampling duration: 54.24267554283142 seconds\n",
      "New train size: 1021\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4927, Accuracy: 0.8052, F1 Micro: 0.8914, F1 Macro: 0.8867\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4399, Accuracy: 0.8752, F1 Micro: 0.9264, F1 Macro: 0.9207\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3252, Accuracy: 0.9233, F1 Micro: 0.9535, F1 Macro: 0.9495\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2414, Accuracy: 0.9398, F1 Micro: 0.9632, F1 Macro: 0.9605\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2047, Accuracy: 0.9479, F1 Micro: 0.9681, F1 Macro: 0.9659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1714, Accuracy: 0.9547, F1 Micro: 0.972, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1513, Accuracy: 0.9554, F1 Micro: 0.9724, F1 Macro: 0.97\n",
      "Epoch 8/10, Train Loss: 0.1222, Accuracy: 0.955, F1 Micro: 0.9722, F1 Macro: 0.9698\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1096, Accuracy: 0.9594, F1 Micro: 0.9749, F1 Macro: 0.9724\n",
      "Epoch 10/10, Train Loss: 0.0937, Accuracy: 0.9592, F1 Micro: 0.9748, F1 Macro: 0.9725\n",
      "\n",
      "Aspect detection accuracy: 0.9594, F1 Micro: 0.9749, F1 Macro: 0.9724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.90      0.95      0.93       317\n",
      "       linen       0.91      0.96      0.93       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4763, Accuracy: 0.8248, F1 Micro: 0.8248, F1 Macro: 0.7799\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3258, Accuracy: 0.8665, F1 Micro: 0.8665, F1 Macro: 0.8185\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.25, Accuracy: 0.893, F1 Micro: 0.893, F1 Macro: 0.8653\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1765, Accuracy: 0.9025, F1 Micro: 0.9025, F1 Macro: 0.875\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1322, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8798\n",
      "Epoch 6/10, Train Loss: 0.0834, Accuracy: 0.9025, F1 Micro: 0.9025, F1 Macro: 0.8717\n",
      "Epoch 7/10, Train Loss: 0.0737, Accuracy: 0.9053, F1 Micro: 0.9053, F1 Macro: 0.8756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0514, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8785\n",
      "Epoch 9/10, Train Loss: 0.0573, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.8733\n",
      "Epoch 10/10, Train Loss: 0.0348, Accuracy: 0.9025, F1 Micro: 0.9025, F1 Macro: 0.8729\n",
      "\n",
      "Sentiment analysis accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.94       753\n",
      "    positive       0.91      0.75      0.82       303\n",
      "\n",
      "    accuracy                           0.91      1056\n",
      "   macro avg       0.91      0.86      0.88      1056\n",
      "weighted avg       0.91      0.91      0.90      1056\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1021: Accuracy: 0.9522, F1 Micro: 0.9522, F1 Macro: 0.8468\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.79      0.81       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.79      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.90      0.69      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.78      0.61      0.66       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.83      0.88       200\n",
      "     neutral       0.90      0.95      0.93       315\n",
      "    positive       0.88      0.91      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.90      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.78      0.83       162\n",
      "     neutral       0.91      0.96      0.93       387\n",
      "    positive       0.53      0.36      0.43        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.77      0.70      0.73       571\n",
      "weighted avg       0.88      0.89      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.86      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.90      0.90      0.90        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.91      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.82      0.76        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.90      0.98      0.93       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 193.63911366462708 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 127\n",
      "Sampling duration: 48.475794553756714 seconds\n",
      "New train size: 1148\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.494, Accuracy: 0.8149, F1 Micro: 0.894, F1 Macro: 0.8831\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4018, Accuracy: 0.8932, F1 Micro: 0.9367, F1 Macro: 0.9324\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2896, Accuracy: 0.9349, F1 Micro: 0.9604, F1 Macro: 0.9574\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2261, Accuracy: 0.9413, F1 Micro: 0.9641, F1 Macro: 0.9615\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1924, Accuracy: 0.9497, F1 Micro: 0.969, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1629, Accuracy: 0.951, F1 Micro: 0.9699, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1368, Accuracy: 0.9564, F1 Micro: 0.973, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1183, Accuracy: 0.9585, F1 Micro: 0.9743, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1002, Accuracy: 0.959, F1 Micro: 0.9746, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0847, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9737\n",
      "\n",
      "Aspect detection accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.96      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.93      0.93       317\n",
      "       linen       0.91      0.98      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4834, Accuracy: 0.8221, F1 Micro: 0.8221, F1 Macro: 0.7901\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3155, Accuracy: 0.8664, F1 Micro: 0.8664, F1 Macro: 0.8296\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2431, Accuracy: 0.8922, F1 Micro: 0.8922, F1 Macro: 0.8594\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1603, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8789\n",
      "Epoch 5/10, Train Loss: 0.1159, Accuracy: 0.8876, F1 Micro: 0.8876, F1 Macro: 0.8489\n",
      "Epoch 6/10, Train Loss: 0.0941, Accuracy: 0.9032, F1 Micro: 0.9032, F1 Macro: 0.8732\n",
      "Epoch 7/10, Train Loss: 0.0731, Accuracy: 0.8995, F1 Micro: 0.8995, F1 Macro: 0.8702\n",
      "Epoch 8/10, Train Loss: 0.0496, Accuracy: 0.9032, F1 Micro: 0.9032, F1 Macro: 0.8749\n",
      "Epoch 9/10, Train Loss: 0.051, Accuracy: 0.894, F1 Micro: 0.894, F1 Macro: 0.866\n",
      "Epoch 10/10, Train Loss: 0.0581, Accuracy: 0.9023, F1 Micro: 0.9023, F1 Macro: 0.8753\n",
      "\n",
      "Sentiment analysis accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.94       769\n",
      "    positive       0.92      0.74      0.82       316\n",
      "\n",
      "    accuracy                           0.91      1085\n",
      "   macro avg       0.91      0.86      0.88      1085\n",
      "weighted avg       0.91      0.91      0.90      1085\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1148: Accuracy: 0.9546, F1 Micro: 0.9546, F1 Macro: 0.8497\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.95      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.87      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.83      0.80        78\n",
      "     neutral       0.97      0.96      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.95      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.83      0.71      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.56      0.58       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.91       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.81      0.85       162\n",
      "     neutral       0.91      0.98      0.94       387\n",
      "    positive       0.73      0.36      0.48        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.85      0.72      0.76       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.87      0.87        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.52      0.64        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.67      0.82      0.74        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.78      0.79       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.95      0.96        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.98      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 208.29386591911316 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 114\n",
      "Sampling duration: 44.16385054588318 seconds\n",
      "New train size: 1262\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4933, Accuracy: 0.803, F1 Micro: 0.8905, F1 Macro: 0.886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.388, Accuracy: 0.9014, F1 Micro: 0.9412, F1 Macro: 0.9366\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2745, Accuracy: 0.9424, F1 Micro: 0.9645, F1 Macro: 0.9615\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2153, Accuracy: 0.9451, F1 Micro: 0.9664, F1 Macro: 0.9639\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1796, Accuracy: 0.95, F1 Micro: 0.9693, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.155, Accuracy: 0.9531, F1 Micro: 0.9711, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1304, Accuracy: 0.9563, F1 Micro: 0.9729, F1 Macro: 0.9705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1138, Accuracy: 0.9582, F1 Micro: 0.9742, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0944, Accuracy: 0.9585, F1 Micro: 0.9743, F1 Macro: 0.9719\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0817, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9734\n",
      "\n",
      "Aspect detection accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9734\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.92      0.95      0.94       317\n",
      "       linen       0.90      0.98      0.94       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4476, Accuracy: 0.8598, F1 Micro: 0.8598, F1 Macro: 0.8084\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3013, Accuracy: 0.8847, F1 Micro: 0.8847, F1 Macro: 0.8438\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2117, Accuracy: 0.9001, F1 Micro: 0.9001, F1 Macro: 0.8624\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1573, Accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8858\n",
      "Epoch 5/10, Train Loss: 0.1236, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8791\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0902, Accuracy: 0.9155, F1 Micro: 0.9155, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0795, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.892\n",
      "Epoch 8/10, Train Loss: 0.0556, Accuracy: 0.9145, F1 Micro: 0.9145, F1 Macro: 0.8858\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0434, Accuracy: 0.9183, F1 Micro: 0.9183, F1 Macro: 0.8909\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0455, Accuracy: 0.9203, F1 Micro: 0.9203, F1 Macro: 0.8932\n",
      "\n",
      "Sentiment analysis accuracy: 0.9203, F1 Micro: 0.9203, F1 Macro: 0.8932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       753\n",
      "    positive       0.95      0.75      0.84       288\n",
      "\n",
      "    accuracy                           0.92      1041\n",
      "   macro avg       0.93      0.87      0.89      1041\n",
      "weighted avg       0.92      0.92      0.92      1041\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1262: Accuracy: 0.9548, F1 Micro: 0.9548, F1 Macro: 0.8506\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.88      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.82      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.91      0.60      0.73        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.62      0.53      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89       200\n",
      "     neutral       0.92      0.95      0.94       315\n",
      "    positive       0.90      0.95      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.79      0.85       162\n",
      "     neutral       0.90      0.98      0.94       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.88      0.74      0.79       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.82      0.86        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.92      0.90      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.90      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.59      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.85      0.65      0.73        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.85      0.74      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 224.34782576560974 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 103\n",
      "Sampling duration: 40.19046139717102 seconds\n",
      "New train size: 1365\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4848, Accuracy: 0.8148, F1 Micro: 0.8958, F1 Macro: 0.8903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3706, Accuracy: 0.9122, F1 Micro: 0.947, F1 Macro: 0.9429\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2601, Accuracy: 0.9439, F1 Micro: 0.9655, F1 Macro: 0.9629\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2106, Accuracy: 0.9472, F1 Micro: 0.9677, F1 Macro: 0.9654\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1686, Accuracy: 0.9516, F1 Micro: 0.9703, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1412, Accuracy: 0.9559, F1 Micro: 0.9727, F1 Macro: 0.9704\n",
      "Epoch 7/10, Train Loss: 0.121, Accuracy: 0.9547, F1 Micro: 0.9721, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1038, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.088, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0795, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9747\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9747\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.89      0.98      0.93       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.99      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4364, Accuracy: 0.8748, F1 Micro: 0.8748, F1 Macro: 0.8315\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2883, Accuracy: 0.8937, F1 Micro: 0.8937, F1 Macro: 0.8589\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2005, Accuracy: 0.8956, F1 Micro: 0.8956, F1 Macro: 0.8589\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1652, Accuracy: 0.9156, F1 Micro: 0.9156, F1 Macro: 0.8896\n",
      "Epoch 5/10, Train Loss: 0.1082, Accuracy: 0.9118, F1 Micro: 0.9118, F1 Macro: 0.8824\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0814, Accuracy: 0.9175, F1 Micro: 0.9175, F1 Macro: 0.8905\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0647, Accuracy: 0.9203, F1 Micro: 0.9203, F1 Macro: 0.8952\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0594, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.8993\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0514, Accuracy: 0.9231, F1 Micro: 0.9231, F1 Macro: 0.9\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.05, Accuracy: 0.925, F1 Micro: 0.925, F1 Macro: 0.9025\n",
      "\n",
      "Sentiment analysis accuracy: 0.925, F1 Micro: 0.925, F1 Macro: 0.9025\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.97      0.95       760\n",
      "    positive       0.92      0.80      0.86       294\n",
      "\n",
      "    accuracy                           0.93      1054\n",
      "   macro avg       0.92      0.89      0.90      1054\n",
      "weighted avg       0.93      0.93      0.92      1054\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1365: Accuracy: 0.9573, F1 Micro: 0.9573, F1 Macro: 0.8551\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.87      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.75      0.60      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.82      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.79      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       0.33      0.50      0.40         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.72      0.76      0.73       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.75      0.80        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.63      0.67       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       200\n",
      "     neutral       0.93      0.94      0.94       315\n",
      "    positive       0.88      0.91      0.89        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.91      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.77      0.84       162\n",
      "     neutral       0.89      0.98      0.93       387\n",
      "    positive       0.88      0.32      0.47        22\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.89      0.69      0.74       571\n",
      "weighted avg       0.90      0.89      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.84      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.67      0.82      0.74        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.78      0.79       571\n",
      "weighted avg       0.97      0.97      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 243.51437830924988 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 62\n",
      "Sampling duration: 36.69153332710266 seconds\n",
      "New train size: 1427\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4927, Accuracy: 0.8243, F1 Micro: 0.9001, F1 Macro: 0.8939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.359, Accuracy: 0.9214, F1 Micro: 0.9522, F1 Macro: 0.9474\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.244, Accuracy: 0.9425, F1 Micro: 0.9648, F1 Macro: 0.9619\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1985, Accuracy: 0.9495, F1 Micro: 0.969, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1643, Accuracy: 0.9507, F1 Micro: 0.9697, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1395, Accuracy: 0.9569, F1 Micro: 0.9733, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1183, Accuracy: 0.9618, F1 Micro: 0.9764, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0964, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9744\n",
      "Epoch 9/10, Train Loss: 0.089, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0732, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9745\n",
      "\n",
      "Aspect detection accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.97      0.96      0.96       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4185, Accuracy: 0.8239, F1 Micro: 0.8239, F1 Macro: 0.7931\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2698, Accuracy: 0.8768, F1 Micro: 0.8768, F1 Macro: 0.8343\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2015, Accuracy: 0.8978, F1 Micro: 0.8978, F1 Macro: 0.8718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1377, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.088, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8768\n",
      "Epoch 6/10, Train Loss: 0.0632, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.8724\n",
      "Epoch 7/10, Train Loss: 0.0647, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8791\n",
      "Epoch 8/10, Train Loss: 0.0363, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.878\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0389, Accuracy: 0.9078, F1 Micro: 0.9078, F1 Macro: 0.8804\n",
      "Epoch 10/10, Train Loss: 0.0258, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8802\n",
      "\n",
      "Sentiment analysis accuracy: 0.9078, F1 Micro: 0.9078, F1 Macro: 0.8804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       776\n",
      "    positive       0.94      0.73      0.82       320\n",
      "\n",
      "    accuracy                           0.91      1096\n",
      "   macro avg       0.92      0.86      0.88      1096\n",
      "weighted avg       0.91      0.91      0.90      1096\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1427: Accuracy: 0.9571, F1 Micro: 0.9571, F1 Macro: 0.8641\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.92      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.83      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.77      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.87      0.69      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.56      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.90      0.89       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.89      0.91      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.81      0.86       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       0.72      0.59      0.65        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.85      0.79      0.82       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.86      0.83        85\n",
      "     neutral       0.97      0.96      0.96       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.91      0.91       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.83      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 244.36891078948975 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 86\n",
      "Sampling duration: 33.96697449684143 seconds\n",
      "New train size: 1513\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4801, Accuracy: 0.8328, F1 Micro: 0.9051, F1 Macro: 0.9004\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3443, Accuracy: 0.9252, F1 Micro: 0.9545, F1 Macro: 0.9505\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2393, Accuracy: 0.9444, F1 Micro: 0.9661, F1 Macro: 0.964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1879, Accuracy: 0.9505, F1 Micro: 0.9697, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1558, Accuracy: 0.9575, F1 Micro: 0.9737, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1325, Accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1101, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9743\n",
      "Epoch 8/10, Train Loss: 0.0962, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0819, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9746\n",
      "Epoch 10/10, Train Loss: 0.0708, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9732\n",
      "\n",
      "Aspect detection accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4076, Accuracy: 0.845, F1 Micro: 0.845, F1 Macro: 0.7804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2782, Accuracy: 0.8881, F1 Micro: 0.8881, F1 Macro: 0.8551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1891, Accuracy: 0.9009, F1 Micro: 0.9009, F1 Macro: 0.8745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1416, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8776\n",
      "Epoch 5/10, Train Loss: 0.1007, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0744, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8873\n",
      "Epoch 7/10, Train Loss: 0.0673, Accuracy: 0.9046, F1 Micro: 0.9046, F1 Macro: 0.8794\n",
      "Epoch 8/10, Train Loss: 0.0527, Accuracy: 0.9073, F1 Micro: 0.9073, F1 Macro: 0.8794\n",
      "Epoch 9/10, Train Loss: 0.0308, Accuracy: 0.9101, F1 Micro: 0.9101, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0288, Accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.8871\n",
      "\n",
      "Sentiment analysis accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.8871\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       775\n",
      "    positive       0.95      0.74      0.83       315\n",
      "\n",
      "    accuracy                           0.91      1090\n",
      "   macro avg       0.93      0.86      0.89      1090\n",
      "weighted avg       0.92      0.91      0.91      1090\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1513: Accuracy: 0.9578, F1 Micro: 0.9578, F1 Macro: 0.8728\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.78      0.70      0.74        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.90      0.87      0.88       571\n",
      "weighted avg       0.97      0.98      0.98       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.57      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.83      0.85       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       1.00      0.41      0.58        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.93      0.74      0.79       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.88      0.87        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.91      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.59      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.65      0.69        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.74      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 251.13646531105042 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 77\n",
      "Sampling duration: 30.640384674072266 seconds\n",
      "New train size: 1590\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4748, Accuracy: 0.8368, F1 Micro: 0.9066, F1 Macro: 0.901\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3413, Accuracy: 0.9266, F1 Micro: 0.9554, F1 Macro: 0.9522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2389, Accuracy: 0.9467, F1 Micro: 0.9673, F1 Macro: 0.9649\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1842, Accuracy: 0.9505, F1 Micro: 0.9697, F1 Macro: 0.9677\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1546, Accuracy: 0.9552, F1 Micro: 0.9724, F1 Macro: 0.9708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1323, Accuracy: 0.9582, F1 Micro: 0.9741, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1117, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0964, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9757\n",
      "Epoch 9/10, Train Loss: 0.0817, Accuracy: 0.9616, F1 Micro: 0.9763, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0677, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9758\n",
      "\n",
      "Aspect detection accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.98      0.98      0.98       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4362, Accuracy: 0.8627, F1 Micro: 0.8627, F1 Macro: 0.8147\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2809, Accuracy: 0.9014, F1 Micro: 0.9014, F1 Macro: 0.8717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1995, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8789\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1291, Accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.8847\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1083, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.8953\n",
      "Epoch 6/10, Train Loss: 0.0767, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8874\n",
      "Epoch 7/10, Train Loss: 0.0441, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8804\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0496, Accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.8971\n",
      "Epoch 9/10, Train Loss: 0.0423, Accuracy: 0.9171, F1 Micro: 0.9171, F1 Macro: 0.8939\n",
      "Epoch 10/10, Train Loss: 0.0405, Accuracy: 0.8995, F1 Micro: 0.8995, F1 Macro: 0.8668\n",
      "\n",
      "Sentiment analysis accuracy: 0.9189, F1 Micro: 0.9189, F1 Macro: 0.8971\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.97      0.94       771\n",
      "    positive       0.92      0.79      0.85       314\n",
      "\n",
      "    accuracy                           0.92      1085\n",
      "   macro avg       0.92      0.88      0.90      1085\n",
      "weighted avg       0.92      0.92      0.92      1085\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1590: Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.877\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.86      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.64      0.70      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.85      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.85      0.85        78\n",
      "     neutral       0.98      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.83      0.76      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.59      0.58      0.59       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.86      0.89       200\n",
      "     neutral       0.93      0.94      0.94       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.82      0.86       162\n",
      "     neutral       0.92      0.97      0.95       387\n",
      "    positive       0.81      0.59      0.68        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.82      0.86        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.91      0.93      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.82      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 261.4008364677429 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 70\n",
      "Sampling duration: 27.524577856063843 seconds\n",
      "New train size: 1660\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4774, Accuracy: 0.8351, F1 Micro: 0.906, F1 Macro: 0.9007\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3265, Accuracy: 0.9332, F1 Micro: 0.9593, F1 Macro: 0.9565\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.222, Accuracy: 0.9465, F1 Micro: 0.9673, F1 Macro: 0.9652\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1807, Accuracy: 0.949, F1 Micro: 0.9688, F1 Macro: 0.9667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1518, Accuracy: 0.9571, F1 Micro: 0.9736, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1261, Accuracy: 0.9601, F1 Micro: 0.9754, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1061, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0891, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.077, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9757\n",
      "Epoch 10/10, Train Loss: 0.0665, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9747\n",
      "\n",
      "Aspect detection accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.93      0.96      0.94       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3951, Accuracy: 0.866, F1 Micro: 0.866, F1 Macro: 0.829\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2442, Accuracy: 0.8888, F1 Micro: 0.8888, F1 Macro: 0.8523\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1822, Accuracy: 0.9079, F1 Micro: 0.9079, F1 Macro: 0.8818\n",
      "Epoch 4/10, Train Loss: 0.1298, Accuracy: 0.9052, F1 Micro: 0.9052, F1 Macro: 0.8789\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1045, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.889\n",
      "Epoch 6/10, Train Loss: 0.0855, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.8877\n",
      "Epoch 7/10, Train Loss: 0.0623, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.882\n",
      "Epoch 8/10, Train Loss: 0.0576, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8841\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0558, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8875\n",
      "Epoch 10/10, Train Loss: 0.0348, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.887\n",
      "\n",
      "Sentiment analysis accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       776\n",
      "    positive       0.93      0.75      0.83       321\n",
      "\n",
      "    accuracy                           0.91      1097\n",
      "   macro avg       0.92      0.87      0.89      1097\n",
      "weighted avg       0.91      0.91      0.91      1097\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1660: Accuracy: 0.9587, F1 Micro: 0.9587, F1 Macro: 0.8788\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.87      0.87       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.81      0.84        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.75      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.76      0.62      0.66       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.87      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.84      0.84       162\n",
      "     neutral       0.93      0.96      0.94       387\n",
      "    positive       0.80      0.36      0.50        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.86      0.72      0.76       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.80      0.85        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.90      0.94      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.83      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 267.414954662323 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 52\n",
      "Sampling duration: 24.85845637321472 seconds\n",
      "New train size: 1712\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4741, Accuracy: 0.8458, F1 Micro: 0.9114, F1 Macro: 0.906\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3151, Accuracy: 0.9314, F1 Micro: 0.9582, F1 Macro: 0.9554\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2263, Accuracy: 0.946, F1 Micro: 0.967, F1 Macro: 0.965\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1765, Accuracy: 0.9497, F1 Micro: 0.9691, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.15, Accuracy: 0.9594, F1 Micro: 0.9749, F1 Macro: 0.9729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1257, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1033, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9739\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0872, Accuracy: 0.9623, F1 Micro: 0.9767, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0783, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0633, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9757\n",
      "\n",
      "Aspect detection accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.94      0.93      0.94       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4105, Accuracy: 0.8654, F1 Micro: 0.8654, F1 Macro: 0.8235\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2315, Accuracy: 0.8986, F1 Micro: 0.8986, F1 Macro: 0.8676\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1598, Accuracy: 0.9032, F1 Micro: 0.9032, F1 Macro: 0.8717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1135, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8853\n",
      "Epoch 5/10, Train Loss: 0.0998, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8826\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0566, Accuracy: 0.9152, F1 Micro: 0.9152, F1 Macro: 0.8898\n",
      "Epoch 7/10, Train Loss: 0.0612, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8773\n",
      "Epoch 8/10, Train Loss: 0.0384, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8763\n",
      "Epoch 9/10, Train Loss: 0.0261, Accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.8858\n",
      "Epoch 10/10, Train Loss: 0.0348, Accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.8823\n",
      "\n",
      "Sentiment analysis accuracy: 0.9152, F1 Micro: 0.9152, F1 Macro: 0.8898\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       775\n",
      "    positive       0.93      0.76      0.84       310\n",
      "\n",
      "    accuracy                           0.92      1085\n",
      "   macro avg       0.92      0.87      0.89      1085\n",
      "weighted avg       0.92      0.92      0.91      1085\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1712: Accuracy: 0.9588, F1 Micro: 0.9588, F1 Macro: 0.8723\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.83      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.88      0.65      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.54      0.57       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.90       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.89      0.98      0.93        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.83      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.79      0.50      0.61        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.77      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.48      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 274.89756870269775 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 58\n",
      "Sampling duration: 22.968849420547485 seconds\n",
      "New train size: 1770\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4702, Accuracy: 0.8625, F1 Micro: 0.9198, F1 Macro: 0.9138\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3049, Accuracy: 0.9332, F1 Micro: 0.9593, F1 Macro: 0.9566\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2131, Accuracy: 0.9474, F1 Micro: 0.9678, F1 Macro: 0.9655\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1712, Accuracy: 0.9533, F1 Micro: 0.9713, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1422, Accuracy: 0.9573, F1 Micro: 0.9737, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1165, Accuracy: 0.9597, F1 Micro: 0.975, F1 Macro: 0.9726\n",
      "Epoch 7/10, Train Loss: 0.1003, Accuracy: 0.959, F1 Micro: 0.9747, F1 Macro: 0.9727\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0851, Accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9765\n",
      "Epoch 9/10, Train Loss: 0.0704, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.976\n",
      "Epoch 10/10, Train Loss: 0.0625, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9755\n",
      "\n",
      "Aspect detection accuracy: 0.9656, F1 Micro: 0.9786, F1 Macro: 0.9765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4325, Accuracy: 0.8605, F1 Micro: 0.8605, F1 Macro: 0.8118\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2572, Accuracy: 0.8961, F1 Micro: 0.8961, F1 Macro: 0.8646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1702, Accuracy: 0.9025, F1 Micro: 0.9025, F1 Macro: 0.8716\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1261, Accuracy: 0.9061, F1 Micro: 0.9061, F1 Macro: 0.8805\n",
      "Epoch 5/10, Train Loss: 0.1003, Accuracy: 0.9025, F1 Micro: 0.9025, F1 Macro: 0.871\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0698, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.8882\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0559, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8873\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0408, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.8883\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0332, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.8881\n",
      "Epoch 10/10, Train Loss: 0.0469, Accuracy: 0.8988, F1 Micro: 0.8988, F1 Macro: 0.8746\n",
      "\n",
      "Sentiment analysis accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.8881\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       776\n",
      "    positive       0.94      0.75      0.83       321\n",
      "\n",
      "    accuracy                           0.91      1097\n",
      "   macro avg       0.92      0.86      0.89      1097\n",
      "weighted avg       0.92      0.91      0.91      1097\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1770: Accuracy: 0.9595, F1 Micro: 0.9595, F1 Macro: 0.874\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.81      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.33      0.14      0.20         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.83      0.79      0.81        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.71      0.64      0.66       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.89      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.90      0.98      0.94        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.92      0.94      0.93       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.86      0.86       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.78      0.32      0.45        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.86      0.72      0.75       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.85        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.81      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 282.5185012817383 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 52\n",
      "Sampling duration: 20.526938438415527 seconds\n",
      "New train size: 1822\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4584, Accuracy: 0.8724, F1 Micro: 0.9249, F1 Macro: 0.9186\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2912, Accuracy: 0.9359, F1 Micro: 0.961, F1 Macro: 0.9583\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2106, Accuracy: 0.9486, F1 Micro: 0.9685, F1 Macro: 0.9663\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1701, Accuracy: 0.9514, F1 Micro: 0.9701, F1 Macro: 0.9679\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1401, Accuracy: 0.9569, F1 Micro: 0.9734, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1172, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0985, Accuracy: 0.9634, F1 Micro: 0.9772, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0823, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0714, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0614, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.976\n",
      "\n",
      "Aspect detection accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3986, Accuracy: 0.8703, F1 Micro: 0.8703, F1 Macro: 0.8367\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2213, Accuracy: 0.8971, F1 Micro: 0.8971, F1 Macro: 0.8614\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1701, Accuracy: 0.9045, F1 Micro: 0.9045, F1 Macro: 0.8714\n",
      "Epoch 4/10, Train Loss: 0.1194, Accuracy: 0.9036, F1 Micro: 0.9036, F1 Macro: 0.8699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0803, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8837\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0751, Accuracy: 0.912, F1 Micro: 0.912, F1 Macro: 0.8871\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0541, Accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.8935\n",
      "Epoch 8/10, Train Loss: 0.0299, Accuracy: 0.9157, F1 Micro: 0.9157, F1 Macro: 0.8916\n",
      "Epoch 9/10, Train Loss: 0.0294, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8836\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0325, Accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.8932\n",
      "\n",
      "Sentiment analysis accuracy: 0.9194, F1 Micro: 0.9194, F1 Macro: 0.8932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       775\n",
      "    positive       0.95      0.75      0.84       304\n",
      "\n",
      "    accuracy                           0.92      1079\n",
      "   macro avg       0.93      0.87      0.89      1079\n",
      "weighted avg       0.92      0.92      0.92      1079\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1822: Accuracy: 0.9594, F1 Micro: 0.9594, F1 Macro: 0.8714\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.67      0.60      0.63        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.83      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.81      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.86      0.65      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.54      0.57       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.90      0.95      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.86       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       1.00      0.36      0.53        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.93      0.73      0.78       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.94      0.96      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.74      0.82      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 292.39426159858704 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 18.55655074119568 seconds\n",
      "New train size: 1872\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4617, Accuracy: 0.8734, F1 Micro: 0.9258, F1 Macro: 0.9203\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.289, Accuracy: 0.9339, F1 Micro: 0.9597, F1 Macro: 0.9571\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2047, Accuracy: 0.9451, F1 Micro: 0.9665, F1 Macro: 0.9645\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1678, Accuracy: 0.9531, F1 Micro: 0.9712, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1359, Accuracy: 0.9578, F1 Micro: 0.974, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1147, Accuracy: 0.962, F1 Micro: 0.9765, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0975, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9759\n",
      "Epoch 8/10, Train Loss: 0.0808, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9749\n",
      "Epoch 9/10, Train Loss: 0.0664, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0576, Accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9768\n",
      "\n",
      "Aspect detection accuracy: 0.966, F1 Micro: 0.9788, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.94      0.95      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3885, Accuracy: 0.8581, F1 Micro: 0.8581, F1 Macro: 0.8035\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2271, Accuracy: 0.8899, F1 Micro: 0.8899, F1 Macro: 0.8531\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1474, Accuracy: 0.9063, F1 Micro: 0.9063, F1 Macro: 0.8792\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1112, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8818\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0837, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8834\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0675, Accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.886\n",
      "Epoch 7/10, Train Loss: 0.0427, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8818\n",
      "Epoch 8/10, Train Loss: 0.0373, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.885\n",
      "Epoch 9/10, Train Loss: 0.0176, Accuracy: 0.9099, F1 Micro: 0.9099, F1 Macro: 0.8812\n",
      "Epoch 10/10, Train Loss: 0.0166, Accuracy: 0.909, F1 Micro: 0.909, F1 Macro: 0.8805\n",
      "\n",
      "Sentiment analysis accuracy: 0.9136, F1 Micro: 0.9136, F1 Macro: 0.886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.99      0.94       783\n",
      "    positive       0.95      0.73      0.83       316\n",
      "\n",
      "    accuracy                           0.91      1099\n",
      "   macro avg       0.93      0.86      0.89      1099\n",
      "weighted avg       0.92      0.91      0.91      1099\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1872: Accuracy: 0.9606, F1 Micro: 0.9606, F1 Macro: 0.8761\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.87      0.87       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.82      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.90      0.68      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.62      0.55      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.91      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.90      0.96      0.93        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.92      0.93      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.88      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.75      0.41      0.53        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.85      0.75      0.78       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.96      0.96      0.96        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.59      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.78      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 292.36646842956543 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 16.756326913833618 seconds\n",
      "New train size: 1922\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4582, Accuracy: 0.8766, F1 Micro: 0.9274, F1 Macro: 0.9217\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2845, Accuracy: 0.9363, F1 Micro: 0.9612, F1 Macro: 0.9587\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2032, Accuracy: 0.9519, F1 Micro: 0.9705, F1 Macro: 0.9687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1625, Accuracy: 0.9542, F1 Micro: 0.9718, F1 Macro: 0.9701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1349, Accuracy: 0.9582, F1 Micro: 0.9742, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1132, Accuracy: 0.962, F1 Micro: 0.9765, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0937, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0758, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9762\n",
      "Epoch 9/10, Train Loss: 0.0663, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9757\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0575, Accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.9767\n",
      "\n",
      "Aspect detection accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.98      0.98       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.93      0.96      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3704, Accuracy: 0.8737, F1 Micro: 0.8737, F1 Macro: 0.8288\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2019, Accuracy: 0.8968, F1 Micro: 0.8968, F1 Macro: 0.8602\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.144, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8766\n",
      "Epoch 4/10, Train Loss: 0.1108, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.88\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0754, Accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.8829\n",
      "Epoch 6/10, Train Loss: 0.0548, Accuracy: 0.9088, F1 Micro: 0.9088, F1 Macro: 0.8807\n",
      "Epoch 7/10, Train Loss: 0.0385, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8826\n",
      "Epoch 8/10, Train Loss: 0.0325, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.031, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.8959\n",
      "Epoch 10/10, Train Loss: 0.0149, Accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.8892\n",
      "\n",
      "Sentiment analysis accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.8959\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       775\n",
      "    positive       0.94      0.77      0.85       310\n",
      "\n",
      "    accuracy                           0.92      1085\n",
      "   macro avg       0.93      0.88      0.90      1085\n",
      "weighted avg       0.92      0.92      0.92      1085\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1922: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.8681\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87        78\n",
      "     neutral       0.98      0.98      0.98       491\n",
      "    positive       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.94      0.88       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.89      0.71      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.56      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.86      0.89       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.86      0.98      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.85      0.85       162\n",
      "     neutral       0.93      0.96      0.94       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.74      0.78       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.89      0.96      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.89      0.84      0.86       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 303.6033294200897 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 15.42298436164856 seconds\n",
      "New train size: 1972\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4521, Accuracy: 0.879, F1 Micro: 0.9284, F1 Macro: 0.922\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2782, Accuracy: 0.9384, F1 Micro: 0.9624, F1 Macro: 0.9602\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2022, Accuracy: 0.9477, F1 Micro: 0.968, F1 Macro: 0.966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1629, Accuracy: 0.954, F1 Micro: 0.9716, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1347, Accuracy: 0.9613, F1 Micro: 0.9759, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1148, Accuracy: 0.9637, F1 Micro: 0.9776, F1 Macro: 0.9757\n",
      "Epoch 7/10, Train Loss: 0.0925, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0762, Accuracy: 0.9651, F1 Micro: 0.9784, F1 Macro: 0.9762\n",
      "Epoch 9/10, Train Loss: 0.0668, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0554, Accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.93      0.99      0.96       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3762, Accuracy: 0.8725, F1 Micro: 0.8725, F1 Macro: 0.8205\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1919, Accuracy: 0.9039, F1 Micro: 0.9039, F1 Macro: 0.8744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1392, Accuracy: 0.9104, F1 Micro: 0.9104, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0952, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8843\n",
      "Epoch 5/10, Train Loss: 0.0726, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0522, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8838\n",
      "Epoch 7/10, Train Loss: 0.0416, Accuracy: 0.8993, F1 Micro: 0.8993, F1 Macro: 0.8692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.029, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8838\n",
      "Epoch 9/10, Train Loss: 0.0248, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.88\n",
      "Epoch 10/10, Train Loss: 0.0307, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8794\n",
      "\n",
      "Sentiment analysis accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8838\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       782\n",
      "    positive       0.91      0.75      0.83       300\n",
      "\n",
      "    accuracy                           0.91      1082\n",
      "   macro avg       0.91      0.86      0.88      1082\n",
      "weighted avg       0.91      0.91      0.91      1082\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1972: Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.8709\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.82      0.85        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.93      0.99      0.96       496\n",
      "    positive       0.90      0.56      0.69        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.61      0.52      0.55       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.90      0.89       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.90      0.93      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.69      0.50      0.58        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.84      0.77      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.82      0.87        85\n",
      "     neutral       0.97      0.99      0.98       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.67      0.94      0.78        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.82      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 306.2605040073395 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 25\n",
      "Sampling duration: 12.884211778640747 seconds\n",
      "New train size: 1997\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4542, Accuracy: 0.88, F1 Micro: 0.9294, F1 Macro: 0.9243\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2791, Accuracy: 0.9411, F1 Micro: 0.9641, F1 Macro: 0.9619\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1928, Accuracy: 0.9488, F1 Micro: 0.9686, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1543, Accuracy: 0.9517, F1 Micro: 0.9704, F1 Macro: 0.9684\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1325, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1091, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0907, Accuracy: 0.9635, F1 Micro: 0.9774, F1 Macro: 0.9752\n",
      "Epoch 8/10, Train Loss: 0.0722, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9747\n",
      "Epoch 9/10, Train Loss: 0.062, Accuracy: 0.9618, F1 Micro: 0.9764, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0549, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9757\n",
      "\n",
      "Aspect detection accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.93      0.94      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3515, Accuracy: 0.8711, F1 Micro: 0.8711, F1 Macro: 0.8249\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2274, Accuracy: 0.8984, F1 Micro: 0.8984, F1 Macro: 0.8706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1673, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8803\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1026, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.8899\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0891, Accuracy: 0.92, F1 Micro: 0.92, F1 Macro: 0.8933\n",
      "Epoch 6/10, Train Loss: 0.0613, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8839\n",
      "Epoch 7/10, Train Loss: 0.0462, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.8797\n",
      "Epoch 8/10, Train Loss: 0.035, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.8886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0378, Accuracy: 0.9247, F1 Micro: 0.9247, F1 Macro: 0.8992\n",
      "Epoch 10/10, Train Loss: 0.021, Accuracy: 0.9153, F1 Micro: 0.9153, F1 Macro: 0.8857\n",
      "\n",
      "Sentiment analysis accuracy: 0.9247, F1 Micro: 0.9247, F1 Macro: 0.8992\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.99      0.95       769\n",
      "    positive       0.96      0.76      0.85       294\n",
      "\n",
      "    accuracy                           0.92      1063\n",
      "   macro avg       0.94      0.87      0.90      1063\n",
      "weighted avg       0.93      0.92      0.92      1063\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1997: Accuracy: 0.959, F1 Micro: 0.959, F1 Macro: 0.8657\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.81      0.84        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.88      0.63      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.61      0.54      0.57       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.89      0.90       200\n",
      "     neutral       0.93      0.94      0.94       315\n",
      "    positive       0.88      0.91      0.89        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.91      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.85      0.50      0.63        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.77      0.82       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.96      0.94      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.98      0.81      0.87       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 307.49150562286377 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 12.060723066329956 seconds\n",
      "New train size: 2047\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4579, Accuracy: 0.8868, F1 Micro: 0.9329, F1 Macro: 0.9278\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2722, Accuracy: 0.9411, F1 Micro: 0.9641, F1 Macro: 0.9618\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1944, Accuracy: 0.9521, F1 Micro: 0.9705, F1 Macro: 0.9685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1541, Accuracy: 0.9549, F1 Micro: 0.9722, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1292, Accuracy: 0.9606, F1 Micro: 0.9757, F1 Macro: 0.9737\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1083, Accuracy: 0.9627, F1 Micro: 0.9769, F1 Macro: 0.9746\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0891, Accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9767\n",
      "Epoch 8/10, Train Loss: 0.0738, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9753\n",
      "Epoch 9/10, Train Loss: 0.0628, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.975\n",
      "Epoch 10/10, Train Loss: 0.0535, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.975\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3601, Accuracy: 0.8801, F1 Micro: 0.8801, F1 Macro: 0.8449\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1957, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.8855\n",
      "Epoch 3/10, Train Loss: 0.1371, Accuracy: 0.9059, F1 Micro: 0.9059, F1 Macro: 0.8733\n",
      "Epoch 4/10, Train Loss: 0.1029, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.8756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0702, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8866\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0516, Accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.8922\n",
      "Epoch 7/10, Train Loss: 0.037, Accuracy: 0.9124, F1 Micro: 0.9124, F1 Macro: 0.8863\n",
      "Epoch 8/10, Train Loss: 0.0377, Accuracy: 0.9133, F1 Micro: 0.9133, F1 Macro: 0.8874\n",
      "Epoch 9/10, Train Loss: 0.0256, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8807\n",
      "Epoch 10/10, Train Loss: 0.0294, Accuracy: 0.9096, F1 Micro: 0.9096, F1 Macro: 0.8806\n",
      "\n",
      "Sentiment analysis accuracy: 0.917, F1 Micro: 0.917, F1 Macro: 0.8922\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       776\n",
      "    positive       0.93      0.77      0.84       308\n",
      "\n",
      "    accuracy                           0.92      1084\n",
      "   macro avg       0.92      0.87      0.89      1084\n",
      "weighted avg       0.92      0.92      0.91      1084\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2047: Accuracy: 0.9597, F1 Micro: 0.9597, F1 Macro: 0.8722\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.91      0.91        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.84      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.79      0.84        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.89      0.71      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.56      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.75      0.79       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.84      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.52      0.64        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.97      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 301.2989413738251 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 10.029613018035889 seconds\n",
      "New train size: 2097\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4467, Accuracy: 0.8882, F1 Micro: 0.9338, F1 Macro: 0.9289\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.261, Accuracy: 0.9441, F1 Micro: 0.9658, F1 Macro: 0.9635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1889, Accuracy: 0.9533, F1 Micro: 0.9713, F1 Macro: 0.9694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1493, Accuracy: 0.9564, F1 Micro: 0.9732, F1 Macro: 0.9711\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1225, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1021, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9763\n",
      "Epoch 7/10, Train Loss: 0.0863, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9756\n",
      "Epoch 8/10, Train Loss: 0.0718, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0593, Accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9765\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.049, Accuracy: 0.9661, F1 Micro: 0.9789, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.9661, F1 Micro: 0.9789, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3592, Accuracy: 0.8635, F1 Micro: 0.8635, F1 Macro: 0.8157\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2081, Accuracy: 0.8987, F1 Micro: 0.8987, F1 Macro: 0.8697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1209, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.8839\n",
      "Epoch 4/10, Train Loss: 0.0907, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8779\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0683, Accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.8868\n",
      "Epoch 6/10, Train Loss: 0.0502, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.8862\n",
      "Epoch 7/10, Train Loss: 0.0362, Accuracy: 0.9078, F1 Micro: 0.9078, F1 Macro: 0.8806\n",
      "Epoch 8/10, Train Loss: 0.036, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.8726\n",
      "Epoch 9/10, Train Loss: 0.0259, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.8845\n",
      "Epoch 10/10, Train Loss: 0.0329, Accuracy: 0.9123, F1 Micro: 0.9123, F1 Macro: 0.886\n",
      "\n",
      "Sentiment analysis accuracy: 0.9132, F1 Micro: 0.9132, F1 Macro: 0.8868\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       784\n",
      "    positive       0.95      0.74      0.83       322\n",
      "\n",
      "    accuracy                           0.91      1106\n",
      "   macro avg       0.93      0.86      0.89      1106\n",
      "weighted avg       0.92      0.91      0.91      1106\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2097: Accuracy: 0.9602, F1 Micro: 0.9602, F1 Macro: 0.8836\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.81      0.84        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.66      0.73       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.74      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.91      0.89        85\n",
      "     neutral       0.98      0.97      0.98       418\n",
      "    positive       0.94      0.97      0.96        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.95      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.62      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 310.0357983112335 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 8.219738006591797 seconds\n",
      "New train size: 2147\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4396, Accuracy: 0.8918, F1 Micro: 0.9355, F1 Macro: 0.9296\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2574, Accuracy: 0.9429, F1 Micro: 0.965, F1 Macro: 0.9628\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1843, Accuracy: 0.9497, F1 Micro: 0.9691, F1 Macro: 0.9671\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.153, Accuracy: 0.9569, F1 Micro: 0.9734, F1 Macro: 0.9713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1197, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.102, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0829, Accuracy: 0.9663, F1 Micro: 0.9791, F1 Macro: 0.9771\n",
      "Epoch 8/10, Train Loss: 0.0716, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0564, Accuracy: 0.9667, F1 Micro: 0.9793, F1 Macro: 0.9774\n",
      "Epoch 10/10, Train Loss: 0.0487, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9756\n",
      "\n",
      "Aspect detection accuracy: 0.9667, F1 Micro: 0.9793, F1 Macro: 0.9774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.93      0.95      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.99      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.99      0.98      4614\n",
      " samples avg       0.97      0.99      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3642, Accuracy: 0.8813, F1 Micro: 0.8813, F1 Macro: 0.8409\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1864, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8785\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1397, Accuracy: 0.914, F1 Micro: 0.914, F1 Macro: 0.8866\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0885, Accuracy: 0.9168, F1 Micro: 0.9168, F1 Macro: 0.8927\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0572, Accuracy: 0.9262, F1 Micro: 0.9262, F1 Macro: 0.9035\n",
      "Epoch 6/10, Train Loss: 0.0477, Accuracy: 0.914, F1 Micro: 0.914, F1 Macro: 0.884\n",
      "Epoch 7/10, Train Loss: 0.0407, Accuracy: 0.9234, F1 Micro: 0.9234, F1 Macro: 0.8984\n",
      "Epoch 8/10, Train Loss: 0.0306, Accuracy: 0.9196, F1 Micro: 0.9196, F1 Macro: 0.8948\n",
      "Epoch 9/10, Train Loss: 0.0283, Accuracy: 0.9206, F1 Micro: 0.9206, F1 Macro: 0.8946\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0274, Accuracy: 0.9271, F1 Micro: 0.9271, F1 Macro: 0.9036\n",
      "\n",
      "Sentiment analysis accuracy: 0.9271, F1 Micro: 0.9271, F1 Macro: 0.9036\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       772\n",
      "    positive       0.95      0.78      0.86       298\n",
      "\n",
      "    accuracy                           0.93      1070\n",
      "   macro avg       0.94      0.88      0.90      1070\n",
      "weighted avg       0.93      0.93      0.92      1070\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2147: Accuracy: 0.9613, F1 Micro: 0.9613, F1 Macro: 0.8835\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.88      0.91        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.82      0.85        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.89      0.69      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.61      0.66       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.90       200\n",
      "     neutral       0.93      0.95      0.94       315\n",
      "    positive       0.90      0.93      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.85      0.50      0.63        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.77      0.81       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88        85\n",
      "     neutral       0.97      0.99      0.98       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.62      0.73        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.88      0.88      0.88        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.92      0.83      0.87       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.93      0.98      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 320.4013783931732 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 6.169177293777466 seconds\n",
      "New train size: 2197\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4391, Accuracy: 0.8802, F1 Micro: 0.9297, F1 Macro: 0.925\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2607, Accuracy: 0.9443, F1 Micro: 0.9658, F1 Macro: 0.9637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1823, Accuracy: 0.9523, F1 Micro: 0.9706, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1507, Accuracy: 0.9569, F1 Micro: 0.9735, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1219, Accuracy: 0.9613, F1 Micro: 0.9761, F1 Macro: 0.9741\n",
      "Epoch 6/10, Train Loss: 0.0982, Accuracy: 0.9608, F1 Micro: 0.9757, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0823, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9756\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0715, Accuracy: 0.9644, F1 Micro: 0.9778, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0588, Accuracy: 0.9656, F1 Micro: 0.9787, F1 Macro: 0.9766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0487, Accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.98       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.93      0.96      0.94       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3487, Accuracy: 0.8731, F1 Micro: 0.8731, F1 Macro: 0.8379\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1891, Accuracy: 0.9014, F1 Micro: 0.9014, F1 Macro: 0.8734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.132, Accuracy: 0.9032, F1 Micro: 0.9032, F1 Macro: 0.8731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.099, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8806\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0678, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8817\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0537, Accuracy: 0.9105, F1 Micro: 0.9105, F1 Macro: 0.8843\n",
      "Epoch 7/10, Train Loss: 0.0373, Accuracy: 0.9078, F1 Micro: 0.9078, F1 Macro: 0.8778\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0325, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.888\n",
      "Epoch 9/10, Train Loss: 0.0234, Accuracy: 0.9123, F1 Micro: 0.9123, F1 Macro: 0.8869\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0173, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8893\n",
      "\n",
      "Sentiment analysis accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8893\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       779\n",
      "    positive       0.94      0.75      0.84       316\n",
      "\n",
      "    accuracy                           0.92      1095\n",
      "   macro avg       0.93      0.87      0.89      1095\n",
      "weighted avg       0.92      0.92      0.91      1095\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2197: Accuracy: 0.9595, F1 Micro: 0.9595, F1 Macro: 0.8739\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.94      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.93      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.91      0.92        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.82      0.84        78\n",
      "     neutral       0.97      0.98      0.98       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.95      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.83      0.72      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.66      0.73       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.88      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86       162\n",
      "     neutral       0.93      0.96      0.94       387\n",
      "    positive       0.85      0.50      0.63        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.77      0.81       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.93      0.97      0.95        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.94      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.96      0.92        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.33      0.50         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.76      0.81       571\n",
      "weighted avg       0.99      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 332.69185090065 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 4.214280843734741 seconds\n",
      "New train size: 2247\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4275, Accuracy: 0.8925, F1 Micro: 0.9363, F1 Macro: 0.9317\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2462, Accuracy: 0.9384, F1 Micro: 0.9625, F1 Macro: 0.9602\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1808, Accuracy: 0.9526, F1 Micro: 0.9708, F1 Macro: 0.9687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1427, Accuracy: 0.9587, F1 Micro: 0.9745, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1151, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0964, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9761\n",
      "Epoch 7/10, Train Loss: 0.082, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0649, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.976\n",
      "Epoch 9/10, Train Loss: 0.053, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.975\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0477, Accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9764\n",
      "\n",
      "Aspect detection accuracy: 0.9655, F1 Micro: 0.9785, F1 Macro: 0.9764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.92      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3271, Accuracy: 0.8672, F1 Micro: 0.8672, F1 Macro: 0.83\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1778, Accuracy: 0.8943, F1 Micro: 0.8943, F1 Macro: 0.8616\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1258, Accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.8741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0913, Accuracy: 0.9142, F1 Micro: 0.9142, F1 Macro: 0.8899\n",
      "Epoch 5/10, Train Loss: 0.0689, Accuracy: 0.9015, F1 Micro: 0.9015, F1 Macro: 0.876\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0543, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8907\n",
      "Epoch 7/10, Train Loss: 0.0376, Accuracy: 0.9097, F1 Micro: 0.9097, F1 Macro: 0.8835\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0344, Accuracy: 0.9151, F1 Micro: 0.9151, F1 Macro: 0.8914\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0298, Accuracy: 0.9178, F1 Micro: 0.9178, F1 Macro: 0.8936\n",
      "Epoch 10/10, Train Loss: 0.0175, Accuracy: 0.9106, F1 Micro: 0.9106, F1 Macro: 0.8845\n",
      "\n",
      "Sentiment analysis accuracy: 0.9178, F1 Micro: 0.9178, F1 Macro: 0.8936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       784\n",
      "    positive       0.95      0.76      0.84       323\n",
      "\n",
      "    accuracy                           0.92      1107\n",
      "   macro avg       0.93      0.87      0.89      1107\n",
      "weighted avg       0.92      0.92      0.91      1107\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2247: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.8892\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.90      0.91        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.82      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.43      0.60         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.80      0.72      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.92      0.71      0.77       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.91      0.90       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.90      0.98      0.94        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.89      0.36      0.52        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.73      0.78       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.80      0.94      0.86        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.84      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 329.60633397102356 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 36\n",
      "Sampling duration: 2.4364631175994873 seconds\n",
      "New train size: 2283\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4263, Accuracy: 0.8967, F1 Micro: 0.9383, F1 Macro: 0.9335\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2428, Accuracy: 0.9444, F1 Micro: 0.9659, F1 Macro: 0.9635\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1784, Accuracy: 0.9502, F1 Micro: 0.9694, F1 Macro: 0.9675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1372, Accuracy: 0.9592, F1 Micro: 0.9748, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1131, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0946, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0797, Accuracy: 0.9661, F1 Micro: 0.9789, F1 Macro: 0.9768\n",
      "Epoch 8/10, Train Loss: 0.0652, Accuracy: 0.9646, F1 Micro: 0.9781, F1 Macro: 0.976\n",
      "Epoch 9/10, Train Loss: 0.0553, Accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.977\n",
      "Epoch 10/10, Train Loss: 0.0477, Accuracy: 0.9658, F1 Micro: 0.9788, F1 Macro: 0.9766\n",
      "\n",
      "Aspect detection accuracy: 0.9661, F1 Micro: 0.9789, F1 Macro: 0.9768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.95      0.92      0.94       317\n",
      "       linen       0.95      0.96      0.96       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3529, Accuracy: 0.8705, F1 Micro: 0.8705, F1 Macro: 0.8344\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2105, Accuracy: 0.9004, F1 Micro: 0.9004, F1 Macro: 0.8671\n",
      "Epoch 3/10, Train Loss: 0.1487, Accuracy: 0.894, F1 Micro: 0.894, F1 Macro: 0.8571\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1331, Accuracy: 0.9067, F1 Micro: 0.9067, F1 Macro: 0.8775\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0914, Accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.8867\n",
      "Epoch 6/10, Train Loss: 0.0533, Accuracy: 0.9076, F1 Micro: 0.9076, F1 Macro: 0.8768\n",
      "Epoch 7/10, Train Loss: 0.0665, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.8715\n",
      "Epoch 8/10, Train Loss: 0.0495, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.8833\n",
      "Epoch 9/10, Train Loss: 0.0441, Accuracy: 0.8976, F1 Micro: 0.8976, F1 Macro: 0.8606\n",
      "Epoch 10/10, Train Loss: 0.0385, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.883\n",
      "\n",
      "Sentiment analysis accuracy: 0.913, F1 Micro: 0.913, F1 Macro: 0.8867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       789\n",
      "    positive       0.93      0.76      0.83       315\n",
      "\n",
      "    accuracy                           0.91      1104\n",
      "   macro avg       0.92      0.87      0.89      1104\n",
      "weighted avg       0.91      0.91      0.91      1104\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2283: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.8791\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        86\n",
      "     neutral       0.99      0.99      0.99       475\n",
      "    positive       0.64      0.70      0.67        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.87      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.81      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.87      0.66      0.75        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.55      0.57       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.90      0.89       200\n",
      "     neutral       0.95      0.92      0.94       315\n",
      "    positive       0.83      0.95      0.88        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.90       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.89      0.89       162\n",
      "     neutral       0.95      0.96      0.96       387\n",
      "    positive       0.73      0.50      0.59        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.86      0.78      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.94      0.91      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.99      1.00      0.99       525\n",
      "    positive       0.73      0.94      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.84      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 325.6690649986267 s\n",
      "Total runtime: 7486.670530796051 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[3], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b495f29",
   "metadata": {
    "papermill": {
     "duration": 0.011369,
     "end_time": "2025-03-31T04:28:08.550433",
     "exception": false,
     "start_time": "2025-03-31T04:28:08.539064",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RUN 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef178ff0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-31T04:28:08.574317Z",
     "iopub.status.busy": "2025-03-31T04:28:08.574049Z",
     "iopub.status.idle": "2025-03-31T06:47:59.675307Z",
     "shell.execute_reply": "2025-03-31T06:47:59.674327Z"
    },
    "papermill": {
     "duration": 8391.11485,
     "end_time": "2025-03-31T06:47:59.676805",
     "exception": false,
     "start_time": "2025-03-31T04:28:08.561955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "TRIAL 5\n",
      "Random seed: 94\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.6222, Accuracy: 0.7984, F1 Micro: 0.8875, F1 Macro: 0.8819\n",
      "Epoch 2/10, Train Loss: 0.4944, Accuracy: 0.7981, F1 Micro: 0.8873, F1 Macro: 0.8811\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4566, Accuracy: 0.7997, F1 Micro: 0.8881, F1 Macro: 0.8821\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4288, Accuracy: 0.8017, F1 Micro: 0.8893, F1 Macro: 0.8836\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.4243, Accuracy: 0.804, F1 Micro: 0.8907, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.4161, Accuracy: 0.8135, F1 Micro: 0.8944, F1 Macro: 0.8872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.4005, Accuracy: 0.8179, F1 Micro: 0.8965, F1 Macro: 0.8903\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.3794, Accuracy: 0.8247, F1 Micro: 0.9001, F1 Macro: 0.8939\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.3213, Accuracy: 0.8417, F1 Micro: 0.9083, F1 Macro: 0.9019\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.3264, Accuracy: 0.8519, F1 Micro: 0.9131, F1 Macro: 0.9062\n",
      "\n",
      "Aspect detection accuracy: 0.8519, F1 Micro: 0.9131, F1 Macro: 0.9062\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.88      1.00      0.94       462\n",
      "   air_panas       0.83      1.00      0.91       480\n",
      "         bau       0.87      0.98      0.92       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.78      0.78      0.78       317\n",
      "       linen       0.79      0.92      0.85       392\n",
      "     service       0.87      0.96      0.91       423\n",
      "sunrise_meal       0.92      1.00      0.96       530\n",
      "          tv       0.90      1.00      0.95       516\n",
      "        wifi       0.86      1.00      0.93       498\n",
      "\n",
      "   micro avg       0.86      0.97      0.91      4614\n",
      "   macro avg       0.86      0.96      0.91      4614\n",
      "weighted avg       0.86      0.97      0.91      4614\n",
      " samples avg       0.86      0.97      0.91      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5506, Accuracy: 0.6036, F1 Micro: 0.6036, F1 Macro: 0.3764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4796, Accuracy: 0.6036, F1 Micro: 0.6036, F1 Macro: 0.3764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4879, Accuracy: 0.6036, F1 Micro: 0.6036, F1 Macro: 0.3764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4287, Accuracy: 0.6036, F1 Micro: 0.6036, F1 Macro: 0.3764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3515, Accuracy: 0.6036, F1 Micro: 0.6036, F1 Macro: 0.3849\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3279, Accuracy: 0.7, F1 Micro: 0.7, F1 Macro: 0.6242\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2793, Accuracy: 0.7073, F1 Micro: 0.7073, F1 Macro: 0.6432\n",
      "Epoch 8/10, Train Loss: 0.202, Accuracy: 0.6873, F1 Micro: 0.6873, F1 Macro: 0.6008\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2003, Accuracy: 0.7309, F1 Micro: 0.7309, F1 Macro: 0.6829\n",
      "Epoch 10/10, Train Loss: 0.1315, Accuracy: 0.7109, F1 Micro: 0.7109, F1 Macro: 0.649\n",
      "\n",
      "Sentiment analysis accuracy: 0.7309, F1 Micro: 0.7309, F1 Macro: 0.6829\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.71      0.93      0.81       332\n",
      "    positive       0.80      0.43      0.56       218\n",
      "\n",
      "    accuracy                           0.73       550\n",
      "   macro avg       0.75      0.68      0.68       550\n",
      "weighted avg       0.75      0.73      0.71       550\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 142: Accuracy: 0.8433, F1 Micro: 0.8433, F1 Macro: 0.4292\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.46      0.61        97\n",
      "     neutral       0.88      1.00      0.94       459\n",
      "    positive       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.59      0.49      0.51       571\n",
      "weighted avg       0.86      0.88      0.86       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        86\n",
      "     neutral       0.83      1.00      0.91       475\n",
      "    positive       0.00      0.00      0.00        10\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.28      0.33      0.30       571\n",
      "weighted avg       0.69      0.83      0.76       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.35      0.08      0.13        78\n",
      "     neutral       0.87      0.98      0.92       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.41      0.35      0.35       571\n",
      "weighted avg       0.79      0.85      0.81       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       0.00      0.00      0.00        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.69      0.71       200\n",
      "     neutral       0.78      0.77      0.78       315\n",
      "    positive       0.39      0.46      0.42        56\n",
      "\n",
      "    accuracy                           0.71       571\n",
      "   macro avg       0.63      0.64      0.64       571\n",
      "weighted avg       0.72      0.71      0.72       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.48      0.56       162\n",
      "     neutral       0.78      0.92      0.85       387\n",
      "    positive       0.50      0.09      0.15        22\n",
      "\n",
      "    accuracy                           0.76       571\n",
      "   macro avg       0.66      0.50      0.52       571\n",
      "weighted avg       0.75      0.76      0.74       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.68      0.49      0.57        85\n",
      "     neutral       0.87      0.96      0.91       418\n",
      "    positive       0.83      0.56      0.67        68\n",
      "\n",
      "    accuracy                           0.84       571\n",
      "   macro avg       0.79      0.67      0.72       571\n",
      "weighted avg       0.83      0.84      0.83       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        29\n",
      "     neutral       0.92      1.00      0.96       525\n",
      "    positive       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.31      0.33      0.32       571\n",
      "weighted avg       0.85      0.92      0.88       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        54\n",
      "     neutral       0.89      1.00      0.94       511\n",
      "    positive       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.89       571\n",
      "   macro avg       0.30      0.33      0.31       571\n",
      "weighted avg       0.80      0.89      0.85       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00        74\n",
      "     neutral       0.87      1.00      0.93       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.29      0.33      0.31       571\n",
      "weighted avg       0.75      0.87      0.80       571\n",
      "\n",
      "Total train time: 85.26979088783264 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 215\n",
      "Sampling duration: 52.67351770401001 seconds\n",
      "New train size: 357\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5618, Accuracy: 0.7991, F1 Micro: 0.8882, F1 Macro: 0.8831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4795, Accuracy: 0.8033, F1 Micro: 0.8901, F1 Macro: 0.8845\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4507, Accuracy: 0.8057, F1 Micro: 0.8915, F1 Macro: 0.8866\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.4151, Accuracy: 0.8222, F1 Micro: 0.8984, F1 Macro: 0.8904\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.3779, Accuracy: 0.8476, F1 Micro: 0.9113, F1 Macro: 0.9054\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.3209, Accuracy: 0.8641, F1 Micro: 0.92, F1 Macro: 0.9138\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.278, Accuracy: 0.884, F1 Micro: 0.9316, F1 Macro: 0.9276\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.242, Accuracy: 0.8995, F1 Micro: 0.9401, F1 Macro: 0.9361\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.2207, Accuracy: 0.9137, F1 Micro: 0.948, F1 Macro: 0.9442\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1885, Accuracy: 0.9203, F1 Micro: 0.9516, F1 Macro: 0.948\n",
      "\n",
      "Aspect detection accuracy: 0.9203, F1 Micro: 0.9516, F1 Macro: 0.948\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.98       462\n",
      "   air_panas       0.94      0.99      0.96       480\n",
      "         bau       0.94      0.97      0.95       496\n",
      "     general       0.87      1.00      0.93       500\n",
      "  kebersihan       0.83      0.89      0.86       317\n",
      "       linen       0.86      0.96      0.91       392\n",
      "     service       0.95      0.96      0.95       423\n",
      "sunrise_meal       0.93      1.00      0.96       530\n",
      "          tv       0.96      1.00      0.98       516\n",
      "        wifi       0.98      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.93      0.98      0.95      4614\n",
      "   macro avg       0.92      0.98      0.95      4614\n",
      "weighted avg       0.93      0.98      0.95      4614\n",
      " samples avg       0.92      0.98      0.95      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5245, Accuracy: 0.7211, F1 Micro: 0.7211, F1 Macro: 0.419\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4352, Accuracy: 0.7211, F1 Micro: 0.7211, F1 Macro: 0.419\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3539, Accuracy: 0.7794, F1 Micro: 0.7794, F1 Macro: 0.6516\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2804, Accuracy: 0.7874, F1 Micro: 0.7874, F1 Macro: 0.6426\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2862, Accuracy: 0.8251, F1 Micro: 0.8251, F1 Macro: 0.7453\n",
      "Epoch 6/10, Train Loss: 0.2358, Accuracy: 0.8229, F1 Micro: 0.8229, F1 Macro: 0.7349\n",
      "Epoch 7/10, Train Loss: 0.1829, Accuracy: 0.8229, F1 Micro: 0.8229, F1 Macro: 0.7349\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1346, Accuracy: 0.8423, F1 Micro: 0.8423, F1 Macro: 0.7892\n",
      "Epoch 9/10, Train Loss: 0.1724, Accuracy: 0.7874, F1 Micro: 0.7874, F1 Macro: 0.6391\n",
      "Epoch 10/10, Train Loss: 0.1312, Accuracy: 0.8366, F1 Micro: 0.8366, F1 Macro: 0.7695\n",
      "\n",
      "Sentiment analysis accuracy: 0.8423, F1 Micro: 0.8423, F1 Macro: 0.7892\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.93      0.89       631\n",
      "    positive       0.78      0.61      0.68       244\n",
      "\n",
      "    accuracy                           0.84       875\n",
      "   macro avg       0.82      0.77      0.79       875\n",
      "weighted avg       0.84      0.84      0.84       875\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 357: Accuracy: 0.9075, F1 Micro: 0.9075, F1 Macro: 0.6421\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.90      0.91        97\n",
      "     neutral       0.98      0.99      0.98       459\n",
      "    positive       0.83      0.67      0.74        15\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.91      0.85      0.88       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.63      0.76        86\n",
      "     neutral       0.94      0.99      0.96       475\n",
      "    positive       0.42      0.50      0.45        10\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.77      0.71      0.72       571\n",
      "weighted avg       0.93      0.93      0.92       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.62      0.69        78\n",
      "     neutral       0.94      0.97      0.95       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.57      0.53      0.55       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.87      1.00      0.93       496\n",
      "    positive       1.00      0.01      0.03        68\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.62      0.34      0.32       571\n",
      "weighted avg       0.87      0.87      0.81       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.73      0.78       200\n",
      "     neutral       0.84      0.89      0.86       315\n",
      "    positive       0.66      0.68      0.67        56\n",
      "\n",
      "    accuracy                           0.81       571\n",
      "   macro avg       0.77      0.77      0.77       571\n",
      "weighted avg       0.81      0.81      0.81       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.59      0.70       162\n",
      "     neutral       0.86      0.96      0.91       387\n",
      "    positive       0.29      0.36      0.32        22\n",
      "\n",
      "    accuracy                           0.83       571\n",
      "   macro avg       0.67      0.64      0.64       571\n",
      "weighted avg       0.84      0.83      0.83       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.75      0.77        85\n",
      "     neutral       0.95      0.96      0.95       418\n",
      "    positive       0.81      0.76      0.79        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.85      0.83      0.84       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.03      0.07        29\n",
      "     neutral       0.93      1.00      0.96       525\n",
      "    positive       0.50      0.18      0.26        17\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.81      0.40      0.43       571\n",
      "weighted avg       0.92      0.92      0.89       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.52      0.66        54\n",
      "     neutral       0.95      1.00      0.98       511\n",
      "    positive       0.29      0.33      0.31         6\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.71      0.62      0.65       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.86      0.90        74\n",
      "     neutral       0.98      1.00      0.99       494\n",
      "    positive       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.64      0.62      0.63       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Total train time: 126.25938439369202 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 193\n",
      "Sampling duration: 56.21826720237732 seconds\n",
      "New train size: 550\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5352, Accuracy: 0.8009, F1 Micro: 0.8894, F1 Macro: 0.885\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4729, Accuracy: 0.8042, F1 Micro: 0.8907, F1 Macro: 0.8857\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.4259, Accuracy: 0.8323, F1 Micro: 0.9044, F1 Macro: 0.8989\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3687, Accuracy: 0.8898, F1 Micro: 0.9344, F1 Macro: 0.9292\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.309, Accuracy: 0.9075, F1 Micro: 0.9447, F1 Macro: 0.9408\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.2509, Accuracy: 0.9222, F1 Micro: 0.953, F1 Macro: 0.9497\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.2196, Accuracy: 0.9328, F1 Micro: 0.959, F1 Macro: 0.9553\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1921, Accuracy: 0.937, F1 Micro: 0.9616, F1 Macro: 0.9582\n",
      "Epoch 9/10, Train Loss: 0.158, Accuracy: 0.9366, F1 Micro: 0.9614, F1 Macro: 0.9583\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1371, Accuracy: 0.9384, F1 Micro: 0.9624, F1 Macro: 0.9588\n",
      "\n",
      "Aspect detection accuracy: 0.9384, F1 Micro: 0.9624, F1 Macro: 0.9588\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.98      0.99      0.99       462\n",
      "   air_panas       0.96      0.99      0.97       480\n",
      "         bau       0.94      0.99      0.97       496\n",
      "     general       0.92      0.99      0.95       500\n",
      "  kebersihan       0.88      0.89      0.89       317\n",
      "       linen       0.84      0.99      0.91       392\n",
      "     service       0.95      0.97      0.96       423\n",
      "sunrise_meal       0.95      1.00      0.98       530\n",
      "          tv       0.98      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.94      0.98      0.96      4614\n",
      "   macro avg       0.94      0.98      0.96      4614\n",
      "weighted avg       0.94      0.98      0.96      4614\n",
      " samples avg       0.94      0.98      0.96      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.538, Accuracy: 0.7152, F1 Micro: 0.7152, F1 Macro: 0.417\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3689, Accuracy: 0.8501, F1 Micro: 0.8501, F1 Macro: 0.7987\n",
      "Epoch 3/10, Train Loss: 0.2632, Accuracy: 0.848, F1 Micro: 0.848, F1 Macro: 0.7834\n",
      "Epoch 4/10, Train Loss: 0.235, Accuracy: 0.8458, F1 Micro: 0.8458, F1 Macro: 0.7773\n",
      "Epoch 5/10, Train Loss: 0.1788, Accuracy: 0.8415, F1 Micro: 0.8415, F1 Macro: 0.7688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1633, Accuracy: 0.863, F1 Micro: 0.863, F1 Macro: 0.8079\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1269, Accuracy: 0.8779, F1 Micro: 0.8779, F1 Macro: 0.8351\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1054, Accuracy: 0.8801, F1 Micro: 0.8801, F1 Macro: 0.8421\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0735, Accuracy: 0.8844, F1 Micro: 0.8844, F1 Macro: 0.8429\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0975, Accuracy: 0.8844, F1 Micro: 0.8844, F1 Macro: 0.8498\n",
      "\n",
      "Sentiment analysis accuracy: 0.8844, F1 Micro: 0.8844, F1 Macro: 0.8498\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.95      0.92       668\n",
      "    positive       0.86      0.71      0.78       266\n",
      "\n",
      "    accuracy                           0.88       934\n",
      "   macro avg       0.88      0.83      0.85       934\n",
      "weighted avg       0.88      0.88      0.88       934\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 550: Accuracy: 0.9289, F1 Micro: 0.9289, F1 Macro: 0.7429\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.92      0.93        97\n",
      "     neutral       0.98      0.99      0.99       459\n",
      "    positive       0.85      0.73      0.79        15\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.93      0.88      0.90       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.74      0.83        86\n",
      "     neutral       0.96      0.99      0.97       475\n",
      "    positive       0.50      0.50      0.50        10\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.79      0.74      0.77       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.65      0.76        78\n",
      "     neutral       0.94      0.99      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.55      0.57       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.92      0.99      0.95       496\n",
      "    positive       0.88      0.44      0.59        68\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.60      0.48      0.51       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.78      0.80       200\n",
      "     neutral       0.88      0.89      0.89       315\n",
      "    positive       0.71      0.82      0.76        56\n",
      "\n",
      "    accuracy                           0.84       571\n",
      "   macro avg       0.81      0.83      0.82       571\n",
      "weighted avg       0.85      0.84      0.84       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.62      0.74       162\n",
      "     neutral       0.84      0.99      0.91       387\n",
      "    positive       0.62      0.23      0.33        22\n",
      "\n",
      "    accuracy                           0.85       571\n",
      "   macro avg       0.79      0.61      0.66       571\n",
      "weighted avg       0.85      0.85      0.84       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.71      0.78        85\n",
      "     neutral       0.95      0.97      0.96       418\n",
      "    positive       0.81      0.88      0.85        68\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.85      0.86       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.24      0.37        29\n",
      "     neutral       0.95      1.00      0.97       525\n",
      "    positive       0.75      0.53      0.62        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.83      0.59      0.65       571\n",
      "weighted avg       0.94      0.95      0.93       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.78      0.82        54\n",
      "     neutral       0.98      1.00      0.99       511\n",
      "    positive       1.00      0.33      0.50         6\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.95      0.70      0.77       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.92      0.94        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.98      0.86      0.91       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Total train time: 152.38699746131897 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 174\n",
      "Sampling duration: 53.73532772064209 seconds\n",
      "New train size: 724\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5209, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4596, Accuracy: 0.8122, F1 Micro: 0.8946, F1 Macro: 0.8892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.415, Accuracy: 0.8602, F1 Micro: 0.9192, F1 Macro: 0.9154\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.3375, Accuracy: 0.8995, F1 Micro: 0.9402, F1 Macro: 0.9366\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2608, Accuracy: 0.9264, F1 Micro: 0.9555, F1 Macro: 0.9522\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.225, Accuracy: 0.9378, F1 Micro: 0.9621, F1 Macro: 0.9591\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1883, Accuracy: 0.9427, F1 Micro: 0.965, F1 Macro: 0.962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1594, Accuracy: 0.9427, F1 Micro: 0.965, F1 Macro: 0.9622\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1429, Accuracy: 0.946, F1 Micro: 0.9669, F1 Macro: 0.964\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1229, Accuracy: 0.9509, F1 Micro: 0.9697, F1 Macro: 0.9665\n",
      "\n",
      "Aspect detection accuracy: 0.9509, F1 Micro: 0.9697, F1 Macro: 0.9665\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.96      0.99      0.98       480\n",
      "         bau       0.95      0.99      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.88      0.91      0.90       317\n",
      "       linen       0.91      0.96      0.93       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.96      1.00      0.98       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       0.99      1.00      0.99       498\n",
      "\n",
      "   micro avg       0.96      0.98      0.97      4614\n",
      "   macro avg       0.95      0.98      0.97      4614\n",
      "weighted avg       0.96      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5408, Accuracy: 0.8137, F1 Micro: 0.8137, F1 Macro: 0.7256\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3286, Accuracy: 0.8235, F1 Micro: 0.8235, F1 Macro: 0.7434\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2713, Accuracy: 0.8765, F1 Micro: 0.8765, F1 Macro: 0.8435\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1754, Accuracy: 0.8892, F1 Micro: 0.8892, F1 Macro: 0.8579\n",
      "Epoch 5/10, Train Loss: 0.191, Accuracy: 0.8814, F1 Micro: 0.8814, F1 Macro: 0.8424\n",
      "Epoch 6/10, Train Loss: 0.1158, Accuracy: 0.8863, F1 Micro: 0.8863, F1 Macro: 0.8492\n",
      "Epoch 7/10, Train Loss: 0.0905, Accuracy: 0.8833, F1 Micro: 0.8833, F1 Macro: 0.8466\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.086, Accuracy: 0.8971, F1 Micro: 0.8971, F1 Macro: 0.8695\n",
      "Epoch 9/10, Train Loss: 0.0643, Accuracy: 0.8922, F1 Micro: 0.8922, F1 Macro: 0.8664\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0605, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8863\n",
      "\n",
      "Sentiment analysis accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8863\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       717\n",
      "    positive       0.92      0.77      0.83       303\n",
      "\n",
      "    accuracy                           0.91      1020\n",
      "   macro avg       0.91      0.87      0.89      1020\n",
      "weighted avg       0.91      0.91      0.91      1020\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 724: Accuracy: 0.9445, F1 Micro: 0.9445, F1 Macro: 0.8254\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.95      0.94       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.81      0.87        86\n",
      "     neutral       0.96      0.99      0.98       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.84      0.77      0.80       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.69      0.78        78\n",
      "     neutral       0.95      0.99      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.95      0.73      0.80       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.57      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.81      0.84       200\n",
      "     neutral       0.89      0.91      0.90       315\n",
      "    positive       0.80      0.86      0.83        56\n",
      "\n",
      "    accuracy                           0.87       571\n",
      "   macro avg       0.85      0.86      0.86       571\n",
      "weighted avg       0.87      0.87      0.87       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.77      0.82       162\n",
      "     neutral       0.90      0.96      0.93       387\n",
      "    positive       0.53      0.45      0.49        22\n",
      "\n",
      "    accuracy                           0.88       571\n",
      "   macro avg       0.77      0.73      0.74       571\n",
      "weighted avg       0.88      0.88      0.88       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.81      0.85        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.91      0.90      0.90        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.90      0.91       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.28      0.42        29\n",
      "     neutral       0.96      1.00      0.98       525\n",
      "    positive       0.69      0.65      0.67        17\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.85      0.64      0.69       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.91      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        74\n",
      "     neutral       0.99      1.00      0.99       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 176.47131180763245 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 156\n",
      "Sampling duration: 48.92389392852783 seconds\n",
      "New train size: 880\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5181, Accuracy: 0.8007, F1 Micro: 0.8893, F1 Macro: 0.8849\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4496, Accuracy: 0.8288, F1 Micro: 0.9029, F1 Macro: 0.8979\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3692, Accuracy: 0.896, F1 Micro: 0.9381, F1 Macro: 0.9345\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.283, Accuracy: 0.9175, F1 Micro: 0.9503, F1 Macro: 0.9471\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.228, Accuracy: 0.9295, F1 Micro: 0.9574, F1 Macro: 0.9549\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1989, Accuracy: 0.9502, F1 Micro: 0.9693, F1 Macro: 0.9662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1681, Accuracy: 0.9512, F1 Micro: 0.97, F1 Macro: 0.967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1463, Accuracy: 0.9556, F1 Micro: 0.9725, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1232, Accuracy: 0.9571, F1 Micro: 0.9735, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.1058, Accuracy: 0.9573, F1 Micro: 0.9737, F1 Macro: 0.9712\n",
      "\n",
      "Aspect detection accuracy: 0.9573, F1 Micro: 0.9737, F1 Macro: 0.9712\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.97      0.99      0.98       480\n",
      "         bau       0.95      0.99      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.90      0.94      0.92       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      1.00      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.96      0.99      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.96      0.99      0.97      4614\n",
      " samples avg       0.96      0.99      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5218, Accuracy: 0.8063, F1 Micro: 0.8063, F1 Macro: 0.6851\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3228, Accuracy: 0.8659, F1 Micro: 0.8659, F1 Macro: 0.8105\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.239, Accuracy: 0.8963, F1 Micro: 0.8963, F1 Macro: 0.8675\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.185, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.137, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8871\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1046, Accuracy: 0.9159, F1 Micro: 0.9159, F1 Macro: 0.8915\n",
      "Epoch 7/10, Train Loss: 0.0996, Accuracy: 0.9129, F1 Micro: 0.9129, F1 Macro: 0.8862\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0529, Accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.8961\n",
      "Epoch 9/10, Train Loss: 0.0437, Accuracy: 0.9188, F1 Micro: 0.9188, F1 Macro: 0.8936\n",
      "Epoch 10/10, Train Loss: 0.0499, Accuracy: 0.911, F1 Micro: 0.911, F1 Macro: 0.8862\n",
      "\n",
      "Sentiment analysis accuracy: 0.9198, F1 Micro: 0.9198, F1 Macro: 0.8961\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       732\n",
      "    positive       0.93      0.78      0.85       290\n",
      "\n",
      "    accuracy                           0.92      1022\n",
      "   macro avg       0.92      0.88      0.90      1022\n",
      "weighted avg       0.92      0.92      0.92      1022\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 880: Accuracy: 0.9506, F1 Micro: 0.9506, F1 Macro: 0.8341\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.85      0.90        86\n",
      "     neutral       0.97      0.99      0.98       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.78      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.68      0.77        78\n",
      "     neutral       0.95      0.99      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.95      0.72      0.80       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.85      0.66      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.55      0.57       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87       200\n",
      "     neutral       0.90      0.94      0.92       315\n",
      "    positive       0.89      0.84      0.86        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.88      0.88       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.80      0.84       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.59      0.45      0.51        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.80      0.74      0.77       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.81      0.84        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.94      0.88      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.89      0.91       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.34      0.50        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.89      0.74      0.77       571\n",
      "weighted avg       0.96      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.98      0.89      0.93        54\n",
      "     neutral       0.99      1.00      0.99       511\n",
      "    positive       0.75      1.00      0.86         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.96      0.93       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.96      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 200.7514705657959 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 141\n",
      "Sampling duration: 44.453798055648804 seconds\n",
      "New train size: 1021\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5154, Accuracy: 0.801, F1 Micro: 0.8894, F1 Macro: 0.8846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4424, Accuracy: 0.8575, F1 Micro: 0.9174, F1 Macro: 0.9127\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3336, Accuracy: 0.9089, F1 Micro: 0.9455, F1 Macro: 0.9422\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2582, Accuracy: 0.9344, F1 Micro: 0.96, F1 Macro: 0.9568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.2109, Accuracy: 0.9472, F1 Micro: 0.9676, F1 Macro: 0.9646\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1775, Accuracy: 0.953, F1 Micro: 0.9709, F1 Macro: 0.9678\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1511, Accuracy: 0.9547, F1 Micro: 0.972, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1302, Accuracy: 0.9552, F1 Micro: 0.9723, F1 Macro: 0.9693\n",
      "Epoch 9/10, Train Loss: 0.1096, Accuracy: 0.9547, F1 Micro: 0.9721, F1 Macro: 0.9695\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0947, Accuracy: 0.9589, F1 Micro: 0.9746, F1 Macro: 0.9719\n",
      "\n",
      "Aspect detection accuracy: 0.9589, F1 Micro: 0.9746, F1 Macro: 0.9719\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.93      0.91      0.92       317\n",
      "       linen       0.90      0.98      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.97      4614\n",
      " samples avg       0.96      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4723, Accuracy: 0.8449, F1 Micro: 0.8449, F1 Macro: 0.7846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2998, Accuracy: 0.8801, F1 Micro: 0.8801, F1 Macro: 0.8369\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2244, Accuracy: 0.8896, F1 Micro: 0.8896, F1 Macro: 0.8585\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1938, Accuracy: 0.9001, F1 Micro: 0.9001, F1 Macro: 0.8729\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1257, Accuracy: 0.9049, F1 Micro: 0.9049, F1 Macro: 0.8763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0833, Accuracy: 0.9058, F1 Micro: 0.9058, F1 Macro: 0.8765\n",
      "Epoch 7/10, Train Loss: 0.0766, Accuracy: 0.9049, F1 Micro: 0.9049, F1 Macro: 0.8739\n",
      "Epoch 8/10, Train Loss: 0.0478, Accuracy: 0.8963, F1 Micro: 0.8963, F1 Macro: 0.8623\n",
      "Epoch 9/10, Train Loss: 0.044, Accuracy: 0.9049, F1 Micro: 0.9049, F1 Macro: 0.8774\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0252, Accuracy: 0.9096, F1 Micro: 0.9096, F1 Macro: 0.8815\n",
      "\n",
      "Sentiment analysis accuracy: 0.9096, F1 Micro: 0.9096, F1 Macro: 0.8815\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       753\n",
      "    positive       0.92      0.74      0.82       298\n",
      "\n",
      "    accuracy                           0.91      1051\n",
      "   macro avg       0.91      0.86      0.88      1051\n",
      "weighted avg       0.91      0.91      0.91      1051\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1021: Accuracy: 0.9518, F1 Micro: 0.9518, F1 Macro: 0.833\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.57      0.40      0.47        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.75      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.74      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.74      0.81       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.89      0.59      0.71        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.61      0.53      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.88      0.87       200\n",
      "     neutral       0.93      0.91      0.92       315\n",
      "    positive       0.82      0.89      0.85        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.87      0.89      0.88       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.79      0.84       162\n",
      "     neutral       0.90      0.98      0.94       387\n",
      "    positive       0.73      0.36      0.48        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.85      0.71      0.76       571\n",
      "weighted avg       0.90      0.90      0.89       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.84      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.89      0.93      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.55      0.67        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.94      0.97      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.96      0.96        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.87      0.87      0.87       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 221.57194805145264 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 127\n",
      "Sampling duration: 40.27713632583618 seconds\n",
      "New train size: 1148\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5123, Accuracy: 0.801, F1 Micro: 0.8895, F1 Macro: 0.8852\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4242, Accuracy: 0.8674, F1 Micro: 0.9222, F1 Macro: 0.916\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.3217, Accuracy: 0.925, F1 Micro: 0.9546, F1 Macro: 0.9513\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2437, Accuracy: 0.9325, F1 Micro: 0.9591, F1 Macro: 0.9566\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.195, Accuracy: 0.954, F1 Micro: 0.9716, F1 Macro: 0.9687\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1629, Accuracy: 0.9568, F1 Micro: 0.9733, F1 Macro: 0.9709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1439, Accuracy: 0.9569, F1 Micro: 0.9734, F1 Macro: 0.9708\n",
      "Epoch 8/10, Train Loss: 0.1243, Accuracy: 0.9564, F1 Micro: 0.9732, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.1065, Accuracy: 0.9595, F1 Micro: 0.975, F1 Macro: 0.9724\n",
      "Epoch 10/10, Train Loss: 0.0942, Accuracy: 0.959, F1 Micro: 0.9746, F1 Macro: 0.9719\n",
      "\n",
      "Aspect detection accuracy: 0.9595, F1 Micro: 0.975, F1 Macro: 0.9724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.98       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.92      0.92      0.92       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.97      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4653, Accuracy: 0.854, F1 Micro: 0.854, F1 Macro: 0.8135\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3059, Accuracy: 0.8644, F1 Micro: 0.8644, F1 Macro: 0.8331\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2087, Accuracy: 0.8974, F1 Micro: 0.8974, F1 Macro: 0.8658\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1586, Accuracy: 0.8983, F1 Micro: 0.8983, F1 Macro: 0.8662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1117, Accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8825\n",
      "Epoch 6/10, Train Loss: 0.0872, Accuracy: 0.9002, F1 Micro: 0.9002, F1 Macro: 0.869\n",
      "Epoch 7/10, Train Loss: 0.0541, Accuracy: 0.903, F1 Micro: 0.903, F1 Macro: 0.8747\n",
      "Epoch 8/10, Train Loss: 0.0616, Accuracy: 0.903, F1 Micro: 0.903, F1 Macro: 0.8758\n",
      "Epoch 9/10, Train Loss: 0.0436, Accuracy: 0.9058, F1 Micro: 0.9058, F1 Macro: 0.8785\n",
      "Epoch 10/10, Train Loss: 0.0289, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.8804\n",
      "\n",
      "Sentiment analysis accuracy: 0.9077, F1 Micro: 0.9077, F1 Macro: 0.8825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       753\n",
      "    positive       0.90      0.76      0.83       309\n",
      "\n",
      "    accuracy                           0.91      1062\n",
      "   macro avg       0.91      0.87      0.88      1062\n",
      "weighted avg       0.91      0.91      0.91      1062\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1148: Accuracy: 0.9529, F1 Micro: 0.9529, F1 Macro: 0.8379\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.86      0.90        86\n",
      "     neutral       0.98      0.99      0.98       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.83      0.78      0.80       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.81      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.87      0.68      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.55      0.57       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87       200\n",
      "     neutral       0.92      0.92      0.92       315\n",
      "    positive       0.83      0.96      0.89        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.88      0.91      0.90       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.81      0.84       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       0.85      0.50      0.63        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.76      0.81       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.81      0.85        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.90      0.93      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.91      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.34      0.49        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.74      0.75       571\n",
      "weighted avg       0.96      0.96      0.95       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       0.86      1.00      0.92         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.94      0.97      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.95      0.96        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.60      1.00      0.75         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.86      0.98      0.90       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 237.6823387145996 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 114\n",
      "Sampling duration: 36.57068705558777 seconds\n",
      "New train size: 1262\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5021, Accuracy: 0.8057, F1 Micro: 0.8916, F1 Macro: 0.8866\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.4056, Accuracy: 0.8885, F1 Micro: 0.9332, F1 Macro: 0.9269\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2965, Accuracy: 0.9319, F1 Micro: 0.9585, F1 Macro: 0.9551\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2206, Accuracy: 0.947, F1 Micro: 0.9675, F1 Macro: 0.9648\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1785, Accuracy: 0.953, F1 Micro: 0.971, F1 Macro: 0.968\n",
      "Epoch 6/10, Train Loss: 0.1511, Accuracy: 0.9517, F1 Micro: 0.9703, F1 Macro: 0.968\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1298, Accuracy: 0.9583, F1 Micro: 0.9742, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1091, Accuracy: 0.9594, F1 Micro: 0.9749, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0974, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9726\n",
      "Epoch 10/10, Train Loss: 0.0846, Accuracy: 0.9592, F1 Micro: 0.9748, F1 Macro: 0.9721\n",
      "\n",
      "Aspect detection accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9726\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.99      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.91      0.94      0.92       317\n",
      "       linen       0.94      0.95      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4774, Accuracy: 0.8532, F1 Micro: 0.8532, F1 Macro: 0.7895\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2778, Accuracy: 0.8816, F1 Micro: 0.8816, F1 Macro: 0.8472\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2165, Accuracy: 0.9072, F1 Micro: 0.9072, F1 Macro: 0.8769\n",
      "Epoch 4/10, Train Loss: 0.1752, Accuracy: 0.8996, F1 Micro: 0.8996, F1 Macro: 0.8648\n",
      "Epoch 5/10, Train Loss: 0.119, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8782\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0964, Accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.888\n",
      "Epoch 7/10, Train Loss: 0.0692, Accuracy: 0.9053, F1 Micro: 0.9053, F1 Macro: 0.8756\n",
      "Epoch 8/10, Train Loss: 0.0556, Accuracy: 0.9025, F1 Micro: 0.9025, F1 Macro: 0.8698\n",
      "Epoch 9/10, Train Loss: 0.0442, Accuracy: 0.9138, F1 Micro: 0.9138, F1 Macro: 0.8893\n",
      "Epoch 10/10, Train Loss: 0.0371, Accuracy: 0.9119, F1 Micro: 0.9119, F1 Macro: 0.885\n",
      "\n",
      "Sentiment analysis accuracy: 0.9148, F1 Micro: 0.9148, F1 Macro: 0.888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       755\n",
      "    positive       0.94      0.75      0.83       301\n",
      "\n",
      "    accuracy                           0.91      1056\n",
      "   macro avg       0.92      0.86      0.89      1056\n",
      "weighted avg       0.92      0.91      0.91      1056\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1262: Accuracy: 0.9541, F1 Micro: 0.9541, F1 Macro: 0.8308\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.87      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.80      0.40      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.90      0.76      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.73      0.80        78\n",
      "     neutral       0.96      0.99      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.62      0.57      0.59       571\n",
      "weighted avg       0.94      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.86      0.62      0.72        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.53      0.56       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.85      0.88       200\n",
      "     neutral       0.91      0.94      0.92       315\n",
      "    positive       0.88      0.89      0.88        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.90      0.89      0.89       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.86       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.87      0.76      0.80       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.85      0.86        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.52      0.64        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.75      0.88      0.81        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 250.70054721832275 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 103\n",
      "Sampling duration: 33.06359577178955 seconds\n",
      "New train size: 1365\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.5037, Accuracy: 0.8142, F1 Micro: 0.893, F1 Macro: 0.8781\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3892, Accuracy: 0.9026, F1 Micro: 0.9418, F1 Macro: 0.9372\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.266, Accuracy: 0.9352, F1 Micro: 0.9607, F1 Macro: 0.9584\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.2145, Accuracy: 0.9457, F1 Micro: 0.9668, F1 Macro: 0.9641\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.18, Accuracy: 0.9545, F1 Micro: 0.972, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1473, Accuracy: 0.9589, F1 Micro: 0.9745, F1 Macro: 0.9721\n",
      "Epoch 7/10, Train Loss: 0.1251, Accuracy: 0.9569, F1 Micro: 0.9734, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.1083, Accuracy: 0.9608, F1 Micro: 0.9756, F1 Macro: 0.9729\n",
      "Epoch 9/10, Train Loss: 0.0925, Accuracy: 0.9595, F1 Micro: 0.9749, F1 Macro: 0.9722\n",
      "Epoch 10/10, Train Loss: 0.0799, Accuracy: 0.9592, F1 Micro: 0.9747, F1 Macro: 0.9723\n",
      "\n",
      "Aspect detection accuracy: 0.9608, F1 Micro: 0.9756, F1 Macro: 0.9729\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.90      0.92       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4622, Accuracy: 0.8009, F1 Micro: 0.8009, F1 Macro: 0.699\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.291, Accuracy: 0.8733, F1 Micro: 0.8733, F1 Macro: 0.8364\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2223, Accuracy: 0.8733, F1 Micro: 0.8733, F1 Macro: 0.8306\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1752, Accuracy: 0.8968, F1 Micro: 0.8968, F1 Macro: 0.8679\n",
      "Epoch 5/10, Train Loss: 0.1205, Accuracy: 0.8959, F1 Micro: 0.8959, F1 Macro: 0.8666\n",
      "Epoch 6/10, Train Loss: 0.0925, Accuracy: 0.8878, F1 Micro: 0.8878, F1 Macro: 0.8534\n",
      "Epoch 7/10, Train Loss: 0.0719, Accuracy: 0.8932, F1 Micro: 0.8932, F1 Macro: 0.8611\n",
      "Epoch 8/10, Train Loss: 0.0495, Accuracy: 0.8941, F1 Micro: 0.8941, F1 Macro: 0.8649\n",
      "Epoch 9/10, Train Loss: 0.0352, Accuracy: 0.8941, F1 Micro: 0.8941, F1 Macro: 0.8671\n",
      "Epoch 10/10, Train Loss: 0.043, Accuracy: 0.8896, F1 Micro: 0.8896, F1 Macro: 0.8599\n",
      "\n",
      "Sentiment analysis accuracy: 0.8968, F1 Micro: 0.8968, F1 Macro: 0.8679\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.98      0.93       771\n",
      "    positive       0.93      0.71      0.81       334\n",
      "\n",
      "    accuracy                           0.90      1105\n",
      "   macro avg       0.91      0.84      0.87      1105\n",
      "weighted avg       0.90      0.90      0.89      1105\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1365: Accuracy: 0.9541, F1 Micro: 0.9541, F1 Macro: 0.8357\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.87      0.89        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.79      0.82       571\n",
      "weighted avg       0.96      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.79      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.59      0.59      0.59       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.72      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.77      0.61      0.66       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.90      0.88       200\n",
      "     neutral       0.95      0.90      0.92       315\n",
      "    positive       0.85      0.98      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.93      0.90       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.84      0.85       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.74      0.79       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.84      0.85        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.89      0.96      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.92      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.55      0.64        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.71      0.71        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.82      0.75      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.92      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 265.3300006389618 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1427\n",
      "Acquired samples: 62\n",
      "Sampling duration: 29.837290048599243 seconds\n",
      "New train size: 1427\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4974, Accuracy: 0.8168, F1 Micro: 0.8968, F1 Macro: 0.8926\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3778, Accuracy: 0.9064, F1 Micro: 0.9442, F1 Macro: 0.9407\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2591, Accuracy: 0.9378, F1 Micro: 0.9622, F1 Macro: 0.9598\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1973, Accuracy: 0.9483, F1 Micro: 0.9683, F1 Macro: 0.966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1677, Accuracy: 0.9542, F1 Micro: 0.9718, F1 Macro: 0.9691\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.137, Accuracy: 0.9578, F1 Micro: 0.9739, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1173, Accuracy: 0.9594, F1 Micro: 0.9748, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0983, Accuracy: 0.9608, F1 Micro: 0.9758, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0881, Accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9737\n",
      "Epoch 10/10, Train Loss: 0.0741, Accuracy: 0.9597, F1 Micro: 0.975, F1 Macro: 0.9727\n",
      "\n",
      "Aspect detection accuracy: 0.9611, F1 Micro: 0.9759, F1 Macro: 0.9737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.90      0.96      0.93       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.97      0.96      0.97       423\n",
      "sunrise_meal       0.97      1.00      0.98       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.96      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4626, Accuracy: 0.8615, F1 Micro: 0.8615, F1 Macro: 0.8217\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2885, Accuracy: 0.8615, F1 Micro: 0.8615, F1 Macro: 0.8075\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2123, Accuracy: 0.9089, F1 Micro: 0.9089, F1 Macro: 0.8827\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1384, Accuracy: 0.9203, F1 Micro: 0.9203, F1 Macro: 0.8988\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1107, Accuracy: 0.9203, F1 Micro: 0.9203, F1 Macro: 0.8979\n",
      "Epoch 6/10, Train Loss: 0.086, Accuracy: 0.9127, F1 Micro: 0.9127, F1 Macro: 0.8879\n",
      "Epoch 7/10, Train Loss: 0.0648, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8872\n",
      "Epoch 8/10, Train Loss: 0.047, Accuracy: 0.9184, F1 Micro: 0.9184, F1 Macro: 0.8947\n",
      "Epoch 9/10, Train Loss: 0.0212, Accuracy: 0.9089, F1 Micro: 0.9089, F1 Macro: 0.8856\n",
      "Epoch 10/10, Train Loss: 0.0334, Accuracy: 0.9137, F1 Micro: 0.9137, F1 Macro: 0.8897\n",
      "\n",
      "Sentiment analysis accuracy: 0.9203, F1 Micro: 0.9203, F1 Macro: 0.8979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.95       747\n",
      "    positive       0.94      0.78      0.85       307\n",
      "\n",
      "    accuracy                           0.92      1054\n",
      "   macro avg       0.93      0.88      0.90      1054\n",
      "weighted avg       0.92      0.92      0.92      1054\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1427: Accuracy: 0.9553, F1 Micro: 0.9553, F1 Macro: 0.8659\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.87      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.74      0.80        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.75      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.58      0.59       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.81      0.86       200\n",
      "     neutral       0.90      0.96      0.92       315\n",
      "    positive       0.87      0.93      0.90        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.90      0.89       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.88      0.74      0.79       571\n",
      "weighted avg       0.91      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.87      0.87        85\n",
      "     neutral       0.97      0.97      0.97       418\n",
      "    positive       0.93      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.45      0.59        29\n",
      "     neutral       0.97      1.00      0.98       525\n",
      "    positive       0.76      0.76      0.76        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.87      0.74      0.78       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 275.8302733898163 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 86\n",
      "Sampling duration: 27.86815643310547 seconds\n",
      "New train size: 1513\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4929, Accuracy: 0.8236, F1 Micro: 0.9005, F1 Macro: 0.8967\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3558, Accuracy: 0.92, F1 Micro: 0.9515, F1 Macro: 0.9477\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2444, Accuracy: 0.9422, F1 Micro: 0.9647, F1 Macro: 0.9623\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1951, Accuracy: 0.949, F1 Micro: 0.9687, F1 Macro: 0.9666\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1611, Accuracy: 0.9589, F1 Micro: 0.9745, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1368, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9736\n",
      "Epoch 7/10, Train Loss: 0.1125, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.973\n",
      "Epoch 8/10, Train Loss: 0.0979, Accuracy: 0.9599, F1 Micro: 0.9752, F1 Macro: 0.9725\n",
      "Epoch 9/10, Train Loss: 0.0829, Accuracy: 0.9595, F1 Micro: 0.975, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0724, Accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9737\n",
      "\n",
      "Aspect detection accuracy: 0.9616, F1 Micro: 0.9762, F1 Macro: 0.9737\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.94      0.98      0.96       500\n",
      "  kebersihan       0.92      0.92      0.92       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       1.00      0.99      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.43, Accuracy: 0.8475, F1 Micro: 0.8475, F1 Macro: 0.8059\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2591, Accuracy: 0.8799, F1 Micro: 0.8799, F1 Macro: 0.8459\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1945, Accuracy: 0.8993, F1 Micro: 0.8993, F1 Macro: 0.8682\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.144, Accuracy: 0.9039, F1 Micro: 0.9039, F1 Macro: 0.8767\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1158, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8791\n",
      "Epoch 6/10, Train Loss: 0.0748, Accuracy: 0.8983, F1 Micro: 0.8983, F1 Macro: 0.8672\n",
      "Epoch 7/10, Train Loss: 0.052, Accuracy: 0.8983, F1 Micro: 0.8983, F1 Macro: 0.8702\n",
      "Epoch 8/10, Train Loss: 0.0463, Accuracy: 0.8993, F1 Micro: 0.8993, F1 Macro: 0.8709\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0415, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8766\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0218, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8788\n",
      "\n",
      "Sentiment analysis accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.97      0.93       765\n",
      "    positive       0.91      0.75      0.82       317\n",
      "\n",
      "    accuracy                           0.90      1082\n",
      "   macro avg       0.90      0.86      0.88      1082\n",
      "weighted avg       0.90      0.90      0.90      1082\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1513: Accuracy: 0.9543, F1 Micro: 0.9543, F1 Macro: 0.8648\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.86      0.89        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.87      0.78      0.82       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.78      0.80        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.98      0.96       496\n",
      "    positive       0.85      0.66      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.60      0.55      0.57       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.85      0.87       200\n",
      "     neutral       0.92      0.92      0.92       315\n",
      "    positive       0.83      0.98      0.90        56\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.88      0.92      0.90       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.82      0.85       162\n",
      "     neutral       0.94      0.97      0.95       387\n",
      "    positive       0.55      0.50      0.52        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.79      0.76      0.77       571\n",
      "weighted avg       0.90      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.84      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.90      0.90      0.90        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.90      0.91       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.48      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.94      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.81      0.80       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.96      0.96        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      1.00      0.98        74\n",
      "     neutral       1.00      0.99      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 290.1996374130249 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 77\n",
      "Sampling duration: 25.32650065422058 seconds\n",
      "New train size: 1590\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4852, Accuracy: 0.8306, F1 Micro: 0.9029, F1 Macro: 0.8955\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3499, Accuracy: 0.9071, F1 Micro: 0.9446, F1 Macro: 0.941\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2381, Accuracy: 0.945, F1 Micro: 0.9663, F1 Macro: 0.9637\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1873, Accuracy: 0.9554, F1 Micro: 0.9725, F1 Macro: 0.9697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1583, Accuracy: 0.9568, F1 Micro: 0.9733, F1 Macro: 0.9706\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1356, Accuracy: 0.9595, F1 Micro: 0.9749, F1 Macro: 0.9721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1122, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0953, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9744\n",
      "Epoch 9/10, Train Loss: 0.0804, Accuracy: 0.9625, F1 Micro: 0.9768, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0715, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.975\n",
      "\n",
      "Aspect detection accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.94      0.93      0.93       317\n",
      "       linen       0.93      0.96      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4382, Accuracy: 0.8578, F1 Micro: 0.8578, F1 Macro: 0.8148\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2884, Accuracy: 0.8831, F1 Micro: 0.8831, F1 Macro: 0.8418\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1808, Accuracy: 0.9074, F1 Micro: 0.9074, F1 Macro: 0.8784\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1437, Accuracy: 0.9083, F1 Micro: 0.9083, F1 Macro: 0.8789\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0968, Accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.8963\n",
      "Epoch 6/10, Train Loss: 0.076, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8852\n",
      "Epoch 7/10, Train Loss: 0.0489, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.886\n",
      "Epoch 8/10, Train Loss: 0.0434, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8827\n",
      "Epoch 9/10, Train Loss: 0.0373, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8807\n",
      "Epoch 10/10, Train Loss: 0.0426, Accuracy: 0.9111, F1 Micro: 0.9111, F1 Macro: 0.8819\n",
      "\n",
      "Sentiment analysis accuracy: 0.9205, F1 Micro: 0.9205, F1 Macro: 0.8963\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.98      0.95       767\n",
      "    positive       0.93      0.77      0.85       302\n",
      "\n",
      "    accuracy                           0.92      1069\n",
      "   macro avg       0.92      0.88      0.90      1069\n",
      "weighted avg       0.92      0.92      0.92      1069\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1590: Accuracy: 0.9576, F1 Micro: 0.9576, F1 Macro: 0.8742\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.86      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.77      0.80        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.88      0.63      0.74        68\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.61      0.54      0.57       571\n",
      "weighted avg       0.92      0.93      0.92       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.86      0.96      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.83      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       0.68      0.59      0.63        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.84      0.79      0.81       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.85      0.88        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.91      0.91      0.91        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.82      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.96      0.96        54\n",
      "     neutral       1.00      1.00      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 298.08566880226135 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 70\n",
      "Sampling duration: 22.932844161987305 seconds\n",
      "New train size: 1660\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.488, Accuracy: 0.8274, F1 Micro: 0.9021, F1 Macro: 0.898\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3389, Accuracy: 0.92, F1 Micro: 0.9517, F1 Macro: 0.9476\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2382, Accuracy: 0.9448, F1 Micro: 0.9662, F1 Macro: 0.9636\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1853, Accuracy: 0.9543, F1 Micro: 0.9718, F1 Macro: 0.9692\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1531, Accuracy: 0.9583, F1 Micro: 0.9742, F1 Macro: 0.9717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1307, Accuracy: 0.9602, F1 Micro: 0.9753, F1 Macro: 0.9726\n",
      "Epoch 7/10, Train Loss: 0.115, Accuracy: 0.9595, F1 Micro: 0.975, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0952, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9737\n",
      "Epoch 9/10, Train Loss: 0.0807, Accuracy: 0.9587, F1 Micro: 0.9745, F1 Macro: 0.972\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0692, Accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9746\n",
      "\n",
      "Aspect detection accuracy: 0.9628, F1 Micro: 0.977, F1 Macro: 0.9746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.94      0.93      0.93       317\n",
      "       linen       0.91      0.97      0.94       392\n",
      "     service       0.96      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      1.00      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.97      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3966, Accuracy: 0.8632, F1 Micro: 0.8632, F1 Macro: 0.8237\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2483, Accuracy: 0.8941, F1 Micro: 0.8941, F1 Macro: 0.8661\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1781, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8886\n",
      "Epoch 4/10, Train Loss: 0.1413, Accuracy: 0.9025, F1 Micro: 0.9025, F1 Macro: 0.8701\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0986, Accuracy: 0.9166, F1 Micro: 0.9166, F1 Macro: 0.8919\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0621, Accuracy: 0.9175, F1 Micro: 0.9175, F1 Macro: 0.8935\n",
      "Epoch 7/10, Train Loss: 0.0629, Accuracy: 0.9128, F1 Micro: 0.9128, F1 Macro: 0.8854\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.041, Accuracy: 0.9175, F1 Micro: 0.9175, F1 Macro: 0.8927\n",
      "Epoch 9/10, Train Loss: 0.043, Accuracy: 0.9091, F1 Micro: 0.9091, F1 Macro: 0.8827\n",
      "Epoch 10/10, Train Loss: 0.0329, Accuracy: 0.9147, F1 Micro: 0.9147, F1 Macro: 0.8887\n",
      "\n",
      "Sentiment analysis accuracy: 0.9175, F1 Micro: 0.9175, F1 Macro: 0.8927\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       762\n",
      "    positive       0.94      0.76      0.84       305\n",
      "\n",
      "    accuracy                           0.92      1067\n",
      "   macro avg       0.92      0.87      0.89      1067\n",
      "weighted avg       0.92      0.92      0.91      1067\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1660: Accuracy: 0.9574, F1 Micro: 0.9574, F1 Macro: 0.8789\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.93      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.95      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.86      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.81      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.88      0.72      0.79        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.62      0.67       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.89      0.89       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.79      0.84       162\n",
      "     neutral       0.91      0.98      0.94       387\n",
      "    positive       1.00      0.50      0.67        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.93      0.76      0.82       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.84      0.87        85\n",
      "     neutral       0.96      0.98      0.97       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.96      0.96        54\n",
      "     neutral       0.99      1.00      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.93      0.96       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 310.0636203289032 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1712\n",
      "Acquired samples: 52\n",
      "Sampling duration: 20.79448437690735 seconds\n",
      "New train size: 1712\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4812, Accuracy: 0.8323, F1 Micro: 0.9043, F1 Macro: 0.8993\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3275, Accuracy: 0.9247, F1 Micro: 0.9545, F1 Macro: 0.9518\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2268, Accuracy: 0.9446, F1 Micro: 0.9661, F1 Macro: 0.9636\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1789, Accuracy: 0.9545, F1 Micro: 0.972, F1 Macro: 0.9696\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1473, Accuracy: 0.9597, F1 Micro: 0.975, F1 Macro: 0.9722\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1255, Accuracy: 0.9608, F1 Micro: 0.9758, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1061, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9748\n",
      "Epoch 8/10, Train Loss: 0.0875, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0739, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9754\n",
      "Epoch 10/10, Train Loss: 0.0653, Accuracy: 0.9641, F1 Micro: 0.9776, F1 Macro: 0.9751\n",
      "\n",
      "Aspect detection accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3962, Accuracy: 0.8565, F1 Micro: 0.8565, F1 Macro: 0.8166\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.227, Accuracy: 0.9025, F1 Micro: 0.9025, F1 Macro: 0.874\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.185, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.8874\n",
      "Epoch 4/10, Train Loss: 0.1263, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8843\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0849, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.8929\n",
      "Epoch 6/10, Train Loss: 0.064, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.8859\n",
      "Epoch 7/10, Train Loss: 0.0518, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8816\n",
      "Epoch 8/10, Train Loss: 0.0415, Accuracy: 0.9089, F1 Micro: 0.9089, F1 Macro: 0.8824\n",
      "Epoch 9/10, Train Loss: 0.0305, Accuracy: 0.9071, F1 Micro: 0.9071, F1 Macro: 0.8766\n",
      "Epoch 10/10, Train Loss: 0.0323, Accuracy: 0.9089, F1 Micro: 0.9089, F1 Macro: 0.883\n",
      "\n",
      "Sentiment analysis accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.8929\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.97      0.94       773\n",
      "    positive       0.92      0.78      0.84       314\n",
      "\n",
      "    accuracy                           0.92      1087\n",
      "   macro avg       0.92      0.87      0.89      1087\n",
      "weighted avg       0.92      0.92      0.91      1087\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1712: Accuracy: 0.9581, F1 Micro: 0.9581, F1 Macro: 0.873\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.56      0.50      0.53        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.83      0.80      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.79      0.82        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.87      0.71      0.78        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.61      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.88      0.89       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.80      0.98      0.88        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.93      0.90       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.83      0.86       162\n",
      "     neutral       0.92      0.97      0.95       387\n",
      "    positive       0.92      0.50      0.65        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.91      0.77      0.82       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.84      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.91      0.94      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.70      0.94      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.82      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       1.00      0.99      0.99       571\n",
      "\n",
      "Total train time: 319.729074716568 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 58\n",
      "Sampling duration: 19.1045663356781 seconds\n",
      "New train size: 1770\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4793, Accuracy: 0.8396, F1 Micro: 0.9085, F1 Macro: 0.9044\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3113, Accuracy: 0.9344, F1 Micro: 0.96, F1 Macro: 0.9571\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2175, Accuracy: 0.9484, F1 Micro: 0.9684, F1 Macro: 0.9659\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1683, Accuracy: 0.9531, F1 Micro: 0.9712, F1 Macro: 0.9688\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1356, Accuracy: 0.9595, F1 Micro: 0.975, F1 Macro: 0.9724\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1191, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1017, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9753\n",
      "Epoch 8/10, Train Loss: 0.0854, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9745\n",
      "Epoch 9/10, Train Loss: 0.0719, Accuracy: 0.9622, F1 Micro: 0.9765, F1 Macro: 0.9742\n",
      "Epoch 10/10, Train Loss: 0.061, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9747\n",
      "\n",
      "Aspect detection accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      0.99      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.92      0.93       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3873, Accuracy: 0.8617, F1 Micro: 0.8617, F1 Macro: 0.8193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2445, Accuracy: 0.88, F1 Micro: 0.88, F1 Macro: 0.8402\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1673, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.88\n",
      "Epoch 4/10, Train Loss: 0.128, Accuracy: 0.9048, F1 Micro: 0.9048, F1 Macro: 0.8763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0947, Accuracy: 0.9112, F1 Micro: 0.9112, F1 Macro: 0.8863\n",
      "Epoch 6/10, Train Loss: 0.0668, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.88\n",
      "Epoch 7/10, Train Loss: 0.0688, Accuracy: 0.9011, F1 Micro: 0.9011, F1 Macro: 0.8751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0618, Accuracy: 0.9121, F1 Micro: 0.9121, F1 Macro: 0.8876\n",
      "Epoch 9/10, Train Loss: 0.0399, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8708\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0302, Accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8874\n",
      "\n",
      "Sentiment analysis accuracy: 0.9139, F1 Micro: 0.9139, F1 Macro: 0.8874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.99      0.94       775\n",
      "    positive       0.96      0.74      0.83       317\n",
      "\n",
      "    accuracy                           0.91      1092\n",
      "   macro avg       0.93      0.86      0.89      1092\n",
      "weighted avg       0.92      0.91      0.91      1092\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1770: Accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.8469\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.88      0.90        86\n",
      "     neutral       0.98      0.99      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.85      0.83        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.60      0.61      0.60       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.85      0.74      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.62      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.89      0.89       200\n",
      "     neutral       0.94      0.92      0.93       315\n",
      "    positive       0.88      0.93      0.90        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.91      0.91       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.83      0.86       162\n",
      "     neutral       0.92      0.97      0.95       387\n",
      "    positive       0.85      0.50      0.63        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.77      0.81       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.86      0.88        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.92      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.66      0.75        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.88      0.82      0.85        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.91      0.82      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 322.021689414978 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 52\n",
      "Sampling duration: 17.24855637550354 seconds\n",
      "New train size: 1822\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4767, Accuracy: 0.8373, F1 Micro: 0.9073, F1 Macro: 0.9031\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.312, Accuracy: 0.9335, F1 Micro: 0.9595, F1 Macro: 0.9568\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2216, Accuracy: 0.9446, F1 Micro: 0.966, F1 Macro: 0.9632\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1721, Accuracy: 0.9524, F1 Micro: 0.9708, F1 Macro: 0.9683\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1355, Accuracy: 0.9602, F1 Micro: 0.9754, F1 Macro: 0.9728\n",
      "Epoch 6/10, Train Loss: 0.1142, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.973\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.1048, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9746\n",
      "Epoch 8/10, Train Loss: 0.0868, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9741\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0712, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9757\n",
      "Epoch 10/10, Train Loss: 0.062, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9754\n",
      "\n",
      "Aspect detection accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.98      0.96      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.93      0.93       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3861, Accuracy: 0.8568, F1 Micro: 0.8568, F1 Macro: 0.8127\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2314, Accuracy: 0.8912, F1 Micro: 0.8912, F1 Macro: 0.8543\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.147, Accuracy: 0.8994, F1 Micro: 0.8994, F1 Macro: 0.8697\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1124, Accuracy: 0.9039, F1 Micro: 0.9039, F1 Macro: 0.8735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0867, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8807\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0664, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8809\n",
      "Epoch 7/10, Train Loss: 0.0466, Accuracy: 0.9021, F1 Micro: 0.9021, F1 Macro: 0.8731\n",
      "Epoch 8/10, Train Loss: 0.0453, Accuracy: 0.903, F1 Micro: 0.903, F1 Macro: 0.8727\n",
      "Epoch 9/10, Train Loss: 0.0253, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8807\n",
      "Epoch 10/10, Train Loss: 0.033, Accuracy: 0.9039, F1 Micro: 0.9039, F1 Macro: 0.8757\n",
      "\n",
      "Sentiment analysis accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8809\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       783\n",
      "    positive       0.95      0.72      0.82       320\n",
      "\n",
      "    accuracy                           0.91      1103\n",
      "   macro avg       0.92      0.85      0.88      1103\n",
      "weighted avg       0.91      0.91      0.91      1103\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1822: Accuracy: 0.9587, F1 Micro: 0.9587, F1 Macro: 0.8794\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.88      0.83        78\n",
      "     neutral       0.98      0.96      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.92      0.95      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.29      0.44         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.86      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.94      0.66      0.73       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.94      0.93      0.93       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.83      0.85       162\n",
      "     neutral       0.92      0.97      0.95       387\n",
      "    positive       0.88      0.32      0.47        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.71      0.75       571\n",
      "weighted avg       0.91      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.93      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.78      0.82      0.80        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.96      0.94        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.87      0.91       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 333.39812660217285 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 15.61664605140686 seconds\n",
      "New train size: 1872\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4704, Accuracy: 0.8597, F1 Micro: 0.9181, F1 Macro: 0.9116\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.3044, Accuracy: 0.9358, F1 Micro: 0.9609, F1 Macro: 0.9586\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2115, Accuracy: 0.9497, F1 Micro: 0.9691, F1 Macro: 0.9667\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1715, Accuracy: 0.9576, F1 Micro: 0.9739, F1 Macro: 0.9712\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1371, Accuracy: 0.9592, F1 Micro: 0.9748, F1 Macro: 0.9723\n",
      "Epoch 6/10, Train Loss: 0.1129, Accuracy: 0.9554, F1 Micro: 0.9725, F1 Macro: 0.9702\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0974, Accuracy: 0.9595, F1 Micro: 0.975, F1 Macro: 0.9725\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0809, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9745\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0718, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0585, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9753\n",
      "\n",
      "Aspect detection accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.98      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.91      0.96      0.94       392\n",
      "     service       0.97      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3879, Accuracy: 0.8537, F1 Micro: 0.8537, F1 Macro: 0.7944\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2294, Accuracy: 0.8951, F1 Micro: 0.8951, F1 Macro: 0.8665\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1554, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1097, Accuracy: 0.9089, F1 Micro: 0.9089, F1 Macro: 0.8835\n",
      "Epoch 5/10, Train Loss: 0.1016, Accuracy: 0.908, F1 Micro: 0.908, F1 Macro: 0.8808\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0569, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.889\n",
      "Epoch 7/10, Train Loss: 0.0523, Accuracy: 0.9062, F1 Micro: 0.9062, F1 Macro: 0.8762\n",
      "Epoch 8/10, Train Loss: 0.0437, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.8827\n",
      "Epoch 9/10, Train Loss: 0.0336, Accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8877\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.037, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.888\n",
      "\n",
      "Sentiment analysis accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       769\n",
      "    positive       0.95      0.75      0.83       318\n",
      "\n",
      "    accuracy                           0.91      1087\n",
      "   macro avg       0.93      0.86      0.89      1087\n",
      "weighted avg       0.92      0.91      0.91      1087\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1872: Accuracy: 0.9585, F1 Micro: 0.9585, F1 Macro: 0.8831\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.82      0.83        78\n",
      "     neutral       0.97      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.89      0.74      0.81        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.62      0.68       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.80      0.83       162\n",
      "     neutral       0.91      0.96      0.94       387\n",
      "    positive       0.92      0.55      0.69        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.90      0.77      0.82       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.87      0.88        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.52      0.62        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.76      0.76        17\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.84      0.76      0.79       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 342.10177421569824 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 13.87539792060852 seconds\n",
      "New train size: 1922\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4701, Accuracy: 0.8578, F1 Micro: 0.9172, F1 Macro: 0.9114\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.298, Accuracy: 0.9378, F1 Micro: 0.962, F1 Macro: 0.9593\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2061, Accuracy: 0.9505, F1 Micro: 0.9696, F1 Macro: 0.9672\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1605, Accuracy: 0.9563, F1 Micro: 0.9729, F1 Macro: 0.9703\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1349, Accuracy: 0.9597, F1 Micro: 0.9751, F1 Macro: 0.9726\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1135, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9744\n",
      "Epoch 7/10, Train Loss: 0.0989, Accuracy: 0.9627, F1 Micro: 0.9768, F1 Macro: 0.9742\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0797, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0673, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9755\n",
      "Epoch 10/10, Train Loss: 0.0592, Accuracy: 0.9634, F1 Micro: 0.9772, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.95      0.94      0.94       317\n",
      "       linen       0.92      0.96      0.94       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.97      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3982, Accuracy: 0.8493, F1 Micro: 0.8493, F1 Macro: 0.7938\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2265, Accuracy: 0.8831, F1 Micro: 0.8831, F1 Macro: 0.8446\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.149, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.8788\n",
      "Epoch 4/10, Train Loss: 0.1205, Accuracy: 0.8968, F1 Micro: 0.8968, F1 Macro: 0.862\n",
      "Epoch 5/10, Train Loss: 0.0868, Accuracy: 0.9014, F1 Micro: 0.9014, F1 Macro: 0.8707\n",
      "Epoch 6/10, Train Loss: 0.0618, Accuracy: 0.9014, F1 Micro: 0.9014, F1 Macro: 0.8707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0519, Accuracy: 0.9114, F1 Micro: 0.9114, F1 Macro: 0.8843\n",
      "Epoch 8/10, Train Loss: 0.0404, Accuracy: 0.9068, F1 Micro: 0.9068, F1 Macro: 0.879\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0379, Accuracy: 0.9123, F1 Micro: 0.9123, F1 Macro: 0.8859\n",
      "Epoch 10/10, Train Loss: 0.0333, Accuracy: 0.9032, F1 Micro: 0.9032, F1 Macro: 0.874\n",
      "\n",
      "Sentiment analysis accuracy: 0.9123, F1 Micro: 0.9123, F1 Macro: 0.8859\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       778\n",
      "    positive       0.94      0.74      0.83       317\n",
      "\n",
      "    accuracy                           0.91      1095\n",
      "   macro avg       0.92      0.86      0.89      1095\n",
      "weighted avg       0.91      0.91      0.91      1095\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1922: Accuracy: 0.9581, F1 Micro: 0.9581, F1 Macro: 0.8784\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.92      0.94        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.83      1.00      0.91        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.93      0.97      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.96      0.90      0.93        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.86      0.87       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.83      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.84      0.71      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.93      0.61      0.66       571\n",
      "weighted avg       0.94      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.91      0.91       200\n",
      "     neutral       0.95      0.94      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.93       571\n",
      "   macro avg       0.91      0.94      0.92       571\n",
      "weighted avg       0.93      0.93      0.93       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.83      0.85       162\n",
      "     neutral       0.92      0.96      0.94       387\n",
      "    positive       0.89      0.36      0.52        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.89      0.72      0.77       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.86      0.86        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.94      0.90      0.92        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.55      0.68        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.81      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 345.6811149120331 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 50\n",
      "Sampling duration: 12.869767427444458 seconds\n",
      "New train size: 1972\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4687, Accuracy: 0.8536, F1 Micro: 0.9155, F1 Macro: 0.9107\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2998, Accuracy: 0.9299, F1 Micro: 0.9574, F1 Macro: 0.9546\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2068, Accuracy: 0.9446, F1 Micro: 0.9662, F1 Macro: 0.9639\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1624, Accuracy: 0.9563, F1 Micro: 0.973, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1342, Accuracy: 0.9587, F1 Micro: 0.9745, F1 Macro: 0.9723\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1116, Accuracy: 0.9609, F1 Micro: 0.9758, F1 Macro: 0.9736\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0932, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0799, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0678, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9762\n",
      "Epoch 10/10, Train Loss: 0.0573, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9759\n",
      "\n",
      "Aspect detection accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.94      0.94      0.94       317\n",
      "       linen       0.93      0.97      0.95       392\n",
      "     service       0.98      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3578, Accuracy: 0.8703, F1 Micro: 0.8703, F1 Macro: 0.8234\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2191, Accuracy: 0.8997, F1 Micro: 0.8997, F1 Macro: 0.8717\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1607, Accuracy: 0.9108, F1 Micro: 0.9108, F1 Macro: 0.8861\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1021, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.8875\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0793, Accuracy: 0.9181, F1 Micro: 0.9181, F1 Macro: 0.8926\n",
      "Epoch 6/10, Train Loss: 0.0689, Accuracy: 0.9126, F1 Micro: 0.9126, F1 Macro: 0.8869\n",
      "Epoch 7/10, Train Loss: 0.056, Accuracy: 0.9163, F1 Micro: 0.9163, F1 Macro: 0.8914\n",
      "Epoch 8/10, Train Loss: 0.0416, Accuracy: 0.9098, F1 Micro: 0.9098, F1 Macro: 0.881\n",
      "Epoch 9/10, Train Loss: 0.0292, Accuracy: 0.9135, F1 Micro: 0.9135, F1 Macro: 0.8875\n",
      "Epoch 10/10, Train Loss: 0.0298, Accuracy: 0.9117, F1 Micro: 0.9117, F1 Macro: 0.8848\n",
      "\n",
      "Sentiment analysis accuracy: 0.9181, F1 Micro: 0.9181, F1 Macro: 0.8926\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       776\n",
      "    positive       0.95      0.75      0.84       311\n",
      "\n",
      "    accuracy                           0.92      1087\n",
      "   macro avg       0.93      0.87      0.89      1087\n",
      "weighted avg       0.92      0.92      0.91      1087\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1972: Accuracy: 0.9597, F1 Micro: 0.9597, F1 Macro: 0.8829\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.92      0.80      0.85       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.82      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.14      0.22         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.88      0.72      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.78      0.62      0.66       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.88      0.90       200\n",
      "     neutral       0.94      0.94      0.94       315\n",
      "    positive       0.82      0.96      0.89        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.93      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.85      0.86       162\n",
      "     neutral       0.93      0.97      0.95       387\n",
      "    positive       1.00      0.45      0.62        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.93      0.76      0.81       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.89      0.89        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.95      0.93      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.62      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.81      0.76      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 351.96582651138306 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 1997\n",
      "Acquired samples: 25\n",
      "Sampling duration: 10.86341404914856 seconds\n",
      "New train size: 1997\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.468, Accuracy: 0.8573, F1 Micro: 0.9175, F1 Macro: 0.9131\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2948, Accuracy: 0.9335, F1 Micro: 0.9595, F1 Macro: 0.9572\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.2114, Accuracy: 0.9448, F1 Micro: 0.9663, F1 Macro: 0.9639\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.16, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9731\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1307, Accuracy: 0.9606, F1 Micro: 0.9756, F1 Macro: 0.9733\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1087, Accuracy: 0.963, F1 Micro: 0.977, F1 Macro: 0.9749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0928, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9749\n",
      "Epoch 8/10, Train Loss: 0.0758, Accuracy: 0.9628, F1 Micro: 0.9769, F1 Macro: 0.9748\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0633, Accuracy: 0.9646, F1 Micro: 0.9781, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0552, Accuracy: 0.9663, F1 Micro: 0.979, F1 Macro: 0.9769\n",
      "\n",
      "Aspect detection accuracy: 0.9663, F1 Micro: 0.979, F1 Macro: 0.9769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.98      0.97       500\n",
      "  kebersihan       0.96      0.91      0.94       317\n",
      "       linen       0.94      0.97      0.96       392\n",
      "     service       0.98      0.97      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3697, Accuracy: 0.8508, F1 Micro: 0.8508, F1 Macro: 0.8016\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2204, Accuracy: 0.8861, F1 Micro: 0.8861, F1 Macro: 0.8464\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1437, Accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.8721\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1177, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8762\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0872, Accuracy: 0.9078, F1 Micro: 0.9078, F1 Macro: 0.88\n",
      "Epoch 6/10, Train Loss: 0.0585, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8795\n",
      "Epoch 7/10, Train Loss: 0.0512, Accuracy: 0.9024, F1 Micro: 0.9024, F1 Macro: 0.8773\n",
      "Epoch 8/10, Train Loss: 0.0499, Accuracy: 0.9005, F1 Micro: 0.9005, F1 Macro: 0.8679\n",
      "Epoch 9/10, Train Loss: 0.0345, Accuracy: 0.9069, F1 Micro: 0.9069, F1 Macro: 0.8795\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0391, Accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8805\n",
      "\n",
      "Sentiment analysis accuracy: 0.9087, F1 Micro: 0.9087, F1 Macro: 0.8805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       786\n",
      "    positive       0.94      0.73      0.82       320\n",
      "\n",
      "    accuracy                           0.91      1106\n",
      "   macro avg       0.92      0.86      0.88      1106\n",
      "weighted avg       0.91      0.91      0.90      1106\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 1997: Accuracy: 0.9602, F1 Micro: 0.9602, F1 Macro: 0.8825\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.88      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.79      0.83       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.81      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.25      0.14      0.18         7\n",
      "     neutral       0.95      0.98      0.97       496\n",
      "    positive       0.89      0.71      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.70      0.61      0.65       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.87      0.91      0.89       200\n",
      "     neutral       0.96      0.91      0.94       315\n",
      "    positive       0.84      0.95      0.89        56\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.89      0.92      0.91       571\n",
      "weighted avg       0.92      0.91      0.91       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.88      0.88       162\n",
      "     neutral       0.94      0.97      0.96       387\n",
      "    positive       1.00      0.45      0.62        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.94      0.77      0.82       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.86      0.87        85\n",
      "     neutral       0.98      0.98      0.98       418\n",
      "    positive       0.92      0.96      0.94        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.82      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 359.7860143184662 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 10.021482229232788 seconds\n",
      "New train size: 2047\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4625, Accuracy: 0.8656, F1 Micro: 0.9211, F1 Macro: 0.9149\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2829, Accuracy: 0.9375, F1 Micro: 0.9619, F1 Macro: 0.9599\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1986, Accuracy: 0.9481, F1 Micro: 0.9682, F1 Macro: 0.966\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1553, Accuracy: 0.9576, F1 Micro: 0.9738, F1 Macro: 0.9715\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1315, Accuracy: 0.9601, F1 Micro: 0.9753, F1 Macro: 0.9728\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1096, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.9738\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0947, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.078, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0644, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9759\n",
      "Epoch 10/10, Train Loss: 0.0556, Accuracy: 0.9632, F1 Micro: 0.9772, F1 Macro: 0.9749\n",
      "\n",
      "Aspect detection accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.96      0.99      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3747, Accuracy: 0.86, F1 Micro: 0.86, F1 Macro: 0.8161\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2028, Accuracy: 0.8902, F1 Micro: 0.8902, F1 Macro: 0.8532\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1323, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8878\n",
      "Epoch 4/10, Train Loss: 0.1131, Accuracy: 0.9058, F1 Micro: 0.9058, F1 Macro: 0.8787\n",
      "Epoch 5/10, Train Loss: 0.0683, Accuracy: 0.9067, F1 Micro: 0.9067, F1 Macro: 0.8764\n",
      "Epoch 6/10, Train Loss: 0.066, Accuracy: 0.9067, F1 Micro: 0.9067, F1 Macro: 0.877\n",
      "Epoch 7/10, Train Loss: 0.0507, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8824\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.048, Accuracy: 0.9131, F1 Micro: 0.9131, F1 Macro: 0.8866\n",
      "Epoch 9/10, Train Loss: 0.0314, Accuracy: 0.9094, F1 Micro: 0.9094, F1 Macro: 0.8827\n",
      "Epoch 10/10, Train Loss: 0.0312, Accuracy: 0.9122, F1 Micro: 0.9122, F1 Macro: 0.8856\n",
      "\n",
      "Sentiment analysis accuracy: 0.9131, F1 Micro: 0.9131, F1 Macro: 0.8866\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       775\n",
      "    positive       0.95      0.74      0.83       318\n",
      "\n",
      "    accuracy                           0.91      1093\n",
      "   macro avg       0.93      0.86      0.89      1093\n",
      "weighted avg       0.92      0.91      0.91      1093\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2047: Accuracy: 0.9592, F1 Micro: 0.9592, F1 Macro: 0.8794\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.87      0.90        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.79      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.86      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.94      0.94       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.96      0.99      0.97       496\n",
      "    positive       0.88      0.75      0.81        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.94      0.63      0.68       571\n",
      "weighted avg       0.95      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.91      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.89      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.81      0.85       162\n",
      "     neutral       0.91      0.97      0.94       387\n",
      "    positive       0.82      0.41      0.55        22\n",
      "\n",
      "    accuracy                           0.90       571\n",
      "   macro avg       0.87      0.73      0.78       571\n",
      "weighted avg       0.90      0.90      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.87      0.87        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.95      0.91      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.92      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.62      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.82      0.82      0.82        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.81      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.99      0.98        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.99      0.99      0.99       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 363.87151408195496 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 8.395460367202759 seconds\n",
      "New train size: 2097\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4565, Accuracy: 0.8689, F1 Micro: 0.9232, F1 Macro: 0.9176\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2811, Accuracy: 0.9408, F1 Micro: 0.964, F1 Macro: 0.962\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1949, Accuracy: 0.9438, F1 Micro: 0.9655, F1 Macro: 0.9623\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1561, Accuracy: 0.9538, F1 Micro: 0.9716, F1 Macro: 0.9693\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1312, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9749\n",
      "Epoch 6/10, Train Loss: 0.1066, Accuracy: 0.9615, F1 Micro: 0.9761, F1 Macro: 0.974\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0894, Accuracy: 0.9634, F1 Micro: 0.9773, F1 Macro: 0.9754\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0751, Accuracy: 0.9648, F1 Micro: 0.9781, F1 Macro: 0.9754\n",
      "Epoch 9/10, Train Loss: 0.0617, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 10/10, Train Loss: 0.0529, Accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9761\n",
      "\n",
      "Aspect detection accuracy: 0.9649, F1 Micro: 0.9782, F1 Macro: 0.9761\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.92      0.97      0.95       392\n",
      "     service       0.97      0.98      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3552, Accuracy: 0.8654, F1 Micro: 0.8654, F1 Macro: 0.8339\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2038, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8781\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1384, Accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.8892\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0974, Accuracy: 0.9217, F1 Micro: 0.9217, F1 Macro: 0.8973\n",
      "Epoch 5/10, Train Loss: 0.0625, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.8861\n",
      "Epoch 6/10, Train Loss: 0.0565, Accuracy: 0.906, F1 Micro: 0.906, F1 Macro: 0.8784\n",
      "Epoch 7/10, Train Loss: 0.0431, Accuracy: 0.9051, F1 Micro: 0.9051, F1 Macro: 0.8732\n",
      "Epoch 8/10, Train Loss: 0.0318, Accuracy: 0.9115, F1 Micro: 0.9115, F1 Macro: 0.8845\n",
      "Epoch 9/10, Train Loss: 0.0266, Accuracy: 0.9152, F1 Micro: 0.9152, F1 Macro: 0.891\n",
      "Epoch 10/10, Train Loss: 0.0219, Accuracy: 0.9143, F1 Micro: 0.9143, F1 Macro: 0.8885\n",
      "\n",
      "Sentiment analysis accuracy: 0.9217, F1 Micro: 0.9217, F1 Macro: 0.8973\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.99      0.95       775\n",
      "    positive       0.96      0.76      0.85       310\n",
      "\n",
      "    accuracy                           0.92      1085\n",
      "   macro avg       0.93      0.87      0.90      1085\n",
      "weighted avg       0.92      0.92      0.92      1085\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2097: Accuracy: 0.9601, F1 Micro: 0.9601, F1 Macro: 0.8623\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.93      0.93      0.93        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.95      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.91      0.93        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.85      0.80      0.83       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.83      0.82        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.77      0.82       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.89      0.72      0.80        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.57      0.59       571\n",
      "weighted avg       0.93      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.90      0.90       200\n",
      "     neutral       0.95      0.93      0.94       315\n",
      "    positive       0.87      0.96      0.92        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.83      0.87       162\n",
      "     neutral       0.92      0.98      0.95       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.75      0.81       571\n",
      "weighted avg       0.92      0.92      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88        85\n",
      "     neutral       0.97      0.98      0.97       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.83      0.88      0.86        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.89      0.83      0.86       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.94      0.94        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.98      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.97      0.97        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.91      0.99      0.94       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Total train time: 366.3750476837158 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 6.860462427139282 seconds\n",
      "New train size: 2147\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4489, Accuracy: 0.8717, F1 Micro: 0.9244, F1 Macro: 0.9193\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2692, Accuracy: 0.9399, F1 Micro: 0.9632, F1 Macro: 0.961\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1929, Accuracy: 0.9491, F1 Micro: 0.9688, F1 Macro: 0.9662\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1514, Accuracy: 0.9564, F1 Micro: 0.9732, F1 Macro: 0.971\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.122, Accuracy: 0.9604, F1 Micro: 0.9755, F1 Macro: 0.9734\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1007, Accuracy: 0.963, F1 Micro: 0.9771, F1 Macro: 0.9752\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0849, Accuracy: 0.9639, F1 Micro: 0.9776, F1 Macro: 0.9758\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0712, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9763\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0614, Accuracy: 0.9655, F1 Micro: 0.9786, F1 Macro: 0.9764\n",
      "Epoch 10/10, Train Loss: 0.0512, Accuracy: 0.9653, F1 Micro: 0.9784, F1 Macro: 0.9764\n",
      "\n",
      "Aspect detection accuracy: 0.9655, F1 Micro: 0.9786, F1 Macro: 0.9764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.96      0.98      0.97       500\n",
      "  kebersihan       0.92      0.96      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3481, Accuracy: 0.8729, F1 Micro: 0.8729, F1 Macro: 0.8312\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.1958, Accuracy: 0.9006, F1 Micro: 0.9006, F1 Macro: 0.8713\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1261, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.8943\n",
      "Epoch 4/10, Train Loss: 0.0905, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8832\n",
      "Epoch 5/10, Train Loss: 0.0644, Accuracy: 0.9061, F1 Micro: 0.9061, F1 Macro: 0.8764\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0704, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.894\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0316, Accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.8965\n",
      "Epoch 8/10, Train Loss: 0.0446, Accuracy: 0.9125, F1 Micro: 0.9125, F1 Macro: 0.8886\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0306, Accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.8956\n",
      "Epoch 10/10, Train Loss: 0.0238, Accuracy: 0.9171, F1 Micro: 0.9171, F1 Macro: 0.8934\n",
      "\n",
      "Sentiment analysis accuracy: 0.919, F1 Micro: 0.919, F1 Macro: 0.8956\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       771\n",
      "    positive       0.94      0.77      0.85       315\n",
      "\n",
      "    accuracy                           0.92      1086\n",
      "   macro avg       0.93      0.87      0.90      1086\n",
      "weighted avg       0.92      0.92      0.92      1086\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2147: Accuracy: 0.9597, F1 Micro: 0.9597, F1 Macro: 0.8885\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.83      0.50      0.62        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.92      0.80      0.85       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.76      0.81        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.95      0.91      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.50      0.29      0.36         7\n",
      "     neutral       0.96      0.98      0.97       496\n",
      "    positive       0.87      0.76      0.81        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.78      0.68      0.72       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.86      0.90       200\n",
      "     neutral       0.92      0.96      0.94       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.91      0.92      0.92       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.86       162\n",
      "     neutral       0.93      0.96      0.95       387\n",
      "    positive       0.90      0.41      0.56        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.90      0.74      0.79       571\n",
      "weighted avg       0.91      0.91      0.91       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.87      0.85        85\n",
      "     neutral       0.98      0.96      0.97       418\n",
      "    positive       0.89      0.96      0.92        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.90      0.93      0.91       571\n",
      "weighted avg       0.95      0.94      0.94       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.59      0.69        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.87      0.82      0.84       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.99      0.98       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 382.7733705043793 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 5.228996515274048 seconds\n",
      "New train size: 2197\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4487, Accuracy: 0.874, F1 Micro: 0.9261, F1 Macro: 0.9213\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2608, Accuracy: 0.9408, F1 Micro: 0.964, F1 Macro: 0.9617\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1882, Accuracy: 0.9528, F1 Micro: 0.9711, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1478, Accuracy: 0.9564, F1 Micro: 0.9732, F1 Macro: 0.9707\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.121, Accuracy: 0.9618, F1 Micro: 0.9763, F1 Macro: 0.9743\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.1005, Accuracy: 0.9637, F1 Micro: 0.9775, F1 Macro: 0.9753\n",
      "Epoch 7/10, Train Loss: 0.0843, Accuracy: 0.9635, F1 Micro: 0.9773, F1 Macro: 0.9751\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0717, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "Epoch 9/10, Train Loss: 0.0599, Accuracy: 0.9642, F1 Micro: 0.9777, F1 Macro: 0.9755\n",
      "Epoch 10/10, Train Loss: 0.0514, Accuracy: 0.9642, F1 Micro: 0.9778, F1 Macro: 0.9758\n",
      "\n",
      "Aspect detection accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9762\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.96      0.98      0.97       496\n",
      "     general       0.94      0.99      0.96       500\n",
      "  kebersihan       0.95      0.93      0.94       317\n",
      "       linen       0.95      0.96      0.95       392\n",
      "     service       0.97      0.98      0.98       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.351, Accuracy: 0.8636, F1 Micro: 0.8636, F1 Macro: 0.8283\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2, Accuracy: 0.9011, F1 Micro: 0.9011, F1 Macro: 0.8694\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1485, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.872\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0995, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.8749\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0721, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8799\n",
      "Epoch 6/10, Train Loss: 0.056, Accuracy: 0.9066, F1 Micro: 0.9066, F1 Macro: 0.8778\n",
      "Epoch 7/10, Train Loss: 0.0473, Accuracy: 0.902, F1 Micro: 0.902, F1 Macro: 0.8705\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0392, Accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8807\n",
      "Epoch 9/10, Train Loss: 0.0225, Accuracy: 0.9038, F1 Micro: 0.9038, F1 Macro: 0.87\n",
      "Epoch 10/10, Train Loss: 0.0229, Accuracy: 0.9084, F1 Micro: 0.9084, F1 Macro: 0.8785\n",
      "\n",
      "Sentiment analysis accuracy: 0.9093, F1 Micro: 0.9093, F1 Macro: 0.8807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       781\n",
      "    positive       0.93      0.74      0.82       311\n",
      "\n",
      "    accuracy                           0.91      1092\n",
      "   macro avg       0.92      0.86      0.88      1092\n",
      "weighted avg       0.91      0.91      0.91      1092\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2197: Accuracy: 0.9588, F1 Micro: 0.9588, F1 Macro: 0.8655\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.94      0.95      0.95       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.76      0.79        78\n",
      "     neutral       0.96      0.98      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.91      0.92       571\n",
      "weighted avg       0.94      0.95      0.94       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.94      0.99      0.96       496\n",
      "    positive       0.87      0.68      0.76        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.60      0.55      0.57       571\n",
      "weighted avg       0.92      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.90      0.89       200\n",
      "     neutral       0.94      0.93      0.94       315\n",
      "    positive       0.87      0.95      0.91        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.88      0.87       162\n",
      "     neutral       0.95      0.96      0.95       387\n",
      "    positive       0.91      0.45      0.61        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.77      0.81       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.87      0.88        85\n",
      "     neutral       0.97      0.98      0.98       418\n",
      "    positive       0.94      0.93      0.93        68\n",
      "\n",
      "    accuracy                           0.96       571\n",
      "   macro avg       0.94      0.93      0.93       571\n",
      "weighted avg       0.96      0.96      0.96       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.89      0.59      0.71        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.76      0.94      0.84        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.84      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.93      0.93        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       0.80      0.67      0.73         6\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.91      0.86      0.88       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 381.93279457092285 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 50\n",
      "Sampling duration: 3.646275758743286 seconds\n",
      "New train size: 2247\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4415, Accuracy: 0.8804, F1 Micro: 0.9297, F1 Macro: 0.9255\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.2557, Accuracy: 0.9429, F1 Micro: 0.965, F1 Macro: 0.9624\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1838, Accuracy: 0.9505, F1 Micro: 0.9696, F1 Macro: 0.9674\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.143, Accuracy: 0.9576, F1 Micro: 0.9738, F1 Macro: 0.9714\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.1166, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9742\n",
      "Epoch 6/10, Train Loss: 0.0971, Accuracy: 0.9613, F1 Micro: 0.976, F1 Macro: 0.9737\n",
      "Epoch 7/10, Train Loss: 0.0865, Accuracy: 0.9625, F1 Micro: 0.9767, F1 Macro: 0.9744\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0687, Accuracy: 0.9646, F1 Micro: 0.978, F1 Macro: 0.9759\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0594, Accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9763\n",
      "Epoch 10/10, Train Loss: 0.0491, Accuracy: 0.9641, F1 Micro: 0.9777, F1 Macro: 0.9755\n",
      "\n",
      "Aspect detection accuracy: 0.9651, F1 Micro: 0.9783, F1 Macro: 0.9763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.98      1.00      0.99       480\n",
      "         bau       0.98      0.97      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.95      0.94      0.94       317\n",
      "       linen       0.92      0.97      0.94       392\n",
      "     service       0.98      0.97      0.97       423\n",
      "sunrise_meal       0.98      1.00      0.99       530\n",
      "          tv       0.99      0.99      0.99       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.97      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.97      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.3499, Accuracy: 0.8692, F1 Micro: 0.8692, F1 Macro: 0.8259\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.189, Accuracy: 0.8941, F1 Micro: 0.8941, F1 Macro: 0.8567\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1257, Accuracy: 0.8987, F1 Micro: 0.8987, F1 Macro: 0.8644\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.0988, Accuracy: 0.9144, F1 Micro: 0.9144, F1 Macro: 0.888\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.0726, Accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.8931\n",
      "Epoch 6/10, Train Loss: 0.0498, Accuracy: 0.9116, F1 Micro: 0.9116, F1 Macro: 0.8817\n",
      "Epoch 7/10, Train Loss: 0.0557, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.8869\n",
      "Epoch 8/10, Train Loss: 0.0309, Accuracy: 0.9162, F1 Micro: 0.9162, F1 Macro: 0.8894\n",
      "Epoch 9/10, Train Loss: 0.0362, Accuracy: 0.9107, F1 Micro: 0.9107, F1 Macro: 0.8809\n",
      "Epoch 10/10, Train Loss: 0.0395, Accuracy: 0.9134, F1 Micro: 0.9134, F1 Macro: 0.8887\n",
      "\n",
      "Sentiment analysis accuracy: 0.918, F1 Micro: 0.918, F1 Macro: 0.8931\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.91      0.98      0.94       777\n",
      "    positive       0.94      0.76      0.84       309\n",
      "\n",
      "    accuracy                           0.92      1086\n",
      "   macro avg       0.92      0.87      0.89      1086\n",
      "weighted avg       0.92      0.92      0.92      1086\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2247: Accuracy: 0.9594, F1 Micro: 0.9594, F1 Macro: 0.8596\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.94      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.96      0.98      0.97       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.90      0.92        86\n",
      "     neutral       0.98      1.00      0.99       475\n",
      "    positive       0.62      0.50      0.56        10\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.85      0.80      0.82       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.85      0.84        78\n",
      "     neutral       0.98      0.97      0.97       491\n",
      "    positive       1.00      0.50      0.67         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.77      0.83       571\n",
      "weighted avg       0.96      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.87      0.69      0.77        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.61      0.56      0.58       571\n",
      "weighted avg       0.93      0.94      0.93       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.89      0.90       200\n",
      "     neutral       0.95      0.94      0.94       315\n",
      "    positive       0.84      0.96      0.90        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.93      0.92       571\n",
      "weighted avg       0.93      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.82      0.85       162\n",
      "     neutral       0.92      0.97      0.94       387\n",
      "    positive       0.83      0.45      0.59        22\n",
      "\n",
      "    accuracy                           0.91       571\n",
      "   macro avg       0.88      0.75      0.79       571\n",
      "weighted avg       0.90      0.91      0.90       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.88      0.87        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.94      0.94      0.94        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.52      0.65        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.71      0.88      0.79        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.86      0.80      0.81       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.95      0.96      0.95        54\n",
      "     neutral       0.99      0.99      0.99       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.98      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       1.00      1.00      1.00       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 384.0000190734863 s\n",
      "Launching training on 2 GPUs.\n",
      "Nearest checkpoint: 2283\n",
      "Acquired samples: 36\n",
      "Sampling duration: 2.0432820320129395 seconds\n",
      "New train size: 2283\n",
      "Launching training on 2 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n",
      "Error during conversion: ChunkedEncodingError(ProtocolError('Response ended prematurely'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASPECT DETECTION\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.4455, Accuracy: 0.8764, F1 Micro: 0.9276, F1 Macro: 0.9227\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.26, Accuracy: 0.9406, F1 Micro: 0.9637, F1 Macro: 0.9609\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1782, Accuracy: 0.9533, F1 Micro: 0.9712, F1 Macro: 0.969\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 4/10, Train Loss: 0.1405, Accuracy: 0.9575, F1 Micro: 0.9738, F1 Macro: 0.9718\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.117, Accuracy: 0.9623, F1 Micro: 0.9766, F1 Macro: 0.9747\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 6/10, Train Loss: 0.0999, Accuracy: 0.9651, F1 Micro: 0.9784, F1 Macro: 0.9764\n",
      "Epoch 7/10, Train Loss: 0.0821, Accuracy: 0.9644, F1 Micro: 0.9779, F1 Macro: 0.9758\n",
      "Epoch 8/10, Train Loss: 0.0673, Accuracy: 0.9642, F1 Micro: 0.9777, F1 Macro: 0.9755\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 9/10, Train Loss: 0.0563, Accuracy: 0.9661, F1 Micro: 0.9789, F1 Macro: 0.9769\n",
      "Epoch 10/10, Train Loss: 0.0487, Accuracy: 0.966, F1 Micro: 0.9789, F1 Macro: 0.977\n",
      "\n",
      "Aspect detection accuracy: 0.9661, F1 Micro: 0.9789, F1 Macro: 0.9769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ac       0.99      0.99      0.99       462\n",
      "   air_panas       0.99      1.00      0.99       480\n",
      "         bau       0.97      0.97      0.97       496\n",
      "     general       0.95      0.99      0.97       500\n",
      "  kebersihan       0.95      0.94      0.94       317\n",
      "       linen       0.94      0.96      0.95       392\n",
      "     service       0.98      0.96      0.97       423\n",
      "sunrise_meal       0.99      1.00      0.99       530\n",
      "          tv       1.00      0.99      1.00       516\n",
      "        wifi       1.00      1.00      1.00       498\n",
      "\n",
      "   micro avg       0.98      0.98      0.98      4614\n",
      "   macro avg       0.97      0.98      0.98      4614\n",
      "weighted avg       0.98      0.98      0.98      4614\n",
      " samples avg       0.97      0.98      0.98      4614\n",
      "\n",
      "--------------------------------------------------\n",
      "SENTIMENT ANALYSIS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Higher F1 achieved, saving model\n",
      "Epoch 1/10, Train Loss: 0.352, Accuracy: 0.875, F1 Micro: 0.875, F1 Macro: 0.8349\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 2/10, Train Loss: 0.208, Accuracy: 0.8986, F1 Micro: 0.8986, F1 Macro: 0.8685\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 3/10, Train Loss: 0.1244, Accuracy: 0.9058, F1 Micro: 0.9058, F1 Macro: 0.8787\n",
      "Epoch 4/10, Train Loss: 0.0875, Accuracy: 0.904, F1 Micro: 0.904, F1 Macro: 0.8735\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 5/10, Train Loss: 0.078, Accuracy: 0.9085, F1 Micro: 0.9085, F1 Macro: 0.8818\n",
      "Epoch 6/10, Train Loss: 0.0456, Accuracy: 0.9058, F1 Micro: 0.9058, F1 Macro: 0.8795\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 7/10, Train Loss: 0.0469, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8846\n",
      "Higher F1 achieved, saving model\n",
      "Epoch 8/10, Train Loss: 0.0246, Accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8836\n",
      "Epoch 9/10, Train Loss: 0.0205, Accuracy: 0.9085, F1 Micro: 0.9085, F1 Macro: 0.8828\n",
      "Epoch 10/10, Train Loss: 0.0242, Accuracy: 0.9031, F1 Micro: 0.9031, F1 Macro: 0.875\n",
      "\n",
      "Sentiment analysis accuracy: 0.9103, F1 Micro: 0.9103, F1 Macro: 0.8836\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.98      0.94       784\n",
      "    positive       0.93      0.74      0.83       320\n",
      "\n",
      "    accuracy                           0.91      1104\n",
      "   macro avg       0.92      0.86      0.88      1104\n",
      "weighted avg       0.91      0.91      0.91      1104\n",
      "\n",
      "--------------------------------------------------\n",
      "Iteration 2283: Accuracy: 0.9599, F1 Micro: 0.9599, F1 Macro: 0.8829\n",
      "--------------------------------------------------\n",
      "Aspect ac report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      0.93      0.95        97\n",
      "     neutral       0.99      0.99      0.99       459\n",
      "    positive       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.95      0.97      0.96       571\n",
      "weighted avg       0.98      0.98      0.98       571\n",
      "\n",
      "Aspect air_panas report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.94      0.91      0.92        86\n",
      "     neutral       0.99      1.00      0.99       475\n",
      "    positive       0.71      0.50      0.59        10\n",
      "\n",
      "    accuracy                           0.98       571\n",
      "   macro avg       0.88      0.80      0.83       571\n",
      "weighted avg       0.97      0.98      0.97       571\n",
      "\n",
      "Aspect bau report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.82      0.81      0.81        78\n",
      "     neutral       0.97      0.97      0.97       491\n",
      "    positive       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.93      0.93      0.93       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect general report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25         7\n",
      "     neutral       0.95      0.99      0.97       496\n",
      "    positive       0.89      0.71      0.79        68\n",
      "\n",
      "    accuracy                           0.94       571\n",
      "   macro avg       0.95      0.61      0.67       571\n",
      "weighted avg       0.94      0.94      0.94       571\n",
      "\n",
      "Aspect kebersihan report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.90      0.89      0.89       200\n",
      "     neutral       0.95      0.94      0.94       315\n",
      "    positive       0.84      0.95      0.89        56\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.90      0.92      0.91       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect linen report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.86      0.87       162\n",
      "     neutral       0.94      0.96      0.95       387\n",
      "    positive       0.85      0.50      0.63        22\n",
      "\n",
      "    accuracy                           0.92       571\n",
      "   macro avg       0.89      0.78      0.82       571\n",
      "weighted avg       0.92      0.92      0.92       571\n",
      "\n",
      "Aspect service report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.87      0.87        85\n",
      "     neutral       0.98      0.97      0.97       418\n",
      "    positive       0.90      0.96      0.93        68\n",
      "\n",
      "    accuracy                           0.95       571\n",
      "   macro avg       0.91      0.93      0.92       571\n",
      "weighted avg       0.95      0.95      0.95       571\n",
      "\n",
      "Aspect sunrise_meal report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.62      0.72        29\n",
      "     neutral       0.98      1.00      0.99       525\n",
      "    positive       0.79      0.88      0.83        17\n",
      "\n",
      "    accuracy                           0.97       571\n",
      "   macro avg       0.88      0.83      0.85       571\n",
      "weighted avg       0.97      0.97      0.97       571\n",
      "\n",
      "Aspect tv report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.96      0.95        54\n",
      "     neutral       1.00      0.99      1.00       511\n",
      "    positive       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.99       571\n",
      "   macro avg       0.97      0.93      0.95       571\n",
      "weighted avg       0.99      0.99      0.99       571\n",
      "\n",
      "Aspect wifi report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.97      1.00      0.99        74\n",
      "     neutral       1.00      1.00      1.00       494\n",
      "    positive       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00       571\n",
      "   macro avg       0.99      1.00      0.99       571\n",
      "weighted avg       1.00      1.00      1.00       571\n",
      "\n",
      "Total train time: 395.63264560699463 s\n",
      "Total runtime: 8390.23510313034 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2100x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "active_learning(seeds[4], 4)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6175442,
     "sourceId": 10027624,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8421.919076,
   "end_time": "2025-03-31T06:48:02.988550",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-31T04:27:41.069474",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "165a728e7dbc4f01ae73841900f896e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2925248005d848a9b36f05073e942995",
       "placeholder": "",
       "style": "IPY_MODEL_35993bbf51294b66b635f0f4f85316fa",
       "tabbable": null,
       "tooltip": null,
       "value": "1.53k/1.53k[00:00&lt;00:00,161kB/s]"
      }
     },
     "22b2cb692f0f4316901ec1fe7546d31a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "22c191d59a5e4a01a7acc42451cac516": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2925248005d848a9b36f05073e942995": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2a2e583225e14f228fe37379503089d6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_914798d8b8de467dbfe3df748594021a",
        "IPY_MODEL_50f2873f83b24e6f9000484eaeca73fc",
        "IPY_MODEL_80508b67765c42e8a0c921cc27267737"
       ],
       "layout": "IPY_MODEL_30d91ab6ca874f8280ed9c8afcc631af",
       "tabbable": null,
       "tooltip": null
      }
     },
     "30d91ab6ca874f8280ed9c8afcc631af": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "356b4a17671a43d18417a4ae9da7478f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "35993bbf51294b66b635f0f4f85316fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3b96a5ba74aa4944af6d4959154b3c2a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3c70aa17ccac415f9e2d684c880b6cf5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3d27d5c4324e4e87875ba9efb277097f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "458c11d00e964af39204898c37c125df": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e3474c5f8e45413491ace26e0264dd79",
       "placeholder": "",
       "style": "IPY_MODEL_d9ce1e0dcc924e87b171d8cc46432af8",
       "tabbable": null,
       "tooltip": null,
       "value": "229k/229k[00:00&lt;00:00,4.50MB/s]"
      }
     },
     "4a556decfd014822803f49198899317a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4cdbb022f4c746908e94ab7f374833d4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4d6649887bc54064a3acf847845fbabd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4e4f23fc5f044dada6afa9d31d0cd38b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "50f2873f83b24e6f9000484eaeca73fc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4e4f23fc5f044dada6afa9d31d0cd38b",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a960cad00bd14edd8a0e378592277116",
       "tabbable": null,
       "tooltip": null,
       "value": 2
      }
     },
     "6a62650e310e4d2dbb5a3ff6c6b43b61": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a4d3a5cdc01e4c51b4f672228a750d5c",
        "IPY_MODEL_b486c5c72a3743bf9723b5ce7f168003",
        "IPY_MODEL_458c11d00e964af39204898c37c125df"
       ],
       "layout": "IPY_MODEL_916bccb976924956ba1dcc4ed5a6910e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "6a8368a53c7d4365b2988a632b57d7ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_22b2cb692f0f4316901ec1fe7546d31a",
       "placeholder": "",
       "style": "IPY_MODEL_356b4a17671a43d18417a4ae9da7478f",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json:100%"
      }
     },
     "76eb576d99714e83a6f3fcb47035470a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "77b41effde9b4dda894d167d84b73caf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6a8368a53c7d4365b2988a632b57d7ff",
        "IPY_MODEL_d8f63dbdc01f456da29b7f8d705139aa",
        "IPY_MODEL_88b23f0753ba48c78f9307f1fea880de"
       ],
       "layout": "IPY_MODEL_c12c49ca467c44ff8ed90e21e5285d2f",
       "tabbable": null,
       "tooltip": null
      }
     },
     "80508b67765c42e8a0c921cc27267737": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3c70aa17ccac415f9e2d684c880b6cf5",
       "placeholder": "",
       "style": "IPY_MODEL_a462f9f55d634297a97aa3c268691763",
       "tabbable": null,
       "tooltip": null,
       "value": "2.00/2.00[00:00&lt;00:00,116B/s]"
      }
     },
     "88b23f0753ba48c78f9307f1fea880de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_22c191d59a5e4a01a7acc42451cac516",
       "placeholder": "",
       "style": "IPY_MODEL_4d6649887bc54064a3acf847845fbabd",
       "tabbable": null,
       "tooltip": null,
       "value": "112/112[00:00&lt;00:00,11.3kB/s]"
      }
     },
     "8d7c7083132b4c34ba2c64edaefeb5d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "914798d8b8de467dbfe3df748594021a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3d27d5c4324e4e87875ba9efb277097f",
       "placeholder": "",
       "style": "IPY_MODEL_f8a6eec386be442a8d1c16e24556d433",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json:100%"
      }
     },
     "916bccb976924956ba1dcc4ed5a6910e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9bd05646fde5415ea2ff523edf1fa7e6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a2a5e0bd0cb0421389eeb38b69ea8a5c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e8dc3c981df54739a22c411100f0e391",
       "placeholder": "",
       "style": "IPY_MODEL_c4dbf86d14b549ab8deb8f6646700224",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json:100%"
      }
     },
     "a462f9f55d634297a97aa3c268691763": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a4d3a5cdc01e4c51b4f672228a750d5c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ca69fdaa478045c8b1267869e090266e",
       "placeholder": "",
       "style": "IPY_MODEL_be83acc6a4294033afa05e3edb2353b7",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt:100%"
      }
     },
     "a960cad00bd14edd8a0e378592277116": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b486c5c72a3743bf9723b5ce7f168003": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9bd05646fde5415ea2ff523edf1fa7e6",
       "max": 229167,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c716eafec420407f97352b79765ee60a",
       "tabbable": null,
       "tooltip": null,
       "value": 229167
      }
     },
     "be83acc6a4294033afa05e3edb2353b7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c12c49ca467c44ff8ed90e21e5285d2f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c4dbf86d14b549ab8deb8f6646700224": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c716eafec420407f97352b79765ee60a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ca69fdaa478045c8b1267869e090266e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d8f63dbdc01f456da29b7f8d705139aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_76eb576d99714e83a6f3fcb47035470a",
       "max": 112,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3b96a5ba74aa4944af6d4959154b3c2a",
       "tabbable": null,
       "tooltip": null,
       "value": 112
      }
     },
     "d9ce1e0dcc924e87b171d8cc46432af8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "da68c00ec9be4c8d95fa2e4f7ea4d603": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a2a5e0bd0cb0421389eeb38b69ea8a5c",
        "IPY_MODEL_fe6d3cca4dfd4492ad2e90a082df5756",
        "IPY_MODEL_165a728e7dbc4f01ae73841900f896e3"
       ],
       "layout": "IPY_MODEL_4a556decfd014822803f49198899317a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "e3474c5f8e45413491ace26e0264dd79": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e8dc3c981df54739a22c411100f0e391": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f8a6eec386be442a8d1c16e24556d433": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fe6d3cca4dfd4492ad2e90a082df5756": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4cdbb022f4c746908e94ab7f374833d4",
       "max": 1534,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8d7c7083132b4c34ba2c64edaefeb5d4",
       "tabbable": null,
       "tooltip": null,
       "value": 1534
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
